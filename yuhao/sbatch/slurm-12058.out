# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0)
('number_of_mlp_layer', 0)
('lr', 0.003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-13-33-21/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-13-33-21/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0,
 'embedding_size_dfscode_rnn': 8,
 'epochs': 50,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 4,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.003,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 1,
 'num_workers': 8,
 'number_of_mlp_layer': 0,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-18-13-33-21',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 50, 'learning_rate': 0.003, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, batch_first=True)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.003
[92maverage training of epoch 0: loss -1.29755 acc 0.49333 roc_auc 0.44960 prc_auc 0.66189[0m
[93maverage test of epoch 0: loss -2.57313 acc 0.65789 roc_auc 0.85846 prc_auc 0.92975[0m
[92maverage training of epoch 1: loss -3.89097 acc 0.66667 roc_auc 0.38140 prc_auc 0.59260[0m
[93maverage test of epoch 1: loss -5.07686 acc 0.65789 roc_auc 0.86154 prc_auc 0.93134[0m
[92maverage training of epoch 2: loss -6.08653 acc 0.66667 roc_auc 0.36640 prc_auc 0.57020[0m
[93maverage test of epoch 2: loss -7.03830 acc 0.65789 roc_auc 0.85692 prc_auc 0.92034[0m
[92maverage training of epoch 3: loss -7.97448 acc 0.66667 roc_auc 0.36020 prc_auc 0.56447[0m
[93maverage test of epoch 3: loss -8.86367 acc 0.65789 roc_auc 0.83846 prc_auc 0.88953[0m
[92maverage training of epoch 4: loss -9.77311 acc 0.66667 roc_auc 0.35940 prc_auc 0.56353[0m
[93maverage test of epoch 4: loss -10.63111 acc 0.65789 roc_auc 0.85385 prc_auc 0.90932[0m
[92maverage training of epoch 5: loss -11.52831 acc 0.66667 roc_auc 0.35800 prc_auc 0.56260[0m
[93maverage test of epoch 5: loss -12.36643 acc 0.65789 roc_auc 0.83231 prc_auc 0.89898[0m
[92maverage training of epoch 6: loss -13.25782 acc 0.66667 roc_auc 0.35740 prc_auc 0.56208[0m
[93maverage test of epoch 6: loss -14.08144 acc 0.65789 roc_auc 0.61231 prc_auc 0.71354[0m
[92maverage training of epoch 7: loss -14.97045 acc 0.66667 roc_auc 0.35750 prc_auc 0.56213[0m
[93maverage test of epoch 7: loss -15.78258 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 8: loss -16.67124 acc 0.66667 roc_auc 0.35740 prc_auc 0.56193[0m
[93maverage test of epoch 8: loss -17.47373 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 9: loss -18.36334 acc 0.66667 roc_auc 0.35720 prc_auc 0.56197[0m
[93maverage test of epoch 9: loss -19.15740 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 10: loss -20.04885 acc 0.66667 roc_auc 0.35730 prc_auc 0.56168[0m
[93maverage test of epoch 10: loss -20.83531 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 11: loss -21.72924 acc 0.66667 roc_auc 0.35760 prc_auc 0.56252[0m
[93maverage test of epoch 11: loss -22.50871 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 12: loss -23.40557 acc 0.66667 roc_auc 0.35760 prc_auc 0.56253[0m
[93maverage test of epoch 12: loss -24.17851 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 13: loss -25.07865 acc 0.66667 roc_auc 0.35780 prc_auc 0.56347[0m
[93maverage test of epoch 13: loss -25.84539 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 14: loss -26.74907 acc 0.66667 roc_auc 0.35800 prc_auc 0.56292[0m
[93maverage test of epoch 14: loss -27.50987 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 15: loss -28.41731 acc 0.66667 roc_auc 0.35850 prc_auc 0.56557[0m
[93maverage test of epoch 15: loss -29.17239 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 16: loss -30.08374 acc 0.66667 roc_auc 0.36120 prc_auc 0.56802[0m
[93maverage test of epoch 16: loss -30.83327 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 17: loss -31.74867 acc 0.66667 roc_auc 0.35800 prc_auc 0.56954[0m
[93maverage test of epoch 17: loss -32.49277 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 18: loss -33.41233 acc 0.66667 roc_auc 0.36570 prc_auc 0.57767[0m
[93maverage test of epoch 18: loss -34.15112 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -35.07492 acc 0.66667 roc_auc 0.36780 prc_auc 0.58388[0m
[93maverage test of epoch 19: loss -35.80849 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -36.73662 acc 0.66667 roc_auc 0.36480 prc_auc 0.59262[0m
[93maverage test of epoch 20: loss -37.46504 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -38.39756 acc 0.66667 roc_auc 0.37720 prc_auc 0.60493[0m
[93maverage test of epoch 21: loss -39.12090 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -40.05784 acc 0.66667 roc_auc 0.43230 prc_auc 0.63385[0m
[93maverage test of epoch 22: loss -40.77615 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -41.71757 acc 0.66667 roc_auc 0.43220 prc_auc 0.63636[0m
[93maverage test of epoch 23: loss -42.43088 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -43.37681 acc 0.66667 roc_auc 0.46500 prc_auc 0.65153[0m
[93maverage test of epoch 24: loss -44.08517 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -45.03565 acc 0.66667 roc_auc 0.48500 prc_auc 0.66007[0m
[93maverage test of epoch 25: loss -45.73909 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -46.69412 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 26: loss -47.39266 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -48.35228 acc 0.66667 roc_auc 0.47000 prc_auc 0.65364[0m
[93maverage test of epoch 27: loss -49.04595 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -50.01019 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 28: loss -50.69901 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -51.66786 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 29: loss -52.35185 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -53.32534 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 30: loss -54.00449 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -54.98262 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 31: loss -55.65696 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -56.63976 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 32: loss -57.30930 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -58.29676 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 33: loss -58.96151 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -59.95365 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -60.61361 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -61.61044 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -62.26562 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -63.26712 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -63.91753 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -64.92372 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -65.56935 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -66.58024 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -67.22112 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -68.23670 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -68.87280 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -69.89308 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -70.52442 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -71.54941 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -72.17600 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -73.20568 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -73.82750 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -74.86188 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -75.47895 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -76.51805 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -77.13037 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -78.17417 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -78.78174 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -79.83025 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -80.43308 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -81.48631 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -82.08440 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -83.14235 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -83.73570 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -84.79836 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -85.38696 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, batch_first=True)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.003
[92maverage training of epoch 0: loss -2.17079 acc 0.66667 roc_auc 0.42480 prc_auc 0.61216[0m
[93maverage test of epoch 0: loss -3.69410 acc 0.65789 roc_auc 0.89231 prc_auc 0.94071[0m
[92maverage training of epoch 1: loss -4.68087 acc 0.66667 roc_auc 0.43800 prc_auc 0.62713[0m
[93maverage test of epoch 1: loss -5.65689 acc 0.65789 roc_auc 0.89231 prc_auc 0.94071[0m
[92maverage training of epoch 2: loss -6.59843 acc 0.66667 roc_auc 0.42900 prc_auc 0.61769[0m
[93maverage test of epoch 2: loss -7.50281 acc 0.65789 roc_auc 0.89231 prc_auc 0.94089[0m
[92maverage training of epoch 3: loss -8.40774 acc 0.66667 roc_auc 0.42400 prc_auc 0.60975[0m
[93maverage test of epoch 3: loss -9.27090 acc 0.65789 roc_auc 0.88308 prc_auc 0.92717[0m
[92maverage training of epoch 4: loss -10.16067 acc 0.66667 roc_auc 0.42160 prc_auc 0.60603[0m
[93maverage test of epoch 4: loss -11.00128 acc 0.65789 roc_auc 0.84308 prc_auc 0.86889[0m
[92maverage training of epoch 5: loss -11.88471 acc 0.66667 roc_auc 0.42060 prc_auc 0.60514[0m
[93maverage test of epoch 5: loss -12.71026 acc 0.65789 roc_auc 0.88462 prc_auc 0.90133[0m
[92maverage training of epoch 6: loss -13.59145 acc 0.66667 roc_auc 0.42020 prc_auc 0.60463[0m
[93maverage test of epoch 6: loss -14.40557 acc 0.65789 roc_auc 0.82308 prc_auc 0.84667[0m
[92maverage training of epoch 7: loss -15.28674 acc 0.66667 roc_auc 0.42010 prc_auc 0.60494[0m
[93maverage test of epoch 7: loss -16.09148 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 8: loss -16.97396 acc 0.66667 roc_auc 0.42010 prc_auc 0.60494[0m
[93maverage test of epoch 8: loss -17.77058 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 9: loss -18.65524 acc 0.66667 roc_auc 0.42020 prc_auc 0.60497[0m
[93maverage test of epoch 9: loss -19.44457 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 10: loss -20.33199 acc 0.66667 roc_auc 0.42020 prc_auc 0.60550[0m
[93maverage test of epoch 10: loss -21.11461 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 11: loss -22.00522 acc 0.66667 roc_auc 0.42020 prc_auc 0.60539[0m
[93maverage test of epoch 11: loss -22.78154 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 12: loss -23.67565 acc 0.66667 roc_auc 0.42070 prc_auc 0.60512[0m
[93maverage test of epoch 12: loss -24.44599 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 13: loss -25.34383 acc 0.66667 roc_auc 0.42030 prc_auc 0.60572[0m
[93maverage test of epoch 13: loss -26.10841 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 14: loss -27.01016 acc 0.66667 roc_auc 0.42030 prc_auc 0.60286[0m
[93maverage test of epoch 14: loss -27.76918 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 15: loss -28.67499 acc 0.66667 roc_auc 0.42090 prc_auc 0.60333[0m
[93maverage test of epoch 15: loss -29.42858 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 16: loss -30.33855 acc 0.66667 roc_auc 0.41870 prc_auc 0.59961[0m
[93maverage test of epoch 16: loss -31.08684 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 17: loss -32.00107 acc 0.66667 roc_auc 0.41830 prc_auc 0.60496[0m
[93maverage test of epoch 17: loss -32.74415 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 18: loss -33.66271 acc 0.66667 roc_auc 0.42000 prc_auc 0.60273[0m
[93maverage test of epoch 18: loss -34.40064 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -35.32360 acc 0.66667 roc_auc 0.42030 prc_auc 0.60566[0m
[93maverage test of epoch 19: loss -36.05646 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -36.98386 acc 0.66667 roc_auc 0.42790 prc_auc 0.61500[0m
[93maverage test of epoch 20: loss -37.71170 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -38.64358 acc 0.66667 roc_auc 0.44040 prc_auc 0.62825[0m
[93maverage test of epoch 21: loss -39.36644 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -40.30284 acc 0.66667 roc_auc 0.45140 prc_auc 0.63838[0m
[93maverage test of epoch 22: loss -41.02076 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -41.96171 acc 0.66667 roc_auc 0.46000 prc_auc 0.64403[0m
[93maverage test of epoch 23: loss -42.67471 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -43.62023 acc 0.66667 roc_auc 0.44280 prc_auc 0.63853[0m
[93maverage test of epoch 24: loss -44.32835 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -45.27846 acc 0.66667 roc_auc 0.45500 prc_auc 0.64810[0m
[93maverage test of epoch 25: loss -45.98171 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -46.93644 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 26: loss -47.63483 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -48.59419 acc 0.66667 roc_auc 0.44000 prc_auc 0.64267[0m
[93maverage test of epoch 27: loss -49.28776 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -50.25176 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 28: loss -50.94050 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -51.90915 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 29: loss -52.59309 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -53.56640 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 30: loss -54.24554 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -55.22352 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 31: loss -55.89787 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -56.88053 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 32: loss -57.55009 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -58.53743 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 33: loss -59.20222 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -60.19424 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -60.85426 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -61.85098 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -62.50624 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -63.50764 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -64.15814 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -65.16424 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -65.80997 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -66.82077 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -67.46176 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -68.47726 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -69.11347 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -70.13369 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -70.76515 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -71.79007 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -72.41679 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -73.44642 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -74.06838 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -75.10272 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -75.71994 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -76.75898 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -77.37146 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -78.41522 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -79.02294 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -80.07141 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -80.67439 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -81.72758 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -82.32582 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -83.38371 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -83.97720 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -85.03980 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -85.62855 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, batch_first=True)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.003
[92maverage training of epoch 0: loss -2.90363 acc 0.56667 roc_auc 0.38300 prc_auc 0.58311[0m
[93maverage test of epoch 0: loss -4.29529 acc 0.65789 roc_auc 0.05385 prc_auc 0.46713[0m
[92maverage training of epoch 1: loss -5.28191 acc 0.66667 roc_auc 0.37980 prc_auc 0.57817[0m
[93maverage test of epoch 1: loss -6.22982 acc 0.65789 roc_auc 0.84615 prc_auc 0.91008[0m
[92maverage training of epoch 2: loss -7.11515 acc 0.66667 roc_auc 0.37800 prc_auc 0.57504[0m
[93maverage test of epoch 2: loss -7.99669 acc 0.65789 roc_auc 0.92000 prc_auc 0.94526[0m
[92maverage training of epoch 3: loss -8.86056 acc 0.66667 roc_auc 0.37760 prc_auc 0.57524[0m
[93maverage test of epoch 3: loss -9.71754 acc 0.65789 roc_auc 0.87077 prc_auc 0.90949[0m
[92maverage training of epoch 4: loss -10.57447 acc 0.66667 roc_auc 0.37740 prc_auc 0.57497[0m
[93maverage test of epoch 4: loss -11.41686 acc 0.65789 roc_auc 0.72154 prc_auc 0.79865[0m
[92maverage training of epoch 5: loss -12.27192 acc 0.66667 roc_auc 0.37720 prc_auc 0.57467[0m
[93maverage test of epoch 5: loss -13.10370 acc 0.65789 roc_auc 0.69231 prc_auc 0.75758[0m
[92maverage training of epoch 6: loss -13.95926 acc 0.66667 roc_auc 0.37740 prc_auc 0.57486[0m
[93maverage test of epoch 6: loss -14.78240 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 7: loss -15.63977 acc 0.66667 roc_auc 0.37740 prc_auc 0.57486[0m
[93maverage test of epoch 7: loss -16.45541 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 8: loss -17.31539 acc 0.66667 roc_auc 0.37720 prc_auc 0.57477[0m
[93maverage test of epoch 8: loss -18.12427 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 9: loss -18.98738 acc 0.66667 roc_auc 0.37710 prc_auc 0.57458[0m
[93maverage test of epoch 9: loss -19.78997 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 10: loss -20.65657 acc 0.66667 roc_auc 0.37720 prc_auc 0.57463[0m
[93maverage test of epoch 10: loss -21.45322 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 11: loss -22.32357 acc 0.66667 roc_auc 0.37700 prc_auc 0.57444[0m
[93maverage test of epoch 11: loss -23.11452 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 12: loss -23.98883 acc 0.66667 roc_auc 0.37690 prc_auc 0.57462[0m
[93maverage test of epoch 12: loss -24.77427 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 13: loss -25.65267 acc 0.66667 roc_auc 0.37690 prc_auc 0.57467[0m
[93maverage test of epoch 13: loss -26.43274 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 14: loss -27.31535 acc 0.66667 roc_auc 0.37680 prc_auc 0.57505[0m
[93maverage test of epoch 14: loss -28.09017 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 15: loss -28.97707 acc 0.66667 roc_auc 0.37690 prc_auc 0.57609[0m
[93maverage test of epoch 15: loss -29.74672 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 16: loss -30.63798 acc 0.66667 roc_auc 0.37710 prc_auc 0.57651[0m
[93maverage test of epoch 16: loss -31.40254 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 17: loss -32.29823 acc 0.66667 roc_auc 0.37800 prc_auc 0.57852[0m
[93maverage test of epoch 17: loss -33.05775 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 18: loss -33.95791 acc 0.66667 roc_auc 0.37730 prc_auc 0.57653[0m
[93maverage test of epoch 18: loss -34.71244 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -35.61711 acc 0.66667 roc_auc 0.37870 prc_auc 0.57605[0m
[93maverage test of epoch 19: loss -36.36669 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -37.27590 acc 0.66667 roc_auc 0.37910 prc_auc 0.57960[0m
[93maverage test of epoch 20: loss -38.02056 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -38.93434 acc 0.66667 roc_auc 0.38300 prc_auc 0.58526[0m
[93maverage test of epoch 21: loss -39.67411 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -40.59249 acc 0.66667 roc_auc 0.37710 prc_auc 0.58501[0m
[93maverage test of epoch 22: loss -41.32738 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -42.25036 acc 0.66667 roc_auc 0.38110 prc_auc 0.59032[0m
[93maverage test of epoch 23: loss -42.98041 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -43.90802 acc 0.66667 roc_auc 0.39090 prc_auc 0.60170[0m
[93maverage test of epoch 24: loss -44.63323 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -45.56548 acc 0.66667 roc_auc 0.40350 prc_auc 0.61422[0m
[93maverage test of epoch 25: loss -46.28587 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -47.22277 acc 0.66667 roc_auc 0.39340 prc_auc 0.61261[0m
[93maverage test of epoch 26: loss -47.93835 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -48.87991 acc 0.66667 roc_auc 0.46000 prc_auc 0.64956[0m
[93maverage test of epoch 27: loss -49.59069 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -50.53692 acc 0.66667 roc_auc 0.43820 prc_auc 0.64469[0m
[93maverage test of epoch 28: loss -51.24292 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -52.19382 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 29: loss -52.89503 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -53.85062 acc 0.66667 roc_auc 0.46500 prc_auc 0.66200[0m
[93maverage test of epoch 30: loss -54.54705 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -55.50733 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 31: loss -56.19899 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -57.16395 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 32: loss -57.85084 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -58.82050 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 33: loss -59.50263 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -60.47699 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -61.15435 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -62.13342 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -62.80603 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -63.78979 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -64.45765 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -65.44611 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -66.10922 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -67.10239 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -67.76074 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -68.75863 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -69.41222 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -70.41483 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -71.06368 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -72.07099 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -72.71510 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -73.72712 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -74.36648 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -75.38322 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -76.01783 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -77.03928 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -77.66915 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -78.69532 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -79.32044 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -80.35132 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -80.97169 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -82.00729 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -82.62291 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -83.66322 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -84.27409 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -85.31912 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -85.92524 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, batch_first=True)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.003
[92maverage training of epoch 0: loss -1.81610 acc 0.66225 roc_auc 0.45549 prc_auc 0.64913[0m
[93maverage test of epoch 0: loss -3.06363 acc 0.67568 roc_auc 0.84000 prc_auc 0.90538[0m
[92maverage training of epoch 1: loss -4.10322 acc 0.66225 roc_auc 0.38294 prc_auc 0.58517[0m
[93maverage test of epoch 1: loss -5.15586 acc 0.67568 roc_auc 0.85333 prc_auc 0.91715[0m
[92maverage training of epoch 2: loss -6.04369 acc 0.66225 roc_auc 0.38000 prc_auc 0.57176[0m
[93maverage test of epoch 2: loss -7.00903 acc 0.67568 roc_auc 0.85167 prc_auc 0.91612[0m
[92maverage training of epoch 3: loss -7.84707 acc 0.66225 roc_auc 0.37784 prc_auc 0.57160[0m
[93maverage test of epoch 3: loss -8.78758 acc 0.67568 roc_auc 0.86000 prc_auc 0.90163[0m
[92maverage training of epoch 4: loss -9.59943 acc 0.66225 roc_auc 0.37667 prc_auc 0.57069[0m
[93maverage test of epoch 4: loss -10.53158 acc 0.67568 roc_auc 0.77333 prc_auc 0.82977[0m
[92maverage training of epoch 5: loss -11.32561 acc 0.66225 roc_auc 0.37667 prc_auc 0.57069[0m
[93maverage test of epoch 5: loss -12.25583 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 6: loss -13.03597 acc 0.66225 roc_auc 0.37667 prc_auc 0.57069[0m
[93maverage test of epoch 6: loss -13.96742 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 7: loss -14.73579 acc 0.66225 roc_auc 0.37647 prc_auc 0.57033[0m
[93maverage test of epoch 7: loss -15.67026 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 8: loss -16.42815 acc 0.66225 roc_auc 0.37618 prc_auc 0.56983[0m
[93maverage test of epoch 8: loss -17.36673 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 9: loss -18.11500 acc 0.66225 roc_auc 0.37598 prc_auc 0.56974[0m
[93maverage test of epoch 9: loss -19.05843 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 10: loss -19.79764 acc 0.66225 roc_auc 0.37578 prc_auc 0.56968[0m
[93maverage test of epoch 10: loss -20.74643 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 11: loss -21.47701 acc 0.66225 roc_auc 0.37588 prc_auc 0.56988[0m
[93maverage test of epoch 11: loss -22.43151 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 12: loss -23.15377 acc 0.66225 roc_auc 0.37578 prc_auc 0.56962[0m
[93maverage test of epoch 12: loss -24.11425 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 13: loss -24.82843 acc 0.66225 roc_auc 0.37608 prc_auc 0.57021[0m
[93maverage test of epoch 13: loss -25.79511 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 14: loss -26.50137 acc 0.66225 roc_auc 0.37569 prc_auc 0.57009[0m
[93maverage test of epoch 14: loss -27.47440 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 15: loss -28.17290 acc 0.66225 roc_auc 0.37608 prc_auc 0.57164[0m
[93maverage test of epoch 15: loss -29.15241 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 16: loss -29.84325 acc 0.66225 roc_auc 0.37559 prc_auc 0.57346[0m
[93maverage test of epoch 16: loss -30.82935 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 17: loss -31.51263 acc 0.66225 roc_auc 0.37353 prc_auc 0.57023[0m
[93maverage test of epoch 17: loss -32.50538 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 18: loss -33.18118 acc 0.66225 roc_auc 0.37520 prc_auc 0.57279[0m
[93maverage test of epoch 18: loss -34.18066 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 19: loss -34.84904 acc 0.66225 roc_auc 0.37510 prc_auc 0.57354[0m
[93maverage test of epoch 19: loss -35.85530 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 20: loss -36.51630 acc 0.66225 roc_auc 0.37892 prc_auc 0.58036[0m
[93maverage test of epoch 20: loss -37.52940 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 21: loss -38.18307 acc 0.66225 roc_auc 0.37667 prc_auc 0.58254[0m
[93maverage test of epoch 21: loss -39.20303 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 22: loss -39.84940 acc 0.66225 roc_auc 0.38441 prc_auc 0.58882[0m
[93maverage test of epoch 22: loss -40.87626 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 23: loss -41.51536 acc 0.66225 roc_auc 0.38265 prc_auc 0.59617[0m
[93maverage test of epoch 23: loss -42.54915 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 24: loss -43.18101 acc 0.66225 roc_auc 0.40127 prc_auc 0.60959[0m
[93maverage test of epoch 24: loss -44.22174 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 25: loss -44.84638 acc 0.66225 roc_auc 0.39804 prc_auc 0.61364[0m
[93maverage test of epoch 25: loss -45.89408 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 26: loss -46.51151 acc 0.66225 roc_auc 0.41902 prc_auc 0.62722[0m
[93maverage test of epoch 26: loss -47.56618 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 27: loss -48.17643 acc 0.66225 roc_auc 0.42245 prc_auc 0.63039[0m
[93maverage test of epoch 27: loss -49.23811 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 28: loss -49.84118 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 28: loss -50.90987 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 29: loss -51.50578 acc 0.66225 roc_auc 0.44647 prc_auc 0.63981[0m
[93maverage test of epoch 29: loss -52.58147 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 30: loss -53.17023 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 30: loss -54.25295 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 31: loss -54.83456 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 31: loss -55.92431 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 32: loss -56.49877 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 32: loss -57.59557 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 33: loss -58.16289 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 33: loss -59.26673 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 34: loss -59.82693 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 34: loss -60.93783 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 35: loss -61.49090 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 35: loss -62.60885 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 36: loss -63.15479 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 36: loss -64.27979 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 37: loss -64.81863 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 37: loss -65.95069 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 38: loss -66.48241 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 38: loss -67.62154 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 39: loss -68.14613 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 39: loss -69.29232 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -69.80980 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 40: loss -70.96306 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -71.47344 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 41: loss -72.63377 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -73.13704 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 42: loss -74.30445 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -74.80061 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 43: loss -75.97509 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -76.46414 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 44: loss -77.64570 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -78.12765 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 45: loss -79.31627 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -79.79111 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 46: loss -80.98682 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -81.45454 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 47: loss -82.65730 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -83.11792 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 48: loss -84.32777 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -84.78127 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 49: loss -85.99820 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, batch_first=True)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.003
[92maverage training of epoch 0: loss -0.88876 acc 0.66225 roc_auc 0.44353 prc_auc 0.63309[0m
[93maverage test of epoch 0: loss -2.20028 acc 0.67568 roc_auc 0.94000 prc_auc 0.97638[0m
[92maverage training of epoch 1: loss -3.43339 acc 0.66225 roc_auc 0.77608 prc_auc 0.83161[0m
[93maverage test of epoch 1: loss -4.70039 acc 0.72973 roc_auc 0.93667 prc_auc 0.97569[0m
[92maverage training of epoch 2: loss -5.52433 acc 0.81457 roc_auc 0.80471 prc_auc 0.83499[0m
[93maverage test of epoch 2: loss -6.44071 acc 0.81081 roc_auc 0.93333 prc_auc 0.97438[0m
[92maverage training of epoch 3: loss -7.29168 acc 0.85430 roc_auc 0.80275 prc_auc 0.82769[0m
[93maverage test of epoch 3: loss -8.04949 acc 0.81081 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 4: loss -8.93511 acc 0.85430 roc_auc 0.80843 prc_auc 0.82156[0m
[93maverage test of epoch 4: loss -9.60054 acc 0.81081 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 5: loss -10.51184 acc 0.85430 roc_auc 0.81137 prc_auc 0.81820[0m
[93maverage test of epoch 5: loss -11.16755 acc 0.81081 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 6: loss -12.09517 acc 0.85430 roc_auc 0.81020 prc_auc 0.81774[0m
[93maverage test of epoch 6: loss -12.75771 acc 0.81081 roc_auc 0.93000 prc_auc 0.97264[0mUsing backend: pytorch

[92maverage training of epoch 7: loss -13.66410 acc 0.85430 roc_auc 0.80647 prc_auc 0.81798[0m
[93maverage test of epoch 7: loss -14.33494 acc 0.81081 roc_auc 0.92833 prc_auc 0.97104[0m
[92maverage training of epoch 8: loss -15.21925 acc 0.85430 roc_auc 0.80598 prc_auc 0.81911[0m
[93maverage test of epoch 8: loss -15.90978 acc 0.81081 roc_auc 0.93167 prc_auc 0.97104[0m
[92maverage training of epoch 9: loss -16.78101 acc 0.85430 roc_auc 0.80637 prc_auc 0.82077[0m
[93maverage test of epoch 9: loss -17.46617 acc 0.81081 roc_auc 0.93333 prc_auc 0.97104[0m
[92maverage training of epoch 10: loss -18.34176 acc 0.85430 roc_auc 0.80765 prc_auc 0.82550[0m
[93maverage test of epoch 10: loss -19.01284 acc 0.81081 roc_auc 0.93333 prc_auc 0.96845[0m
[92maverage training of epoch 11: loss -19.90312 acc 0.85430 roc_auc 0.80961 prc_auc 0.83360[0m
[93maverage test of epoch 11: loss -20.55294 acc 0.81081 roc_auc 0.93333 prc_auc 0.96845[0m
[92maverage training of epoch 12: loss -21.46146 acc 0.85430 roc_auc 0.81716 prc_auc 0.85095[0m
[93maverage test of epoch 12: loss -22.09320 acc 0.81081 roc_auc 0.79333 prc_auc 0.84401[0m
[92maverage training of epoch 13: loss -23.02216 acc 0.85430 roc_auc 0.83755 prc_auc 0.87393[0m
[93maverage test of epoch 13: loss -23.63371 acc 0.81081 roc_auc 0.79333 prc_auc 0.84401[0m
[92maverage training of epoch 14: loss -24.59694 acc 0.86093 roc_auc 0.82147 prc_auc 0.86045[0m
[93maverage test of epoch 14: loss -25.17431 acc 0.81081 roc_auc 0.78667 prc_auc 0.83899[0m
[92maverage training of epoch 15: loss -26.16951 acc 0.86755 roc_auc 0.84843 prc_auc 0.88408[0m
[93maverage test of epoch 15: loss -26.70540 acc 0.81081 roc_auc 0.79333 prc_auc 0.84401[0m
[92maverage training of epoch 16: loss -27.72836 acc 0.86755 roc_auc 0.85108 prc_auc 0.88612[0m
[93maverage test of epoch 16: loss -28.23362 acc 0.81081 roc_auc 0.79333 prc_auc 0.84401[0m
[92maverage training of epoch 17: loss -29.28064 acc 0.86755 roc_auc 0.84529 prc_auc 0.88097[0m
[93maverage test of epoch 17: loss -29.75703 acc 0.81081 roc_auc 0.79333 prc_auc 0.84401[0m
[92maverage training of epoch 18: loss -30.83658 acc 0.86755 roc_auc 0.85549 prc_auc 0.88999[0m
[93maverage test of epoch 18: loss -31.26918 acc 0.81081 roc_auc 0.79333 prc_auc 0.84401[0m
[92maverage training of epoch 19: loss -32.40725 acc 0.86755 roc_auc 0.86441 prc_auc 0.89817[0m
[93maverage test of epoch 19: loss -32.77512 acc 0.81081 roc_auc 0.79333 prc_auc 0.84401[0m
[92maverage training of epoch 20: loss -33.96730 acc 0.86755 roc_auc 0.86461 prc_auc 0.89823[0m
[93maverage test of epoch 20: loss -34.28237 acc 0.81081 roc_auc 0.79333 prc_auc 0.84401[0m
[92maverage training of epoch 21: loss -35.51114 acc 0.86755 roc_auc 0.86520 prc_auc 0.89838[0m
[93maverage test of epoch 21: loss -35.79407 acc 0.81081 roc_auc 0.79333 prc_auc 0.84401[0m
[92maverage training of epoch 22: loss -37.05171 acc 0.86755 roc_auc 0.86578 prc_auc 0.89853[0m
[93maverage test of epoch 22: loss -37.31808 acc 0.81081 roc_auc 0.79333 prc_auc 0.84401[0m
[92maverage training of epoch 23: loss -38.59361 acc 0.86755 roc_auc 0.85824 prc_auc 0.89079[0m
[93maverage test of epoch 23: loss -38.85036 acc 0.81081 roc_auc 0.75500 prc_auc 0.81602[0m
[92maverage training of epoch 24: loss -40.13756 acc 0.86093 roc_auc 0.86000 prc_auc 0.89145[0m
[93maverage test of epoch 24: loss -40.38155 acc 0.81081 roc_auc 0.75500 prc_auc 0.81602[0m
[92maverage training of epoch 25: loss -41.68523 acc 0.86093 roc_auc 0.85980 prc_auc 0.89134[0m
[93maverage test of epoch 25: loss -41.90492 acc 0.81081 roc_auc 0.75500 prc_auc 0.81602[0m
[92maverage training of epoch 26: loss -43.23472 acc 0.86755 roc_auc 0.85961 prc_auc 0.89128[0m
[93maverage test of epoch 26: loss -43.42829 acc 0.81081 roc_auc 0.75500 prc_auc 0.81602[0m
[92maverage training of epoch 27: loss -44.78340 acc 0.86093 roc_auc 0.85069 prc_auc 0.88324[0m
[93maverage test of epoch 27: loss -44.95597 acc 0.81081 roc_auc 0.75500 prc_auc 0.81602[0m
[92maverage training of epoch 28: loss -46.33388 acc 0.86093 roc_auc 0.85049 prc_auc 0.88317[0m
[93maverage test of epoch 28: loss -46.49364 acc 0.81081 roc_auc 0.75500 prc_auc 0.81602[0m
[92maverage training of epoch 29: loss -47.88861 acc 0.86755 roc_auc 0.85127 prc_auc 0.88342[0m
[93maverage test of epoch 29: loss -48.03014 acc 0.81081 roc_auc 0.75500 prc_auc 0.81602[0m
[92maverage training of epoch 30: loss -49.43229 acc 0.86093 roc_auc 0.85108 prc_auc 0.88336[0m
[93maverage test of epoch 30: loss -49.57314 acc 0.81081 roc_auc 0.75833 prc_auc 0.81699[0m
[92maverage training of epoch 31: loss -50.97161 acc 0.86755 roc_auc 0.85167 prc_auc 0.88354[0m
[93maverage test of epoch 31: loss -51.10724 acc 0.81081 roc_auc 0.76167 prc_auc 0.81802[0m
[92maverage training of epoch 32: loss -52.53014 acc 0.86755 roc_auc 0.85206 prc_auc 0.88369[0m
[93maverage test of epoch 32: loss -52.67205 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 33: loss -54.08409 acc 0.86755 roc_auc 0.85225 prc_auc 0.88374[0m
[93maverage test of epoch 33: loss -54.21958 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 34: loss -55.63787 acc 0.86755 roc_auc 0.85206 prc_auc 0.88369[0m
[93maverage test of epoch 34: loss -55.76204 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 35: loss -57.19138 acc 0.86755 roc_auc 0.85225 prc_auc 0.88378[0m
[93maverage test of epoch 35: loss -57.32090 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 36: loss -58.74689 acc 0.86755 roc_auc 0.86118 prc_auc 0.89183[0m
[93maverage test of epoch 36: loss -58.89879 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 37: loss -60.30268 acc 0.87417 roc_auc 0.86098 prc_auc 0.89181[0m
[93maverage test of epoch 37: loss -60.49886 acc 0.81081 roc_auc 0.80333 prc_auc 0.84711[0m
[92maverage training of epoch 38: loss -61.85380 acc 0.87417 roc_auc 0.86078 prc_auc 0.89176[0m
[93maverage test of epoch 38: loss -62.06010 acc 0.81081 roc_auc 0.80333 prc_auc 0.84711[0m
[92maverage training of epoch 39: loss -63.40399 acc 0.87417 roc_auc 0.86078 prc_auc 0.89176[0m
[93maverage test of epoch 39: loss -63.60340 acc 0.81081 roc_auc 0.80333 prc_auc 0.84711[0m
[92maverage training of epoch 40: loss -64.95280 acc 0.87417 roc_auc 0.86078 prc_auc 0.89177[0m
[93maverage test of epoch 40: loss -65.08648 acc 0.81081 roc_auc 0.80333 prc_auc 0.84711[0m
[92maverage training of epoch 41: loss -66.50255 acc 0.87417 roc_auc 0.86039 prc_auc 0.89162[0m
[93maverage test of epoch 41: loss -66.55354 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 42: loss -68.04114 acc 0.87417 roc_auc 0.86059 prc_auc 0.89169[0m
[93maverage test of epoch 42: loss -68.10779 acc 0.81081 roc_auc 0.76333 prc_auc 0.81823[0m
[92maverage training of epoch 43: loss -69.53682 acc 0.86093 roc_auc 0.85245 prc_auc 0.88391[0m
[93maverage test of epoch 43: loss -69.78293 acc 0.83784 roc_auc 0.76167 prc_auc 0.81823[0m
[92maverage training of epoch 44: loss -70.92602 acc 0.86755 roc_auc 0.84275 prc_auc 0.87582[0m
[93maverage test of epoch 44: loss -71.35327 acc 0.83784 roc_auc 0.80333 prc_auc 0.84711[0m
[92maverage training of epoch 45: loss -72.55610 acc 0.87417 roc_auc 0.84020 prc_auc 0.87496[0m
[93maverage test of epoch 45: loss -72.86710 acc 0.83784 roc_auc 0.80667 prc_auc 0.84806[0m
[92maverage training of epoch 46: loss -74.11861 acc 0.87417 roc_auc 0.83941 prc_auc 0.87478[0m
[93maverage test of epoch 46: loss -74.35546 acc 0.81081 roc_auc 0.80667 prc_auc 0.84806[0m
[92maverage training of epoch 47: loss -75.67234 acc 0.87417 roc_auc 0.83863 prc_auc 0.87460[0m
[93maverage test of epoch 47: loss -75.83746 acc 0.81081 roc_auc 0.80667 prc_auc 0.84806[0m
[92maverage training of epoch 48: loss -77.23663 acc 0.87417 roc_auc 0.84902 prc_auc 0.88356[0m
[93maverage test of epoch 48: loss -77.30875 acc 0.81081 roc_auc 0.80667 prc_auc 0.84806[0m
[92maverage training of epoch 49: loss -78.85052 acc 0.87417 roc_auc 0.84902 prc_auc 0.88356[0m
[93maverage test of epoch 49: loss -78.64332 acc 0.83784 roc_auc 0.80833 prc_auc 0.84806[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0)
('number_of_mlp_layer', 0)
('lr', 0.003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.69744 ROC_AUC (avg): 0.56167 PRC_AUC (avg): 0.69948 

Average forward propagation time taken(ms): 2.6277860394115296
Average backward propagation time taken(ms): 0.9306562230240126

