# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======


torch.cuda.is_available():  True 


load_data.py load_model_data(): Unserialising pickled dataset into Graph objects
==== Dataset Information ====
== General Information == 
Number of graphs: 188
Number of classes: 2
Class distribution: 
0:63 1:125 

== Node information== 
Average number of nodes: 18
Average number of edges (undirected): 20
Max number of nodes: 28
Number of distinct node labels: 7
Average number of distinct node labels: 3
Node labels distribution: 
0:2395 1:345 2:593 3:12 4:1 5:23 6:2 

*** 3 dataset_features:  {'name': 'MUTAG', 'num_class': 2, 'label_dict': {'0': 0, '1': 1}, 'have_node_labels': True, 'have_node_attributions': False, 'node_dict': {'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, 'UNKNOWN': 7}, 'feat_dim': 8, 'edge_feat_dim': 0, 'max_num_nodes': 28, 'avg_num_nodes': 18, 'graph_sizes_list': [17, 13, 13, 19, 11, 28, 16, 20, 12, 17, 17, 20, 22, 13, 19, 22, 11, 17, 13, 18, 18, 17, 23, 27, 17, 13, 23, 17, 23, 23, 22, 24, 23, 13, 17, 14, 17, 15, 15, 13, 17, 13, 19, 17, 12, 23, 22, 17, 20, 16, 26, 26, 19, 19, 14, 17, 21, 25, 23, 19, 17, 11, 23, 20, 16, 16, 20, 23, 19, 14, 26, 16, 16, 23, 18, 10, 16, 16, 17, 19, 12, 25, 16, 11, 23, 23, 16, 12, 13, 23, 25, 19, 23, 19, 19, 25, 18, 13, 15, 16, 23, 26, 19, 23, 17, 20, 25, 19, 28, 24, 11, 15, 13, 16, 12, 10, 21, 23, 21, 13, 25, 21, 17, 11, 19, 20, 21, 15, 14, 11, 19, 11, 21, 22, 11, 20, 22, 13, 11, 16, 11, 20, 12, 11, 16, 16, 13, 15, 20, 12, 12, 22, 15, 12, 14, 12, 20, 20, 20, 14, 26, 24, 22, 22, 19, 23, 22, 11, 13, 17, 24, 12, 21, 22, 22, 12, 20, 13, 22, 28, 11, 14, 22, 22, 13, 12, 21, 16], 'attr_dim': 0, 'dataset_info': '==== Dataset Information ====\n== General Information == \nNumber of graphs: 188\nNumber of classes: 2\nClass distribution: \n0:63 1:125 \n\n== Node information== \nAverage number of nodes: 18\nAverage number of edges (undirected): 20\nMax number of nodes: 28\nNumber of distinct node labels: 7\nAverage number of distinct node labels: 3\nNode labels distribution: \n0:2395 1:345 2:593 3:12 4:1 5:23 6:2 \n'}
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]


config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 50, 'learning_rate': 0.0001, 'seed': 1800, 'k_fold': 5, 'model': 'DiffPool', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'name': 'MUTAG', 'num_class': 2, 'label_dict': {'0': 0, '1': 1}, 'have_node_labels': True, 'have_node_attributions': False, 'node_dict': {'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, 'UNKNOWN': 7}, 'feat_dim': 8, 'edge_feat_dim': 0, 'max_num_nodes': 28, 'avg_num_nodes': 18, 'graph_sizes_list': [17, 13, 13, 19, 11, 28, 16, 20, 12, 17, 17, 20, 22, 13, 19, 22, 11, 17, 13, 18, 18, 17, 23, 27, 17, 13, 23, 17, 23, 23, 22, 24, 23, 13, 17, 14, 17, 15, 15, 13, 17, 13, 19, 17, 12, 23, 22, 17, 20, 16, 26, 26, 19, 19, 14, 17, 21, 25, 23, 19, 17, 11, 23, 20, 16, 16, 20, 23, 19, 14, 26, 16, 16, 23, 18, 10, 16, 16, 17, 19, 12, 25, 16, 11, 23, 23, 16, 12, 13, 23, 25, 19, 23, 19, 19, 25, 18, 13, 15, 16, 23, 26, 19, 23, 17, 20, 25, 19, 28, 24, 11, 15, 13, 16, 12, 10, 21, 23, 21, 13, 25, 21, 17, 11, 19, 20, 21, 15, 14, 11, 19, 11, 21, 22, 11, 20, 22, 13, 11, 16, 11, 20, 12, 11, 16, 16, 13, 15, 20, 12, 12, 22, 15, 12, 14, 12, 20, 20, 20, 14, 26, 24, 22, 22, 19, 23, 22, 11, 13, 17, 24, 12, 21, 22, 22, 12, 20, 13, 22, 28, 11, 14, 22, 22, 13, 12, 21, 16], 'attr_dim': 0, 'dataset_info': '==== Dataset Information ====\n== General Information == \nNumber of graphs: 188\nNumber of classes: 2\nClass distribution: \n0:63 1:125 \n\n== Node information== \nAverage number of nodes: 18\nAverage number of edges (undirected): 20\nMax number of nodes: 28\nNumber of distinct node labels: 7\nAverage number of distinct node labels: 3\nNode labels distribution: \n0:2395 1:345 2:593 3:12 4:1 5:23 6:2 \n'}}


Training a new model: DiffPool
Training model with dataset, testing using fold 0
[92maverage training of epoch 0: loss 0.70225 acc 0.33333 roc_auc 0.41180 prc_auc 0.61223[0m
[93maverage test of epoch 0: loss 0.69366 acc 0.34211 roc_auc 0.64615 prc_auc 0.74309[0m
[92maverage training of epoch 1: loss 0.68825 acc 0.64667 roc_auc 0.39580 prc_auc 0.59827[0m
[93maverage test of epoch 1: loss 0.68161 acc 0.65789 roc_auc 0.76000 prc_auc 0.81935[0m
[92maverage training of epoch 2: loss 0.67632 acc 0.66667 roc_auc 0.38700 prc_auc 0.58730[0m
[93maverage test of epoch 2: loss 0.67041 acc 0.65789 roc_auc 0.75692 prc_auc 0.79057[0m
[92maverage training of epoch 3: loss 0.66485 acc 0.66667 roc_auc 0.41200 prc_auc 0.60197[0m
[93maverage test of epoch 3: loss 0.65938 acc 0.65789 roc_auc 0.73231 prc_auc 0.79541[0m
[92maverage training of epoch 4: loss 0.65364 acc 0.66667 roc_auc 0.47400 prc_auc 0.63632[0m
[93maverage test of epoch 4: loss 0.64782 acc 0.65789 roc_auc 0.80308 prc_auc 0.83874[0m
[92maverage training of epoch 5: loss 0.64160 acc 0.66667 roc_auc 0.54340 prc_auc 0.68864[0m
[93maverage test of epoch 5: loss 0.63524 acc 0.65789 roc_auc 0.81846 prc_auc 0.86779[0m
[92maverage training of epoch 6: loss 0.62738 acc 0.66667 roc_auc 0.61520 prc_auc 0.73377[0m
[93maverage test of epoch 6: loss 0.61957 acc 0.65789 roc_auc 0.83077 prc_auc 0.86952[0m
[92maverage training of epoch 7: loss 0.60985 acc 0.66667 roc_auc 0.67480 prc_auc 0.78089[0m
[93maverage test of epoch 7: loss 0.59756 acc 0.65789 roc_auc 0.83385 prc_auc 0.86969[0m
[92maverage training of epoch 8: loss 0.58926 acc 0.66667 roc_auc 0.72300 prc_auc 0.80802[0m
[93maverage test of epoch 8: loss 0.57041 acc 0.65789 roc_auc 0.84308 prc_auc 0.87450[0m
[92maverage training of epoch 9: loss 0.56600 acc 0.74000 roc_auc 0.75680 prc_auc 0.82723[0m
[93maverage test of epoch 9: loss 0.54012 acc 0.71053 roc_auc 0.85538 prc_auc 0.90000[0m
[92maverage training of epoch 10: loss 0.54411 acc 0.78000 roc_auc 0.77300 prc_auc 0.83832[0m
[93maverage test of epoch 10: loss 0.50745 acc 0.78947 roc_auc 0.89231 prc_auc 0.95034[0m
[92maverage training of epoch 11: loss 0.52517 acc 0.80000 roc_auc 0.78840 prc_auc 0.85455[0m
[93maverage test of epoch 11: loss 0.48490 acc 0.76316 roc_auc 0.88615 prc_auc 0.94909[0m
[92maverage training of epoch 12: loss 0.50966 acc 0.80000 roc_auc 0.80160 prc_auc 0.86446[0m
[93maverage test of epoch 12: loss 0.46916 acc 0.76316 roc_auc 0.88923 prc_auc 0.94980[0m
[92maverage training of epoch 13: loss 0.49218 acc 0.80667 roc_auc 0.82700 prc_auc 0.88774[0m
[93maverage test of epoch 13: loss 0.45138 acc 0.76316 roc_auc 0.90462 prc_auc 0.95559[0m
[92maverage training of epoch 14: loss 0.47556 acc 0.78667 roc_auc 0.84560 prc_auc 0.90101[0m
[93maverage test of epoch 14: loss 0.43915 acc 0.76316 roc_auc 0.91385 prc_auc 0.96031[0m
[92maverage training of epoch 15: loss 0.45989 acc 0.80000 roc_auc 0.85800 prc_auc 0.90773[0m
[93maverage test of epoch 15: loss 0.42664 acc 0.76316 roc_auc 0.91385 prc_auc 0.96031[0m
[92maverage training of epoch 16: loss 0.44515 acc 0.82667 roc_auc 0.86700 prc_auc 0.91906[0m
[93maverage test of epoch 16: loss 0.41644 acc 0.76316 roc_auc 0.92000 prc_auc 0.96331[0m
[92maverage training of epoch 17: loss 0.43217 acc 0.82667 roc_auc 0.87060 prc_auc 0.92027[0m
[93maverage test of epoch 17: loss 0.41068 acc 0.76316 roc_auc 0.91692 prc_auc 0.96281[0m
[92maverage training of epoch 18: loss 0.42002 acc 0.82000 roc_auc 0.87800 prc_auc 0.92626[0m
[93maverage test of epoch 18: loss 0.40706 acc 0.76316 roc_auc 0.92000 prc_auc 0.96461[0m
[92maverage training of epoch 19: loss 0.41083 acc 0.81333 roc_auc 0.88180 prc_auc 0.92580[0m
[93maverage test of epoch 19: loss 0.40467 acc 0.76316 roc_auc 0.91692 prc_auc 0.96325[0m
[92maverage training of epoch 20: loss 0.40177 acc 0.81333 roc_auc 0.88380 prc_auc 0.92784[0m
[93maverage test of epoch 20: loss 0.40146 acc 0.73684 roc_auc 0.91692 prc_auc 0.96325[0m
[92maverage training of epoch 21: loss 0.39467 acc 0.80667 roc_auc 0.88620 prc_auc 0.92732[0m
[93maverage test of epoch 21: loss 0.39078 acc 0.73684 roc_auc 0.91692 prc_auc 0.96325[0m
[92maverage training of epoch 22: loss 0.38768 acc 0.82000 roc_auc 0.89080 prc_auc 0.93173[0m
[93maverage test of epoch 22: loss 0.38733 acc 0.73684 roc_auc 0.91385 prc_auc 0.96231[0m
[92maverage training of epoch 23: loss 0.38297 acc 0.83333 roc_auc 0.89240 prc_auc 0.93341[0m
[93maverage test of epoch 23: loss 0.37433 acc 0.78947 roc_auc 0.91692 prc_auc 0.96397[0m
[92maverage training of epoch 24: loss 0.37781 acc 0.83333 roc_auc 0.89720 prc_auc 0.93771[0m
[93maverage test of epoch 24: loss 0.36102 acc 0.78947 roc_auc 0.91692 prc_auc 0.96453[0m
[92maverage training of epoch 25: loss 0.37615 acc 0.83333 roc_auc 0.89900 prc_auc 0.94150[0m
[93maverage test of epoch 25: loss 0.34734 acc 0.78947 roc_auc 0.92000 prc_auc 0.96578[0m
[92maverage training of epoch 26: loss 0.37152 acc 0.84000 roc_auc 0.90120 prc_auc 0.94316[0m
[93maverage test of epoch 26: loss 0.34476 acc 0.78947 roc_auc 0.92000 prc_auc 0.96578[0m
[92maverage training of epoch 27: loss 0.36838 acc 0.82667 roc_auc 0.90340 prc_auc 0.94443[0m
[93maverage test of epoch 27: loss 0.33993 acc 0.78947 roc_auc 0.92308 prc_auc 0.96714[0m
[92maverage training of epoch 28: loss 0.36682 acc 0.82667 roc_auc 0.90420 prc_auc 0.94641[0m
[93maverage test of epoch 28: loss 0.33408 acc 0.78947 roc_auc 0.92308 prc_auc 0.96714[0m
[92maverage training of epoch 29: loss 0.36523 acc 0.84000 roc_auc 0.90380 prc_auc 0.94467[0m
[93maverage test of epoch 29: loss 0.32789 acc 0.78947 roc_auc 0.92308 prc_auc 0.96714[0m
[92maverage training of epoch 30: loss 0.36107 acc 0.82667 roc_auc 0.90760 prc_auc 0.94810[0m
[93maverage test of epoch 30: loss 0.32383 acc 0.81579 roc_auc 0.92615 prc_auc 0.96860[0m
[92maverage training of epoch 31: loss 0.36121 acc 0.82000 roc_auc 0.90780 prc_auc 0.94862[0m
[93maverage test of epoch 31: loss 0.31982 acc 0.81579 roc_auc 0.92615 prc_auc 0.96860[0m
[92maverage training of epoch 32: loss 0.35863 acc 0.82000 roc_auc 0.90760 prc_auc 0.94817[0m
[93maverage test of epoch 32: loss 0.31790 acc 0.84211 roc_auc 0.92615 prc_auc 0.96860[0m
[92maverage training of epoch 33: loss 0.35810 acc 0.82000 roc_auc 0.90720 prc_auc 0.94633[0m
[93maverage test of epoch 33: loss 0.31633 acc 0.81579 roc_auc 0.92615 prc_auc 0.96860[0m
[92maverage training of epoch 34: loss 0.35785 acc 0.82667 roc_auc 0.90820 prc_auc 0.94736[0m
[93maverage test of epoch 34: loss 0.31488 acc 0.81579 roc_auc 0.92615 prc_auc 0.96860[0m
[92maverage training of epoch 35: loss 0.35484 acc 0.82667 roc_auc 0.90820 prc_auc 0.94428[0m
[93maverage test of epoch 35: loss 0.30808 acc 0.84211 roc_auc 0.92615 prc_auc 0.96860[0m
[92maverage training of epoch 36: loss 0.35278 acc 0.82000 roc_auc 0.90860 prc_auc 0.94347[0m
[93maverage test of epoch 36: loss 0.31008 acc 0.81579 roc_auc 0.92615 prc_auc 0.96860[0m
[92maverage training of epoch 37: loss 0.35139 acc 0.82667 roc_auc 0.90960 prc_auc 0.94374[0m
[93maverage test of epoch 37: loss 0.31673 acc 0.81579 roc_auc 0.92615 prc_auc 0.96860[0m
[92maverage training of epoch 38: loss 0.35296 acc 0.82667 roc_auc 0.90880 prc_auc 0.94565[0m
[93maverage test of epoch 38: loss 0.31547 acc 0.81579 roc_auc 0.92615 prc_auc 0.96860[0m
[92maverage training of epoch 39: loss 0.35120 acc 0.82667 roc_auc 0.91020 prc_auc 0.94668[0m
[93maverage test of epoch 39: loss 0.31433 acc 0.81579 roc_auc 0.92615 prc_auc 0.96860[0m
[92maverage training of epoch 40: loss 0.35295 acc 0.82667 roc_auc 0.90900 prc_auc 0.94416[0m
[93maverage test of epoch 40: loss 0.31218 acc 0.81579 roc_auc 0.92615 prc_auc 0.96860[0m
[92maverage training of epoch 41: loss 0.34827 acc 0.82667 roc_auc 0.91060 prc_auc 0.94518[0m
[93maverage test of epoch 41: loss 0.30654 acc 0.84211 roc_auc 0.92923 prc_auc 0.97020[0m
[92maverage training of epoch 42: loss 0.34377 acc 0.82667 roc_auc 0.91320 prc_auc 0.94809[0m
[93maverage test of epoch 42: loss 0.30721 acc 0.84211 roc_auc 0.92923 prc_auc 0.97020[0m
[92maverage training of epoch 43: loss 0.34570 acc 0.82667 roc_auc 0.91360 prc_auc 0.95056[0m
[93maverage test of epoch 43: loss 0.30664 acc 0.84211 roc_auc 0.92923 prc_auc 0.97020[0m
[92maverage training of epoch 44: loss 0.34649 acc 0.82000 roc_auc 0.91440 prc_auc 0.95309[0m
[93maverage test of epoch 44: loss 0.30596 acc 0.84211 roc_auc 0.92923 prc_auc 0.97097[0m
[92maverage training of epoch 45: loss 0.34467 acc 0.82000 roc_auc 0.91640 prc_auc 0.95543[0m
[93maverage test of epoch 45: loss 0.30702 acc 0.84211 roc_auc 0.92923 prc_auc 0.97029[0m
[92maverage training of epoch 46: loss 0.34239 acc 0.82000 roc_auc 0.91580 prc_auc 0.95495[0m
[93maverage test of epoch 46: loss 0.31018 acc 0.84211 roc_auc 0.92923 prc_auc 0.97029[0m
[92maverage training of epoch 47: loss 0.34152 acc 0.82000 roc_auc 0.91680 prc_auc 0.95611[0m
[93maverage test of epoch 47: loss 0.31081 acc 0.86842 roc_auc 0.93231 prc_auc 0.97203[0m
[92maverage training of epoch 48: loss 0.33722 acc 0.82000 roc_auc 0.91740 prc_auc 0.95624[0m
[93maverage test of epoch 48: loss 0.31169 acc 0.86842 roc_auc 0.93538 prc_auc 0.97288[0m
[92maverage training of epoch 49: loss 0.33632 acc 0.83333 roc_auc 0.91720 prc_auc 0.95599[0m
[93maverage test of epoch 49: loss 0.31596 acc 0.86842 roc_auc 0.93538 prc_auc 0.97288[0m
Training model with dataset, testing using fold 1
[92maverage training of epoch 0: loss 0.66009 acc 0.66667 roc_auc 0.44360 prc_auc 0.62991[0m
[93maverage test of epoch 0: loss 0.65926 acc 0.65789 roc_auc 0.86154 prc_auc 0.94007[0m
[92maverage training of epoch 1: loss 0.65538 acc 0.66667 roc_auc 0.46160 prc_auc 0.64821[0m
[93maverage test of epoch 1: loss 0.65523 acc 0.65789 roc_auc 0.86462 prc_auc 0.94146[0m
[92maverage training of epoch 2: loss 0.65111 acc 0.66667 roc_auc 0.48640 prc_auc 0.66510[0m
[93maverage test of epoch 2: loss 0.64987 acc 0.65789 roc_auc 0.86154 prc_auc 0.93977[0m
[92maverage training of epoch 3: loss 0.64532 acc 0.66667 roc_auc 0.55560 prc_auc 0.70258[0m
[93maverage test of epoch 3: loss 0.64149 acc 0.65789 roc_auc 0.87385 prc_auc 0.94497[0m
[92maverage training of epoch 4: loss 0.63802 acc 0.66667 roc_auc 0.62840 prc_auc 0.73833[0m
[93maverage test of epoch 4: loss 0.63045 acc 0.65789 roc_auc 0.88000 prc_auc 0.94816[0m
[92maverage training of epoch 5: loss 0.62804 acc 0.66667 roc_auc 0.67740 prc_auc 0.78212[0m
[93maverage test of epoch 5: loss 0.61194 acc 0.65789 roc_auc 0.89231 prc_auc 0.95472[0m
[92maverage training of epoch 6: loss 0.61357 acc 0.66667 roc_auc 0.70740 prc_auc 0.81260[0m
[93maverage test of epoch 6: loss 0.58419 acc 0.65789 roc_auc 0.88615 prc_auc 0.95349[0m
[92maverage training of epoch 7: loss 0.59671 acc 0.66667 roc_auc 0.72500 prc_auc 0.82199[0m
[93maverage test of epoch 7: loss 0.56055 acc 0.65789 roc_auc 0.90769 prc_auc 0.96207[0m
[92maverage training of epoch 8: loss 0.57866 acc 0.66667 roc_auc 0.72440 prc_auc 0.81136[0m
[93maverage test of epoch 8: loss 0.54617 acc 0.65789 roc_auc 0.92000 prc_auc 0.96492[0m
[92maverage training of epoch 9: loss 0.55988 acc 0.66667 roc_auc 0.72240 prc_auc 0.80944[0m
[93maverage test of epoch 9: loss 0.51099 acc 0.76316 roc_auc 0.92308 prc_auc 0.96700[0m
[92maverage training of epoch 10: loss 0.54237 acc 0.77333 roc_auc 0.72180 prc_auc 0.80043[0m
[93maverage test of epoch 10: loss 0.47810 acc 0.78947 roc_auc 0.92615 prc_auc 0.96733[0m
[92maverage training of epoch 11: loss 0.52599 acc 0.80000 roc_auc 0.72740 prc_auc 0.79606[0m
[93maverage test of epoch 11: loss 0.46162 acc 0.81579 roc_auc 0.92923 prc_auc 0.96823[0m
[92maverage training of epoch 12: loss 0.52169 acc 0.78667 roc_auc 0.71440 prc_auc 0.78063[0m
[93maverage test of epoch 12: loss 0.45294 acc 0.81579 roc_auc 0.93538 prc_auc 0.97014[0m
[92maverage training of epoch 13: loss 0.52025 acc 0.78667 roc_auc 0.72160 prc_auc 0.76655[0m
[93maverage test of epoch 13: loss 0.44740 acc 0.81579 roc_auc 0.93538 prc_auc 0.97014[0m
[92maverage training of epoch 14: loss 0.51754 acc 0.78667 roc_auc 0.72000 prc_auc 0.76530[0m
[93maverage test of epoch 14: loss 0.41810 acc 0.86842 roc_auc 0.94769 prc_auc 0.97436[0m
[92maverage training of epoch 15: loss 0.50904 acc 0.78000 roc_auc 0.72600 prc_auc 0.77133[0m
[93maverage test of epoch 15: loss 0.41116 acc 0.86842 roc_auc 0.95077 prc_auc 0.97554[0m
[92maverage training of epoch 16: loss 0.50242 acc 0.78000 roc_auc 0.73860 prc_auc 0.78827[0m
[93maverage test of epoch 16: loss 0.40624 acc 0.84211 roc_auc 0.96000 prc_auc 0.98049[0m
[92maverage training of epoch 17: loss 0.50075 acc 0.79333 roc_auc 0.74940 prc_auc 0.82298[0m
[93maverage test of epoch 17: loss 0.39978 acc 0.86842 roc_auc 0.96308 prc_auc 0.98314[0m
[92maverage training of epoch 18: loss 0.49387 acc 0.80000 roc_auc 0.77840 prc_auc 0.86083[0m
[93maverage test of epoch 18: loss 0.38583 acc 0.89474 roc_auc 0.96923 prc_auc 0.98481[0m
[92maverage training of epoch 19: loss 0.48905 acc 0.80000 roc_auc 0.80080 prc_auc 0.87849[0m
[93maverage test of epoch 19: loss 0.36727 acc 0.89474 roc_auc 0.97231 prc_auc 0.98605[0m
[92maverage training of epoch 20: loss 0.47509 acc 0.79333 roc_auc 0.83220 prc_auc 0.88606[0m
[93maverage test of epoch 20: loss 0.38909 acc 0.89474 roc_auc 0.97231 prc_auc 0.98605[0m
[92maverage training of epoch 21: loss 0.45909 acc 0.80000 roc_auc 0.85080 prc_auc 0.90597[0m
[93maverage test of epoch 21: loss 0.39022 acc 0.86842 roc_auc 0.96923 prc_auc 0.98414[0m
[92maverage training of epoch 22: loss 0.44358 acc 0.80667 roc_auc 0.86400 prc_auc 0.91294[0m
[93maverage test of epoch 22: loss 0.37673 acc 0.86842 roc_auc 0.96308 prc_auc 0.98038[0m
[92maverage training of epoch 23: loss 0.43138 acc 0.80667 roc_auc 0.87400 prc_auc 0.92091[0m
[93maverage test of epoch 23: loss 0.38032 acc 0.86842 roc_auc 0.96000 prc_auc 0.97915[0m
[92maverage training of epoch 24: loss 0.42177 acc 0.80000 roc_auc 0.87920 prc_auc 0.92362[0m
[93maverage test of epoch 24: loss 0.38008 acc 0.86842 roc_auc 0.95077 prc_auc 0.97282[0m
[92maverage training of epoch 25: loss 0.41300 acc 0.80000 roc_auc 0.88160 prc_auc 0.92518[0m
[93maverage test of epoch 25: loss 0.38962 acc 0.84211 roc_auc 0.95077 prc_auc 0.97282[0m
[92maverage training of epoch 26: loss 0.40686 acc 0.81333 roc_auc 0.88460 prc_auc 0.92685[0m
[93maverage test of epoch 26: loss 0.38394 acc 0.84211 roc_auc 0.94462 prc_auc 0.96795[0m
[92maverage training of epoch 27: loss 0.40056 acc 0.81333 roc_auc 0.88560 prc_auc 0.93150[0m
[93maverage test of epoch 27: loss 0.38459 acc 0.84211 roc_auc 0.94154 prc_auc 0.96557[0m
[92maverage training of epoch 28: loss 0.39451 acc 0.80667 roc_auc 0.89040 prc_auc 0.93692[0m
[93maverage test of epoch 28: loss 0.38336 acc 0.84211 roc_auc 0.93231 prc_auc 0.95697[0m
[92maverage training of epoch 29: loss 0.38757 acc 0.82000 roc_auc 0.89540 prc_auc 0.94173[0m
[93maverage test of epoch 29: loss 0.38161 acc 0.84211 roc_auc 0.92308 prc_auc 0.95069[0m
[92maverage training of epoch 30: loss 0.38338 acc 0.82667 roc_auc 0.89640 prc_auc 0.94316[0m
[93maverage test of epoch 30: loss 0.38897 acc 0.84211 roc_auc 0.91077 prc_auc 0.93890[0m
[92maverage training of epoch 31: loss 0.38234 acc 0.82667 roc_auc 0.89700 prc_auc 0.94404[0m
[93maverage test of epoch 31: loss 0.38310 acc 0.86842 roc_auc 0.89846 prc_auc 0.93083[0m
[92maverage training of epoch 32: loss 0.37578 acc 0.84000 roc_auc 0.90200 prc_auc 0.94695[0m
[93maverage test of epoch 32: loss 0.38074 acc 0.86842 roc_auc 0.89846 prc_auc 0.93083[0m
[92maverage training of epoch 33: loss 0.37179 acc 0.84667 roc_auc 0.90380 prc_auc 0.94837[0m
[93maverage test of epoch 33: loss 0.38769 acc 0.86842 roc_auc 0.89538 prc_auc 0.93183[0m
[92maverage training of epoch 34: loss 0.36758 acc 0.84667 roc_auc 0.90640 prc_auc 0.94916[0m
[93maverage test of epoch 34: loss 0.38817 acc 0.86842 roc_auc 0.89538 prc_auc 0.93183[0m
[92maverage training of epoch 35: loss 0.36165 acc 0.84667 roc_auc 0.91080 prc_auc 0.95106[0m
[93maverage test of epoch 35: loss 0.38181 acc 0.86842 roc_auc 0.89846 prc_auc 0.93546[0m
[92maverage training of epoch 36: loss 0.35781 acc 0.86000 roc_auc 0.91200 prc_auc 0.95139[0m
[93maverage test of epoch 36: loss 0.38949 acc 0.86842 roc_auc 0.89231 prc_auc 0.93293[0m
[92maverage training of epoch 37: loss 0.35493 acc 0.86667 roc_auc 0.91320 prc_auc 0.95193[0m
[93maverage test of epoch 37: loss 0.39149 acc 0.86842 roc_auc 0.89231 prc_auc 0.93025[0m
[92maverage training of epoch 38: loss 0.34845 acc 0.87333 roc_auc 0.91640 prc_auc 0.95357[0m
[93maverage test of epoch 38: loss 0.40287 acc 0.86842 roc_auc 0.88923 prc_auc 0.92860[0m
[92maverage training of epoch 39: loss 0.34449 acc 0.86667 roc_auc 0.91680 prc_auc 0.95485[0m
[93maverage test of epoch 39: loss 0.41787 acc 0.86842 roc_auc 0.87077 prc_auc 0.90014[0m
[92maverage training of epoch 40: loss 0.34246 acc 0.86667 roc_auc 0.91700 prc_auc 0.95487[0m
[93maverage test of epoch 40: loss 0.41671 acc 0.86842 roc_auc 0.85231 prc_auc 0.87557[0m
[92maverage training of epoch 41: loss 0.34165 acc 0.86667 roc_auc 0.91760 prc_auc 0.95455[0m
[93maverage test of epoch 41: loss 0.41557 acc 0.86842 roc_auc 0.84923 prc_auc 0.86557[0m
[92maverage training of epoch 42: loss 0.33596 acc 0.87333 roc_auc 0.91960 prc_auc 0.95591[0m
[93maverage test of epoch 42: loss 0.42072 acc 0.86842 roc_auc 0.84615 prc_auc 0.86957[0m
[92maverage training of epoch 43: loss 0.33260 acc 0.87333 roc_auc 0.92140 prc_auc 0.95699[0m
[93maverage test of epoch 43: loss 0.42222 acc 0.86842 roc_auc 0.84308 prc_auc 0.86778[0m
[92maverage training of epoch 44: loss 0.33232 acc 0.86667 roc_auc 0.92080 prc_auc 0.95632[0m
[93maverage test of epoch 44: loss 0.42889 acc 0.84211 roc_auc 0.83077 prc_auc 0.83781[0m
[92maverage training of epoch 45: loss 0.32935 acc 0.86667 roc_auc 0.92400 prc_auc 0.95865[0m
[93maverage test of epoch 45: loss 0.43772 acc 0.81579 roc_auc 0.84923 prc_auc 0.87128[0m
[92maverage training of epoch 46: loss 0.32694 acc 0.87333 roc_auc 0.92380 prc_auc 0.95852[0m
[93maverage test of epoch 46: loss 0.43903 acc 0.81579 roc_auc 0.83692 prc_auc 0.86719[0m
[92maverage training of epoch 47: loss 0.32350 acc 0.87333 roc_auc 0.92480 prc_auc 0.95892[0m
[93maverage test of epoch 47: loss 0.45089 acc 0.81579 roc_auc 0.83692 prc_auc 0.86719[0m
[92maverage training of epoch 48: loss 0.32023 acc 0.87333 roc_auc 0.92680 prc_auc 0.96024[0m
[93maverage test of epoch 48: loss 0.44951 acc 0.81579 roc_auc 0.83385 prc_auc 0.85919[0m
[92maverage training of epoch 49: loss 0.31874 acc 0.87333 roc_auc 0.92800 prc_auc 0.96079[0m
[93maverage test of epoch 49: loss 0.45286 acc 0.81579 roc_auc 0.83385 prc_auc 0.85919[0m
Training model with dataset, testing using fold 2
[92maverage training of epoch 0: loss 0.66079 acc 0.66667 roc_auc 0.39020 prc_auc 0.59722[0m
[93maverage test of epoch 0: loss 0.65886 acc 0.65789 roc_auc 0.64615 prc_auc 0.82100[0m
[92maverage training of epoch 1: loss 0.65449 acc 0.66667 roc_auc 0.40360 prc_auc 0.61077[0m
[93maverage test of epoch 1: loss 0.65397 acc 0.65789 roc_auc 0.65846 prc_auc 0.82479[0m
[92maverage training of epoch 2: loss 0.64971 acc 0.66667 roc_auc 0.40820 prc_auc 0.61528[0m
[93maverage test of epoch 2: loss 0.65002 acc 0.65789 roc_auc 0.65846 prc_auc 0.82880[0m
[92maverage training of epoch 3: loss 0.64582 acc 0.66667 roc_auc 0.41820 prc_auc 0.62359[0m
[93maverage test of epoch 3: loss 0.64700 acc 0.65789 roc_auc 0.65231 prc_auc 0.82146[0m
[92maverage training of epoch 4: loss 0.64265 acc 0.66667 roc_auc 0.46280 prc_auc 0.65651[0m
[93maverage test of epoch 4: loss 0.64434 acc 0.65789 roc_auc 0.68923 prc_auc 0.83498[0m
[92maverage training of epoch 5: loss 0.63950 acc 0.66667 roc_auc 0.52280 prc_auc 0.70222[0m
[93maverage test of epoch 5: loss 0.64098 acc 0.65789 roc_auc 0.74154 prc_auc 0.85861[0m
[92maverage training of epoch 6: loss 0.63378 acc 0.66667 roc_auc 0.61580 prc_auc 0.74454[0m
[93maverage test of epoch 6: loss 0.63871 acc 0.65789 roc_auc 0.64308 prc_auc 0.73721[0m
[92maverage training of epoch 7: loss 0.62369 acc 0.66667 roc_auc 0.68100 prc_auc 0.77621[0m
[93maverage test of epoch 7: loss 0.63096 acc 0.65789 roc_auc 0.65846 prc_auc 0.73578[0m
[92maverage training of epoch 8: loss 0.60831 acc 0.66667 roc_auc 0.72340 prc_auc 0.80609[0m
[93maverage test of epoch 8: loss 0.61941 acc 0.65789 roc_auc 0.67077 prc_auc 0.74653[0m
[92maverage training of epoch 9: loss 0.59244 acc 0.66667 roc_auc 0.73760 prc_auc 0.82025[0m
[93maverage test of epoch 9: loss 0.60691 acc 0.65789 roc_auc 0.69846 prc_auc 0.77724[0m
[92maverage training of epoch 10: loss 0.57678 acc 0.66667 roc_auc 0.75560 prc_auc 0.83079[0m
[93maverage test of epoch 10: loss 0.59832 acc 0.65789 roc_auc 0.69846 prc_auc 0.76044[0m
[92maverage training of epoch 11: loss 0.55902 acc 0.66667 roc_auc 0.76920 prc_auc 0.83903[0m
[93maverage test of epoch 11: loss 0.58370 acc 0.65789 roc_auc 0.75385 prc_auc 0.79917[0m
[92maverage training of epoch 12: loss 0.54980 acc 0.66667 roc_auc 0.75600 prc_auc 0.82085[0m
[93maverage test of epoch 12: loss 0.57251 acc 0.65789 roc_auc 0.78769 prc_auc 0.82500[0m
[92maverage training of epoch 13: loss 0.53973 acc 0.74000 roc_auc 0.76500 prc_auc 0.83450[0m
[93maverage test of epoch 13: loss 0.56103 acc 0.76316 roc_auc 0.82769 prc_auc 0.90444[0m
[92maverage training of epoch 14: loss 0.52858 acc 0.80667 roc_auc 0.77740 prc_auc 0.84894[0m
[93maverage test of epoch 14: loss 0.55314 acc 0.78947 roc_auc 0.82769 prc_auc 0.90444[0m
[92maverage training of epoch 15: loss 0.51936 acc 0.80667 roc_auc 0.78900 prc_auc 0.86579[0m
[93maverage test of epoch 15: loss 0.54042 acc 0.78947 roc_auc 0.84308 prc_auc 0.91436[0m
[92maverage training of epoch 16: loss 0.50550 acc 0.80667 roc_auc 0.80420 prc_auc 0.87717[0m
[93maverage test of epoch 16: loss 0.52916 acc 0.81579 roc_auc 0.84923 prc_auc 0.91666[0m
[92maverage training of epoch 17: loss 0.49119 acc 0.81333 roc_auc 0.81740 prc_auc 0.88731[0m
[93maverage test of epoch 17: loss 0.51428 acc 0.78947 roc_auc 0.85538 prc_auc 0.92027[0m
[92maverage training of epoch 18: loss 0.47663 acc 0.82000 roc_auc 0.82480 prc_auc 0.89253[0m
[93maverage test of epoch 18: loss 0.49893 acc 0.78947 roc_auc 0.86462 prc_auc 0.92827[0m
[92maverage training of epoch 19: loss 0.46321 acc 0.82000 roc_auc 0.84280 prc_auc 0.90249[0m
[93maverage test of epoch 19: loss 0.48191 acc 0.78947 roc_auc 0.88923 prc_auc 0.94352[0m
[92maverage training of epoch 20: loss 0.44659 acc 0.82667 roc_auc 0.85800 prc_auc 0.91015[0m
[93maverage test of epoch 20: loss 0.46966 acc 0.81579 roc_auc 0.90462 prc_auc 0.95104[0m
[92maverage training of epoch 21: loss 0.43294 acc 0.81333 roc_auc 0.86860 prc_auc 0.91659[0m
[93maverage test of epoch 21: loss 0.45170 acc 0.81579 roc_auc 0.90769 prc_auc 0.95235[0m
[92maverage training of epoch 22: loss 0.42037 acc 0.82000 roc_auc 0.87640 prc_auc 0.92085[0m
[93maverage test of epoch 22: loss 0.43243 acc 0.81579 roc_auc 0.91077 prc_auc 0.95387[0m
[92maverage training of epoch 23: loss 0.41000 acc 0.83333 roc_auc 0.88160 prc_auc 0.92501[0m
[93maverage test of epoch 23: loss 0.42252 acc 0.81579 roc_auc 0.91692 prc_auc 0.95632[0m
[92maverage training of epoch 24: loss 0.40045 acc 0.82667 roc_auc 0.88780 prc_auc 0.93331[0m
[93maverage test of epoch 24: loss 0.40755 acc 0.84211 roc_auc 0.92000 prc_auc 0.95899[0m
[92maverage training of epoch 25: loss 0.39318 acc 0.84667 roc_auc 0.89340 prc_auc 0.94069[0m
[93maverage test of epoch 25: loss 0.39656 acc 0.84211 roc_auc 0.92308 prc_auc 0.96046[0m
[92maverage training of epoch 26: loss 0.38667 acc 0.84667 roc_auc 0.89600 prc_auc 0.94294[0m
[93maverage test of epoch 26: loss 0.38937 acc 0.84211 roc_auc 0.92308 prc_auc 0.96046[0m
[92maverage training of epoch 27: loss 0.37964 acc 0.85333 roc_auc 0.90220 prc_auc 0.94627[0m
[93maverage test of epoch 27: loss 0.38262 acc 0.84211 roc_auc 0.92308 prc_auc 0.96046[0m
[92maverage training of epoch 28: loss 0.37597 acc 0.85333 roc_auc 0.90400 prc_auc 0.94706[0m
[93maverage test of epoch 28: loss 0.37596 acc 0.84211 roc_auc 0.92308 prc_auc 0.96046[0m
[92maverage training of epoch 29: loss 0.37384 acc 0.84000 roc_auc 0.90640 prc_auc 0.94862[0m
[93maverage test of epoch 29: loss 0.36706 acc 0.84211 roc_auc 0.92308 prc_auc 0.96046[0m
[92maverage training of epoch 30: loss 0.36880 acc 0.84667 roc_auc 0.90780 prc_auc 0.94985[0m
[93maverage test of epoch 30: loss 0.36348 acc 0.84211 roc_auc 0.92615 prc_auc 0.96296[0m
[92maverage training of epoch 31: loss 0.36599 acc 0.85333 roc_auc 0.90900 prc_auc 0.95024[0m
[93maverage test of epoch 31: loss 0.35682 acc 0.84211 roc_auc 0.92923 prc_auc 0.96531[0m
[92maverage training of epoch 32: loss 0.36132 acc 0.85333 roc_auc 0.90860 prc_auc 0.94990[0m
[93maverage test of epoch 32: loss 0.34856 acc 0.84211 roc_auc 0.93538 prc_auc 0.96811[0m
[92maverage training of epoch 33: loss 0.35602 acc 0.85333 roc_auc 0.91240 prc_auc 0.95194[0m
[93maverage test of epoch 33: loss 0.34611 acc 0.84211 roc_auc 0.93231 prc_auc 0.96588[0m
[92maverage training of epoch 34: loss 0.35283 acc 0.84667 roc_auc 0.91240 prc_auc 0.95224[0m
[93maverage test of epoch 34: loss 0.34709 acc 0.84211 roc_auc 0.93538 prc_auc 0.96811[0m
[92maverage training of epoch 35: loss 0.34791 acc 0.86667 roc_auc 0.91480 prc_auc 0.95335[0m
[93maverage test of epoch 35: loss 0.35604 acc 0.84211 roc_auc 0.93231 prc_auc 0.96669[0m
[92maverage training of epoch 36: loss 0.34706 acc 0.86000 roc_auc 0.91640 prc_auc 0.95397[0m
[93maverage test of epoch 36: loss 0.35327 acc 0.84211 roc_auc 0.93231 prc_auc 0.96669[0m
[92maverage training of epoch 37: loss 0.34634 acc 0.86000 roc_auc 0.91760 prc_auc 0.95522[0m
[93maverage test of epoch 37: loss 0.34443 acc 0.84211 roc_auc 0.93231 prc_auc 0.96669[0m
[92maverage training of epoch 38: loss 0.34440 acc 0.85333 roc_auc 0.91880 prc_auc 0.95580[0m
[93maverage test of epoch 38: loss 0.34583 acc 0.84211 roc_auc 0.92923 prc_auc 0.96488[0m
[92maverage training of epoch 39: loss 0.34258 acc 0.85333 roc_auc 0.92140 prc_auc 0.95663[0m
[93maverage test of epoch 39: loss 0.34713 acc 0.84211 roc_auc 0.92615 prc_auc 0.96266[0m
[92maverage training of epoch 40: loss 0.34261 acc 0.85333 roc_auc 0.92000 prc_auc 0.95536[0m
[93maverage test of epoch 40: loss 0.34541 acc 0.84211 roc_auc 0.92923 prc_auc 0.96488[0m
[92maverage training of epoch 41: loss 0.34100 acc 0.85333 roc_auc 0.92140 prc_auc 0.95631[0m
[93maverage test of epoch 41: loss 0.34296 acc 0.84211 roc_auc 0.93538 prc_auc 0.96793[0m
[92maverage training of epoch 42: loss 0.33503 acc 0.85333 roc_auc 0.92520 prc_auc 0.95889[0m
[93maverage test of epoch 42: loss 0.34295 acc 0.84211 roc_auc 0.93538 prc_auc 0.96793[0m
[92maverage training of epoch 43: loss 0.33365 acc 0.84667 roc_auc 0.92580 prc_auc 0.95878[0m
[93maverage test of epoch 43: loss 0.35267 acc 0.84211 roc_auc 0.93231 prc_auc 0.96699[0m
[92maverage training of epoch 44: loss 0.33232 acc 0.86000 roc_auc 0.92420 prc_auc 0.95697[0m
[93maverage test of epoch 44: loss 0.35814 acc 0.84211 roc_auc 0.92615 prc_auc 0.96341[0m
[92maverage training of epoch 45: loss 0.33091 acc 0.85333 roc_auc 0.92760 prc_auc 0.96050[0m
[93maverage test of epoch 45: loss 0.35644 acc 0.84211 roc_auc 0.92308 prc_auc 0.95972[0m
[92maverage training of epoch 46: loss 0.33094 acc 0.85333 roc_auc 0.92760 prc_auc 0.96002[0m
[93maverage test of epoch 46: loss 0.35292 acc 0.84211 roc_auc 0.92615 prc_auc 0.96171[0m
[92maverage training of epoch 47: loss 0.32919 acc 0.86000 roc_auc 0.92760 prc_auc 0.95981[0m
[93maverage test of epoch 47: loss 0.34888 acc 0.84211 roc_auc 0.93538 prc_auc 0.96793[0m
[92maverage training of epoch 48: loss 0.32441 acc 0.86000 roc_auc 0.93020 prc_auc 0.96107[0m
[93maverage test of epoch 48: loss 0.35071 acc 0.84211 roc_auc 0.92615 prc_auc 0.96171[0m
[92maverage training of epoch 49: loss 0.32651 acc 0.86000 roc_auc 0.92920 prc_auc 0.96052[0m
[93maverage test of epoch 49: loss 0.35133 acc 0.84211 roc_auc 0.92923 prc_auc 0.96393[0m
Training model with dataset, testing using fold 3
[92maverage training of epoch 0: loss 0.71233 acc 0.33775 roc_auc 0.42706 prc_auc 0.61024[0m
[93maverage test of epoch 0: loss 0.70316 acc 0.32432 roc_auc 0.55333 prc_auc 0.73527[0m
[92maverage training of epoch 1: loss 0.69477 acc 0.47682 roc_auc 0.42020 prc_auc 0.60317[0m
[93maverage test of epoch 1: loss 0.68278 acc 0.67568 roc_auc 0.49000 prc_auc 0.65647[0m
[92maverage training of epoch 2: loss 0.67742 acc 0.66225 roc_auc 0.41745 prc_auc 0.60003[0m
[93maverage test of epoch 2: loss 0.66480 acc 0.67568 roc_auc 0.62000 prc_auc 0.70764[0m
[92maverage training of epoch 3: loss 0.66290 acc 0.66225 roc_auc 0.43510 prc_auc 0.61697[0m
[93maverage test of epoch 3: loss 0.64894 acc 0.67568 roc_auc 0.65000 prc_auc 0.75705[0m
[92maverage training of epoch 4: loss 0.64933 acc 0.66225 roc_auc 0.52490 prc_auc 0.67929[0m
[93maverage test of epoch 4: loss 0.63567 acc 0.67568 roc_auc 0.67000 prc_auc 0.81890[0m
[92maverage training of epoch 5: loss 0.63232 acc 0.66225 roc_auc 0.64255 prc_auc 0.73302[0m
[93maverage test of epoch 5: loss 0.62158 acc 0.67568 roc_auc 0.65333 prc_auc 0.75444[0m
[92maverage training of epoch 6: loss 0.60805 acc 0.66225 roc_auc 0.72569 prc_auc 0.80875[0m
[93maverage test of epoch 6: loss 0.60348 acc 0.67568 roc_auc 0.62000 prc_auc 0.75559[0m
[92maverage training of epoch 7: loss 0.57844 acc 0.66225 roc_auc 0.76392 prc_auc 0.82894[0m
[93maverage test of epoch 7: loss 0.58973 acc 0.67568 roc_auc 0.61000 prc_auc 0.69499[0m
[92maverage training of epoch 8: loss 0.55113 acc 0.66225 roc_auc 0.77941 prc_auc 0.84450[0m
[93maverage test of epoch 8: loss 0.58819 acc 0.67568 roc_auc 0.62000 prc_auc 0.75189[0m
[92maverage training of epoch 9: loss 0.52798 acc 0.71523 roc_auc 0.80569 prc_auc 0.87887[0m
[93maverage test of epoch 9: loss 0.58639 acc 0.75676 roc_auc 0.63333 prc_auc 0.76036[0m
[92maverage training of epoch 10: loss 0.51130 acc 0.80795 roc_auc 0.81608 prc_auc 0.89157[0m
[93maverage test of epoch 10: loss 0.58505 acc 0.75676 roc_auc 0.70000 prc_auc 0.79841[0m
[92maverage training of epoch 11: loss 0.49206 acc 0.80795 roc_auc 0.83784 prc_auc 0.90987[0m
[93maverage test of epoch 11: loss 0.58599 acc 0.72973 roc_auc 0.70667 prc_auc 0.78519[0m
[92maverage training of epoch 12: loss 0.47599 acc 0.79470 roc_auc 0.84510 prc_auc 0.91483[0m
[93maverage test of epoch 12: loss 0.58926 acc 0.75676 roc_auc 0.72667 prc_auc 0.80162[0m
[92maverage training of epoch 13: loss 0.46043 acc 0.80132 roc_auc 0.85569 prc_auc 0.92414[0m
[93maverage test of epoch 13: loss 0.59637 acc 0.72973 roc_auc 0.71333 prc_auc 0.78750[0m
[92maverage training of epoch 14: loss 0.44744 acc 0.80795 roc_auc 0.85922 prc_auc 0.92741[0m
[93maverage test of epoch 14: loss 0.60486 acc 0.72973 roc_auc 0.71333 prc_auc 0.78126[0m
[92maverage training of epoch 15: loss 0.43410 acc 0.82781 roc_auc 0.86255 prc_auc 0.93094[0m
[93maverage test of epoch 15: loss 0.61228 acc 0.70270 roc_auc 0.74667 prc_auc 0.84719[0m
[92maverage training of epoch 16: loss 0.42443 acc 0.83444 roc_auc 0.86392 prc_auc 0.93221[0m
[93maverage test of epoch 16: loss 0.62028 acc 0.72973 roc_auc 0.75000 prc_auc 0.86107[0m
[92maverage training of epoch 17: loss 0.41810 acc 0.82119 roc_auc 0.86549 prc_auc 0.93371[0m
[93maverage test of epoch 17: loss 0.63044 acc 0.72973 roc_auc 0.72667 prc_auc 0.84091[0m
[92maverage training of epoch 18: loss 0.40993 acc 0.82781 roc_auc 0.87686 prc_auc 0.93713[0m
[93maverage test of epoch 18: loss 0.63277 acc 0.72973 roc_auc 0.74667 prc_auc 0.85238[0m
[92maverage training of epoch 19: loss 0.40023 acc 0.83444 roc_auc 0.88882 prc_auc 0.94208[0m
[93maverage test of epoch 19: loss 0.62508 acc 0.78378 roc_auc 0.75333 prc_auc 0.86705[0m
[92maverage training of epoch 20: loss 0.39187 acc 0.84768 roc_auc 0.89667 prc_auc 0.94660[0m
[93maverage test of epoch 20: loss 0.61733 acc 0.78378 roc_auc 0.75333 prc_auc 0.86410[0m
[92maverage training of epoch 21: loss 0.38515 acc 0.85430 roc_auc 0.90647 prc_auc 0.95114[0m
[93maverage test of epoch 21: loss 0.60668 acc 0.78378 roc_auc 0.74667 prc_auc 0.85189[0m
[92maverage training of epoch 22: loss 0.37726 acc 0.86093 roc_auc 0.91333 prc_auc 0.95413[0m
[93maverage test of epoch 22: loss 0.60431 acc 0.78378 roc_auc 0.76333 prc_auc 0.86627[0m
[92maverage training of epoch 23: loss 0.36963 acc 0.86093 roc_auc 0.91843 prc_auc 0.95688[0m
[93maverage test of epoch 23: loss 0.59429 acc 0.78378 roc_auc 0.77333 prc_auc 0.87082[0m
[92maverage training of epoch 24: loss 0.36165 acc 0.86093 roc_auc 0.92529 prc_auc 0.96046[0m
[93maverage test of epoch 24: loss 0.59372 acc 0.78378 roc_auc 0.77667 prc_auc 0.87188[0m
[92maverage training of epoch 25: loss 0.35525 acc 0.86093 roc_auc 0.92843 prc_auc 0.96233[0m
[93maverage test of epoch 25: loss 0.59408 acc 0.78378 roc_auc 0.78333 prc_auc 0.87225[0m
[92maverage training of epoch 26: loss 0.35228 acc 0.86093 roc_auc 0.92824 prc_auc 0.96236[0m
[93maverage test of epoch 26: loss 0.58822 acc 0.78378 roc_auc 0.78333 prc_auc 0.87225[0m
[92maverage training of epoch 27: loss 0.34871 acc 0.86755 roc_auc 0.93020 prc_auc 0.96370[0m
[93maverage test of epoch 27: loss 0.58379 acc 0.75676 roc_auc 0.78667 prc_auc 0.87892[0m
[92maverage training of epoch 28: loss 0.34108 acc 0.87417 roc_auc 0.93196 prc_auc 0.96476[0m
[93maverage test of epoch 28: loss 0.58386 acc 0.78378 roc_auc 0.80000 prc_auc 0.88458[0m
[92maverage training of epoch 29: loss 0.33559 acc 0.88079 roc_auc 0.93255 prc_auc 0.96494[0m
[93maverage test of epoch 29: loss 0.58520 acc 0.78378 roc_auc 0.79000 prc_auc 0.87698[0m
[92maverage training of epoch 30: loss 0.33011 acc 0.88079 roc_auc 0.93471 prc_auc 0.96632[0m
[93maverage test of epoch 30: loss 0.58738 acc 0.78378 roc_auc 0.79667 prc_auc 0.88172[0m
[92maverage training of epoch 31: loss 0.32572 acc 0.88079 roc_auc 0.93549 prc_auc 0.96670[0m
[93maverage test of epoch 31: loss 0.58177 acc 0.78378 roc_auc 0.81000 prc_auc 0.88400[0m
[92maverage training of epoch 32: loss 0.32225 acc 0.88079 roc_auc 0.93647 prc_auc 0.96739[0m
[93maverage test of epoch 32: loss 0.57997 acc 0.78378 roc_auc 0.81667 prc_auc 0.89464[0m
[92maverage training of epoch 33: loss 0.31608 acc 0.88079 roc_auc 0.93843 prc_auc 0.96836[0m
[93maverage test of epoch 33: loss 0.57785 acc 0.78378 roc_auc 0.81333 prc_auc 0.88817[0m
[92maverage training of epoch 34: loss 0.31239 acc 0.87417 roc_auc 0.94078 prc_auc 0.96936[0m
[93maverage test of epoch 34: loss 0.57476 acc 0.78378 roc_auc 0.82000 prc_auc 0.89096[0m
[92maverage training of epoch 35: loss 0.30931 acc 0.87417 roc_auc 0.94176 prc_auc 0.96975[0m
[93maverage test of epoch 35: loss 0.57337 acc 0.78378 roc_auc 0.81333 prc_auc 0.88510[0m
[92maverage training of epoch 36: loss 0.30565 acc 0.87417 roc_auc 0.94275 prc_auc 0.97038[0m
[93maverage test of epoch 36: loss 0.57253 acc 0.78378 roc_auc 0.82000 prc_auc 0.89096[0m
[92maverage training of epoch 37: loss 0.30303 acc 0.87417 roc_auc 0.94255 prc_auc 0.97028[0m
[93maverage test of epoch 37: loss 0.57689 acc 0.78378 roc_auc 0.81667 prc_auc 0.88985[0m
[92maverage training of epoch 38: loss 0.29940 acc 0.87417 roc_auc 0.94412 prc_auc 0.97112[0m
[93maverage test of epoch 38: loss 0.57392 acc 0.78378 roc_auc 0.81667 prc_auc 0.88985[0m
[92maverage training of epoch 39: loss 0.29739 acc 0.87417 roc_auc 0.94451 prc_auc 0.97130[0m
[93maverage test of epoch 39: loss 0.57495 acc 0.78378 roc_auc 0.82000 prc_auc 0.89249[0m
[92maverage training of epoch 40: loss 0.29709 acc 0.87417 roc_auc 0.94392 prc_auc 0.97090[0m
[93maverage test of epoch 40: loss 0.56752 acc 0.78378 roc_auc 0.81333 prc_auc 0.88972[0m
[92maverage training of epoch 41: loss 0.29338 acc 0.87417 roc_auc 0.94490 prc_auc 0.97154[0m
[93maverage test of epoch 41: loss 0.56697 acc 0.78378 roc_auc 0.81333 prc_auc 0.88972[0m
[92maverage training of epoch 42: loss 0.29054 acc 0.87417 roc_auc 0.94608 prc_auc 0.97221[0m
[93maverage test of epoch 42: loss 0.56208 acc 0.75676 roc_auc 0.81333 prc_auc 0.88972[0m
[92maverage training of epoch 43: loss 0.29036 acc 0.86755 roc_auc 0.94569 prc_auc 0.97198[0m
[93maverage test of epoch 43: loss 0.55821 acc 0.75676 roc_auc 0.81333 prc_auc 0.88972[0m
[92maverage training of epoch 44: loss 0.28678 acc 0.87417 roc_auc 0.94667 prc_auc 0.97236[0m
[93maverage test of epoch 44: loss 0.56128 acc 0.75676 roc_auc 0.81333 prc_auc 0.88972[0m
[92maverage training of epoch 45: loss 0.28498 acc 0.86755 roc_auc 0.94667 prc_auc 0.97245[0m
[93maverage test of epoch 45: loss 0.56100 acc 0.75676 roc_auc 0.81333 prc_auc 0.88972[0m
[92maverage training of epoch 46: loss 0.28275 acc 0.86755 roc_auc 0.94686 prc_auc 0.97247[0m
[93maverage test of epoch 46: loss 0.56063 acc 0.75676 roc_auc 0.81333 prc_auc 0.88972[0m
[92maverage training of epoch 47: loss 0.28179 acc 0.86755 roc_auc 0.94784 prc_auc 0.97311[0m
[93maverage test of epoch 47: loss 0.56162 acc 0.75676 roc_auc 0.81333 prc_auc 0.88972[0m
[92maverage training of epoch 48: loss 0.28055 acc 0.87417 roc_auc 0.94765 prc_auc 0.97302[0m
[93maverage test of epoch 48: loss 0.55883 acc 0.75676 roc_auc 0.81333 prc_auc 0.88972[0m
[92maverage training of epoch 49: loss 0.28072 acc 0.88079 roc_auc 0.94686 prc_auc 0.97256[0m
[93maverage test of epoch 49: loss 0.55894 acc 0.75676 roc_auc 0.81333 prc_auc 0.88972[0m
Training model with dataset, testing using fold 4
[92maverage training of epoch 0: loss 0.72704 acc 0.33775 roc_auc 0.41196 prc_auc 0.60713[0m
[93maverage test of epoch 0: loss 0.72222 acc 0.32432 roc_auc 0.60000 prc_auc 0.73998[0m
[92maverage training of epoch 1: loss 0.71522 acc 0.33775 roc_auc 0.41373 prc_auc 0.60730[0m
[93maverage test of epoch 1: loss 0.70901 acc 0.32432 roc_auc 0.48000 prc_auc 0.66069[0m
[92maverage training of epoch 2: loss 0.70079 acc 0.35099 roc_auc 0.40098 prc_auc 0.59370[0m
[93maverage test of epoch 2: loss 0.69043 acc 0.67568 roc_auc 0.39000 prc_auc 0.62904[0m
[92maverage training of epoch 3: loss 0.68306 acc 0.66225 roc_auc 0.40373 prc_auc 0.59339[0m
[93maverage test of epoch 3: loss 0.66797 acc 0.67568 roc_auc 0.61000 prc_auc 0.70796[0m
[92maverage training of epoch 4: loss 0.66375 acc 0.66225 roc_auc 0.45412 prc_auc 0.63253[0m
[93maverage test of epoch 4: loss 0.64659 acc 0.67568 roc_auc 0.77667 prc_auc 0.89255[0m
[92maverage training of epoch 5: loss 0.64540 acc 0.66225 roc_auc 0.54490 prc_auc 0.67608[0m
[93maverage test of epoch 5: loss 0.62915 acc 0.67568 roc_auc 0.70667 prc_auc 0.75772[0m
[92maverage training of epoch 6: loss 0.62508 acc 0.66225 roc_auc 0.63843 prc_auc 0.72169[0m
[93maverage test of epoch 6: loss 0.61501 acc 0.67568 roc_auc 0.77333 prc_auc 0.86954[0m
[92maverage training of epoch 7: loss 0.60332 acc 0.66225 roc_auc 0.70725 prc_auc 0.77616[0m
[93maverage test of epoch 7: loss 0.59707 acc 0.67568 roc_auc 0.78000 prc_auc 0.86528[0m
[92maverage training of epoch 8: loss 0.58090 acc 0.66225 roc_auc 0.74373 prc_auc 0.80620[0m
[93maverage test of epoch 8: loss 0.57776 acc 0.67568 roc_auc 0.78000 prc_auc 0.86535[0m
[92maverage training of epoch 9: loss 0.55838 acc 0.66225 roc_auc 0.77275 prc_auc 0.82410[0m
[93maverage test of epoch 9: loss 0.56082 acc 0.70270 roc_auc 0.78667 prc_auc 0.87381[0m
[92maverage training of epoch 10: loss 0.53929 acc 0.76821 roc_auc 0.79451 prc_auc 0.84045[0m
[93maverage test of epoch 10: loss 0.54914 acc 0.72973 roc_auc 0.82333 prc_auc 0.90562[0m
[92maverage training of epoch 11: loss 0.52333 acc 0.80132 roc_auc 0.81196 prc_auc 0.85663[0m
[93maverage test of epoch 11: loss 0.52761 acc 0.72973 roc_auc 0.85333 prc_auc 0.93381[0m
[92maverage training of epoch 12: loss 0.50501 acc 0.82119 roc_auc 0.82863 prc_auc 0.87013[0m
[93maverage test of epoch 12: loss 0.51473 acc 0.72973 roc_auc 0.86000 prc_auc 0.93696[0m
[92maverage training of epoch 13: loss 0.48708 acc 0.82781 roc_auc 0.84510 prc_auc 0.88243[0m
[93maverage test of epoch 13: loss 0.49841 acc 0.72973 roc_auc 0.86000 prc_auc 0.93696[0m
[92maverage training of epoch 14: loss 0.46811 acc 0.80132 roc_auc 0.85980 prc_auc 0.89121[0m
[93maverage test of epoch 14: loss 0.47133 acc 0.78378 roc_auc 0.86667 prc_auc 0.94140[0m
[92maverage training of epoch 15: loss 0.45480 acc 0.81457 roc_auc 0.86588 prc_auc 0.90990[0m
[93maverage test of epoch 15: loss 0.45949 acc 0.83784 roc_auc 0.86333 prc_auc 0.93905[0m
[92maverage training of epoch 16: loss 0.44223 acc 0.82119 roc_auc 0.87020 prc_auc 0.91243[0m
[93maverage test of epoch 16: loss 0.45119 acc 0.83784 roc_auc 0.86333 prc_auc 0.93793[0m
[92maverage training of epoch 17: loss 0.42829 acc 0.82119 roc_auc 0.87725 prc_auc 0.92126[0m
[93maverage test of epoch 17: loss 0.44240 acc 0.83784 roc_auc 0.87000 prc_auc 0.93980[0m
[92maverage training of epoch 18: loss 0.41870 acc 0.83444 roc_auc 0.88294 prc_auc 0.93166[0m
[93maverage test of epoch 18: loss 0.43702 acc 0.83784 roc_auc 0.86667 prc_auc 0.93869[0m
[92maverage training of epoch 19: loss 0.40937 acc 0.83444 roc_auc 0.88569 prc_auc 0.93423[0m
[93maverage test of epoch 19: loss 0.42858 acc 0.83784 roc_auc 0.87000 prc_auc 0.93966[0m
[92maverage training of epoch 20: loss 0.39940 acc 0.84106 roc_auc 0.88961 prc_auc 0.93613[0m
[93maverage test of epoch 20: loss 0.42369 acc 0.83784 roc_auc 0.86667 prc_auc 0.93869[0m
[92maverage training of epoch 21: loss 0.39228 acc 0.84106 roc_auc 0.89451 prc_auc 0.94014[0m
[93maverage test of epoch 21: loss 0.42126 acc 0.83784 roc_auc 0.86667 prc_auc 0.93869[0m
[92maverage training of epoch 22: loss 0.38577 acc 0.84768 roc_auc 0.89490 prc_auc 0.93983[0m
[93maverage test of epoch 22: loss 0.42156 acc 0.83784 roc_auc 0.87667 prc_auc 0.94312[0m
[92maverage training of epoch 23: loss 0.37997 acc 0.84106 roc_auc 0.89647 prc_auc 0.94181[0m
[93maverage test of epoch 23: loss 0.41622 acc 0.83784 roc_auc 0.88333 prc_auc 0.94561[0m
[92maverage training of epoch 24: loss 0.37401 acc 0.84768 roc_auc 0.89961 prc_auc 0.94364[0m
[93maverage test of epoch 24: loss 0.41632 acc 0.81081 roc_auc 0.88333 prc_auc 0.94561[0m
[92maverage training of epoch 25: loss 0.36989 acc 0.85430 roc_auc 0.89863 prc_auc 0.94249[0m
[93maverage test of epoch 25: loss 0.41736 acc 0.81081 roc_auc 0.89333 prc_auc 0.95109[0m
[92maverage training of epoch 26: loss 0.36650 acc 0.85430 roc_auc 0.90078 prc_auc 0.94457[0m
[93maverage test of epoch 26: loss 0.40608 acc 0.81081 roc_auc 0.88333 prc_auc 0.94543[0m
[92maverage training of epoch 27: loss 0.36180 acc 0.86755 roc_auc 0.90510 prc_auc 0.94643[0m
[93maverage test of epoch 27: loss 0.39929 acc 0.81081 roc_auc 0.89333 prc_auc 0.95098[0m
[92maverage training of epoch 28: loss 0.35852 acc 0.86093 roc_auc 0.90902 prc_auc 0.94807[0m
[93maverage test of epoch 28: loss 0.39697 acc 0.81081 roc_auc 0.89333 prc_auc 0.95098[0m
[92maverage training of epoch 29: loss 0.35619 acc 0.85430 roc_auc 0.90804 prc_auc 0.94836[0m
[93maverage test of epoch 29: loss 0.39851 acc 0.81081 roc_auc 0.90000 prc_auc 0.95519[0m
[92maverage training of epoch 30: loss 0.35227 acc 0.86093 roc_auc 0.91000 prc_auc 0.94914[0m
[93maverage test of epoch 30: loss 0.39712 acc 0.81081 roc_auc 0.89667 prc_auc 0.95408[0m
[92maverage training of epoch 31: loss 0.34962 acc 0.86093 roc_auc 0.91118 prc_auc 0.94947[0m
[93maverage test of epoch 31: loss 0.39498 acc 0.78378 roc_auc 0.89667 prc_auc 0.95608[0m
[92maverage training of epoch 32: loss 0.34704 acc 0.85430 roc_auc 0.91333 prc_auc 0.95158[0m
[93maverage test of epoch 32: loss 0.39592 acc 0.78378 roc_auc 0.90333 prc_auc 0.95989[0m
[92maverage training of epoch 33: loss 0.34318 acc 0.84768 roc_auc 0.91294 prc_auc 0.95168[0m
[93maverage test of epoch 33: loss 0.39659 acc 0.78378 roc_auc 0.90333 prc_auc 0.96049[0m
[92maverage training of epoch 34: loss 0.34215 acc 0.84768 roc_auc 0.91275 prc_auc 0.95153[0m
[93maverage test of epoch 34: loss 0.39503 acc 0.78378 roc_auc 0.90333 prc_auc 0.95989[0m
[92maverage training of epoch 35: loss 0.34482 acc 0.84768 roc_auc 0.91373 prc_auc 0.95174[0m
[93maverage test of epoch 35: loss 0.38944 acc 0.81081 roc_auc 0.91667 prc_auc 0.96701[0m
[92maverage training of epoch 36: loss 0.34027 acc 0.86093 roc_auc 0.91686 prc_auc 0.95370[0m
[93maverage test of epoch 36: loss 0.38409 acc 0.81081 roc_auc 0.91333 prc_auc 0.96474[0m
[92maverage training of epoch 37: loss 0.33475 acc 0.85430 roc_auc 0.91843 prc_auc 0.95497[0m
[93maverage test of epoch 37: loss 0.39286 acc 0.81081 roc_auc 0.90667 prc_auc 0.96111[0m
[92maverage training of epoch 38: loss 0.33385 acc 0.86755 roc_auc 0.92157 prc_auc 0.95661[0m
[93maverage test of epoch 38: loss 0.38657 acc 0.81081 roc_auc 0.91667 prc_auc 0.96641[0m
[92maverage training of epoch 39: loss 0.33045 acc 0.86755 roc_auc 0.92294 prc_auc 0.95766[0m
[93maverage test of epoch 39: loss 0.38771 acc 0.81081 roc_auc 0.91333 prc_auc 0.96474[0m
[92maverage training of epoch 40: loss 0.32640 acc 0.86093 roc_auc 0.92529 prc_auc 0.95889[0m
[93maverage test of epoch 40: loss 0.39118 acc 0.81081 roc_auc 0.90667 prc_auc 0.96111[0m
[92maverage training of epoch 41: loss 0.32651 acc 0.86755 roc_auc 0.92431 prc_auc 0.95810[0m
[93maverage test of epoch 41: loss 0.38458 acc 0.81081 roc_auc 0.92000 prc_auc 0.96757[0m
[92maverage training of epoch 42: loss 0.32325 acc 0.86755 roc_auc 0.92569 prc_auc 0.95867[0m
[93maverage test of epoch 42: loss 0.38790 acc 0.81081 roc_auc 0.91333 prc_auc 0.96474[0m
[92maverage training of epoch 43: loss 0.32361 acc 0.86093 roc_auc 0.92412 prc_auc 0.95782[0m
[93maverage test of epoch 43: loss 0.40052 acc 0.81081 roc_auc 0.90667 prc_auc 0.96111[0m
[92maverage training of epoch 44: loss 0.31815 acc 0.86755 roc_auc 0.92765 prc_auc 0.95999[0m
[93maverage test of epoch 44: loss 0.40036 acc 0.81081 roc_auc 0.90333 prc_auc 0.95989[0m
[92maverage training of epoch 45: loss 0.31992 acc 0.86755 roc_auc 0.92549 prc_auc 0.95882[0m
[93maverage test of epoch 45: loss 0.39395 acc 0.81081 roc_auc 0.90667 prc_auc 0.96111[0m
[92maverage training of epoch 46: loss 0.31671 acc 0.86755 roc_auc 0.92882 prc_auc 0.96017[0m
[93maverage test of epoch 46: loss 0.39047 acc 0.81081 roc_auc 0.91667 prc_auc 0.96571[0m
[92maverage training of epoch 47: loss 0.31481 acc 0.86093 roc_auc 0.92882 prc_auc 0.96085[0m
[93maverage test of epoch 47: loss 0.40334 acc 0.81081 roc_auc 0.90667 prc_auc 0.96086[0m
[92maverage training of epoch 48: loss 0.31573 acc 0.86755 roc_auc 0.92765 prc_auc 0.96036[0m
[93maverage test of epoch 48: loss 0.40123 acc 0.81081 roc_auc 0.91333 prc_auc 0.96302[0m
[92maverage training of epoch 49: loss 0.31535 acc 0.86093 roc_auc 0.92686 prc_auc 0.95947[0m
[93maverage test of epoch 49: loss 0.40397 acc 0.81081 roc_auc 0.91333 prc_auc 0.96302[0m
Run statistics: 
==== Configuration Settings ====
== Run Settings ==
Model: DiffPool, Dataset: MUTAG
num_epochs: 50
learning_rate: 0.0001
seed: 1800
k_fold: 5
model: DiffPool
dataset: MUTAG

== Model Settings and results ==
convolution_layers_size: 64-64-64
pred_hidden_layers: 50-50-50
assign_ratio: 0.25
number_of_pooling: 1
concat_tensors: False

Accuracy (avg): 0.81878 ROC_AUC (avg): 0.88503 PRC_AUC (avg): 0.92975 

Average forward propagation time taken(ms): 2.5455240609991896
Average backward propagation time taken(ms): 3.7171973752970544

