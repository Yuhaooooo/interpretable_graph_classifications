# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======


torch.cuda.is_available():  True 


load_data.py load_model_data(): Unserialising pickled dataset into Graph objects
==== Dataset Information ====
== General Information == 
Number of graphs: 188
Number of classes: 2
Class distribution: 
0:63 1:125 

== Node information== 
Average number of nodes: 18
Average number of edges (undirected): 20
Max number of nodes: 28
Number of distinct node labels: 7
Average number of distinct node labels: 3
Node labels distribution: 
0:2395 1:345 2:593 3:12 4:1 5:23 6:2 

*** 3 dataset_features:  {'name': 'MUTAG', 'num_class': 2, 'label_dict': {'0': 0, '1': 1}, 'have_node_labels': True, 'have_node_attributions': False, 'node_dict': {'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, 'UNKNOWN': 7}, 'feat_dim': 8, 'edge_feat_dim': 0, 'max_num_nodes': 28, 'avg_num_nodes': 18, 'graph_sizes_list': [17, 13, 13, 19, 11, 28, 16, 20, 12, 17, 17, 20, 22, 13, 19, 22, 11, 17, 13, 18, 18, 17, 23, 27, 17, 13, 23, 17, 23, 23, 22, 24, 23, 13, 17, 14, 17, 15, 15, 13, 17, 13, 19, 17, 12, 23, 22, 17, 20, 16, 26, 26, 19, 19, 14, 17, 21, 25, 23, 19, 17, 11, 23, 20, 16, 16, 20, 23, 19, 14, 26, 16, 16, 23, 18, 10, 16, 16, 17, 19, 12, 25, 16, 11, 23, 23, 16, 12, 13, 23, 25, 19, 23, 19, 19, 25, 18, 13, 15, 16, 23, 26, 19, 23, 17, 20, 25, 19, 28, 24, 11, 15, 13, 16, 12, 10, 21, 23, 21, 13, 25, 21, 17, 11, 19, 20, 21, 15, 14, 11, 19, 11, 21, 22, 11, 20, 22, 13, 11, 16, 11, 20, 12, 11, 16, 16, 13, 15, 20, 12, 12, 22, 15, 12, 14, 12, 20, 20, 20, 14, 26, 24, 22, 22, 19, 23, 22, 11, 13, 17, 24, 12, 21, 22, 22, 12, 20, 13, 22, 28, 11, 14, 22, 22, 13, 12, 21, 16], 'attr_dim': 0, 'dataset_info': '==== Dataset Information ====\n== General Information == \nNumber of graphs: 188\nNumber of classes: 2\nClass distribution: \n0:63 1:125 \n\n== Node information== \nAverage number of nodes: 18\nAverage number of edges (undirected): 20\nMax number of nodes: 28\nNumber of distinct node labels: 7\nAverage number of distinct node labels: 3\nNode labels distribution: \n0:2395 1:345 2:593 3:12 4:1 5:23 6:2 \n'}
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]


config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 50, 'learning_rate': 0.0001, 'seed': 1800, 'k_fold': 5, 'model': 'GCN', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'name': 'MUTAG', 'num_class': 2, 'label_dict': {'0': 0, '1': 1}, 'have_node_labels': True, 'have_node_attributions': False, 'node_dict': {'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, 'UNKNOWN': 7}, 'feat_dim': 8, 'edge_feat_dim': 0, 'max_num_nodes': 28, 'avg_num_nodes': 18, 'graph_sizes_list': [17, 13, 13, 19, 11, 28, 16, 20, 12, 17, 17, 20, 22, 13, 19, 22, 11, 17, 13, 18, 18, 17, 23, 27, 17, 13, 23, 17, 23, 23, 22, 24, 23, 13, 17, 14, 17, 15, 15, 13, 17, 13, 19, 17, 12, 23, 22, 17, 20, 16, 26, 26, 19, 19, 14, 17, 21, 25, 23, 19, 17, 11, 23, 20, 16, 16, 20, 23, 19, 14, 26, 16, 16, 23, 18, 10, 16, 16, 17, 19, 12, 25, 16, 11, 23, 23, 16, 12, 13, 23, 25, 19, 23, 19, 19, 25, 18, 13, 15, 16, 23, 26, 19, 23, 17, 20, 25, 19, 28, 24, 11, 15, 13, 16, 12, 10, 21, 23, 21, 13, 25, 21, 17, 11, 19, 20, 21, 15, 14, 11, 19, 11, 21, 22, 11, 20, 22, 13, 11, 16, 11, 20, 12, 11, 16, 16, 13, 15, 20, 12, 12, 22, 15, 12, 14, 12, 20, 20, 20, 14, 26, 24, 22, 22, 19, 23, 22, 11, 13, 17, 24, 12, 21, 22, 22, 12, 20, 13, 22, 28, 11, 14, 22, 22, 13, 12, 21, 16], 'attr_dim': 0, 'dataset_info': '==== Dataset Information ====\n== General Information == \nNumber of graphs: 188\nNumber of classes: 2\nClass distribution: \n0:63 1:125 \n\n== Node information== \nAverage number of nodes: 18\nAverage number of edges (undirected): 20\nMax number of nodes: 28\nNumber of distinct node labels: 7\nAverage number of distinct node labels: 3\nNode labels distribution: \n0:2395 1:345 2:593 3:12 4:1 5:23 6:2 \n'}}


Training a new model: GCN
Training model with dataset, testing using fold 0
[92maverage training of epoch 0: loss 0.67029 acc 0.59333 roc_auc 0.48860 prc_auc 0.66469[0m
[93maverage test of epoch 0: loss 0.62308 acc 0.65789 roc_auc 0.79385 prc_auc 0.89107[0m
[92maverage training of epoch 1: loss 0.63834 acc 0.67333 roc_auc 0.56460 prc_auc 0.70242[0m
[93maverage test of epoch 1: loss 0.61396 acc 0.65789 roc_auc 0.78462 prc_auc 0.88845[0m
[92maverage training of epoch 2: loss 0.64359 acc 0.66000 roc_auc 0.53920 prc_auc 0.68955[0m
[93maverage test of epoch 2: loss 0.61151 acc 0.65789 roc_auc 0.77538 prc_auc 0.88855[0m
[92maverage training of epoch 3: loss 0.64094 acc 0.66667 roc_auc 0.55180 prc_auc 0.67905[0m
[93maverage test of epoch 3: loss 0.60083 acc 0.65789 roc_auc 0.77538 prc_auc 0.88855[0m
[92maverage training of epoch 4: loss 0.63195 acc 0.68667 roc_auc 0.56900 prc_auc 0.69747[0m
[93maverage test of epoch 4: loss 0.60155 acc 0.65789 roc_auc 0.77538 prc_auc 0.88855[0m
[92maverage training of epoch 5: loss 0.61627 acc 0.66667 roc_auc 0.62320 prc_auc 0.73485[0m
[93maverage test of epoch 5: loss 0.58853 acc 0.65789 roc_auc 0.77846 prc_auc 0.89089[0m
[92maverage training of epoch 6: loss 0.61042 acc 0.66667 roc_auc 0.64340 prc_auc 0.78720[0m
[93maverage test of epoch 6: loss 0.58742 acc 0.65789 roc_auc 0.78462 prc_auc 0.89248[0m
[92maverage training of epoch 7: loss 0.61488 acc 0.68667 roc_auc 0.61860 prc_auc 0.76780[0m
[93maverage test of epoch 7: loss 0.58860 acc 0.65789 roc_auc 0.78462 prc_auc 0.89248[0m
[92maverage training of epoch 8: loss 0.59589 acc 0.69333 roc_auc 0.66800 prc_auc 0.79966[0m
[93maverage test of epoch 8: loss 0.57979 acc 0.68421 roc_auc 0.78769 prc_auc 0.89335[0m
[92maverage training of epoch 9: loss 0.60243 acc 0.70000 roc_auc 0.64760 prc_auc 0.77726[0m
[93maverage test of epoch 9: loss 0.57471 acc 0.68421 roc_auc 0.79385 prc_auc 0.89531[0m
[92maverage training of epoch 10: loss 0.59148 acc 0.70667 roc_auc 0.67100 prc_auc 0.77578[0m
[93maverage test of epoch 10: loss 0.57191 acc 0.68421 roc_auc 0.80308 prc_auc 0.89789[0m
[92maverage training of epoch 11: loss 0.58727 acc 0.70000 roc_auc 0.68660 prc_auc 0.78748[0m
[93maverage test of epoch 11: loss 0.57074 acc 0.68421 roc_auc 0.80308 prc_auc 0.89789[0m
[92maverage training of epoch 12: loss 0.58607 acc 0.73333 roc_auc 0.68360 prc_auc 0.80751[0m
[93maverage test of epoch 12: loss 0.57301 acc 0.68421 roc_auc 0.80308 prc_auc 0.89789[0m
[92maverage training of epoch 13: loss 0.59122 acc 0.73333 roc_auc 0.67780 prc_auc 0.77196[0m
[93maverage test of epoch 13: loss 0.56722 acc 0.68421 roc_auc 0.81538 prc_auc 0.90260[0m
[92maverage training of epoch 14: loss 0.59144 acc 0.68667 roc_auc 0.67120 prc_auc 0.81784[0m
[93maverage test of epoch 14: loss 0.56150 acc 0.71053 roc_auc 0.82154 prc_auc 0.90484[0m
[92maverage training of epoch 15: loss 0.58440 acc 0.72000 roc_auc 0.67680 prc_auc 0.79085[0m
[93maverage test of epoch 15: loss 0.55635 acc 0.71053 roc_auc 0.82154 prc_auc 0.90484[0m
[92maverage training of epoch 16: loss 0.58788 acc 0.70667 roc_auc 0.68000 prc_auc 0.80722[0m
[93maverage test of epoch 16: loss 0.55759 acc 0.71053 roc_auc 0.82769 prc_auc 0.90661[0m
[92maverage training of epoch 17: loss 0.57690 acc 0.74000 roc_auc 0.69320 prc_auc 0.80117[0m
[93maverage test of epoch 17: loss 0.55330 acc 0.73684 roc_auc 0.84308 prc_auc 0.91549[0m
[92maverage training of epoch 18: loss 0.57076 acc 0.73333 roc_auc 0.70940 prc_auc 0.81453[0m
[93maverage test of epoch 18: loss 0.54666 acc 0.73684 roc_auc 0.83692 prc_auc 0.91271[0m
[92maverage training of epoch 19: loss 0.56711 acc 0.71333 roc_auc 0.70340 prc_auc 0.81552[0m
[93maverage test of epoch 19: loss 0.54392 acc 0.71053 roc_auc 0.83692 prc_auc 0.91271[0m
[92maverage training of epoch 20: loss 0.57019 acc 0.70667 roc_auc 0.70140 prc_auc 0.83368[0m
[93maverage test of epoch 20: loss 0.55240 acc 0.73684 roc_auc 0.83385 prc_auc 0.90826[0m
[92maverage training of epoch 21: loss 0.56753 acc 0.70667 roc_auc 0.70840 prc_auc 0.81653[0m
[93maverage test of epoch 21: loss 0.53705 acc 0.71053 roc_auc 0.83385 prc_auc 0.90826[0m
[92maverage training of epoch 22: loss 0.56451 acc 0.70667 roc_auc 0.71140 prc_auc 0.83711[0m
[93maverage test of epoch 22: loss 0.53632 acc 0.71053 roc_auc 0.82769 prc_auc 0.89756[0m
[92maverage training of epoch 23: loss 0.55639 acc 0.70000 roc_auc 0.72520 prc_auc 0.84423[0m
[93maverage test of epoch 23: loss 0.54051 acc 0.71053 roc_auc 0.82769 prc_auc 0.89756[0m
[92maverage training of epoch 24: loss 0.56345 acc 0.70667 roc_auc 0.71560 prc_auc 0.82157[0m
[93maverage test of epoch 24: loss 0.53199 acc 0.71053 roc_auc 0.82769 prc_auc 0.89756[0m
[92maverage training of epoch 25: loss 0.55174 acc 0.72667 roc_auc 0.72620 prc_auc 0.82702[0m
[93maverage test of epoch 25: loss 0.54107 acc 0.71053 roc_auc 0.82769 prc_auc 0.89756[0m
[92maverage training of epoch 26: loss 0.56290 acc 0.70667 roc_auc 0.71560 prc_auc 0.82371[0m
[93maverage test of epoch 26: loss 0.53364 acc 0.71053 roc_auc 0.82769 prc_auc 0.89758[0m
[92maverage training of epoch 27: loss 0.56216 acc 0.71333 roc_auc 0.72000 prc_auc 0.83404[0m
[93maverage test of epoch 27: loss 0.52639 acc 0.71053 roc_auc 0.83077 prc_auc 0.89859[0m
[92maverage training of epoch 28: loss 0.56764 acc 0.70667 roc_auc 0.71300 prc_auc 0.83105[0m
[93maverage test of epoch 28: loss 0.52810 acc 0.71053 roc_auc 0.83077 prc_auc 0.89859[0m
[92maverage training of epoch 29: loss 0.56317 acc 0.73333 roc_auc 0.71040 prc_auc 0.81670[0m
[93maverage test of epoch 29: loss 0.52017 acc 0.71053 roc_auc 0.83077 prc_auc 0.89861[0m
[92maverage training of epoch 30: loss 0.54220 acc 0.72667 roc_auc 0.74120 prc_auc 0.82888[0m
[93maverage test of epoch 30: loss 0.51424 acc 0.71053 roc_auc 0.83077 prc_auc 0.89861[0m
[92maverage training of epoch 31: loss 0.53829 acc 0.75333 roc_auc 0.74060 prc_auc 0.84460[0m
[93maverage test of epoch 31: loss 0.52413 acc 0.71053 roc_auc 0.83077 prc_auc 0.89861[0m
[92maverage training of epoch 32: loss 0.54338 acc 0.72667 roc_auc 0.75160 prc_auc 0.85134[0m
[93maverage test of epoch 32: loss 0.52868 acc 0.71053 roc_auc 0.83077 prc_auc 0.89861[0m
[92maverage training of epoch 33: loss 0.56496 acc 0.72000 roc_auc 0.70820 prc_auc 0.78668[0m
[93maverage test of epoch 33: loss 0.51965 acc 0.71053 roc_auc 0.83077 prc_auc 0.89861[0m
[92maverage training of epoch 34: loss 0.55941 acc 0.70667 roc_auc 0.73000 prc_auc 0.83362[0m
[93maverage test of epoch 34: loss 0.51669 acc 0.71053 roc_auc 0.83077 prc_auc 0.89861[0m
[92maverage training of epoch 35: loss 0.54463 acc 0.72000 roc_auc 0.74060 prc_auc 0.84680[0m
[93maverage test of epoch 35: loss 0.51276 acc 0.71053 roc_auc 0.83077 prc_auc 0.89861[0m
[92maverage training of epoch 36: loss 0.54879 acc 0.74667 roc_auc 0.72340 prc_auc 0.82875[0m
[93maverage test of epoch 36: loss 0.51356 acc 0.71053 roc_auc 0.83077 prc_auc 0.89861[0m
[92maverage training of epoch 37: loss 0.55766 acc 0.70000 roc_auc 0.71660 prc_auc 0.81307[0m
[93maverage test of epoch 37: loss 0.51268 acc 0.71053 roc_auc 0.83077 prc_auc 0.89861[0m
[92maverage training of epoch 38: loss 0.54181 acc 0.73333 roc_auc 0.75080 prc_auc 0.82921[0m
[93maverage test of epoch 38: loss 0.51675 acc 0.71053 roc_auc 0.83077 prc_auc 0.89861[0m
[92maverage training of epoch 39: loss 0.54342 acc 0.72000 roc_auc 0.74700 prc_auc 0.84433[0m
[93maverage test of epoch 39: loss 0.50762 acc 0.71053 roc_auc 0.83077 prc_auc 0.89768[0m
[92maverage training of epoch 40: loss 0.54533 acc 0.70667 roc_auc 0.74080 prc_auc 0.85396[0m
[93maverage test of epoch 40: loss 0.50739 acc 0.71053 roc_auc 0.83077 prc_auc 0.89768[0m
[92maverage training of epoch 41: loss 0.53878 acc 0.75333 roc_auc 0.74080 prc_auc 0.83213[0m
[93maverage test of epoch 41: loss 0.50813 acc 0.71053 roc_auc 0.83077 prc_auc 0.89768[0m
[92maverage training of epoch 42: loss 0.54660 acc 0.74000 roc_auc 0.73460 prc_auc 0.82751[0m
[93maverage test of epoch 42: loss 0.50617 acc 0.71053 roc_auc 0.83077 prc_auc 0.89768[0m
[92maverage training of epoch 43: loss 0.54355 acc 0.73333 roc_auc 0.73860 prc_auc 0.83757[0m
[93maverage test of epoch 43: loss 0.50170 acc 0.73684 roc_auc 0.83692 prc_auc 0.90139[0m
[92maverage training of epoch 44: loss 0.55080 acc 0.71333 roc_auc 0.72340 prc_auc 0.81895[0m
[93maverage test of epoch 44: loss 0.51268 acc 0.71053 roc_auc 0.84000 prc_auc 0.90245[0m
[92maverage training of epoch 45: loss 0.53935 acc 0.72000 roc_auc 0.74060 prc_auc 0.83016[0m
[93maverage test of epoch 45: loss 0.50623 acc 0.71053 roc_auc 0.84308 prc_auc 0.90358[0m
[92maverage training of epoch 46: loss 0.54510 acc 0.74000 roc_auc 0.73580 prc_auc 0.82513[0m
[93maverage test of epoch 46: loss 0.50446 acc 0.71053 roc_auc 0.84308 prc_auc 0.90358[0m
[92maverage training of epoch 47: loss 0.52492 acc 0.76667 roc_auc 0.75720 prc_auc 0.83870[0m
[93maverage test of epoch 47: loss 0.50206 acc 0.73684 roc_auc 0.84308 prc_auc 0.90358[0m
[92maverage training of epoch 48: loss 0.53965 acc 0.72667 roc_auc 0.74160 prc_auc 0.84592[0m
[93maverage test of epoch 48: loss 0.50213 acc 0.73684 roc_auc 0.84308 prc_auc 0.90358[0m
[92maverage training of epoch 49: loss 0.54172 acc 0.76667 roc_auc 0.74960 prc_auc 0.83979[0m
[93maverage test of epoch 49: loss 0.50327 acc 0.73684 roc_auc 0.84308 prc_auc 0.90358[0m
Training model with dataset, testing using fold 1
[92maverage training of epoch 0: loss 0.66596 acc 0.63333 roc_auc 0.52940 prc_auc 0.68739[0m
[93maverage test of epoch 0: loss 0.61610 acc 0.65789 roc_auc 0.82462 prc_auc 0.92470[0m
[92maverage training of epoch 1: loss 0.66314 acc 0.63333 roc_auc 0.47180 prc_auc 0.66824[0m
[93maverage test of epoch 1: loss 0.60079 acc 0.65789 roc_auc 0.83385 prc_auc 0.92830[0m
[92maverage training of epoch 2: loss 0.63926 acc 0.66000 roc_auc 0.54200 prc_auc 0.71849[0m
[93maverage test of epoch 2: loss 0.59227 acc 0.65789 roc_auc 0.83385 prc_auc 0.92854[0m
[92maverage training of epoch 3: loss 0.63019 acc 0.67333 roc_auc 0.58280 prc_auc 0.71142[0m
[93maverage test of epoch 3: loss 0.58799 acc 0.65789 roc_auc 0.84615 prc_auc 0.93282[0m
[92maverage training of epoch 4: loss 0.64661 acc 0.68000 roc_auc 0.53600 prc_auc 0.66151[0m
[93maverage test of epoch 4: loss 0.57837 acc 0.65789 roc_auc 0.84615 prc_auc 0.93291[0m
[92maverage training of epoch 5: loss 0.62553 acc 0.68667 roc_auc 0.58520 prc_auc 0.71825[0m
[93maverage test of epoch 5: loss 0.57261 acc 0.65789 roc_auc 0.84615 prc_auc 0.93282[0m
[92maverage training of epoch 6: loss 0.62128 acc 0.66667 roc_auc 0.60160 prc_auc 0.72731[0m
[93maverage test of epoch 6: loss 0.56487 acc 0.65789 roc_auc 0.84000 prc_auc 0.93100[0m
[92maverage training of epoch 7: loss 0.60395 acc 0.68667 roc_auc 0.64060 prc_auc 0.74057[0m
[93maverage test of epoch 7: loss 0.57052 acc 0.65789 roc_auc 0.84000 prc_auc 0.93100[0m
[92maverage training of epoch 8: loss 0.61443 acc 0.70000 roc_auc 0.61360 prc_auc 0.73958[0m
[93maverage test of epoch 8: loss 0.56355 acc 0.65789 roc_auc 0.84000 prc_auc 0.93241[0m
[92maverage training of epoch 9: loss 0.62936 acc 0.66667 roc_auc 0.59800 prc_auc 0.71556[0m
[93maverage test of epoch 9: loss 0.55270 acc 0.65789 roc_auc 0.84615 prc_auc 0.93401[0m
[92maverage training of epoch 10: loss 0.61719 acc 0.68000 roc_auc 0.62640 prc_auc 0.73936[0m
[93maverage test of epoch 10: loss 0.55246 acc 0.65789 roc_auc 0.84923 prc_auc 0.93487[0m
[92maverage training of epoch 11: loss 0.62407 acc 0.65333 roc_auc 0.61440 prc_auc 0.74446[0m
[93maverage test of epoch 11: loss 0.54707 acc 0.68421 roc_auc 0.84923 prc_auc 0.93505[0m
[92maverage training of epoch 12: loss 0.60111 acc 0.70000 roc_auc 0.65280 prc_auc 0.78712[0m
[93maverage test of epoch 12: loss 0.54398 acc 0.68421 roc_auc 0.84923 prc_auc 0.93505[0m
[92maverage training of epoch 13: loss 0.58981 acc 0.71333 roc_auc 0.68520 prc_auc 0.77038[0m
[93maverage test of epoch 13: loss 0.54031 acc 0.68421 roc_auc 0.86154 prc_auc 0.94115[0m
[92maverage training of epoch 14: loss 0.59530 acc 0.72667 roc_auc 0.66860 prc_auc 0.76623[0m
[93maverage test of epoch 14: loss 0.53778 acc 0.68421 roc_auc 0.86154 prc_auc 0.94115[0m
[92maverage training of epoch 15: loss 0.57991 acc 0.73333 roc_auc 0.67480 prc_auc 0.80304[0m
[93maverage test of epoch 15: loss 0.54247 acc 0.68421 roc_auc 0.87077 prc_auc 0.94396[0m
[92maverage training of epoch 16: loss 0.61404 acc 0.68667 roc_auc 0.63240 prc_auc 0.75209[0m
[93maverage test of epoch 16: loss 0.52850 acc 0.68421 roc_auc 0.87077 prc_auc 0.94396[0m
[92maverage training of epoch 17: loss 0.60347 acc 0.70000 roc_auc 0.65460 prc_auc 0.76502[0m
[93maverage test of epoch 17: loss 0.52827 acc 0.68421 roc_auc 0.87692 prc_auc 0.94576[0m
[92maverage training of epoch 18: loss 0.61078 acc 0.69333 roc_auc 0.63360 prc_auc 0.77082[0m
[93maverage test of epoch 18: loss 0.53426 acc 0.68421 roc_auc 0.87692 prc_auc 0.94576[0m
[92maverage training of epoch 19: loss 0.58794 acc 0.69333 roc_auc 0.68380 prc_auc 0.80046[0m
[93maverage test of epoch 19: loss 0.52702 acc 0.68421 roc_auc 0.87692 prc_auc 0.94576[0m
[92maverage training of epoch 20: loss 0.59307 acc 0.70000 roc_auc 0.68000 prc_auc 0.79523[0m
[93maverage test of epoch 20: loss 0.52527 acc 0.68421 roc_auc 0.88923 prc_auc 0.94981[0m
[92maverage training of epoch 21: loss 0.57624 acc 0.69333 roc_auc 0.70060 prc_auc 0.81188[0m
[93maverage test of epoch 21: loss 0.52588 acc 0.68421 roc_auc 0.88923 prc_auc 0.94981[0m
[92maverage training of epoch 22: loss 0.58212 acc 0.71333 roc_auc 0.68160 prc_auc 0.79380[0m
[93maverage test of epoch 22: loss 0.53534 acc 0.68421 roc_auc 0.88923 prc_auc 0.94981[0m
[92maverage training of epoch 23: loss 0.59044 acc 0.67333 roc_auc 0.67680 prc_auc 0.78612[0m
[93maverage test of epoch 23: loss 0.52377 acc 0.68421 roc_auc 0.88923 prc_auc 0.94981[0m
[92maverage training of epoch 24: loss 0.58045 acc 0.71333 roc_auc 0.68780 prc_auc 0.80897[0m
[93maverage test of epoch 24: loss 0.51982 acc 0.68421 roc_auc 0.88923 prc_auc 0.94981[0m
[92maverage training of epoch 25: loss 0.57561 acc 0.70000 roc_auc 0.69440 prc_auc 0.80623[0m
[93maverage test of epoch 25: loss 0.52076 acc 0.68421 roc_auc 0.88615 prc_auc 0.94887[0m
[92maverage training of epoch 26: loss 0.58142 acc 0.72000 roc_auc 0.68560 prc_auc 0.79462[0m
[93maverage test of epoch 26: loss 0.51237 acc 0.68421 roc_auc 0.88615 prc_auc 0.94887[0m
[92maverage training of epoch 27: loss 0.56422 acc 0.72667 roc_auc 0.71420 prc_auc 0.79816[0m
[93maverage test of epoch 27: loss 0.50986 acc 0.73684 roc_auc 0.88615 prc_auc 0.94887[0m
[92maverage training of epoch 28: loss 0.56689 acc 0.69333 roc_auc 0.72060 prc_auc 0.80329[0m
[93maverage test of epoch 28: loss 0.51989 acc 0.68421 roc_auc 0.88615 prc_auc 0.94887[0m
[92maverage training of epoch 29: loss 0.57145 acc 0.73333 roc_auc 0.69780 prc_auc 0.78302[0m
[93maverage test of epoch 29: loss 0.51841 acc 0.71053 roc_auc 0.88615 prc_auc 0.94887[0m
[92maverage training of epoch 30: loss 0.56296 acc 0.72667 roc_auc 0.71080 prc_auc 0.80025[0m
[93maverage test of epoch 30: loss 0.52335 acc 0.71053 roc_auc 0.88615 prc_auc 0.94887[0m
[92maverage training of epoch 31: loss 0.56852 acc 0.71333 roc_auc 0.69920 prc_auc 0.78670[0m
[93maverage test of epoch 31: loss 0.50485 acc 0.73684 roc_auc 0.88615 prc_auc 0.94887[0m
[92maverage training of epoch 32: loss 0.55700 acc 0.74000 roc_auc 0.72480 prc_auc 0.82726[0m
[93maverage test of epoch 32: loss 0.51894 acc 0.71053 roc_auc 0.88923 prc_auc 0.95032[0m
[92maverage training of epoch 33: loss 0.58042 acc 0.72000 roc_auc 0.68340 prc_auc 0.75810[0m
[93maverage test of epoch 33: loss 0.50628 acc 0.73684 roc_auc 0.88923 prc_auc 0.95032[0m
[92maverage training of epoch 34: loss 0.55742 acc 0.74667 roc_auc 0.73040 prc_auc 0.82249[0m
[93maverage test of epoch 34: loss 0.50501 acc 0.76316 roc_auc 0.88923 prc_auc 0.95032[0m
[92maverage training of epoch 35: loss 0.56170 acc 0.74000 roc_auc 0.72060 prc_auc 0.80967[0m
[93maverage test of epoch 35: loss 0.50417 acc 0.76316 roc_auc 0.89231 prc_auc 0.95046[0m
[92maverage training of epoch 36: loss 0.57334 acc 0.74000 roc_auc 0.68040 prc_auc 0.78441[0m
[93maverage test of epoch 36: loss 0.50300 acc 0.76316 roc_auc 0.89231 prc_auc 0.95046[0m
[92maverage training of epoch 37: loss 0.56503 acc 0.74667 roc_auc 0.69760 prc_auc 0.78554[0m
[93maverage test of epoch 37: loss 0.49739 acc 0.76316 roc_auc 0.89231 prc_auc 0.95023[0m
[92maverage training of epoch 38: loss 0.55239 acc 0.75333 roc_auc 0.71720 prc_auc 0.81988[0m
[93maverage test of epoch 38: loss 0.50484 acc 0.76316 roc_auc 0.89231 prc_auc 0.95023[0m
[92maverage training of epoch 39: loss 0.55701 acc 0.73333 roc_auc 0.72220 prc_auc 0.82006[0m
[93maverage test of epoch 39: loss 0.49541 acc 0.76316 roc_auc 0.89231 prc_auc 0.95023[0m
[92maverage training of epoch 40: loss 0.54896 acc 0.74000 roc_auc 0.72220 prc_auc 0.82077[0m
[93maverage test of epoch 40: loss 0.49045 acc 0.76316 roc_auc 0.89231 prc_auc 0.95023[0m
[92maverage training of epoch 41: loss 0.56286 acc 0.71333 roc_auc 0.72100 prc_auc 0.79429[0m
[93maverage test of epoch 41: loss 0.50826 acc 0.76316 roc_auc 0.89231 prc_auc 0.95023[0m
[92maverage training of epoch 42: loss 0.54907 acc 0.71333 roc_auc 0.74160 prc_auc 0.83878[0m
[93maverage test of epoch 42: loss 0.50448 acc 0.76316 roc_auc 0.89231 prc_auc 0.95023[0m
[92maverage training of epoch 43: loss 0.56013 acc 0.74000 roc_auc 0.71340 prc_auc 0.80294[0m
[93maverage test of epoch 43: loss 0.49358 acc 0.76316 roc_auc 0.89231 prc_auc 0.95023[0m
[92maverage training of epoch 44: loss 0.54875 acc 0.74667 roc_auc 0.73240 prc_auc 0.80610[0m
[93maverage test of epoch 44: loss 0.49028 acc 0.76316 roc_auc 0.89538 prc_auc 0.95204[0m
[92maverage training of epoch 45: loss 0.54885 acc 0.74000 roc_auc 0.72940 prc_auc 0.79333[0m
[93maverage test of epoch 45: loss 0.49691 acc 0.76316 roc_auc 0.89538 prc_auc 0.95204[0m
[92maverage training of epoch 46: loss 0.56934 acc 0.74667 roc_auc 0.68740 prc_auc 0.77335[0m
[93maverage test of epoch 46: loss 0.49822 acc 0.76316 roc_auc 0.89538 prc_auc 0.95204[0m
[92maverage training of epoch 47: loss 0.54593 acc 0.76000 roc_auc 0.71160 prc_auc 0.78928[0m
[93maverage test of epoch 47: loss 0.49753 acc 0.76316 roc_auc 0.89538 prc_auc 0.95204[0m
[92maverage training of epoch 48: loss 0.54258 acc 0.74667 roc_auc 0.73640 prc_auc 0.80821[0m
[93maverage test of epoch 48: loss 0.49924 acc 0.76316 roc_auc 0.89231 prc_auc 0.94994[0m
[92maverage training of epoch 49: loss 0.53119 acc 0.73333 roc_auc 0.75660 prc_auc 0.85179[0m
[93maverage test of epoch 49: loss 0.50075 acc 0.76316 roc_auc 0.89231 prc_auc 0.94994[0m
Training model with dataset, testing using fold 2
[92maverage training of epoch 0: loss 0.64353 acc 0.60667 roc_auc 0.57520 prc_auc 0.74081[0m
[93maverage test of epoch 0: loss 0.64166 acc 0.65789 roc_auc 0.69538 prc_auc 0.84172[0m
[92maverage training of epoch 1: loss 0.64534 acc 0.64667 roc_auc 0.54760 prc_auc 0.72119[0m
[93maverage test of epoch 1: loss 0.63903 acc 0.65789 roc_auc 0.68308 prc_auc 0.83762[0m
[92maverage training of epoch 2: loss 0.61559 acc 0.64667 roc_auc 0.62880 prc_auc 0.77461[0m
[93maverage test of epoch 2: loss 0.63412 acc 0.65789 roc_auc 0.66769 prc_auc 0.83121[0m
[92maverage training of epoch 3: loss 0.61490 acc 0.67333 roc_auc 0.62460 prc_auc 0.76382[0m
[93maverage test of epoch 3: loss 0.63813 acc 0.65789 roc_auc 0.67692 prc_auc 0.83370[0m
[92maverage training of epoch 4: loss 0.60929 acc 0.65333 roc_auc 0.64200 prc_auc 0.79239[0m
[93maverage test of epoch 4: loss 0.63842 acc 0.65789 roc_auc 0.67077 prc_auc 0.83211[0m
[92maverage training of epoch 5: loss 0.59307 acc 0.71333 roc_auc 0.66920 prc_auc 0.80163[0m
[93maverage test of epoch 5: loss 0.64991 acc 0.65789 roc_auc 0.67692 prc_auc 0.83370[0m
[92maverage training of epoch 6: loss 0.61082 acc 0.66000 roc_auc 0.63480 prc_auc 0.73628[0m
[93maverage test of epoch 6: loss 0.65657 acc 0.65789 roc_auc 0.68000 prc_auc 0.83459[0m
[92maverage training of epoch 7: loss 0.58558 acc 0.70000 roc_auc 0.68320 prc_auc 0.80287[0m
[93maverage test of epoch 7: loss 0.66764 acc 0.65789 roc_auc 0.68000 prc_auc 0.83459[0m
[92maverage training of epoch 8: loss 0.60501 acc 0.69333 roc_auc 0.64560 prc_auc 0.76335[0m
[93maverage test of epoch 8: loss 0.64675 acc 0.65789 roc_auc 0.69846 prc_auc 0.84281[0m
[92maverage training of epoch 9: loss 0.56811 acc 0.72000 roc_auc 0.71680 prc_auc 0.82525[0m
[93maverage test of epoch 9: loss 0.66778 acc 0.65789 roc_auc 0.69231 prc_auc 0.84020[0m
[92maverage training of epoch 10: loss 0.57223 acc 0.71333 roc_auc 0.71880 prc_auc 0.78982[0m
[93maverage test of epoch 10: loss 0.67631 acc 0.65789 roc_auc 0.70462 prc_auc 0.84425[0m
[92maverage training of epoch 11: loss 0.57912 acc 0.69333 roc_auc 0.69300 prc_auc 0.82560[0m
[93maverage test of epoch 11: loss 0.67564 acc 0.65789 roc_auc 0.71692 prc_auc 0.84736[0m
[92maverage training of epoch 12: loss 0.58038 acc 0.71333 roc_auc 0.69500 prc_auc 0.79055[0m
[93maverage test of epoch 12: loss 0.69401 acc 0.65789 roc_auc 0.72000 prc_auc 0.84623[0m
[92maverage training of epoch 13: loss 0.56979 acc 0.70667 roc_auc 0.71700 prc_auc 0.83787[0m
[93maverage test of epoch 13: loss 0.68743 acc 0.65789 roc_auc 0.72000 prc_auc 0.84623[0m
[92maverage training of epoch 14: loss 0.56332 acc 0.70000 roc_auc 0.72400 prc_auc 0.85610[0m
[93maverage test of epoch 14: loss 0.69113 acc 0.65789 roc_auc 0.72000 prc_auc 0.84623[0m
[92maverage training of epoch 15: loss 0.56556 acc 0.72667 roc_auc 0.71520 prc_auc 0.81578[0m
[93maverage test of epoch 15: loss 0.68109 acc 0.65789 roc_auc 0.71692 prc_auc 0.84382[0m
[92maverage training of epoch 16: loss 0.54097 acc 0.74000 roc_auc 0.75380 prc_auc 0.85666[0m
[93maverage test of epoch 16: loss 0.70155 acc 0.65789 roc_auc 0.71385 prc_auc 0.84298[0m
[92maverage training of epoch 17: loss 0.55264 acc 0.74667 roc_auc 0.74120 prc_auc 0.83351[0m
[93maverage test of epoch 17: loss 0.71823 acc 0.65789 roc_auc 0.70769 prc_auc 0.84143[0m
[92maverage training of epoch 18: loss 0.55124 acc 0.73333 roc_auc 0.73240 prc_auc 0.83332[0m
[93maverage test of epoch 18: loss 0.72013 acc 0.65789 roc_auc 0.71692 prc_auc 0.84693[0m
[92maverage training of epoch 19: loss 0.53856 acc 0.73333 roc_auc 0.75320 prc_auc 0.84693[0m
[93maverage test of epoch 19: loss 0.70989 acc 0.65789 roc_auc 0.71385 prc_auc 0.84546[0m
[92maverage training of epoch 20: loss 0.53058 acc 0.74000 roc_auc 0.74860 prc_auc 0.84308[0m
[93maverage test of epoch 20: loss 0.73780 acc 0.65789 roc_auc 0.71692 prc_auc 0.84548[0m
[92maverage training of epoch 21: loss 0.56534 acc 0.74000 roc_auc 0.72540 prc_auc 0.80186[0m
[93maverage test of epoch 21: loss 0.72675 acc 0.65789 roc_auc 0.72000 prc_auc 0.84644[0m
[92maverage training of epoch 22: loss 0.54817 acc 0.73333 roc_auc 0.73280 prc_auc 0.82192[0m
[93maverage test of epoch 22: loss 0.73057 acc 0.65789 roc_auc 0.72000 prc_auc 0.84644[0m
[92maverage training of epoch 23: loss 0.53972 acc 0.74667 roc_auc 0.74260 prc_auc 0.84799[0m
[93maverage test of epoch 23: loss 0.72314 acc 0.65789 roc_auc 0.72000 prc_auc 0.84644[0m
[92maverage training of epoch 24: loss 0.52478 acc 0.76000 roc_auc 0.76820 prc_auc 0.84574[0m
[93maverage test of epoch 24: loss 0.73868 acc 0.65789 roc_auc 0.71385 prc_auc 0.84490[0m
[92maverage training of epoch 25: loss 0.54330 acc 0.72667 roc_auc 0.74020 prc_auc 0.83287[0m
[93maverage test of epoch 25: loss 0.73377 acc 0.65789 roc_auc 0.71692 prc_auc 0.84565[0m
[92maverage training of epoch 26: loss 0.53574 acc 0.72000 roc_auc 0.75020 prc_auc 0.84092[0m
[93maverage test of epoch 26: loss 0.71757 acc 0.65789 roc_auc 0.71077 prc_auc 0.84355[0m
[92maverage training of epoch 27: loss 0.50409 acc 0.76000 roc_auc 0.79060 prc_auc 0.86979[0m
[93maverage test of epoch 27: loss 0.72875 acc 0.65789 roc_auc 0.71077 prc_auc 0.84355[0m
[92maverage training of epoch 28: loss 0.54233 acc 0.74000 roc_auc 0.74300 prc_auc 0.83769[0m
[93maverage test of epoch 28: loss 0.71998 acc 0.65789 roc_auc 0.71077 prc_auc 0.84355[0m
[92maverage training of epoch 29: loss 0.52610 acc 0.74667 roc_auc 0.76440 prc_auc 0.85849[0m
[93maverage test of epoch 29: loss 0.71668 acc 0.65789 roc_auc 0.71692 prc_auc 0.84553[0m
[92maverage training of epoch 30: loss 0.52490 acc 0.74000 roc_auc 0.76020 prc_auc 0.86011[0m
[93maverage test of epoch 30: loss 0.71968 acc 0.65789 roc_auc 0.71692 prc_auc 0.84553[0m
[92maverage training of epoch 31: loss 0.51611 acc 0.77333 roc_auc 0.77620 prc_auc 0.86316[0m
[93maverage test of epoch 31: loss 0.75651 acc 0.65789 roc_auc 0.72000 prc_auc 0.84646[0m
[92maverage training of epoch 32: loss 0.54153 acc 0.73333 roc_auc 0.73660 prc_auc 0.81310[0m
[93maverage test of epoch 32: loss 0.73684 acc 0.65789 roc_auc 0.72308 prc_auc 0.84737[0m
[92maverage training of epoch 33: loss 0.54077 acc 0.72667 roc_auc 0.75280 prc_auc 0.83382[0m
[93maverage test of epoch 33: loss 0.72275 acc 0.65789 roc_auc 0.72308 prc_auc 0.84737[0m
[92maverage training of epoch 34: loss 0.52215 acc 0.74667 roc_auc 0.76640 prc_auc 0.85192[0m
[93maverage test of epoch 34: loss 0.72115 acc 0.65789 roc_auc 0.72308 prc_auc 0.84737[0m
[92maverage training of epoch 35: loss 0.52483 acc 0.74000 roc_auc 0.76540 prc_auc 0.85400[0m
[93maverage test of epoch 35: loss 0.71375 acc 0.65789 roc_auc 0.73231 prc_auc 0.85034[0m
[92maverage training of epoch 36: loss 0.53607 acc 0.73333 roc_auc 0.75620 prc_auc 0.82089[0m
[93maverage test of epoch 36: loss 0.71282 acc 0.65789 roc_auc 0.73231 prc_auc 0.85034[0m
[92maverage training of epoch 37: loss 0.54617 acc 0.72000 roc_auc 0.73940 prc_auc 0.83975[0m
[93maverage test of epoch 37: loss 0.69760 acc 0.65789 roc_auc 0.73231 prc_auc 0.85034[0m
[92maverage training of epoch 38: loss 0.52204 acc 0.76000 roc_auc 0.76120 prc_auc 0.85598[0m
[93maverage test of epoch 38: loss 0.69823 acc 0.68421 roc_auc 0.73538 prc_auc 0.85168[0m
[92maverage training of epoch 39: loss 0.53113 acc 0.74000 roc_auc 0.75440 prc_auc 0.85181[0m
[93maverage test of epoch 39: loss 0.69455 acc 0.65789 roc_auc 0.73538 prc_auc 0.85168[0m
[92maverage training of epoch 40: loss 0.51602 acc 0.74000 roc_auc 0.77460 prc_auc 0.85934[0m
[93maverage test of epoch 40: loss 0.68100 acc 0.68421 roc_auc 0.73538 prc_auc 0.85168[0m
[92maverage training of epoch 41: loss 0.53564 acc 0.74667 roc_auc 0.75320 prc_auc 0.83184[0m
[93maverage test of epoch 41: loss 0.69073 acc 0.68421 roc_auc 0.73538 prc_auc 0.85168[0m
[92maverage training of epoch 42: loss 0.53133 acc 0.75333 roc_auc 0.75620 prc_auc 0.80920[0m
[93maverage test of epoch 42: loss 0.67960 acc 0.68421 roc_auc 0.73538 prc_auc 0.85168[0m
[92maverage training of epoch 43: loss 0.52073 acc 0.75333 roc_auc 0.76860 prc_auc 0.83809[0m
[93maverage test of epoch 43: loss 0.68966 acc 0.68421 roc_auc 0.73538 prc_auc 0.85168[0m
[92maverage training of epoch 44: loss 0.50095 acc 0.75333 roc_auc 0.78980 prc_auc 0.88026[0m
[93maverage test of epoch 44: loss 0.69785 acc 0.68421 roc_auc 0.73538 prc_auc 0.85168[0m
[92maverage training of epoch 45: loss 0.52620 acc 0.74000 roc_auc 0.75940 prc_auc 0.84025[0m
[93maverage test of epoch 45: loss 0.68861 acc 0.68421 roc_auc 0.73538 prc_auc 0.85168[0m
[92maverage training of epoch 46: loss 0.52267 acc 0.76000 roc_auc 0.76420 prc_auc 0.85886[0m
[93maverage test of epoch 46: loss 0.69034 acc 0.68421 roc_auc 0.73538 prc_auc 0.85168[0m
[92maverage training of epoch 47: loss 0.51170 acc 0.74667 roc_auc 0.77520 prc_auc 0.85468[0m
[93maverage test of epoch 47: loss 0.70269 acc 0.68421 roc_auc 0.73538 prc_auc 0.85168[0m
[92maverage training of epoch 48: loss 0.53627 acc 0.72667 roc_auc 0.75360 prc_auc 0.85907[0m
[93maverage test of epoch 48: loss 0.68233 acc 0.68421 roc_auc 0.73538 prc_auc 0.85168[0m
[92maverage training of epoch 49: loss 0.50434 acc 0.75333 roc_auc 0.78320 prc_auc 0.86701[0m
[93maverage test of epoch 49: loss 0.68901 acc 0.68421 roc_auc 0.73538 prc_auc 0.85168[0m
Training model with dataset, testing using fold 3
[92maverage training of epoch 0: loss 0.67281 acc 0.60265 roc_auc 0.50255 prc_auc 0.67894[0m
[93maverage test of epoch 0: loss 0.62485 acc 0.67568 roc_auc 0.65000 prc_auc 0.80317[0m
[92maverage training of epoch 1: loss 0.65404 acc 0.66887 roc_auc 0.51529 prc_auc 0.68403[0m
[93maverage test of epoch 1: loss 0.61425 acc 0.67568 roc_auc 0.67667 prc_auc 0.81356[0m
[92maverage training of epoch 2: loss 0.65619 acc 0.64901 roc_auc 0.53451 prc_auc 0.68423[0m
[93maverage test of epoch 2: loss 0.60873 acc 0.67568 roc_auc 0.69667 prc_auc 0.82901[0m
[92maverage training of epoch 3: loss 0.62692 acc 0.65563 roc_auc 0.60275 prc_auc 0.74940[0m
[93maverage test of epoch 3: loss 0.60526 acc 0.67568 roc_auc 0.68667 prc_auc 0.81781[0m
[92maverage training of epoch 4: loss 0.61413 acc 0.64901 roc_auc 0.63627 prc_auc 0.75975[0m
[93maverage test of epoch 4: loss 0.60037 acc 0.67568 roc_auc 0.69667 prc_auc 0.82519[0m
[92maverage training of epoch 5: loss 0.60883 acc 0.70861 roc_auc 0.63804 prc_auc 0.76584[0m
[93maverage test of epoch 5: loss 0.60474 acc 0.67568 roc_auc 0.69000 prc_auc 0.82275[0m
[92maverage training of epoch 6: loss 0.59729 acc 0.71523 roc_auc 0.66529 prc_auc 0.77155[0m
[93maverage test of epoch 6: loss 0.60560 acc 0.67568 roc_auc 0.68333 prc_auc 0.81628[0m
[92maverage training of epoch 7: loss 0.62123 acc 0.68212 roc_auc 0.61686 prc_auc 0.74660[0m
[93maverage test of epoch 7: loss 0.60096 acc 0.67568 roc_auc 0.67333 prc_auc 0.81236[0m
[92maverage training of epoch 8: loss 0.60139 acc 0.70199 roc_auc 0.64961 prc_auc 0.79310[0m
[93maverage test of epoch 8: loss 0.60299 acc 0.67568 roc_auc 0.66667 prc_auc 0.80954[0m
[92maverage training of epoch 9: loss 0.58150 acc 0.72848 roc_auc 0.69412 prc_auc 0.78051[0m
[93maverage test of epoch 9: loss 0.61116 acc 0.67568 roc_auc 0.65000 prc_auc 0.79917[0m
[92maverage training of epoch 10: loss 0.57356 acc 0.70199 roc_auc 0.71059 prc_auc 0.81306[0m
[93maverage test of epoch 10: loss 0.62534 acc 0.67568 roc_auc 0.63667 prc_auc 0.78960[0m
[92maverage training of epoch 11: loss 0.57461 acc 0.73510 roc_auc 0.70725 prc_auc 0.79827[0m
[93maverage test of epoch 11: loss 0.61303 acc 0.67568 roc_auc 0.63667 prc_auc 0.79004[0m
[92maverage training of epoch 12: loss 0.57066 acc 0.70199 roc_auc 0.71706 prc_auc 0.81313[0m
[93maverage test of epoch 12: loss 0.62054 acc 0.67568 roc_auc 0.63667 prc_auc 0.79004[0m
[92maverage training of epoch 13: loss 0.57511 acc 0.71523 roc_auc 0.70373 prc_auc 0.81610[0m
[93maverage test of epoch 13: loss 0.61728 acc 0.67568 roc_auc 0.63333 prc_auc 0.78821[0m
[92maverage training of epoch 14: loss 0.56693 acc 0.73510 roc_auc 0.71490 prc_auc 0.80605[0m
[93maverage test of epoch 14: loss 0.62719 acc 0.67568 roc_auc 0.63333 prc_auc 0.78821[0m
[92maverage training of epoch 15: loss 0.53803 acc 0.75497 roc_auc 0.75765 prc_auc 0.85081[0m
[93maverage test of epoch 15: loss 0.63412 acc 0.67568 roc_auc 0.63000 prc_auc 0.78746[0m
[92maverage training of epoch 16: loss 0.56347 acc 0.72185 roc_auc 0.71686 prc_auc 0.83581[0m
[93maverage test of epoch 16: loss 0.63789 acc 0.67568 roc_auc 0.63000 prc_auc 0.78746[0m
[92maverage training of epoch 17: loss 0.54038 acc 0.74172 roc_auc 0.75314 prc_auc 0.83879[0m
[93maverage test of epoch 17: loss 0.64936 acc 0.67568 roc_auc 0.63000 prc_auc 0.78746[0m
[92maverage training of epoch 18: loss 0.49442 acc 0.76159 roc_auc 0.79961 prc_auc 0.87555[0m
[93maverage test of epoch 18: loss 0.65612 acc 0.67568 roc_auc 0.63000 prc_auc 0.78746[0m
[92maverage training of epoch 19: loss 0.53824 acc 0.73510 roc_auc 0.75804 prc_auc 0.84677[0m
[93maverage test of epoch 19: loss 0.65799 acc 0.67568 roc_auc 0.63000 prc_auc 0.78746[0m
[92maverage training of epoch 20: loss 0.54593 acc 0.73510 roc_auc 0.74157 prc_auc 0.83055[0m
[93maverage test of epoch 20: loss 0.66200 acc 0.67568 roc_auc 0.63667 prc_auc 0.78965[0m
[92maverage training of epoch 21: loss 0.53881 acc 0.74834 roc_auc 0.73863 prc_auc 0.81841[0m
[93maverage test of epoch 21: loss 0.64865 acc 0.67568 roc_auc 0.64000 prc_auc 0.79099[0m
[92maverage training of epoch 22: loss 0.53647 acc 0.73510 roc_auc 0.76020 prc_auc 0.86107[0m
[93maverage test of epoch 22: loss 0.64581 acc 0.70270 roc_auc 0.64333 prc_auc 0.79247[0m
[92maverage training of epoch 23: loss 0.53292 acc 0.76159 roc_auc 0.75431 prc_auc 0.82989[0m
[93maverage test of epoch 23: loss 0.65557 acc 0.70270 roc_auc 0.64333 prc_auc 0.79247[0m
[92maverage training of epoch 24: loss 0.50692 acc 0.74834 roc_auc 0.79314 prc_auc 0.85812[0m
[93maverage test of epoch 24: loss 0.66066 acc 0.70270 roc_auc 0.64333 prc_auc 0.79247[0m
[92maverage training of epoch 25: loss 0.53951 acc 0.73510 roc_auc 0.74569 prc_auc 0.82542[0m
[93maverage test of epoch 25: loss 0.65276 acc 0.70270 roc_auc 0.64000 prc_auc 0.79156[0m
[92maverage training of epoch 26: loss 0.51108 acc 0.76159 roc_auc 0.78863 prc_auc 0.86225[0m
[93maverage test of epoch 26: loss 0.65400 acc 0.70270 roc_auc 0.64000 prc_auc 0.79156[0m
[92maverage training of epoch 27: loss 0.51955 acc 0.75497 roc_auc 0.78549 prc_auc 0.84750[0m
[93maverage test of epoch 27: loss 0.65522 acc 0.70270 roc_auc 0.64000 prc_auc 0.79176[0m
[92maverage training of epoch 28: loss 0.51051 acc 0.74834 roc_auc 0.78020 prc_auc 0.84278[0m
[93maverage test of epoch 28: loss 0.65281 acc 0.70270 roc_auc 0.64000 prc_auc 0.79176[0m
[92maverage training of epoch 29: loss 0.52785 acc 0.71523 roc_auc 0.77431 prc_auc 0.85386[0m
[93maverage test of epoch 29: loss 0.65638 acc 0.70270 roc_auc 0.64000 prc_auc 0.79176[0m
[92maverage training of epoch 30: loss 0.52695 acc 0.73510 roc_auc 0.77490 prc_auc 0.85808[0m
[93maverage test of epoch 30: loss 0.66070 acc 0.70270 roc_auc 0.63667 prc_auc 0.79029[0m
[92maverage training of epoch 31: loss 0.52376 acc 0.75497 roc_auc 0.76961 prc_auc 0.85301[0m
[93maverage test of epoch 31: loss 0.65914 acc 0.70270 roc_auc 0.63667 prc_auc 0.79029[0m
[92maverage training of epoch 32: loss 0.51347 acc 0.75497 roc_auc 0.77569 prc_auc 0.84438[0m
[93maverage test of epoch 32: loss 0.65178 acc 0.67568 roc_auc 0.64000 prc_auc 0.79132[0m
[92maverage training of epoch 33: loss 0.52940 acc 0.74834 roc_auc 0.75686 prc_auc 0.83972[0m
[93maverage test of epoch 33: loss 0.65837 acc 0.67568 roc_auc 0.64000 prc_auc 0.79132[0m
[92maverage training of epoch 34: loss 0.53255 acc 0.73510 roc_auc 0.75059 prc_auc 0.82561[0m
[93maverage test of epoch 34: loss 0.65110 acc 0.67568 roc_auc 0.64000 prc_auc 0.79132[0m
[92maverage training of epoch 35: loss 0.51412 acc 0.74834 roc_auc 0.78078 prc_auc 0.83791[0m
[93maverage test of epoch 35: loss 0.65269 acc 0.67568 roc_auc 0.64000 prc_auc 0.79132[0m
[92maverage training of epoch 36: loss 0.51559 acc 0.76159 roc_auc 0.77588 prc_auc 0.85429[0m
[93maverage test of epoch 36: loss 0.66114 acc 0.67568 roc_auc 0.64000 prc_auc 0.79132[0m
[92maverage training of epoch 37: loss 0.49165 acc 0.74834 roc_auc 0.80314 prc_auc 0.88388[0m
[93maverage test of epoch 37: loss 0.66700 acc 0.67568 roc_auc 0.64333 prc_auc 0.79799[0m
[92maverage training of epoch 38: loss 0.49963 acc 0.76159 roc_auc 0.79255 prc_auc 0.86769[0m
[93maverage test of epoch 38: loss 0.66202 acc 0.67568 roc_auc 0.64333 prc_auc 0.79799[0m
[92maverage training of epoch 39: loss 0.48201 acc 0.75497 roc_auc 0.81667 prc_auc 0.89011[0m
[93maverage test of epoch 39: loss 0.66809 acc 0.67568 roc_auc 0.64333 prc_auc 0.79799[0m
[92maverage training of epoch 40: loss 0.49542 acc 0.74834 roc_auc 0.79196 prc_auc 0.85943[0m
[93maverage test of epoch 40: loss 0.67366 acc 0.67568 roc_auc 0.64333 prc_auc 0.79799[0m
[92maverage training of epoch 41: loss 0.50484 acc 0.76159 roc_auc 0.79314 prc_auc 0.87048[0m
[93maverage test of epoch 41: loss 0.67841 acc 0.67568 roc_auc 0.64667 prc_auc 0.79919[0m
[92maverage training of epoch 42: loss 0.50317 acc 0.73510 roc_auc 0.80039 prc_auc 0.85701[0m
[93maverage test of epoch 42: loss 0.66475 acc 0.67568 roc_auc 0.64000 prc_auc 0.79629[0m
[92maverage training of epoch 43: loss 0.49552 acc 0.74834 roc_auc 0.80176 prc_auc 0.86348[0m
[93maverage test of epoch 43: loss 0.66804 acc 0.67568 roc_auc 0.64667 prc_auc 0.79894[0m
[92maverage training of epoch 44: loss 0.50184 acc 0.73510 roc_auc 0.79196 prc_auc 0.85531[0m
[93maverage test of epoch 44: loss 0.67252 acc 0.67568 roc_auc 0.65333 prc_auc 0.80212[0m
[92maverage training of epoch 45: loss 0.50712 acc 0.74172 roc_auc 0.79706 prc_auc 0.82646[0m
[93maverage test of epoch 45: loss 0.66584 acc 0.67568 roc_auc 0.65000 prc_auc 0.80021[0m
[92maverage training of epoch 46: loss 0.50183 acc 0.74834 roc_auc 0.80333 prc_auc 0.86562[0m
[93maverage test of epoch 46: loss 0.65999 acc 0.67568 roc_auc 0.65000 prc_auc 0.80021[0m
[92maverage training of epoch 47: loss 0.49354 acc 0.75497 roc_auc 0.80314 prc_auc 0.86428[0m
[93maverage test of epoch 47: loss 0.66657 acc 0.67568 roc_auc 0.64667 prc_auc 0.79945[0m
[92maverage training of epoch 48: loss 0.50871 acc 0.76159 roc_auc 0.77804 prc_auc 0.80729[0m
[93maverage test of epoch 48: loss 0.66542 acc 0.67568 roc_auc 0.64667 prc_auc 0.79945[0m
[92maverage training of epoch 49: loss 0.51118 acc 0.76159 roc_auc 0.77137 prc_auc 0.83385[0m
[93maverage test of epoch 49: loss 0.66511 acc 0.67568 roc_auc 0.64667 prc_auc 0.79945[0m
Training model with dataset, testing using fold 4
[92maverage training of epoch 0: loss 0.65524 acc 0.65563 roc_auc 0.53020 prc_auc 0.66679[0m
[93maverage test of epoch 0: loss 0.61418 acc 0.67568 roc_auc 0.69333 prc_auc 0.85355[0m
[92maverage training of epoch 1: loss 0.63409 acc 0.63576 roc_auc 0.58137 prc_auc 0.71133[0m
[93maverage test of epoch 1: loss 0.60816 acc 0.67568 roc_auc 0.72667 prc_auc 0.86496[0m
[92maverage training of epoch 2: loss 0.63723 acc 0.68212 roc_auc 0.57078 prc_auc 0.70767[0m
[93maverage test of epoch 2: loss 0.60247 acc 0.67568 roc_auc 0.73333 prc_auc 0.86691[0m
[92maverage training of epoch 3: loss 0.63276 acc 0.64901 roc_auc 0.60000 prc_auc 0.73664[0m
[93maverage test of epoch 3: loss 0.59826 acc 0.67568 roc_auc 0.74667 prc_auc 0.87188[0m
[92maverage training of epoch 4: loss 0.60501 acc 0.69536 roc_auc 0.65431 prc_auc 0.79535[0m
[93maverage test of epoch 4: loss 0.59270 acc 0.67568 roc_auc 0.74667 prc_auc 0.87188[0m
[92maverage training of epoch 5: loss 0.61014 acc 0.68212 roc_auc 0.64020 prc_auc 0.77392[0m
[93maverage test of epoch 5: loss 0.59283 acc 0.67568 roc_auc 0.75000 prc_auc 0.87292[0m
[92maverage training of epoch 6: loss 0.58166 acc 0.69536 roc_auc 0.70137 prc_auc 0.83128[0m
[93maverage test of epoch 6: loss 0.58858 acc 0.67568 roc_auc 0.75000 prc_auc 0.87272[0m
[92maverage training of epoch 7: loss 0.57354 acc 0.71523 roc_auc 0.72000 prc_auc 0.82718[0m
[93maverage test of epoch 7: loss 0.59839 acc 0.67568 roc_auc 0.75000 prc_auc 0.87272[0m
[92maverage training of epoch 8: loss 0.59809 acc 0.70199 roc_auc 0.67647 prc_auc 0.78736[0m
[93maverage test of epoch 8: loss 0.59927 acc 0.67568 roc_auc 0.76000 prc_auc 0.87685[0m
[92maverage training of epoch 9: loss 0.59491 acc 0.72185 roc_auc 0.66471 prc_auc 0.75279[0m
[93maverage test of epoch 9: loss 0.59744 acc 0.67568 roc_auc 0.76000 prc_auc 0.87685[0m
[92maverage training of epoch 10: loss 0.56195 acc 0.73510 roc_auc 0.74196 prc_auc 0.82148[0m
[93maverage test of epoch 10: loss 0.61141 acc 0.67568 roc_auc 0.76000 prc_auc 0.87685[0m
[92maverage training of epoch 11: loss 0.57944 acc 0.72848 roc_auc 0.69922 prc_auc 0.81256[0m
[93maverage test of epoch 11: loss 0.61320 acc 0.67568 roc_auc 0.76000 prc_auc 0.87685[0m
[92maverage training of epoch 12: loss 0.56824 acc 0.72185 roc_auc 0.71314 prc_auc 0.81373[0m
[93maverage test of epoch 12: loss 0.59822 acc 0.67568 roc_auc 0.76000 prc_auc 0.87685[0m
[92maverage training of epoch 13: loss 0.55760 acc 0.73510 roc_auc 0.72275 prc_auc 0.82792[0m
[93maverage test of epoch 13: loss 0.59895 acc 0.67568 roc_auc 0.76000 prc_auc 0.87685[0m
[92maverage training of epoch 14: loss 0.56840 acc 0.71523 roc_auc 0.71765 prc_auc 0.82083[0m
[93maverage test of epoch 14: loss 0.58887 acc 0.70270 roc_auc 0.75667 prc_auc 0.87433[0m
[92maverage training of epoch 15: loss 0.57378 acc 0.74172 roc_auc 0.71137 prc_auc 0.79917[0m
[93maverage test of epoch 15: loss 0.59381 acc 0.70270 roc_auc 0.76333 prc_auc 0.87634[0m
[92maverage training of epoch 16: loss 0.56401 acc 0.72848 roc_auc 0.71922 prc_auc 0.82270[0m
[93maverage test of epoch 16: loss 0.60031 acc 0.70270 roc_auc 0.76333 prc_auc 0.87634[0m
[92maverage training of epoch 17: loss 0.54440 acc 0.72848 roc_auc 0.74412 prc_auc 0.85218[0m
[93maverage test of epoch 17: loss 0.60447 acc 0.70270 roc_auc 0.76333 prc_auc 0.87634[0m
[92maverage training of epoch 18: loss 0.56591 acc 0.74834 roc_auc 0.72059 prc_auc 0.80570[0m
[93maverage test of epoch 18: loss 0.59863 acc 0.70270 roc_auc 0.76333 prc_auc 0.87634[0m
[92maverage training of epoch 19: loss 0.55963 acc 0.74172 roc_auc 0.72020 prc_auc 0.82469[0m
[93maverage test of epoch 19: loss 0.61580 acc 0.70270 roc_auc 0.76333 prc_auc 0.87634[0m
[92maverage training of epoch 20: loss 0.53687 acc 0.74834 roc_auc 0.76118 prc_auc 0.83735[0m
[93maverage test of epoch 20: loss 0.61613 acc 0.70270 roc_auc 0.76333 prc_auc 0.87634[0m
[92maverage training of epoch 21: loss 0.54798 acc 0.74834 roc_auc 0.73078 prc_auc 0.83051[0m
[93maverage test of epoch 21: loss 0.60307 acc 0.70270 roc_auc 0.76667 prc_auc 0.87753[0m
[92maverage training of epoch 22: loss 0.54717 acc 0.76159 roc_auc 0.73569 prc_auc 0.81441[0m
[93maverage test of epoch 22: loss 0.61064 acc 0.70270 roc_auc 0.76667 prc_auc 0.87753[0m
[92maverage training of epoch 23: loss 0.51597 acc 0.78146 roc_auc 0.77176 prc_auc 0.85659[0m
[93maverage test of epoch 23: loss 0.60387 acc 0.78378 roc_auc 0.76667 prc_auc 0.87753[0m
[92maverage training of epoch 24: loss 0.53980 acc 0.73510 roc_auc 0.74765 prc_auc 0.84847[0m
[93maverage test of epoch 24: loss 0.61131 acc 0.78378 roc_auc 0.76667 prc_auc 0.87753[0m
[92maverage training of epoch 25: loss 0.52519 acc 0.75497 roc_auc 0.76235 prc_auc 0.84886[0m
[93maverage test of epoch 25: loss 0.61341 acc 0.78378 roc_auc 0.76667 prc_auc 0.87753[0m
[92maverage training of epoch 26: loss 0.55021 acc 0.74172 roc_auc 0.73294 prc_auc 0.81925[0m
[93maverage test of epoch 26: loss 0.59873 acc 0.78378 roc_auc 0.76667 prc_auc 0.87753[0m
[92maverage training of epoch 27: loss 0.52588 acc 0.74172 roc_auc 0.76941 prc_auc 0.86583[0m
[93maverage test of epoch 27: loss 0.60710 acc 0.78378 roc_auc 0.76667 prc_auc 0.87753[0m
[92maverage training of epoch 28: loss 0.51332 acc 0.75497 roc_auc 0.77961 prc_auc 0.86471[0m
[93maverage test of epoch 28: loss 0.62053 acc 0.72973 roc_auc 0.76667 prc_auc 0.87753[0m
[92maverage training of epoch 29: loss 0.52706 acc 0.74172 roc_auc 0.75902 prc_auc 0.85160[0m
[93maverage test of epoch 29: loss 0.60954 acc 0.78378 roc_auc 0.76667 prc_auc 0.87753[0m
[92maverage training of epoch 30: loss 0.55813 acc 0.70861 roc_auc 0.72941 prc_auc 0.82221[0m
[93maverage test of epoch 30: loss 0.60454 acc 0.72973 roc_auc 0.76667 prc_auc 0.87753[0m
[92maverage training of epoch 31: loss 0.52181 acc 0.74172 roc_auc 0.76686 prc_auc 0.84666[0m
[93maverage test of epoch 31: loss 0.60970 acc 0.72973 roc_auc 0.76667 prc_auc 0.87753[0m
[92maverage training of epoch 32: loss 0.53567 acc 0.73510 roc_auc 0.75647 prc_auc 0.85320[0m
[93maverage test of epoch 32: loss 0.59897 acc 0.75676 roc_auc 0.76667 prc_auc 0.87753[0m
[92maverage training of epoch 33: loss 0.53269 acc 0.72185 roc_auc 0.74608 prc_auc 0.83135[0m
[93maverage test of epoch 33: loss 0.59847 acc 0.75676 roc_auc 0.76333 prc_auc 0.87620[0m
[92maverage training of epoch 34: loss 0.51503 acc 0.76159 roc_auc 0.76412 prc_auc 0.83649[0m
[93maverage test of epoch 34: loss 0.59218 acc 0.75676 roc_auc 0.76333 prc_auc 0.87620[0m
[92maverage training of epoch 35: loss 0.54295 acc 0.73510 roc_auc 0.75745 prc_auc 0.85296[0m
[93maverage test of epoch 35: loss 0.58747 acc 0.75676 roc_auc 0.75667 prc_auc 0.87447[0m
[92maverage training of epoch 36: loss 0.52169 acc 0.76159 roc_auc 0.76392 prc_auc 0.80645[0m
[93maverage test of epoch 36: loss 0.59835 acc 0.75676 roc_auc 0.75667 prc_auc 0.87447[0m
[92maverage training of epoch 37: loss 0.50631 acc 0.76821 roc_auc 0.78882 prc_auc 0.86314[0m
[93maverage test of epoch 37: loss 0.59032 acc 0.75676 roc_auc 0.76333 prc_auc 0.87620[0m
[92maverage training of epoch 38: loss 0.51760 acc 0.72848 roc_auc 0.77608 prc_auc 0.85843[0m
[93maverage test of epoch 38: loss 0.59545 acc 0.75676 roc_auc 0.75667 prc_auc 0.87447[0m
[92maverage training of epoch 39: loss 0.52161 acc 0.74834 roc_auc 0.77353 prc_auc 0.84920[0m
[93maverage test of epoch 39: loss 0.60452 acc 0.75676 roc_auc 0.75667 prc_auc 0.87447[0m
[92maverage training of epoch 40: loss 0.52369 acc 0.76821 roc_auc 0.77196 prc_auc 0.86846[0m
[93maverage test of epoch 40: loss 0.60322 acc 0.75676 roc_auc 0.75667 prc_auc 0.87447[0m
[92maverage training of epoch 41: loss 0.53585 acc 0.76159 roc_auc 0.75902 prc_auc 0.82619[0m
[93maverage test of epoch 41: loss 0.60655 acc 0.75676 roc_auc 0.75667 prc_auc 0.87447[0m
[92maverage training of epoch 42: loss 0.53473 acc 0.76159 roc_auc 0.74431 prc_auc 0.78970[0m
[93maverage test of epoch 42: loss 0.58961 acc 0.75676 roc_auc 0.75667 prc_auc 0.87447[0m
[92maverage training of epoch 43: loss 0.52993 acc 0.74172 roc_auc 0.77549 prc_auc 0.82597[0m
[93maverage test of epoch 43: loss 0.60169 acc 0.75676 roc_auc 0.75667 prc_auc 0.87447[0m
[92maverage training of epoch 44: loss 0.51854 acc 0.76821 roc_auc 0.75275 prc_auc 0.79979[0m
[93maverage test of epoch 44: loss 0.59178 acc 0.75676 roc_auc 0.75667 prc_auc 0.87447[0m
[92maverage training of epoch 45: loss 0.49924 acc 0.74172 roc_auc 0.79059 prc_auc 0.86864[0m
[93maverage test of epoch 45: loss 0.59016 acc 0.75676 roc_auc 0.77667 prc_auc 0.88470[0m
[92maverage training of epoch 46: loss 0.50723 acc 0.76821 roc_auc 0.78118 prc_auc 0.87325[0m
[93maverage test of epoch 46: loss 0.60100 acc 0.75676 roc_auc 0.77667 prc_auc 0.88470[0m
[92maverage training of epoch 47: loss 0.54041 acc 0.75497 roc_auc 0.75137 prc_auc 0.82388[0m
[93maverage test of epoch 47: loss 0.59053 acc 0.75676 roc_auc 0.77667 prc_auc 0.88470[0m
[92maverage training of epoch 48: loss 0.51836 acc 0.78808 roc_auc 0.76647 prc_auc 0.83442[0m
[93maverage test of epoch 48: loss 0.58672 acc 0.72973 roc_auc 0.77667 prc_auc 0.88470[0m
[92maverage training of epoch 49: loss 0.51587 acc 0.75497 roc_auc 0.77137 prc_auc 0.85847[0m
[93maverage test of epoch 49: loss 0.59326 acc 0.72973 roc_auc 0.77667 prc_auc 0.88470[0m
Run statistics: 
==== Configuration Settings ====
== Run Settings ==
Model: GCN, Dataset: MUTAG
num_epochs: 50
learning_rate: 0.0001
seed: 1800
k_fold: 5
model: GCN
dataset: MUTAG

== Model Settings and results ==
convolution_layers_size: 128-256-512
dropout: 0.5

Accuracy (avg): 0.71792 ROC_AUC (avg): 0.77882 PRC_AUC (avg): 0.87787 

Average forward propagation time taken(ms): 2.360942836142666
Average backward propagation time taken(ms): 1.5490482561676775

