# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======


torch.cuda.is_available():  True 


model: DFScodeRNN_cls_GRU
dataset: PTC_FR
args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/PTC_FR/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/PTC_FR/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/PTC_FR/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/PTC_FR/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   1   2   3   4   6   8   9  10  11  12  13  14  15  16  17  19  20
  21  22  23  24  25  26  27  28  29  30  31  32  33  36  37  38  40  42
  43  44  45  46  48  50  53  54  56  57  58  60  61  62  63  64  65  66
  68  71  72  73  74  75  77  78  79  80  81  82  83  84  85  86  88  89
  90  92  94  95  97  98 100 101 102 103 104 106 108 109 111 112 113 114
 115 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 134
 135 136 137 138 139 140 141 143 145 146 147 148 149 150 151 152 154 155
 156 157 158 159 160 161 162 163 164 165 166 168 169 171 173 174 176 180
 181 182 184 185 187 188 189 193 194 196 197 198 199 200 201 202 203 204
 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223
 226 227 228 230 231 232 233 234 235 236 238 239 242 243 244 245 246 248
 250 251 252 253 254 255 256 257 258 260 261 262 263 264 265 266 268 270
 272 273 276 277 278 279 280 281 282 283 284 285 286 287 289 290 291 293
 294 295 296 297 298 299 300 301 303 304 306 307 308 309 311 312 313 316
 317 318 320 321 323 324 325 326 327 328 329 330 331 332 333 334 335 336
 338 339 340 341 342 343 346 348 349 350]
*** 2 test_index:  [  5   7  18  34  35  39  41  47  49  51  52  55  59  67  69  70  76  87
  91  93  96  99 105 107 110 122 133 142 144 153 167 170 172 175 177 178
 179 183 186 190 191 192 195 205 224 225 229 237 240 241 247 249 259 267
 269 271 274 275 288 292 302 305 310 314 315 319 322 337 344 345 347]
*** 1 train_index:  [  0   1   2   3   5   6   7   9  11  12  13  15  16  17  18  19  20  21
  22  23  25  26  27  28  29  32  33  34  35  37  38  39  40  41  42  46
  47  48  49  50  51  52  53  54  55  56  58  59  60  61  62  63  64  65
  67  69  70  72  75  76  77  80  81  82  83  84  85  86  87  88  90  91
  93  94  95  96  98  99 100 102 103 104 105 107 108 109 110 111 112 113
 114 115 116 117 118 120 121 122 123 124 125 126 127 128 130 131 132 133
 134 135 137 138 139 140 141 142 144 145 146 147 149 151 153 154 155 156
 157 158 159 160 161 162 163 165 166 167 168 169 170 171 172 173 175 176
 177 178 179 180 182 183 185 186 187 188 189 190 191 192 193 194 195 197
 198 199 200 202 203 204 205 207 208 210 211 212 213 214 215 216 217 218
 220 222 224 225 226 227 228 229 230 231 232 233 235 236 237 239 240 241
 242 243 244 247 248 249 250 252 255 257 258 259 260 261 262 263 264 266
 267 268 269 270 271 272 273 274 275 277 278 280 282 284 285 286 287 288
 289 290 291 292 293 295 296 297 302 303 304 305 306 308 309 310 311 312
 314 315 316 318 319 320 321 322 323 324 325 327 328 330 331 332 335 336
 337 338 339 341 342 343 344 345 347 349 350]
*** 2 test_index:  [  4   8  10  14  24  30  31  36  43  44  45  57  66  68  71  73  74  78
  79  89  92  97 101 106 119 129 136 143 148 150 152 164 174 181 184 196
 201 206 209 219 221 223 234 238 245 246 251 253 254 256 265 276 279 281
 283 294 298 299 300 301 307 313 317 326 329 333 334 340 346 348]
*** 1 train_index:  [  1   2   4   5   6   7   8   9  10  12  13  14  15  16  17  18  21  22
  23  24  26  27  28  30  31  32  34  35  36  37  39  40  41  43  44  45
  46  47  48  49  51  52  53  55  56  57  58  59  60  61  63  65  66  67
  68  69  70  71  72  73  74  75  76  78  79  80  81  83  87  89  90  91
  92  93  96  97  98  99 100 101 102 104 105 106 107 109 110 111 113 116
 119 120 121 122 123 125 126 127 129 130 131 133 134 136 137 138 139 140
 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158
 159 161 162 164 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 181 182 183 184 186 189 190 191 192 195 196 197 198 199 200 201 202 203
 204 205 206 208 209 211 212 217 218 219 221 222 223 224 225 226 227 228
 229 231 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248
 249 250 251 252 253 254 256 257 258 259 261 262 263 264 265 266 267 269
 271 273 274 275 276 277 278 279 281 282 283 284 288 290 291 292 294 295
 296 297 298 299 300 301 302 303 304 305 307 309 310 311 312 313 314 315
 316 317 318 319 321 322 324 325 326 327 328 329 330 332 333 334 335 337
 338 339 340 343 344 345 346 347 348 349 350]
*** 2 test_index:  [  0   3  11  19  20  25  29  33  38  42  50  54  62  64  77  82  84  85
  86  88  94  95 103 108 112 114 115 117 118 124 128 132 135 160 163 165
 180 185 187 188 193 194 207 210 213 214 215 216 220 230 232 255 260 268
 270 272 280 285 286 287 289 293 306 308 320 323 331 336 341 342]
*** 1 train_index:  [  0   1   2   3   4   5   6   7   8  10  11  12  14  15  16  17  18  19
  20  21  24  25  28  29  30  31  33  34  35  36  37  38  39  40  41  42
  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60
  62  63  64  65  66  67  68  69  70  71  73  74  76  77  78  79  82  83
  84  85  86  87  88  89  91  92  93  94  95  96  97  99 101 103 104 105
 106 107 108 110 112 114 115 116 117 118 119 122 123 124 128 129 132 133
 134 135 136 137 138 141 142 143 144 146 147 148 149 150 152 153 155 156
 157 158 160 163 164 165 167 168 169 170 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 200 201 204 205 206 207 209 210 211 212 213 214 215 216 218 219 220
 221 222 223 224 225 226 227 229 230 232 234 235 236 237 238 240 241 243
 245 246 247 248 249 250 251 252 253 254 255 256 258 259 260 261 262 264
 265 266 267 268 269 270 271 272 274 275 276 277 279 280 281 282 283 285
 286 287 288 289 290 292 293 294 295 296 298 299 300 301 302 303 305 306
 307 308 310 312 313 314 315 317 319 320 322 323 326 329 331 332 333 334
 336 337 340 341 342 343 344 345 346 347 348]
*** 2 test_index:  [  9  13  22  23  26  27  32  61  72  75  80  81  90  98 100 102 109 111
 113 120 121 125 126 127 130 131 139 140 145 151 154 159 161 162 166 171
 199 202 203 208 217 228 231 233 239 242 244 257 263 273 278 284 291 297
 304 309 311 316 318 321 324 325 327 328 330 335 338 339 349 350]
*** 1 train_index:  [  0   3   4   5   7   8   9  10  11  13  14  18  19  20  22  23  24  25
  26  27  29  30  31  32  33  34  35  36  38  39  41  42  43  44  45  47
  49  50  51  52  54  55  57  59  61  62  64  66  67  68  69  70  71  72
  73  74  75  76  77  78  79  80  81  82  84  85  86  87  88  89  90  91
  92  93  94  95  96  97  98  99 100 101 102 103 105 106 107 108 109 110
 111 112 113 114 115 117 118 119 120 121 122 124 125 126 127 128 129 130
 131 132 133 135 136 139 140 142 143 144 145 148 150 151 152 153 154 159
 160 161 162 163 164 165 166 167 170 171 172 174 175 177 178 179 180 181
 183 184 185 186 187 188 190 191 192 193 194 195 196 199 201 202 203 205
 206 207 208 209 210 213 214 215 216 217 219 220 221 223 224 225 228 229
 230 231 232 233 234 237 238 239 240 241 242 244 245 246 247 249 251 253
 254 255 256 257 259 260 263 265 267 268 269 270 271 272 273 274 275 276
 278 279 280 281 283 284 285 286 287 288 289 291 292 293 294 297 298 299
 300 301 302 304 305 306 307 308 309 310 311 313 314 315 316 317 318 319
 320 321 322 323 324 325 326 327 328 329 330 331 333 334 335 336 337 338
 339 340 341 342 344 345 346 347 348 349 350]
*** 2 test_index:  [  1   2   6  12  15  16  17  21  28  37  40  46  48  53  56  58  60  63
  65  83 104 116 123 134 137 138 141 146 147 149 155 156 157 158 168 169
 173 176 182 189 197 198 200 204 211 212 218 222 226 227 235 236 243 248
 250 252 258 261 262 264 266 277 282 290 295 296 303 312 332 343]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/PTC_FR/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/PTC_FR/graphgen/model_save/DFScodeRNN_cls_GRU_PTC_FR_2021-01-14-23-08-21/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/PTC_FR/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/PTC_FR/graphgen/tmp/DFScodeRNN_cls_GRU_PTC_FR_2021-01-14-23-08-21/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/PTC_FR/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0,
 'embedding_size_dfscode_rnn': 8,
 'epochs': 50,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_GRU_PTC_FR',
 'gamma': 0.3,
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/PTC_FR/graphgen/graphs/',
 'graph_type': 'PTC_FR',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/PTC_FR/graphgen/',
 'hidden_size_dfscode_rnn': 4,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.003,
 'max_prev_node': None,
 'milestones': [100, 200, 400, 800],
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/PTC_FR/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/PTC_FR/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/PTC_FR/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_GRU',
 'num_graphs': None,
 'num_layers': 1,
 'num_workers': 8,
 'rnn_type': 'GRU',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/PTC_FR/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/PTC_FR/graphgen/tensorboard/',
 'time': '2021-01-14-23-08-21',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'1': 0, '0': 1, '3': 2, '2': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '12': 9, '13': 10, '14': 11, '9': 12, '15': 13, '16': 14, '17': 15, '18': 16, '10': 17, '11': 18}, 'node_backward': {0: '1', 1: '0', 2: '3', 3: '2', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '12', 10: '13', 11: '14', 12: '9', 13: '15', 14: '16', 15: '17', 16: '18', 17: '10', 18: '11'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 64, 'min_nodes': 2, 'max_edges': 71, 'min_edges': 1, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 50, 'learning_rate': 0.003, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_GRU', 'dataset': 'PTC_FR'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'1': 0, '0': 1, '3': 2, '2': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '12': 9, '13': 10, '14': 11, '9': 12, '15': 13, '16': 14, '17': 15, '18': 16, '10': 17, '11': 18}, 'node_backward': {0: '1', 1: '0', 2: '3', 3: '2', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '12', 10: '13', 11: '14', 12: '9', 13: '15', 14: '16', 15: '17', 16: '18', 17: '10', 18: '11'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 64, 'min_nodes': 2, 'max_edges': 71, 'min_edges': 1, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_GRU
Training model with dataset, testing using fold 0
use GRU
DfscodeRnn_cls_GRU args.lr: 0.003
[92maverage training of epoch 0: loss -1.28233 acc 0.65714 roc_auc 0.50634 prc_auc 0.35817[0m
[93maverage test of epoch 0: loss -1.90044 acc 0.64789 roc_auc 0.51696 prc_auc 0.36468[0m
[92maverage training of epoch 1: loss -2.08066 acc 0.65714 roc_auc 0.51336 prc_auc 0.37471[0m
[93maverage test of epoch 1: loss -2.12473 acc 0.64789 roc_auc 0.55739 prc_auc 0.40161[0m
[92maverage training of epoch 2: loss -2.22013 acc 0.65714 roc_auc 0.51681 prc_auc 0.38306[0m
[93maverage test of epoch 2: loss -2.22791 acc 0.64789 roc_auc 0.51652 prc_auc 0.36388[0m
[92maverage training of epoch 3: loss -2.28579 acc 0.65714 roc_auc 0.51681 prc_auc 0.38370[0m
[93maverage test of epoch 3: loss -2.26171 acc 0.64789 roc_auc 0.47087 prc_auc 0.33917[0m
[92maverage training of epoch 4: loss -2.32009 acc 0.65714 roc_auc 0.51710 prc_auc 0.38389[0m
[93maverage test of epoch 4: loss -2.29541 acc 0.64789 roc_auc 0.47087 prc_auc 0.33917[0m
[92maverage training of epoch 5: loss -2.35430 acc 0.65714 roc_auc 0.51724 prc_auc 0.38408[0m
[93maverage test of epoch 5: loss -2.32903 acc 0.64789 roc_auc 0.47087 prc_auc 0.33917[0m
[92maverage training of epoch 6: loss -2.38842 acc 0.65714 roc_auc 0.51727 prc_auc 0.38385[0m
[93maverage test of epoch 6: loss -2.36257 acc 0.64789 roc_auc 0.47087 prc_auc 0.33917[0m
[92maverage training of epoch 7: loss -2.42244 acc 0.65714 roc_auc 0.51744 prc_auc 0.38412[0m
[93maverage test of epoch 7: loss -2.39600 acc 0.64789 roc_auc 0.55696 prc_auc 0.39741[0m
[92maverage training of epoch 8: loss -2.45633 acc 0.65714 roc_auc 0.51744 prc_auc 0.38406[0m
[93maverage test of epoch 8: loss -2.42932 acc 0.64789 roc_auc 0.47087 prc_auc 0.33917[0m
[92maverage training of epoch 9: loss -2.49007 acc 0.65714 roc_auc 0.51766 prc_auc 0.38483[0m
[93maverage test of epoch 9: loss -2.46250 acc 0.64789 roc_auc 0.55696 prc_auc 0.39741[0m
[92maverage training of epoch 10: loss -2.52367 acc 0.65714 roc_auc 0.51795 prc_auc 0.38520[0m
[93maverage test of epoch 10: loss -2.49554 acc 0.64789 roc_auc 0.48783 prc_auc 0.35203[0m
[92maverage training of epoch 11: loss -2.55711 acc 0.65714 roc_auc 0.51792 prc_auc 0.38512[0m
[93maverage test of epoch 11: loss -2.52843 acc 0.64789 roc_auc 0.47087 prc_auc 0.33917[0m
[92maverage training of epoch 12: loss -2.59038 acc 0.65714 roc_auc 0.51789 prc_auc 0.38473[0m
[93maverage test of epoch 12: loss -2.56117 acc 0.64789 roc_auc 0.50217 prc_auc 0.35956[0m
[92maverage training of epoch 13: loss -2.62347 acc 0.65714 roc_auc 0.51783 prc_auc 0.38473[0m
[93maverage test of epoch 13: loss -2.59374 acc 0.64789 roc_auc 0.52391 prc_auc 0.39869[0m
[92maverage training of epoch 14: loss -2.65638 acc 0.65714 roc_auc 0.51800 prc_auc 0.38508[0m
[93maverage test of epoch 14: loss -2.62614 acc 0.64789 roc_auc 0.52391 prc_auc 0.39869[0m
[92maverage training of epoch 15: loss -2.68911 acc 0.65714 roc_auc 0.51800 prc_auc 0.38508[0m
[93maverage test of epoch 15: loss -2.65838 acc 0.64789 roc_auc 0.44609 prc_auc 0.32864[0m
[92maverage training of epoch 16: loss -2.72166 acc 0.65714 roc_auc 0.51800 prc_auc 0.38508[0m
[93maverage test of epoch 16: loss -2.69044 acc 0.64789 roc_auc 0.44609 prc_auc 0.32864[0m
[92maverage training of epoch 17: loss -2.75401 acc 0.65714 roc_auc 0.51789 prc_auc 0.38474[0m
[93maverage test of epoch 17: loss -2.72232 acc 0.64789 roc_auc 0.49217 prc_auc 0.38602[0m
[92maverage training of epoch 18: loss -2.78618 acc 0.65714 roc_auc 0.51792 prc_auc 0.38496[0m
[93maverage test of epoch 18: loss -2.75403 acc 0.64789 roc_auc 0.44609 prc_auc 0.32864[0m
[92maverage training of epoch 19: loss -2.81816 acc 0.65714 roc_auc 0.51783 prc_auc 0.38511[0m
[93maverage test of epoch 19: loss -2.78556 acc 0.64789 roc_auc 0.47087 prc_auc 0.33917[0m
[92maverage training of epoch 20: loss -2.84995 acc 0.65714 roc_auc 0.51783 prc_auc 0.38536[0m
[93maverage test of epoch 20: loss -2.81692 acc 0.64789 roc_auc 0.51348 prc_auc 0.36432[0m
[92maverage training of epoch 21: loss -2.88155 acc 0.65714 roc_auc 0.51778 prc_auc 0.38500[0m
[93maverage test of epoch 21: loss -2.84810 acc 0.64789 roc_auc 0.51652 prc_auc 0.36388[0m
[92maverage training of epoch 22: loss -2.91297 acc 0.65714 roc_auc 0.51761 prc_auc 0.38435[0m
[93maverage test of epoch 22: loss -2.87910 acc 0.64789 roc_auc 0.47087 prc_auc 0.33917[0m
[92maverage training of epoch 23: loss -2.94419 acc 0.65714 roc_auc 0.51749 prc_auc 0.38414[0m
[93maverage test of epoch 23: loss -2.90993 acc 0.64789 roc_auc 0.51652 prc_auc 0.36388[0m
[92maverage training of epoch 24: loss -2.97523 acc 0.65714 roc_auc 0.51735 prc_auc 0.38397[0m
[93maverage test of epoch 24: loss -2.94058 acc 0.64789 roc_auc 0.50087 prc_auc 0.35581[0m
[92maverage training of epoch 25: loss -3.00609 acc 0.65714 roc_auc 0.51721 prc_auc 0.38383[0m
[93maverage test of epoch 25: loss -2.97106 acc 0.64789 roc_auc 0.48348 prc_auc 0.34509[0m
[92maverage training of epoch 26: loss -3.03676 acc 0.65714 roc_auc 0.51715 prc_auc 0.38430[0m
[93maverage test of epoch 26: loss -3.00136 acc 0.64789 roc_auc 0.47087 prc_auc 0.33917[0m
[92maverage training of epoch 27: loss -3.06725 acc 0.65714 roc_auc 0.51701 prc_auc 0.38421[0m
[93maverage test of epoch 27: loss -3.03150 acc 0.64789 roc_auc 0.47087 prc_auc 0.33917[0m
[92maverage training of epoch 28: loss -3.09757 acc 0.65714 roc_auc 0.51687 prc_auc 0.38371[0m
[93maverage test of epoch 28: loss -3.06147 acc 0.64789 roc_auc 0.46043 prc_auc 0.33132[0m
[92maverage training of epoch 29: loss -3.12771 acc 0.65714 roc_auc 0.51676 prc_auc 0.38350[0m
[93maverage test of epoch 29: loss -3.09127 acc 0.64789 roc_auc 0.48435 prc_auc 0.34554[0m
[92maverage training of epoch 30: loss -3.15768 acc 0.65714 roc_auc 0.51673 prc_auc 0.38360[0m
[93maverage test of epoch 30: loss -3.12092 acc 0.64789 roc_auc 0.45522 prc_auc 0.33229[0m
[92maverage training of epoch 31: loss -3.18747 acc 0.65714 roc_auc 0.51645 prc_auc 0.38293[0m
[93maverage test of epoch 31: loss -3.15040 acc 0.64789 roc_auc 0.50696 prc_auc 0.35828[0m
[92maverage training of epoch 32: loss -3.21711 acc 0.65714 roc_auc 0.51642 prc_auc 0.38360[0m
[93maverage test of epoch 32: loss -3.17973 acc 0.64789 roc_auc 0.50261 prc_auc 0.35722[0m
[92maverage training of epoch 33: loss -3.24657 acc 0.65714 roc_auc 0.51605 prc_auc 0.38220[0m
[93maverage test of epoch 33: loss -3.20890 acc 0.64789 roc_auc 0.49522 prc_auc 0.35055[0m
[92maverage training of epoch 34: loss -3.27589 acc 0.65714 roc_auc 0.51579 prc_auc 0.38145[0m
[93maverage test of epoch 34: loss -3.23792 acc 0.64789 roc_auc 0.54261 prc_auc 0.40302[0m
[92maverage training of epoch 35: loss -3.30504 acc 0.65714 roc_auc 0.51540 prc_auc 0.38075[0m
[93maverage test of epoch 35: loss -3.26680 acc 0.64789 roc_auc 0.55696 prc_auc 0.39741[0m
[92maverage training of epoch 36: loss -3.33404 acc 0.65714 roc_auc 0.51483 prc_auc 0.37907[0m
[93maverage test of epoch 36: loss -3.29553 acc 0.64789 roc_auc 0.50696 prc_auc 0.35828[0m
[92maverage training of epoch 37: loss -3.36290 acc 0.65714 roc_auc 0.51432 prc_auc 0.37790[0m
[93maverage test of epoch 37: loss -3.32413 acc 0.64789 roc_auc 0.47087 prc_auc 0.33917[0m
[92maverage training of epoch 38: loss -3.39161 acc 0.65714 roc_auc 0.51395 prc_auc 0.37697[0m
[93maverage test of epoch 38: loss -3.35259 acc 0.64789 roc_auc 0.47087 prc_auc 0.33917[0m
[92maverage training of epoch 39: loss -3.42018 acc 0.65714 roc_auc 0.51285 prc_auc 0.37449[0m
[93maverage test of epoch 39: loss -3.38091 acc 0.64789 roc_auc 0.54043 prc_auc 0.39339[0m
[92maverage training of epoch 40: loss -3.44861 acc 0.65714 roc_auc 0.51260 prc_auc 0.37423[0m
[93maverage test of epoch 40: loss -3.40910 acc 0.64789 roc_auc 0.48391 prc_auc 0.34531[0m
[92maverage training of epoch 41: loss -3.47691 acc 0.65714 roc_auc 0.51251 prc_auc 0.37350[0m
[93maverage test of epoch 41: loss -3.43717 acc 0.64789 roc_auc 0.47087 prc_auc 0.33917[0m
[92maverage training of epoch 42: loss -3.50509 acc 0.65714 roc_auc 0.51186 prc_auc 0.37131[0m
[93maverage test of epoch 42: loss -3.46512 acc 0.64789 roc_auc 0.56000 prc_auc 0.39168[0m
[92maverage training of epoch 43: loss -3.53313 acc 0.65714 roc_auc 0.51141 prc_auc 0.37045[0m
[93maverage test of epoch 43: loss -3.49295 acc 0.64789 roc_auc 0.47087 prc_auc 0.33917[0m
[92maverage training of epoch 44: loss -3.56106 acc 0.65714 roc_auc 0.51087 prc_auc 0.36940[0m
[93maverage test of epoch 44: loss -3.52066 acc 0.64789 roc_auc 0.55217 prc_auc 0.38231[0m
[92maverage training of epoch 45: loss -3.58887 acc 0.65714 roc_auc 0.51056 prc_auc 0.36895[0m
[93maverage test of epoch 45: loss -3.54827 acc 0.64789 roc_auc 0.39261 prc_auc 0.32626[0m
[92maverage training of epoch 46: loss -3.61656 acc 0.65714 roc_auc 0.50982 prc_auc 0.36762[0m
[93maverage test of epoch 46: loss -3.57576 acc 0.64789 roc_auc 0.49174 prc_auc 0.34860[0m
[92maverage training of epoch 47: loss -3.64415 acc 0.65714 roc_auc 0.50968 prc_auc 0.36777[0m
[93maverage test of epoch 47: loss -3.60315 acc 0.64789 roc_auc 0.57261 prc_auc 0.40278[0m
[92maverage training of epoch 48: loss -3.67163 acc 0.65714 roc_auc 0.50923 prc_auc 0.36686[0m
[93maverage test of epoch 48: loss -3.63044 acc 0.64789 roc_auc 0.53609 prc_auc 0.37843[0m
[92maverage training of epoch 49: loss -3.69900 acc 0.65714 roc_auc 0.50880 prc_auc 0.36626[0m
[93maverage test of epoch 49: loss -3.65762 acc 0.64789 roc_auc 0.58565 prc_auc 0.42879[0m
Training model with dataset, testing using fold 1
use GRU
DfscodeRnn_cls_GRU args.lr: 0.003
[92maverage training of epoch 0: loss -2.42707 acc 0.54093 roc_auc 0.52135 prc_auc 0.38167[0m
[93maverage test of epoch 0: loss -3.26523 acc 0.65714 roc_auc 0.53804 prc_auc 0.36557[0m
[92maverage training of epoch 1: loss -3.38592 acc 0.65480 roc_auc 0.50325 prc_auc 0.34853[0m
[93maverage test of epoch 1: loss -3.45388 acc 0.65714 roc_auc 0.56069 prc_auc 0.38624[0m
[92maverage training of epoch 2: loss -3.49822 acc 0.65480 roc_auc 0.50168 prc_auc 0.34660[0m
[93maverage test of epoch 2: loss -3.53610 acc 0.65714 roc_auc 0.43478 prc_auc 0.31246[0m
[92maverage training of epoch 3: loss -3.54898 acc 0.65480 roc_auc 0.50168 prc_auc 0.34588[0m
[93maverage test of epoch 3: loss -3.56344 acc 0.65714 roc_auc 0.52083 prc_auc 0.35339[0m
[92maverage training of epoch 4: loss -3.57630 acc 0.65480 roc_auc 0.50146 prc_auc 0.34576[0m
[93maverage test of epoch 4: loss -3.59076 acc 0.65714 roc_auc 0.43659 prc_auc 0.31932[0m
[92maverage training of epoch 5: loss -3.60357 acc 0.65480 roc_auc 0.50134 prc_auc 0.34565[0m
[93maverage test of epoch 5: loss -3.61802 acc 0.65714 roc_auc 0.42120 prc_auc 0.31615[0m
[92maverage training of epoch 6: loss -3.63078 acc 0.65480 roc_auc 0.50120 prc_auc 0.34553[0m
[93maverage test of epoch 6: loss -3.64520 acc 0.65714 roc_auc 0.51902 prc_auc 0.35253[0m
[92maverage training of epoch 7: loss -3.65790 acc 0.65480 roc_auc 0.50106 prc_auc 0.34537[0m
[93maverage test of epoch 7: loss -3.67229 acc 0.65714 roc_auc 0.43841 prc_auc 0.31818[0m
[92maverage training of epoch 8: loss -3.68492 acc 0.65480 roc_auc 0.50090 prc_auc 0.34523[0m
[93maverage test of epoch 8: loss -3.69926 acc 0.65714 roc_auc 0.42437 prc_auc 0.31284[0m
[92maverage training of epoch 9: loss -3.71182 acc 0.65480 roc_auc 0.50078 prc_auc 0.34519[0m
[93maverage test of epoch 9: loss -3.72612 acc 0.65714 roc_auc 0.59058 prc_auc 0.40086[0m
[92maverage training of epoch 10: loss -3.73861 acc 0.65480 roc_auc 0.50067 prc_auc 0.34515[0m
[93maverage test of epoch 10: loss -3.75286 acc 0.65714 roc_auc 0.49502 prc_auc 0.34100[0m
[92maverage training of epoch 11: loss -3.76527 acc 0.65480 roc_auc 0.50067 prc_auc 0.34510[0m
[93maverage test of epoch 11: loss -3.77948 acc 0.65714 roc_auc 0.52219 prc_auc 0.35407[0m
[92maverage training of epoch 12: loss -3.79182 acc 0.65480 roc_auc 0.50062 prc_auc 0.34504[0m
[93maverage test of epoch 12: loss -3.80598 acc 0.65714 roc_auc 0.52083 prc_auc 0.35339[0m
[92maverage training of epoch 13: loss -3.81825 acc 0.65480 roc_auc 0.50053 prc_auc 0.34495[0m
[93maverage test of epoch 13: loss -3.83237 acc 0.65714 roc_auc 0.41576 prc_auc 0.30720[0m
[92maverage training of epoch 14: loss -3.84457 acc 0.65480 roc_auc 0.50042 prc_auc 0.34492[0m
[93maverage test of epoch 14: loss -3.85866 acc 0.65714 roc_auc 0.38995 prc_auc 0.30444[0m
[92maverage training of epoch 15: loss -3.87079 acc 0.65480 roc_auc 0.50036 prc_auc 0.34487[0m
[93maverage test of epoch 15: loss -3.88485 acc 0.65714 roc_auc 0.63632 prc_auc 0.44329[0m
[92maverage training of epoch 16: loss -3.89691 acc 0.65480 roc_auc 0.50025 prc_auc 0.34478[0m
[93maverage test of epoch 16: loss -3.91094 acc 0.65714 roc_auc 0.50362 prc_auc 0.34500[0m
[92maverage training of epoch 17: loss -3.92294 acc 0.65480 roc_auc 0.50028 prc_auc 0.34480[0m
[93maverage test of epoch 17: loss -3.93695 acc 0.65714 roc_auc 0.59194 prc_auc 0.40507[0m
[92maverage training of epoch 18: loss -3.94889 acc 0.65480 roc_auc 0.50028 prc_auc 0.34479[0m
[93maverage test of epoch 18: loss -3.96287 acc 0.65714 roc_auc 0.50091 prc_auc 0.34369[0m
[92maverage training of epoch 19: loss -3.97477 acc 0.65480 roc_auc 0.50031 prc_auc 0.34480[0m
[93maverage test of epoch 19: loss -3.98872 acc 0.65714 roc_auc 0.50045 prc_auc 0.34369[0m
[92maverage training of epoch 20: loss -4.00056 acc 0.65480 roc_auc 0.50022 prc_auc 0.34480[0m
[93maverage test of epoch 20: loss -4.01451 acc 0.65714 roc_auc 0.51042 prc_auc 0.34825[0m
[92maverage training of epoch 21: loss -4.02630 acc 0.65480 roc_auc 0.50048 prc_auc 0.34490[0m
[93maverage test of epoch 21: loss -4.04023 acc 0.65714 roc_auc 0.51042 prc_auc 0.34825[0m
[92maverage training of epoch 22: loss -4.05197 acc 0.65480 roc_auc 0.50048 prc_auc 0.34492[0m
[93maverage test of epoch 22: loss -4.06589 acc 0.65714 roc_auc 0.41440 prc_auc 0.30968[0m
[92maverage training of epoch 23: loss -4.07759 acc 0.65480 roc_auc 0.50050 prc_auc 0.34494[0m
[93maverage test of epoch 23: loss -4.09149 acc 0.65714 roc_auc 0.55072 prc_auc 0.37574[0m
[92maverage training of epoch 24: loss -4.10315 acc 0.65480 roc_auc 0.50062 prc_auc 0.34501[0m
[93maverage test of epoch 24: loss -4.11705 acc 0.65714 roc_auc 0.49502 prc_auc 0.34102[0m
[92maverage training of epoch 25: loss -4.12867 acc 0.65480 roc_auc 0.50067 prc_auc 0.34506[0m
[93maverage test of epoch 25: loss -4.14256 acc 0.65714 roc_auc 0.51676 prc_auc 0.35156[0m
[92maverage training of epoch 26: loss -4.15414 acc 0.65480 roc_auc 0.50073 prc_auc 0.34513[0m
[93maverage test of epoch 26: loss -4.16803 acc 0.65714 roc_auc 0.51042 prc_auc 0.34825[0m
[92maverage training of epoch 27: loss -4.17958 acc 0.65480 roc_auc 0.50081 prc_auc 0.34517[0m
[93maverage test of epoch 27: loss -4.19346 acc 0.65714 roc_auc 0.55072 prc_auc 0.37070[0m
[92maverage training of epoch 28: loss -4.20497 acc 0.65480 roc_auc 0.50087 prc_auc 0.34521[0m
[93maverage test of epoch 28: loss -4.21886 acc 0.65714 roc_auc 0.50000 prc_auc 0.34327[0m
[92maverage training of epoch 29: loss -4.23033 acc 0.65480 roc_auc 0.50104 prc_auc 0.34536[0m
[93maverage test of epoch 29: loss -4.24422 acc 0.65714 roc_auc 0.50000 prc_auc 0.34327[0m
[92maverage training of epoch 30: loss -4.25567 acc 0.65480 roc_auc 0.50098 prc_auc 0.34530[0m
[93maverage test of epoch 30: loss -4.26956 acc 0.65714 roc_auc 0.50000 prc_auc 0.34327[0m
[92maverage training of epoch 31: loss -4.28097 acc 0.65480 roc_auc 0.50095 prc_auc 0.34536[0m
[93maverage test of epoch 31: loss -4.29487 acc 0.65714 roc_auc 0.50000 prc_auc 0.34327[0m
[92maverage training of epoch 32: loss -4.30625 acc 0.65480 roc_auc 0.50095 prc_auc 0.34533[0m
[93maverage test of epoch 32: loss -4.32015 acc 0.65714 roc_auc 0.50000 prc_auc 0.34327[0m
[92maverage training of epoch 33: loss -4.33150 acc 0.65480 roc_auc 0.50101 prc_auc 0.34532[0m
[93maverage test of epoch 33: loss -4.34541 acc 0.65714 roc_auc 0.48958 prc_auc 0.33843[0m
[92maverage training of epoch 34: loss -4.35673 acc 0.65480 roc_auc 0.50092 prc_auc 0.34528[0m
[93maverage test of epoch 34: loss -4.37065 acc 0.65714 roc_auc 0.48958 prc_auc 0.33843[0m
[92maverage training of epoch 35: loss -4.38194 acc 0.65480 roc_auc 0.50098 prc_auc 0.34532[0m
[93maverage test of epoch 35: loss -4.39587 acc 0.65714 roc_auc 0.50000 prc_auc 0.34327[0m
[92maverage training of epoch 36: loss -4.40714 acc 0.65480 roc_auc 0.50081 prc_auc 0.34519[0m
[93maverage test of epoch 36: loss -4.42107 acc 0.65714 roc_auc 0.47917 prc_auc 0.33373[0m
[92maverage training of epoch 37: loss -4.43231 acc 0.65480 roc_auc 0.50070 prc_auc 0.34516[0m
[93maverage test of epoch 37: loss -4.44626 acc 0.65714 roc_auc 0.48958 prc_auc 0.33843[0m
[92maverage training of epoch 38: loss -4.45747 acc 0.65480 roc_auc 0.50064 prc_auc 0.34509[0m
[93maverage test of epoch 38: loss -4.47143 acc 0.65714 roc_auc 0.50000 prc_auc 0.34327[0m
[92maverage training of epoch 39: loss -4.48262 acc 0.65480 roc_auc 0.50059 prc_auc 0.34506[0m
[93maverage test of epoch 39: loss -4.49659 acc 0.65714 roc_auc 0.48958 prc_auc 0.33843[0m
[92maverage training of epoch 40: loss -4.50776 acc 0.65480 roc_auc 0.50053 prc_auc 0.34502[0m
[93maverage test of epoch 40: loss -4.52173 acc 0.65714 roc_auc 0.50000 prc_auc 0.34327[0m
[92maverage training of epoch 41: loss -4.53288 acc 0.65480 roc_auc 0.50056 prc_auc 0.34506[0m
[93maverage test of epoch 41: loss -4.54687 acc 0.65714 roc_auc 0.45833 prc_auc 0.33373[0m
[92maverage training of epoch 42: loss -4.55799 acc 0.65480 roc_auc 0.50056 prc_auc 0.34506[0m
[93maverage test of epoch 42: loss -4.57199 acc 0.65714 roc_auc 0.47917 prc_auc 0.33373[0m
[92maverage training of epoch 43: loss -4.58309 acc 0.65480 roc_auc 0.50056 prc_auc 0.34502[0m
[93maverage test of epoch 43: loss -4.59711 acc 0.65714 roc_auc 0.50000 prc_auc 0.34327[0m
[92maverage training of epoch 44: loss -4.60819 acc 0.65480 roc_auc 0.50053 prc_auc 0.34483[0m
[93maverage test of epoch 44: loss -4.62222 acc 0.65714 roc_auc 0.47917 prc_auc 0.33373[0m
[92maverage training of epoch 45: loss -4.63327 acc 0.65480 roc_auc 0.50056 prc_auc 0.34502[0m
[93maverage test of epoch 45: loss -4.64732 acc 0.65714 roc_auc 0.47917 prc_auc 0.33373[0m
[92maverage training of epoch 46: loss -4.65835 acc 0.65480 roc_auc 0.50059 prc_auc 0.34506[0m
[93maverage test of epoch 46: loss -4.67241 acc 0.65714 roc_auc 0.50000 prc_auc 0.34327[0m
[92maverage training of epoch 47: loss -4.68342 acc 0.65480 roc_auc 0.50059 prc_auc 0.34509[0m
[93maverage test of epoch 47: loss -4.69750 acc 0.65714 roc_auc 0.50000 prc_auc 0.34327[0m
[92maverage training of epoch 48: loss -4.70849 acc 0.65480 roc_auc 0.50045 prc_auc 0.34498[0m
[93maverage test of epoch 48: loss -4.72258 acc 0.65714 roc_auc 0.50000 prc_auc 0.34327[0m
[92maverage training of epoch 49: loss -4.73355 acc 0.65480 roc_auc 0.50050 prc_auc 0.34498[0m
[93maverage test of epoch 49: loss -4.74765 acc 0.65714 roc_auc 0.48958 prc_auc 0.33843[0m
Training model with dataset, testing using fold 2
use GRU
DfscodeRnn_cls_GRU args.lr: 0.003
[92maverage training of epoch 0: loss -1.75499 acc 0.55872 roc_auc 0.49625 prc_auc 0.36169[0m
[93maverage test of epoch 0: loss -2.33396 acc 0.65714 roc_auc 0.55163 prc_auc 0.37368[0m
[92maverage training of epoch 1: loss -2.44471 acc 0.65480 roc_auc 0.48935 prc_auc 0.33968[0m
[93maverage test of epoch 1: loss -2.50872 acc 0.65714 roc_auc 0.57111 prc_auc 0.38777[0m
[92maverage training of epoch 2: loss -2.55082 acc 0.65480 roc_auc 0.48952 prc_auc 0.34179[0m
[93maverage test of epoch 2: loss -2.58853 acc 0.65714 roc_auc 0.60734 prc_auc 0.42732[0m
[92maverage training of epoch 3: loss -2.60049 acc 0.65480 roc_auc 0.48700 prc_auc 0.34433[0m
[93maverage test of epoch 3: loss -2.61524 acc 0.65714 roc_auc 0.58107 prc_auc 0.39924[0m
[92maverage training of epoch 4: loss -2.62717 acc 0.65480 roc_auc 0.48759 prc_auc 0.34608[0m
[93maverage test of epoch 4: loss -2.64201 acc 0.65714 roc_auc 0.55072 prc_auc 0.37076[0m
[92maverage training of epoch 5: loss -2.65393 acc 0.65480 roc_auc 0.48835 prc_auc 0.34729[0m
[93maverage test of epoch 5: loss -2.66887 acc 0.65714 roc_auc 0.55072 prc_auc 0.37258[0m
[92maverage training of epoch 6: loss -2.68076 acc 0.65480 roc_auc 0.48921 prc_auc 0.34891[0m
[93maverage test of epoch 6: loss -2.69580 acc 0.65714 roc_auc 0.58469 prc_auc 0.40209[0m
[92maverage training of epoch 7: loss -2.70767 acc 0.65480 roc_auc 0.48986 prc_auc 0.34996[0m
[93maverage test of epoch 7: loss -2.72280 acc 0.65714 roc_auc 0.58786 prc_auc 0.41776[0m
[92maverage training of epoch 8: loss -2.73465 acc 0.65480 roc_auc 0.48994 prc_auc 0.34991[0m
[93maverage test of epoch 8: loss -2.74987 acc 0.65714 roc_auc 0.58696 prc_auc 0.40403[0m
[92maverage training of epoch 9: loss -2.76170 acc 0.65480 roc_auc 0.49019 prc_auc 0.35034[0m
[93maverage test of epoch 9: loss -2.77701 acc 0.65714 roc_auc 0.56476 prc_auc 0.38302[0m
[92maverage training of epoch 10: loss -2.78881 acc 0.65480 roc_auc 0.49070 prc_auc 0.35101[0m
[93maverage test of epoch 10: loss -2.80423 acc 0.65714 roc_auc 0.52853 prc_auc 0.36122[0m
[92maverage training of epoch 11: loss -2.81601 acc 0.65480 roc_auc 0.49106 prc_auc 0.35189[0m
[93maverage test of epoch 11: loss -2.83152 acc 0.65714 roc_auc 0.56341 prc_auc 0.38455[0m
[92maverage training of epoch 12: loss -2.84327 acc 0.65480 roc_auc 0.49148 prc_auc 0.35247[0m
[93maverage test of epoch 12: loss -2.85888 acc 0.65714 roc_auc 0.56114 prc_auc 0.38600[0m
[92maverage training of epoch 13: loss -2.87061 acc 0.65480 roc_auc 0.49188 prc_auc 0.35279[0m
[93maverage test of epoch 13: loss -2.88632 acc 0.65714 roc_auc 0.49909 prc_auc 0.34920[0m
[92maverage training of epoch 14: loss -2.89803 acc 0.65480 roc_auc 0.49199 prc_auc 0.35269[0m
[93maverage test of epoch 14: loss -2.91384 acc 0.65714 roc_auc 0.57835 prc_auc 0.38932[0m
[92maverage training of epoch 15: loss -2.92553 acc 0.65480 roc_auc 0.49227 prc_auc 0.35258[0m
[93maverage test of epoch 15: loss -2.94145 acc 0.65714 roc_auc 0.54937 prc_auc 0.36288[0m
[92maverage training of epoch 16: loss -2.95311 acc 0.65480 roc_auc 0.49328 prc_auc 0.35423[0m
[93maverage test of epoch 16: loss -2.96913 acc 0.65714 roc_auc 0.54393 prc_auc 0.36677[0m
[92maverage training of epoch 17: loss -2.98078 acc 0.65480 roc_auc 0.49361 prc_auc 0.35445[0m
[93maverage test of epoch 17: loss -2.99690 acc 0.65714 roc_auc 0.57382 prc_auc 0.38303[0m
[92maverage training of epoch 18: loss -3.00852 acc 0.65480 roc_auc 0.49378 prc_auc 0.35460[0m
[93maverage test of epoch 18: loss -3.02475 acc 0.65714 roc_auc 0.50408 prc_auc 0.34737[0m
[92maverage training of epoch 19: loss -3.03635 acc 0.65480 roc_auc 0.49400 prc_auc 0.35516[0m
[93maverage test of epoch 19: loss -3.05269 acc 0.65714 roc_auc 0.56612 prc_auc 0.37885[0m
[92maverage training of epoch 20: loss -3.06426 acc 0.65480 roc_auc 0.49417 prc_auc 0.35495[0m
[93maverage test of epoch 20: loss -3.08071 acc 0.65714 roc_auc 0.49457 prc_auc 0.35983[0m
[92maverage training of epoch 21: loss -3.09226 acc 0.65480 roc_auc 0.49462 prc_auc 0.35541[0m
[93maverage test of epoch 21: loss -3.10881 acc 0.65714 roc_auc 0.55525 prc_auc 0.37103[0m
[92maverage training of epoch 22: loss -3.12033 acc 0.65480 roc_auc 0.49490 prc_auc 0.35583[0m
[93maverage test of epoch 22: loss -3.13699 acc 0.65714 roc_auc 0.57473 prc_auc 0.38303[0m
[92maverage training of epoch 23: loss -3.14848 acc 0.65480 roc_auc 0.49518 prc_auc 0.35590[0m
[93maverage test of epoch 23: loss -3.16524 acc 0.65714 roc_auc 0.55208 prc_auc 0.37060[0m
[92maverage training of epoch 24: loss -3.17670 acc 0.65480 roc_auc 0.49527 prc_auc 0.35632[0m
[93maverage test of epoch 24: loss -3.19357 acc 0.65714 roc_auc 0.43976 prc_auc 0.32614[0m
[92maverage training of epoch 25: loss -3.20499 acc 0.65480 roc_auc 0.49555 prc_auc 0.35697[0m
[93maverage test of epoch 25: loss -3.22197 acc 0.65714 roc_auc 0.48098 prc_auc 0.34867[0m
[92maverage training of epoch 26: loss -3.23335 acc 0.65480 roc_auc 0.49574 prc_auc 0.35714[0m
[93maverage test of epoch 26: loss -3.25043 acc 0.65714 roc_auc 0.50543 prc_auc 0.34546[0m
[92maverage training of epoch 27: loss -3.26178 acc 0.65480 roc_auc 0.49608 prc_auc 0.35760[0m
[93maverage test of epoch 27: loss -3.27896 acc 0.65714 roc_auc 0.48460 prc_auc 0.34495[0m
[92maverage training of epoch 28: loss -3.29026 acc 0.65480 roc_auc 0.49608 prc_auc 0.35760[0m
[93maverage test of epoch 28: loss -3.30754 acc 0.65714 roc_auc 0.50362 prc_auc 0.34452[0m
[92maverage training of epoch 29: loss -3.31880 acc 0.65480 roc_auc 0.49641 prc_auc 0.35800[0m
[93maverage test of epoch 29: loss -3.33617 acc 0.65714 roc_auc 0.50136 prc_auc 0.34347[0m
[92maverage training of epoch 30: loss -3.34738 acc 0.65480 roc_auc 0.49655 prc_auc 0.35803[0m
[93maverage test of epoch 30: loss -3.36485 acc 0.65714 roc_auc 0.50136 prc_auc 0.34347[0m
[92maverage training of epoch 31: loss -3.37601 acc 0.65480 roc_auc 0.49675 prc_auc 0.35809[0m
[93maverage test of epoch 31: loss -3.39356 acc 0.65714 roc_auc 0.50091 prc_auc 0.34347[0m
[92maverage training of epoch 32: loss -3.40467 acc 0.65480 roc_auc 0.49681 prc_auc 0.35822[0m
[93maverage test of epoch 32: loss -3.42231 acc 0.65714 roc_auc 0.49864 prc_auc 0.34375[0m
[92maverage training of epoch 33: loss -3.43336 acc 0.65480 roc_auc 0.49686 prc_auc 0.35823[0m
[93maverage test of epoch 33: loss -3.45109 acc 0.65714 roc_auc 0.48913 prc_auc 0.34286[0m
[92maverage training of epoch 34: loss -3.46208 acc 0.65480 roc_auc 0.49709 prc_auc 0.35830[0m
[93maverage test of epoch 34: loss -3.47989 acc 0.65714 roc_auc 0.50951 prc_auc 0.34722[0m
[92maverage training of epoch 35: loss -3.49081 acc 0.65480 roc_auc 0.49709 prc_auc 0.35842[0m
[93maverage test of epoch 35: loss -3.50870 acc 0.65714 roc_auc 0.49909 prc_auc 0.34246[0m
[92maverage training of epoch 36: loss -3.51955 acc 0.65480 roc_auc 0.49709 prc_auc 0.35831[0m
[93maverage test of epoch 36: loss -3.53752 acc 0.65714 roc_auc 0.51947 prc_auc 0.35634[0m
[92maverage training of epoch 37: loss -3.54830 acc 0.65480 roc_auc 0.49700 prc_auc 0.35828[0m
[93maverage test of epoch 37: loss -3.56634 acc 0.65714 roc_auc 0.52038 prc_auc 0.35417[0m
[92maverage training of epoch 38: loss -3.57705 acc 0.65480 roc_auc 0.49683 prc_auc 0.35824[0m
[93maverage test of epoch 38: loss -3.59516 acc 0.65714 roc_auc 0.52174 prc_auc 0.35294[0m
[92maverage training of epoch 39: loss -3.60579 acc 0.65480 roc_auc 0.49664 prc_auc 0.35808[0m
[93maverage test of epoch 39: loss -3.62396 acc 0.65714 roc_auc 0.55616 prc_auc 0.37038[0m
[92maverage training of epoch 40: loss -3.63452 acc 0.65480 roc_auc 0.49658 prc_auc 0.35817[0m
[93maverage test of epoch 40: loss -3.65276 acc 0.65714 roc_auc 0.49638 prc_auc 0.34436[0m
[92maverage training of epoch 41: loss -3.66323 acc 0.65480 roc_auc 0.49653 prc_auc 0.35816[0m
[93maverage test of epoch 41: loss -3.68153 acc 0.65714 roc_auc 0.52174 prc_auc 0.35294[0m
[92maverage training of epoch 42: loss -3.69193 acc 0.65480 roc_auc 0.49636 prc_auc 0.35811[0m
[93maverage test of epoch 42: loss -3.71029 acc 0.65714 roc_auc 0.47645 prc_auc 0.33512[0m
[92maverage training of epoch 43: loss -3.72060 acc 0.65480 roc_auc 0.49625 prc_auc 0.35808[0m
[93maverage test of epoch 43: loss -3.73902 acc 0.65714 roc_auc 0.49819 prc_auc 0.34246[0m
[92maverage training of epoch 44: loss -3.74925 acc 0.65480 roc_auc 0.49608 prc_auc 0.35795[0m
[93maverage test of epoch 44: loss -3.76772 acc 0.65714 roc_auc 0.46603 prc_auc 0.33050[0m
[92maverage training of epoch 45: loss -3.77788 acc 0.65480 roc_auc 0.49602 prc_auc 0.35806[0m
[93maverage test of epoch 45: loss -3.79641 acc 0.65714 roc_auc 0.47464 prc_auc 0.33244[0m
[92maverage training of epoch 46: loss -3.80649 acc 0.65480 roc_auc 0.49591 prc_auc 0.35791[0m
[93maverage test of epoch 46: loss -3.82508 acc 0.65714 roc_auc 0.47192 prc_auc 0.33163[0m
[92maverage training of epoch 47: loss -3.83509 acc 0.65480 roc_auc 0.49591 prc_auc 0.35786[0m
[93maverage test of epoch 47: loss -3.85374 acc 0.65714 roc_auc 0.50091 prc_auc 0.34327[0m
[92maverage training of epoch 48: loss -3.86367 acc 0.65480 roc_auc 0.49574 prc_auc 0.35771[0m
[93maverage test of epoch 48: loss -3.88238 acc 0.65714 roc_auc 0.50000 prc_auc 0.34285[0m
[92maverage training of epoch 49: loss -3.89224 acc 0.65480 roc_auc 0.49563 prc_auc 0.35752[0m
[93maverage test of epoch 49: loss -3.91101 acc 0.65714 roc_auc 0.53895 prc_auc 0.36178[0m
Training model with dataset, testing using fold 3
use GRU
DfscodeRnn_cls_GRU args.lr: 0.003
[92maverage training of epoch 0: loss -3.22961 acc 0.65125 roc_auc 0.51502 prc_auc 0.39903[0m
[93maverage test of epoch 0: loss -3.86797 acc 0.65714 roc_auc 0.54031 prc_auc 0.36209[0m
[92maverage training of epoch 1: loss -3.99385 acc 0.65480 roc_auc 0.50717 prc_auc 0.36890[0m
[93maverage test of epoch 1: loss -4.07358 acc 0.65714 roc_auc 0.47826 prc_auc 0.34286[0m
[92maverage training of epoch 2: loss -4.11771 acc 0.65480 roc_auc 0.50796 prc_auc 0.37094[0m
[93maverage test of epoch 2: loss -4.16661 acc 0.65714 roc_auc 0.46830 prc_auc 0.33400[0m
[92maverage training of epoch 3: loss -4.17521 acc 0.65480 roc_auc 0.50560 prc_auc 0.37019[0m
[93maverage test of epoch 3: loss -4.19736 acc 0.65714 roc_auc 0.42482 prc_auc 0.31499[0m
[92maverage training of epoch 4: loss -4.20586 acc 0.65480 roc_auc 0.50583 prc_auc 0.37142[0m
[93maverage test of epoch 4: loss -4.22808 acc 0.65714 roc_auc 0.44203 prc_auc 0.31935[0m
[92maverage training of epoch 5: loss -4.23649 acc 0.65480 roc_auc 0.50605 prc_auc 0.37169[0m
[93maverage test of epoch 5: loss -4.25877 acc 0.65714 roc_auc 0.50000 prc_auc 0.34286[0m
[92maverage training of epoch 6: loss -4.26708 acc 0.65480 roc_auc 0.50614 prc_auc 0.37174[0m
[93maverage test of epoch 6: loss -4.28941 acc 0.65714 roc_auc 0.45743 prc_auc 0.32576[0m
[92maverage training of epoch 7: loss -4.29759 acc 0.65480 roc_auc 0.50611 prc_auc 0.37171[0m
[93maverage test of epoch 7: loss -4.31996 acc 0.65714 roc_auc 0.50000 prc_auc 0.34286[0m
[92maverage training of epoch 8: loss -4.32801 acc 0.65480 roc_auc 0.50611 prc_auc 0.37171[0m
[93maverage test of epoch 8: loss -4.35041 acc 0.65714 roc_auc 0.46649 prc_auc 0.32889[0m
[92maverage training of epoch 9: loss -4.35833 acc 0.65480 roc_auc 0.50605 prc_auc 0.37153[0m
[93maverage test of epoch 9: loss -4.38075 acc 0.65714 roc_auc 0.50861 prc_auc 0.34675[0m
[92maverage training of epoch 10: loss -4.38853 acc 0.65480 roc_auc 0.50605 prc_auc 0.37153[0m
[93maverage test of epoch 10: loss -4.41096 acc 0.65714 roc_auc 0.47192 prc_auc 0.33017[0m
[92maverage training of epoch 11: loss -4.41859 acc 0.65480 roc_auc 0.50597 prc_auc 0.37152[0m
[93maverage test of epoch 11: loss -4.44103 acc 0.65714 roc_auc 0.44067 prc_auc 0.31753[0m
[92maverage training of epoch 12: loss -4.44853 acc 0.65480 roc_auc 0.50574 prc_auc 0.36944[0m
[93maverage test of epoch 12: loss -4.47097 acc 0.65714 roc_auc 0.43659 prc_auc 0.31726[0m
[92maverage training of epoch 13: loss -4.47832 acc 0.65480 roc_auc 0.50560 prc_auc 0.36920[0m
[93maverage test of epoch 13: loss -4.50077 acc 0.65714 roc_auc 0.52355 prc_auc 0.35432[0m
[92maverage training of epoch 14: loss -4.50797 acc 0.65480 roc_auc 0.50524 prc_auc 0.36793[0m
[93maverage test of epoch 14: loss -4.53042 acc 0.65714 roc_auc 0.46830 prc_auc 0.32976[0m
[92maverage training of epoch 15: loss -4.53747 acc 0.65480 roc_auc 0.50504 prc_auc 0.36767[0m
[93maverage test of epoch 15: loss -4.55992 acc 0.65714 roc_auc 0.47917 prc_auc 0.33373[0m
[92maverage training of epoch 16: loss -4.56683 acc 0.65480 roc_auc 0.50465 prc_auc 0.36716[0m
[93maverage test of epoch 16: loss -4.58928 acc 0.65714 roc_auc 0.48098 prc_auc 0.33396[0m
[92maverage training of epoch 17: loss -4.59605 acc 0.65480 roc_auc 0.50429 prc_auc 0.36658[0m
[93maverage test of epoch 17: loss -4.61849 acc 0.65714 roc_auc 0.53170 prc_auc 0.35833[0m
[92maverage training of epoch 18: loss -4.62512 acc 0.65480 roc_auc 0.50431 prc_auc 0.36684[0m
[93maverage test of epoch 18: loss -4.64755 acc 0.65714 roc_auc 0.53125 prc_auc 0.35789[0m
[92maverage training of epoch 19: loss -4.65405 acc 0.65480 roc_auc 0.50437 prc_auc 0.36699[0m
[93maverage test of epoch 19: loss -4.67647 acc 0.65714 roc_auc 0.46286 prc_auc 0.32668[0m
[92maverage training of epoch 20: loss -4.68283 acc 0.65480 roc_auc 0.50378 prc_auc 0.36597[0m
[93maverage test of epoch 20: loss -4.70525 acc 0.65714 roc_auc 0.45743 prc_auc 0.32576[0m
[92maverage training of epoch 21: loss -4.71147 acc 0.65480 roc_auc 0.50370 prc_auc 0.36586[0m
[93maverage test of epoch 21: loss -4.73388 acc 0.65714 roc_auc 0.46558 prc_auc 0.32846[0m
[92maverage training of epoch 22: loss -4.73998 acc 0.65480 roc_auc 0.50325 prc_auc 0.36609[0m
[93maverage test of epoch 22: loss -4.76238 acc 0.65714 roc_auc 0.45018 prc_auc 0.32131[0m
[92maverage training of epoch 23: loss -4.76835 acc 0.65480 roc_auc 0.50291 prc_auc 0.36582[0m
[93maverage test of epoch 23: loss -4.79074 acc 0.65714 roc_auc 0.50906 prc_auc 0.34762[0m
[92maverage training of epoch 24: loss -4.79658 acc 0.65480 roc_auc 0.50275 prc_auc 0.36001[0m
[93maverage test of epoch 24: loss -4.81897 acc 0.65714 roc_auc 0.54348 prc_auc 0.36498[0m
[92maverage training of epoch 25: loss -4.82469 acc 0.65480 roc_auc 0.50207 prc_auc 0.35619[0m
[93maverage test of epoch 25: loss -4.84706 acc 0.65714 roc_auc 0.46558 prc_auc 0.32846[0m
[92maverage training of epoch 26: loss -4.85266 acc 0.65480 roc_auc 0.50140 prc_auc 0.35483[0m
[93maverage test of epoch 26: loss -4.87503 acc 0.65714 roc_auc 0.53080 prc_auc 0.36984[0m
[92maverage training of epoch 27: loss -4.88052 acc 0.65480 roc_auc 0.50109 prc_auc 0.35457[0m
[93maverage test of epoch 27: loss -4.90287 acc 0.65714 roc_auc 0.51359 prc_auc 0.34929[0m
[92maverage training of epoch 28: loss -4.90825 acc 0.65480 roc_auc 0.50073 prc_auc 0.35406[0m
[93maverage test of epoch 28: loss -4.93059 acc 0.65714 roc_auc 0.43750 prc_auc 0.31214[0m
[92maverage training of epoch 29: loss -4.93586 acc 0.65480 roc_auc 0.50042 prc_auc 0.35383[0m
[93maverage test of epoch 29: loss -4.95819 acc 0.65714 roc_auc 0.46558 prc_auc 0.32846[0m
[92maverage training of epoch 30: loss -4.96335 acc 0.65480 roc_auc 0.50050 prc_auc 0.35416[0m
[93maverage test of epoch 30: loss -4.98568 acc 0.65714 roc_auc 0.55299 prc_auc 0.36378[0m
[92maverage training of epoch 31: loss -4.99073 acc 0.65480 roc_auc 0.50034 prc_auc 0.35391[0m
[93maverage test of epoch 31: loss -5.01305 acc 0.65714 roc_auc 0.46558 prc_auc 0.32846[0m
[92maverage training of epoch 32: loss -5.01801 acc 0.65480 roc_auc 0.50014 prc_auc 0.35404[0m
[93maverage test of epoch 32: loss -5.04032 acc 0.65714 roc_auc 0.50996 prc_auc 0.34940[0m
[92maverage training of epoch 33: loss -5.04518 acc 0.65480 roc_auc 0.50031 prc_auc 0.35413[0m
[93maverage test of epoch 33: loss -5.06748 acc 0.65714 roc_auc 0.54438 prc_auc 0.36577[0m
[92maverage training of epoch 34: loss -5.07224 acc 0.65480 roc_auc 0.50011 prc_auc 0.35390[0m
[93maverage test of epoch 34: loss -5.09454 acc 0.65714 roc_auc 0.46558 prc_auc 0.32846[0m
[92maverage training of epoch 35: loss -5.09921 acc 0.65480 roc_auc 0.49955 prc_auc 0.35339[0m
[93maverage test of epoch 35: loss -5.12150 acc 0.65714 roc_auc 0.49366 prc_auc 0.34008[0m
[92maverage training of epoch 36: loss -5.12608 acc 0.65480 roc_auc 0.49955 prc_auc 0.35303[0m
[93maverage test of epoch 36: loss -5.14837 acc 0.65714 roc_auc 0.46558 prc_auc 0.32846[0m
[92maverage training of epoch 37: loss -5.15286 acc 0.65480 roc_auc 0.49933 prc_auc 0.35287[0m
[93maverage test of epoch 37: loss -5.17514 acc 0.65714 roc_auc 0.50000 prc_auc 0.34286[0m
[92maverage training of epoch 38: loss -5.17955 acc 0.65480 roc_auc 0.49908 prc_auc 0.35181[0m
[93maverage test of epoch 38: loss -5.20183 acc 0.65714 roc_auc 0.46558 prc_auc 0.32846[0m
[92maverage training of epoch 39: loss -5.20616 acc 0.65480 roc_auc 0.49896 prc_auc 0.35211[0m
[93maverage test of epoch 39: loss -5.22843 acc 0.65714 roc_auc 0.46558 prc_auc 0.32846[0m
[92maverage training of epoch 40: loss -5.23269 acc 0.65480 roc_auc 0.49852 prc_auc 0.35174[0m
[93maverage test of epoch 40: loss -5.25495 acc 0.65714 roc_auc 0.49366 prc_auc 0.34008[0m
[92maverage training of epoch 41: loss -5.25913 acc 0.65480 roc_auc 0.49843 prc_auc 0.35170[0m
[93maverage test of epoch 41: loss -5.28140 acc 0.65714 roc_auc 0.53442 prc_auc 0.36764[0m
[92maverage training of epoch 42: loss -5.28550 acc 0.65480 roc_auc 0.49807 prc_auc 0.35107[0m
[93maverage test of epoch 42: loss -5.30777 acc 0.65714 roc_auc 0.46558 prc_auc 0.32846[0m
[92maverage training of epoch 43: loss -5.31180 acc 0.65480 roc_auc 0.49810 prc_auc 0.35100[0m
[93maverage test of epoch 43: loss -5.33407 acc 0.65714 roc_auc 0.53442 prc_auc 0.36026[0mUsing backend: pytorch

[92maverage training of epoch 44: loss -5.33803 acc 0.65480 roc_auc 0.49751 prc_auc 0.35049[0m
[93maverage test of epoch 44: loss -5.36030 acc 0.65714 roc_auc 0.50000 prc_auc 0.34286[0m
[92maverage training of epoch 45: loss -5.36420 acc 0.65480 roc_auc 0.49725 prc_auc 0.35034[0m
[93maverage test of epoch 45: loss -5.38646 acc 0.65714 roc_auc 0.46558 prc_auc 0.32846[0m
[92maverage training of epoch 46: loss -5.39030 acc 0.65480 roc_auc 0.49700 prc_auc 0.35020[0m
[93maverage test of epoch 46: loss -5.41256 acc 0.65714 roc_auc 0.47917 prc_auc 0.33373[0m
[92maverage training of epoch 47: loss -5.41634 acc 0.65480 roc_auc 0.49650 prc_auc 0.34939[0m
[93maverage test of epoch 47: loss -5.43861 acc 0.65714 roc_auc 0.46558 prc_auc 0.32846[0m
[92maverage training of epoch 48: loss -5.44233 acc 0.65480 roc_auc 0.49627 prc_auc 0.34897[0m
[93maverage test of epoch 48: loss -5.46459 acc 0.65714 roc_auc 0.44928 prc_auc 0.32169[0m
[92maverage training of epoch 49: loss -5.46826 acc 0.65480 roc_auc 0.49625 prc_auc 0.34944[0m
[93maverage test of epoch 49: loss -5.49052 acc 0.65714 roc_auc 0.50000 prc_auc 0.34286[0m
Training model with dataset, testing using fold 4
use GRU
DfscodeRnn_cls_GRU args.lr: 0.003
[92maverage training of epoch 0: loss -3.73108 acc 0.66192 roc_auc 0.51939 prc_auc 0.41745[0m
[93maverage test of epoch 0: loss -4.52821 acc 0.65714 roc_auc 0.48143 prc_auc 0.33659[0m
[92maverage training of epoch 1: loss -4.65025 acc 0.65480 roc_auc 0.50487 prc_auc 0.35946[0m
[93maverage test of epoch 1: loss -4.72560 acc 0.65714 roc_auc 0.47509 prc_auc 0.33669[0m
[92maverage training of epoch 2: loss -4.76741 acc 0.65480 roc_auc 0.50151 prc_auc 0.35813[0m
[93maverage test of epoch 2: loss -4.81157 acc 0.65714 roc_auc 0.44565 prc_auc 0.32509[0m
[92maverage training of epoch 3: loss -4.82041 acc 0.65480 roc_auc 0.50168 prc_auc 0.35598[0m
[93maverage test of epoch 3: loss -4.84017 acc 0.65714 roc_auc 0.45109 prc_auc 0.32776[0m
[92maverage training of epoch 4: loss -4.84901 acc 0.65480 roc_auc 0.50185 prc_auc 0.35611[0m
[93maverage test of epoch 4: loss -4.86878 acc 0.65714 roc_auc 0.50000 prc_auc 0.34783[0m
[92maverage training of epoch 5: loss -4.87758 acc 0.65480 roc_auc 0.50207 prc_auc 0.35629[0m
[93maverage test of epoch 5: loss -4.89733 acc 0.65714 roc_auc 0.45743 prc_auc 0.32583[0m
[92maverage training of epoch 6: loss -4.90606 acc 0.65480 roc_auc 0.50213 prc_auc 0.35625[0m
[93maverage test of epoch 6: loss -4.92576 acc 0.65714 roc_auc 0.45743 prc_auc 0.32536[0m
[92maverage training of epoch 7: loss -4.93440 acc 0.65480 roc_auc 0.50154 prc_auc 0.35547[0m
[93maverage test of epoch 7: loss -4.95405 acc 0.65714 roc_auc 0.45335 prc_auc 0.32744[0m
[92maverage training of epoch 8: loss -4.96258 acc 0.65480 roc_auc 0.50090 prc_auc 0.35409[0m
[93maverage test of epoch 8: loss -4.98216 acc 0.65714 roc_auc 0.45290 prc_auc 0.32291[0m
[92maverage training of epoch 9: loss -4.99058 acc 0.65480 roc_auc 0.50087 prc_auc 0.35436[0m
[93maverage test of epoch 9: loss -5.01008 acc 0.65714 roc_auc 0.56159 prc_auc 0.38002[0m
[92maverage training of epoch 10: loss -5.01839 acc 0.65480 roc_auc 0.50073 prc_auc 0.35481[0m
[93maverage test of epoch 10: loss -5.03781 acc 0.65714 roc_auc 0.55435 prc_auc 0.37391[0m
[92maverage training of epoch 11: loss -5.04601 acc 0.65480 roc_auc 0.50014 prc_auc 0.35320[0m
[93maverage test of epoch 11: loss -5.06536 acc 0.65714 roc_auc 0.45471 prc_auc 0.32708[0m
[92maverage training of epoch 12: loss -5.07345 acc 0.65480 roc_auc 0.49955 prc_auc 0.35280[0m
[93maverage test of epoch 12: loss -5.09272 acc 0.65714 roc_auc 0.50000 prc_auc 0.34783[0m
[92maverage training of epoch 13: loss -5.10071 acc 0.65480 roc_auc 0.49936 prc_auc 0.35344[0m
[93maverage test of epoch 13: loss -5.11990 acc 0.65714 roc_auc 0.52536 prc_auc 0.35722[0m
[92maverage training of epoch 14: loss -5.12779 acc 0.65480 roc_auc 0.49868 prc_auc 0.35282[0m
[93maverage test of epoch 14: loss -5.14692 acc 0.65714 roc_auc 0.50543 prc_auc 0.34720[0m
[92maverage training of epoch 15: loss -5.15472 acc 0.65480 roc_auc 0.49824 prc_auc 0.35208[0m
[93maverage test of epoch 15: loss -5.17379 acc 0.65714 roc_auc 0.58560 prc_auc 0.39082[0m
[92maverage training of epoch 16: loss -5.18149 acc 0.65480 roc_auc 0.49829 prc_auc 0.35200[0m
[93maverage test of epoch 16: loss -5.20051 acc 0.65714 roc_auc 0.51630 prc_auc 0.35122[0m
[92maverage training of epoch 17: loss -5.20812 acc 0.65480 roc_auc 0.49821 prc_auc 0.35153[0m
[93maverage test of epoch 17: loss -5.22709 acc 0.65714 roc_auc 0.57790 prc_auc 0.38848[0m
[92maverage training of epoch 18: loss -5.23463 acc 0.65480 roc_auc 0.49770 prc_auc 0.35068[0m
[93maverage test of epoch 18: loss -5.25354 acc 0.65714 roc_auc 0.53442 prc_auc 0.36436[0m
[92maverage training of epoch 19: loss -5.26100 acc 0.65480 roc_auc 0.49753 prc_auc 0.35052[0m
[93maverage test of epoch 19: loss -5.27988 acc 0.65714 roc_auc 0.48279 prc_auc 0.33732[0m
[92maverage training of epoch 20: loss -5.28727 acc 0.65480 roc_auc 0.49728 prc_auc 0.35062[0m
[93maverage test of epoch 20: loss -5.30611 acc 0.65714 roc_auc 0.55254 prc_auc 0.37398[0m
[92maverage training of epoch 21: loss -5.31343 acc 0.65480 roc_auc 0.49706 prc_auc 0.35043[0m
[93maverage test of epoch 21: loss -5.33224 acc 0.65714 roc_auc 0.53895 prc_auc 0.37102[0m
[92maverage training of epoch 22: loss -5.33949 acc 0.65480 roc_auc 0.49669 prc_auc 0.34964[0m
[93maverage test of epoch 22: loss -5.35827 acc 0.65714 roc_auc 0.51857 prc_auc 0.35165[0m
[92maverage training of epoch 23: loss -5.36547 acc 0.65480 roc_auc 0.49647 prc_auc 0.34954[0m
[93maverage test of epoch 23: loss -5.38423 acc 0.65714 roc_auc 0.51766 prc_auc 0.35101[0m
[92maverage training of epoch 24: loss -5.39136 acc 0.65480 roc_auc 0.49630 prc_auc 0.34937[0m
[93maverage test of epoch 24: loss -5.41010 acc 0.65714 roc_auc 0.49094 prc_auc 0.33928[0m
[92maverage training of epoch 25: loss -5.41718 acc 0.65480 roc_auc 0.49625 prc_auc 0.34953[0m
[93maverage test of epoch 25: loss -5.43590 acc 0.65714 roc_auc 0.50679 prc_auc 0.34596[0m
[92maverage training of epoch 26: loss -5.44293 acc 0.65480 roc_auc 0.49585 prc_auc 0.34917[0m
[93maverage test of epoch 26: loss -5.46163 acc 0.65714 roc_auc 0.49094 prc_auc 0.33866[0m
[92maverage training of epoch 27: loss -5.46862 acc 0.65480 roc_auc 0.49594 prc_auc 0.34965[0m
[93maverage test of epoch 27: loss -5.48730 acc 0.65714 roc_auc 0.54620 prc_auc 0.36801[0m
[92maverage training of epoch 28: loss -5.49424 acc 0.65480 roc_auc 0.49594 prc_auc 0.34952[0m
[93maverage test of epoch 28: loss -5.51292 acc 0.65714 roc_auc 0.44837 prc_auc 0.32246[0m
[92maverage training of epoch 29: loss -5.51982 acc 0.65480 roc_auc 0.49571 prc_auc 0.34935[0m
[93maverage test of epoch 29: loss -5.53848 acc 0.65714 roc_auc 0.53668 prc_auc 0.36217[0m
[92maverage training of epoch 30: loss -5.54534 acc 0.65480 roc_auc 0.49535 prc_auc 0.34912[0m
[93maverage test of epoch 30: loss -5.56400 acc 0.65714 roc_auc 0.50000 prc_auc 0.34783[0m
[92maverage training of epoch 31: loss -5.57082 acc 0.65480 roc_auc 0.49527 prc_auc 0.35032[0m
[93maverage test of epoch 31: loss -5.58948 acc 0.65714 roc_auc 0.48505 prc_auc 0.33635[0m
[92maverage training of epoch 32: loss -5.59626 acc 0.65480 roc_auc 0.49499 prc_auc 0.34880[0m
[93maverage test of epoch 32: loss -5.61491 acc 0.65714 roc_auc 0.53668 prc_auc 0.36217[0m
[92maverage training of epoch 33: loss -5.62166 acc 0.65480 roc_auc 0.49471 prc_auc 0.34823[0m
[93maverage test of epoch 33: loss -5.64031 acc 0.65714 roc_auc 0.55616 prc_auc 0.37513[0m
[92maverage training of epoch 34: loss -5.64702 acc 0.65480 roc_auc 0.49457 prc_auc 0.34824[0m
[93maverage test of epoch 34: loss -5.66568 acc 0.65714 roc_auc 0.51087 prc_auc 0.34783[0m
[92maverage training of epoch 35: loss -5.67236 acc 0.65480 roc_auc 0.49448 prc_auc 0.34810[0m
[93maverage test of epoch 35: loss -5.69101 acc 0.65714 roc_auc 0.51087 prc_auc 0.34783[0m
[92maverage training of epoch 36: loss -5.69766 acc 0.65480 roc_auc 0.49459 prc_auc 0.34832[0m
[93maverage test of epoch 36: loss -5.71632 acc 0.65714 roc_auc 0.47826 prc_auc 0.33363[0m
[92maverage training of epoch 37: loss -5.72294 acc 0.65480 roc_auc 0.49443 prc_auc 0.34823[0m
[93maverage test of epoch 37: loss -5.74160 acc 0.65714 roc_auc 0.48098 prc_auc 0.33485[0m
[92maverage training of epoch 38: loss -5.74819 acc 0.65480 roc_auc 0.49445 prc_auc 0.34820[0m
[93maverage test of epoch 38: loss -5.76686 acc 0.65714 roc_auc 0.48505 prc_auc 0.33844[0m
[92maverage training of epoch 39: loss -5.77343 acc 0.65480 roc_auc 0.49417 prc_auc 0.34791[0m
[93maverage test of epoch 39: loss -5.79210 acc 0.65714 roc_auc 0.51087 prc_auc 0.34783[0m
[92maverage training of epoch 40: loss -5.79864 acc 0.65480 roc_auc 0.49406 prc_auc 0.34786[0m
[93maverage test of epoch 40: loss -5.81732 acc 0.65714 roc_auc 0.51087 prc_auc 0.34783[0m
[92maverage training of epoch 41: loss -5.82383 acc 0.65480 roc_auc 0.49392 prc_auc 0.34783[0m
[93maverage test of epoch 41: loss -5.84252 acc 0.65714 roc_auc 0.52853 prc_auc 0.35646[0m
[92maverage training of epoch 42: loss -5.84901 acc 0.65480 roc_auc 0.49389 prc_auc 0.34764[0m
[93maverage test of epoch 42: loss -5.86771 acc 0.65714 roc_auc 0.55163 prc_auc 0.40217[0m
[92maverage training of epoch 43: loss -5.87417 acc 0.65480 roc_auc 0.49381 prc_auc 0.34765[0m
[93maverage test of epoch 43: loss -5.89288 acc 0.65714 roc_auc 0.55707 prc_auc 0.37079[0m
[92maverage training of epoch 44: loss -5.89932 acc 0.65480 roc_auc 0.49370 prc_auc 0.34750[0m
[93maverage test of epoch 44: loss -5.91804 acc 0.65714 roc_auc 0.51087 prc_auc 0.34783[0m
[92maverage training of epoch 45: loss -5.92445 acc 0.65480 roc_auc 0.49370 prc_auc 0.34750[0m
[93maverage test of epoch 45: loss -5.94319 acc 0.65714 roc_auc 0.47554 prc_auc 0.33736[0m
[92maverage training of epoch 46: loss -5.94958 acc 0.65480 roc_auc 0.49364 prc_auc 0.34747[0m
[93maverage test of epoch 46: loss -5.96832 acc 0.65714 roc_auc 0.49457 prc_auc 0.34058[0m
[92maverage training of epoch 47: loss -5.97469 acc 0.65480 roc_auc 0.49358 prc_auc 0.34763[0m
[93maverage test of epoch 47: loss -5.99345 acc 0.65714 roc_auc 0.51087 prc_auc 0.34783[0m
[92maverage training of epoch 48: loss -5.99979 acc 0.65480 roc_auc 0.49350 prc_auc 0.34745[0m
[93maverage test of epoch 48: loss -6.01856 acc 0.65714 roc_auc 0.51087 prc_auc 0.34783[0m
[92maverage training of epoch 49: loss -6.02489 acc 0.65480 roc_auc 0.49358 prc_auc 0.34741[0m
[93maverage test of epoch 49: loss -6.04367 acc 0.65714 roc_auc 0.47554 prc_auc 0.33736[0m
Run statistics: 
==== Configuration Settings ====
== Run Settings ==
Model: DFScodeRNN_cls_GRU, Dataset: PTC_FR
num_epochs: 50
learning_rate: 0.003
seed: 1800
k_fold: 5
model: DFScodeRNN_cls_GRU
dataset: PTC_FR

== Model Settings and results ==

Accuracy (avg): 0.65529 ROC_AUC (avg): 0.51795 PRC_AUC (avg): 0.36184 

Average forward propagation time taken(ms): 3.407351671932499
Average backward propagation time taken(ms): 1.2762044560367567

