# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======


torch.cuda.is_available():  True 


*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/results/interpretable_graph_classifications/graphgen/DfsRNN_MUTAG_classification/datasets/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': '/home/FYP/heyu0012/results/interpretable_graph_classifications/graphgen/DfsRNN_MUTAG_classification/datasets/MUTAG/graphs/',
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/results/interpretable_graph_classifications/graphgen/DfsRNN_MUTAG_classification/model_save/DFScodeRNN_cls_MUTAG_2021-01-08-16-10-55/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/results/interpretable_graph_classifications/graphgen/DfsRNN_MUTAG_classification/datasets/MUTAG/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/results/interpretable_graph_classifications/graphgen/DfsRNN_MUTAG_classification/tmp/DFScodeRNN_cls_MUTAG_2021-01-08-16-10-55/',
 'dataset_path': '/home/FYP/heyu0012/results/interpretable_graph_classifications/graphgen/DfsRNN_MUTAG_classification/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'dir_input': '/home/FYP/heyu0012/results/interpretable_graph_classifications/graphgen/DfsRNN_MUTAG_classification/',
 'embedding_size_dfscode_rnn': 8,
 'epochs': 10000,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_MUTAG',
 'gamma': 0.3,
 'gradient_clipping': True,
 'graph_type': 'MUTAG',
 'hidden_size_dfscode_rnn': 4,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'loss_type': 'BCE',
 'lr': 0.003,
 'max_prev_node': None,
 'milestones': [100, 200, 400, 800],
 'min_dfscode_path': '/home/FYP/heyu0012/results/interpretable_graph_classifications/graphgen/DfsRNN_MUTAG_classification/datasets/MUTAG/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/results/interpretable_graph_classifications/graphgen/DfsRNN_MUTAG_classification/datasets/MUTAG/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/results/interpretable_graph_classifications/graphgen/DfsRNN_MUTAG_classification/model_save/',
 'note': 'DFScodeRNN_cls',
 'num_graphs': None,
 'num_layers': 1,
 'num_workers': 8,
 'produce_graphs': False,
 'produce_min_dfscode_tensors': False,
 'produce_min_dfscodes': False,
 'rnn_type': 'LSTM',
 'save_model': True,
 'temp_path': '/home/FYP/heyu0012/results/interpretable_graph_classifications/graphgen/DfsRNN_MUTAG_classification/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/results/interpretable_graph_classifications/graphgen/DfsRNN_MUTAG_classification/tensorboard/',
 'time': '2021-01-08-16-10-55',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 50, 'learning_rate': 0.0001, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'interpretability_methods': {'DeepLIFT': {'enabled': False, 'compare_with_zero_tensor': True, 'compare_with_isomorphic_samples': True, 'number_of_zero_tensor_samples': 3, 'sample_ids': None, 'number_of_isomorphic_sample_pairs': 5}, 'saliency': {'enabled': False, 'number_of_samples': 3, 'sample_ids': None}, 'LayerGradCAM': {'enabled': False, 'number_of_samples': 3, 'sample_ids': None, 'layer': 0, 'assign_attribution': 'hard'}}, 'metrics': {'fidelity': {'enabled': True, 'importance_range': '0.5,1'}, 'contrastivity': {'enabled': True, 'importance_range': '0.5,1'}, 'sparsity': {'enabled': True, 'importance_range': '0.5,1'}}, 'custom_visualisation_options': {'GNN_models': {'DiffPool': {'cluster_nodes': True}}, 'dataset': {'MUTAG': {'custom_mapping': {'0': 'C', '1': 'N', '2': 'O', '3': 'F', '4': 'I', '5': 'Cl', '6': 'Br'}}}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls
Training model with dataset, testing using fold 0
[92maverage training of epoch 0: loss 1.01569 acc 0.33333 roc_auc 0.39980 prc_auc 0.72246[0m
[93maverage test of epoch 0: loss 1.00895 acc 0.34211 roc_auc 0.39231 prc_auc 0.70709[0m
[92maverage training of epoch 1: loss 1.01569 acc 0.33333 roc_auc 0.39980 prc_auc 0.72246[0m
[93maverage test of epoch 1: loss 1.00895 acc 0.34211 roc_auc 0.39231 prc_auc 0.70709[0m
[92maverage training of epoch 2: loss 1.01569 acc 0.33333 roc_auc 0.39980 prc_auc 0.72246[0m
[93maverage test of epoch 2: loss 1.00895 acc 0.34211 roc_auc 0.39231 prc_auc 0.70709[0m
[92maverage training of epoch 3: loss 1.01569 acc 0.33333 roc_auc 0.39980 prc_auc 0.72246[0m
[93maverage test of epoch 3: loss 1.00895 acc 0.34211 roc_auc 0.39231 prc_auc 0.70709[0m
[92maverage training of epoch 4: loss 1.01569 acc 0.33333 roc_auc 0.39980 prc_auc 0.72246[0m
[93maverage test of epoch 4: loss 1.00895 acc 0.34211 roc_auc 0.39231 prc_auc 0.70709[0m
[92maverage training of epoch 5: loss 1.01569 acc 0.33333 roc_auc 0.39980 prc_auc 0.72246[0m
[93maverage test of epoch 5: loss 1.00895 acc 0.34211 roc_auc 0.39231 prc_auc 0.70709[0m
[92maverage training of epoch 6: loss 1.01569 acc 0.33333 roc_auc 0.39980 prc_auc 0.72246[0m
[93maverage test of epoch 6: loss 1.00895 acc 0.34211 roc_auc 0.39231 prc_auc 0.70709[0m
[92maverage training of epoch 7: loss 1.01569 acc 0.33333 roc_auc 0.39980 prc_auc 0.72246[0m
[93maverage test of epoch 7: loss 1.00895 acc 0.34211 roc_auc 0.39231 prc_auc 0.70709[0m
[92maverage training of epoch 8: loss 1.01569 acc 0.33333 roc_auc 0.39980 prc_auc 0.72246[0m
[93maverage test of epoch 8: loss 1.00895 acc 0.34211 roc_auc 0.39231 prc_auc 0.70709[0m
[92maverage training of epoch 9: loss 1.01569 acc 0.33333 roc_auc 0.39980 prc_auc 0.72246[0m
[93maverage test of epoch 9: loss 1.00895 acc 0.34211 roc_auc 0.39231 prc_auc 0.70709[0m
[92maverage training of epoch 10: loss 1.01569 acc 0.33333 roc_auc 0.39980 prc_auc 0.72246[0m
[93maverage test of epoch 10: loss 1.00895 acc 0.34211 roc_auc 0.39231 prc_auc 0.70709[0m
[92maverage training of epoch 11: loss 1.01569 acc 0.33333 roc_auc 0.39980 prc_auc 0.72246[0m
[93maverage test of epoch 11: loss 1.00895 acc 0.34211 roc_auc 0.39231 prc_auc 0.70709[0m
[92maverage training of epoch 12: loss 1.01569 acc 0.33333 roc_auc 0.39980 prc_auc 0.72246[0m
[93maverage test of epoch 12: loss 1.00895 acc 0.34211 roc_auc 0.39231 prc_auc 0.70709[0m
[92maverage training of epoch 13: loss 1.01569 acc 0.33333 roc_auc 0.39980 prc_auc 0.72246[0m
[93maverage test of epoch 13: loss 1.00895 acc 0.34211 roc_auc 0.39231 prc_auc 0.70709[0m
[92maverage training of epoch 14: loss 1.01569 acc 0.33333 roc_auc 0.39980 prc_auc 0.72246[0m
[93maverage test of epoch 14: loss 1.00895 acc 0.34211 roc_auc 0.39231 prc_auc 0.70709[0m
[92maverage training of epoch 15: loss 1.01569 acc 0.33333 roc_auc 0.39980 prc_auc 0.72246[0m
[93maverage test of epoch 15: loss 1.00895 acc 0.34211 roc_auc 0.39231 prc_auc 0.70709[0m
[92maverage training of epoch 16: loss 1.01569 acc 0.33333 roc_auc 0.39980 prc_auc 0.72246[0m
[93maverage test of epoch 16: loss 1.00895 acc 0.34211 roc_auc 0.39231 prc_auc 0.70709[0m
[92maverage training of epoch 17: loss 1.01569 acc 0.33333 roc_auc 0.39980 prc_auc 0.72246[0m
[93maverage test of epoch 17: loss 1.00895 acc 0.34211 roc_auc 0.39231 prc_auc 0.70709[0m
[92maverage training of epoch 18: loss 1.01569 acc 0.33333 roc_auc 0.39980 prc_auc 0.72246[0m
[93maverage test of epoch 18: loss 1.00895 acc 0.34211 roc_auc 0.39231 prc_auc 0.70709[0m
[92maverage training of epoch 19: loss 1.01569 acc 0.33333 roc_auc 0.39980 prc_auc 0.72246[0m
[93maverage test of epoch 19: loss 1.00895 acc 0.34211 roc_auc 0.39231 prc_auc 0.70709[0m
[92maverage training of epoch 20: loss 1.01569 acc 0.33333 roc_auc 0.39980 prc_auc 0.72246[0m
[93maverage test of epoch 20: loss 1.00895 acc 0.34211 roc_auc 0.39231 prc_auc 0.70709[0m
[92maverage training of epoch 21: loss 1.01569 acc 0.33333 roc_auc 0.39980 prc_auc 0.72246[0m
[93maverage test of epoch 21: loss 1.00895 acc 0.34211 roc_auc 0.39231 prc_auc 0.70709[0m
[92maverage training of epoch 22: loss 1.01569 acc 0.33333 roc_auc 0.39980 prc_auc 0.72246[0m
[93maverage test of epoch 22: loss 1.00895 acc 0.34211 roc_auc 0.39231 prc_auc 0.70709[0m
[92maverage training of epoch 23: loss 1.01569 acc 0.33333 roc_auc 0.39980 prc_auc 0.72246[0m
[93maverage test of epoch 23: loss 1.00895 acc 0.34211 roc_auc 0.39231 prc_auc 0.70709[0m
[92maverage training of epoch 24: loss 1.01569 acc 0.33333 roc_auc 0.39980 prc_auc 0.72246[0m
[93maverage test of epoch 24: loss 1.00895 acc 0.34211 roc_auc 0.39231 prc_auc 0.70709[0m
[92maverage training of epoch 25: loss 1.01569 acc 0.33333 roc_auc 0.39980 prc_auc 0.72246[0m
[93maverage test of epoch 25: loss 1.00895 acc 0.34211 roc_auc 0.39231 prc_auc 0.70709[0m
[92maverage training of epoch 26: loss 1.01569 acc 0.33333 roc_auc 0.39980 prc_auc 0.72246[0m
[93maverage test of epoch 26: loss 1.00895 acc 0.34211 roc_auc 0.39231 prc_auc 0.70709[0m
[92maverage training of epoch 27: loss 1.01569 acc 0.33333 roc_auc 0.39980 prc_auc 0.72246[0m
[93maverage test of epoch 27: loss 1.00895 acc 0.34211 roc_auc 0.39231 prc_auc 0.70709[0m
[92maverage training of epoch 28: loss 1.01569 acc 0.33333 roc_auc 0.39980 prc_auc 0.72246[0m
[93maverage test of epoch 28: loss 1.00895 acc 0.34211 roc_auc 0.39231 prc_auc 0.70709[0m
[92maverage training of epoch 29: loss 1.01569 acc 0.33333 roc_auc 0.39980 prc_auc 0.72246[0m
[93maverage test of epoch 29: loss 1.00895 acc 0.34211 roc_auc 0.39231 prc_auc 0.70709[0m
[92maverage training of epoch 30: loss 1.01569 acc 0.33333 roc_auc 0.39980 prc_auc 0.72246[0m
[93maverage test of epoch 30: loss 1.00895 acc 0.34211 roc_auc 0.39231 prc_auc 0.70709[0m
[92maverage training of epoch 31: loss 1.01569 acc 0.33333 roc_auc 0.39980 prc_auc 0.72246[0m
[93maverage test of epoch 31: loss 1.00895 acc 0.34211 roc_auc 0.39231 prc_auc 0.70709[0m
[92maverage training of epoch 32: loss 1.01569 acc 0.33333 roc_auc 0.39980 prc_auc 0.72246[0m
[93maverage test of epoch 32: loss 1.00895 acc 0.34211 roc_auc 0.39231 prc_auc 0.70709[0m
[92maverage training of epoch 33: loss 1.01569 acc 0.33333 roc_auc 0.39980 prc_auc 0.72246[0m
[93maverage test of epoch 33: loss 1.00895 acc 0.34211 roc_auc 0.39231 prc_auc 0.70709[0m
[92maverage training of epoch 34: loss 1.01569 acc 0.33333 roc_auc 0.39980 prc_auc 0.72246[0m
[93maverage test of epoch 34: loss 1.00895 acc 0.34211 roc_auc 0.39231 prc_auc 0.70709[0m
[92maverage training of epoch 35: loss 1.01569 acc 0.33333 roc_auc 0.39980 prc_auc 0.72246[0m
[93maverage test of epoch 35: loss 1.00895 acc 0.34211 roc_auc 0.39231 prc_auc 0.70709[0m
[92maverage training of epoch 36: loss 1.01569 acc 0.33333 roc_auc 0.39980 prc_auc 0.72246[0m
[93maverage test of epoch 36: loss 1.00895 acc 0.34211 roc_auc 0.39231 prc_auc 0.70709[0m
[92maverage training of epoch 37: loss 1.01569 acc 0.33333 roc_auc 0.39980 prc_auc 0.72246[0m
[93maverage test of epoch 37: loss 1.00895 acc 0.34211 roc_auc 0.39231 prc_auc 0.70709[0m
[92maverage training of epoch 38: loss 1.01569 acc 0.33333 roc_auc 0.39980 prc_auc 0.72246[0m
[93maverage test of epoch 38: loss 1.00895 acc 0.34211 roc_auc 0.39231 prc_auc 0.70709[0m
[92maverage training of epoch 39: loss 1.01569 acc 0.33333 roc_auc 0.39980 prc_auc 0.72246[0m
[93maverage test of epoch 39: loss 1.00895 acc 0.34211 roc_auc 0.39231 prc_auc 0.70709[0m
[92maverage training of epoch 40: loss 1.01569 acc 0.33333 roc_auc 0.39980 prc_auc 0.72246[0m
[93maverage test of epoch 40: loss 1.00895 acc 0.34211 roc_auc 0.39231 prc_auc 0.70709[0m
[92maverage training of epoch 41: loss 1.01569 acc 0.33333 roc_auc 0.39980 prc_auc 0.72246[0m
[93maverage test of epoch 41: loss 1.00895 acc 0.34211 roc_auc 0.39231 prc_auc 0.70709[0m
[92maverage training of epoch 42: loss 1.01569 acc 0.33333 roc_auc 0.39980 prc_auc 0.72246[0m
[93maverage test of epoch 42: loss 1.00895 acc 0.34211 roc_auc 0.39231 prc_auc 0.70709[0m
[92maverage training of epoch 43: loss 1.01569 acc 0.33333 roc_auc 0.39980 prc_auc 0.72246[0m
[93maverage test of epoch 43: loss 1.00895 acc 0.34211 roc_auc 0.39231 prc_auc 0.70709[0m
[92maverage training of epoch 44: loss 1.01569 acc 0.33333 roc_auc 0.39980 prc_auc 0.72246[0m
[93maverage test of epoch 44: loss 1.00895 acc 0.34211 roc_auc 0.39231 prc_auc 0.70709[0m
[92maverage training of epoch 45: loss 1.01569 acc 0.33333 roc_auc 0.39980 prc_auc 0.72246[0m
[93maverage test of epoch 45: loss 1.00895 acc 0.34211 roc_auc 0.39231 prc_auc 0.70709[0m
[92maverage training of epoch 46: loss 1.01569 acc 0.33333 roc_auc 0.39980 prc_auc 0.72246[0m
[93maverage test of epoch 46: loss 1.00895 acc 0.34211 roc_auc 0.39231 prc_auc 0.70709[0m
[92maverage training of epoch 47: loss 1.01569 acc 0.33333 roc_auc 0.39980 prc_auc 0.72246[0m
[93maverage test of epoch 47: loss 1.00895 acc 0.34211 roc_auc 0.39231 prc_auc 0.70709[0m
[92maverage training of epoch 48: loss 1.01569 acc 0.33333 roc_auc 0.39980 prc_auc 0.72246[0m
[93maverage test of epoch 48: loss 1.00895 acc 0.34211 roc_auc 0.39231 prc_auc 0.70709[0m
[92maverage training of epoch 49: loss 1.01569 acc 0.33333 roc_auc 0.39980 prc_auc 0.72246[0m
[93maverage test of epoch 49: loss 1.00895 acc 0.34211 roc_auc 0.39231 prc_auc 0.70709[0m
Training model with dataset, testing using fold 1
[92maverage training of epoch 0: loss 0.82716 acc 0.33333 roc_auc 0.73190 prc_auc 0.88923[0m
[93maverage test of epoch 0: loss 0.81598 acc 0.34211 roc_auc 0.72615 prc_auc 0.87807[0m
[92maverage training of epoch 1: loss 0.82716 acc 0.33333 roc_auc 0.73190 prc_auc 0.88923[0m
[93maverage test of epoch 1: loss 0.81598 acc 0.34211 roc_auc 0.72615 prc_auc 0.87807[0m
[92maverage training of epoch 2: loss 0.82716 acc 0.33333 roc_auc 0.73190 prc_auc 0.88923[0m
[93maverage test of epoch 2: loss 0.81598 acc 0.34211 roc_auc 0.72615 prc_auc 0.87807[0m
[92maverage training of epoch 3: loss 0.82716 acc 0.33333 roc_auc 0.73190 prc_auc 0.88923[0m
[93maverage test of epoch 3: loss 0.81598 acc 0.34211 roc_auc 0.72615 prc_auc 0.87807[0m
[92maverage training of epoch 4: loss 0.82716 acc 0.33333 roc_auc 0.73190 prc_auc 0.88923[0m
[93maverage test of epoch 4: loss 0.81598 acc 0.34211 roc_auc 0.72615 prc_auc 0.87807[0m
[92maverage training of epoch 5: loss 0.82716 acc 0.33333 roc_auc 0.73190 prc_auc 0.88923[0m
[93maverage test of epoch 5: loss 0.81598 acc 0.34211 roc_auc 0.72615 prc_auc 0.87807[0m
[92maverage training of epoch 6: loss 0.82716 acc 0.33333 roc_auc 0.73190 prc_auc 0.88923[0m
[93maverage test of epoch 6: loss 0.81598 acc 0.34211 roc_auc 0.72615 prc_auc 0.87807[0m
[92maverage training of epoch 7: loss 0.82716 acc 0.33333 roc_auc 0.73190 prc_auc 0.88923[0m
[93maverage test of epoch 7: loss 0.81598 acc 0.34211 roc_auc 0.72615 prc_auc 0.87807[0m
[92maverage training of epoch 8: loss 0.82716 acc 0.33333 roc_auc 0.73190 prc_auc 0.88923[0m
[93maverage test of epoch 8: loss 0.81598 acc 0.34211 roc_auc 0.72615 prc_auc 0.87807[0m
[92maverage training of epoch 9: loss 0.82716 acc 0.33333 roc_auc 0.73190 prc_auc 0.88923[0m
[93maverage test of epoch 9: loss 0.81598 acc 0.34211 roc_auc 0.72615 prc_auc 0.87807[0m
[92maverage training of epoch 10: loss 0.82716 acc 0.33333 roc_auc 0.73190 prc_auc 0.88923[0m
[93maverage test of epoch 10: loss 0.81598 acc 0.34211 roc_auc 0.72615 prc_auc 0.87807[0m
[92maverage training of epoch 11: loss 0.82716 acc 0.33333 roc_auc 0.73190 prc_auc 0.88923[0m
[93maverage test of epoch 11: loss 0.81598 acc 0.34211 roc_auc 0.72615 prc_auc 0.87807[0m
[92maverage training of epoch 12: loss 0.82716 acc 0.33333 roc_auc 0.73190 prc_auc 0.88923[0m
[93maverage test of epoch 12: loss 0.81598 acc 0.34211 roc_auc 0.72615 prc_auc 0.87807[0m
[92maverage training of epoch 13: loss 0.82716 acc 0.33333 roc_auc 0.73190 prc_auc 0.88923[0m
[93maverage test of epoch 13: loss 0.81598 acc 0.34211 roc_auc 0.72615 prc_auc 0.87807[0m
[92maverage training of epoch 14: loss 0.82716 acc 0.33333 roc_auc 0.73190 prc_auc 0.88923[0m
[93maverage test of epoch 14: loss 0.81598 acc 0.34211 roc_auc 0.72615 prc_auc 0.87807[0m
[92maverage training of epoch 15: loss 0.82716 acc 0.33333 roc_auc 0.73190 prc_auc 0.88923[0m
[93maverage test of epoch 15: loss 0.81598 acc 0.34211 roc_auc 0.72615 prc_auc 0.87807[0m
[92maverage training of epoch 16: loss 0.82716 acc 0.33333 roc_auc 0.73190 prc_auc 0.88923[0m
[93maverage test of epoch 16: loss 0.81598 acc 0.34211 roc_auc 0.72615 prc_auc 0.87807[0m
[92maverage training of epoch 17: loss 0.82716 acc 0.33333 roc_auc 0.73190 prc_auc 0.88923[0m
[93maverage test of epoch 17: loss 0.81598 acc 0.34211 roc_auc 0.72615 prc_auc 0.87807[0m
[92maverage training of epoch 18: loss 0.82716 acc 0.33333 roc_auc 0.73190 prc_auc 0.88923[0m
[93maverage test of epoch 18: loss 0.81598 acc 0.34211 roc_auc 0.72615 prc_auc 0.87807[0m
[92maverage training of epoch 19: loss 0.82716 acc 0.33333 roc_auc 0.73190 prc_auc 0.88923[0m
[93maverage test of epoch 19: loss 0.81598 acc 0.34211 roc_auc 0.72615 prc_auc 0.87807[0m
[92maverage training of epoch 20: loss 0.82716 acc 0.33333 roc_auc 0.73190 prc_auc 0.88923[0m
[93maverage test of epoch 20: loss 0.81598 acc 0.34211 roc_auc 0.72615 prc_auc 0.87807[0m
[92maverage training of epoch 21: loss 0.82716 acc 0.33333 roc_auc 0.73190 prc_auc 0.88923[0m
[93maverage test of epoch 21: loss 0.81598 acc 0.34211 roc_auc 0.72615 prc_auc 0.87807[0m
[92maverage training of epoch 22: loss 0.82716 acc 0.33333 roc_auc 0.73190 prc_auc 0.88923[0m
[93maverage test of epoch 22: loss 0.81598 acc 0.34211 roc_auc 0.72615 prc_auc 0.87807[0m
[92maverage training of epoch 23: loss 0.82716 acc 0.33333 roc_auc 0.73190 prc_auc 0.88923[0m
[93maverage test of epoch 23: loss 0.81598 acc 0.34211 roc_auc 0.72615 prc_auc 0.87807[0m
[92maverage training of epoch 24: loss 0.82716 acc 0.33333 roc_auc 0.73190 prc_auc 0.88923[0m
[93maverage test of epoch 24: loss 0.81598 acc 0.34211 roc_auc 0.72615 prc_auc 0.87807[0m
[92maverage training of epoch 25: loss 0.82716 acc 0.33333 roc_auc 0.73190 prc_auc 0.88923[0m
[93maverage test of epoch 25: loss 0.81598 acc 0.34211 roc_auc 0.72615 prc_auc 0.87807[0m
[92maverage training of epoch 26: loss 0.82716 acc 0.33333 roc_auc 0.73190 prc_auc 0.88923[0m
[93maverage test of epoch 26: loss 0.81598 acc 0.34211 roc_auc 0.72615 prc_auc 0.87807[0m
[92maverage training of epoch 27: loss 0.82716 acc 0.33333 roc_auc 0.73190 prc_auc 0.88923[0m
[93maverage test of epoch 27: loss 0.81598 acc 0.34211 roc_auc 0.72615 prc_auc 0.87807[0m
[92maverage training of epoch 28: loss 0.82716 acc 0.33333 roc_auc 0.73190 prc_auc 0.88923[0m
[93maverage test of epoch 28: loss 0.81598 acc 0.34211 roc_auc 0.72615 prc_auc 0.87807[0m
[92maverage training of epoch 29: loss 0.82716 acc 0.33333 roc_auc 0.73190 prc_auc 0.88923[0m
[93maverage test of epoch 29: loss 0.81598 acc 0.34211 roc_auc 0.72615 prc_auc 0.87807[0m
[92maverage training of epoch 30: loss 0.82716 acc 0.33333 roc_auc 0.73190 prc_auc 0.88923[0m
[93maverage test of epoch 30: loss 0.81598 acc 0.34211 roc_auc 0.72615 prc_auc 0.87807[0m
[92maverage training of epoch 31: loss 0.82716 acc 0.33333 roc_auc 0.73190 prc_auc 0.88923[0m
[93maverage test of epoch 31: loss 0.81598 acc 0.34211 roc_auc 0.72615 prc_auc 0.87807[0m
[92maverage training of epoch 32: loss 0.82716 acc 0.33333 roc_auc 0.73190 prc_auc 0.88923[0m
[93maverage test of epoch 32: loss 0.81598 acc 0.34211 roc_auc 0.72615 prc_auc 0.87807[0m
[92maverage training of epoch 33: loss 0.82716 acc 0.33333 roc_auc 0.73190 prc_auc 0.88923[0m
[93maverage test of epoch 33: loss 0.81598 acc 0.34211 roc_auc 0.72615 prc_auc 0.87807[0m
[92maverage training of epoch 34: loss 0.82716 acc 0.33333 roc_auc 0.73190 prc_auc 0.88923[0m
[93maverage test of epoch 34: loss 0.81598 acc 0.34211 roc_auc 0.72615 prc_auc 0.87807[0m
[92maverage training of epoch 35: loss 0.82716 acc 0.33333 roc_auc 0.73190 prc_auc 0.88923[0m
[93maverage test of epoch 35: loss 0.81598 acc 0.34211 roc_auc 0.72615 prc_auc 0.87807[0m
[92maverage training of epoch 36: loss 0.82716 acc 0.33333 roc_auc 0.73190 prc_auc 0.88923[0m
[93maverage test of epoch 36: loss 0.81598 acc 0.34211 roc_auc 0.72615 prc_auc 0.87807[0mUsing backend: pytorch
/home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
/home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
/home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
/home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
/home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))

[92maverage training of epoch 37: loss 0.82716 acc 0.33333 roc_auc 0.73190 prc_auc 0.88923[0m
[93maverage test of epoch 37: loss 0.81598 acc 0.34211 roc_auc 0.72615 prc_auc 0.87807[0m
[92maverage training of epoch 38: loss 0.82716 acc 0.33333 roc_auc 0.73190 prc_auc 0.88923[0m
[93maverage test of epoch 38: loss 0.81598 acc 0.34211 roc_auc 0.72615 prc_auc 0.87807[0m
[92maverage training of epoch 39: loss 0.82716 acc 0.33333 roc_auc 0.73190 prc_auc 0.88923[0m
[93maverage test of epoch 39: loss 0.81598 acc 0.34211 roc_auc 0.72615 prc_auc 0.87807[0m
[92maverage training of epoch 40: loss 0.82716 acc 0.33333 roc_auc 0.73190 prc_auc 0.88923[0m
[93maverage test of epoch 40: loss 0.81598 acc 0.34211 roc_auc 0.72615 prc_auc 0.87807[0m
[92maverage training of epoch 41: loss 0.82716 acc 0.33333 roc_auc 0.73190 prc_auc 0.88923[0m
[93maverage test of epoch 41: loss 0.81598 acc 0.34211 roc_auc 0.72615 prc_auc 0.87807[0m
[92maverage training of epoch 42: loss 0.82716 acc 0.33333 roc_auc 0.73190 prc_auc 0.88923[0m
[93maverage test of epoch 42: loss 0.81598 acc 0.34211 roc_auc 0.72615 prc_auc 0.87807[0m
[92maverage training of epoch 43: loss 0.82716 acc 0.33333 roc_auc 0.73190 prc_auc 0.88923[0m
[93maverage test of epoch 43: loss 0.81598 acc 0.34211 roc_auc 0.72615 prc_auc 0.87807[0m
[92maverage training of epoch 44: loss 0.82716 acc 0.33333 roc_auc 0.73190 prc_auc 0.88923[0m
[93maverage test of epoch 44: loss 0.81598 acc 0.34211 roc_auc 0.72615 prc_auc 0.87807[0m
[92maverage training of epoch 45: loss 0.82716 acc 0.33333 roc_auc 0.73190 prc_auc 0.88923[0m
[93maverage test of epoch 45: loss 0.81598 acc 0.34211 roc_auc 0.72615 prc_auc 0.87807[0m
[92maverage training of epoch 46: loss 0.82716 acc 0.33333 roc_auc 0.73190 prc_auc 0.88923[0m
[93maverage test of epoch 46: loss 0.81598 acc 0.34211 roc_auc 0.72615 prc_auc 0.87807[0m
[92maverage training of epoch 47: loss 0.82716 acc 0.33333 roc_auc 0.73190 prc_auc 0.88923[0m
[93maverage test of epoch 47: loss 0.81598 acc 0.34211 roc_auc 0.72615 prc_auc 0.87807[0m
[92maverage training of epoch 48: loss 0.82716 acc 0.33333 roc_auc 0.73190 prc_auc 0.88923[0m
[93maverage test of epoch 48: loss 0.81598 acc 0.34211 roc_auc 0.72615 prc_auc 0.87807[0m
[92maverage training of epoch 49: loss 0.82716 acc 0.33333 roc_auc 0.73190 prc_auc 0.88923[0m
[93maverage test of epoch 49: loss 0.81598 acc 0.34211 roc_auc 0.72615 prc_auc 0.87807[0m
Training model with dataset, testing using fold 2
[92maverage training of epoch 0: loss 0.91594 acc 0.33333 roc_auc 0.11950 prc_auc 0.47839[0m
[93maverage test of epoch 0: loss 0.90766 acc 0.34211 roc_auc 0.05538 prc_auc 0.46472[0m
[92maverage training of epoch 1: loss 0.91594 acc 0.33333 roc_auc 0.11950 prc_auc 0.47839[0m
[93maverage test of epoch 1: loss 0.90766 acc 0.34211 roc_auc 0.05538 prc_auc 0.46472[0m
[92maverage training of epoch 2: loss 0.91594 acc 0.33333 roc_auc 0.11950 prc_auc 0.47839[0m
[93maverage test of epoch 2: loss 0.90766 acc 0.34211 roc_auc 0.05538 prc_auc 0.46472[0m
[92maverage training of epoch 3: loss 0.91594 acc 0.33333 roc_auc 0.11950 prc_auc 0.47839[0m
[93maverage test of epoch 3: loss 0.90766 acc 0.34211 roc_auc 0.05538 prc_auc 0.46472[0m
[92maverage training of epoch 4: loss 0.91594 acc 0.33333 roc_auc 0.11950 prc_auc 0.47839[0m
[93maverage test of epoch 4: loss 0.90766 acc 0.34211 roc_auc 0.05538 prc_auc 0.46472[0m
[92maverage training of epoch 5: loss 0.91594 acc 0.33333 roc_auc 0.11950 prc_auc 0.47839[0m
[93maverage test of epoch 5: loss 0.90766 acc 0.34211 roc_auc 0.05538 prc_auc 0.46472[0m
[92maverage training of epoch 6: loss 0.91594 acc 0.33333 roc_auc 0.11950 prc_auc 0.47839[0m
[93maverage test of epoch 6: loss 0.90766 acc 0.34211 roc_auc 0.05538 prc_auc 0.46472[0m
[92maverage training of epoch 7: loss 0.91594 acc 0.33333 roc_auc 0.11950 prc_auc 0.47839[0m
[93maverage test of epoch 7: loss 0.90766 acc 0.34211 roc_auc 0.05538 prc_auc 0.46472[0m
[92maverage training of epoch 8: loss 0.91594 acc 0.33333 roc_auc 0.11950 prc_auc 0.47839[0m
[93maverage test of epoch 8: loss 0.90766 acc 0.34211 roc_auc 0.05538 prc_auc 0.46472[0m
[92maverage training of epoch 9: loss 0.91594 acc 0.33333 roc_auc 0.11950 prc_auc 0.47839[0m
[93maverage test of epoch 9: loss 0.90766 acc 0.34211 roc_auc 0.05538 prc_auc 0.46472[0m
[92maverage training of epoch 10: loss 0.91594 acc 0.33333 roc_auc 0.11950 prc_auc 0.47839[0m
[93maverage test of epoch 10: loss 0.90766 acc 0.34211 roc_auc 0.05538 prc_auc 0.46472[0m
[92maverage training of epoch 11: loss 0.91594 acc 0.33333 roc_auc 0.11950 prc_auc 0.47839[0m
[93maverage test of epoch 11: loss 0.90766 acc 0.34211 roc_auc 0.05538 prc_auc 0.46472[0m
[92maverage training of epoch 12: loss 0.91594 acc 0.33333 roc_auc 0.11950 prc_auc 0.47839[0m
[93maverage test of epoch 12: loss 0.90766 acc 0.34211 roc_auc 0.05538 prc_auc 0.46472[0m
[92maverage training of epoch 13: loss 0.91594 acc 0.33333 roc_auc 0.11950 prc_auc 0.47839[0m
[93maverage test of epoch 13: loss 0.90766 acc 0.34211 roc_auc 0.05538 prc_auc 0.46472[0m
[92maverage training of epoch 14: loss 0.91594 acc 0.33333 roc_auc 0.11950 prc_auc 0.47839[0m
[93maverage test of epoch 14: loss 0.90766 acc 0.34211 roc_auc 0.05538 prc_auc 0.46472[0m
[92maverage training of epoch 15: loss 0.91594 acc 0.33333 roc_auc 0.11950 prc_auc 0.47839[0m
[93maverage test of epoch 15: loss 0.90766 acc 0.34211 roc_auc 0.05538 prc_auc 0.46472[0m
[92maverage training of epoch 16: loss 0.91594 acc 0.33333 roc_auc 0.11950 prc_auc 0.47839[0m
[93maverage test of epoch 16: loss 0.90766 acc 0.34211 roc_auc 0.05538 prc_auc 0.46472[0m
[92maverage training of epoch 17: loss 0.91594 acc 0.33333 roc_auc 0.11950 prc_auc 0.47839[0m
[93maverage test of epoch 17: loss 0.90766 acc 0.34211 roc_auc 0.05538 prc_auc 0.46472[0m
[92maverage training of epoch 18: loss 0.91594 acc 0.33333 roc_auc 0.11950 prc_auc 0.47839[0m
[93maverage test of epoch 18: loss 0.90766 acc 0.34211 roc_auc 0.05538 prc_auc 0.46472[0m
[92maverage training of epoch 19: loss 0.91594 acc 0.33333 roc_auc 0.11950 prc_auc 0.47839[0m
[93maverage test of epoch 19: loss 0.90766 acc 0.34211 roc_auc 0.05538 prc_auc 0.46472[0m
[92maverage training of epoch 20: loss 0.91594 acc 0.33333 roc_auc 0.11950 prc_auc 0.47839[0m
[93maverage test of epoch 20: loss 0.90766 acc 0.34211 roc_auc 0.05538 prc_auc 0.46472[0m
[92maverage training of epoch 21: loss 0.91594 acc 0.33333 roc_auc 0.11950 prc_auc 0.47839[0m
[93maverage test of epoch 21: loss 0.90766 acc 0.34211 roc_auc 0.05538 prc_auc 0.46472[0m
[92maverage training of epoch 22: loss 0.91594 acc 0.33333 roc_auc 0.11950 prc_auc 0.47839[0m
[93maverage test of epoch 22: loss 0.90766 acc 0.34211 roc_auc 0.05538 prc_auc 0.46472[0m
[92maverage training of epoch 23: loss 0.91594 acc 0.33333 roc_auc 0.11950 prc_auc 0.47839[0m
[93maverage test of epoch 23: loss 0.90766 acc 0.34211 roc_auc 0.05538 prc_auc 0.46472[0m
[92maverage training of epoch 24: loss 0.91594 acc 0.33333 roc_auc 0.11950 prc_auc 0.47839[0m
[93maverage test of epoch 24: loss 0.90766 acc 0.34211 roc_auc 0.05538 prc_auc 0.46472[0m
[92maverage training of epoch 25: loss 0.91594 acc 0.33333 roc_auc 0.11950 prc_auc 0.47839[0m
[93maverage test of epoch 25: loss 0.90766 acc 0.34211 roc_auc 0.05538 prc_auc 0.46472[0m
[92maverage training of epoch 26: loss 0.91594 acc 0.33333 roc_auc 0.11950 prc_auc 0.47839[0m
[93maverage test of epoch 26: loss 0.90766 acc 0.34211 roc_auc 0.05538 prc_auc 0.46472[0m
[92maverage training of epoch 27: loss 0.91594 acc 0.33333 roc_auc 0.11950 prc_auc 0.47839[0m
[93maverage test of epoch 27: loss 0.90766 acc 0.34211 roc_auc 0.05538 prc_auc 0.46472[0m
[92maverage training of epoch 28: loss 0.91594 acc 0.33333 roc_auc 0.11950 prc_auc 0.47839[0m
[93maverage test of epoch 28: loss 0.90766 acc 0.34211 roc_auc 0.05538 prc_auc 0.46472[0m
[92maverage training of epoch 29: loss 0.91594 acc 0.33333 roc_auc 0.11950 prc_auc 0.47839[0m
[93maverage test of epoch 29: loss 0.90766 acc 0.34211 roc_auc 0.05538 prc_auc 0.46472[0m
[92maverage training of epoch 30: loss 0.91594 acc 0.33333 roc_auc 0.11950 prc_auc 0.47839[0m
[93maverage test of epoch 30: loss 0.90766 acc 0.34211 roc_auc 0.05538 prc_auc 0.46472[0m
[92maverage training of epoch 31: loss 0.91594 acc 0.33333 roc_auc 0.11950 prc_auc 0.47839[0m
[93maverage test of epoch 31: loss 0.90766 acc 0.34211 roc_auc 0.05538 prc_auc 0.46472[0m
[92maverage training of epoch 32: loss 0.91594 acc 0.33333 roc_auc 0.11950 prc_auc 0.47839[0m
[93maverage test of epoch 32: loss 0.90766 acc 0.34211 roc_auc 0.05538 prc_auc 0.46472[0m
[92maverage training of epoch 33: loss 0.91594 acc 0.33333 roc_auc 0.11950 prc_auc 0.47839[0m
[93maverage test of epoch 33: loss 0.90766 acc 0.34211 roc_auc 0.05538 prc_auc 0.46472[0m
[92maverage training of epoch 34: loss 0.91594 acc 0.33333 roc_auc 0.11950 prc_auc 0.47839[0m
[93maverage test of epoch 34: loss 0.90766 acc 0.34211 roc_auc 0.05538 prc_auc 0.46472[0m
[92maverage training of epoch 35: loss 0.91594 acc 0.33333 roc_auc 0.11950 prc_auc 0.47839[0m
[93maverage test of epoch 35: loss 0.90766 acc 0.34211 roc_auc 0.05538 prc_auc 0.46472[0m
[92maverage training of epoch 36: loss 0.91594 acc 0.33333 roc_auc 0.11950 prc_auc 0.47839[0m
[93maverage test of epoch 36: loss 0.90766 acc 0.34211 roc_auc 0.05538 prc_auc 0.46472[0m
[92maverage training of epoch 37: loss 0.91594 acc 0.33333 roc_auc 0.11950 prc_auc 0.47839[0m
[93maverage test of epoch 37: loss 0.90766 acc 0.34211 roc_auc 0.05538 prc_auc 0.46472[0m
[92maverage training of epoch 38: loss 0.91594 acc 0.33333 roc_auc 0.11950 prc_auc 0.47839[0m
[93maverage test of epoch 38: loss 0.90766 acc 0.34211 roc_auc 0.05538 prc_auc 0.46472[0m
[92maverage training of epoch 39: loss 0.91594 acc 0.33333 roc_auc 0.11950 prc_auc 0.47839[0m
[93maverage test of epoch 39: loss 0.90766 acc 0.34211 roc_auc 0.05538 prc_auc 0.46472[0m
[92maverage training of epoch 40: loss 0.91594 acc 0.33333 roc_auc 0.11950 prc_auc 0.47839[0m
[93maverage test of epoch 40: loss 0.90766 acc 0.34211 roc_auc 0.05538 prc_auc 0.46472[0m
[92maverage training of epoch 41: loss 0.91594 acc 0.33333 roc_auc 0.11950 prc_auc 0.47839[0m
[93maverage test of epoch 41: loss 0.90766 acc 0.34211 roc_auc 0.05538 prc_auc 0.46472[0m
[92maverage training of epoch 42: loss 0.91594 acc 0.33333 roc_auc 0.11950 prc_auc 0.47839[0m
[93maverage test of epoch 42: loss 0.90766 acc 0.34211 roc_auc 0.05538 prc_auc 0.46472[0m
[92maverage training of epoch 43: loss 0.91594 acc 0.33333 roc_auc 0.11950 prc_auc 0.47839[0m
[93maverage test of epoch 43: loss 0.90766 acc 0.34211 roc_auc 0.05538 prc_auc 0.46472[0m
[92maverage training of epoch 44: loss 0.91594 acc 0.33333 roc_auc 0.11950 prc_auc 0.47839[0m
[93maverage test of epoch 44: loss 0.90766 acc 0.34211 roc_auc 0.05538 prc_auc 0.46472[0m
[92maverage training of epoch 45: loss 0.91594 acc 0.33333 roc_auc 0.11950 prc_auc 0.47839[0m
[93maverage test of epoch 45: loss 0.90766 acc 0.34211 roc_auc 0.05538 prc_auc 0.46472[0m
[92maverage training of epoch 46: loss 0.91594 acc 0.33333 roc_auc 0.11950 prc_auc 0.47839[0m
[93maverage test of epoch 46: loss 0.90766 acc 0.34211 roc_auc 0.05538 prc_auc 0.46472[0m
[92maverage training of epoch 47: loss 0.91594 acc 0.33333 roc_auc 0.11950 prc_auc 0.47839[0m
[93maverage test of epoch 47: loss 0.90766 acc 0.34211 roc_auc 0.05538 prc_auc 0.46472[0m
[92maverage training of epoch 48: loss 0.91594 acc 0.33333 roc_auc 0.11950 prc_auc 0.47839[0m
[93maverage test of epoch 48: loss 0.90766 acc 0.34211 roc_auc 0.05538 prc_auc 0.46472[0m
[92maverage training of epoch 49: loss 0.91594 acc 0.33333 roc_auc 0.11950 prc_auc 0.47839[0m
[93maverage test of epoch 49: loss 0.90766 acc 0.34211 roc_auc 0.05538 prc_auc 0.46472[0m
Training model with dataset, testing using fold 3
[92maverage training of epoch 0: loss 1.15274 acc 0.33775 roc_auc 0.10069 prc_auc 0.46981[0m
[93maverage test of epoch 0: loss 1.16870 acc 0.32432 roc_auc 0.11000 prc_auc 0.50089[0m
[92maverage training of epoch 1: loss 1.15274 acc 0.33775 roc_auc 0.10069 prc_auc 0.46981[0m
[93maverage test of epoch 1: loss 1.16870 acc 0.32432 roc_auc 0.11000 prc_auc 0.50089[0m
[92maverage training of epoch 2: loss 1.15274 acc 0.33775 roc_auc 0.10069 prc_auc 0.46981[0m
[93maverage test of epoch 2: loss 1.16870 acc 0.32432 roc_auc 0.11000 prc_auc 0.50089[0m
[92maverage training of epoch 3: loss 1.15274 acc 0.33775 roc_auc 0.10069 prc_auc 0.46981[0m
[93maverage test of epoch 3: loss 1.16870 acc 0.32432 roc_auc 0.11000 prc_auc 0.50089[0m
[92maverage training of epoch 4: loss 1.15274 acc 0.33775 roc_auc 0.10069 prc_auc 0.46981[0m
[93maverage test of epoch 4: loss 1.16870 acc 0.32432 roc_auc 0.11000 prc_auc 0.50089[0m
[92maverage training of epoch 5: loss 1.15274 acc 0.33775 roc_auc 0.10069 prc_auc 0.46981[0m
[93maverage test of epoch 5: loss 1.16870 acc 0.32432 roc_auc 0.11000 prc_auc 0.50089[0m
[92maverage training of epoch 6: loss 1.15274 acc 0.33775 roc_auc 0.10069 prc_auc 0.46981[0m
[93maverage test of epoch 6: loss 1.16870 acc 0.32432 roc_auc 0.11000 prc_auc 0.50089[0m
[92maverage training of epoch 7: loss 1.15274 acc 0.33775 roc_auc 0.10069 prc_auc 0.46981[0m
[93maverage test of epoch 7: loss 1.16870 acc 0.32432 roc_auc 0.11000 prc_auc 0.50089[0m
[92maverage training of epoch 8: loss 1.15274 acc 0.33775 roc_auc 0.10069 prc_auc 0.46981[0m
[93maverage test of epoch 8: loss 1.16870 acc 0.32432 roc_auc 0.11000 prc_auc 0.50089[0m
[92maverage training of epoch 9: loss 1.15274 acc 0.33775 roc_auc 0.10069 prc_auc 0.46981[0m
[93maverage test of epoch 9: loss 1.16870 acc 0.32432 roc_auc 0.11000 prc_auc 0.50089[0m
[92maverage training of epoch 10: loss 1.15274 acc 0.33775 roc_auc 0.10069 prc_auc 0.46981[0m
[93maverage test of epoch 10: loss 1.16870 acc 0.32432 roc_auc 0.11000 prc_auc 0.50089[0m
[92maverage training of epoch 11: loss 1.15274 acc 0.33775 roc_auc 0.10069 prc_auc 0.46981[0m
[93maverage test of epoch 11: loss 1.16870 acc 0.32432 roc_auc 0.11000 prc_auc 0.50089[0m
[92maverage training of epoch 12: loss 1.15274 acc 0.33775 roc_auc 0.10069 prc_auc 0.46981[0m
[93maverage test of epoch 12: loss 1.16870 acc 0.32432 roc_auc 0.11000 prc_auc 0.50089[0m
[92maverage training of epoch 13: loss 1.15274 acc 0.33775 roc_auc 0.10069 prc_auc 0.46981[0m
[93maverage test of epoch 13: loss 1.16870 acc 0.32432 roc_auc 0.11000 prc_auc 0.50089[0m
[92maverage training of epoch 14: loss 1.15274 acc 0.33775 roc_auc 0.10069 prc_auc 0.46981[0m
[93maverage test of epoch 14: loss 1.16870 acc 0.32432 roc_auc 0.11000 prc_auc 0.50089[0m
[92maverage training of epoch 15: loss 1.15274 acc 0.33775 roc_auc 0.10069 prc_auc 0.46981[0m
[93maverage test of epoch 15: loss 1.16870 acc 0.32432 roc_auc 0.11000 prc_auc 0.50089[0m
[92maverage training of epoch 16: loss 1.15274 acc 0.33775 roc_auc 0.10069 prc_auc 0.46981[0m
[93maverage test of epoch 16: loss 1.16870 acc 0.32432 roc_auc 0.11000 prc_auc 0.50089[0m
[92maverage training of epoch 17: loss 1.15274 acc 0.33775 roc_auc 0.10069 prc_auc 0.46981[0m
[93maverage test of epoch 17: loss 1.16870 acc 0.32432 roc_auc 0.11000 prc_auc 0.50089[0m
[92maverage training of epoch 18: loss 1.15274 acc 0.33775 roc_auc 0.10069 prc_auc 0.46981[0m
[93maverage test of epoch 18: loss 1.16870 acc 0.32432 roc_auc 0.11000 prc_auc 0.50089[0m
[92maverage training of epoch 19: loss 1.15274 acc 0.33775 roc_auc 0.10069 prc_auc 0.46981[0m
[93maverage test of epoch 19: loss 1.16870 acc 0.32432 roc_auc 0.11000 prc_auc 0.50089[0m
[92maverage training of epoch 20: loss 1.15274 acc 0.33775 roc_auc 0.10069 prc_auc 0.46981[0m
[93maverage test of epoch 20: loss 1.16870 acc 0.32432 roc_auc 0.11000 prc_auc 0.50089[0m
[92maverage training of epoch 21: loss 1.15274 acc 0.33775 roc_auc 0.10069 prc_auc 0.46981[0m
[93maverage test of epoch 21: loss 1.16870 acc 0.32432 roc_auc 0.11000 prc_auc 0.50089[0m
[92maverage training of epoch 22: loss 1.15274 acc 0.33775 roc_auc 0.10069 prc_auc 0.46981[0m
[93maverage test of epoch 22: loss 1.16870 acc 0.32432 roc_auc 0.11000 prc_auc 0.50089[0m
[92maverage training of epoch 23: loss 1.15274 acc 0.33775 roc_auc 0.10069 prc_auc 0.46981[0m
[93maverage test of epoch 23: loss 1.16870 acc 0.32432 roc_auc 0.11000 prc_auc 0.50089[0m
[92maverage training of epoch 24: loss 1.15274 acc 0.33775 roc_auc 0.10069 prc_auc 0.46981[0m
[93maverage test of epoch 24: loss 1.16870 acc 0.32432 roc_auc 0.11000 prc_auc 0.50089[0m
[92maverage training of epoch 25: loss 1.15274 acc 0.33775 roc_auc 0.10069 prc_auc 0.46981[0m
[93maverage test of epoch 25: loss 1.16870 acc 0.32432 roc_auc 0.11000 prc_auc 0.50089[0m
[92maverage training of epoch 26: loss 1.15274 acc 0.33775 roc_auc 0.10069 prc_auc 0.46981[0m
[93maverage test of epoch 26: loss 1.16870 acc 0.32432 roc_auc 0.11000 prc_auc 0.50089[0m
[92maverage training of epoch 27: loss 1.15274 acc 0.33775 roc_auc 0.10069 prc_auc 0.46981[0m
[93maverage test of epoch 27: loss 1.16870 acc 0.32432 roc_auc 0.11000 prc_auc 0.50089[0m
[92maverage training of epoch 28: loss 1.15274 acc 0.33775 roc_auc 0.10069 prc_auc 0.46981[0m
[93maverage test of epoch 28: loss 1.16870 acc 0.32432 roc_auc 0.11000 prc_auc 0.50089[0m
[92maverage training of epoch 29: loss 1.15274 acc 0.33775 roc_auc 0.10069 prc_auc 0.46981[0m
[93maverage test of epoch 29: loss 1.16870 acc 0.32432 roc_auc 0.11000 prc_auc 0.50089[0m
[92maverage training of epoch 30: loss 1.15274 acc 0.33775 roc_auc 0.10069 prc_auc 0.46981[0m
[93maverage test of epoch 30: loss 1.16870 acc 0.32432 roc_auc 0.11000 prc_auc 0.50089[0m
[92maverage training of epoch 31: loss 1.15274 acc 0.33775 roc_auc 0.10069 prc_auc 0.46981[0m
[93maverage test of epoch 31: loss 1.16870 acc 0.32432 roc_auc 0.11000 prc_auc 0.50089[0m
[92maverage training of epoch 32: loss 1.15274 acc 0.33775 roc_auc 0.10069 prc_auc 0.46981[0m
[93maverage test of epoch 32: loss 1.16870 acc 0.32432 roc_auc 0.11000 prc_auc 0.50089[0m
[92maverage training of epoch 33: loss 1.15274 acc 0.33775 roc_auc 0.10069 prc_auc 0.46981[0m
[93maverage test of epoch 33: loss 1.16870 acc 0.32432 roc_auc 0.11000 prc_auc 0.50089[0m
[92maverage training of epoch 34: loss 1.15274 acc 0.33775 roc_auc 0.10069 prc_auc 0.46981[0m
[93maverage test of epoch 34: loss 1.16870 acc 0.32432 roc_auc 0.11000 prc_auc 0.50089[0m
[92maverage training of epoch 35: loss 1.15274 acc 0.33775 roc_auc 0.10069 prc_auc 0.46981[0m
[93maverage test of epoch 35: loss 1.16870 acc 0.32432 roc_auc 0.11000 prc_auc 0.50089[0m
[92maverage training of epoch 36: loss 1.15274 acc 0.33775 roc_auc 0.10069 prc_auc 0.46981[0m
[93maverage test of epoch 36: loss 1.16870 acc 0.32432 roc_auc 0.11000 prc_auc 0.50089[0m
[92maverage training of epoch 37: loss 1.15274 acc 0.33775 roc_auc 0.10069 prc_auc 0.46981[0m
[93maverage test of epoch 37: loss 1.16870 acc 0.32432 roc_auc 0.11000 prc_auc 0.50089[0m
[92maverage training of epoch 38: loss 1.15274 acc 0.33775 roc_auc 0.10069 prc_auc 0.46981[0m
[93maverage test of epoch 38: loss 1.16870 acc 0.32432 roc_auc 0.11000 prc_auc 0.50089[0m
[92maverage training of epoch 39: loss 1.15274 acc 0.33775 roc_auc 0.10069 prc_auc 0.46981[0m
[93maverage test of epoch 39: loss 1.16870 acc 0.32432 roc_auc 0.11000 prc_auc 0.50089[0m
[92maverage training of epoch 40: loss 1.15274 acc 0.33775 roc_auc 0.10069 prc_auc 0.46981[0m
[93maverage test of epoch 40: loss 1.16870 acc 0.32432 roc_auc 0.11000 prc_auc 0.50089[0m
[92maverage training of epoch 41: loss 1.15274 acc 0.33775 roc_auc 0.10069 prc_auc 0.46981[0m
[93maverage test of epoch 41: loss 1.16870 acc 0.32432 roc_auc 0.11000 prc_auc 0.50089[0m
[92maverage training of epoch 42: loss 1.15274 acc 0.33775 roc_auc 0.10069 prc_auc 0.46981[0m
[93maverage test of epoch 42: loss 1.16870 acc 0.32432 roc_auc 0.11000 prc_auc 0.50089[0m
[92maverage training of epoch 43: loss 1.15274 acc 0.33775 roc_auc 0.10069 prc_auc 0.46981[0m
[93maverage test of epoch 43: loss 1.16870 acc 0.32432 roc_auc 0.11000 prc_auc 0.50089[0m
[92maverage training of epoch 44: loss 1.15274 acc 0.33775 roc_auc 0.10069 prc_auc 0.46981[0m
[93maverage test of epoch 44: loss 1.16870 acc 0.32432 roc_auc 0.11000 prc_auc 0.50089[0m
[92maverage training of epoch 45: loss 1.15274 acc 0.33775 roc_auc 0.10069 prc_auc 0.46981[0m
[93maverage test of epoch 45: loss 1.16870 acc 0.32432 roc_auc 0.11000 prc_auc 0.50089[0m
[92maverage training of epoch 46: loss 1.15274 acc 0.33775 roc_auc 0.10069 prc_auc 0.46981[0m
[93maverage test of epoch 46: loss 1.16870 acc 0.32432 roc_auc 0.11000 prc_auc 0.50089[0m
[92maverage training of epoch 47: loss 1.15274 acc 0.33775 roc_auc 0.10069 prc_auc 0.46981[0m
[93maverage test of epoch 47: loss 1.16870 acc 0.32432 roc_auc 0.11000 prc_auc 0.50089[0m
[92maverage training of epoch 48: loss 1.15274 acc 0.33775 roc_auc 0.10069 prc_auc 0.46981[0m
[93maverage test of epoch 48: loss 1.16870 acc 0.32432 roc_auc 0.11000 prc_auc 0.50089[0m
[92maverage training of epoch 49: loss 1.15274 acc 0.33775 roc_auc 0.10069 prc_auc 0.46981[0m
[93maverage test of epoch 49: loss 1.16870 acc 0.32432 roc_auc 0.11000 prc_auc 0.50089[0m
Training model with dataset, testing using fold 4
[92maverage training of epoch 0: loss 0.75060 acc 0.66225 roc_auc 0.19520 prc_auc 0.54258[0m
[93maverage test of epoch 0: loss 0.72408 acc 0.67568 roc_auc 0.05333 prc_auc 0.51189[0m
[92maverage training of epoch 1: loss 0.75060 acc 0.66225 roc_auc 0.19520 prc_auc 0.54258[0m
[93maverage test of epoch 1: loss 0.72408 acc 0.67568 roc_auc 0.05333 prc_auc 0.51189[0m
[92maverage training of epoch 2: loss 0.75060 acc 0.66225 roc_auc 0.19520 prc_auc 0.54258[0m
[93maverage test of epoch 2: loss 0.72408 acc 0.67568 roc_auc 0.05333 prc_auc 0.51189[0m
[92maverage training of epoch 3: loss 0.75060 acc 0.66225 roc_auc 0.19520 prc_auc 0.54258[0m
[93maverage test of epoch 3: loss 0.72408 acc 0.67568 roc_auc 0.05333 prc_auc 0.51189[0m
[92maverage training of epoch 4: loss 0.75060 acc 0.66225 roc_auc 0.19520 prc_auc 0.54258[0m
[93maverage test of epoch 4: loss 0.72408 acc 0.67568 roc_auc 0.05333 prc_auc 0.51189[0m
[92maverage training of epoch 5: loss 0.75060 acc 0.66225 roc_auc 0.19520 prc_auc 0.54258[0m
[93maverage test of epoch 5: loss 0.72408 acc 0.67568 roc_auc 0.05333 prc_auc 0.51189[0m
[92maverage training of epoch 6: loss 0.75060 acc 0.66225 roc_auc 0.19520 prc_auc 0.54258[0m
[93maverage test of epoch 6: loss 0.72408 acc 0.67568 roc_auc 0.05333 prc_auc 0.51189[0m
[92maverage training of epoch 7: loss 0.75060 acc 0.66225 roc_auc 0.19520 prc_auc 0.54258[0m
[93maverage test of epoch 7: loss 0.72408 acc 0.67568 roc_auc 0.05333 prc_auc 0.51189[0m
[92maverage training of epoch 8: loss 0.75060 acc 0.66225 roc_auc 0.19520 prc_auc 0.54258[0m
[93maverage test of epoch 8: loss 0.72408 acc 0.67568 roc_auc 0.05333 prc_auc 0.51189[0m
[92maverage training of epoch 9: loss 0.75060 acc 0.66225 roc_auc 0.19520 prc_auc 0.54258[0m
[93maverage test of epoch 9: loss 0.72408 acc 0.67568 roc_auc 0.05333 prc_auc 0.51189[0m
[92maverage training of epoch 10: loss 0.75060 acc 0.66225 roc_auc 0.19520 prc_auc 0.54258[0m
[93maverage test of epoch 10: loss 0.72408 acc 0.67568 roc_auc 0.05333 prc_auc 0.51189[0m
[92maverage training of epoch 11: loss 0.75060 acc 0.66225 roc_auc 0.19520 prc_auc 0.54258[0m
[93maverage test of epoch 11: loss 0.72408 acc 0.67568 roc_auc 0.05333 prc_auc 0.51189[0m
[92maverage training of epoch 12: loss 0.75060 acc 0.66225 roc_auc 0.19520 prc_auc 0.54258[0m
[93maverage test of epoch 12: loss 0.72408 acc 0.67568 roc_auc 0.05333 prc_auc 0.51189[0m
[92maverage training of epoch 13: loss 0.75060 acc 0.66225 roc_auc 0.19520 prc_auc 0.54258[0m
[93maverage test of epoch 13: loss 0.72408 acc 0.67568 roc_auc 0.05333 prc_auc 0.51189[0m
[92maverage training of epoch 14: loss 0.75060 acc 0.66225 roc_auc 0.19520 prc_auc 0.54258[0m
[93maverage test of epoch 14: loss 0.72408 acc 0.67568 roc_auc 0.05333 prc_auc 0.51189[0m
[92maverage training of epoch 15: loss 0.75060 acc 0.66225 roc_auc 0.19520 prc_auc 0.54258[0m
[93maverage test of epoch 15: loss 0.72408 acc 0.67568 roc_auc 0.05333 prc_auc 0.51189[0m
[92maverage training of epoch 16: loss 0.75060 acc 0.66225 roc_auc 0.19520 prc_auc 0.54258[0m
[93maverage test of epoch 16: loss 0.72408 acc 0.67568 roc_auc 0.05333 prc_auc 0.51189[0m
[92maverage training of epoch 17: loss 0.75060 acc 0.66225 roc_auc 0.19520 prc_auc 0.54258[0m
[93maverage test of epoch 17: loss 0.72408 acc 0.67568 roc_auc 0.05333 prc_auc 0.51189[0m
[92maverage training of epoch 18: loss 0.75060 acc 0.66225 roc_auc 0.19520 prc_auc 0.54258[0m
[93maverage test of epoch 18: loss 0.72408 acc 0.67568 roc_auc 0.05333 prc_auc 0.51189[0m
[92maverage training of epoch 19: loss 0.75060 acc 0.66225 roc_auc 0.19520 prc_auc 0.54258[0m
[93maverage test of epoch 19: loss 0.72408 acc 0.67568 roc_auc 0.05333 prc_auc 0.51189[0m
[92maverage training of epoch 20: loss 0.75060 acc 0.66225 roc_auc 0.19520 prc_auc 0.54258[0m
[93maverage test of epoch 20: loss 0.72408 acc 0.67568 roc_auc 0.05333 prc_auc 0.51189[0m
[92maverage training of epoch 21: loss 0.75060 acc 0.66225 roc_auc 0.19520 prc_auc 0.54258[0m
[93maverage test of epoch 21: loss 0.72408 acc 0.67568 roc_auc 0.05333 prc_auc 0.51189[0m
[92maverage training of epoch 22: loss 0.75060 acc 0.66225 roc_auc 0.19520 prc_auc 0.54258[0m
[93maverage test of epoch 22: loss 0.72408 acc 0.67568 roc_auc 0.05333 prc_auc 0.51189[0m
[92maverage training of epoch 23: loss 0.75060 acc 0.66225 roc_auc 0.19520 prc_auc 0.54258[0m
[93maverage test of epoch 23: loss 0.72408 acc 0.67568 roc_auc 0.05333 prc_auc 0.51189[0m
[92maverage training of epoch 24: loss 0.75060 acc 0.66225 roc_auc 0.19520 prc_auc 0.54258[0m
[93maverage test of epoch 24: loss 0.72408 acc 0.67568 roc_auc 0.05333 prc_auc 0.51189[0m
[92maverage training of epoch 25: loss 0.75060 acc 0.66225 roc_auc 0.19520 prc_auc 0.54258[0m
[93maverage test of epoch 25: loss 0.72408 acc 0.67568 roc_auc 0.05333 prc_auc 0.51189[0m
[92maverage training of epoch 26: loss 0.75060 acc 0.66225 roc_auc 0.19520 prc_auc 0.54258[0m
[93maverage test of epoch 26: loss 0.72408 acc 0.67568 roc_auc 0.05333 prc_auc 0.51189[0m
[92maverage training of epoch 27: loss 0.75060 acc 0.66225 roc_auc 0.19520 prc_auc 0.54258[0m
[93maverage test of epoch 27: loss 0.72408 acc 0.67568 roc_auc 0.05333 prc_auc 0.51189[0m
[92maverage training of epoch 28: loss 0.75060 acc 0.66225 roc_auc 0.19520 prc_auc 0.54258[0m
[93maverage test of epoch 28: loss 0.72408 acc 0.67568 roc_auc 0.05333 prc_auc 0.51189[0m
[92maverage training of epoch 29: loss 0.75060 acc 0.66225 roc_auc 0.19520 prc_auc 0.54258[0m
[93maverage test of epoch 29: loss 0.72408 acc 0.67568 roc_auc 0.05333 prc_auc 0.51189[0m
[92maverage training of epoch 30: loss 0.75060 acc 0.66225 roc_auc 0.19520 prc_auc 0.54258[0m
[93maverage test of epoch 30: loss 0.72408 acc 0.67568 roc_auc 0.05333 prc_auc 0.51189[0m
[92maverage training of epoch 31: loss 0.75060 acc 0.66225 roc_auc 0.19520 prc_auc 0.54258[0m
[93maverage test of epoch 31: loss 0.72408 acc 0.67568 roc_auc 0.05333 prc_auc 0.51189[0m
[92maverage training of epoch 32: loss 0.75060 acc 0.66225 roc_auc 0.19520 prc_auc 0.54258[0m
[93maverage test of epoch 32: loss 0.72408 acc 0.67568 roc_auc 0.05333 prc_auc 0.51189[0m
[92maverage training of epoch 33: loss 0.75060 acc 0.66225 roc_auc 0.19520 prc_auc 0.54258[0m
[93maverage test of epoch 33: loss 0.72408 acc 0.67568 roc_auc 0.05333 prc_auc 0.51189[0m
[92maverage training of epoch 34: loss 0.75060 acc 0.66225 roc_auc 0.19520 prc_auc 0.54258[0m
[93maverage test of epoch 34: loss 0.72408 acc 0.67568 roc_auc 0.05333 prc_auc 0.51189[0m
[92maverage training of epoch 35: loss 0.75060 acc 0.66225 roc_auc 0.19520 prc_auc 0.54258[0m
[93maverage test of epoch 35: loss 0.72408 acc 0.67568 roc_auc 0.05333 prc_auc 0.51189[0m
[92maverage training of epoch 36: loss 0.75060 acc 0.66225 roc_auc 0.19520 prc_auc 0.54258[0m
[93maverage test of epoch 36: loss 0.72408 acc 0.67568 roc_auc 0.05333 prc_auc 0.51189[0m
[92maverage training of epoch 37: loss 0.75060 acc 0.66225 roc_auc 0.19520 prc_auc 0.54258[0m
[93maverage test of epoch 37: loss 0.72408 acc 0.67568 roc_auc 0.05333 prc_auc 0.51189[0m
[92maverage training of epoch 38: loss 0.75060 acc 0.66225 roc_auc 0.19520 prc_auc 0.54258[0m
[93maverage test of epoch 38: loss 0.72408 acc 0.67568 roc_auc 0.05333 prc_auc 0.51189[0m
[92maverage training of epoch 39: loss 0.75060 acc 0.66225 roc_auc 0.19520 prc_auc 0.54258[0m
[93maverage test of epoch 39: loss 0.72408 acc 0.67568 roc_auc 0.05333 prc_auc 0.51189[0m
[92maverage training of epoch 40: loss 0.75060 acc 0.66225 roc_auc 0.19520 prc_auc 0.54258[0m
[93maverage test of epoch 40: loss 0.72408 acc 0.67568 roc_auc 0.05333 prc_auc 0.51189[0m
[92maverage training of epoch 41: loss 0.75060 acc 0.66225 roc_auc 0.19520 prc_auc 0.54258[0m
[93maverage test of epoch 41: loss 0.72408 acc 0.67568 roc_auc 0.05333 prc_auc 0.51189[0m
[92maverage training of epoch 42: loss 0.75060 acc 0.66225 roc_auc 0.19520 prc_auc 0.54258[0m
[93maverage test of epoch 42: loss 0.72408 acc 0.67568 roc_auc 0.05333 prc_auc 0.51189[0m
[92maverage training of epoch 43: loss 0.75060 acc 0.66225 roc_auc 0.19520 prc_auc 0.54258[0m
[93maverage test of epoch 43: loss 0.72408 acc 0.67568 roc_auc 0.05333 prc_auc 0.51189[0m
[92maverage training of epoch 44: loss 0.75060 acc 0.66225 roc_auc 0.19520 prc_auc 0.54258[0m
[93maverage test of epoch 44: loss 0.72408 acc 0.67568 roc_auc 0.05333 prc_auc 0.51189[0m
[92maverage training of epoch 45: loss 0.75060 acc 0.66225 roc_auc 0.19520 prc_auc 0.54258[0m
[93maverage test of epoch 45: loss 0.72408 acc 0.67568 roc_auc 0.05333 prc_auc 0.51189[0m
[92maverage training of epoch 46: loss 0.75060 acc 0.66225 roc_auc 0.19520 prc_auc 0.54258[0m
[93maverage test of epoch 46: loss 0.72408 acc 0.67568 roc_auc 0.05333 prc_auc 0.51189[0m
[92maverage training of epoch 47: loss 0.75060 acc 0.66225 roc_auc 0.19520 prc_auc 0.54258[0m
[93maverage test of epoch 47: loss 0.72408 acc 0.67568 roc_auc 0.05333 prc_auc 0.51189[0m
[92maverage training of epoch 48: loss 0.75060 acc 0.66225 roc_auc 0.19520 prc_auc 0.54258[0m
[93maverage test of epoch 48: loss 0.72408 acc 0.67568 roc_auc 0.05333 prc_auc 0.51189[0m
[92maverage training of epoch 49: loss 0.75060 acc 0.66225 roc_auc 0.19520 prc_auc 0.54258[0m
[93maverage test of epoch 49: loss 0.72408 acc 0.67568 roc_auc 0.05333 prc_auc 0.51189[0m
Run statistics: 
==== Configuration Settings ====
== Run Settings ==
Model: DFScodeRNN_cls, Dataset: MUTAG
num_epochs: 50
learning_rate: 0.0001
seed: 1800
k_fold: 5
model: DFScodeRNN_cls
dataset: MUTAG

== Model Settings and results ==
dummy: 0

Accuracy (avg): 0.40526 ROC_AUC (avg): 0.26744 PRC_AUC (avg): 0.61253 


