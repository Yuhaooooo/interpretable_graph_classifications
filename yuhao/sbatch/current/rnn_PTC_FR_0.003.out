# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======


torch.cuda.is_available():  True 


args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/PTC_FR/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/PTC_FR/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/PTC_FR/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/PTC_FR/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   1   2   3   4   6   8   9  10  11  12  13  14  15  16  17  19  20
  21  22  23  24  25  26  27  28  29  30  31  32  33  36  37  38  40  42
  43  44  45  46  48  50  53  54  56  57  58  60  61  62  63  64  65  66
  68  71  72  73  74  75  77  78  79  80  81  82  83  84  85  86  88  89
  90  92  94  95  97  98 100 101 102 103 104 106 108 109 111 112 113 114
 115 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 134
 135 136 137 138 139 140 141 143 145 146 147 148 149 150 151 152 154 155
 156 157 158 159 160 161 162 163 164 165 166 168 169 171 173 174 176 180
 181 182 184 185 187 188 189 193 194 196 197 198 199 200 201 202 203 204
 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223
 226 227 228 230 231 232 233 234 235 236 238 239 242 243 244 245 246 248
 250 251 252 253 254 255 256 257 258 260 261 262 263 264 265 266 268 270
 272 273 276 277 278 279 280 281 282 283 284 285 286 287 289 290 291 293
 294 295 296 297 298 299 300 301 303 304 306 307 308 309 311 312 313 316
 317 318 320 321 323 324 325 326 327 328 329 330 331 332 333 334 335 336
 338 339 340 341 342 343 346 348 349 350]
*** 2 test_index:  [  5   7  18  34  35  39  41  47  49  51  52  55  59  67  69  70  76  87
  91  93  96  99 105 107 110 122 133 142 144 153 167 170 172 175 177 178
 179 183 186 190 191 192 195 205 224 225 229 237 240 241 247 249 259 267
 269 271 274 275 288 292 302 305 310 314 315 319 322 337 344 345 347]
*** 1 train_index:  [  0   1   2   3   5   6   7   9  11  12  13  15  16  17  18  19  20  21
  22  23  25  26  27  28  29  32  33  34  35  37  38  39  40  41  42  46
  47  48  49  50  51  52  53  54  55  56  58  59  60  61  62  63  64  65
  67  69  70  72  75  76  77  80  81  82  83  84  85  86  87  88  90  91
  93  94  95  96  98  99 100 102 103 104 105 107 108 109 110 111 112 113
 114 115 116 117 118 120 121 122 123 124 125 126 127 128 130 131 132 133
 134 135 137 138 139 140 141 142 144 145 146 147 149 151 153 154 155 156
 157 158 159 160 161 162 163 165 166 167 168 169 170 171 172 173 175 176
 177 178 179 180 182 183 185 186 187 188 189 190 191 192 193 194 195 197
 198 199 200 202 203 204 205 207 208 210 211 212 213 214 215 216 217 218
 220 222 224 225 226 227 228 229 230 231 232 233 235 236 237 239 240 241
 242 243 244 247 248 249 250 252 255 257 258 259 260 261 262 263 264 266
 267 268 269 270 271 272 273 274 275 277 278 280 282 284 285 286 287 288
 289 290 291 292 293 295 296 297 302 303 304 305 306 308 309 310 311 312
 314 315 316 318 319 320 321 322 323 324 325 327 328 330 331 332 335 336
 337 338 339 341 342 343 344 345 347 349 350]
*** 2 test_index:  [  4   8  10  14  24  30  31  36  43  44  45  57  66  68  71  73  74  78
  79  89  92  97 101 106 119 129 136 143 148 150 152 164 174 181 184 196
 201 206 209 219 221 223 234 238 245 246 251 253 254 256 265 276 279 281
 283 294 298 299 300 301 307 313 317 326 329 333 334 340 346 348]
*** 1 train_index:  [  1   2   4   5   6   7   8   9  10  12  13  14  15  16  17  18  21  22
  23  24  26  27  28  30  31  32  34  35  36  37  39  40  41  43  44  45
  46  47  48  49  51  52  53  55  56  57  58  59  60  61  63  65  66  67
  68  69  70  71  72  73  74  75  76  78  79  80  81  83  87  89  90  91
  92  93  96  97  98  99 100 101 102 104 105 106 107 109 110 111 113 116
 119 120 121 122 123 125 126 127 129 130 131 133 134 136 137 138 139 140
 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158
 159 161 162 164 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 181 182 183 184 186 189 190 191 192 195 196 197 198 199 200 201 202 203
 204 205 206 208 209 211 212 217 218 219 221 222 223 224 225 226 227 228
 229 231 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248
 249 250 251 252 253 254 256 257 258 259 261 262 263 264 265 266 267 269
 271 273 274 275 276 277 278 279 281 282 283 284 288 290 291 292 294 295
 296 297 298 299 300 301 302 303 304 305 307 309 310 311 312 313 314 315
 316 317 318 319 321 322 324 325 326 327 328 329 330 332 333 334 335 337
 338 339 340 343 344 345 346 347 348 349 350]
*** 2 test_index:  [  0   3  11  19  20  25  29  33  38  42  50  54  62  64  77  82  84  85
  86  88  94  95 103 108 112 114 115 117 118 124 128 132 135 160 163 165
 180 185 187 188 193 194 207 210 213 214 215 216 220 230 232 255 260 268
 270 272 280 285 286 287 289 293 306 308 320 323 331 336 341 342]
*** 1 train_index:  [  0   1   2   3   4   5   6   7   8  10  11  12  14  15  16  17  18  19
  20  21  24  25  28  29  30  31  33  34  35  36  37  38  39  40  41  42
  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60
  62  63  64  65  66  67  68  69  70  71  73  74  76  77  78  79  82  83
  84  85  86  87  88  89  91  92  93  94  95  96  97  99 101 103 104 105
 106 107 108 110 112 114 115 116 117 118 119 122 123 124 128 129 132 133
 134 135 136 137 138 141 142 143 144 146 147 148 149 150 152 153 155 156
 157 158 160 163 164 165 167 168 169 170 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 200 201 204 205 206 207 209 210 211 212 213 214 215 216 218 219 220
 221 222 223 224 225 226 227 229 230 232 234 235 236 237 238 240 241 243
 245 246 247 248 249 250 251 252 253 254 255 256 258 259 260 261 262 264
 265 266 267 268 269 270 271 272 274 275 276 277 279 280 281 282 283 285
 286 287 288 289 290 292 293 294 295 296 298 299 300 301 302 303 305 306
 307 308 310 312 313 314 315 317 319 320 322 323 326 329 331 332 333 334
 336 337 340 341 342 343 344 345 346 347 348]
*** 2 test_index:  [  9  13  22  23  26  27  32  61  72  75  80  81  90  98 100 102 109 111
 113 120 121 125 126 127 130 131 139 140 145 151 154 159 161 162 166 171
 199 202 203 208 217 228 231 233 239 242 244 257 263 273 278 284 291 297
 304 309 311 316 318 321 324 325 327 328 330 335 338 339 349 350]
*** 1 train_index:  [  0   3   4   5   7   8   9  10  11  13  14  18  19  20  22  23  24  25
  26  27  29  30  31  32  33  34  35  36  38  39  41  42  43  44  45  47
  49  50  51  52  54  55  57  59  61  62  64  66  67  68  69  70  71  72
  73  74  75  76  77  78  79  80  81  82  84  85  86  87  88  89  90  91
  92  93  94  95  96  97  98  99 100 101 102 103 105 106 107 108 109 110
 111 112 113 114 115 117 118 119 120 121 122 124 125 126 127 128 129 130
 131 132 133 135 136 139 140 142 143 144 145 148 150 151 152 153 154 159
 160 161 162 163 164 165 166 167 170 171 172 174 175 177 178 179 180 181
 183 184 185 186 187 188 190 191 192 193 194 195 196 199 201 202 203 205
 206 207 208 209 210 213 214 215 216 217 219 220 221 223 224 225 228 229
 230 231 232 233 234 237 238 239 240 241 242 244 245 246 247 249 251 253
 254 255 256 257 259 260 263 265 267 268 269 270 271 272 273 274 275 276
 278 279 280 281 283 284 285 286 287 288 289 291 292 293 294 297 298 299
 300 301 302 304 305 306 307 308 309 310 311 313 314 315 316 317 318 319
 320 321 322 323 324 325 326 327 328 329 330 331 333 334 335 336 337 338
 339 340 341 342 344 345 346 347 348 349 350]
*** 2 test_index:  [  1   2   6  12  15  16  17  21  28  37  40  46  48  53  56  58  60  63
  65  83 104 116 123 134 137 138 141 146 147 149 155 156 157 158 168 169
 173 176 182 189 197 198 200 204 211 212 218 222 226 227 235 236 243 248
 250 252 258 261 262 264 266 277 282 290 295 296 303 312 332 343]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/PTC_FR/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/PTC_FR/graphgen/model_save/DFScodeRNN_cls_PTC_FR_2021-01-11-20-43-27/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/PTC_FR/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/PTC_FR/graphgen/tmp/DFScodeRNN_cls_PTC_FR_2021-01-11-20-43-27/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/PTC_FR/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0,
 'embedding_size_dfscode_rnn': 8,
 'epochs': 50,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_PTC_FR',
 'gamma': 0.3,
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/PTC_FR/graphgen/graphs/',
 'graph_type': 'PTC_FR',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/PTC_FR/graphgen/',
 'hidden_size_dfscode_rnn': 4,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.003,
 'max_prev_node': None,
 'milestones': [100, 200, 400, 800],
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/PTC_FR/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/PTC_FR/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/PTC_FR/graphgen/model_save/',
 'note': 'DFScodeRNN_cls',
 'num_graphs': None,
 'num_layers': 1,
 'num_workers': 8,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/PTC_FR/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/PTC_FR/graphgen/tensorboard/',
 'time': '2021-01-11-20-43-27',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'1': 0, '0': 1, '3': 2, '2': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '12': 9, '13': 10, '14': 11, '9': 12, '15': 13, '16': 14, '17': 15, '18': 16, '10': 17, '11': 18}, 'node_backward': {0: '1', 1: '0', 2: '3', 3: '2', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '12', 10: '13', 11: '14', 12: '9', 13: '15', 14: '16', 15: '17', 16: '18', 17: '10', 18: '11'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 64, 'min_nodes': 2, 'max_edges': 71, 'min_edges': 1, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 50, 'learning_rate': 0.003, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls', 'dataset': 'PTC_FR'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'1': 0, '0': 1, '3': 2, '2': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '12': 9, '13': 10, '14': 11, '9': 12, '15': 13, '16': 14, '17': 15, '18': 16, '10': 17, '11': 18}, 'node_backward': {0: '1', 1: '0', 2: '3', 3: '2', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '12', 10: '13', 11: '14', 12: '9', 13: '15', 14: '16', 15: '17', 16: '18', 17: '10', 18: '11'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 64, 'min_nodes': 2, 'max_edges': 71, 'min_edges': 1, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls
Training model with dataset, testing using fold 0
DfscodeRnn_cls args.lr:  0.003
[92maverage training of epoch 0: loss -2.42970 acc 0.34286 roc_auc 0.49156 prc_auc 0.35193[0m
[93maverage test of epoch 0: loss -3.42234 acc 0.35211 roc_auc 0.47087 prc_auc 0.33917[0m
[92maverage training of epoch 1: loss -3.58384 acc 0.34286 roc_auc 0.48149 prc_auc 0.33860[0m
[93maverage test of epoch 1: loss -3.67111 acc 0.35211 roc_auc 0.47087 prc_auc 0.33917[0m
[92maverage training of epoch 2: loss -3.72774 acc 0.42857 roc_auc 0.48443 prc_auc 0.33845[0m
[93maverage test of epoch 2: loss -3.77431 acc 0.64789 roc_auc 0.47087 prc_auc 0.33917[0m
[92maverage training of epoch 3: loss -3.79128 acc 0.65357 roc_auc 0.48242 prc_auc 0.33815[0m
[93maverage test of epoch 3: loss -3.80792 acc 0.64789 roc_auc 0.47087 prc_auc 0.33917[0m
[92maverage training of epoch 4: loss -3.82484 acc 0.65714 roc_auc 0.48254 prc_auc 0.33803[0m
[93maverage test of epoch 4: loss -3.84130 acc 0.64789 roc_auc 0.47435 prc_auc 0.34063[0m
[92maverage training of epoch 5: loss -3.85814 acc 0.65714 roc_auc 0.48302 prc_auc 0.33834[0m
[93maverage test of epoch 5: loss -3.87440 acc 0.64789 roc_auc 0.47087 prc_auc 0.33917[0m
[92maverage training of epoch 6: loss -3.89113 acc 0.65714 roc_auc 0.48319 prc_auc 0.33834[0m
[93maverage test of epoch 6: loss -3.90715 acc 0.64789 roc_auc 0.47087 prc_auc 0.33917[0m
[92maverage training of epoch 7: loss -3.92375 acc 0.65714 roc_auc 0.48389 prc_auc 0.33884[0m
[93maverage test of epoch 7: loss -3.93953 acc 0.64789 roc_auc 0.47087 prc_auc 0.33917[0m
[92maverage training of epoch 8: loss -3.95600 acc 0.65714 roc_auc 0.48474 prc_auc 0.33946[0m
[93maverage test of epoch 8: loss -3.97153 acc 0.64789 roc_auc 0.49043 prc_auc 0.34800[0m
[92maverage training of epoch 9: loss -3.98788 acc 0.65714 roc_auc 0.48517 prc_auc 0.33948[0m
[93maverage test of epoch 9: loss -4.00316 acc 0.64789 roc_auc 0.47087 prc_auc 0.33917[0m
[92maverage training of epoch 10: loss -4.01938 acc 0.65714 roc_auc 0.48588 prc_auc 0.33992[0m
[93maverage test of epoch 10: loss -4.03443 acc 0.64789 roc_auc 0.47087 prc_auc 0.33917[0m
[92maverage training of epoch 11: loss -4.05054 acc 0.65714 roc_auc 0.48650 prc_auc 0.34045[0m
[93maverage test of epoch 11: loss -4.06535 acc 0.64789 roc_auc 0.46957 prc_auc 0.33859[0m
[92maverage training of epoch 12: loss -4.08135 acc 0.65714 roc_auc 0.48689 prc_auc 0.34083[0m
[93maverage test of epoch 12: loss -4.09594 acc 0.64789 roc_auc 0.49043 prc_auc 0.34800[0m
[92maverage training of epoch 13: loss -4.11183 acc 0.65714 roc_auc 0.48723 prc_auc 0.34097[0m
[93maverage test of epoch 13: loss -4.12620 acc 0.64789 roc_auc 0.50087 prc_auc 0.35291[0m
[92maverage training of epoch 14: loss -4.14201 acc 0.65714 roc_auc 0.48732 prc_auc 0.34100[0m
[93maverage test of epoch 14: loss -4.15617 acc 0.64789 roc_auc 0.49043 prc_auc 0.34800[0m
[92maverage training of epoch 15: loss -4.17189 acc 0.65714 roc_auc 0.48763 prc_auc 0.34116[0m
[93maverage test of epoch 15: loss -4.18584 acc 0.64789 roc_auc 0.50000 prc_auc 0.36951[0m
[92maverage training of epoch 16: loss -4.20149 acc 0.65714 roc_auc 0.48772 prc_auc 0.34128[0m
[93maverage test of epoch 16: loss -4.21525 acc 0.64789 roc_auc 0.49043 prc_auc 0.34800[0m
[92maverage training of epoch 17: loss -4.23083 acc 0.65714 roc_auc 0.48794 prc_auc 0.34133[0m
[93maverage test of epoch 17: loss -4.24439 acc 0.64789 roc_auc 0.47087 prc_auc 0.33917[0m
[92maverage training of epoch 18: loss -4.25992 acc 0.65714 roc_auc 0.48808 prc_auc 0.34150[0m
[93maverage test of epoch 18: loss -4.27329 acc 0.64789 roc_auc 0.47043 prc_auc 0.33898[0m
[92maverage training of epoch 19: loss -4.28877 acc 0.65714 roc_auc 0.48814 prc_auc 0.34181[0m
[93maverage test of epoch 19: loss -4.30197 acc 0.64789 roc_auc 0.47043 prc_auc 0.33898[0m
[92maverage training of epoch 20: loss -4.31740 acc 0.65714 roc_auc 0.48851 prc_auc 0.34202[0m
[93maverage test of epoch 20: loss -4.33042 acc 0.64789 roc_auc 0.51000 prc_auc 0.37408[0m
[92maverage training of epoch 21: loss -4.34581 acc 0.65714 roc_auc 0.48899 prc_auc 0.34222[0m
[93maverage test of epoch 21: loss -4.35866 acc 0.64789 roc_auc 0.47087 prc_auc 0.33917[0m
[92maverage training of epoch 22: loss -4.37403 acc 0.65714 roc_auc 0.48922 prc_auc 0.34228[0m
[93maverage test of epoch 22: loss -4.38672 acc 0.64789 roc_auc 0.48000 prc_auc 0.34323[0m
[92maverage training of epoch 23: loss -4.40205 acc 0.65714 roc_auc 0.48958 prc_auc 0.34250[0m
[93maverage test of epoch 23: loss -4.41459 acc 0.64789 roc_auc 0.48000 prc_auc 0.34323[0m
[92maverage training of epoch 24: loss -4.42990 acc 0.65714 roc_auc 0.49009 prc_auc 0.34334[0m
[93maverage test of epoch 24: loss -4.44228 acc 0.64789 roc_auc 0.48000 prc_auc 0.34323[0m
[92maverage training of epoch 25: loss -4.45758 acc 0.65714 roc_auc 0.49040 prc_auc 0.34448[0m
[93maverage test of epoch 25: loss -4.46981 acc 0.64789 roc_auc 0.48000 prc_auc 0.34323[0m
[92maverage training of epoch 26: loss -4.48510 acc 0.65714 roc_auc 0.49125 prc_auc 0.34537[0m
[93maverage test of epoch 26: loss -4.49719 acc 0.64789 roc_auc 0.49043 prc_auc 0.34800[0m
[92maverage training of epoch 27: loss -4.51247 acc 0.65714 roc_auc 0.49165 prc_auc 0.34589[0m
[93maverage test of epoch 27: loss -4.52442 acc 0.64789 roc_auc 0.48000 prc_auc 0.34323[0m
[92maverage training of epoch 28: loss -4.53970 acc 0.65714 roc_auc 0.49233 prc_auc 0.34664[0m
[93maverage test of epoch 28: loss -4.55151 acc 0.64789 roc_auc 0.48000 prc_auc 0.34323[0m
[92maverage training of epoch 29: loss -4.56679 acc 0.65714 roc_auc 0.49270 prc_auc 0.34685[0m
[93maverage test of epoch 29: loss -4.57847 acc 0.64789 roc_auc 0.48087 prc_auc 0.34362[0m
[92maverage training of epoch 30: loss -4.59376 acc 0.65714 roc_auc 0.49275 prc_auc 0.34704[0m
[93maverage test of epoch 30: loss -4.60530 acc 0.64789 roc_auc 0.48000 prc_auc 0.34323[0m
[92maverage training of epoch 31: loss -4.62060 acc 0.65714 roc_auc 0.49258 prc_auc 0.34666[0m
[93maverage test of epoch 31: loss -4.63202 acc 0.64789 roc_auc 0.48000 prc_auc 0.34323[0m
[92maverage training of epoch 32: loss -4.64733 acc 0.65714 roc_auc 0.49290 prc_auc 0.34692[0m
[93maverage test of epoch 32: loss -4.65863 acc 0.64789 roc_auc 0.49043 prc_auc 0.34800[0m
[92maverage training of epoch 33: loss -4.67396 acc 0.65714 roc_auc 0.49304 prc_auc 0.34697[0m
[93maverage test of epoch 33: loss -4.68513 acc 0.64789 roc_auc 0.49043 prc_auc 0.34800[0m
[92maverage training of epoch 34: loss -4.70048 acc 0.65714 roc_auc 0.49306 prc_auc 0.34700[0m
[93maverage test of epoch 34: loss -4.71154 acc 0.64789 roc_auc 0.46957 prc_auc 0.34323[0m
[92maverage training of epoch 35: loss -4.72691 acc 0.65714 roc_auc 0.49335 prc_auc 0.34730[0m
[93maverage test of epoch 35: loss -4.73785 acc 0.64789 roc_auc 0.46957 prc_auc 0.34323[0m
[92maverage training of epoch 36: loss -4.75325 acc 0.65714 roc_auc 0.49360 prc_auc 0.34744[0m
[93maverage test of epoch 36: loss -4.76408 acc 0.64789 roc_auc 0.48000 prc_auc 0.34323[0m
[92maverage training of epoch 37: loss -4.77950 acc 0.65714 roc_auc 0.49355 prc_auc 0.34741[0m
[93maverage test of epoch 37: loss -4.79022 acc 0.64789 roc_auc 0.52000 prc_auc 0.37803[0m
[92maverage training of epoch 38: loss -4.80568 acc 0.65714 roc_auc 0.49366 prc_auc 0.34754[0m
[93maverage test of epoch 38: loss -4.81629 acc 0.64789 roc_auc 0.48000 prc_auc 0.34323[0m
[92maverage training of epoch 39: loss -4.83178 acc 0.65714 roc_auc 0.49380 prc_auc 0.34747[0m
[93maverage test of epoch 39: loss -4.84228 acc 0.64789 roc_auc 0.48913 prc_auc 0.35211[0m
[92maverage training of epoch 40: loss -4.85780 acc 0.65714 roc_auc 0.49383 prc_auc 0.34758[0m
[93maverage test of epoch 40: loss -4.86820 acc 0.64789 roc_auc 0.52913 prc_auc 0.37728[0m
[92maverage training of epoch 41: loss -4.88376 acc 0.65714 roc_auc 0.49391 prc_auc 0.34758[0m
[93maverage test of epoch 41: loss -4.89406 acc 0.64789 roc_auc 0.49087 prc_auc 0.34800[0m
[92maverage training of epoch 42: loss -4.90966 acc 0.65714 roc_auc 0.49400 prc_auc 0.34769[0m
[93maverage test of epoch 42: loss -4.91986 acc 0.64789 roc_auc 0.48957 prc_auc 0.34951[0m
[92maverage training of epoch 43: loss -4.93550 acc 0.65714 roc_auc 0.49394 prc_auc 0.34797[0m
[93maverage test of epoch 43: loss -4.94559 acc 0.64789 roc_auc 0.46000 prc_auc 0.33484[0m
[92maverage training of epoch 44: loss -4.96128 acc 0.65714 roc_auc 0.49406 prc_auc 0.34778[0m
[93maverage test of epoch 44: loss -4.97128 acc 0.64789 roc_auc 0.48000 prc_auc 0.34323[0m
[92maverage training of epoch 45: loss -4.98701 acc 0.65714 roc_auc 0.49411 prc_auc 0.34782[0m
[93maverage test of epoch 45: loss -4.99691 acc 0.64789 roc_auc 0.49087 prc_auc 0.34800[0m
[92maverage training of epoch 46: loss -5.01269 acc 0.65714 roc_auc 0.49417 prc_auc 0.34793[0m
[93maverage test of epoch 46: loss -5.02250 acc 0.64789 roc_auc 0.49087 prc_auc 0.34800[0m
[92maverage training of epoch 47: loss -5.03832 acc 0.65714 roc_auc 0.49403 prc_auc 0.34770[0m
[93maverage test of epoch 47: loss -5.04804 acc 0.64789 roc_auc 0.49087 prc_auc 0.34800[0m
[92maverage training of epoch 48: loss -5.06391 acc 0.65714 roc_auc 0.49408 prc_auc 0.34782[0m
[93maverage test of epoch 48: loss -5.07353 acc 0.64789 roc_auc 0.50000 prc_auc 0.35211[0m
[92maverage training of epoch 49: loss -5.08946 acc 0.65714 roc_auc 0.49406 prc_auc 0.34770[0m
[93maverage test of epoch 49: loss -5.09899 acc 0.64789 roc_auc 0.48913 prc_auc 0.35211[0m
Training model with dataset, testing using fold 1
DfscodeRnn_cls args.lr:  0.003
[92maverage training of epoch 0: loss -1.56605 acc 0.32384 roc_auc 0.37220 prc_auc 0.27445[0m
[93maverage test of epoch 0: loss -2.38524 acc 0.34286 roc_auc 0.54438 prc_auc 0.39411[0m
[92maverage training of epoch 1: loss -2.62781 acc 0.34520 roc_auc 0.39013 prc_auc 0.28339[0m
[93maverage test of epoch 1: loss -2.75752 acc 0.34286 roc_auc 0.52310 prc_auc 0.39596[0m
[92maverage training of epoch 2: loss -2.84325 acc 0.34520 roc_auc 0.43069 prc_auc 0.29866[0m
[93maverage test of epoch 2: loss -2.90860 acc 0.34286 roc_auc 0.55389 prc_auc 0.39827[0m
[92maverage training of epoch 3: loss -2.93475 acc 0.34520 roc_auc 0.44764 prc_auc 0.30572[0m
[93maverage test of epoch 3: loss -2.95667 acc 0.34286 roc_auc 0.55118 prc_auc 0.40089[0m
[92maverage training of epoch 4: loss -2.98218 acc 0.34520 roc_auc 0.45089 prc_auc 0.30720[0m
[93maverage test of epoch 4: loss -3.00346 acc 0.34286 roc_auc 0.55842 prc_auc 0.39284[0m
[92maverage training of epoch 5: loss -3.02839 acc 0.34520 roc_auc 0.45400 prc_auc 0.30941[0m
[93maverage test of epoch 5: loss -3.04908 acc 0.34286 roc_auc 0.57473 prc_auc 0.40045[0m
[92maverage training of epoch 6: loss -3.07344 acc 0.34520 roc_auc 0.45422 prc_auc 0.31068[0m
[93maverage test of epoch 6: loss -3.09356 acc 0.34286 roc_auc 0.55616 prc_auc 0.38793[0m
[92maverage training of epoch 7: loss -3.11734 acc 0.34520 roc_auc 0.45644 prc_auc 0.31224[0m
[93maverage test of epoch 7: loss -3.13689 acc 0.34286 roc_auc 0.54438 prc_auc 0.38636[0m
[92maverage training of epoch 8: loss -3.16011 acc 0.34520 roc_auc 0.45837 prc_auc 0.31377[0m
[93maverage test of epoch 8: loss -3.17910 acc 0.34286 roc_auc 0.52717 prc_auc 0.38600[0m
[92maverage training of epoch 9: loss -3.20177 acc 0.34520 roc_auc 0.45784 prc_auc 0.31426[0m
[93maverage test of epoch 9: loss -3.22021 acc 0.34286 roc_auc 0.42301 prc_auc 0.34852[0m
[92maverage training of epoch 10: loss -3.24235 acc 0.34520 roc_auc 0.45862 prc_auc 0.31489[0m
[93maverage test of epoch 10: loss -3.26026 acc 0.34286 roc_auc 0.49139 prc_auc 0.37907[0m
[92maverage training of epoch 11: loss -3.28187 acc 0.34520 roc_auc 0.46120 prc_auc 0.31647[0m
[93maverage test of epoch 11: loss -3.29927 acc 0.34286 roc_auc 0.54574 prc_auc 0.39549[0m
[92maverage training of epoch 12: loss -3.32038 acc 0.34520 roc_auc 0.46501 prc_auc 0.31859[0m
[93maverage test of epoch 12: loss -3.33730 acc 0.34286 roc_auc 0.49864 prc_auc 0.36968[0m
[92maverage training of epoch 13: loss -3.35793 acc 0.34520 roc_auc 0.46913 prc_auc 0.32069[0m
[93maverage test of epoch 13: loss -3.37440 acc 0.34286 roc_auc 0.49864 prc_auc 0.36984[0m
[92maverage training of epoch 14: loss -3.39458 acc 0.34520 roc_auc 0.47294 prc_auc 0.32261[0m
[93maverage test of epoch 14: loss -3.41063 acc 0.34286 roc_auc 0.54891 prc_auc 0.41039[0m
[92maverage training of epoch 15: loss -3.43038 acc 0.34520 roc_auc 0.47566 prc_auc 0.32401[0m
[93maverage test of epoch 15: loss -3.44603 acc 0.34286 roc_auc 0.40670 prc_auc 0.33743[0m
[92maverage training of epoch 16: loss -3.46538 acc 0.34520 roc_auc 0.47776 prc_auc 0.32524[0m
[93maverage test of epoch 16: loss -3.48067 acc 0.34286 roc_auc 0.48822 prc_auc 0.36984[0m
[92maverage training of epoch 17: loss -3.49965 acc 0.34520 roc_auc 0.47947 prc_auc 0.32626[0m
[93maverage test of epoch 17: loss -3.51460 acc 0.34286 roc_auc 0.49955 prc_auc 0.37262[0m
[92maverage training of epoch 18: loss -3.53323 acc 0.34520 roc_auc 0.48056 prc_auc 0.32722[0m
[93maverage test of epoch 18: loss -3.54788 acc 0.34286 roc_auc 0.54438 prc_auc 0.38956[0m
[92maverage training of epoch 19: loss -3.56620 acc 0.34520 roc_auc 0.48244 prc_auc 0.32847[0m
[93maverage test of epoch 19: loss -3.58056 acc 0.34286 roc_auc 0.56567 prc_auc 0.40595[0m
[92maverage training of epoch 20: loss -3.59859 acc 0.34520 roc_auc 0.48392 prc_auc 0.32955[0m
[93maverage test of epoch 20: loss -3.61269 acc 0.34286 roc_auc 0.49909 prc_auc 0.36984[0m
[92maverage training of epoch 21: loss -3.63045 acc 0.34520 roc_auc 0.48526 prc_auc 0.33057[0m
[93maverage test of epoch 21: loss -3.64433 acc 0.34286 roc_auc 0.49819 prc_auc 0.36984[0m
[92maverage training of epoch 22: loss -3.66183 acc 0.34520 roc_auc 0.48608 prc_auc 0.33118[0m
[93maverage test of epoch 22: loss -3.67550 acc 0.34286 roc_auc 0.53487 prc_auc 0.39651[0m
[92maverage training of epoch 23: loss -3.69277 acc 0.34520 roc_auc 0.48678 prc_auc 0.33168[0m
[93maverage test of epoch 23: loss -3.70625 acc 0.34286 roc_auc 0.52944 prc_auc 0.38254[0m
[92maverage training of epoch 24: loss -3.72331 acc 0.34520 roc_auc 0.48762 prc_auc 0.33231[0m
[93maverage test of epoch 24: loss -3.73662 acc 0.34286 roc_auc 0.55525 prc_auc 0.39881[0m
[92maverage training of epoch 25: loss -3.75348 acc 0.34520 roc_auc 0.48821 prc_auc 0.33263[0m
[93maverage test of epoch 25: loss -3.76663 acc 0.34286 roc_auc 0.50000 prc_auc 0.37024[0m
[92maverage training of epoch 26: loss -3.78331 acc 0.34520 roc_auc 0.48832 prc_auc 0.33286[0m
[93maverage test of epoch 26: loss -3.79632 acc 0.34286 roc_auc 0.52083 prc_auc 0.37063[0m
[92maverage training of epoch 27: loss -3.81283 acc 0.34520 roc_auc 0.48938 prc_auc 0.33371[0m
[93maverage test of epoch 27: loss -3.82571 acc 0.34286 roc_auc 0.51042 prc_auc 0.37024[0m
[92maverage training of epoch 28: loss -3.84207 acc 0.34520 roc_auc 0.48969 prc_auc 0.33395[0m
[93maverage test of epoch 28: loss -3.85482 acc 0.34286 roc_auc 0.51042 prc_auc 0.37024[0m
[92maverage training of epoch 29: loss -3.87103 acc 0.34520 roc_auc 0.49050 prc_auc 0.33453[0m
[93maverage test of epoch 29: loss -3.88368 acc 0.34286 roc_auc 0.48958 prc_auc 0.36786[0m
[92maverage training of epoch 30: loss -3.89976 acc 0.34520 roc_auc 0.49120 prc_auc 0.33485[0m
[93maverage test of epoch 30: loss -3.91231 acc 0.34286 roc_auc 0.52083 prc_auc 0.37024[0m
[92maverage training of epoch 31: loss -3.92826 acc 0.34520 roc_auc 0.49188 prc_auc 0.33534[0m
[93maverage test of epoch 31: loss -3.94071 acc 0.34286 roc_auc 0.52129 prc_auc 0.37540[0m
[92maverage training of epoch 32: loss -3.95654 acc 0.34520 roc_auc 0.49227 prc_auc 0.33571[0m
[93maverage test of epoch 32: loss -3.96892 acc 0.34286 roc_auc 0.50000 prc_auc 0.37024[0m
[92maverage training of epoch 33: loss -3.98464 acc 0.34520 roc_auc 0.49286 prc_auc 0.33623[0m
[93maverage test of epoch 33: loss -3.99694 acc 0.34286 roc_auc 0.52083 prc_auc 0.37024[0m
[92maverage training of epoch 34: loss -4.01255 acc 0.34520 roc_auc 0.49347 prc_auc 0.33688[0m
[93maverage test of epoch 34: loss -4.02478 acc 0.34286 roc_auc 0.50000 prc_auc 0.37024[0m
[92maverage training of epoch 35: loss -4.04029 acc 0.34520 roc_auc 0.49406 prc_auc 0.33732[0m
[93maverage test of epoch 35: loss -4.05245 acc 0.34286 roc_auc 0.51042 prc_auc 0.37024[0m
[92maverage training of epoch 36: loss -4.06787 acc 0.34520 roc_auc 0.49451 prc_auc 0.33793[0m
[93maverage test of epoch 36: loss -4.07998 acc 0.34286 roc_auc 0.53125 prc_auc 0.37500[0m
[92maverage training of epoch 37: loss -4.09530 acc 0.34520 roc_auc 0.49490 prc_auc 0.33796[0m
[93maverage test of epoch 37: loss -4.10735 acc 0.34286 roc_auc 0.51042 prc_auc 0.37024[0m
[92maverage training of epoch 38: loss -4.12259 acc 0.34520 roc_auc 0.49538 prc_auc 0.33846[0m
[93maverage test of epoch 38: loss -4.13459 acc 0.34286 roc_auc 0.51042 prc_auc 0.37024[0m
[92maverage training of epoch 39: loss -4.14975 acc 0.34520 roc_auc 0.49563 prc_auc 0.33867[0m
[93maverage test of epoch 39: loss -4.16171 acc 0.34286 roc_auc 0.51042 prc_auc 0.37024[0m
[92maverage training of epoch 40: loss -4.17679 acc 0.34520 roc_auc 0.49583 prc_auc 0.33881[0m
[93maverage test of epoch 40: loss -4.18870 acc 0.34286 roc_auc 0.51042 prc_auc 0.37024[0m
[92maverage training of epoch 41: loss -4.20371 acc 0.34520 roc_auc 0.49639 prc_auc 0.33988[0m
[93maverage test of epoch 41: loss -4.21558 acc 0.34286 roc_auc 0.50091 prc_auc 0.37063[0m
[92maverage training of epoch 42: loss -4.23051 acc 0.34520 roc_auc 0.49647 prc_auc 0.34007[0m
[93maverage test of epoch 42: loss -4.24235 acc 0.34286 roc_auc 0.50000 prc_auc 0.37024[0m
[92maverage training of epoch 43: loss -4.25722 acc 0.34520 roc_auc 0.49653 prc_auc 0.34010[0m
[93maverage test of epoch 43: loss -4.26902 acc 0.34286 roc_auc 0.50000 prc_auc 0.37024[0m
[92maverage training of epoch 44: loss -4.28382 acc 0.34520 roc_auc 0.49675 prc_auc 0.34040[0m
[93maverage test of epoch 44: loss -4.29560 acc 0.34286 roc_auc 0.52083 prc_auc 0.37102[0m
[92maverage training of epoch 45: loss -4.31034 acc 0.34520 roc_auc 0.49686 prc_auc 0.34056[0m
[93maverage test of epoch 45: loss -4.32208 acc 0.34286 roc_auc 0.50000 prc_auc 0.37024[0m
[92maverage training of epoch 46: loss -4.33676 acc 0.34520 roc_auc 0.49709 prc_auc 0.34084[0m
[93maverage test of epoch 46: loss -4.34848 acc 0.34286 roc_auc 0.50000 prc_auc 0.37024[0m
[92maverage training of epoch 47: loss -4.36310 acc 0.34520 roc_auc 0.49734 prc_auc 0.34113[0m
[93maverage test of epoch 47: loss -4.37480 acc 0.34286 roc_auc 0.53125 prc_auc 0.37500[0m
[92maverage training of epoch 48: loss -4.38936 acc 0.34520 roc_auc 0.49748 prc_auc 0.34124[0m
[93maverage test of epoch 48: loss -4.40104 acc 0.34286 roc_auc 0.50000 prc_auc 0.37024[0m
[92maverage training of epoch 49: loss -4.41555 acc 0.34520 roc_auc 0.49756 prc_auc 0.34143[0m
[93maverage test of epoch 49: loss -4.42721 acc 0.34286 roc_auc 0.50000 prc_auc 0.36984[0m
Training model with dataset, testing using fold 2
DfscodeRnn_cls args.lr:  0.003
[92maverage training of epoch 0: loss -1.35150 acc 0.64769 roc_auc 0.50611 prc_auc 0.36990[0m
[93maverage test of epoch 0: loss -2.06259 acc 0.65714 roc_auc 0.56703 prc_auc 0.36863[0m
[92maverage training of epoch 1: loss -2.19969 acc 0.65480 roc_auc 0.50611 prc_auc 0.37178[0m
[93maverage test of epoch 1: loss -2.28899 acc 0.65714 roc_auc 0.54076 prc_auc 0.37555[0m
[92maverage training of epoch 2: loss -2.33288 acc 0.65480 roc_auc 0.50577 prc_auc 0.37088[0m
[93maverage test of epoch 2: loss -2.38676 acc 0.65714 roc_auc 0.46603 prc_auc 0.34879[0m
[92maverage training of epoch 3: loss -2.39309 acc 0.65480 roc_auc 0.50574 prc_auc 0.37038[0m
[93maverage test of epoch 3: loss -2.41888 acc 0.65714 roc_auc 0.52174 prc_auc 0.36169[0m
[92maverage training of epoch 4: loss -2.42506 acc 0.65480 roc_auc 0.50585 prc_auc 0.37091[0m
[93maverage test of epoch 4: loss -2.45082 acc 0.65714 roc_auc 0.51359 prc_auc 0.36027[0m
[92maverage training of epoch 5: loss -2.45687 acc 0.65480 roc_auc 0.50571 prc_auc 0.37054[0m
[93maverage test of epoch 5: loss -2.48262 acc 0.65714 roc_auc 0.55842 prc_auc 0.37036[0m
[92maverage training of epoch 6: loss -2.48855 acc 0.65480 roc_auc 0.50563 prc_auc 0.37024[0m
[93maverage test of epoch 6: loss -2.51428 acc 0.65714 roc_auc 0.51676 prc_auc 0.35027[0m
[92maverage training of epoch 7: loss -2.52009 acc 0.65480 roc_auc 0.50546 prc_auc 0.37015[0m
[93maverage test of epoch 7: loss -2.54580 acc 0.65714 roc_auc 0.48370 prc_auc 0.33724[0m
[92maverage training of epoch 8: loss -2.55149 acc 0.65480 roc_auc 0.50521 prc_auc 0.36988[0m
[93maverage test of epoch 8: loss -2.57718 acc 0.65714 roc_auc 0.51857 prc_auc 0.34910[0m
[92maverage training of epoch 9: loss -2.58275 acc 0.65480 roc_auc 0.50504 prc_auc 0.36973[0m
[93maverage test of epoch 9: loss -2.60843 acc 0.65714 roc_auc 0.46241 prc_auc 0.33023[0m
[92maverage training of epoch 10: loss -2.61388 acc 0.65480 roc_auc 0.50501 prc_auc 0.36962[0m
[93maverage test of epoch 10: loss -2.63955 acc 0.65714 roc_auc 0.53351 prc_auc 0.35587[0m
[92maverage training of epoch 11: loss -2.64488 acc 0.65480 roc_auc 0.50487 prc_auc 0.36949[0m
[93maverage test of epoch 11: loss -2.67053 acc 0.65714 roc_auc 0.43659 prc_auc 0.31876[0m
[92maverage training of epoch 12: loss -2.67575 acc 0.65480 roc_auc 0.50468 prc_auc 0.36921[0m
[93maverage test of epoch 12: loss -2.70140 acc 0.65714 roc_auc 0.48868 prc_auc 0.34043[0m
[92maverage training of epoch 13: loss -2.70650 acc 0.65480 roc_auc 0.50451 prc_auc 0.36907[0m
[93maverage test of epoch 13: loss -2.73214 acc 0.65714 roc_auc 0.49411 prc_auc 0.34359[0m
[92maverage training of epoch 14: loss -2.73714 acc 0.65480 roc_auc 0.50420 prc_auc 0.36892[0m
[93maverage test of epoch 14: loss -2.76276 acc 0.65714 roc_auc 0.40625 prc_auc 0.31137[0m
[92maverage training of epoch 15: loss -2.76765 acc 0.65480 roc_auc 0.50409 prc_auc 0.36900[0m
[93maverage test of epoch 15: loss -2.79326 acc 0.65714 roc_auc 0.52174 prc_auc 0.34792[0m
[92maverage training of epoch 16: loss -2.79805 acc 0.65480 roc_auc 0.50395 prc_auc 0.36870[0m
[93maverage test of epoch 16: loss -2.82366 acc 0.65714 roc_auc 0.46920 prc_auc 0.32843[0m
[92maverage training of epoch 17: loss -2.82834 acc 0.65480 roc_auc 0.50381 prc_auc 0.36870[0m
[93maverage test of epoch 17: loss -2.85394 acc 0.65714 roc_auc 0.43705 prc_auc 0.33033[0m
[92maverage training of epoch 18: loss -2.85853 acc 0.65480 roc_auc 0.50359 prc_auc 0.36815[0m
[93maverage test of epoch 18: loss -2.88411 acc 0.65714 roc_auc 0.54167 prc_auc 0.37150[0m
[92maverage training of epoch 19: loss -2.88860 acc 0.65480 roc_auc 0.50342 prc_auc 0.36778[0m
[93maverage test of epoch 19: loss -2.91418 acc 0.65714 roc_auc 0.44973 prc_auc 0.32976[0m
[92maverage training of epoch 20: loss -2.91858 acc 0.65480 roc_auc 0.50291 prc_auc 0.36715[0m
[93maverage test of epoch 20: loss -2.94415 acc 0.65714 roc_auc 0.44792 prc_auc 0.32679[0m
[92maverage training of epoch 21: loss -2.94844 acc 0.65480 roc_auc 0.50275 prc_auc 0.36687[0m
[93maverage test of epoch 21: loss -2.97401 acc 0.65714 roc_auc 0.46694 prc_auc 0.33849[0m
[92maverage training of epoch 22: loss -2.97821 acc 0.65480 roc_auc 0.50241 prc_auc 0.36607[0m
[93maverage test of epoch 22: loss -3.00376 acc 0.65714 roc_auc 0.49728 prc_auc 0.34206[0m
[92maverage training of epoch 23: loss -3.00787 acc 0.65480 roc_auc 0.50221 prc_auc 0.36575[0m
[93maverage test of epoch 23: loss -3.03342 acc 0.65714 roc_auc 0.46558 prc_auc 0.33743[0m
[92maverage training of epoch 24: loss -3.03743 acc 0.65480 roc_auc 0.50185 prc_auc 0.36509[0m
[93maverage test of epoch 24: loss -3.06298 acc 0.65714 roc_auc 0.46513 prc_auc 0.33396[0m
[92maverage training of epoch 25: loss -3.06690 acc 0.65480 roc_auc 0.50129 prc_auc 0.36449[0m
[93maverage test of epoch 25: loss -3.09243 acc 0.65714 roc_auc 0.47826 prc_auc 0.33373[0m
[92maverage training of epoch 26: loss -3.09626 acc 0.65480 roc_auc 0.50084 prc_auc 0.36420[0m
[93maverage test of epoch 26: loss -3.12179 acc 0.65714 roc_auc 0.48732 prc_auc 0.33899[0m
[92maverage training of epoch 27: loss -3.12553 acc 0.65480 roc_auc 0.50059 prc_auc 0.36400[0m
[93maverage test of epoch 27: loss -3.15105 acc 0.65714 roc_auc 0.45063 prc_auc 0.32282[0m
[92maverage training of epoch 28: loss -3.15470 acc 0.65480 roc_auc 0.50025 prc_auc 0.36894[0m
[93maverage test of epoch 28: loss -3.18021 acc 0.65714 roc_auc 0.46558 prc_auc 0.33552[0m
[92maverage training of epoch 29: loss -3.18377 acc 0.65480 roc_auc 0.49994 prc_auc 0.36853[0m
[93maverage test of epoch 29: loss -3.20927 acc 0.65714 roc_auc 0.46014 prc_auc 0.32758[0m
[92maverage training of epoch 30: loss -3.21275 acc 0.65480 roc_auc 0.50067 prc_auc 0.37180[0m
[93maverage test of epoch 30: loss -3.23824 acc 0.65714 roc_auc 0.42844 prc_auc 0.31964[0m
[92maverage training of epoch 31: loss -3.24163 acc 0.65480 roc_auc 0.50064 prc_auc 0.37164[0m
[93maverage test of epoch 31: loss -3.26712 acc 0.65714 roc_auc 0.49728 prc_auc 0.34206[0m
[92maverage training of epoch 32: loss -3.27042 acc 0.65480 roc_auc 0.50045 prc_auc 0.37162[0m
[93maverage test of epoch 32: loss -3.29590 acc 0.65714 roc_auc 0.48732 prc_auc 0.33899[0m
[92maverage training of epoch 33: loss -3.29912 acc 0.65480 roc_auc 0.50053 prc_auc 0.37135[0m
[93maverage test of epoch 33: loss -3.32459 acc 0.65714 roc_auc 0.49774 prc_auc 0.34206[0m
[92maverage training of epoch 34: loss -3.32772 acc 0.65480 roc_auc 0.50045 prc_auc 0.37155[0m
[93maverage test of epoch 34: loss -3.35318 acc 0.65714 roc_auc 0.47826 prc_auc 0.34286[0m
[92maverage training of epoch 35: loss -3.35624 acc 0.65480 roc_auc 0.50028 prc_auc 0.37127[0m
[93maverage test of epoch 35: loss -3.38170 acc 0.65714 roc_auc 0.44384 prc_auc 0.32944[0m
[92maverage training of epoch 36: loss -3.38467 acc 0.65480 roc_auc 0.50011 prc_auc 0.36554[0m
[93maverage test of epoch 36: loss -3.41012 acc 0.65714 roc_auc 0.46558 prc_auc 0.33280[0m
[92maverage training of epoch 37: loss -3.41302 acc 0.65480 roc_auc 0.49980 prc_auc 0.36481[0m
[93maverage test of epoch 37: loss -3.43846 acc 0.65714 roc_auc 0.49774 prc_auc 0.34206[0m
[92maverage training of epoch 38: loss -3.44129 acc 0.65480 roc_auc 0.49933 prc_auc 0.36220[0m
[93maverage test of epoch 38: loss -3.46672 acc 0.65714 roc_auc 0.44384 prc_auc 0.32672[0m
[92maverage training of epoch 39: loss -3.46947 acc 0.65480 roc_auc 0.49950 prc_auc 0.36261[0m
[93maverage test of epoch 39: loss -3.49490 acc 0.65714 roc_auc 0.50000 prc_auc 0.34286[0m
[92maverage training of epoch 40: loss -3.49758 acc 0.65480 roc_auc 0.49938 prc_auc 0.36306[0m
[93maverage test of epoch 40: loss -3.52300 acc 0.65714 roc_auc 0.49547 prc_auc 0.34087[0m
[92maverage training of epoch 41: loss -3.52560 acc 0.65480 roc_auc 0.49941 prc_auc 0.36146[0m
[93maverage test of epoch 41: loss -3.55101 acc 0.65714 roc_auc 0.55072 prc_auc 0.36825[0m
[92maverage training of epoch 42: loss -3.55355 acc 0.65480 roc_auc 0.49916 prc_auc 0.36091[0m
[93maverage test of epoch 42: loss -3.57895 acc 0.65714 roc_auc 0.50000 prc_auc 0.34286[0m
[92maverage training of epoch 43: loss -3.58141 acc 0.65480 roc_auc 0.49882 prc_auc 0.36021[0m
[93maverage test of epoch 43: loss -3.60681 acc 0.65714 roc_auc 0.50000 prc_auc 0.34286[0m
[92maverage training of epoch 44: loss -3.60920 acc 0.65480 roc_auc 0.49871 prc_auc 0.35985[0m
[93maverage test of epoch 44: loss -3.63458 acc 0.65714 roc_auc 0.49909 prc_auc 0.34246[0m
[92maverage training of epoch 45: loss -3.63690 acc 0.65480 roc_auc 0.49840 prc_auc 0.35932[0m
[93maverage test of epoch 45: loss -3.66228 acc 0.65714 roc_auc 0.49909 prc_auc 0.34246[0m
[92maverage training of epoch 46: loss -3.66452 acc 0.65480 roc_auc 0.49863 prc_auc 0.35968[0m
[93maverage test of epoch 46: loss -3.68990 acc 0.65714 roc_auc 0.48732 prc_auc 0.33810[0m
[92maverage training of epoch 47: loss -3.69207 acc 0.65480 roc_auc 0.49930 prc_auc 0.35925[0m
[93maverage test of epoch 47: loss -3.71743 acc 0.65714 roc_auc 0.50000 prc_auc 0.34286[0m
[92maverage training of epoch 48: loss -3.71954 acc 0.65480 roc_auc 0.49899 prc_auc 0.35812[0m
[93maverage test of epoch 48: loss -3.74489 acc 0.65714 roc_auc 0.49728 prc_auc 0.33859[0m
[92maverage training of epoch 49: loss -3.74693 acc 0.65480 roc_auc 0.49838 prc_auc 0.35677[0m
[93maverage test of epoch 49: loss -3.77228 acc 0.65714 roc_auc 0.47645 prc_auc 0.33512[0m
Training model with dataset, testing using fold 3
DfscodeRnn_cls args.lr:  0.003
[92maverage training of epoch 0: loss -1.11057 acc 0.56584 roc_auc 0.48554 prc_auc 0.34722[0m
[93maverage test of epoch 0: loss -1.82419 acc 0.65714 roc_auc 0.51268 prc_auc 0.34868[0m
[92maverage training of epoch 1: loss -1.94640 acc 0.65480 roc_auc 0.48201 prc_auc 0.33950[0m
[93maverage test of epoch 1: loss -2.01817 acc 0.65714 roc_auc 0.48913 prc_auc 0.34286[0m
[92maverage training of epoch 2: loss -2.06422 acc 0.65480 roc_auc 0.48661 prc_auc 0.34356[0m
[93maverage test of epoch 2: loss -2.10723 acc 0.65714 roc_auc 0.52310 prc_auc 0.35360[0m
[92maverage training of epoch 3: loss -2.11988 acc 0.65480 roc_auc 0.48650 prc_auc 0.34481[0m
[93maverage test of epoch 3: loss -2.13690 acc 0.65714 roc_auc 0.43614 prc_auc 0.34173[0m
[92maverage training of epoch 4: loss -2.14944 acc 0.65480 roc_auc 0.48703 prc_auc 0.34542[0m
[93maverage test of epoch 4: loss -2.16658 acc 0.65714 roc_auc 0.46649 prc_auc 0.32735[0m
[92maverage training of epoch 5: loss -2.17906 acc 0.65480 roc_auc 0.48795 prc_auc 0.34608[0m
[93maverage test of epoch 5: loss -2.19635 acc 0.65714 roc_auc 0.38859 prc_auc 0.30249[0m
[92maverage training of epoch 6: loss -2.20878 acc 0.65480 roc_auc 0.48846 prc_auc 0.34711[0m
[93maverage test of epoch 6: loss -2.22622 acc 0.65714 roc_auc 0.54620 prc_auc 0.36940[0m
[92maverage training of epoch 7: loss -2.23859 acc 0.65480 roc_auc 0.48891 prc_auc 0.34748[0m
[93maverage test of epoch 7: loss -2.25620 acc 0.65714 roc_auc 0.45743 prc_auc 0.34013[0m
[92maverage training of epoch 8: loss -2.26851 acc 0.65480 roc_auc 0.48924 prc_auc 0.34755[0m
[93maverage test of epoch 8: loss -2.28628 acc 0.65714 roc_auc 0.54846 prc_auc 0.37352[0m
[92maverage training of epoch 9: loss -2.29853 acc 0.65480 roc_auc 0.48975 prc_auc 0.34867[0m
[93maverage test of epoch 9: loss -2.31645 acc 0.65714 roc_auc 0.51676 prc_auc 0.35185[0m
[92maverage training of epoch 10: loss -2.32863 acc 0.65480 roc_auc 0.48991 prc_auc 0.34865[0m
[93maverage test of epoch 10: loss -2.34670 acc 0.65714 roc_auc 0.55072 prc_auc 0.37157[0m
[92maverage training of epoch 11: loss -2.35879 acc 0.65480 roc_auc 0.49081 prc_auc 0.34989[0m
[93maverage test of epoch 11: loss -2.37700 acc 0.65714 roc_auc 0.55616 prc_auc 0.37441[0m
[92maverage training of epoch 12: loss -2.38900 acc 0.65480 roc_auc 0.49092 prc_auc 0.35027[0m
[93maverage test of epoch 12: loss -2.40734 acc 0.65714 roc_auc 0.54891 prc_auc 0.37180[0m
[92maverage training of epoch 13: loss -2.41923 acc 0.65480 roc_auc 0.49126 prc_auc 0.35075[0m
[93maverage test of epoch 13: loss -2.43768 acc 0.65714 roc_auc 0.51721 prc_auc 0.36235[0m
[92maverage training of epoch 14: loss -2.44945 acc 0.65480 roc_auc 0.49204 prc_auc 0.35166[0m
[93maverage test of epoch 14: loss -2.46800 acc 0.65714 roc_auc 0.54891 prc_auc 0.37808[0m
[92maverage training of epoch 15: loss -2.47965 acc 0.65480 roc_auc 0.49224 prc_auc 0.35156[0m
[93maverage test of epoch 15: loss -2.49829 acc 0.65714 roc_auc 0.51902 prc_auc 0.35385[0m
[92maverage training of epoch 16: loss -2.50980 acc 0.65480 roc_auc 0.49238 prc_auc 0.35153[0m
[93maverage test of epoch 16: loss -2.52851 acc 0.65714 roc_auc 0.46694 prc_auc 0.32448[0m
[92maverage training of epoch 17: loss -2.53987 acc 0.65480 roc_auc 0.49255 prc_auc 0.35144[0m
[93maverage test of epoch 17: loss -2.55865 acc 0.65714 roc_auc 0.49411 prc_auc 0.34017[0m
[92maverage training of epoch 18: loss -2.56986 acc 0.65480 roc_auc 0.49322 prc_auc 0.35235[0m
[93maverage test of epoch 18: loss -2.58868 acc 0.65714 roc_auc 0.58967 prc_auc 0.45459[0m
[92maverage training of epoch 19: loss -2.59975 acc 0.65480 roc_auc 0.49372 prc_auc 0.35256[0m
[93maverage test of epoch 19: loss -2.61861 acc 0.65714 roc_auc 0.48596 prc_auc 0.34114[0m
[92maverage training of epoch 20: loss -2.62951 acc 0.65480 roc_auc 0.49389 prc_auc 0.35256[0m
[93maverage test of epoch 20: loss -2.64841 acc 0.65714 roc_auc 0.50000 prc_auc 0.34930[0m
[92maverage training of epoch 21: loss -2.65916 acc 0.65480 roc_auc 0.49440 prc_auc 0.35342[0m
[93maverage test of epoch 21: loss -2.67808 acc 0.65714 roc_auc 0.46920 prc_auc 0.32774[0m
[92maverage training of epoch 22: loss -2.68867 acc 0.65480 roc_auc 0.49501 prc_auc 0.35406[0m
[93maverage test of epoch 22: loss -2.70762 acc 0.65714 roc_auc 0.50226 prc_auc 0.36267[0m
[92maverage training of epoch 23: loss -2.71805 acc 0.65480 roc_auc 0.49560 prc_auc 0.35502[0m
[93maverage test of epoch 23: loss -2.73702 acc 0.65714 roc_auc 0.50996 prc_auc 0.35318[0m
[92maverage training of epoch 24: loss -2.74730 acc 0.65480 roc_auc 0.49602 prc_auc 0.35590[0m
[93maverage test of epoch 24: loss -2.76629 acc 0.65714 roc_auc 0.46603 prc_auc 0.32408[0m
[92maverage training of epoch 25: loss -2.77643 acc 0.65480 roc_auc 0.49602 prc_auc 0.35617[0m
[93maverage test of epoch 25: loss -2.79543 acc 0.65714 roc_auc 0.46784 prc_auc 0.32373[0m
[92maverage training of epoch 26: loss -2.80542 acc 0.65480 roc_auc 0.49636 prc_auc 0.35691[0m
[93maverage test of epoch 26: loss -2.82444 acc 0.65714 roc_auc 0.46196 prc_auc 0.32261[0m
[92maverage training of epoch 27: loss -2.83430 acc 0.65480 roc_auc 0.49619 prc_auc 0.35799[0m
[93maverage test of epoch 27: loss -2.85334 acc 0.65714 roc_auc 0.50589 prc_auc 0.37435[0m
[92maverage training of epoch 28: loss -2.86307 acc 0.65480 roc_auc 0.49641 prc_auc 0.35816[0m
[93maverage test of epoch 28: loss -2.88212 acc 0.65714 roc_auc 0.51132 prc_auc 0.37030[0m
[92maverage training of epoch 29: loss -2.89172 acc 0.65480 roc_auc 0.49625 prc_auc 0.35784[0m
[93maverage test of epoch 29: loss -2.91080 acc 0.65714 roc_auc 0.48868 prc_auc 0.34939[0m
[92maverage training of epoch 30: loss -2.92028 acc 0.65480 roc_auc 0.49658 prc_auc 0.36471[0m
[93maverage test of epoch 30: loss -2.93938 acc 0.65714 roc_auc 0.50317 prc_auc 0.36032[0m
[92maverage training of epoch 31: loss -2.94875 acc 0.65480 roc_auc 0.49641 prc_auc 0.36459[0m
[93maverage test of epoch 31: loss -2.96787 acc 0.65714 roc_auc 0.52310 prc_auc 0.39526[0m
[92maverage training of epoch 32: loss -2.97713 acc 0.65480 roc_auc 0.49625 prc_auc 0.36424[0m
[93maverage test of epoch 32: loss -2.99628 acc 0.65714 roc_auc 0.47418 prc_auc 0.32817[0m
[92maverage training of epoch 33: loss -3.00544 acc 0.65480 roc_auc 0.49641 prc_auc 0.36425[0m
[93maverage test of epoch 33: loss -3.02462 acc 0.65714 roc_auc 0.48777 prc_auc 0.33813[0m
[92maverage training of epoch 34: loss -3.03368 acc 0.65480 roc_auc 0.49810 prc_auc 0.36457[0m
[93maverage test of epoch 34: loss -3.05288 acc 0.65714 roc_auc 0.52446 prc_auc 0.39045[0m
[92maverage training of epoch 35: loss -3.06185 acc 0.65480 roc_auc 0.49905 prc_auc 0.36483[0m
[93maverage test of epoch 35: loss -3.08109 acc 0.65714 roc_auc 0.50317 prc_auc 0.34817[0m
[92maverage training of epoch 36: loss -3.08998 acc 0.65480 roc_auc 0.49966 prc_auc 0.36499[0m
[93maverage test of epoch 36: loss -3.10925 acc 0.65714 roc_auc 0.50272 prc_auc 0.35728[0m
[92maverage training of epoch 37: loss -3.11805 acc 0.65480 roc_auc 0.50050 prc_auc 0.36530[0m
[93maverage test of epoch 37: loss -3.13737 acc 0.65714 roc_auc 0.48551 prc_auc 0.33704[0m
[92maverage training of epoch 38: loss -3.14609 acc 0.65480 roc_auc 0.50112 prc_auc 0.36543[0m
[93maverage test of epoch 38: loss -3.16544 acc 0.65714 roc_auc 0.52944 prc_auc 0.38583[0m
[92maverage training of epoch 39: loss -3.17409 acc 0.65480 roc_auc 0.50210 prc_auc 0.36613[0m
[93maverage test of epoch 39: loss -3.19348 acc 0.65714 roc_auc 0.50815 prc_auc 0.36550[0m
[92maverage training of epoch 40: loss -3.20206 acc 0.65480 roc_auc 0.50252 prc_auc 0.36622[0m
[93maverage test of epoch 40: loss -3.22149 acc 0.65714 roc_auc 0.50679 prc_auc 0.36912[0m
[92maverage training of epoch 41: loss -3.23000 acc 0.65480 roc_auc 0.50294 prc_auc 0.36642[0m
[93maverage test of epoch 41: loss -3.24949 acc 0.65714 roc_auc 0.50725 prc_auc 0.35017[0m
[92maverage training of epoch 42: loss -3.25793 acc 0.65480 roc_auc 0.50336 prc_auc 0.36663[0m
[93maverage test of epoch 42: loss -3.27746 acc 0.65714 roc_auc 0.46966 prc_auc 0.32933[0m
[92maverage training of epoch 43: loss -3.28585 acc 0.65480 roc_auc 0.50398 prc_auc 0.36776[0m
[93maverage test of epoch 43: loss -3.30542 acc 0.65714 roc_auc 0.51495 prc_auc 0.35882[0m
[92maverage training of epoch 44: loss -3.31375 acc 0.65480 roc_auc 0.50431 prc_auc 0.36705[0mUsing backend: pytorch

[93maverage test of epoch 44: loss -3.33338 acc 0.65714 roc_auc 0.53080 prc_auc 0.39031[0m
[92maverage training of epoch 45: loss -3.34164 acc 0.65480 roc_auc 0.50465 prc_auc 0.36709[0m
[93maverage test of epoch 45: loss -3.36132 acc 0.65714 roc_auc 0.51132 prc_auc 0.35795[0m
[92maverage training of epoch 46: loss -3.36953 acc 0.65480 roc_auc 0.50493 prc_auc 0.36771[0m
[93maverage test of epoch 46: loss -3.38926 acc 0.65714 roc_auc 0.48868 prc_auc 0.34021[0m
[92maverage training of epoch 47: loss -3.39743 acc 0.65480 roc_auc 0.50499 prc_auc 0.36740[0m
[93maverage test of epoch 47: loss -3.41721 acc 0.65714 roc_auc 0.49366 prc_auc 0.33928[0m
[92maverage training of epoch 48: loss -3.42532 acc 0.65480 roc_auc 0.50527 prc_auc 0.36727[0m
[93maverage test of epoch 48: loss -3.44515 acc 0.65714 roc_auc 0.47283 prc_auc 0.32698[0m
[92maverage training of epoch 49: loss -3.45321 acc 0.65480 roc_auc 0.50532 prc_auc 0.36719[0m
[93maverage test of epoch 49: loss -3.47310 acc 0.65714 roc_auc 0.49683 prc_auc 0.34205[0m
Training model with dataset, testing using fold 4
DfscodeRnn_cls args.lr:  0.003
[92maverage training of epoch 0: loss -1.39649 acc 0.61922 roc_auc 0.50784 prc_auc 0.36065[0m
[93maverage test of epoch 0: loss -1.98790 acc 0.65714 roc_auc 0.49230 prc_auc 0.33012[0m
[92maverage training of epoch 1: loss -2.12098 acc 0.65480 roc_auc 0.50992 prc_auc 0.37618[0m
[93maverage test of epoch 1: loss -2.19123 acc 0.65714 roc_auc 0.48007 prc_auc 0.33340[0m
[92maverage training of epoch 2: loss -2.23686 acc 0.65480 roc_auc 0.50482 prc_auc 0.37175[0m
[93maverage test of epoch 2: loss -2.27472 acc 0.65714 roc_auc 0.47871 prc_auc 0.33215[0m
[92maverage training of epoch 3: loss -2.28769 acc 0.65480 roc_auc 0.50882 prc_auc 0.38680[0m
[93maverage test of epoch 3: loss -2.30172 acc 0.65714 roc_auc 0.49049 prc_auc 0.33424[0m
[92maverage training of epoch 4: loss -2.31422 acc 0.65480 roc_auc 0.50840 prc_auc 0.38626[0m
[93maverage test of epoch 4: loss -2.32843 acc 0.65714 roc_auc 0.48279 prc_auc 0.33223[0m
[92maverage training of epoch 5: loss -2.34048 acc 0.65480 roc_auc 0.50759 prc_auc 0.38645[0m
[93maverage test of epoch 5: loss -2.35490 acc 0.65714 roc_auc 0.48370 prc_auc 0.33453[0m
[92maverage training of epoch 6: loss -2.36650 acc 0.65480 roc_auc 0.50672 prc_auc 0.38529[0m
[93maverage test of epoch 6: loss -2.38116 acc 0.65714 roc_auc 0.49864 prc_auc 0.33817[0m
[92maverage training of epoch 7: loss -2.39231 acc 0.65480 roc_auc 0.50588 prc_auc 0.38539[0m
[93maverage test of epoch 7: loss -2.40722 acc 0.65714 roc_auc 0.49547 prc_auc 0.34016[0m
[92maverage training of epoch 8: loss -2.41795 acc 0.65480 roc_auc 0.50543 prc_auc 0.38374[0m
[93maverage test of epoch 8: loss -2.43312 acc 0.65714 roc_auc 0.48370 prc_auc 0.33455[0m
[92maverage training of epoch 9: loss -2.44345 acc 0.65480 roc_auc 0.50431 prc_auc 0.38027[0m
[93maverage test of epoch 9: loss -2.45888 acc 0.65714 roc_auc 0.48324 prc_auc 0.33450[0m
[92maverage training of epoch 10: loss -2.46883 acc 0.65480 roc_auc 0.50300 prc_auc 0.37818[0m
[93maverage test of epoch 10: loss -2.48453 acc 0.65714 roc_auc 0.50045 prc_auc 0.33874[0m
[92maverage training of epoch 11: loss -2.49413 acc 0.65480 roc_auc 0.50050 prc_auc 0.36638[0m
[93maverage test of epoch 11: loss -2.51010 acc 0.65714 roc_auc 0.48777 prc_auc 0.34006[0m
[92maverage training of epoch 12: loss -2.51937 acc 0.65480 roc_auc 0.49919 prc_auc 0.36519[0m
[93maverage test of epoch 12: loss -2.53561 acc 0.65714 roc_auc 0.48505 prc_auc 0.33541[0m
[92maverage training of epoch 13: loss -2.54458 acc 0.65480 roc_auc 0.49770 prc_auc 0.36397[0m
[93maverage test of epoch 13: loss -2.56109 acc 0.65714 roc_auc 0.47328 prc_auc 0.32805[0m
[92maverage training of epoch 14: loss -2.56977 acc 0.65480 roc_auc 0.49527 prc_auc 0.36260[0m
[93maverage test of epoch 14: loss -2.58655 acc 0.65714 roc_auc 0.48279 prc_auc 0.33425[0m
[92maverage training of epoch 15: loss -2.59498 acc 0.65480 roc_auc 0.49431 prc_auc 0.36169[0m
[93maverage test of epoch 15: loss -2.61202 acc 0.65714 roc_auc 0.49139 prc_auc 0.33541[0m
[92maverage training of epoch 16: loss -2.62021 acc 0.65480 roc_auc 0.49238 prc_auc 0.36044[0m
[93maverage test of epoch 16: loss -2.63750 acc 0.65714 roc_auc 0.47328 prc_auc 0.33125[0m
[92maverage training of epoch 17: loss -2.64547 acc 0.65480 roc_auc 0.49120 prc_auc 0.35856[0m
[93maverage test of epoch 17: loss -2.66302 acc 0.65714 roc_auc 0.48279 prc_auc 0.33078[0m
[92maverage training of epoch 18: loss -2.67078 acc 0.65480 roc_auc 0.48896 prc_auc 0.35547[0m
[93maverage test of epoch 18: loss -2.68857 acc 0.65714 roc_auc 0.48007 prc_auc 0.33078[0m
[92maverage training of epoch 19: loss -2.69614 acc 0.65480 roc_auc 0.48655 prc_auc 0.35387[0m
[93maverage test of epoch 19: loss -2.71416 acc 0.65714 roc_auc 0.48460 prc_auc 0.33466[0m
[92maverage training of epoch 20: loss -2.72156 acc 0.65480 roc_auc 0.48420 prc_auc 0.35296[0m
[93maverage test of epoch 20: loss -2.73982 acc 0.65714 roc_auc 0.48234 prc_auc 0.32819[0m
[92maverage training of epoch 21: loss -2.74705 acc 0.65480 roc_auc 0.48129 prc_auc 0.35007[0m
[93maverage test of epoch 21: loss -2.76553 acc 0.65714 roc_auc 0.49411 prc_auc 0.34025[0m
[92maverage training of epoch 22: loss -2.77262 acc 0.65480 roc_auc 0.47952 prc_auc 0.34840[0m
[93maverage test of epoch 22: loss -2.79132 acc 0.65714 roc_auc 0.50181 prc_auc 0.33895[0m
[92maverage training of epoch 23: loss -2.79827 acc 0.65480 roc_auc 0.47700 prc_auc 0.34676[0m
[93maverage test of epoch 23: loss -2.81718 acc 0.65714 roc_auc 0.50634 prc_auc 0.34068[0m
[92maverage training of epoch 24: loss -2.82402 acc 0.65480 roc_auc 0.47462 prc_auc 0.34490[0m
[93maverage test of epoch 24: loss -2.84312 acc 0.65714 roc_auc 0.47101 prc_auc 0.32790[0m
[92maverage training of epoch 25: loss -2.84985 acc 0.65480 roc_auc 0.47397 prc_auc 0.34332[0m
[93maverage test of epoch 25: loss -2.86915 acc 0.65714 roc_auc 0.49049 prc_auc 0.33165[0m
[92maverage training of epoch 26: loss -2.87579 acc 0.65480 roc_auc 0.47134 prc_auc 0.34137[0m
[93maverage test of epoch 26: loss -2.89527 acc 0.65714 roc_auc 0.48188 prc_auc 0.32785[0m
[92maverage training of epoch 27: loss -2.90184 acc 0.65480 roc_auc 0.46966 prc_auc 0.34038[0m
[93maverage test of epoch 27: loss -2.92149 acc 0.65714 roc_auc 0.47781 prc_auc 0.33834[0m
[92maverage training of epoch 28: loss -2.92799 acc 0.65480 roc_auc 0.46728 prc_auc 0.33744[0m
[93maverage test of epoch 28: loss -2.94782 acc 0.65714 roc_auc 0.49638 prc_auc 0.34035[0m
[92maverage training of epoch 29: loss -2.95428 acc 0.65480 roc_auc 0.46456 prc_auc 0.33495[0m
[93maverage test of epoch 29: loss -2.97427 acc 0.65714 roc_auc 0.48687 prc_auc 0.33341[0m
[92maverage training of epoch 30: loss -2.98069 acc 0.65480 roc_auc 0.46288 prc_auc 0.33353[0m
[93maverage test of epoch 30: loss -3.00085 acc 0.65714 roc_auc 0.47373 prc_auc 0.32858[0m
[92maverage training of epoch 31: loss -3.00725 acc 0.65480 roc_auc 0.46098 prc_auc 0.33243[0m
[93maverage test of epoch 31: loss -3.02756 acc 0.65714 roc_auc 0.48913 prc_auc 0.33437[0m
[92maverage training of epoch 32: loss -3.03396 acc 0.65480 roc_auc 0.45820 prc_auc 0.33041[0m
[93maverage test of epoch 32: loss -3.05442 acc 0.65714 roc_auc 0.47554 prc_auc 0.33079[0m
[92maverage training of epoch 33: loss -3.06083 acc 0.65480 roc_auc 0.45675 prc_auc 0.32846[0m
[93maverage test of epoch 33: loss -3.08144 acc 0.65714 roc_auc 0.49185 prc_auc 0.33040[0m
[92maverage training of epoch 34: loss -3.08787 acc 0.65480 roc_auc 0.45450 prc_auc 0.32658[0m
[93maverage test of epoch 34: loss -3.10863 acc 0.65714 roc_auc 0.48868 prc_auc 0.34043[0m
[92maverage training of epoch 35: loss -3.11510 acc 0.65480 roc_auc 0.44585 prc_auc 0.32234[0m
[93maverage test of epoch 35: loss -3.13601 acc 0.65714 roc_auc 0.48188 prc_auc 0.33164[0m
[92maverage training of epoch 36: loss -3.14252 acc 0.65480 roc_auc 0.43814 prc_auc 0.31876[0m
[93maverage test of epoch 36: loss -3.16357 acc 0.65714 roc_auc 0.49592 prc_auc 0.34460[0m
[92maverage training of epoch 37: loss -3.17014 acc 0.65480 roc_auc 0.43747 prc_auc 0.31850[0m
[93maverage test of epoch 37: loss -3.19134 acc 0.65714 roc_auc 0.48460 prc_auc 0.33428[0m
[92maverage training of epoch 38: loss -3.19797 acc 0.65480 roc_auc 0.43361 prc_auc 0.31610[0m
[93maverage test of epoch 38: loss -3.21932 acc 0.65714 roc_auc 0.51087 prc_auc 0.34330[0m
[92maverage training of epoch 39: loss -3.22603 acc 0.65480 roc_auc 0.42918 prc_auc 0.31390[0m
[93maverage test of epoch 39: loss -3.24752 acc 0.65714 roc_auc 0.49321 prc_auc 0.34341[0m
[92maverage training of epoch 40: loss -3.25431 acc 0.65480 roc_auc 0.42450 prc_auc 0.31148[0m
[93maverage test of epoch 40: loss -3.27595 acc 0.65714 roc_auc 0.47871 prc_auc 0.33267[0m
[92maverage training of epoch 41: loss -3.28283 acc 0.65480 roc_auc 0.42052 prc_auc 0.30956[0m
[93maverage test of epoch 41: loss -3.30462 acc 0.65714 roc_auc 0.48596 prc_auc 0.34330[0m
[92maverage training of epoch 42: loss -3.31161 acc 0.65480 roc_auc 0.41472 prc_auc 0.30567[0m
[93maverage test of epoch 42: loss -3.33355 acc 0.65714 roc_auc 0.45562 prc_auc 0.31811[0m
[92maverage training of epoch 43: loss -3.34064 acc 0.65480 roc_auc 0.40862 prc_auc 0.30097[0m
[93maverage test of epoch 43: loss -3.36273 acc 0.65714 roc_auc 0.48732 prc_auc 0.33413[0m
[92maverage training of epoch 44: loss -3.36993 acc 0.65480 roc_auc 0.40447 prc_auc 0.29872[0m
[93maverage test of epoch 44: loss -3.39218 acc 0.65714 roc_auc 0.49185 prc_auc 0.34772[0m
[92maverage training of epoch 45: loss -3.39949 acc 0.65480 roc_auc 0.40061 prc_auc 0.29739[0m
[93maverage test of epoch 45: loss -3.42190 acc 0.65714 roc_auc 0.48460 prc_auc 0.33665[0m
[92maverage training of epoch 46: loss -3.42932 acc 0.65480 roc_auc 0.39909 prc_auc 0.29777[0m
[93maverage test of epoch 46: loss -3.45187 acc 0.65714 roc_auc 0.44928 prc_auc 0.32774[0m
[92maverage training of epoch 47: loss -3.45940 acc 0.65480 roc_auc 0.39820 prc_auc 0.30090[0m
[93maverage test of epoch 47: loss -3.48210 acc 0.65714 roc_auc 0.46603 prc_auc 0.33016[0m
[92maverage training of epoch 48: loss -3.48974 acc 0.65480 roc_auc 0.39962 prc_auc 0.30739[0m
[93maverage test of epoch 48: loss -3.51259 acc 0.65714 roc_auc 0.44611 prc_auc 0.32051[0m
[92maverage training of epoch 49: loss -3.52034 acc 0.65480 roc_auc 0.39904 prc_auc 0.31040[0m
[93maverage test of epoch 49: loss -3.54332 acc 0.65714 roc_auc 0.46920 prc_auc 0.32847[0m
Run statistics: 
==== Configuration Settings ====
== Run Settings ==
Model: DFScodeRNN_cls, Dataset: PTC_FR
num_epochs: 50
learning_rate: 0.003
seed: 1800
k_fold: 5
model: DFScodeRNN_cls
dataset: PTC_FR

== Model Settings and results ==
dummy: 0

Accuracy (avg): 0.59243 ROC_AUC (avg): 0.48632 PRC_AUC (avg): 0.34552 

Average forward propagation time taken(ms): 3.22110408689563
Average backward propagation time taken(ms): 1.2198846329305875

