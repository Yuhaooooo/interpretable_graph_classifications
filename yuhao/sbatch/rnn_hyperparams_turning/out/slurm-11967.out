# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-02-39-48/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-02-39-48/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 16,
 'epochs': 100,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 4,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.001,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 1,
 'num_workers': 8,
 'number_of_mlp_layer': 0,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-18-02-39-48',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 100, 'learning_rate': 0.001, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -0.33836 acc 0.33333 roc_auc 0.48400 prc_auc 0.65068[0m
[93maverage test of epoch 0: loss -0.95406 acc 0.34211 roc_auc 0.88615 prc_auc 0.94926[0m
[92maverage training of epoch 1: loss -1.45803 acc 0.50000 roc_auc 0.50160 prc_auc 0.70957[0m
[93maverage test of epoch 1: loss -1.97115 acc 0.65789 roc_auc 0.86462 prc_auc 0.93807[0m
[92maverage training of epoch 2: loss -2.41038 acc 0.71333 roc_auc 0.78800 prc_auc 0.86390[0m
[93maverage test of epoch 2: loss -2.84427 acc 0.76316 roc_auc 0.86462 prc_auc 0.93807[0m
[92maverage training of epoch 3: loss -3.21614 acc 0.76000 roc_auc 0.81440 prc_auc 0.86766[0m
[93maverage test of epoch 3: loss -3.45690 acc 0.65789 roc_auc 0.88615 prc_auc 0.94870[0m
[92maverage training of epoch 4: loss -3.93439 acc 0.78667 roc_auc 0.85260 prc_auc 0.90293[0m
[93maverage test of epoch 4: loss -4.30003 acc 0.81579 roc_auc 0.90769 prc_auc 0.95773[0m
[92maverage training of epoch 5: loss -4.65820 acc 0.84000 roc_auc 0.80700 prc_auc 0.86914[0m
[93maverage test of epoch 5: loss -4.84338 acc 0.78947 roc_auc 0.89231 prc_auc 0.95163[0m
[92maverage training of epoch 6: loss -5.42292 acc 0.88667 roc_auc 0.83500 prc_auc 0.87669[0m
[93maverage test of epoch 6: loss -5.53079 acc 0.81579 roc_auc 0.88308 prc_auc 0.95114[0m
[92maverage training of epoch 7: loss -5.90240 acc 0.83333 roc_auc 0.65540 prc_auc 0.73018[0m
[93maverage test of epoch 7: loss -6.18600 acc 0.84211 roc_auc 0.88923 prc_auc 0.95460[0m
[92maverage training of epoch 8: loss -6.58564 acc 0.87333 roc_auc 0.82900 prc_auc 0.86451[0m
[93maverage test of epoch 8: loss -6.60929 acc 0.81579 roc_auc 0.88000 prc_auc 0.94983[0m
[92maverage training of epoch 9: loss -7.17371 acc 0.88667 roc_auc 0.82520 prc_auc 0.84844[0m
[93maverage test of epoch 9: loss -7.29018 acc 0.84211 roc_auc 0.88923 prc_auc 0.95530[0m
[92maverage training of epoch 10: loss -7.52669 acc 0.82000 roc_auc 0.74520 prc_auc 0.80842[0m
[93maverage test of epoch 10: loss -7.82175 acc 0.84211 roc_auc 0.88615 prc_auc 0.95364[0m
[92maverage training of epoch 11: loss -8.14917 acc 0.84667 roc_auc 0.72420 prc_auc 0.76766[0m
[93maverage test of epoch 11: loss -8.12219 acc 0.76316 roc_auc 0.90462 prc_auc 0.95865[0m
[92maverage training of epoch 12: loss -8.54694 acc 0.80667 roc_auc 0.74340 prc_auc 0.80698[0m
[93maverage test of epoch 12: loss -8.86630 acc 0.84211 roc_auc 0.90769 prc_auc 0.96011[0m
[92maverage training of epoch 13: loss -9.27060 acc 0.86667 roc_auc 0.78460 prc_auc 0.79758[0m
[93maverage test of epoch 13: loss -9.07001 acc 0.73684 roc_auc 0.90615 prc_auc 0.95865[0m
[92maverage training of epoch 14: loss -9.59277 acc 0.80000 roc_auc 0.72900 prc_auc 0.79503[0m
[93maverage test of epoch 14: loss -9.76452 acc 0.81579 roc_auc 0.90154 prc_auc 0.95549[0m
[92maverage training of epoch 15: loss -10.14833 acc 0.84667 roc_auc 0.80000 prc_auc 0.86134[0m
[93maverage test of epoch 15: loss -10.03364 acc 0.78947 roc_auc 0.88923 prc_auc 0.94828[0m
[92maverage training of epoch 16: loss -10.87076 acc 0.87333 roc_auc 0.76690 prc_auc 0.79227[0m
[93maverage test of epoch 16: loss -10.92234 acc 0.84211 roc_auc 0.91231 prc_auc 0.96127[0m
[92maverage training of epoch 17: loss -11.18506 acc 0.82000 roc_auc 0.74340 prc_auc 0.80062[0m
[93maverage test of epoch 17: loss -11.27758 acc 0.81579 roc_auc 0.90308 prc_auc 0.95477[0m
[92maverage training of epoch 18: loss -11.90583 acc 0.88000 roc_auc 0.80700 prc_auc 0.83152[0m
[93maverage test of epoch 18: loss -11.78266 acc 0.81579 roc_auc 0.90769 prc_auc 0.95618[0m
[92maverage training of epoch 19: loss -12.42406 acc 0.88000 roc_auc 0.80630 prc_auc 0.83308[0m
[93maverage test of epoch 19: loss -12.28630 acc 0.81579 roc_auc 0.90154 prc_auc 0.95445[0m
[92maverage training of epoch 20: loss -12.87566 acc 0.84667 roc_auc 0.70440 prc_auc 0.74247[0m
[93maverage test of epoch 20: loss -12.50577 acc 0.71053 roc_auc 0.85692 prc_auc 0.89837[0m
[92maverage training of epoch 21: loss -13.10356 acc 0.75333 roc_auc 0.57920 prc_auc 0.68083[0m
[93maverage test of epoch 21: loss -12.97137 acc 0.65789 roc_auc 0.86923 prc_auc 0.89343[0m
[92maverage training of epoch 22: loss -13.31762 acc 0.66667 roc_auc 0.36540 prc_auc 0.57221[0m
[93maverage test of epoch 22: loss -13.52713 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -13.87507 acc 0.66667 roc_auc 0.36260 prc_auc 0.56790[0m
[93maverage test of epoch 23: loss -14.08268 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -14.43188 acc 0.66667 roc_auc 0.36190 prc_auc 0.56676[0m
[93maverage test of epoch 24: loss -14.63761 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -14.98813 acc 0.66667 roc_auc 0.35970 prc_auc 0.56731[0m
[93maverage test of epoch 25: loss -15.19202 acc 0.65789 roc_auc 0.61538 prc_auc 0.71429[0m
[92maverage training of epoch 26: loss -15.54387 acc 0.66667 roc_auc 0.36030 prc_auc 0.56681[0m
[93maverage test of epoch 26: loss -15.74596 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -16.09919 acc 0.66667 roc_auc 0.36080 prc_auc 0.56785[0m
[93maverage test of epoch 27: loss -16.29950 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -16.65413 acc 0.66667 roc_auc 0.36130 prc_auc 0.56714[0m
[93maverage test of epoch 28: loss -16.85270 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -17.20875 acc 0.66667 roc_auc 0.36040 prc_auc 0.56647[0m
[93maverage test of epoch 29: loss -17.40559 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -17.76308 acc 0.66667 roc_auc 0.35990 prc_auc 0.56779[0m
[93maverage test of epoch 30: loss -17.95821 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -18.31715 acc 0.66667 roc_auc 0.36350 prc_auc 0.57036[0m
[93maverage test of epoch 31: loss -18.51060 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -18.87101 acc 0.66667 roc_auc 0.36110 prc_auc 0.57029[0m
[93maverage test of epoch 32: loss -19.06278 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -19.42468 acc 0.66667 roc_auc 0.36360 prc_auc 0.57346[0m
[93maverage test of epoch 33: loss -19.61478 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -19.97818 acc 0.66667 roc_auc 0.35930 prc_auc 0.57030[0m
[93maverage test of epoch 34: loss -20.16663 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -20.53153 acc 0.66667 roc_auc 0.35980 prc_auc 0.57366[0m
[93maverage test of epoch 35: loss -20.71834 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -21.08475 acc 0.66667 roc_auc 0.36070 prc_auc 0.57320[0m
[93maverage test of epoch 36: loss -21.26993 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -21.63786 acc 0.66667 roc_auc 0.36800 prc_auc 0.57959[0m
[93maverage test of epoch 37: loss -21.82141 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -22.19087 acc 0.66667 roc_auc 0.36200 prc_auc 0.57791[0m
[93maverage test of epoch 38: loss -22.37279 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -22.74379 acc 0.66667 roc_auc 0.35890 prc_auc 0.58382[0m
[93maverage test of epoch 39: loss -22.92410 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -23.29663 acc 0.66667 roc_auc 0.36500 prc_auc 0.58520[0m
[93maverage test of epoch 40: loss -23.47533 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -23.84940 acc 0.66667 roc_auc 0.35860 prc_auc 0.58194[0m
[93maverage test of epoch 41: loss -24.02650 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -24.40212 acc 0.66667 roc_auc 0.36450 prc_auc 0.58945[0m
[93maverage test of epoch 42: loss -24.57762 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -24.95478 acc 0.66667 roc_auc 0.37000 prc_auc 0.59731[0m
[93maverage test of epoch 43: loss -25.12868 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -25.50739 acc 0.66667 roc_auc 0.37100 prc_auc 0.59854[0m
[93maverage test of epoch 44: loss -25.67970 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -26.05997 acc 0.66667 roc_auc 0.36060 prc_auc 0.59470[0m
[93maverage test of epoch 45: loss -26.23067 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -26.61250 acc 0.66667 roc_auc 0.38610 prc_auc 0.61015[0m
[93maverage test of epoch 46: loss -26.78162 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -27.16501 acc 0.66667 roc_auc 0.39710 prc_auc 0.61488[0m
[93maverage test of epoch 47: loss -27.33254 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -27.71749 acc 0.66667 roc_auc 0.42790 prc_auc 0.63206[0m
[93maverage test of epoch 48: loss -27.88343 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -28.26994 acc 0.66667 roc_auc 0.42820 prc_auc 0.63240[0m
[93maverage test of epoch 49: loss -28.43429 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 50: loss -28.82237 acc 0.66667 roc_auc 0.42220 prc_auc 0.63148[0m
[93maverage test of epoch 50: loss -28.98514 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 51: loss -29.37478 acc 0.66667 roc_auc 0.42280 prc_auc 0.63250[0m
[93maverage test of epoch 51: loss -29.53596 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 52: loss -29.92717 acc 0.66667 roc_auc 0.42250 prc_auc 0.63180[0m
[93maverage test of epoch 52: loss -30.08678 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 53: loss -30.47955 acc 0.66667 roc_auc 0.43500 prc_auc 0.63948[0m
[93maverage test of epoch 53: loss -30.63757 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 54: loss -31.03191 acc 0.66667 roc_auc 0.44500 prc_auc 0.64328[0m
[93maverage test of epoch 54: loss -31.18834 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 55: loss -31.58426 acc 0.66667 roc_auc 0.46000 prc_auc 0.64944[0m
[93maverage test of epoch 55: loss -31.73911 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 56: loss -32.13660 acc 0.66667 roc_auc 0.45000 prc_auc 0.64533[0m
[93maverage test of epoch 56: loss -32.28987 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 57: loss -32.68893 acc 0.66667 roc_auc 0.44000 prc_auc 0.64172[0m
[93maverage test of epoch 57: loss -32.84062 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 58: loss -33.24124 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 58: loss -33.39136 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 59: loss -33.79355 acc 0.66667 roc_auc 0.42000 prc_auc 0.63385[0m
[93maverage test of epoch 59: loss -33.94208 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 60: loss -34.34585 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 60: loss -34.49281 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 61: loss -34.89815 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 61: loss -35.04352 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 62: loss -35.45044 acc 0.66667 roc_auc 0.44500 prc_auc 0.64342[0m
[93maverage test of epoch 62: loss -35.59424 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 63: loss -36.00272 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 63: loss -36.14494 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 64: loss -36.55499 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 64: loss -36.69564 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 65: loss -37.10727 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 65: loss -37.24633 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 66: loss -37.65954 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 66: loss -37.79703 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 67: loss -38.21181 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 67: loss -38.34772 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 68: loss -38.76407 acc 0.66667 roc_auc 0.43000 prc_auc 0.63761[0m
[93maverage test of epoch 68: loss -38.89840 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 69: loss -39.31633 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 69: loss -39.44909 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 70: loss -39.86858 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 70: loss -39.99976 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 71: loss -40.42083 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 71: loss -40.55043 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 72: loss -40.97308 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 72: loss -41.10110 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 73: loss -41.52532 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 73: loss -41.65177 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 74: loss -42.07755 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 74: loss -42.20242 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 75: loss -42.62979 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 75: loss -42.75308 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 76: loss -43.18202 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 76: loss -43.30374 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 77: loss -43.73425 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 77: loss -43.85439 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 78: loss -44.28648 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 78: loss -44.40504 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 79: loss -44.83871 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 79: loss -44.95569 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 80: loss -45.39093 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 80: loss -45.50634 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 81: loss -45.94315 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 81: loss -46.05698 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 82: loss -46.49537 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 82: loss -46.60762 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 83: loss -47.04759 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 83: loss -47.15827 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 84: loss -47.59980 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 84: loss -47.70890 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 85: loss -48.15202 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 85: loss -48.25954 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 86: loss -48.70423 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 86: loss -48.81017 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 87: loss -49.25644 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 87: loss -49.36081 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 88: loss -49.80865 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 88: loss -49.91144 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 89: loss -50.36085 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 89: loss -50.46206 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -50.91305 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 90: loss -51.01268 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 91: loss -51.46525 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 91: loss -51.56331 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 92: loss -52.01745 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 92: loss -52.11393 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 93: loss -52.56965 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 93: loss -52.66454 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 94: loss -53.12184 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 94: loss -53.21516 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 95: loss -53.67403 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 95: loss -53.76578 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 96: loss -54.22622 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 96: loss -54.31639 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 97: loss -54.77841 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 97: loss -54.86700 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 98: loss -55.33060 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 98: loss -55.41761 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -55.88278 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 99: loss -55.96822 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -1.13624 acc 0.43333 roc_auc 0.46600 prc_auc 0.65907[0m
[93maverage test of epoch 0: loss -2.47877 acc 0.65789 roc_auc 0.79692 prc_auc 0.89472[0m
[92maverage training of epoch 1: loss -3.15434 acc 0.66667 roc_auc 0.47160 prc_auc 0.66250[0m
[93maverage test of epoch 1: loss -3.64656 acc 0.65789 roc_auc 0.80462 prc_auc 0.90072[0m
[92maverage training of epoch 2: loss -4.03562 acc 0.66667 roc_auc 0.43920 prc_auc 0.61841[0m
[93maverage test of epoch 2: loss -4.39146 acc 0.65789 roc_auc 0.80462 prc_auc 0.90058[0m
[92maverage training of epoch 3: loss -4.74144 acc 0.66667 roc_auc 0.42520 prc_auc 0.60229[0m
[93maverage test of epoch 3: loss -5.06309 acc 0.65789 roc_auc 0.80462 prc_auc 0.90058[0m
[92maverage training of epoch 4: loss -5.39575 acc 0.66667 roc_auc 0.42200 prc_auc 0.59888[0m
[93maverage test of epoch 4: loss -5.69785 acc 0.65789 roc_auc 0.80308 prc_auc 0.89908[0m
[92maverage training of epoch 5: loss -6.02034 acc 0.66667 roc_auc 0.42020 prc_auc 0.59967[0m
[93maverage test of epoch 5: loss -6.30914 acc 0.65789 roc_auc 0.79385 prc_auc 0.88780[0m
[92maverage training of epoch 6: loss -6.62562 acc 0.66667 roc_auc 0.42140 prc_auc 0.60590[0m
[93maverage test of epoch 6: loss -6.90500 acc 0.65789 roc_auc 0.87846 prc_auc 0.92352[0m
[92maverage training of epoch 7: loss -7.21800 acc 0.66667 roc_auc 0.42300 prc_auc 0.61138[0m
[93maverage test of epoch 7: loss -7.49037 acc 0.65789 roc_auc 0.86769 prc_auc 0.91703[0m
[92maverage training of epoch 8: loss -7.80143 acc 0.66667 roc_auc 0.42240 prc_auc 0.61092[0m
[93maverage test of epoch 8: loss -8.06835 acc 0.65789 roc_auc 0.87077 prc_auc 0.91434[0m
[92maverage training of epoch 9: loss -8.37843 acc 0.66667 roc_auc 0.42220 prc_auc 0.60970[0m
[93maverage test of epoch 9: loss -8.64090 acc 0.65789 roc_auc 0.86154 prc_auc 0.89346[0m
[92maverage training of epoch 10: loss -8.95065 acc 0.66667 roc_auc 0.42180 prc_auc 0.60960[0m
[93maverage test of epoch 10: loss -9.20938 acc 0.65789 roc_auc 0.86462 prc_auc 0.89079[0m
[92maverage training of epoch 11: loss -9.51924 acc 0.66667 roc_auc 0.42170 prc_auc 0.60810[0m
[93maverage test of epoch 11: loss -9.77470 acc 0.65789 roc_auc 0.87077 prc_auc 0.89689[0m
[92maverage training of epoch 12: loss -10.08498 acc 0.66667 roc_auc 0.42160 prc_auc 0.60810[0m
[93maverage test of epoch 12: loss -10.33753 acc 0.65789 roc_auc 0.82462 prc_auc 0.84889[0m
[92maverage training of epoch 13: loss -10.64847 acc 0.66667 roc_auc 0.42140 prc_auc 0.60715[0m
[93maverage test of epoch 13: loss -10.89838 acc 0.65789 roc_auc 0.82462 prc_auc 0.84889[0m
[92maverage training of epoch 14: loss -11.21015 acc 0.66667 roc_auc 0.42100 prc_auc 0.60588[0m
[93maverage test of epoch 14: loss -11.45761 acc 0.65789 roc_auc 0.82769 prc_auc 0.85173[0m
[92maverage training of epoch 15: loss -11.77035 acc 0.66667 roc_auc 0.42070 prc_auc 0.60517[0m
[93maverage test of epoch 15: loss -12.01552 acc 0.65789 roc_auc 0.81231 prc_auc 0.84174[0m
[92maverage training of epoch 16: loss -12.32934 acc 0.66667 roc_auc 0.42060 prc_auc 0.60510[0m
[93maverage test of epoch 16: loss -12.57235 acc 0.65789 roc_auc 0.80462 prc_auc 0.83625[0m
[92maverage training of epoch 17: loss -12.88732 acc 0.66667 roc_auc 0.42040 prc_auc 0.60495[0m
[93maverage test of epoch 17: loss -13.12826 acc 0.65789 roc_auc 0.82308 prc_auc 0.84667[0m
[92maverage training of epoch 18: loss -13.44446 acc 0.66667 roc_auc 0.42060 prc_auc 0.60502[0m
[93maverage test of epoch 18: loss -13.68341 acc 0.65789 roc_auc 0.81846 prc_auc 0.84819[0m
[92maverage training of epoch 19: loss -14.00090 acc 0.66667 roc_auc 0.42020 prc_auc 0.60458[0m
[93maverage test of epoch 19: loss -14.23793 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 20: loss -14.55674 acc 0.66667 roc_auc 0.42030 prc_auc 0.60458[0m
[93maverage test of epoch 20: loss -14.79191 acc 0.65789 roc_auc 0.68000 prc_auc 0.78105[0m
[92maverage training of epoch 21: loss -15.11208 acc 0.66667 roc_auc 0.42030 prc_auc 0.60458[0m
[93maverage test of epoch 21: loss -15.34543 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 22: loss -15.66700 acc 0.66667 roc_auc 0.42030 prc_auc 0.60458[0m
[93maverage test of epoch 22: loss -15.89856 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 23: loss -16.22155 acc 0.66667 roc_auc 0.42030 prc_auc 0.60497[0m
[93maverage test of epoch 23: loss -16.45136 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 24: loss -16.77580 acc 0.66667 roc_auc 0.42030 prc_auc 0.60497[0m
[93maverage test of epoch 24: loss -17.00387 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 25: loss -17.32978 acc 0.66667 roc_auc 0.42020 prc_auc 0.60461[0m
[93maverage test of epoch 25: loss -17.55615 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 26: loss -17.88354 acc 0.66667 roc_auc 0.42020 prc_auc 0.60494[0m
[93maverage test of epoch 26: loss -18.10821 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 27: loss -18.43710 acc 0.66667 roc_auc 0.42030 prc_auc 0.60461[0m
[93maverage test of epoch 27: loss -18.66010 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 28: loss -18.99049 acc 0.66667 roc_auc 0.42030 prc_auc 0.60499[0m
[93maverage test of epoch 28: loss -19.21183 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 29: loss -19.54373 acc 0.66667 roc_auc 0.42010 prc_auc 0.60540[0m
[93maverage test of epoch 29: loss -19.76343 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 30: loss -20.09686 acc 0.66667 roc_auc 0.42050 prc_auc 0.60542[0m
[93maverage test of epoch 30: loss -20.31492 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 31: loss -20.64988 acc 0.66667 roc_auc 0.42060 prc_auc 0.60552[0m
[93maverage test of epoch 31: loss -20.86631 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 32: loss -21.20280 acc 0.66667 roc_auc 0.42040 prc_auc 0.60566[0m
[93maverage test of epoch 32: loss -21.41761 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 33: loss -21.75564 acc 0.66667 roc_auc 0.42020 prc_auc 0.60537[0m
[93maverage test of epoch 33: loss -21.96884 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -22.30842 acc 0.66667 roc_auc 0.42090 prc_auc 0.60543[0m
[93maverage test of epoch 34: loss -22.52000 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 35: loss -22.86113 acc 0.66667 roc_auc 0.42130 prc_auc 0.60570[0m
[93maverage test of epoch 35: loss -23.07111 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 36: loss -23.41379 acc 0.66667 roc_auc 0.42050 prc_auc 0.60404[0m
[93maverage test of epoch 36: loss -23.62217 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -23.96641 acc 0.66667 roc_auc 0.42020 prc_auc 0.60461[0m
[93maverage test of epoch 37: loss -24.17318 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -24.51898 acc 0.66667 roc_auc 0.42070 prc_auc 0.60550[0m
[93maverage test of epoch 38: loss -24.72417 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -25.07152 acc 0.66667 roc_auc 0.42120 prc_auc 0.60547[0m
[93maverage test of epoch 39: loss -25.27511 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -25.62403 acc 0.66667 roc_auc 0.42040 prc_auc 0.60386[0m
[93maverage test of epoch 40: loss -25.82603 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -26.17652 acc 0.66667 roc_auc 0.42030 prc_auc 0.60260[0m
[93maverage test of epoch 41: loss -26.37693 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -26.72898 acc 0.66667 roc_auc 0.41970 prc_auc 0.60210[0m
[93maverage test of epoch 42: loss -26.92780 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -27.28142 acc 0.66667 roc_auc 0.41990 prc_auc 0.60302[0m
[93maverage test of epoch 43: loss -27.47865 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -27.83384 acc 0.66667 roc_auc 0.41980 prc_auc 0.59945[0m
[93maverage test of epoch 44: loss -28.02949 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -28.38625 acc 0.66667 roc_auc 0.41960 prc_auc 0.60582[0m
[93maverage test of epoch 45: loss -28.58031 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -28.93864 acc 0.66667 roc_auc 0.42040 prc_auc 0.60548[0m
[93maverage test of epoch 46: loss -29.13112 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -29.49102 acc 0.66667 roc_auc 0.42010 prc_auc 0.59957[0m
[93maverage test of epoch 47: loss -29.68192 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -30.04339 acc 0.66667 roc_auc 0.42450 prc_auc 0.60981[0m
[93maverage test of epoch 48: loss -30.23271 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -30.59575 acc 0.66667 roc_auc 0.41710 prc_auc 0.59673[0m
[93maverage test of epoch 49: loss -30.78349 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 50: loss -31.14810 acc 0.66667 roc_auc 0.42130 prc_auc 0.60308[0m
[93maverage test of epoch 50: loss -31.33427 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 51: loss -31.70045 acc 0.66667 roc_auc 0.42200 prc_auc 0.60606[0m
[93maverage test of epoch 51: loss -31.88503 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 52: loss -32.25279 acc 0.66667 roc_auc 0.42010 prc_auc 0.60438[0m
[93maverage test of epoch 52: loss -32.43579 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 53: loss -32.80511 acc 0.66667 roc_auc 0.42770 prc_auc 0.60789[0m
[93maverage test of epoch 53: loss -32.98653 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 54: loss -33.35743 acc 0.66667 roc_auc 0.42650 prc_auc 0.60990[0m
[93maverage test of epoch 54: loss -33.53727 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 55: loss -33.90974 acc 0.66667 roc_auc 0.42930 prc_auc 0.61231[0m
[93maverage test of epoch 55: loss -34.08800 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 56: loss -34.46204 acc 0.66667 roc_auc 0.41950 prc_auc 0.60576[0m
[93maverage test of epoch 56: loss -34.63871 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 57: loss -35.01433 acc 0.66667 roc_auc 0.42580 prc_auc 0.61334[0m
[93maverage test of epoch 57: loss -35.18943 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 58: loss -35.56662 acc 0.66667 roc_auc 0.42540 prc_auc 0.61699[0m
[93maverage test of epoch 58: loss -35.74014 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 59: loss -36.11890 acc 0.66667 roc_auc 0.44400 prc_auc 0.62988[0m
[93maverage test of epoch 59: loss -36.29085 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 60: loss -36.67118 acc 0.66667 roc_auc 0.42930 prc_auc 0.62178[0m
[93maverage test of epoch 60: loss -36.84155 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 61: loss -37.22346 acc 0.66667 roc_auc 0.42550 prc_auc 0.62061[0m
[93maverage test of epoch 61: loss -37.39225 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 62: loss -37.77573 acc 0.66667 roc_auc 0.43970 prc_auc 0.63078[0m
[93maverage test of epoch 62: loss -37.94294 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 63: loss -38.32800 acc 0.66667 roc_auc 0.44000 prc_auc 0.63045[0m
[93maverage test of epoch 63: loss -38.49364 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 64: loss -38.88027 acc 0.66667 roc_auc 0.42670 prc_auc 0.62430[0m
[93maverage test of epoch 64: loss -39.04433 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 65: loss -39.43253 acc 0.66667 roc_auc 0.46040 prc_auc 0.64549[0m
[93maverage test of epoch 65: loss -39.59501 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 66: loss -39.98479 acc 0.66667 roc_auc 0.46880 prc_auc 0.65161[0m
[93maverage test of epoch 66: loss -40.14570 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 67: loss -40.53705 acc 0.66667 roc_auc 0.47000 prc_auc 0.65195[0m
[93maverage test of epoch 67: loss -40.69637 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 68: loss -41.08930 acc 0.66667 roc_auc 0.44540 prc_auc 0.64333[0m
[93maverage test of epoch 68: loss -41.24705 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 69: loss -41.64155 acc 0.66667 roc_auc 0.45000 prc_auc 0.64615[0m
[93maverage test of epoch 69: loss -41.79772 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 70: loss -42.19379 acc 0.66667 roc_auc 0.45500 prc_auc 0.64797[0m
[93maverage test of epoch 70: loss -42.34839 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 71: loss -42.74603 acc 0.66667 roc_auc 0.44500 prc_auc 0.64443[0m
[93maverage test of epoch 71: loss -42.89905 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 72: loss -43.29827 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 72: loss -43.44971 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 73: loss -43.85051 acc 0.66667 roc_auc 0.49000 prc_auc 0.66226[0m
[93maverage test of epoch 73: loss -44.00037 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 74: loss -44.40274 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 74: loss -44.55103 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 75: loss -44.95497 acc 0.66667 roc_auc 0.49500 prc_auc 0.66445[0m
[93maverage test of epoch 75: loss -45.10168 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 76: loss -45.50720 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 76: loss -45.65233 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 77: loss -46.05943 acc 0.66667 roc_auc 0.41500 prc_auc 0.63833[0m
[93maverage test of epoch 77: loss -46.20298 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 78: loss -46.61165 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 78: loss -46.75363 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 79: loss -47.16387 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 79: loss -47.30428 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 80: loss -47.71610 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 80: loss -47.85492 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 81: loss -48.26832 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 81: loss -48.40557 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 82: loss -48.82053 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 82: loss -48.95621 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 83: loss -49.37275 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 83: loss -49.50684 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 84: loss -49.92496 acc 0.66667 roc_auc 0.50500 prc_auc 0.66890[0m
[93maverage test of epoch 84: loss -50.05748 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 85: loss -50.47717 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 85: loss -50.60811 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 86: loss -51.02937 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 86: loss -51.15874 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 87: loss -51.58157 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 87: loss -51.70936 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 88: loss -52.13377 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 88: loss -52.25998 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 89: loss -52.68597 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 89: loss -52.81060 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -53.23816 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 90: loss -53.36122 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 91: loss -53.79035 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 91: loss -53.91183 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 92: loss -54.34254 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 92: loss -54.46244 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 93: loss -54.89473 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 93: loss -55.01305 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 94: loss -55.44691 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 94: loss -55.56366 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 95: loss -55.99910 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 95: loss -56.11427 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 96: loss -56.55127 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 96: loss -56.66486 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 97: loss -57.10345 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 97: loss -57.21546 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 98: loss -57.65562 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 98: loss -57.76606 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -58.20779 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 99: loss -58.31666 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -0.11268 acc 0.54000 roc_auc 0.41840 prc_auc 0.63460[0m
[93maverage test of epoch 0: loss -0.54858 acc 0.65789 roc_auc 0.95077 prc_auc 0.97861[0m
[92maverage training of epoch 1: loss -1.26706 acc 0.66667 roc_auc 0.45500 prc_auc 0.65970[0m
[93maverage test of epoch 1: loss -2.04607 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 2: loss -2.78470 acc 0.66667 roc_auc 0.45680 prc_auc 0.66397[0m
[93maverage test of epoch 2: loss -3.36986 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 3: loss -3.81973 acc 0.66667 roc_auc 0.42750 prc_auc 0.63595[0m
[93maverage test of epoch 3: loss -4.18307 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 4: loss -4.56937 acc 0.66667 roc_auc 0.41260 prc_auc 0.62056[0m
[93maverage test of epoch 4: loss -4.88115 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 5: loss -5.24263 acc 0.66667 roc_auc 0.40080 prc_auc 0.61013[0m
[93maverage test of epoch 5: loss -5.53010 acc 0.65789 roc_auc 0.95231 prc_auc 0.97791[0m
[92maverage training of epoch 6: loss -5.87874 acc 0.66667 roc_auc 0.39320 prc_auc 0.60619[0m
[93maverage test of epoch 6: loss -6.15165 acc 0.65789 roc_auc 0.95231 prc_auc 0.97791[0m
[92maverage training of epoch 7: loss -6.49285 acc 0.66667 roc_auc 0.38880 prc_auc 0.60458[0m
[93maverage test of epoch 7: loss -6.75585 acc 0.65789 roc_auc 0.95385 prc_auc 0.97946[0m
[92maverage training of epoch 8: loss -7.09254 acc 0.66667 roc_auc 0.38710 prc_auc 0.60286[0m
[93maverage test of epoch 8: loss -7.34821 acc 0.65789 roc_auc 0.95077 prc_auc 0.97663[0m
[92maverage training of epoch 9: loss -7.68214 acc 0.66667 roc_auc 0.38620 prc_auc 0.60073[0m
[93maverage test of epoch 9: loss -7.93207 acc 0.65789 roc_auc 0.94615 prc_auc 0.97264[0m
[92maverage training of epoch 10: loss -8.26436 acc 0.66667 roc_auc 0.38420 prc_auc 0.59334[0m
[93maverage test of epoch 10: loss -8.50959 acc 0.65789 roc_auc 0.94462 prc_auc 0.97298[0m
[92maverage training of epoch 11: loss -8.84099 acc 0.66667 roc_auc 0.38170 prc_auc 0.58744[0m
[93maverage test of epoch 11: loss -9.08223 acc 0.65789 roc_auc 0.93385 prc_auc 0.95526[0m
[92maverage training of epoch 12: loss -9.41329 acc 0.66667 roc_auc 0.38090 prc_auc 0.58747[0m
[93maverage test of epoch 12: loss -9.65107 acc 0.65789 roc_auc 0.91846 prc_auc 0.93000[0m
[92maverage training of epoch 13: loss -9.98219 acc 0.66667 roc_auc 0.38010 prc_auc 0.57905[0m
[93maverage test of epoch 13: loss -10.21688 acc 0.65789 roc_auc 0.86923 prc_auc 0.90632[0m
[92maverage training of epoch 14: loss -10.54834 acc 0.66667 roc_auc 0.37910 prc_auc 0.57743[0m
[93maverage test of epoch 14: loss -10.78023 acc 0.65789 roc_auc 0.92000 prc_auc 0.94526[0m
[92maverage training of epoch 15: loss -11.11227 acc 0.66667 roc_auc 0.37890 prc_auc 0.57707[0m
[93maverage test of epoch 15: loss -11.34158 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 16: loss -11.67438 acc 0.66667 roc_auc 0.37850 prc_auc 0.57635[0m
[93maverage test of epoch 16: loss -11.90128 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 17: loss -12.23498 acc 0.66667 roc_auc 0.37780 prc_auc 0.57563[0m
[93maverage test of epoch 17: loss -12.45962 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 18: loss -12.79432 acc 0.66667 roc_auc 0.37750 prc_auc 0.57556[0m
[93maverage test of epoch 18: loss -13.01682 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -13.35262 acc 0.66667 roc_auc 0.37700 prc_auc 0.57521[0m
[93maverage test of epoch 19: loss -13.57306 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -13.91004 acc 0.66667 roc_auc 0.37680 prc_auc 0.57591[0m
[93maverage test of epoch 20: loss -14.12849 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -14.46671 acc 0.66667 roc_auc 0.37680 prc_auc 0.57590[0m
[93maverage test of epoch 21: loss -14.68324 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -15.02275 acc 0.66667 roc_auc 0.37700 prc_auc 0.57665[0m
[93maverage test of epoch 22: loss -15.23742 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -15.57826 acc 0.66667 roc_auc 0.37670 prc_auc 0.57662[0m
[93maverage test of epoch 23: loss -15.79110 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -16.13331 acc 0.66667 roc_auc 0.37690 prc_auc 0.57571[0m
[93maverage test of epoch 24: loss -16.34436 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -16.68796 acc 0.66667 roc_auc 0.37680 prc_auc 0.57840[0m
[93maverage test of epoch 25: loss -16.89726 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -17.24229 acc 0.66667 roc_auc 0.37680 prc_auc 0.57679[0m
[93maverage test of epoch 26: loss -17.44986 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -17.79633 acc 0.66667 roc_auc 0.37710 prc_auc 0.57946[0m
[93maverage test of epoch 27: loss -18.00219 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -18.35013 acc 0.66667 roc_auc 0.37740 prc_auc 0.57717[0m
[93maverage test of epoch 28: loss -18.55430 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -18.90371 acc 0.66667 roc_auc 0.37690 prc_auc 0.57385[0m
[93maverage test of epoch 29: loss -19.10621 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -19.45712 acc 0.66667 roc_auc 0.37620 prc_auc 0.57873[0m
[93maverage test of epoch 30: loss -19.65796 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -20.01037 acc 0.66667 roc_auc 0.37680 prc_auc 0.57763[0m
[93maverage test of epoch 31: loss -20.20956 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -20.56349 acc 0.66667 roc_auc 0.37770 prc_auc 0.57708[0m
[93maverage test of epoch 32: loss -20.76104 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -21.11649 acc 0.66667 roc_auc 0.37880 prc_auc 0.57848[0m
[93maverage test of epoch 33: loss -21.31242 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -21.66940 acc 0.66667 roc_auc 0.38150 prc_auc 0.58353[0m
[93maverage test of epoch 34: loss -21.86370 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -22.22222 acc 0.66667 roc_auc 0.37810 prc_auc 0.58051[0m
[93maverage test of epoch 35: loss -22.41490 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -22.77496 acc 0.66667 roc_auc 0.38280 prc_auc 0.58575[0m
[93maverage test of epoch 36: loss -22.96603 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -23.32764 acc 0.66667 roc_auc 0.38120 prc_auc 0.58920[0m
[93maverage test of epoch 37: loss -23.51710 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -23.88026 acc 0.66667 roc_auc 0.37860 prc_auc 0.58249[0m
[93maverage test of epoch 38: loss -24.06812 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -24.43283 acc 0.66667 roc_auc 0.38400 prc_auc 0.59013[0m
[93maverage test of epoch 39: loss -24.61910 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -24.98536 acc 0.66667 roc_auc 0.37430 prc_auc 0.58054[0m
[93maverage test of epoch 40: loss -25.17003 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -25.53786 acc 0.66667 roc_auc 0.37950 prc_auc 0.58596[0m
[93maverage test of epoch 41: loss -25.72094 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -26.09032 acc 0.66667 roc_auc 0.38650 prc_auc 0.59119[0m
[93maverage test of epoch 42: loss -26.27181 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -26.64276 acc 0.66667 roc_auc 0.38510 prc_auc 0.58943[0m
[93maverage test of epoch 43: loss -26.82266 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -27.19517 acc 0.66667 roc_auc 0.38240 prc_auc 0.59001[0m
[93maverage test of epoch 44: loss -27.37348 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -27.74755 acc 0.66667 roc_auc 0.39030 prc_auc 0.59910[0m
[93maverage test of epoch 45: loss -27.92428 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -28.29992 acc 0.66667 roc_auc 0.38560 prc_auc 0.59493[0m
[93maverage test of epoch 46: loss -28.47506 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -28.85227 acc 0.66667 roc_auc 0.38070 prc_auc 0.59568[0m
[93maverage test of epoch 47: loss -29.02583 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -29.40460 acc 0.66667 roc_auc 0.38620 prc_auc 0.60032[0m
[93maverage test of epoch 48: loss -29.57657 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -29.95692 acc 0.66667 roc_auc 0.40140 prc_auc 0.61322[0m
[93maverage test of epoch 49: loss -30.12731 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 50: loss -30.50922 acc 0.66667 roc_auc 0.39760 prc_auc 0.61126[0m
[93maverage test of epoch 50: loss -30.67803 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 51: loss -31.06152 acc 0.66667 roc_auc 0.39600 prc_auc 0.61129[0m
[93maverage test of epoch 51: loss -31.22875 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 52: loss -31.61380 acc 0.66667 roc_auc 0.44020 prc_auc 0.63704[0m
[93maverage test of epoch 52: loss -31.77945 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 53: loss -32.16608 acc 0.66667 roc_auc 0.40520 prc_auc 0.61796[0m
[93maverage test of epoch 53: loss -32.33015 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 54: loss -32.71835 acc 0.66667 roc_auc 0.43000 prc_auc 0.63386[0m
[93maverage test of epoch 54: loss -32.88083 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 55: loss -33.27061 acc 0.66667 roc_auc 0.44560 prc_auc 0.64041[0m
[93maverage test of epoch 55: loss -33.43152 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 56: loss -33.82286 acc 0.66667 roc_auc 0.42170 prc_auc 0.63010[0m
[93maverage test of epoch 56: loss -33.98219 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 57: loss -34.37512 acc 0.66667 roc_auc 0.44500 prc_auc 0.64353[0m
[93maverage test of epoch 57: loss -34.53286 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 58: loss -34.92736 acc 0.66667 roc_auc 0.48500 prc_auc 0.66009[0m
[93maverage test of epoch 58: loss -35.08353 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 59: loss -35.47960 acc 0.66667 roc_auc 0.46500 prc_auc 0.65156[0m
[93maverage test of epoch 59: loss -35.63419 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 60: loss -36.03183 acc 0.66667 roc_auc 0.47500 prc_auc 0.65580[0m
[93maverage test of epoch 60: loss -36.18485 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 61: loss -36.58406 acc 0.66667 roc_auc 0.43000 prc_auc 0.63812[0m
[93maverage test of epoch 61: loss -36.73550 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 62: loss -37.13628 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 62: loss -37.28614 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 63: loss -37.68850 acc 0.66667 roc_auc 0.43000 prc_auc 0.63780[0m
[93maverage test of epoch 63: loss -37.83677 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 64: loss -38.24071 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 64: loss -38.38741 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 65: loss -38.79291 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 65: loss -38.93803 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 66: loss -39.34511 acc 0.66667 roc_auc 0.45500 prc_auc 0.64752[0m
[93maverage test of epoch 66: loss -39.48865 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 67: loss -39.89730 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 67: loss -40.03927 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 68: loss -40.44949 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 68: loss -40.58988 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 69: loss -41.00168 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 69: loss -41.14049 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 70: loss -41.55387 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 70: loss -41.69110 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 71: loss -42.10605 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 71: loss -42.24170 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 72: loss -42.65822 acc 0.66667 roc_auc 0.44000 prc_auc 0.64162[0m
[93maverage test of epoch 72: loss -42.79230 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 73: loss -43.21039 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 73: loss -43.34290 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 74: loss -43.76257 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 74: loss -43.89349 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 75: loss -44.31473 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 75: loss -44.44408 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 76: loss -44.86690 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 76: loss -44.99468 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 77: loss -45.41907 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 77: loss -45.54526 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 78: loss -45.97123 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 78: loss -46.09585 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 79: loss -46.52339 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 79: loss -46.64643 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 80: loss -47.07555 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 80: loss -47.19702 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 81: loss -47.62771 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 81: loss -47.74760 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 82: loss -48.17986 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 82: loss -48.29817 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 83: loss -48.73202 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 83: loss -48.84875 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 84: loss -49.28417 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 84: loss -49.39933 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 85: loss -49.83632 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 85: loss -49.94990 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 86: loss -50.38847 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 86: loss -50.50048 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 87: loss -50.94062 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 87: loss -51.05104 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 88: loss -51.49277 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 88: loss -51.60161 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 89: loss -52.04491 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 89: loss -52.15218 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -52.59705 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 90: loss -52.70274 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 91: loss -53.14919 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 91: loss -53.25330 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 92: loss -53.70132 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 92: loss -53.80385 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 93: loss -54.25345 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 93: loss -54.35441 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 94: loss -54.80558 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 94: loss -54.90496 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 95: loss -55.35771 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 95: loss -55.45551 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 96: loss -55.90984 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 96: loss -56.00606 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 97: loss -56.46196 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 97: loss -56.55661 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 98: loss -57.01408 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 98: loss -57.10715 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -57.56619 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 99: loss -57.65769 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -0.19392 acc 0.60927 roc_auc 0.53157 prc_auc 0.66222[0m
[93maverage test of epoch 0: loss -0.43759 acc 0.35135 roc_auc 0.87333 prc_auc 0.93181[0m
[92maverage training of epoch 1: loss -0.72351 acc 0.35099 roc_auc 0.68431 prc_auc 0.83696[0m
[93maverage test of epoch 1: loss -1.05705 acc 0.35135 roc_auc 0.86000 prc_auc 0.92282[0m
[92maverage training of epoch 2: loss -1.55655 acc 0.34437 roc_auc 0.53667 prc_auc 0.75045[0m
[93maverage test of epoch 2: loss -2.00498 acc 0.32432 roc_auc 0.23000 prc_auc 0.57923[0m
[92maverage training of epoch 3: loss -2.39662 acc 0.33775 roc_auc 0.36765 prc_auc 0.57246[0m
[93maverage test of epoch 3: loss -2.75663 acc 0.32432 roc_auc 0.28500 prc_auc 0.67521[0m
[92maverage training of epoch 4: loss -3.10257 acc 0.33775 roc_auc 0.37216 prc_auc 0.56698[0m
[93maverage test of epoch 4: loss -3.43174 acc 0.32432 roc_auc 0.29667 prc_auc 0.67869[0m
[92maverage training of epoch 5: loss -3.75479 acc 0.33775 roc_auc 0.37353 prc_auc 0.56780[0m
[93maverage test of epoch 5: loss -4.06942 acc 0.32432 roc_auc 0.31167 prc_auc 0.68263[0m
[92maverage training of epoch 6: loss -4.37833 acc 0.33775 roc_auc 0.37510 prc_auc 0.56924[0m
[93maverage test of epoch 6: loss -4.68526 acc 0.32432 roc_auc 0.31000 prc_auc 0.67987[0m
[92maverage training of epoch 7: loss -4.98427 acc 0.33775 roc_auc 0.37529 prc_auc 0.56892[0m
[93maverage test of epoch 7: loss -5.28702 acc 0.32432 roc_auc 0.36333 prc_auc 0.70017[0m
[92maverage training of epoch 8: loss -5.57849 acc 0.30464 roc_auc 0.37608 prc_auc 0.57006[0m
[93maverage test of epoch 8: loss -5.87903 acc 0.67568 roc_auc 0.52667 prc_auc 0.74655[0m
[92maverage training of epoch 9: loss -6.16440 acc 0.66225 roc_auc 0.37588 prc_auc 0.56998[0m
[93maverage test of epoch 9: loss -6.46400 acc 0.67568 roc_auc 0.58167 prc_auc 0.75364[0m
[92maverage training of epoch 10: loss -6.74421 acc 0.66225 roc_auc 0.37608 prc_auc 0.57008[0m
[93maverage test of epoch 10: loss -7.04368 acc 0.67568 roc_auc 0.54667 prc_auc 0.71176[0m
[92maverage training of epoch 11: loss -7.31938 acc 0.66225 roc_auc 0.37588 prc_auc 0.56971[0m
[93maverage test of epoch 11: loss -7.61929 acc 0.67568 roc_auc 0.64000 prc_auc 0.77262[0m
[92maverage training of epoch 12: loss -7.89093 acc 0.66225 roc_auc 0.37588 prc_auc 0.56971[0m
[93maverage test of epoch 12: loss -8.19170 acc 0.67568 roc_auc 0.34000 prc_auc 0.61569[0m
[92maverage training of epoch 13: loss -8.45963 acc 0.66225 roc_auc 0.37588 prc_auc 0.56971[0m
[93maverage test of epoch 13: loss -8.76155 acc 0.67568 roc_auc 0.42500 prc_auc 0.64400[0m
[92maverage training of epoch 14: loss -9.02603 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 14: loss -9.32934 acc 0.67568 roc_auc 0.58000 prc_auc 0.71494[0m
[92maverage training of epoch 15: loss -9.59056 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 15: loss -9.89543 acc 0.67568 roc_auc 0.62000 prc_auc 0.73274[0m
[92maverage training of epoch 16: loss -10.15356 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 16: loss -10.46014 acc 0.67568 roc_auc 0.16000 prc_auc 0.62824[0m
[92maverage training of epoch 17: loss -10.71529 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 17: loss -11.02368 acc 0.67568 roc_auc 0.12000 prc_auc 0.62703[0m
[92maverage training of epoch 18: loss -11.27597 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 18: loss -11.58626 acc 0.67568 roc_auc 0.34000 prc_auc 0.61318[0m
[92maverage training of epoch 19: loss -11.83576 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 19: loss -12.14804 acc 0.67568 roc_auc 0.54000 prc_auc 0.69491[0m
[92maverage training of epoch 20: loss -12.39481 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 20: loss -12.70913 acc 0.67568 roc_auc 0.70000 prc_auc 0.79644[0m
[92maverage training of epoch 21: loss -12.95323 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 21: loss -13.26964 acc 0.67568 roc_auc 0.77333 prc_auc 0.86097[0m
[92maverage training of epoch 22: loss -13.51113 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 22: loss -13.82966 acc 0.67568 roc_auc 0.62000 prc_auc 0.75103[0m
[92maverage training of epoch 23: loss -14.06857 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 23: loss -14.38927 acc 0.67568 roc_auc 0.40000 prc_auc 0.63392[0m
[92maverage training of epoch 24: loss -14.62562 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 24: loss -14.94852 acc 0.67568 roc_auc 0.83500 prc_auc 0.86790[0m
[92maverage training of epoch 25: loss -15.18236 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 25: loss -15.50747 acc 0.67568 roc_auc 0.74000 prc_auc 0.81658[0m
[92maverage training of epoch 26: loss -15.73881 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 26: loss -16.06616 acc 0.67568 roc_auc 0.68000 prc_auc 0.78032[0m
[92maverage training of epoch 27: loss -16.29502 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 27: loss -16.62463 acc 0.67568 roc_auc 0.58000 prc_auc 0.71961[0m
[92maverage training of epoch 28: loss -16.85103 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 28: loss -17.18291 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 29: loss -17.40687 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 29: loss -17.74103 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 30: loss -17.96255 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 30: loss -18.29901 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 31: loss -18.51810 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 31: loss -18.85687 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 32: loss -19.07355 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 32: loss -19.41463 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 33: loss -19.62890 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 33: loss -19.97230 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 34: loss -20.18416 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 34: loss -20.52989 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 35: loss -20.73936 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 35: loss -21.08741 acc 0.67568 roc_auc 0.72000 prc_auc 0.80439[0m
[92maverage training of epoch 36: loss -21.29449 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 36: loss -21.64488 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 37: loss -21.84958 acc 0.66225 roc_auc 0.37578 prc_auc 0.56962[0mUsing backend: pytorch
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))

[93maverage test of epoch 37: loss -22.20230 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 38: loss -22.40461 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 38: loss -22.75968 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 39: loss -22.95960 acc 0.66225 roc_auc 0.37578 prc_auc 0.56962[0m
[93maverage test of epoch 39: loss -23.31701 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 40: loss -23.51456 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 40: loss -23.87431 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 41: loss -24.06948 acc 0.66225 roc_auc 0.37588 prc_auc 0.56962[0m
[93maverage test of epoch 41: loss -24.43159 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 42: loss -24.62438 acc 0.66225 roc_auc 0.37588 prc_auc 0.56968[0m
[93maverage test of epoch 42: loss -24.98883 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -25.17925 acc 0.66225 roc_auc 0.37569 prc_auc 0.56937[0m
[93maverage test of epoch 43: loss -25.54606 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -25.73411 acc 0.66225 roc_auc 0.37578 prc_auc 0.56968[0m
[93maverage test of epoch 44: loss -26.10328 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -26.28896 acc 0.66225 roc_auc 0.37569 prc_auc 0.56993[0m
[93maverage test of epoch 45: loss -26.66047 acc 0.67568 roc_auc 0.32333 prc_auc 0.61317[0m
[92maverage training of epoch 46: loss -26.84378 acc 0.66225 roc_auc 0.37598 prc_auc 0.56972[0m
[93maverage test of epoch 46: loss -27.21766 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -27.39860 acc 0.66225 roc_auc 0.37559 prc_auc 0.56984[0m
[93maverage test of epoch 47: loss -27.77483 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -27.95341 acc 0.66225 roc_auc 0.37588 prc_auc 0.57082[0m
[93maverage test of epoch 48: loss -28.33199 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -28.50820 acc 0.66225 roc_auc 0.37588 prc_auc 0.56942[0m
[93maverage test of epoch 49: loss -28.88915 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 50: loss -29.06299 acc 0.66225 roc_auc 0.37598 prc_auc 0.56971[0m
[93maverage test of epoch 50: loss -29.44629 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 51: loss -29.61776 acc 0.66225 roc_auc 0.37559 prc_auc 0.57051[0m
[93maverage test of epoch 51: loss -30.00342 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 52: loss -30.17253 acc 0.66225 roc_auc 0.37598 prc_auc 0.57066[0m
[93maverage test of epoch 52: loss -30.56055 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 53: loss -30.72729 acc 0.66225 roc_auc 0.37608 prc_auc 0.57043[0m
[93maverage test of epoch 53: loss -31.11766 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 54: loss -31.28204 acc 0.66225 roc_auc 0.37569 prc_auc 0.57034[0m
[93maverage test of epoch 54: loss -31.67477 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 55: loss -31.83678 acc 0.66225 roc_auc 0.37627 prc_auc 0.57227[0m
[93maverage test of epoch 55: loss -32.23187 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 56: loss -32.39152 acc 0.66225 roc_auc 0.37520 prc_auc 0.57149[0m
[93maverage test of epoch 56: loss -32.78896 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 57: loss -32.94625 acc 0.66225 roc_auc 0.37588 prc_auc 0.57058[0m
[93maverage test of epoch 57: loss -33.34606 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 58: loss -33.50097 acc 0.66225 roc_auc 0.37637 prc_auc 0.57394[0m
[93maverage test of epoch 58: loss -33.90314 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 59: loss -34.05570 acc 0.66225 roc_auc 0.37559 prc_auc 0.56967[0m
[93maverage test of epoch 59: loss -34.46023 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 60: loss -34.61042 acc 0.66225 roc_auc 0.37647 prc_auc 0.57361[0m
[93maverage test of epoch 60: loss -35.01731 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 61: loss -35.16513 acc 0.66225 roc_auc 0.37529 prc_auc 0.57079[0m
[93maverage test of epoch 61: loss -35.57438 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 62: loss -35.71984 acc 0.66225 roc_auc 0.37539 prc_auc 0.57268[0m
[93maverage test of epoch 62: loss -36.13145 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 63: loss -36.27454 acc 0.66225 roc_auc 0.37490 prc_auc 0.57052[0m
[93maverage test of epoch 63: loss -36.68851 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 64: loss -36.82923 acc 0.66225 roc_auc 0.37500 prc_auc 0.57187[0m
[93maverage test of epoch 64: loss -37.24555 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 65: loss -37.38391 acc 0.66225 roc_auc 0.37480 prc_auc 0.57107[0m
[93maverage test of epoch 65: loss -37.80259 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 66: loss -37.93858 acc 0.66225 roc_auc 0.37441 prc_auc 0.57190[0m
[93maverage test of epoch 66: loss -38.35962 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 67: loss -38.49325 acc 0.66225 roc_auc 0.37637 prc_auc 0.57529[0m
[93maverage test of epoch 67: loss -38.91665 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 68: loss -39.04791 acc 0.66225 roc_auc 0.37520 prc_auc 0.57583[0m
[93maverage test of epoch 68: loss -39.47368 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 69: loss -39.60258 acc 0.66225 roc_auc 0.37775 prc_auc 0.57929[0m
[93maverage test of epoch 69: loss -40.03070 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 70: loss -40.15724 acc 0.66225 roc_auc 0.37657 prc_auc 0.57830[0m
[93maverage test of epoch 70: loss -40.58772 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 71: loss -40.71190 acc 0.66225 roc_auc 0.37882 prc_auc 0.57960[0m
[93maverage test of epoch 71: loss -41.14474 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 72: loss -41.26655 acc 0.66225 roc_auc 0.37676 prc_auc 0.58131[0m
[93maverage test of epoch 72: loss -41.70176 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 73: loss -41.82120 acc 0.66225 roc_auc 0.37382 prc_auc 0.57766[0m
[93maverage test of epoch 73: loss -42.25877 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 74: loss -42.37585 acc 0.66225 roc_auc 0.37049 prc_auc 0.57867[0m
[93maverage test of epoch 74: loss -42.81578 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 75: loss -42.93050 acc 0.66225 roc_auc 0.38343 prc_auc 0.58897[0m
[93maverage test of epoch 75: loss -43.37279 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 76: loss -43.48514 acc 0.66225 roc_auc 0.37882 prc_auc 0.58967[0m
[93maverage test of epoch 76: loss -43.92980 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 77: loss -44.03979 acc 0.66225 roc_auc 0.38422 prc_auc 0.59181[0m
[93maverage test of epoch 77: loss -44.48680 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 78: loss -44.59442 acc 0.66225 roc_auc 0.39118 prc_auc 0.59695[0m
[93maverage test of epoch 78: loss -45.04380 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 79: loss -45.14906 acc 0.66225 roc_auc 0.38343 prc_auc 0.60003[0m
[93maverage test of epoch 79: loss -45.60079 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 80: loss -45.70369 acc 0.66225 roc_auc 0.38147 prc_auc 0.59978[0m
[93maverage test of epoch 80: loss -46.15779 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 81: loss -46.25832 acc 0.66225 roc_auc 0.38902 prc_auc 0.60365[0m
[93maverage test of epoch 81: loss -46.71478 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 82: loss -46.81295 acc 0.66225 roc_auc 0.40873 prc_auc 0.61824[0m
[93maverage test of epoch 82: loss -47.27178 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 83: loss -47.36758 acc 0.66225 roc_auc 0.43108 prc_auc 0.62951[0m
[93maverage test of epoch 83: loss -47.82877 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 84: loss -47.92221 acc 0.66225 roc_auc 0.36902 prc_auc 0.60336[0m
[93maverage test of epoch 84: loss -48.38575 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 85: loss -48.47683 acc 0.66225 roc_auc 0.35569 prc_auc 0.60251[0m
[93maverage test of epoch 85: loss -48.94274 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 86: loss -49.03146 acc 0.66225 roc_auc 0.43765 prc_auc 0.63608[0m
[93maverage test of epoch 86: loss -49.49973 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 87: loss -49.58608 acc 0.66225 roc_auc 0.40343 prc_auc 0.61969[0m
[93maverage test of epoch 87: loss -50.05671 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 88: loss -50.14070 acc 0.66225 roc_auc 0.42725 prc_auc 0.63225[0m
[93maverage test of epoch 88: loss -50.61370 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 89: loss -50.69532 acc 0.66225 roc_auc 0.42745 prc_auc 0.63225[0m
[93maverage test of epoch 89: loss -51.17068 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 90: loss -51.24994 acc 0.66225 roc_auc 0.45088 prc_auc 0.64167[0m
[93maverage test of epoch 90: loss -51.72766 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 91: loss -51.80455 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 91: loss -52.28463 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 92: loss -52.35916 acc 0.66225 roc_auc 0.49784 prc_auc 0.66129[0m
[93maverage test of epoch 92: loss -52.84161 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 93: loss -52.91377 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 93: loss -53.39858 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 94: loss -53.46838 acc 0.66225 roc_auc 0.48363 prc_auc 0.65502[0m
[93maverage test of epoch 94: loss -53.95555 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 95: loss -54.02298 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 95: loss -54.51251 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 96: loss -54.57758 acc 0.66225 roc_auc 0.40333 prc_auc 0.63276[0m
[93maverage test of epoch 96: loss -55.06947 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 97: loss -55.13217 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 97: loss -55.62642 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 98: loss -55.68677 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 98: loss -56.18338 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 99: loss -56.24136 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 99: loss -56.74033 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -0.86847 acc 0.66225 roc_auc 0.39118 prc_auc 0.61203[0m
[93maverage test of epoch 0: loss -1.25238 acc 0.67568 roc_auc 0.92667 prc_auc 0.97089[0m
[92maverage training of epoch 1: loss -1.59482 acc 0.66225 roc_auc 0.43412 prc_auc 0.64581[0m
[93maverage test of epoch 1: loss -1.98787 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 2: loss -2.32336 acc 0.66225 roc_auc 0.41980 prc_auc 0.62801[0m
[93maverage test of epoch 2: loss -2.71711 acc 0.67568 roc_auc 0.92667 prc_auc 0.97104[0m
[92maverage training of epoch 3: loss -3.02987 acc 0.66225 roc_auc 0.39529 prc_auc 0.60647[0m
[93maverage test of epoch 3: loss -3.40621 acc 0.67568 roc_auc 0.93333 prc_auc 0.97377[0m
[92maverage training of epoch 4: loss -3.69180 acc 0.66225 roc_auc 0.38137 prc_auc 0.59772[0m
[93maverage test of epoch 4: loss -4.05134 acc 0.67568 roc_auc 0.93167 prc_auc 0.97104[0m
[92maverage training of epoch 5: loss -4.31875 acc 0.66225 roc_auc 0.37843 prc_auc 0.58897[0m
[93maverage test of epoch 5: loss -4.66893 acc 0.67568 roc_auc 0.93167 prc_auc 0.97104[0m
[92maverage training of epoch 6: loss -4.92455 acc 0.66225 roc_auc 0.37804 prc_auc 0.59065[0m
[93maverage test of epoch 6: loss -5.26995 acc 0.67568 roc_auc 0.93000 prc_auc 0.96958[0m
[92maverage training of epoch 7: loss -5.51724 acc 0.66225 roc_auc 0.37686 prc_auc 0.57751[0m
[93maverage test of epoch 7: loss -5.86036 acc 0.67568 roc_auc 0.93333 prc_auc 0.96845[0m
[92maverage training of epoch 8: loss -6.10122 acc 0.66225 roc_auc 0.37451 prc_auc 0.57198[0m
[93maverage test of epoch 8: loss -6.44347 acc 0.67568 roc_auc 0.93333 prc_auc 0.96845[0m
[92maverage training of epoch 9: loss -6.67908 acc 0.66225 roc_auc 0.37294 prc_auc 0.57087[0m
[93maverage test of epoch 9: loss -7.02135 acc 0.67568 roc_auc 0.93333 prc_auc 0.96845[0m
[92maverage training of epoch 10: loss -7.25243 acc 0.66225 roc_auc 0.37216 prc_auc 0.56989[0m
[93maverage test of epoch 10: loss -7.59529 acc 0.67568 roc_auc 0.93667 prc_auc 0.96845[0m
[92maverage training of epoch 11: loss -7.82236 acc 0.66225 roc_auc 0.37078 prc_auc 0.56889[0m
[93maverage test of epoch 11: loss -8.16622 acc 0.67568 roc_auc 0.93333 prc_auc 0.96875[0m
[92maverage training of epoch 12: loss -8.38964 acc 0.66225 roc_auc 0.37098 prc_auc 0.56906[0m
[93maverage test of epoch 12: loss -8.73478 acc 0.67568 roc_auc 0.92333 prc_auc 0.95512[0m
[92maverage training of epoch 13: loss -8.95481 acc 0.66225 roc_auc 0.37039 prc_auc 0.56861[0m
[93maverage test of epoch 13: loss -9.30145 acc 0.67568 roc_auc 0.91333 prc_auc 0.94698[0m
[92maverage training of epoch 14: loss -9.51828 acc 0.66225 roc_auc 0.37020 prc_auc 0.56846[0m
[93maverage test of epoch 14: loss -9.86658 acc 0.67568 roc_auc 0.79667 prc_auc 0.83926[0m
[92maverage training of epoch 15: loss -10.08038 acc 0.66225 roc_auc 0.37020 prc_auc 0.56846[0m
[93maverage test of epoch 15: loss -10.43046 acc 0.67568 roc_auc 0.66833 prc_auc 0.75939[0m
[92maverage training of epoch 16: loss -10.64133 acc 0.66225 roc_auc 0.37020 prc_auc 0.56846[0m
[93maverage test of epoch 16: loss -10.99330 acc 0.67568 roc_auc 0.79333 prc_auc 0.83776[0m
[92maverage training of epoch 17: loss -11.20135 acc 0.66225 roc_auc 0.37000 prc_auc 0.56832[0m
[93maverage test of epoch 17: loss -11.55528 acc 0.67568 roc_auc 0.84000 prc_auc 0.89622[0m
[92maverage training of epoch 18: loss -11.76058 acc 0.66225 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 18: loss -12.11655 acc 0.67568 roc_auc 0.79333 prc_auc 0.83776[0m
[92maverage training of epoch 19: loss -12.31916 acc 0.66225 roc_auc 0.36990 prc_auc 0.56821[0m
[93maverage test of epoch 19: loss -12.67721 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 20: loss -12.87718 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 20: loss -13.23736 acc 0.67568 roc_auc 0.75167 prc_auc 0.80977[0m
[92maverage training of epoch 21: loss -13.43474 acc 0.66225 roc_auc 0.36971 prc_auc 0.56804[0m
[93maverage test of epoch 21: loss -13.79708 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 22: loss -13.99190 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 22: loss -14.35643 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 23: loss -14.54873 acc 0.66225 roc_auc 0.36980 prc_auc 0.56801[0m
[93maverage test of epoch 23: loss -14.91547 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 24: loss -15.10526 acc 0.66225 roc_auc 0.36990 prc_auc 0.56804[0m
[93maverage test of epoch 24: loss -15.47425 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 25: loss -15.66156 acc 0.66225 roc_auc 0.36990 prc_auc 0.56821[0m
[93maverage test of epoch 25: loss -16.03280 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 26: loss -16.21764 acc 0.66225 roc_auc 0.37000 prc_auc 0.56821[0m
[93maverage test of epoch 26: loss -16.59115 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 27: loss -16.77355 acc 0.66225 roc_auc 0.36990 prc_auc 0.56825[0m
[93maverage test of epoch 27: loss -17.14934 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 28: loss -17.32930 acc 0.66225 roc_auc 0.36990 prc_auc 0.56804[0m
[93maverage test of epoch 28: loss -17.70739 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 29: loss -17.88492 acc 0.66225 roc_auc 0.37000 prc_auc 0.56827[0m
[93maverage test of epoch 29: loss -18.26531 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 30: loss -18.44043 acc 0.66225 roc_auc 0.37010 prc_auc 0.56846[0m
[93maverage test of epoch 30: loss -18.82313 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 31: loss -18.99583 acc 0.66225 roc_auc 0.36980 prc_auc 0.56887[0m
[93maverage test of epoch 31: loss -19.38085 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 32: loss -19.55115 acc 0.66225 roc_auc 0.37000 prc_auc 0.56942[0m
[93maverage test of epoch 32: loss -19.93850 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 33: loss -20.10640 acc 0.66225 roc_auc 0.36990 prc_auc 0.56949[0m
[93maverage test of epoch 33: loss -20.49608 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 34: loss -20.66159 acc 0.66225 roc_auc 0.37000 prc_auc 0.56925[0m
[93maverage test of epoch 34: loss -21.05360 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 35: loss -21.21672 acc 0.66225 roc_auc 0.37000 prc_auc 0.56972[0m
[93maverage test of epoch 35: loss -21.61106 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 36: loss -21.77180 acc 0.66225 roc_auc 0.37020 prc_auc 0.57005[0m
[93maverage test of epoch 36: loss -22.16848 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 37: loss -22.32683 acc 0.66225 roc_auc 0.36941 prc_auc 0.57147[0m
[93maverage test of epoch 37: loss -22.72586 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 38: loss -22.88184 acc 0.66225 roc_auc 0.36882 prc_auc 0.56854[0m
[93maverage test of epoch 38: loss -23.28321 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 39: loss -23.43681 acc 0.66225 roc_auc 0.36902 prc_auc 0.57009[0m
[93maverage test of epoch 39: loss -23.84053 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -23.99176 acc 0.66225 roc_auc 0.36892 prc_auc 0.56907[0m
[93maverage test of epoch 40: loss -24.39783 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -24.54668 acc 0.66225 roc_auc 0.36873 prc_auc 0.57127[0m
[93maverage test of epoch 41: loss -24.95510 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -25.10158 acc 0.66225 roc_auc 0.36951 prc_auc 0.56852[0m
[93maverage test of epoch 42: loss -25.51236 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -25.65646 acc 0.66225 roc_auc 0.36863 prc_auc 0.57157[0m
[93maverage test of epoch 43: loss -26.06959 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -26.21133 acc 0.66225 roc_auc 0.36755 prc_auc 0.57012[0m
[93maverage test of epoch 44: loss -26.62681 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -26.76618 acc 0.66225 roc_auc 0.36892 prc_auc 0.56912[0m
[93maverage test of epoch 45: loss -27.18402 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -27.32102 acc 0.66225 roc_auc 0.36549 prc_auc 0.56716[0m
[93maverage test of epoch 46: loss -27.74122 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -27.87585 acc 0.66225 roc_auc 0.36716 prc_auc 0.56853[0m
[93maverage test of epoch 47: loss -28.29840 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -28.43067 acc 0.66225 roc_auc 0.36559 prc_auc 0.57002[0m
[93maverage test of epoch 48: loss -28.85557 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -28.98547 acc 0.66225 roc_auc 0.36569 prc_auc 0.57033[0m
[93maverage test of epoch 49: loss -29.41273 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 50: loss -29.54027 acc 0.66225 roc_auc 0.36794 prc_auc 0.57158[0m
[93maverage test of epoch 50: loss -29.96988 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 51: loss -30.09505 acc 0.66225 roc_auc 0.36225 prc_auc 0.56992[0m
[93maverage test of epoch 51: loss -30.52702 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 52: loss -30.64983 acc 0.66225 roc_auc 0.37137 prc_auc 0.57590[0m
[93maverage test of epoch 52: loss -31.08415 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 53: loss -31.20459 acc 0.66225 roc_auc 0.36941 prc_auc 0.57701[0m
[93maverage test of epoch 53: loss -31.64128 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 54: loss -31.75935 acc 0.66225 roc_auc 0.36588 prc_auc 0.57594[0m
[93maverage test of epoch 54: loss -32.19839 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 55: loss -32.31410 acc 0.66225 roc_auc 0.36000 prc_auc 0.57538[0m
[93maverage test of epoch 55: loss -32.75550 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 56: loss -32.86885 acc 0.66225 roc_auc 0.35843 prc_auc 0.57734[0m
[93maverage test of epoch 56: loss -33.31261 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 57: loss -33.42359 acc 0.66225 roc_auc 0.37186 prc_auc 0.58609[0m
[93maverage test of epoch 57: loss -33.86971 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 58: loss -33.97833 acc 0.66225 roc_auc 0.38637 prc_auc 0.59412[0m
[93maverage test of epoch 58: loss -34.42681 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 59: loss -34.53307 acc 0.66225 roc_auc 0.37824 prc_auc 0.59340[0m
[93maverage test of epoch 59: loss -34.98391 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 60: loss -35.08781 acc 0.66225 roc_auc 0.38745 prc_auc 0.60535[0m
[93maverage test of epoch 60: loss -35.54102 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 61: loss -35.64255 acc 0.66225 roc_auc 0.39127 prc_auc 0.60568[0m
[93maverage test of epoch 61: loss -36.09812 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 62: loss -36.19729 acc 0.66225 roc_auc 0.39127 prc_auc 0.60434[0m
[93maverage test of epoch 62: loss -36.65521 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 63: loss -36.75203 acc 0.66225 roc_auc 0.37294 prc_auc 0.60006[0m
[93maverage test of epoch 63: loss -37.21231 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 64: loss -37.30676 acc 0.66225 roc_auc 0.44902 prc_auc 0.63662[0m
[93maverage test of epoch 64: loss -37.76940 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 65: loss -37.86149 acc 0.66225 roc_auc 0.44176 prc_auc 0.63541[0m
[93maverage test of epoch 65: loss -38.32649 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 66: loss -38.41622 acc 0.66225 roc_auc 0.44020 prc_auc 0.63446[0m
[93maverage test of epoch 66: loss -38.88358 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 67: loss -38.97095 acc 0.66225 roc_auc 0.43461 prc_auc 0.63409[0m
[93maverage test of epoch 67: loss -39.44067 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 68: loss -39.52567 acc 0.66225 roc_auc 0.40118 prc_auc 0.61997[0m
[93maverage test of epoch 68: loss -39.99776 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 69: loss -40.08040 acc 0.66225 roc_auc 0.41108 prc_auc 0.62735[0m
[93maverage test of epoch 69: loss -40.55485 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 70: loss -40.63512 acc 0.66225 roc_auc 0.36471 prc_auc 0.62071[0m
[93maverage test of epoch 70: loss -41.11193 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 71: loss -41.18984 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 71: loss -41.66901 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 72: loss -41.74457 acc 0.66225 roc_auc 0.44784 prc_auc 0.64007[0m
[93maverage test of epoch 72: loss -42.22610 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 73: loss -42.29929 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 73: loss -42.78318 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 74: loss -42.85400 acc 0.66225 roc_auc 0.47804 prc_auc 0.65262[0m
[93maverage test of epoch 74: loss -43.34026 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 75: loss -43.40872 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 75: loss -43.89733 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 76: loss -43.96343 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 76: loss -44.45441 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 77: loss -44.51814 acc 0.66225 roc_auc 0.45382 prc_auc 0.64238[0m
[93maverage test of epoch 77: loss -45.01148 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 78: loss -45.07285 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 78: loss -45.56855 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 79: loss -45.62756 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 79: loss -46.12561 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 80: loss -46.18226 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 80: loss -46.68267 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 81: loss -46.73696 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 81: loss -47.23973 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 82: loss -47.29166 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 82: loss -47.79680 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 83: loss -47.84636 acc 0.66225 roc_auc 0.44765 prc_auc 0.64002[0m
[93maverage test of epoch 83: loss -48.35386 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 84: loss -48.40105 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 84: loss -48.91091 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 85: loss -48.95575 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 85: loss -49.46797 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 86: loss -49.51044 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 86: loss -50.02502 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 87: loss -50.06513 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 87: loss -50.58207 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 88: loss -50.61981 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 88: loss -51.13912 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 89: loss -51.17449 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 89: loss -51.69616 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 90: loss -51.72917 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 90: loss -52.25320 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 91: loss -52.28385 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 91: loss -52.81024 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 92: loss -52.83852 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 92: loss -53.36727 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 93: loss -53.39319 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 93: loss -53.92430 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 94: loss -53.94785 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 94: loss -54.48132 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 95: loss -54.50251 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 95: loss -55.03835 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 96: loss -55.05717 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 96: loss -55.59536 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 97: loss -55.61183 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 97: loss -56.15238 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 98: loss -56.16648 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 98: loss -56.70939 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 99: loss -56.72113 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 99: loss -57.26640 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.66501 ROC_AUC (avg): 0.5 PRC_AUC (avg): 0.66501 

Average forward propagation time taken(ms): 2.481241066771054
Average backward propagation time taken(ms): 0.8728398113615533

