# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.0003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-17-27-50/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-17-27-50/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 8,
 'epochs': 50,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 8,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.0003,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 1,
 'num_workers': 8,
 'number_of_mlp_layer': 0,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-17-17-27-50',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 50, 'learning_rate': 0.0003, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss 0.12610 acc 0.45333 roc_auc 0.46560 prc_auc 0.68889[0m
[93maverage test of epoch 0: loss -0.07634 acc 0.65789 roc_auc 0.87077 prc_auc 0.93994[0m
[92maverage training of epoch 1: loss -0.27744 acc 0.66000 roc_auc 0.47020 prc_auc 0.69270[0m
[93maverage test of epoch 1: loss -0.50806 acc 0.65789 roc_auc 0.87077 prc_auc 0.93581[0m
[92maverage training of epoch 2: loss -0.83101 acc 0.66667 roc_auc 0.40300 prc_auc 0.60615[0m
[93maverage test of epoch 2: loss -1.22823 acc 0.65789 roc_auc 0.25538 prc_auc 0.60226[0m
[92maverage training of epoch 3: loss -1.57646 acc 0.66667 roc_auc 0.40020 prc_auc 0.60199[0m
[93maverage test of epoch 3: loss -1.85892 acc 0.65789 roc_auc 0.24308 prc_auc 0.60347[0m
[92maverage training of epoch 4: loss -2.06831 acc 0.66667 roc_auc 0.46300 prc_auc 0.64730[0m
[93maverage test of epoch 4: loss -2.27454 acc 0.65789 roc_auc 0.70769 prc_auc 0.85835[0m
[92maverage training of epoch 5: loss -2.46716 acc 0.60000 roc_auc 0.50900 prc_auc 0.70205[0m
[93maverage test of epoch 5: loss -2.66528 acc 0.42105 roc_auc 0.85846 prc_auc 0.92042[0m
[92maverage training of epoch 6: loss -2.84970 acc 0.41333 roc_auc 0.52080 prc_auc 0.72163[0m
[93maverage test of epoch 6: loss -3.04016 acc 0.34211 roc_auc 0.84923 prc_auc 0.91705[0m
[92maverage training of epoch 7: loss -3.21476 acc 0.33333 roc_auc 0.51400 prc_auc 0.71554[0m
[93maverage test of epoch 7: loss -3.39854 acc 0.34211 roc_auc 0.84923 prc_auc 0.91719[0m
[92maverage training of epoch 8: loss -3.56848 acc 0.33333 roc_auc 0.52480 prc_auc 0.72429[0m
[93maverage test of epoch 8: loss -3.75221 acc 0.34211 roc_auc 0.87385 prc_auc 0.93725[0m
[92maverage training of epoch 9: loss -3.92506 acc 0.33333 roc_auc 0.55540 prc_auc 0.73902[0m
[93maverage test of epoch 9: loss -4.11810 acc 0.34211 roc_auc 0.88000 prc_auc 0.93878[0m
[92maverage training of epoch 10: loss -4.30435 acc 0.33333 roc_auc 0.59960 prc_auc 0.76904[0m
[93maverage test of epoch 10: loss -4.52006 acc 0.34211 roc_auc 0.88308 prc_auc 0.93915[0m
[92maverage training of epoch 11: loss -4.72795 acc 0.33333 roc_auc 0.64080 prc_auc 0.80733[0m
[93maverage test of epoch 11: loss -4.96441 acc 0.34211 roc_auc 0.87692 prc_auc 0.93688[0m
[92maverage training of epoch 12: loss -5.16229 acc 0.33333 roc_auc 0.67960 prc_auc 0.84862[0m
[93maverage test of epoch 12: loss -5.38614 acc 0.34211 roc_auc 0.85846 prc_auc 0.93689[0m
[92maverage training of epoch 13: loss -5.56879 acc 0.33333 roc_auc 0.55860 prc_auc 0.76231[0m
[93maverage test of epoch 13: loss -5.78079 acc 0.34211 roc_auc 0.83385 prc_auc 0.92837[0m
[92maverage training of epoch 14: loss -5.95306 acc 0.33333 roc_auc 0.43080 prc_auc 0.65575[0m
[93maverage test of epoch 14: loss -6.15533 acc 0.34211 roc_auc 0.65846 prc_auc 0.84303[0m
[92maverage training of epoch 15: loss -6.31985 acc 0.33333 roc_auc 0.36080 prc_auc 0.57162[0m
[93maverage test of epoch 15: loss -6.51406 acc 0.34211 roc_auc 0.27385 prc_auc 0.59274[0m
[92maverage training of epoch 16: loss -6.67297 acc 0.33333 roc_auc 0.35360 prc_auc 0.56543[0m
[93maverage test of epoch 16: loss -6.86077 acc 0.34211 roc_auc 0.14769 prc_auc 0.49418[0m
[92maverage training of epoch 17: loss -7.01569 acc 0.33333 roc_auc 0.35240 prc_auc 0.56345[0m
[93maverage test of epoch 17: loss -7.19838 acc 0.34211 roc_auc 0.13846 prc_auc 0.49188[0m
[92maverage training of epoch 18: loss -7.35043 acc 0.33333 roc_auc 0.35360 prc_auc 0.56341[0m
[93maverage test of epoch 18: loss -7.52896 acc 0.34211 roc_auc 0.13538 prc_auc 0.49155[0m
[92maverage training of epoch 19: loss -7.67896 acc 0.33333 roc_auc 0.35460 prc_auc 0.56396[0m
[93maverage test of epoch 19: loss -7.85400 acc 0.34211 roc_auc 0.13538 prc_auc 0.49161[0m
[92maverage training of epoch 20: loss -8.00254 acc 0.33333 roc_auc 0.35700 prc_auc 0.56491[0m
[93maverage test of epoch 20: loss -8.17462 acc 0.34211 roc_auc 0.13846 prc_auc 0.49518[0m
[92maverage training of epoch 21: loss -8.32215 acc 0.33333 roc_auc 0.35760 prc_auc 0.56509[0m
[93maverage test of epoch 21: loss -8.49166 acc 0.34211 roc_auc 0.13385 prc_auc 0.49248[0m
[92maverage training of epoch 22: loss -8.63851 acc 0.33333 roc_auc 0.35720 prc_auc 0.56413[0m
[93maverage test of epoch 22: loss -8.80575 acc 0.34211 roc_auc 0.13231 prc_auc 0.49574[0m
[92maverage training of epoch 23: loss -8.95220 acc 0.33333 roc_auc 0.35780 prc_auc 0.56431[0m
[93maverage test of epoch 23: loss -9.11742 acc 0.34211 roc_auc 0.13385 prc_auc 0.49312[0m
[92maverage training of epoch 24: loss -9.26366 acc 0.33333 roc_auc 0.35680 prc_auc 0.56258[0m
[93maverage test of epoch 24: loss -9.42704 acc 0.34211 roc_auc 0.13385 prc_auc 0.49974[0m
[92maverage training of epoch 25: loss -9.57326 acc 0.33333 roc_auc 0.35740 prc_auc 0.56274[0m
[93maverage test of epoch 25: loss -9.73496 acc 0.34211 roc_auc 0.13692 prc_auc 0.50232[0m
[92maverage training of epoch 26: loss -9.88128 acc 0.33333 roc_auc 0.35700 prc_auc 0.56268[0m
[93maverage test of epoch 26: loss -10.04144 acc 0.34211 roc_auc 0.13692 prc_auc 0.50514[0m
[92maverage training of epoch 27: loss -10.18798 acc 0.33333 roc_auc 0.35640 prc_auc 0.56176[0m
[93maverage test of epoch 27: loss -10.34669 acc 0.34211 roc_auc 0.12308 prc_auc 0.50166[0m
[92maverage training of epoch 28: loss -10.49354 acc 0.33333 roc_auc 0.35640 prc_auc 0.56171[0m
[93maverage test of epoch 28: loss -10.65089 acc 0.34211 roc_auc 0.12154 prc_auc 0.50067[0m
[92maverage training of epoch 29: loss -10.79813 acc 0.33333 roc_auc 0.35620 prc_auc 0.56166[0m
[93maverage test of epoch 29: loss -10.95420 acc 0.34211 roc_auc 0.13538 prc_auc 0.50733[0m
[92maverage training of epoch 30: loss -11.10189 acc 0.33333 roc_auc 0.35620 prc_auc 0.56162[0m
[93maverage test of epoch 30: loss -11.25674 acc 0.34211 roc_auc 0.10154 prc_auc 0.49025[0m
[92maverage training of epoch 31: loss -11.40494 acc 0.44667 roc_auc 0.35620 prc_auc 0.56142[0m
[93maverage test of epoch 31: loss -11.55862 acc 0.65789 roc_auc 0.15692 prc_auc 0.51798[0m
[92maverage training of epoch 32: loss -11.70738 acc 0.66667 roc_auc 0.35640 prc_auc 0.56151[0m
[93maverage test of epoch 32: loss -11.85993 acc 0.65789 roc_auc 0.16000 prc_auc 0.52532[0m
[92maverage training of epoch 33: loss -12.00928 acc 0.66667 roc_auc 0.35640 prc_auc 0.56151[0m
[93maverage test of epoch 33: loss -12.16075 acc 0.65789 roc_auc 0.14000 prc_auc 0.52147[0m
[92maverage training of epoch 34: loss -12.31072 acc 0.66667 roc_auc 0.35660 prc_auc 0.56164[0m
[93maverage test of epoch 34: loss -12.46113 acc 0.65789 roc_auc 0.17231 prc_auc 0.54729[0m
[92maverage training of epoch 35: loss -12.61177 acc 0.66667 roc_auc 0.35640 prc_auc 0.56146[0m
[93maverage test of epoch 35: loss -12.76115 acc 0.65789 roc_auc 0.16923 prc_auc 0.58752[0m
[92maverage training of epoch 36: loss -12.91247 acc 0.66667 roc_auc 0.35640 prc_auc 0.56146[0m
[93maverage test of epoch 36: loss -13.06085 acc 0.65789 roc_auc 0.10923 prc_auc 0.55506[0m
[92maverage training of epoch 37: loss -13.21287 acc 0.66667 roc_auc 0.35620 prc_auc 0.56137[0m
[93maverage test of epoch 37: loss -13.36026 acc 0.65789 roc_auc 0.32462 prc_auc 0.58629[0m
[92maverage training of epoch 38: loss -13.51301 acc 0.66667 roc_auc 0.35660 prc_auc 0.56162[0m
[93maverage test of epoch 38: loss -13.65944 acc 0.65789 roc_auc 0.29692 prc_auc 0.58249[0m
[92maverage training of epoch 39: loss -13.81292 acc 0.66667 roc_auc 0.35700 prc_auc 0.56196[0m
[93maverage test of epoch 39: loss -13.95840 acc 0.65789 roc_auc 0.27231 prc_auc 0.57947[0m
[92maverage training of epoch 40: loss -14.11263 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 40: loss -14.25717 acc 0.65789 roc_auc 0.54615 prc_auc 0.69946[0m
[92maverage training of epoch 41: loss -14.41217 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 41: loss -14.55578 acc 0.65789 roc_auc 0.11846 prc_auc 0.56708[0m
[92maverage training of epoch 42: loss -14.71156 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 42: loss -14.85425 acc 0.65789 roc_auc 0.44923 prc_auc 0.63152[0m
[92maverage training of epoch 43: loss -15.01082 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 43: loss -15.15260 acc 0.65789 roc_auc 0.58462 prc_auc 0.71122[0m
[92maverage training of epoch 44: loss -15.30995 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 44: loss -15.45084 acc 0.65789 roc_auc 0.54923 prc_auc 0.68301[0m
[92maverage training of epoch 45: loss -15.60899 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 45: loss -15.74898 acc 0.65789 roc_auc 0.56308 prc_auc 0.69271[0m
[92maverage training of epoch 46: loss -15.90794 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 46: loss -16.04704 acc 0.65789 roc_auc 0.60000 prc_auc 0.73334[0m
[92maverage training of epoch 47: loss -16.20681 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 47: loss -16.34502 acc 0.65789 roc_auc 0.30615 prc_auc 0.57664[0m
[92maverage training of epoch 48: loss -16.50561 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 48: loss -16.64294 acc 0.65789 roc_auc 0.18000 prc_auc 0.56278[0m
[92maverage training of epoch 49: loss -16.80435 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 49: loss -16.94081 acc 0.65789 roc_auc 0.31385 prc_auc 0.57182[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.41255 acc 0.66667 roc_auc 0.37340 prc_auc 0.57976[0m
[93maverage test of epoch 0: loss -0.80164 acc 0.65789 roc_auc 0.15385 prc_auc 0.49597[0m
[92maverage training of epoch 1: loss -1.14402 acc 0.66667 roc_auc 0.36340 prc_auc 0.56835[0m
[93maverage test of epoch 1: loss -1.47047 acc 0.65789 roc_auc 0.15077 prc_auc 0.49502[0m
[92maverage training of epoch 2: loss -1.88567 acc 0.66667 roc_auc 0.34240 prc_auc 0.55660[0m
[93maverage test of epoch 2: loss -2.36954 acc 0.65789 roc_auc 0.12923 prc_auc 0.48869[0m
[92maverage training of epoch 3: loss -2.81016 acc 0.66667 roc_auc 0.41680 prc_auc 0.60583[0m
[93maverage test of epoch 3: loss -3.23144 acc 0.65789 roc_auc 0.20308 prc_auc 0.53775[0m
[92maverage training of epoch 4: loss -3.57902 acc 0.66667 roc_auc 0.42460 prc_auc 0.61532[0m
[93maverage test of epoch 4: loss -3.88818 acc 0.65789 roc_auc 0.22462 prc_auc 0.56821[0m
[92maverage training of epoch 5: loss -4.15818 acc 0.66667 roc_auc 0.42480 prc_auc 0.61543[0m
[93maverage test of epoch 5: loss -4.40398 acc 0.65789 roc_auc 0.29846 prc_auc 0.63441[0m
[92maverage training of epoch 6: loss -4.63746 acc 0.66667 roc_auc 0.41860 prc_auc 0.60435[0m
[93maverage test of epoch 6: loss -4.84491 acc 0.65789 roc_auc 0.42769 prc_auc 0.72351[0m
[92maverage training of epoch 7: loss -5.05755 acc 0.66667 roc_auc 0.42080 prc_auc 0.60818[0m
[93maverage test of epoch 7: loss -5.24092 acc 0.65789 roc_auc 0.76923 prc_auc 0.90248[0m
[92maverage training of epoch 8: loss -5.44206 acc 0.66667 roc_auc 0.42750 prc_auc 0.61471[0m
[93maverage test of epoch 8: loss -5.61073 acc 0.65789 roc_auc 0.91231 prc_auc 0.95144[0m
[92maverage training of epoch 9: loss -5.80625 acc 0.66667 roc_auc 0.43080 prc_auc 0.62547[0m
[93maverage test of epoch 9: loss -5.96628 acc 0.65789 roc_auc 0.90462 prc_auc 0.94549[0m
[92maverage training of epoch 10: loss -6.15984 acc 0.66667 roc_auc 0.43560 prc_auc 0.63299[0m
[93maverage test of epoch 10: loss -6.31502 acc 0.65789 roc_auc 0.90462 prc_auc 0.94573[0m
[92maverage training of epoch 11: loss -6.50882 acc 0.66667 roc_auc 0.43530 prc_auc 0.63357[0m
[93maverage test of epoch 11: loss -6.66158 acc 0.65789 roc_auc 0.90769 prc_auc 0.94743[0m
[92maverage training of epoch 12: loss -6.85679 acc 0.66667 roc_auc 0.42980 prc_auc 0.62475[0m
[93maverage test of epoch 12: loss -7.00855 acc 0.65789 roc_auc 0.90769 prc_auc 0.94708[0m
[92maverage training of epoch 13: loss -7.20521 acc 0.66667 roc_auc 0.42230 prc_auc 0.60426[0m
[93maverage test of epoch 13: loss -7.35614 acc 0.65789 roc_auc 0.91385 prc_auc 0.94584[0m
[92maverage training of epoch 14: loss -7.55325 acc 0.66667 roc_auc 0.41500 prc_auc 0.59859[0m
[93maverage test of epoch 14: loss -7.70250 acc 0.65789 roc_auc 0.84154 prc_auc 0.92488[0m
[92maverage training of epoch 15: loss -7.89878 acc 0.66667 roc_auc 0.41320 prc_auc 0.59588[0m
[93maverage test of epoch 15: loss -8.04521 acc 0.65789 roc_auc 0.80154 prc_auc 0.90321[0m
[92maverage training of epoch 16: loss -8.23981 acc 0.66667 roc_auc 0.41200 prc_auc 0.59414[0m
[93maverage test of epoch 16: loss -8.38273 acc 0.65789 roc_auc 0.67077 prc_auc 0.83413[0m
[92maverage training of epoch 17: loss -8.57545 acc 0.66667 roc_auc 0.41320 prc_auc 0.59493[0m
[93maverage test of epoch 17: loss -8.71470 acc 0.65789 roc_auc 0.47692 prc_auc 0.73906[0m
[92maverage training of epoch 18: loss -8.90572 acc 0.66667 roc_auc 0.41220 prc_auc 0.59260[0m
[93maverage test of epoch 18: loss -9.04150 acc 0.65789 roc_auc 0.38615 prc_auc 0.68606[0m
[92maverage training of epoch 19: loss -9.23118 acc 0.66667 roc_auc 0.41450 prc_auc 0.59395[0m
[93maverage test of epoch 19: loss -9.36380 acc 0.65789 roc_auc 0.36615 prc_auc 0.66089[0m
[92maverage training of epoch 20: loss -9.55250 acc 0.66667 roc_auc 0.41470 prc_auc 0.59387[0m
[93maverage test of epoch 20: loss -9.68228 acc 0.65789 roc_auc 0.27231 prc_auc 0.55020[0m
[92maverage training of epoch 21: loss -9.87034 acc 0.66667 roc_auc 0.41540 prc_auc 0.59437[0m
[93maverage test of epoch 21: loss -9.99760 acc 0.65789 roc_auc 0.22000 prc_auc 0.55497[0m
[92maverage training of epoch 22: loss -10.18528 acc 0.66667 roc_auc 0.41680 prc_auc 0.59753[0m
[93maverage test of epoch 22: loss -10.31027 acc 0.65789 roc_auc 0.22000 prc_auc 0.55650[0m
[92maverage training of epoch 23: loss -10.49779 acc 0.66667 roc_auc 0.41720 prc_auc 0.59917[0m
[93maverage test of epoch 23: loss -10.62073 acc 0.65789 roc_auc 0.24308 prc_auc 0.54440[0m
[92maverage training of epoch 24: loss -10.80827 acc 0.66667 roc_auc 0.41800 prc_auc 0.60047[0m
[93maverage test of epoch 24: loss -10.92934 acc 0.65789 roc_auc 0.27538 prc_auc 0.56020[0m
[92maverage training of epoch 25: loss -11.11704 acc 0.66667 roc_auc 0.41950 prc_auc 0.60358[0m
[93maverage test of epoch 25: loss -11.23640 acc 0.65789 roc_auc 0.27385 prc_auc 0.55932[0m
[92maverage training of epoch 26: loss -11.42437 acc 0.66667 roc_auc 0.41940 prc_auc 0.60346[0m
[93maverage test of epoch 26: loss -11.54214 acc 0.65789 roc_auc 0.36154 prc_auc 0.62357[0m
[92maverage training of epoch 27: loss -11.73048 acc 0.66667 roc_auc 0.41940 prc_auc 0.60346[0m
[93maverage test of epoch 27: loss -11.84676 acc 0.65789 roc_auc 0.37385 prc_auc 0.62872[0m
[92maverage training of epoch 28: loss -12.03554 acc 0.66667 roc_auc 0.42020 prc_auc 0.60518[0m
[93maverage test of epoch 28: loss -12.15043 acc 0.65789 roc_auc 0.39077 prc_auc 0.63827[0m
[92maverage training of epoch 29: loss -12.33971 acc 0.66667 roc_auc 0.42040 prc_auc 0.60559[0m
[93maverage test of epoch 29: loss -12.45328 acc 0.65789 roc_auc 0.46000 prc_auc 0.65467[0m
[92maverage training of epoch 30: loss -12.64312 acc 0.66667 roc_auc 0.42050 prc_auc 0.60521[0m
[93maverage test of epoch 30: loss -12.75543 acc 0.65789 roc_auc 0.48000 prc_auc 0.66180[0m
[92maverage training of epoch 31: loss -12.94587 acc 0.66667 roc_auc 0.42030 prc_auc 0.60491[0m
[93maverage test of epoch 31: loss -13.05698 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 32: loss -13.24806 acc 0.66667 roc_auc 0.42040 prc_auc 0.60530[0m
[93maverage test of epoch 32: loss -13.35800 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 33: loss -13.54975 acc 0.66667 roc_auc 0.42040 prc_auc 0.60495[0m
[93maverage test of epoch 33: loss -13.65858 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 34: loss -13.85102 acc 0.66667 roc_auc 0.42020 prc_auc 0.60491[0m
[93maverage test of epoch 34: loss -13.95877 acc 0.65789 roc_auc 0.56000 prc_auc 0.69895[0m
[92maverage training of epoch 35: loss -14.15193 acc 0.66667 roc_auc 0.42030 prc_auc 0.60495[0m
[93maverage test of epoch 35: loss -14.25862 acc 0.65789 roc_auc 0.37231 prc_auc 0.65385[0m
[92maverage training of epoch 36: loss -14.45251 acc 0.66667 roc_auc 0.42040 prc_auc 0.60491[0m
[93maverage test of epoch 36: loss -14.55817 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 37: loss -14.75281 acc 0.66667 roc_auc 0.42040 prc_auc 0.60491[0m
[93maverage test of epoch 37: loss -14.85747 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 38: loss -15.05288 acc 0.66667 roc_auc 0.42040 prc_auc 0.60491[0m
[93maverage test of epoch 38: loss -15.15654 acc 0.65789 roc_auc 0.39231 prc_auc 0.65368[0m
[92maverage training of epoch 39: loss -15.35273 acc 0.66667 roc_auc 0.42050 prc_auc 0.60495[0m
[93maverage test of epoch 39: loss -15.45542 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 40: loss -15.65239 acc 0.66667 roc_auc 0.42030 prc_auc 0.60491[0m
[93maverage test of epoch 40: loss -15.75413 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 41: loss -15.95189 acc 0.66667 roc_auc 0.42050 prc_auc 0.60536[0m
[93maverage test of epoch 41: loss -16.05268 acc 0.65789 roc_auc 0.25692 prc_auc 0.68526[0m
[92maverage training of epoch 42: loss -16.25125 acc 0.66667 roc_auc 0.42040 prc_auc 0.60495[0m
[93maverage test of epoch 42: loss -16.35111 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 43: loss -16.55049 acc 0.66667 roc_auc 0.42040 prc_auc 0.60454[0m
[93maverage test of epoch 43: loss -16.64942 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 44: loss -16.84961 acc 0.66667 roc_auc 0.42040 prc_auc 0.60500[0m
[93maverage test of epoch 44: loss -16.94763 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 45: loss -17.14864 acc 0.66667 roc_auc 0.42050 prc_auc 0.60492[0m
[93maverage test of epoch 45: loss -17.24575 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 46: loss -17.44759 acc 0.66667 roc_auc 0.42040 prc_auc 0.60478[0m
[93maverage test of epoch 46: loss -17.54380 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 47: loss -17.74646 acc 0.66667 roc_auc 0.42050 prc_auc 0.60456[0m
[93maverage test of epoch 47: loss -17.84177 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 48: loss -18.04527 acc 0.66667 roc_auc 0.42040 prc_auc 0.60486[0m
[93maverage test of epoch 48: loss -18.13969 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 49: loss -18.34401 acc 0.66667 roc_auc 0.42070 prc_auc 0.60459[0m
[93maverage test of epoch 49: loss -18.43755 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.55397 acc 0.66667 roc_auc 0.43320 prc_auc 0.63537[0m
[93maverage test of epoch 0: loss -1.06440 acc 0.65789 roc_auc 0.46769 prc_auc 0.74855[0m
[92maverage training of epoch 1: loss -1.51775 acc 0.66667 roc_auc 0.42600 prc_auc 0.63077[0m
[93maverage test of epoch 1: loss -1.94717 acc 0.65789 roc_auc 0.86462 prc_auc 0.94578[0m
[92maverage training of epoch 2: loss -2.42141 acc 0.66667 roc_auc 0.43360 prc_auc 0.63665[0m
[93maverage test of epoch 2: loss -2.95069 acc 0.65789 roc_auc 0.95692 prc_auc 0.98124[0m
[92maverage training of epoch 3: loss -3.62598 acc 0.66667 roc_auc 0.44680 prc_auc 0.64967[0m
[93maverage test of epoch 3: loss -4.33644 acc 0.65789 roc_auc 0.95077 prc_auc 0.97751[0m
[92maverage training of epoch 4: loss -4.92609 acc 0.66667 roc_auc 0.43740 prc_auc 0.63649[0m
[93maverage test of epoch 4: loss -5.36830 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 5: loss -5.69559 acc 0.66667 roc_auc 0.40880 prc_auc 0.60954[0m
[93maverage test of epoch 5: loss -5.95315 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 6: loss -6.20948 acc 0.66667 roc_auc 0.40280 prc_auc 0.60805[0m
[93maverage test of epoch 6: loss -6.41370 acc 0.65789 roc_auc 0.95538 prc_auc 0.97946[0m
[92maverage training of epoch 7: loss -6.64168 acc 0.66667 roc_auc 0.39700 prc_auc 0.60293[0m
[93maverage test of epoch 7: loss -6.82080 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 8: loss -7.03371 acc 0.66667 roc_auc 0.39160 prc_auc 0.60164[0m
[93maverage test of epoch 8: loss -7.19806 acc 0.65789 roc_auc 0.95231 prc_auc 0.97791[0m
[92maverage training of epoch 9: loss -7.40188 acc 0.66667 roc_auc 0.38930 prc_auc 0.60056[0m
[93maverage test of epoch 9: loss -7.55642 acc 0.65789 roc_auc 0.94923 prc_auc 0.97661[0m
[92maverage training of epoch 10: loss -7.75435 acc 0.66667 roc_auc 0.38780 prc_auc 0.60312[0m
[93maverage test of epoch 10: loss -7.90184 acc 0.65789 roc_auc 0.95385 prc_auc 0.97808[0m
[92maverage training of epoch 11: loss -8.09579 acc 0.66667 roc_auc 0.38680 prc_auc 0.60277[0m
[93maverage test of epoch 11: loss -8.23793 acc 0.65789 roc_auc 0.95231 prc_auc 0.97697[0m
[92maverage training of epoch 12: loss -8.42911 acc 0.66667 roc_auc 0.38640 prc_auc 0.60237[0m
[93maverage test of epoch 12: loss -8.56701 acc 0.65789 roc_auc 0.95231 prc_auc 0.97697[0m
[92maverage training of epoch 13: loss -8.75626 acc 0.66667 roc_auc 0.38560 prc_auc 0.60203[0m
[93maverage test of epoch 13: loss -8.89069 acc 0.65789 roc_auc 0.95231 prc_auc 0.97697[0m
[92maverage training of epoch 14: loss -9.07859 acc 0.66667 roc_auc 0.38540 prc_auc 0.60088[0m
[93maverage test of epoch 14: loss -9.21009 acc 0.65789 roc_auc 0.95077 prc_auc 0.97369[0m
[92maverage training of epoch 15: loss -9.39708 acc 0.66667 roc_auc 0.38520 prc_auc 0.60023[0m
[93maverage test of epoch 15: loss -9.52606 acc 0.65789 roc_auc 0.94923 prc_auc 0.97298[0m
[92maverage training of epoch 16: loss -9.71246 acc 0.66667 roc_auc 0.38440 prc_auc 0.59407[0m
[93maverage test of epoch 16: loss -9.83924 acc 0.65789 roc_auc 0.94923 prc_auc 0.97298[0m
[92maverage training of epoch 17: loss -10.02530 acc 0.66667 roc_auc 0.38380 prc_auc 0.59177[0m
[93maverage test of epoch 17: loss -10.15011 acc 0.65789 roc_auc 0.95538 prc_auc 0.97298[0m
[92maverage training of epoch 18: loss -10.33604 acc 0.66667 roc_auc 0.38350 prc_auc 0.59000[0m
[93maverage test of epoch 18: loss -10.45906 acc 0.65789 roc_auc 0.96769 prc_auc 0.97697[0m
[92maverage training of epoch 19: loss -10.64501 acc 0.66667 roc_auc 0.38330 prc_auc 0.58956[0m
[93maverage test of epoch 19: loss -10.76641 acc 0.65789 roc_auc 0.95385 prc_auc 0.97298[0m
[92maverage training of epoch 20: loss -10.95251 acc 0.66667 roc_auc 0.38300 prc_auc 0.58879[0m
[93maverage test of epoch 20: loss -11.07240 acc 0.65789 roc_auc 0.96154 prc_auc 0.97298[0m
[92maverage training of epoch 21: loss -11.25875 acc 0.66667 roc_auc 0.38140 prc_auc 0.58706[0m
[93maverage test of epoch 21: loss -11.37724 acc 0.65789 roc_auc 0.93692 prc_auc 0.95922[0m
[92maverage training of epoch 22: loss -11.56394 acc 0.66667 roc_auc 0.38080 prc_auc 0.58671[0m
[93maverage test of epoch 22: loss -11.68110 acc 0.65789 roc_auc 0.90769 prc_auc 0.93514[0m
[92maverage training of epoch 23: loss -11.86821 acc 0.66667 roc_auc 0.38070 prc_auc 0.58628[0m
[93maverage test of epoch 23: loss -11.98412 acc 0.65789 roc_auc 0.86000 prc_auc 0.90421[0m
[92maverage training of epoch 24: loss -12.17171 acc 0.66667 roc_auc 0.38040 prc_auc 0.58650[0m
[93maverage test of epoch 24: loss -12.28642 acc 0.65789 roc_auc 0.83077 prc_auc 0.87778[0m
[92maverage training of epoch 25: loss -12.47453 acc 0.66667 roc_auc 0.38050 prc_auc 0.58161[0m
[93maverage test of epoch 25: loss -12.58810 acc 0.65789 roc_auc 0.86000 prc_auc 0.90421[0m
[92maverage training of epoch 26: loss -12.77678 acc 0.66667 roc_auc 0.38050 prc_auc 0.58161[0m
[93maverage test of epoch 26: loss -12.88925 acc 0.65789 roc_auc 0.65385 prc_auc 0.73529[0m
[92maverage training of epoch 27: loss -13.07853 acc 0.66667 roc_auc 0.37950 prc_auc 0.57763[0m
[93maverage test of epoch 27: loss -13.18993 acc 0.65789 roc_auc 0.66000 prc_auc 0.76737[0m
[92maverage training of epoch 28: loss -13.37985 acc 0.66667 roc_auc 0.37900 prc_auc 0.57696[0m
[93maverage test of epoch 28: loss -13.49020 acc 0.65789 roc_auc 0.82615 prc_auc 0.84917[0m
[92maverage training of epoch 29: loss -13.68080 acc 0.66667 roc_auc 0.37900 prc_auc 0.57727[0m
[93maverage test of epoch 29: loss -13.79013 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -13.98142 acc 0.66667 roc_auc 0.37870 prc_auc 0.57646[0m
[93maverage test of epoch 30: loss -14.08976 acc 0.65789 roc_auc 0.74000 prc_auc 0.82211[0m
[92maverage training of epoch 31: loss -14.28175 acc 0.66667 roc_auc 0.37860 prc_auc 0.57646[0m
[93maverage test of epoch 31: loss -14.38912 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -14.58184 acc 0.66667 roc_auc 0.37840 prc_auc 0.57642[0m
[93maverage test of epoch 32: loss -14.68824 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -14.88171 acc 0.66667 roc_auc 0.37820 prc_auc 0.57603[0m
[93maverage test of epoch 33: loss -14.98717 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -15.18138 acc 0.66667 roc_auc 0.37810 prc_auc 0.57568[0m
[93maverage test of epoch 34: loss -15.28591 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -15.48090 acc 0.66667 roc_auc 0.37750 prc_auc 0.57508[0m
[93maverage test of epoch 35: loss -15.58450 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -15.78026 acc 0.66667 roc_auc 0.37730 prc_auc 0.57519[0m
[93maverage test of epoch 36: loss -15.88296 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -16.07951 acc 0.66667 roc_auc 0.37720 prc_auc 0.57475[0m
[93maverage test of epoch 37: loss -16.18129 acc 0.65789 roc_auc 0.52000 prc_auc 0.67158[0m
[92maverage training of epoch 38: loss -16.37863 acc 0.66667 roc_auc 0.37710 prc_auc 0.57495[0m
[93maverage test of epoch 38: loss -16.47952 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -16.67766 acc 0.66667 roc_auc 0.37670 prc_auc 0.57459[0m
[93maverage test of epoch 39: loss -16.77765 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -16.97660 acc 0.66667 roc_auc 0.37700 prc_auc 0.57450[0m
[93maverage test of epoch 40: loss -17.07571 acc 0.65789 roc_auc 0.66769 prc_auc 0.74769[0m
[92maverage training of epoch 41: loss -17.27547 acc 0.66667 roc_auc 0.37680 prc_auc 0.57509[0m
[93maverage test of epoch 41: loss -17.37369 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -17.57427 acc 0.66667 roc_auc 0.37680 prc_auc 0.57516[0m
[93maverage test of epoch 42: loss -17.67161 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -17.87301 acc 0.66667 roc_auc 0.37680 prc_auc 0.57472[0m
[93maverage test of epoch 43: loss -17.96948 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -18.17169 acc 0.66667 roc_auc 0.37710 prc_auc 0.57503[0m
[93maverage test of epoch 44: loss -18.26729 acc 0.65789 roc_auc 0.38000 prc_auc 0.60914[0m
[92maverage training of epoch 45: loss -18.47034 acc 0.66667 roc_auc 0.37660 prc_auc 0.57502[0m
[93maverage test of epoch 45: loss -18.56506 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -18.76894 acc 0.66667 roc_auc 0.37660 prc_auc 0.57568[0m
[93maverage test of epoch 46: loss -18.86279 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -19.06750 acc 0.66667 roc_auc 0.37700 prc_auc 0.57536[0m
[93maverage test of epoch 47: loss -19.16049 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -19.36603 acc 0.66667 roc_auc 0.37700 prc_auc 0.57501[0m
[93maverage test of epoch 48: loss -19.45816 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -19.66454 acc 0.66667 roc_auc 0.37670 prc_auc 0.57557[0m
[93maverage test of epoch 49: loss -19.75580 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.44623 acc 0.66225 roc_auc 0.42137 prc_auc 0.61139[0m
[93maverage test of epoch 0: loss -0.98321 acc 0.67568 roc_auc 0.49333 prc_auc 0.78338[0m
[92maverage training of epoch 1: loss -1.49600 acc 0.66225 roc_auc 0.41000 prc_auc 0.61669[0m
[93maverage test of epoch 1: loss -1.95574 acc 0.67568 roc_auc 0.83333 prc_auc 0.91580[0m
[92maverage training of epoch 2: loss -2.20691 acc 0.66225 roc_auc 0.40451 prc_auc 0.60051[0m
[93maverage test of epoch 2: loss -2.51610 acc 0.67568 roc_auc 0.83333 prc_auc 0.91580[0m
[92maverage training of epoch 3: loss -2.70428 acc 0.66225 roc_auc 0.42216 prc_auc 0.60809[0m
[93maverage test of epoch 3: loss -2.97580 acc 0.67568 roc_auc 0.87000 prc_auc 0.93133[0m
[92maverage training of epoch 4: loss -3.13735 acc 0.66225 roc_auc 0.42814 prc_auc 0.62048[0m
[93maverage test of epoch 4: loss -3.39687 acc 0.67568 roc_auc 0.86833 prc_auc 0.92994[0m
[92maverage training of epoch 5: loss -3.54440 acc 0.66225 roc_auc 0.43275 prc_auc 0.62193[0m
[93maverage test of epoch 5: loss -3.80001 acc 0.67568 roc_auc 0.86833 prc_auc 0.93137[0m
[92maverage training of epoch 6: loss -3.93794 acc 0.66225 roc_auc 0.43020 prc_auc 0.61808[0m
[93maverage test of epoch 6: loss -4.19174 acc 0.67568 roc_auc 0.86667 prc_auc 0.92904[0m
[92maverage training of epoch 7: loss -4.32173 acc 0.66225 roc_auc 0.42765 prc_auc 0.61632[0m
[93maverage test of epoch 7: loss -4.57387 acc 0.67568 roc_auc 0.86500 prc_auc 0.92939[0m
[92maverage training of epoch 8: loss -4.69665 acc 0.66225 roc_auc 0.42059 prc_auc 0.61096[0m
[93maverage test of epoch 8: loss -4.94681 acc 0.67568 roc_auc 0.86667 prc_auc 0.92965[0m
[92maverage training of epoch 9: loss -5.06288 acc 0.66225 roc_auc 0.41627 prc_auc 0.60770[0m
[93maverage test of epoch 9: loss -5.31082 acc 0.67568 roc_auc 0.86667 prc_auc 0.92991[0m
[92maverage training of epoch 10: loss -5.42069 acc 0.66225 roc_auc 0.40863 prc_auc 0.60077[0m
[93maverage test of epoch 10: loss -5.66643 acc 0.67568 roc_auc 0.86833 prc_auc 0.93054[0m
[92maverage training of epoch 11: loss -5.77064 acc 0.66225 roc_auc 0.40402 prc_auc 0.59629[0m
[93maverage test of epoch 11: loss -6.01441 acc 0.67568 roc_auc 0.86667 prc_auc 0.93154[0m
[92maverage training of epoch 12: loss -6.11355 acc 0.66225 roc_auc 0.39882 prc_auc 0.59207[0m
[93maverage test of epoch 12: loss -6.35566 acc 0.67568 roc_auc 0.86833 prc_auc 0.92821[0m
[92maverage training of epoch 13: loss -6.45028 acc 0.66225 roc_auc 0.39667 prc_auc 0.59100[0m
[93maverage test of epoch 13: loss -6.69111 acc 0.67568 roc_auc 0.86000 prc_auc 0.92570[0m
[92maverage training of epoch 14: loss -6.78170 acc 0.66225 roc_auc 0.39373 prc_auc 0.58865[0m
[93maverage test of epoch 14: loss -7.02159 acc 0.67568 roc_auc 0.86500 prc_auc 0.92376[0m
[92maverage training of epoch 15: loss -7.10859 acc 0.66225 roc_auc 0.39245 prc_auc 0.58835[0m
[93maverage test of epoch 15: loss -7.34785 acc 0.67568 roc_auc 0.85833 prc_auc 0.91941[0m
[92maverage training of epoch 16: loss -7.43162 acc 0.66225 roc_auc 0.38980 prc_auc 0.58657[0m
[93maverage test of epoch 16: loss -7.67054 acc 0.67568 roc_auc 0.86000 prc_auc 0.91777[0m
[92maverage training of epoch 17: loss -7.75138 acc 0.66225 roc_auc 0.38706 prc_auc 0.58548[0m
[93maverage test of epoch 17: loss -7.99019 acc 0.67568 roc_auc 0.87167 prc_auc 0.91867[0m
[92maverage training of epoch 18: loss -8.06836 acc 0.66225 roc_auc 0.38647 prc_auc 0.58527[0m
[93maverage test of epoch 18: loss -8.30726 acc 0.67568 roc_auc 0.86833 prc_auc 0.92296[0m
[92maverage training of epoch 19: loss -8.38297 acc 0.66225 roc_auc 0.38520 prc_auc 0.58387[0m
[93maverage test of epoch 19: loss -8.62213 acc 0.67568 roc_auc 0.84667 prc_auc 0.89590[0m
[92maverage training of epoch 20: loss -8.69556 acc 0.66225 roc_auc 0.38529 prc_auc 0.58403[0m
[93maverage test of epoch 20: loss -8.93512 acc 0.67568 roc_auc 0.82500 prc_auc 0.87120[0m
[92maverage training of epoch 21: loss -9.00642 acc 0.66225 roc_auc 0.38480 prc_auc 0.58400[0m
[93maverage test of epoch 21: loss -9.24652 acc 0.67568 roc_auc 0.87000 prc_auc 0.90108[0m
[92maverage training of epoch 22: loss -9.31580 acc 0.66225 roc_auc 0.38412 prc_auc 0.58385[0m
[93maverage test of epoch 22: loss -9.55653 acc 0.67568 roc_auc 0.66000 prc_auc 0.77268[0m
[92maverage training of epoch 23: loss -9.62391 acc 0.66225 roc_auc 0.38363 prc_auc 0.58357[0m
[93maverage test of epoch 23: loss -9.86536 acc 0.67568 roc_auc 0.84000 prc_auc 0.87252[0m
[92maverage training of epoch 24: loss -9.93092 acc 0.66225 roc_auc 0.38363 prc_auc 0.58337[0m
[93maverage test of epoch 24: loss -10.17317 acc 0.67568 roc_auc 0.70000 prc_auc 0.79751[0m
[92maverage training of epoch 25: loss -10.23699 acc 0.66225 roc_auc 0.38343 prc_auc 0.58361[0m
[93maverage test of epoch 25: loss -10.48009 acc 0.67568 roc_auc 0.68000 prc_auc 0.78032[0m
[92maverage training of epoch 26: loss -10.54224 acc 0.66225 roc_auc 0.38294 prc_auc 0.58257[0m
[93maverage test of epoch 26: loss -10.78625 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 27: loss -10.84678 acc 0.66225 roc_auc 0.38235 prc_auc 0.58319[0m
[93maverage test of epoch 27: loss -11.09175 acc 0.67568 roc_auc 0.60000 prc_auc 0.74054[0m
[92maverage training of epoch 28: loss -11.15070 acc 0.66225 roc_auc 0.38206 prc_auc 0.58315[0m
[93maverage test of epoch 28: loss -11.39668 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 29: loss -11.45409 acc 0.66225 roc_auc 0.38235 prc_auc 0.58384[0m
[93maverage test of epoch 29: loss -11.70110 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 30: loss -11.75701 acc 0.66225 roc_auc 0.38147 prc_auc 0.57530[0m
[93maverage test of epoch 30: loss -12.00509 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 31: loss -12.05953 acc 0.66225 roc_auc 0.38176 prc_auc 0.57627[0m
[93maverage test of epoch 31: loss -12.30870 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 32: loss -12.36169 acc 0.66225 roc_auc 0.38078 prc_auc 0.57393[0m
[93maverage test of epoch 32: loss -12.61198 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 33: loss -12.66354 acc 0.66225 roc_auc 0.37990 prc_auc 0.57196[0m
[93maverage test of epoch 33: loss -12.91497 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 34: loss -12.96513 acc 0.66225 roc_auc 0.37922 prc_auc 0.57232[0m
[93maverage test of epoch 34: loss -13.21771 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 35: loss -13.26648 acc 0.66225 roc_auc 0.37892 prc_auc 0.57197[0m
[93maverage test of epoch 35: loss -13.52023 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 36: loss -13.56762 acc 0.66225 roc_auc 0.37892 prc_auc 0.57225[0m
[93maverage test of epoch 36: loss -13.82255 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 37: loss -13.86858 acc 0.66225 roc_auc 0.37794 prc_auc 0.57117[0m
[93maverage test of epoch 37: loss -14.12470 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 38: loss -14.16938 acc 0.66225 roc_auc 0.37784 prc_auc 0.57132[0m
[93maverage test of epoch 38: loss -14.42670 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 39: loss -14.47004 acc 0.66225 roc_auc 0.37784 prc_auc 0.57198[0m
[93maverage test of epoch 39: loss -14.72857 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 40: loss -14.77057 acc 0.66225 roc_auc 0.37686 prc_auc 0.57151[0m
[93maverage test of epoch 40: loss -15.03033 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 41: loss -15.07100 acc 0.66225 roc_auc 0.37706 prc_auc 0.57270[0m
[93maverage test of epoch 41: loss -15.33199 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 42: loss -15.37134 acc 0.66225 roc_auc 0.37637 prc_auc 0.57124[0m
[93maverage test of epoch 42: loss -15.63355 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 43: loss -15.67159 acc 0.66225 roc_auc 0.37578 prc_auc 0.57066[0m
[93maverage test of epoch 43: loss -15.93504 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 44: loss -15.97177 acc 0.66225 roc_auc 0.37608 prc_auc 0.57052[0m
[93maverage test of epoch 44: loss -16.23646 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 45: loss -16.27188 acc 0.66225 roc_auc 0.37608 prc_auc 0.57309[0m
[93maverage test of epoch 45: loss -16.53782 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 46: loss -16.57194 acc 0.66225 roc_auc 0.37608 prc_auc 0.57106[0m
[93maverage test of epoch 46: loss -16.83912 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 47: loss -16.87194 acc 0.66225 roc_auc 0.37578 prc_auc 0.57029[0m
[93maverage test of epoch 47: loss -17.14037 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 48: loss -17.17190 acc 0.66225 roc_auc 0.37578 prc_auc 0.57292[0m
[93maverage test of epoch 48: loss -17.44159 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 49: loss -17.47182 acc 0.66225 roc_auc 0.37549 prc_auc 0.57015[0m
[93maverage test of epoch 49: loss -17.74277 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.84013 acc 0.33113 roc_auc 0.37353 prc_auc 0.57907[0m
[93maverage test of epoch 0: loss -1.19592 acc 0.67568 roc_auc 0.56667 prc_auc 0.82206[0m
[92maverage training of epoch 1: loss -1.59353 acc 0.65563 roc_auc 0.42490 prc_auc 0.62996[0m
[93maverage test of epoch 1: loss -2.12334 acc 0.67568 roc_auc 0.93000 prc_auc 0.97316[0m
[92maverage training of epoch 2: loss -2.70960 acc 0.66225 roc_auc 0.43588 prc_auc 0.64110[0m
[93maverage test of epoch 2: loss -3.28193 acc 0.67568 roc_auc 0.94333 prc_auc 0.97669[0m
[92maverage training of epoch 3: loss -3.58994 acc 0.66225 roc_auc 0.44392 prc_auc 0.64852[0m
[93maverage test of epoch 3: loss -3.93309 acc 0.67568 roc_auc 0.95000 prc_auc 0.97877[0m
[92maverage training of epoch 4: loss -4.14030 acc 0.66225 roc_auc 0.44765 prc_auc 0.65417[0m
[93maverage test of epoch 4: loss -4.42504 acc 0.67568 roc_auc 0.95000 prc_auc 0.97888[0m
[92maverage training of epoch 5: loss -4.62112 acc 0.66225 roc_auc 0.44451 prc_auc 0.65330[0m
[93maverage test of epoch 5: loss -4.93033 acc 0.67568 roc_auc 0.95000 prc_auc 0.97888[0m
[92maverage training of epoch 6: loss -5.12944 acc 0.66225 roc_auc 0.45725 prc_auc 0.66094[0m
[93maverage test of epoch 6: loss -5.42351 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0mUsing backend: pytorch
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))

[92maverage training of epoch 7: loss -5.58332 acc 0.66225 roc_auc 0.43765 prc_auc 0.64187[0m
[93maverage test of epoch 7: loss -5.85188 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 8: loss -5.99058 acc 0.66225 roc_auc 0.41853 prc_auc 0.62417[0m
[93maverage test of epoch 8: loss -6.24597 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 9: loss -6.37075 acc 0.66225 roc_auc 0.40284 prc_auc 0.61254[0m
[93maverage test of epoch 9: loss -6.61819 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 10: loss -6.73297 acc 0.66225 roc_auc 0.39245 prc_auc 0.60752[0m
[93maverage test of epoch 10: loss -6.97534 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 11: loss -7.08249 acc 0.66225 roc_auc 0.38961 prc_auc 0.60662[0m
[93maverage test of epoch 11: loss -7.32157 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 12: loss -7.42265 acc 0.66225 roc_auc 0.38490 prc_auc 0.60060[0m
[93maverage test of epoch 12: loss -7.65958 acc 0.67568 roc_auc 0.92500 prc_auc 0.96822[0m
[92maverage training of epoch 13: loss -7.75566 acc 0.66225 roc_auc 0.38108 prc_auc 0.59405[0m
[93maverage test of epoch 13: loss -7.99123 acc 0.67568 roc_auc 0.93000 prc_auc 0.97294[0m
[92maverage training of epoch 14: loss -8.08309 acc 0.66225 roc_auc 0.38069 prc_auc 0.59378[0m
[93maverage test of epoch 14: loss -8.31786 acc 0.67568 roc_auc 0.92667 prc_auc 0.96988[0m
[92maverage training of epoch 15: loss -8.40606 acc 0.66225 roc_auc 0.37980 prc_auc 0.59121[0m
[93maverage test of epoch 15: loss -8.64045 acc 0.67568 roc_auc 0.92500 prc_auc 0.96853[0m
[92maverage training of epoch 16: loss -8.72543 acc 0.66225 roc_auc 0.37961 prc_auc 0.59063[0m
[93maverage test of epoch 16: loss -8.95975 acc 0.67568 roc_auc 0.93333 prc_auc 0.97135[0m
[92maverage training of epoch 17: loss -9.04184 acc 0.66225 roc_auc 0.37922 prc_auc 0.59228[0m
[93maverage test of epoch 17: loss -9.27633 acc 0.67568 roc_auc 0.93000 prc_auc 0.96875[0m
[92maverage training of epoch 18: loss -9.35582 acc 0.66225 roc_auc 0.37961 prc_auc 0.59193[0m
[93maverage test of epoch 18: loss -9.59066 acc 0.67568 roc_auc 0.93000 prc_auc 0.96801[0m
[92maverage training of epoch 19: loss -9.66775 acc 0.66225 roc_auc 0.37902 prc_auc 0.59119[0m
[93maverage test of epoch 19: loss -9.90310 acc 0.67568 roc_auc 0.92000 prc_auc 0.96028[0m
[92maverage training of epoch 20: loss -9.97796 acc 0.66225 roc_auc 0.37892 prc_auc 0.59099[0m
[93maverage test of epoch 20: loss -10.21395 acc 0.67568 roc_auc 0.92333 prc_auc 0.95098[0m
[92maverage training of epoch 21: loss -10.28673 acc 0.66225 roc_auc 0.37882 prc_auc 0.59080[0m
[93maverage test of epoch 21: loss -10.52345 acc 0.67568 roc_auc 0.94000 prc_auc 0.96632[0m
[92maverage training of epoch 22: loss -10.59426 acc 0.66225 roc_auc 0.37863 prc_auc 0.59085[0m
[93maverage test of epoch 22: loss -10.83180 acc 0.67568 roc_auc 0.82667 prc_auc 0.87924[0m
[92maverage training of epoch 23: loss -10.90075 acc 0.66225 roc_auc 0.37863 prc_auc 0.59087[0m
[93maverage test of epoch 23: loss -11.13916 acc 0.67568 roc_auc 0.80667 prc_auc 0.84431[0m
[92maverage training of epoch 24: loss -11.20633 acc 0.66225 roc_auc 0.37745 prc_auc 0.58463[0m
[93maverage test of epoch 24: loss -11.44568 acc 0.67568 roc_auc 0.79667 prc_auc 0.83926[0m
[92maverage training of epoch 25: loss -11.51114 acc 0.66225 roc_auc 0.37657 prc_auc 0.58242[0m
[93maverage test of epoch 25: loss -11.75148 acc 0.67568 roc_auc 0.92000 prc_auc 0.94811[0m
[92maverage training of epoch 26: loss -11.81529 acc 0.66225 roc_auc 0.37627 prc_auc 0.58248[0m
[93maverage test of epoch 26: loss -12.05665 acc 0.67568 roc_auc 0.66833 prc_auc 0.75939[0m
[92maverage training of epoch 27: loss -12.11885 acc 0.66225 roc_auc 0.37549 prc_auc 0.57400[0m
[93maverage test of epoch 27: loss -12.36128 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 28: loss -12.42193 acc 0.66225 roc_auc 0.37480 prc_auc 0.57280[0m
[93maverage test of epoch 28: loss -12.66544 acc 0.67568 roc_auc 0.75167 prc_auc 0.80977[0m
[92maverage training of epoch 29: loss -12.72457 acc 0.66225 roc_auc 0.37363 prc_auc 0.57210[0m
[93maverage test of epoch 29: loss -12.96920 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 30: loss -13.02683 acc 0.66225 roc_auc 0.37333 prc_auc 0.57106[0m
[93maverage test of epoch 30: loss -13.27260 acc 0.67568 roc_auc 0.79333 prc_auc 0.83776[0m
[92maverage training of epoch 31: loss -13.32877 acc 0.66225 roc_auc 0.37314 prc_auc 0.57136[0m
[93maverage test of epoch 31: loss -13.57570 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 32: loss -13.63043 acc 0.66225 roc_auc 0.37294 prc_auc 0.57119[0m
[93maverage test of epoch 32: loss -13.87853 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 33: loss -13.93184 acc 0.66225 roc_auc 0.37245 prc_auc 0.57052[0m
[93maverage test of epoch 33: loss -14.18112 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 34: loss -14.23304 acc 0.66225 roc_auc 0.37235 prc_auc 0.57005[0m
[93maverage test of epoch 34: loss -14.48352 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 35: loss -14.53405 acc 0.66225 roc_auc 0.37216 prc_auc 0.57142[0m
[93maverage test of epoch 35: loss -14.78573 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 36: loss -14.83489 acc 0.66225 roc_auc 0.37108 prc_auc 0.56899[0m
[93maverage test of epoch 36: loss -15.08779 acc 0.67568 roc_auc 0.71000 prc_auc 0.78371[0m
[92maverage training of epoch 37: loss -15.13559 acc 0.66225 roc_auc 0.37098 prc_auc 0.56945[0m
[93maverage test of epoch 37: loss -15.38971 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 38: loss -15.43616 acc 0.66225 roc_auc 0.37088 prc_auc 0.57073[0m
[93maverage test of epoch 38: loss -15.69151 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 39: loss -15.73662 acc 0.66225 roc_auc 0.37118 prc_auc 0.56995[0m
[93maverage test of epoch 39: loss -15.99321 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -16.03699 acc 0.66225 roc_auc 0.37059 prc_auc 0.57071[0m
[93maverage test of epoch 40: loss -16.29481 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -16.33726 acc 0.66225 roc_auc 0.36990 prc_auc 0.56980[0m
[93maverage test of epoch 41: loss -16.59633 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -16.63747 acc 0.66225 roc_auc 0.37069 prc_auc 0.57022[0m
[93maverage test of epoch 42: loss -16.89778 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -16.93760 acc 0.66225 roc_auc 0.37029 prc_auc 0.56974[0m
[93maverage test of epoch 43: loss -17.19918 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -17.23769 acc 0.66225 roc_auc 0.37029 prc_auc 0.57005[0m
[93maverage test of epoch 44: loss -17.50051 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -17.53771 acc 0.66225 roc_auc 0.37029 prc_auc 0.57165[0m
[93maverage test of epoch 45: loss -17.80180 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -17.83770 acc 0.66225 roc_auc 0.37000 prc_auc 0.56940[0m
[93maverage test of epoch 46: loss -18.10304 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -18.13764 acc 0.66225 roc_auc 0.36902 prc_auc 0.56969[0m
[93maverage test of epoch 47: loss -18.40424 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -18.43755 acc 0.66225 roc_auc 0.36922 prc_auc 0.57091[0m
[93maverage test of epoch 48: loss -18.70541 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -18.73742 acc 0.66225 roc_auc 0.37039 prc_auc 0.57170[0m
[93maverage test of epoch 49: loss -19.00655 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.0003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.66501 ROC_AUC (avg): 0.47477 PRC_AUC (avg): 0.65586 

Average forward propagation time taken(ms): 2.4888224540317796
Average backward propagation time taken(ms): 0.876185065346377

