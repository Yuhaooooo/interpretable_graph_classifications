# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.0003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-09-19-15/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-09-19-15/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 16,
 'epochs': 100,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 4,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.0003,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 2,
 'num_workers': 8,
 'number_of_mlp_layer': 0,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-18-09-19-15',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 100, 'learning_rate': 0.0003, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss 0.43685 acc 0.66667 roc_auc 0.42640 prc_auc 0.63785[0m
[93maverage test of epoch 0: loss 0.20470 acc 0.65789 roc_auc 0.65846 prc_auc 0.82777[0m
[92maverage training of epoch 1: loss -0.00507 acc 0.66667 roc_auc 0.47560 prc_auc 0.66958[0m
[93maverage test of epoch 1: loss -0.19462 acc 0.65789 roc_auc 0.73231 prc_auc 0.85499[0m
[92maverage training of epoch 2: loss -0.46137 acc 0.66667 roc_auc 0.42880 prc_auc 0.64794[0m
[93maverage test of epoch 2: loss -0.70148 acc 0.65789 roc_auc 0.31077 prc_auc 0.61443[0m
[92maverage training of epoch 3: loss -1.01281 acc 0.66667 roc_auc 0.50220 prc_auc 0.67687[0m
[93maverage test of epoch 3: loss -1.23843 acc 0.65789 roc_auc 0.59385 prc_auc 0.78483[0m
[92maverage training of epoch 4: loss -1.48598 acc 0.66667 roc_auc 0.48360 prc_auc 0.67343[0m
[93maverage test of epoch 4: loss -1.66497 acc 0.65789 roc_auc 0.44308 prc_auc 0.64168[0m
[92maverage training of epoch 5: loss -1.89065 acc 0.66667 roc_auc 0.40860 prc_auc 0.61260[0m
[93maverage test of epoch 5: loss -2.05717 acc 0.65789 roc_auc 0.47692 prc_auc 0.70877[0m
[92maverage training of epoch 6: loss -2.22330 acc 0.66667 roc_auc 0.40580 prc_auc 0.61588[0m
[93maverage test of epoch 6: loss -2.35475 acc 0.65789 roc_auc 0.59077 prc_auc 0.75057[0m
[92maverage training of epoch 7: loss -2.49978 acc 0.66667 roc_auc 0.41670 prc_auc 0.62082[0m
[93maverage test of epoch 7: loss -2.61595 acc 0.65789 roc_auc 0.42769 prc_auc 0.62086[0m
[92maverage training of epoch 8: loss -2.73612 acc 0.66667 roc_auc 0.49590 prc_auc 0.67712[0m
[93maverage test of epoch 8: loss -2.81609 acc 0.65789 roc_auc 0.51077 prc_auc 0.64526[0m
[92maverage training of epoch 9: loss -2.94532 acc 0.66667 roc_auc 0.46160 prc_auc 0.63944[0m
[93maverage test of epoch 9: loss -3.03406 acc 0.65789 roc_auc 0.54769 prc_auc 0.73664[0m
[92maverage training of epoch 10: loss -3.14952 acc 0.66667 roc_auc 0.44480 prc_auc 0.62486[0m
[93maverage test of epoch 10: loss -3.21907 acc 0.65789 roc_auc 0.63692 prc_auc 0.77672[0m
[92maverage training of epoch 11: loss -3.34169 acc 0.66667 roc_auc 0.41100 prc_auc 0.60973[0m
[93maverage test of epoch 11: loss -3.43062 acc 0.65789 roc_auc 0.63692 prc_auc 0.77537[0m
[92maverage training of epoch 12: loss -3.53764 acc 0.66667 roc_auc 0.45610 prc_auc 0.64657[0m
[93maverage test of epoch 12: loss -3.60965 acc 0.65789 roc_auc 0.56923 prc_auc 0.71441[0m
[92maverage training of epoch 13: loss -3.72975 acc 0.66667 roc_auc 0.39540 prc_auc 0.59825[0m
[93maverage test of epoch 13: loss -3.80768 acc 0.65789 roc_auc 0.50154 prc_auc 0.71672[0m
[92maverage training of epoch 14: loss -3.92167 acc 0.66667 roc_auc 0.47540 prc_auc 0.62863[0m
[93maverage test of epoch 14: loss -3.98532 acc 0.65789 roc_auc 0.37538 prc_auc 0.58664[0m
[92maverage training of epoch 15: loss -4.11428 acc 0.66667 roc_auc 0.46690 prc_auc 0.63146[0m
[93maverage test of epoch 15: loss -4.18011 acc 0.65789 roc_auc 0.39692 prc_auc 0.59892[0m
[92maverage training of epoch 16: loss -4.30369 acc 0.66667 roc_auc 0.45240 prc_auc 0.61871[0m
[93maverage test of epoch 16: loss -4.35747 acc 0.65789 roc_auc 0.67077 prc_auc 0.83587[0m
[92maverage training of epoch 17: loss -4.48864 acc 0.66667 roc_auc 0.43020 prc_auc 0.61570[0m
[93maverage test of epoch 17: loss -4.54622 acc 0.65789 roc_auc 0.57077 prc_auc 0.69458[0m
[92maverage training of epoch 18: loss -4.67054 acc 0.66667 roc_auc 0.40750 prc_auc 0.60447[0m
[93maverage test of epoch 18: loss -4.72704 acc 0.65789 roc_auc 0.51385 prc_auc 0.69354[0m
[92maverage training of epoch 19: loss -4.84444 acc 0.66667 roc_auc 0.40510 prc_auc 0.60914[0m
[93maverage test of epoch 19: loss -4.90983 acc 0.65789 roc_auc 0.54769 prc_auc 0.74503[0m
[92maverage training of epoch 20: loss -5.03399 acc 0.66667 roc_auc 0.46460 prc_auc 0.65999[0m
[93maverage test of epoch 20: loss -5.08640 acc 0.65789 roc_auc 0.49231 prc_auc 0.71645[0m
[92maverage training of epoch 21: loss -5.20688 acc 0.66667 roc_auc 0.37480 prc_auc 0.58189[0m
[93maverage test of epoch 21: loss -5.26482 acc 0.65789 roc_auc 0.56154 prc_auc 0.73170[0m
[92maverage training of epoch 22: loss -5.38014 acc 0.66667 roc_auc 0.40690 prc_auc 0.59465[0m
[93maverage test of epoch 22: loss -5.43366 acc 0.65789 roc_auc 0.48923 prc_auc 0.72055[0m
[92maverage training of epoch 23: loss -5.55892 acc 0.66667 roc_auc 0.42680 prc_auc 0.60970[0m
[93maverage test of epoch 23: loss -5.60749 acc 0.65789 roc_auc 0.41231 prc_auc 0.65616[0m
[92maverage training of epoch 24: loss -5.73102 acc 0.66667 roc_auc 0.39740 prc_auc 0.60126[0m
[93maverage test of epoch 24: loss -5.78316 acc 0.65789 roc_auc 0.50615 prc_auc 0.67825[0m
[92maverage training of epoch 25: loss -5.90346 acc 0.66667 roc_auc 0.39750 prc_auc 0.58882[0m
[93maverage test of epoch 25: loss -5.95017 acc 0.65789 roc_auc 0.47846 prc_auc 0.68069[0m
[92maverage training of epoch 26: loss -6.07341 acc 0.66667 roc_auc 0.36550 prc_auc 0.57276[0m
[93maverage test of epoch 26: loss -6.12327 acc 0.65789 roc_auc 0.51077 prc_auc 0.68352[0m
[92maverage training of epoch 27: loss -6.24796 acc 0.66667 roc_auc 0.38510 prc_auc 0.58896[0m
[93maverage test of epoch 27: loss -6.29272 acc 0.65789 roc_auc 0.47077 prc_auc 0.67607[0m
[92maverage training of epoch 28: loss -6.41906 acc 0.66667 roc_auc 0.42370 prc_auc 0.59430[0m
[93maverage test of epoch 28: loss -6.46245 acc 0.65789 roc_auc 0.40462 prc_auc 0.61328[0m
[92maverage training of epoch 29: loss -6.58844 acc 0.66667 roc_auc 0.38060 prc_auc 0.57833[0m
[93maverage test of epoch 29: loss -6.63154 acc 0.65789 roc_auc 0.45077 prc_auc 0.67489[0m
[92maverage training of epoch 30: loss -6.75543 acc 0.66667 roc_auc 0.38620 prc_auc 0.59011[0m
[93maverage test of epoch 30: loss -6.80627 acc 0.65789 roc_auc 0.68615 prc_auc 0.76907[0m
[92maverage training of epoch 31: loss -6.92473 acc 0.66667 roc_auc 0.35850 prc_auc 0.58226[0m
[93maverage test of epoch 31: loss -6.97195 acc 0.65789 roc_auc 0.56000 prc_auc 0.67962[0m
[92maverage training of epoch 32: loss -7.09616 acc 0.66667 roc_auc 0.38830 prc_auc 0.59121[0m
[93maverage test of epoch 32: loss -7.13825 acc 0.65789 roc_auc 0.49692 prc_auc 0.66362[0m
[92maverage training of epoch 33: loss -7.26436 acc 0.66667 roc_auc 0.42020 prc_auc 0.60376[0m
[93maverage test of epoch 33: loss -7.30382 acc 0.65789 roc_auc 0.51538 prc_auc 0.65495[0m
[92maverage training of epoch 34: loss -7.43135 acc 0.66667 roc_auc 0.36000 prc_auc 0.56703[0m
[93maverage test of epoch 34: loss -7.47582 acc 0.65789 roc_auc 0.44615 prc_auc 0.62219[0m
[92maverage training of epoch 35: loss -7.59788 acc 0.66667 roc_auc 0.35160 prc_auc 0.57243[0m
[93maverage test of epoch 35: loss -7.63935 acc 0.65789 roc_auc 0.38769 prc_auc 0.60877[0m
[92maverage training of epoch 36: loss -7.76792 acc 0.66667 roc_auc 0.41860 prc_auc 0.60302[0m
[93maverage test of epoch 36: loss -7.80514 acc 0.65789 roc_auc 0.55077 prc_auc 0.75615[0m
[92maverage training of epoch 37: loss -7.93549 acc 0.66667 roc_auc 0.42790 prc_auc 0.60700[0m
[93maverage test of epoch 37: loss -7.97655 acc 0.65789 roc_auc 0.64923 prc_auc 0.78749[0m
[92maverage training of epoch 38: loss -8.10317 acc 0.66667 roc_auc 0.35280 prc_auc 0.55982[0m
[93maverage test of epoch 38: loss -8.13807 acc 0.65789 roc_auc 0.43846 prc_auc 0.66632[0m
[92maverage training of epoch 39: loss -8.27072 acc 0.66667 roc_auc 0.38690 prc_auc 0.58277[0m
[93maverage test of epoch 39: loss -8.30696 acc 0.65789 roc_auc 0.42615 prc_auc 0.65944[0m
[92maverage training of epoch 40: loss -8.43700 acc 0.66667 roc_auc 0.38760 prc_auc 0.59296[0m
[93maverage test of epoch 40: loss -8.47546 acc 0.65789 roc_auc 0.57385 prc_auc 0.71048[0m
[92maverage training of epoch 41: loss -8.60400 acc 0.66667 roc_auc 0.39170 prc_auc 0.58049[0m
[93maverage test of epoch 41: loss -8.63874 acc 0.65789 roc_auc 0.65231 prc_auc 0.81941[0m
[92maverage training of epoch 42: loss -8.77052 acc 0.66667 roc_auc 0.35440 prc_auc 0.56479[0m
[93maverage test of epoch 42: loss -8.80734 acc 0.65789 roc_auc 0.56462 prc_auc 0.70492[0m
[92maverage training of epoch 43: loss -8.93692 acc 0.66667 roc_auc 0.36800 prc_auc 0.57124[0m
[93maverage test of epoch 43: loss -8.97542 acc 0.65789 roc_auc 0.62154 prc_auc 0.73819[0m
[92maverage training of epoch 44: loss -9.10384 acc 0.66667 roc_auc 0.37060 prc_auc 0.57038[0m
[93maverage test of epoch 44: loss -9.14028 acc 0.65789 roc_auc 0.55385 prc_auc 0.72480[0m
[92maverage training of epoch 45: loss -9.27054 acc 0.66667 roc_auc 0.36220 prc_auc 0.56930[0m
[93maverage test of epoch 45: loss -9.30551 acc 0.65789 roc_auc 0.39538 prc_auc 0.59182[0m
[92maverage training of epoch 46: loss -9.43685 acc 0.66667 roc_auc 0.37820 prc_auc 0.57704[0m
[93maverage test of epoch 46: loss -9.47055 acc 0.65789 roc_auc 0.45538 prc_auc 0.63046[0m
[92maverage training of epoch 47: loss -9.60201 acc 0.66667 roc_auc 0.39660 prc_auc 0.59482[0m
[93maverage test of epoch 47: loss -9.63734 acc 0.65789 roc_auc 0.28000 prc_auc 0.56208[0m
[92maverage training of epoch 48: loss -9.76913 acc 0.66667 roc_auc 0.36040 prc_auc 0.57184[0m
[93maverage test of epoch 48: loss -9.80294 acc 0.65789 roc_auc 0.35385 prc_auc 0.59728[0m
[92maverage training of epoch 49: loss -9.93451 acc 0.66667 roc_auc 0.35880 prc_auc 0.56597[0m
[93maverage test of epoch 49: loss -9.96973 acc 0.65789 roc_auc 0.53385 prc_auc 0.69261[0m
[92maverage training of epoch 50: loss -10.10187 acc 0.66667 roc_auc 0.37170 prc_auc 0.56856[0m
[93maverage test of epoch 50: loss -10.13591 acc 0.65789 roc_auc 0.60462 prc_auc 0.72847[0m
[92maverage training of epoch 51: loss -10.26780 acc 0.66667 roc_auc 0.35790 prc_auc 0.56353[0m
[93maverage test of epoch 51: loss -10.29970 acc 0.65789 roc_auc 0.61692 prc_auc 0.72366[0m
[92maverage training of epoch 52: loss -10.43357 acc 0.66667 roc_auc 0.36650 prc_auc 0.56784[0m
[93maverage test of epoch 52: loss -10.46656 acc 0.65789 roc_auc 0.49692 prc_auc 0.67685[0m
[92maverage training of epoch 53: loss -10.59990 acc 0.66667 roc_auc 0.35360 prc_auc 0.56576[0m
[93maverage test of epoch 53: loss -10.63174 acc 0.65789 roc_auc 0.48462 prc_auc 0.63957[0m
[92maverage training of epoch 54: loss -10.76646 acc 0.66667 roc_auc 0.36930 prc_auc 0.56949[0m
[93maverage test of epoch 54: loss -10.79782 acc 0.65789 roc_auc 0.34308 prc_auc 0.57163[0m
[92maverage training of epoch 55: loss -10.93224 acc 0.66667 roc_auc 0.37510 prc_auc 0.58175[0m
[93maverage test of epoch 55: loss -10.96220 acc 0.65789 roc_auc 0.50308 prc_auc 0.68463[0m
[92maverage training of epoch 56: loss -11.09844 acc 0.66667 roc_auc 0.37300 prc_auc 0.58348[0m
[93maverage test of epoch 56: loss -11.12863 acc 0.65789 roc_auc 0.63846 prc_auc 0.73106[0m
[92maverage training of epoch 57: loss -11.26411 acc 0.66667 roc_auc 0.35680 prc_auc 0.56141[0m
[93maverage test of epoch 57: loss -11.29366 acc 0.65789 roc_auc 0.72769 prc_auc 0.79706[0m
[92maverage training of epoch 58: loss -11.42978 acc 0.66667 roc_auc 0.36790 prc_auc 0.57075[0m
[93maverage test of epoch 58: loss -11.45977 acc 0.65789 roc_auc 0.59846 prc_auc 0.74739[0m
[92maverage training of epoch 59: loss -11.59556 acc 0.66667 roc_auc 0.35920 prc_auc 0.56556[0m
[93maverage test of epoch 59: loss -11.62486 acc 0.65789 roc_auc 0.56462 prc_auc 0.68052[0m
[92maverage training of epoch 60: loss -11.76197 acc 0.66667 roc_auc 0.35870 prc_auc 0.56676[0m
[93maverage test of epoch 60: loss -11.79017 acc 0.65789 roc_auc 0.58615 prc_auc 0.72603[0m
[92maverage training of epoch 61: loss -11.92788 acc 0.66667 roc_auc 0.37320 prc_auc 0.57408[0m
[93maverage test of epoch 61: loss -11.95588 acc 0.65789 roc_auc 0.58462 prc_auc 0.71362[0m
[92maverage training of epoch 62: loss -12.09359 acc 0.66667 roc_auc 0.36170 prc_auc 0.56767[0m
[93maverage test of epoch 62: loss -12.12111 acc 0.65789 roc_auc 0.59692 prc_auc 0.71860[0m
[92maverage training of epoch 63: loss -12.25958 acc 0.66667 roc_auc 0.35580 prc_auc 0.56512[0m
[93maverage test of epoch 63: loss -12.28623 acc 0.65789 roc_auc 0.37231 prc_auc 0.59093[0m
[92maverage training of epoch 64: loss -12.42527 acc 0.66667 roc_auc 0.36140 prc_auc 0.56962[0m
[93maverage test of epoch 64: loss -12.45181 acc 0.65789 roc_auc 0.52154 prc_auc 0.66893[0m
[92maverage training of epoch 65: loss -12.59110 acc 0.66667 roc_auc 0.36670 prc_auc 0.57222[0m
[93maverage test of epoch 65: loss -12.61735 acc 0.65789 roc_auc 0.35077 prc_auc 0.58012[0m
[92maverage training of epoch 66: loss -12.75730 acc 0.66667 roc_auc 0.36010 prc_auc 0.57048[0m
[93maverage test of epoch 66: loss -12.78265 acc 0.65789 roc_auc 0.55385 prc_auc 0.69115[0m
[92maverage training of epoch 67: loss -12.92278 acc 0.66667 roc_auc 0.35850 prc_auc 0.56689[0m
[93maverage test of epoch 67: loss -12.94662 acc 0.65789 roc_auc 0.56462 prc_auc 0.70688[0m
[92maverage training of epoch 68: loss -13.08881 acc 0.66667 roc_auc 0.36350 prc_auc 0.56561[0m
[93maverage test of epoch 68: loss -13.11374 acc 0.65789 roc_auc 0.56615 prc_auc 0.68808[0m
[92maverage training of epoch 69: loss -13.25459 acc 0.66667 roc_auc 0.35890 prc_auc 0.56377[0m
[93maverage test of epoch 69: loss -13.27836 acc 0.65789 roc_auc 0.52462 prc_auc 0.67378[0m
[92maverage training of epoch 70: loss -13.42053 acc 0.66667 roc_auc 0.35640 prc_auc 0.56326[0m
[93maverage test of epoch 70: loss -13.44375 acc 0.65789 roc_auc 0.60154 prc_auc 0.72927[0m
[92maverage training of epoch 71: loss -13.58609 acc 0.66667 roc_auc 0.36140 prc_auc 0.56814[0m
[93maverage test of epoch 71: loss -13.60911 acc 0.65789 roc_auc 0.43538 prc_auc 0.61703[0m
[92maverage training of epoch 72: loss -13.75203 acc 0.66667 roc_auc 0.36140 prc_auc 0.56600[0m
[93maverage test of epoch 72: loss -13.77478 acc 0.65789 roc_auc 0.60154 prc_auc 0.70324[0m
[92maverage training of epoch 73: loss -13.91783 acc 0.66667 roc_auc 0.35880 prc_auc 0.56506[0m
[93maverage test of epoch 73: loss -13.93997 acc 0.65789 roc_auc 0.57077 prc_auc 0.70109[0m
[92maverage training of epoch 74: loss -14.08332 acc 0.66667 roc_auc 0.35820 prc_auc 0.56475[0m
[93maverage test of epoch 74: loss -14.10548 acc 0.65789 roc_auc 0.51846 prc_auc 0.67978[0m
[92maverage training of epoch 75: loss -14.24936 acc 0.66667 roc_auc 0.36090 prc_auc 0.56517[0m
[93maverage test of epoch 75: loss -14.27052 acc 0.65789 roc_auc 0.51538 prc_auc 0.67268[0m
[92maverage training of epoch 76: loss -14.41497 acc 0.66667 roc_auc 0.35590 prc_auc 0.56408[0m
[93maverage test of epoch 76: loss -14.43591 acc 0.65789 roc_auc 0.47077 prc_auc 0.65023[0m
[92maverage training of epoch 77: loss -14.58076 acc 0.66667 roc_auc 0.36060 prc_auc 0.56868[0m
[93maverage test of epoch 77: loss -14.60049 acc 0.65789 roc_auc 0.46769 prc_auc 0.63813[0m
[92maverage training of epoch 78: loss -14.74647 acc 0.66667 roc_auc 0.35860 prc_auc 0.56475[0m
[93maverage test of epoch 78: loss -14.76635 acc 0.65789 roc_auc 0.51077 prc_auc 0.66946[0m
[92maverage training of epoch 79: loss -14.91224 acc 0.66667 roc_auc 0.36380 prc_auc 0.57050[0m
[93maverage test of epoch 79: loss -14.93171 acc 0.65789 roc_auc 0.51692 prc_auc 0.66817[0m
[92maverage training of epoch 80: loss -15.07816 acc 0.66667 roc_auc 0.36290 prc_auc 0.56719[0m
[93maverage test of epoch 80: loss -15.09717 acc 0.65789 roc_auc 0.56615 prc_auc 0.68910[0m
[92maverage training of epoch 81: loss -15.24381 acc 0.66667 roc_auc 0.36250 prc_auc 0.56672[0m
[93maverage test of epoch 81: loss -15.26223 acc 0.65789 roc_auc 0.33692 prc_auc 0.58893[0m
[92maverage training of epoch 82: loss -15.40954 acc 0.66667 roc_auc 0.35600 prc_auc 0.56447[0m
[93maverage test of epoch 82: loss -15.42737 acc 0.65789 roc_auc 0.45538 prc_auc 0.63441[0m
[92maverage training of epoch 83: loss -15.57536 acc 0.66667 roc_auc 0.35850 prc_auc 0.56382[0m
[93maverage test of epoch 83: loss -15.59284 acc 0.65789 roc_auc 0.61538 prc_auc 0.71324[0m
[92maverage training of epoch 84: loss -15.74109 acc 0.66667 roc_auc 0.36390 prc_auc 0.56891[0m
[93maverage test of epoch 84: loss -15.75801 acc 0.65789 roc_auc 0.48000 prc_auc 0.64677[0m
[92maverage training of epoch 85: loss -15.90677 acc 0.66667 roc_auc 0.36030 prc_auc 0.56776[0m
[93maverage test of epoch 85: loss -15.92339 acc 0.65789 roc_auc 0.43846 prc_auc 0.63158[0m
[92maverage training of epoch 86: loss -16.07252 acc 0.66667 roc_auc 0.35740 prc_auc 0.56482[0m
[93maverage test of epoch 86: loss -16.08870 acc 0.65789 roc_auc 0.51692 prc_auc 0.66561[0m
[92maverage training of epoch 87: loss -16.23821 acc 0.66667 roc_auc 0.35940 prc_auc 0.56439[0m
[93maverage test of epoch 87: loss -16.25391 acc 0.65789 roc_auc 0.47692 prc_auc 0.64762[0m
[92maverage training of epoch 88: loss -16.40392 acc 0.66667 roc_auc 0.35450 prc_auc 0.56285[0m
[93maverage test of epoch 88: loss -16.41917 acc 0.65789 roc_auc 0.41692 prc_auc 0.62291[0m
[92maverage training of epoch 89: loss -16.56975 acc 0.66667 roc_auc 0.36110 prc_auc 0.56631[0m
[93maverage test of epoch 89: loss -16.58442 acc 0.65789 roc_auc 0.51385 prc_auc 0.66482[0m
[92maverage training of epoch 90: loss -16.73548 acc 0.66667 roc_auc 0.35560 prc_auc 0.56327[0m
[93maverage test of epoch 90: loss -16.74954 acc 0.65789 roc_auc 0.57692 prc_auc 0.70104[0m
[92maverage training of epoch 91: loss -16.90113 acc 0.66667 roc_auc 0.35720 prc_auc 0.56826[0m
[93maverage test of epoch 91: loss -16.91483 acc 0.65789 roc_auc 0.42769 prc_auc 0.62797[0m
[92maverage training of epoch 92: loss -17.06694 acc 0.66667 roc_auc 0.35910 prc_auc 0.56468[0m
[93maverage test of epoch 92: loss -17.08022 acc 0.65789 roc_auc 0.42000 prc_auc 0.62298[0m
[92maverage training of epoch 93: loss -17.23256 acc 0.66667 roc_auc 0.36000 prc_auc 0.56658[0m
[93maverage test of epoch 93: loss -17.24533 acc 0.65789 roc_auc 0.40000 prc_auc 0.61495[0m
[92maverage training of epoch 94: loss -17.39823 acc 0.66667 roc_auc 0.35800 prc_auc 0.56441[0m
[93maverage test of epoch 94: loss -17.41038 acc 0.65789 roc_auc 0.50462 prc_auc 0.66025[0m
[92maverage training of epoch 95: loss -17.56395 acc 0.66667 roc_auc 0.35840 prc_auc 0.56613[0m
[93maverage test of epoch 95: loss -17.57568 acc 0.65789 roc_auc 0.32769 prc_auc 0.60219[0m
[92maverage training of epoch 96: loss -17.72969 acc 0.66667 roc_auc 0.35730 prc_auc 0.56580[0m
[93maverage test of epoch 96: loss -17.74107 acc 0.65789 roc_auc 0.52308 prc_auc 0.66847[0m
[92maverage training of epoch 97: loss -17.89538 acc 0.66667 roc_auc 0.36130 prc_auc 0.56771[0m
[93maverage test of epoch 97: loss -17.90638 acc 0.65789 roc_auc 0.43846 prc_auc 0.63158[0m
[92maverage training of epoch 98: loss -18.06116 acc 0.66667 roc_auc 0.35790 prc_auc 0.56508[0m
[93maverage test of epoch 98: loss -18.07155 acc 0.65789 roc_auc 0.43692 prc_auc 0.63010[0m
[92maverage training of epoch 99: loss -18.22683 acc 0.66667 roc_auc 0.36150 prc_auc 0.56878[0m
[93maverage test of epoch 99: loss -18.23676 acc 0.65789 roc_auc 0.47538 prc_auc 0.64760[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss 0.92581 acc 0.33333 roc_auc 0.48780 prc_auc 0.68484[0m
[93maverage test of epoch 0: loss 0.59173 acc 0.34211 roc_auc 0.55385 prc_auc 0.75672[0m
[92maverage training of epoch 1: loss 0.24868 acc 0.33333 roc_auc 0.57940 prc_auc 0.74842[0m
[93maverage test of epoch 1: loss -0.13461 acc 0.34211 roc_auc 0.60000 prc_auc 0.79347[0m
[92maverage training of epoch 2: loss -0.65753 acc 0.33333 roc_auc 0.50500 prc_auc 0.68795[0m
[93maverage test of epoch 2: loss -1.23823 acc 0.39474 roc_auc 0.58769 prc_auc 0.75289[0m
[92maverage training of epoch 3: loss -1.59238 acc 0.64000 roc_auc 0.45580 prc_auc 0.66488[0m
[93maverage test of epoch 3: loss -1.87186 acc 0.65789 roc_auc 0.44000 prc_auc 0.60808[0m
[92maverage training of epoch 4: loss -2.07979 acc 0.66667 roc_auc 0.46700 prc_auc 0.66010[0m
[93maverage test of epoch 4: loss -2.25305 acc 0.65789 roc_auc 0.55385 prc_auc 0.73008[0m
[92maverage training of epoch 5: loss -2.40607 acc 0.66667 roc_auc 0.45640 prc_auc 0.64646[0m
[93maverage test of epoch 5: loss -2.55464 acc 0.65789 roc_auc 0.39077 prc_auc 0.59350[0m
[92maverage training of epoch 6: loss -2.68190 acc 0.66667 roc_auc 0.43860 prc_auc 0.66327[0m
[93maverage test of epoch 6: loss -2.78703 acc 0.65789 roc_auc 0.48615 prc_auc 0.68156[0m
[92maverage training of epoch 7: loss -2.92252 acc 0.66667 roc_auc 0.45520 prc_auc 0.63046[0m
[93maverage test of epoch 7: loss -3.02412 acc 0.65789 roc_auc 0.52615 prc_auc 0.69990[0m
[92maverage training of epoch 8: loss -3.13959 acc 0.66667 roc_auc 0.46600 prc_auc 0.65708[0m
[93maverage test of epoch 8: loss -3.23823 acc 0.65789 roc_auc 0.80308 prc_auc 0.88339[0m
[92maverage training of epoch 9: loss -3.33105 acc 0.66667 roc_auc 0.51080 prc_auc 0.68158[0m
[93maverage test of epoch 9: loss -3.41226 acc 0.65789 roc_auc 0.40000 prc_auc 0.62332[0m
[92maverage training of epoch 10: loss -3.51963 acc 0.66667 roc_auc 0.49400 prc_auc 0.65052[0m
[93maverage test of epoch 10: loss -3.59021 acc 0.65789 roc_auc 0.55385 prc_auc 0.71642[0m
[92maverage training of epoch 11: loss -3.68015 acc 0.66667 roc_auc 0.50920 prc_auc 0.70250[0m
[93maverage test of epoch 11: loss -3.75563 acc 0.65789 roc_auc 0.61846 prc_auc 0.75203[0m
[92maverage training of epoch 12: loss -3.85280 acc 0.66667 roc_auc 0.47000 prc_auc 0.67913[0m
[93maverage test of epoch 12: loss -3.93401 acc 0.65789 roc_auc 0.38769 prc_auc 0.63288[0m
[92maverage training of epoch 13: loss -4.02212 acc 0.66667 roc_auc 0.45440 prc_auc 0.63981[0m
[93maverage test of epoch 13: loss -4.08771 acc 0.65789 roc_auc 0.42462 prc_auc 0.59593[0m
[92maverage training of epoch 14: loss -4.18373 acc 0.66667 roc_auc 0.48460 prc_auc 0.65518[0m
[93maverage test of epoch 14: loss -4.24918 acc 0.65789 roc_auc 0.30462 prc_auc 0.54597[0m
[92maverage training of epoch 15: loss -4.34959 acc 0.66667 roc_auc 0.48960 prc_auc 0.67919[0m
[93maverage test of epoch 15: loss -4.41853 acc 0.65789 roc_auc 0.58154 prc_auc 0.74490[0m
[92maverage training of epoch 16: loss -4.51546 acc 0.66667 roc_auc 0.43420 prc_auc 0.59796[0m
[93maverage test of epoch 16: loss -4.61171 acc 0.65789 roc_auc 0.70154 prc_auc 0.78453[0m
[92maverage training of epoch 17: loss -4.73790 acc 0.66667 roc_auc 0.45140 prc_auc 0.62164[0m
[93maverage test of epoch 17: loss -4.84694 acc 0.65789 roc_auc 0.54769 prc_auc 0.74687[0m
[92maverage training of epoch 18: loss -4.99271 acc 0.66667 roc_auc 0.44080 prc_auc 0.63425[0m
[93maverage test of epoch 18: loss -5.15677 acc 0.65789 roc_auc 0.46769 prc_auc 0.65558[0m
[92maverage training of epoch 19: loss -5.31396 acc 0.66667 roc_auc 0.46180 prc_auc 0.63594[0m
[93maverage test of epoch 19: loss -5.41966 acc 0.65789 roc_auc 0.31385 prc_auc 0.57791[0m
[92maverage training of epoch 20: loss -5.59245 acc 0.66667 roc_auc 0.49930 prc_auc 0.68741[0m
[93maverage test of epoch 20: loss -5.68754 acc 0.65789 roc_auc 0.51692 prc_auc 0.69847[0m
[92maverage training of epoch 21: loss -5.81913 acc 0.66667 roc_auc 0.58160 prc_auc 0.70793[0m
[93maverage test of epoch 21: loss -5.91601 acc 0.65789 roc_auc 0.69538 prc_auc 0.80143[0m
[92maverage training of epoch 22: loss -6.03999 acc 0.66667 roc_auc 0.48980 prc_auc 0.63468[0m
[93maverage test of epoch 22: loss -6.10777 acc 0.65789 roc_auc 0.61846 prc_auc 0.78187[0m
[92maverage training of epoch 23: loss -6.22958 acc 0.66667 roc_auc 0.49580 prc_auc 0.65839[0m
[93maverage test of epoch 23: loss -6.28958 acc 0.65789 roc_auc 0.48308 prc_auc 0.67275[0m
[92maverage training of epoch 24: loss -6.42241 acc 0.66667 roc_auc 0.49900 prc_auc 0.65137[0m
[93maverage test of epoch 24: loss -6.49237 acc 0.65789 roc_auc 0.53846 prc_auc 0.73432[0m
[92maverage training of epoch 25: loss -6.61050 acc 0.66667 roc_auc 0.54020 prc_auc 0.67023[0m
[93maverage test of epoch 25: loss -6.66780 acc 0.65789 roc_auc 0.55077 prc_auc 0.74112[0m
[92maverage training of epoch 26: loss -6.78693 acc 0.66667 roc_auc 0.47470 prc_auc 0.65647[0m
[93maverage test of epoch 26: loss -6.84461 acc 0.65789 roc_auc 0.41231 prc_auc 0.66528[0m
[92maverage training of epoch 27: loss -6.97178 acc 0.66667 roc_auc 0.51410 prc_auc 0.66759[0m
[93maverage test of epoch 27: loss -7.02929 acc 0.65789 roc_auc 0.66154 prc_auc 0.76855[0m
[92maverage training of epoch 28: loss -7.14980 acc 0.66667 roc_auc 0.51380 prc_auc 0.64689[0m
[93maverage test of epoch 28: loss -7.20303 acc 0.65789 roc_auc 0.41538 prc_auc 0.62831[0m
[92maverage training of epoch 29: loss -7.32366 acc 0.66667 roc_auc 0.47100 prc_auc 0.63831[0m
[93maverage test of epoch 29: loss -7.37257 acc 0.65789 roc_auc 0.46769 prc_auc 0.69866[0m
[92maverage training of epoch 30: loss -7.49716 acc 0.66667 roc_auc 0.44120 prc_auc 0.61976[0m
[93maverage test of epoch 30: loss -7.55919 acc 0.65789 roc_auc 0.78615 prc_auc 0.86708[0m
[92maverage training of epoch 31: loss -7.67034 acc 0.66667 roc_auc 0.45320 prc_auc 0.63138[0m
[93maverage test of epoch 31: loss -7.72343 acc 0.65789 roc_auc 0.51692 prc_auc 0.75214[0m
[92maverage training of epoch 32: loss -7.84938 acc 0.66667 roc_auc 0.40840 prc_auc 0.59264[0m
[93maverage test of epoch 32: loss -7.88949 acc 0.65789 roc_auc 0.60308 prc_auc 0.70692[0m
[92maverage training of epoch 33: loss -8.01788 acc 0.66667 roc_auc 0.47280 prc_auc 0.66346[0m
[93maverage test of epoch 33: loss -8.06916 acc 0.65789 roc_auc 0.46154 prc_auc 0.68688[0m
[92maverage training of epoch 34: loss -8.18801 acc 0.66667 roc_auc 0.45990 prc_auc 0.63030[0m
[93maverage test of epoch 34: loss -8.23765 acc 0.65789 roc_auc 0.46000 prc_auc 0.64151[0m
[92maverage training of epoch 35: loss -8.35911 acc 0.66667 roc_auc 0.46090 prc_auc 0.63633[0m
[93maverage test of epoch 35: loss -8.40844 acc 0.65789 roc_auc 0.31846 prc_auc 0.58242[0m
[92maverage training of epoch 36: loss -8.52847 acc 0.66667 roc_auc 0.43940 prc_auc 0.64127[0m
[93maverage test of epoch 36: loss -8.56962 acc 0.65789 roc_auc 0.47077 prc_auc 0.65964[0m
[92maverage training of epoch 37: loss -8.69618 acc 0.66667 roc_auc 0.43700 prc_auc 0.60916[0m
[93maverage test of epoch 37: loss -8.74544 acc 0.65789 roc_auc 0.42769 prc_auc 0.65474[0m
[92maverage training of epoch 38: loss -8.86820 acc 0.66667 roc_auc 0.42360 prc_auc 0.60588[0m
[93maverage test of epoch 38: loss -8.91456 acc 0.65789 roc_auc 0.53385 prc_auc 0.66044[0m
[92maverage training of epoch 39: loss -9.03515 acc 0.66667 roc_auc 0.42620 prc_auc 0.63345[0m
[93maverage test of epoch 39: loss -9.08022 acc 0.65789 roc_auc 0.48769 prc_auc 0.73049[0m
[92maverage training of epoch 40: loss -9.20318 acc 0.66667 roc_auc 0.45200 prc_auc 0.63878[0m
[93maverage test of epoch 40: loss -9.24807 acc 0.65789 roc_auc 0.38769 prc_auc 0.63941[0m
[92maverage training of epoch 41: loss -9.37084 acc 0.66667 roc_auc 0.45250 prc_auc 0.62356[0m
[93maverage test of epoch 41: loss -9.41687 acc 0.65789 roc_auc 0.66308 prc_auc 0.78718[0m
[92maverage training of epoch 42: loss -9.53823 acc 0.66667 roc_auc 0.44910 prc_auc 0.62928[0m
[93maverage test of epoch 42: loss -9.58110 acc 0.65789 roc_auc 0.43077 prc_auc 0.70874[0m
[92maverage training of epoch 43: loss -9.70704 acc 0.66667 roc_auc 0.45260 prc_auc 0.64483[0m
[93maverage test of epoch 43: loss -9.74999 acc 0.65789 roc_auc 0.50308 prc_auc 0.71604[0m
[92maverage training of epoch 44: loss -9.87475 acc 0.66667 roc_auc 0.46260 prc_auc 0.64181[0m
[93maverage test of epoch 44: loss -9.91783 acc 0.65789 roc_auc 0.60308 prc_auc 0.73115[0m
[92maverage training of epoch 45: loss -10.04230 acc 0.66667 roc_auc 0.42190 prc_auc 0.61245[0m
[93maverage test of epoch 45: loss -10.08314 acc 0.65789 roc_auc 0.42154 prc_auc 0.60285[0m
[92maverage training of epoch 46: loss -10.20751 acc 0.66667 roc_auc 0.42070 prc_auc 0.61092[0m
[93maverage test of epoch 46: loss -10.24896 acc 0.65789 roc_auc 0.57538 prc_auc 0.70880[0m
[92maverage training of epoch 47: loss -10.37506 acc 0.66667 roc_auc 0.42750 prc_auc 0.62433[0m
[93maverage test of epoch 47: loss -10.41467 acc 0.65789 roc_auc 0.48000 prc_auc 0.65991[0m
[92maverage training of epoch 48: loss -10.54135 acc 0.66667 roc_auc 0.43670 prc_auc 0.62069[0m
[93maverage test of epoch 48: loss -10.58393 acc 0.65789 roc_auc 0.56615 prc_auc 0.73653[0m
[92maverage training of epoch 49: loss -10.70854 acc 0.66667 roc_auc 0.44350 prc_auc 0.61698[0m
[93maverage test of epoch 49: loss -10.74896 acc 0.65789 roc_auc 0.46769 prc_auc 0.63132[0m
[92maverage training of epoch 50: loss -10.87577 acc 0.66667 roc_auc 0.42390 prc_auc 0.63969[0m
[93maverage test of epoch 50: loss -10.91419 acc 0.65789 roc_auc 0.44769 prc_auc 0.64238[0m
[92maverage training of epoch 51: loss -11.04191 acc 0.66667 roc_auc 0.43090 prc_auc 0.62286[0m
[93maverage test of epoch 51: loss -11.07988 acc 0.65789 roc_auc 0.62615 prc_auc 0.76004[0m
[92maverage training of epoch 52: loss -11.20851 acc 0.66667 roc_auc 0.42780 prc_auc 0.61161[0m
[93maverage test of epoch 52: loss -11.24401 acc 0.65789 roc_auc 0.55385 prc_auc 0.72826[0m
[92maverage training of epoch 53: loss -11.37456 acc 0.66667 roc_auc 0.43280 prc_auc 0.63171[0m
[93maverage test of epoch 53: loss -11.41272 acc 0.65789 roc_auc 0.39385 prc_auc 0.60853[0m
[92maverage training of epoch 54: loss -11.54036 acc 0.66667 roc_auc 0.45300 prc_auc 0.62465[0m
[93maverage test of epoch 54: loss -11.57761 acc 0.65789 roc_auc 0.60615 prc_auc 0.74742[0m
[92maverage training of epoch 55: loss -11.70647 acc 0.66667 roc_auc 0.40480 prc_auc 0.58762[0m
[93maverage test of epoch 55: loss -11.74408 acc 0.65789 roc_auc 0.39846 prc_auc 0.61825[0m
[92maverage training of epoch 56: loss -11.87337 acc 0.66667 roc_auc 0.43100 prc_auc 0.60517[0m
[93maverage test of epoch 56: loss -11.90952 acc 0.65789 roc_auc 0.14769 prc_auc 0.52750[0m
[92maverage training of epoch 57: loss -12.03919 acc 0.66667 roc_auc 0.43550 prc_auc 0.62954[0m
[93maverage test of epoch 57: loss -12.07516 acc 0.65789 roc_auc 0.60000 prc_auc 0.76212[0m
[92maverage training of epoch 58: loss -12.20559 acc 0.66667 roc_auc 0.43520 prc_auc 0.61801[0m
[93maverage test of epoch 58: loss -12.24050 acc 0.65789 roc_auc 0.36923 prc_auc 0.60824[0m
[92maverage training of epoch 59: loss -12.37192 acc 0.66667 roc_auc 0.43080 prc_auc 0.62002[0m
[93maverage test of epoch 59: loss -12.40581 acc 0.65789 roc_auc 0.32769 prc_auc 0.56813[0m
[92maverage training of epoch 60: loss -12.53746 acc 0.66667 roc_auc 0.42250 prc_auc 0.60177[0m
[93maverage test of epoch 60: loss -12.57226 acc 0.65789 roc_auc 0.52154 prc_auc 0.66512[0m
[92maverage training of epoch 61: loss -12.70303 acc 0.66667 roc_auc 0.41820 prc_auc 0.61554[0m
[93maverage test of epoch 61: loss -12.73684 acc 0.65789 roc_auc 0.54769 prc_auc 0.72298[0m
[92maverage training of epoch 62: loss -12.87004 acc 0.66667 roc_auc 0.43570 prc_auc 0.60711[0m
[93maverage test of epoch 62: loss -12.90401 acc 0.65789 roc_auc 0.44769 prc_auc 0.63123[0m
[92maverage training of epoch 63: loss -13.03577 acc 0.66667 roc_auc 0.42040 prc_auc 0.60661[0m
[93maverage test of epoch 63: loss -13.06750 acc 0.65789 roc_auc 0.50000 prc_auc 0.65768[0m
[92maverage training of epoch 64: loss -13.20201 acc 0.66667 roc_auc 0.41160 prc_auc 0.58975[0m
[93maverage test of epoch 64: loss -13.23440 acc 0.65789 roc_auc 0.48923 prc_auc 0.65534[0m
[92maverage training of epoch 65: loss -13.36765 acc 0.66667 roc_auc 0.41810 prc_auc 0.60078[0m
[93maverage test of epoch 65: loss -13.39911 acc 0.65789 roc_auc 0.57385 prc_auc 0.73361[0m
[92maverage training of epoch 66: loss -13.53393 acc 0.66667 roc_auc 0.42120 prc_auc 0.61017[0m
[93maverage test of epoch 66: loss -13.56493 acc 0.65789 roc_auc 0.62769 prc_auc 0.74346[0m
[92maverage training of epoch 67: loss -13.69957 acc 0.66667 roc_auc 0.42890 prc_auc 0.61120[0m
[93maverage test of epoch 67: loss -13.73054 acc 0.65789 roc_auc 0.53231 prc_auc 0.74420[0m
[92maverage training of epoch 68: loss -13.86586 acc 0.66667 roc_auc 0.42440 prc_auc 0.60713[0m
[93maverage test of epoch 68: loss -13.89575 acc 0.65789 roc_auc 0.35385 prc_auc 0.58703[0m
[92maverage training of epoch 69: loss -14.03133 acc 0.66667 roc_auc 0.41520 prc_auc 0.59137[0m
[93maverage test of epoch 69: loss -14.06077 acc 0.65789 roc_auc 0.48000 prc_auc 0.64700[0m
[92maverage training of epoch 70: loss -14.19777 acc 0.66667 roc_auc 0.43840 prc_auc 0.62655[0m
[93maverage test of epoch 70: loss -14.22668 acc 0.65789 roc_auc 0.38462 prc_auc 0.59644[0m
[92maverage training of epoch 71: loss -14.36324 acc 0.66667 roc_auc 0.41510 prc_auc 0.59575[0m
[93maverage test of epoch 71: loss -14.39214 acc 0.65789 roc_auc 0.40923 prc_auc 0.63098[0m
[92maverage training of epoch 72: loss -14.52958 acc 0.66667 roc_auc 0.42160 prc_auc 0.60592[0m
[93maverage test of epoch 72: loss -14.55802 acc 0.65789 roc_auc 0.53231 prc_auc 0.67784[0m
[92maverage training of epoch 73: loss -14.69524 acc 0.66667 roc_auc 0.41790 prc_auc 0.60977[0m
[93maverage test of epoch 73: loss -14.72320 acc 0.65789 roc_auc 0.49077 prc_auc 0.65849[0m
[92maverage training of epoch 74: loss -14.86128 acc 0.66667 roc_auc 0.41850 prc_auc 0.60288[0m
[93maverage test of epoch 74: loss -14.88736 acc 0.65789 roc_auc 0.36462 prc_auc 0.58901[0m
[92maverage training of epoch 75: loss -15.02652 acc 0.66667 roc_auc 0.42020 prc_auc 0.61237[0m
[93maverage test of epoch 75: loss -15.05356 acc 0.65789 roc_auc 0.46615 prc_auc 0.62946[0m
[92maverage training of epoch 76: loss -15.19234 acc 0.66667 roc_auc 0.41660 prc_auc 0.59406[0m
[93maverage test of epoch 76: loss -15.21919 acc 0.65789 roc_auc 0.59077 prc_auc 0.71575[0m
[92maverage training of epoch 77: loss -15.35866 acc 0.66667 roc_auc 0.43180 prc_auc 0.60972[0m
[93maverage test of epoch 77: loss -15.38409 acc 0.65789 roc_auc 0.49077 prc_auc 0.65396[0m
[92maverage training of epoch 78: loss -15.52447 acc 0.66667 roc_auc 0.42180 prc_auc 0.60585[0m
[93maverage test of epoch 78: loss -15.54934 acc 0.65789 roc_auc 0.45846 prc_auc 0.63959[0m
[92maverage training of epoch 79: loss -15.69004 acc 0.66667 roc_auc 0.41760 prc_auc 0.60304[0m
[93maverage test of epoch 79: loss -15.71492 acc 0.65789 roc_auc 0.40615 prc_auc 0.62415[0m
[92maverage training of epoch 80: loss -15.85582 acc 0.66667 roc_auc 0.42180 prc_auc 0.60480[0m
[93maverage test of epoch 80: loss -15.88042 acc 0.65789 roc_auc 0.47846 prc_auc 0.65549[0m
[92maverage training of epoch 81: loss -16.02149 acc 0.66667 roc_auc 0.41950 prc_auc 0.60503[0m
[93maverage test of epoch 81: loss -16.04571 acc 0.65789 roc_auc 0.56615 prc_auc 0.68801[0m
[92maverage training of epoch 82: loss -16.18748 acc 0.66667 roc_auc 0.42180 prc_auc 0.60681[0m
[93maverage test of epoch 82: loss -16.21077 acc 0.65789 roc_auc 0.51385 prc_auc 0.66890[0m
[92maverage training of epoch 83: loss -16.35324 acc 0.66667 roc_auc 0.41980 prc_auc 0.60249[0m
[93maverage test of epoch 83: loss -16.37634 acc 0.65789 roc_auc 0.44308 prc_auc 0.63283[0m
[92maverage training of epoch 84: loss -16.51911 acc 0.66667 roc_auc 0.41940 prc_auc 0.60032[0m
[93maverage test of epoch 84: loss -16.54129 acc 0.65789 roc_auc 0.49231 prc_auc 0.65388[0m
[92maverage training of epoch 85: loss -16.68473 acc 0.66667 roc_auc 0.41820 prc_auc 0.59937[0m
[93maverage test of epoch 85: loss -16.70674 acc 0.65789 roc_auc 0.43077 prc_auc 0.63050[0m
[92maverage training of epoch 86: loss -16.85055 acc 0.66667 roc_auc 0.41860 prc_auc 0.60177[0m
[93maverage test of epoch 86: loss -16.87163 acc 0.65789 roc_auc 0.39385 prc_auc 0.59897[0m
[92maverage training of epoch 87: loss -17.01618 acc 0.66667 roc_auc 0.42680 prc_auc 0.61287[0m
[93maverage test of epoch 87: loss -17.03729 acc 0.65789 roc_auc 0.58923 prc_auc 0.70599[0m
[92maverage training of epoch 88: loss -17.18181 acc 0.66667 roc_auc 0.41980 prc_auc 0.60063[0m
[93maverage test of epoch 88: loss -17.20248 acc 0.65789 roc_auc 0.60154 prc_auc 0.71707[0m
[92maverage training of epoch 89: loss -17.34780 acc 0.66667 roc_auc 0.42220 prc_auc 0.60332[0m
[93maverage test of epoch 89: loss -17.36789 acc 0.65789 roc_auc 0.40923 prc_auc 0.61564[0m
[92maverage training of epoch 90: loss -17.51353 acc 0.66667 roc_auc 0.42240 prc_auc 0.60197[0m
[93maverage test of epoch 90: loss -17.53335 acc 0.65789 roc_auc 0.62308 prc_auc 0.72164[0m
[92maverage training of epoch 91: loss -17.67935 acc 0.66667 roc_auc 0.42620 prc_auc 0.60899[0m
[93maverage test of epoch 91: loss -17.69845 acc 0.65789 roc_auc 0.64923 prc_auc 0.74042[0m
[92maverage training of epoch 92: loss -17.84500 acc 0.66667 roc_auc 0.41790 prc_auc 0.59666[0m
[93maverage test of epoch 92: loss -17.86354 acc 0.65789 roc_auc 0.68000 prc_auc 0.76058[0m
[92maverage training of epoch 93: loss -18.01089 acc 0.66667 roc_auc 0.41760 prc_auc 0.60303[0m
[93maverage test of epoch 93: loss -18.02888 acc 0.65789 roc_auc 0.56308 prc_auc 0.68815[0m
[92maverage training of epoch 94: loss -18.17655 acc 0.66667 roc_auc 0.41960 prc_auc 0.60346[0m
[93maverage test of epoch 94: loss -18.19437 acc 0.65789 roc_auc 0.67385 prc_auc 0.77010[0m
[92maverage training of epoch 95: loss -18.34238 acc 0.66667 roc_auc 0.42780 prc_auc 0.60943[0m
[93maverage test of epoch 95: loss -18.35959 acc 0.65789 roc_auc 0.34769 prc_auc 0.59285[0m
[92maverage training of epoch 96: loss -18.50800 acc 0.66667 roc_auc 0.42090 prc_auc 0.59925[0m
[93maverage test of epoch 96: loss -18.52457 acc 0.65789 roc_auc 0.58615 prc_auc 0.72367[0m
[92maverage training of epoch 97: loss -18.67380 acc 0.66667 roc_auc 0.41820 prc_auc 0.60231[0m
[93maverage test of epoch 97: loss -18.69016 acc 0.65789 roc_auc 0.58462 prc_auc 0.69747[0m
[92maverage training of epoch 98: loss -18.83948 acc 0.66667 roc_auc 0.42300 prc_auc 0.60499[0m
[93maverage test of epoch 98: loss -18.85541 acc 0.65789 roc_auc 0.48154 prc_auc 0.64906[0m
[92maverage training of epoch 99: loss -19.00522 acc 0.66667 roc_auc 0.41910 prc_auc 0.60396[0m
[93maverage test of epoch 99: loss -19.02070 acc 0.65789 roc_auc 0.37692 prc_auc 0.60612[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.57273 acc 0.61333 roc_auc 0.47860 prc_auc 0.67009[0m
[93maverage test of epoch 0: loss -0.87786 acc 0.65789 roc_auc 0.52000 prc_auc 0.66614[0m
[92maverage training of epoch 1: loss -1.16673 acc 0.66667 roc_auc 0.41660 prc_auc 0.65611[0m
[93maverage test of epoch 1: loss -1.45434 acc 0.65789 roc_auc 0.56923 prc_auc 0.75188[0m
[92maverage training of epoch 2: loss -1.80780 acc 0.66667 roc_auc 0.46940 prc_auc 0.69511[0m
[93maverage test of epoch 2: loss -2.11433 acc 0.65789 roc_auc 0.36308 prc_auc 0.59208[0m
[92maverage training of epoch 3: loss -2.45780 acc 0.66667 roc_auc 0.42660 prc_auc 0.62178[0m
[93maverage test of epoch 3: loss -2.85334 acc 0.65789 roc_auc 0.49231 prc_auc 0.70583[0m
[92maverage training of epoch 4: loss -3.11434 acc 0.66667 roc_auc 0.40480 prc_auc 0.63290[0m
[93maverage test of epoch 4: loss -3.31675 acc 0.65789 roc_auc 0.39385 prc_auc 0.61592[0m
[92maverage training of epoch 5: loss -3.53099 acc 0.66667 roc_auc 0.52660 prc_auc 0.70566[0m
[93maverage test of epoch 5: loss -3.68374 acc 0.65789 roc_auc 0.58154 prc_auc 0.79464[0m
[92maverage training of epoch 6: loss -3.86037 acc 0.66667 roc_auc 0.42200 prc_auc 0.62975[0m
[93maverage test of epoch 6: loss -3.96430 acc 0.65789 roc_auc 0.60615 prc_auc 0.76624[0m
[92maverage training of epoch 7: loss -4.13321 acc 0.66667 roc_auc 0.51000 prc_auc 0.67700[0m
[93maverage test of epoch 7: loss -4.23808 acc 0.65789 roc_auc 0.56000 prc_auc 0.67134[0m
[92maverage training of epoch 8: loss -4.38230 acc 0.66667 roc_auc 0.47340 prc_auc 0.64456[0m
[93maverage test of epoch 8: loss -4.44381 acc 0.65789 roc_auc 0.39077 prc_auc 0.65386[0m
[92maverage training of epoch 9: loss -4.60930 acc 0.66667 roc_auc 0.43320 prc_auc 0.63588[0m
[93maverage test of epoch 9: loss -4.68384 acc 0.65789 roc_auc 0.71385 prc_auc 0.85978[0m
[92maverage training of epoch 10: loss -4.83272 acc 0.66667 roc_auc 0.50740 prc_auc 0.65492[0m
[93maverage test of epoch 10: loss -4.89943 acc 0.65789 roc_auc 0.45077 prc_auc 0.67206[0m
[92maverage training of epoch 11: loss -5.02350 acc 0.66667 roc_auc 0.42930 prc_auc 0.64125[0m
[93maverage test of epoch 11: loss -5.09960 acc 0.65789 roc_auc 0.66154 prc_auc 0.79342[0m
[92maverage training of epoch 12: loss -5.22377 acc 0.66667 roc_auc 0.40530 prc_auc 0.61084[0m
[93maverage test of epoch 12: loss -5.29485 acc 0.65789 roc_auc 0.47077 prc_auc 0.68077[0m
[92maverage training of epoch 13: loss -5.42231 acc 0.66667 roc_auc 0.45500 prc_auc 0.64216[0m
[93maverage test of epoch 13: loss -5.48979 acc 0.65789 roc_auc 0.48923 prc_auc 0.72595[0m
[92maverage training of epoch 14: loss -5.60964 acc 0.66667 roc_auc 0.36540 prc_auc 0.57127[0m
[93maverage test of epoch 14: loss -5.66898 acc 0.65789 roc_auc 0.43077 prc_auc 0.65949[0m
[92maverage training of epoch 15: loss -5.79444 acc 0.66667 roc_auc 0.36400 prc_auc 0.57551[0m
[93maverage test of epoch 15: loss -5.85386 acc 0.65789 roc_auc 0.45231 prc_auc 0.68632[0m
[92maverage training of epoch 16: loss -5.98056 acc 0.66667 roc_auc 0.50130 prc_auc 0.67017[0m
[93maverage test of epoch 16: loss -6.03816 acc 0.65789 roc_auc 0.44000 prc_auc 0.65558[0m
[92maverage training of epoch 17: loss -6.16041 acc 0.66667 roc_auc 0.46340 prc_auc 0.63701[0m
[93maverage test of epoch 17: loss -6.20703 acc 0.65789 roc_auc 0.43692 prc_auc 0.67389[0m
[92maverage training of epoch 18: loss -6.33713 acc 0.66667 roc_auc 0.51300 prc_auc 0.69111[0m
[93maverage test of epoch 18: loss -6.38488 acc 0.65789 roc_auc 0.62308 prc_auc 0.79513[0m
[92maverage training of epoch 19: loss -6.51381 acc 0.66667 roc_auc 0.34280 prc_auc 0.56735[0m
[93maverage test of epoch 19: loss -6.56812 acc 0.65789 roc_auc 0.66462 prc_auc 0.80367[0m
[92maverage training of epoch 20: loss -6.69138 acc 0.66667 roc_auc 0.39160 prc_auc 0.61213[0m
[93maverage test of epoch 20: loss -6.73069 acc 0.65789 roc_auc 0.69231 prc_auc 0.78517[0m
[92maverage training of epoch 21: loss -6.86535 acc 0.66667 roc_auc 0.39230 prc_auc 0.59524[0m
[93maverage test of epoch 21: loss -6.90521 acc 0.65789 roc_auc 0.48615 prc_auc 0.69197[0m
[92maverage training of epoch 22: loss -7.03730 acc 0.66667 roc_auc 0.40950 prc_auc 0.61697[0m
[93maverage test of epoch 22: loss -7.08703 acc 0.65789 roc_auc 0.52308 prc_auc 0.67551[0m
[92maverage training of epoch 23: loss -7.20854 acc 0.66667 roc_auc 0.41120 prc_auc 0.61936[0m
[93maverage test of epoch 23: loss -7.25621 acc 0.65789 roc_auc 0.66923 prc_auc 0.82196[0m
[92maverage training of epoch 24: loss -7.37894 acc 0.66667 roc_auc 0.40810 prc_auc 0.59722[0m
[93maverage test of epoch 24: loss -7.42631 acc 0.65789 roc_auc 0.41692 prc_auc 0.64212[0m
[92maverage training of epoch 25: loss -7.55312 acc 0.66667 roc_auc 0.42870 prc_auc 0.61171[0m
[93maverage test of epoch 25: loss -7.59373 acc 0.65789 roc_auc 0.38308 prc_auc 0.62910[0m
[92maverage training of epoch 26: loss -7.72042 acc 0.66667 roc_auc 0.38480 prc_auc 0.59561[0m
[93maverage test of epoch 26: loss -7.76359 acc 0.65789 roc_auc 0.46000 prc_auc 0.67938[0m
[92maverage training of epoch 27: loss -7.88995 acc 0.66667 roc_auc 0.41690 prc_auc 0.59784[0m
[93maverage test of epoch 27: loss -7.92673 acc 0.65789 roc_auc 0.44923 prc_auc 0.64219[0m
[92maverage training of epoch 28: loss -8.06170 acc 0.66667 roc_auc 0.39730 prc_auc 0.60651[0m
[93maverage test of epoch 28: loss -8.10225 acc 0.65789 roc_auc 0.36462 prc_auc 0.56086[0m
[92maverage training of epoch 29: loss -8.23023 acc 0.66667 roc_auc 0.36890 prc_auc 0.57052[0m
[93maverage test of epoch 29: loss -8.26763 acc 0.65789 roc_auc 0.48308 prc_auc 0.68276[0m
[92maverage training of epoch 30: loss -8.39677 acc 0.66667 roc_auc 0.38450 prc_auc 0.58428[0m
[93maverage test of epoch 30: loss -8.43367 acc 0.65789 roc_auc 0.33385 prc_auc 0.55373[0m
[92maverage training of epoch 31: loss -8.56769 acc 0.66667 roc_auc 0.40710 prc_auc 0.60544[0m
[93maverage test of epoch 31: loss -8.60219 acc 0.65789 roc_auc 0.45231 prc_auc 0.65024[0m
[92maverage training of epoch 32: loss -8.73240 acc 0.66667 roc_auc 0.40710 prc_auc 0.60047[0m
[93maverage test of epoch 32: loss -8.77048 acc 0.65789 roc_auc 0.54000 prc_auc 0.67998[0m
[92maverage training of epoch 33: loss -8.90231 acc 0.66667 roc_auc 0.39950 prc_auc 0.58699[0m
[93maverage test of epoch 33: loss -8.93636 acc 0.65789 roc_auc 0.42000 prc_auc 0.60078[0m
[92maverage training of epoch 34: loss -9.06923 acc 0.66667 roc_auc 0.39800 prc_auc 0.58623[0m
[93maverage test of epoch 34: loss -9.10328 acc 0.65789 roc_auc 0.51692 prc_auc 0.67085[0m
[92maverage training of epoch 35: loss -9.23715 acc 0.66667 roc_auc 0.38900 prc_auc 0.58642[0m
[93maverage test of epoch 35: loss -9.27145 acc 0.65789 roc_auc 0.52462 prc_auc 0.70433[0m
[92maverage training of epoch 36: loss -9.40461 acc 0.66667 roc_auc 0.41560 prc_auc 0.59957[0m
[93maverage test of epoch 36: loss -9.43923 acc 0.65789 roc_auc 0.35692 prc_auc 0.60414[0m
[92maverage training of epoch 37: loss -9.57259 acc 0.66667 roc_auc 0.41560 prc_auc 0.59880[0m
[93maverage test of epoch 37: loss -9.60642 acc 0.65789 roc_auc 0.51077 prc_auc 0.69836[0m
[92maverage training of epoch 38: loss -9.73962 acc 0.66667 roc_auc 0.43300 prc_auc 0.62926[0m
[93maverage test of epoch 38: loss -9.77055 acc 0.65789 roc_auc 0.44615 prc_auc 0.61797[0m
[92maverage training of epoch 39: loss -9.90420 acc 0.66667 roc_auc 0.35780 prc_auc 0.56278[0m
[93maverage test of epoch 39: loss -9.93948 acc 0.65789 roc_auc 0.53846 prc_auc 0.68957[0m
[92maverage training of epoch 40: loss -10.07255 acc 0.66667 roc_auc 0.38340 prc_auc 0.58989[0m
[93maverage test of epoch 40: loss -10.10220 acc 0.65789 roc_auc 0.57538 prc_auc 0.75716[0m
[92maverage training of epoch 41: loss -10.23910 acc 0.66667 roc_auc 0.40090 prc_auc 0.58976[0m
[93maverage test of epoch 41: loss -10.27321 acc 0.65789 roc_auc 0.60000 prc_auc 0.73879[0m
[92maverage training of epoch 42: loss -10.40516 acc 0.66667 roc_auc 0.40140 prc_auc 0.59289[0m
[93maverage test of epoch 42: loss -10.43629 acc 0.65789 roc_auc 0.64615 prc_auc 0.75621[0m
[92maverage training of epoch 43: loss -10.57279 acc 0.66667 roc_auc 0.39180 prc_auc 0.59069[0m
[93maverage test of epoch 43: loss -10.60294 acc 0.65789 roc_auc 0.43846 prc_auc 0.62992[0m
[92maverage training of epoch 44: loss -10.73860 acc 0.66667 roc_auc 0.37900 prc_auc 0.57847[0m
[93maverage test of epoch 44: loss -10.76968 acc 0.65789 roc_auc 0.40000 prc_auc 0.61087[0m
[92maverage training of epoch 45: loss -10.90570 acc 0.66667 roc_auc 0.39300 prc_auc 0.59768[0m
[93maverage test of epoch 45: loss -10.93481 acc 0.65789 roc_auc 0.59538 prc_auc 0.74129[0m
[92maverage training of epoch 46: loss -11.07092 acc 0.66667 roc_auc 0.36530 prc_auc 0.57835[0m
[93maverage test of epoch 46: loss -11.10216 acc 0.65789 roc_auc 0.62462 prc_auc 0.72548[0m
[92maverage training of epoch 47: loss -11.23744 acc 0.66667 roc_auc 0.38190 prc_auc 0.60225[0m
[93maverage test of epoch 47: loss -11.26768 acc 0.65789 roc_auc 0.53077 prc_auc 0.67934[0m
[92maverage training of epoch 48: loss -11.40280 acc 0.66667 roc_auc 0.40170 prc_auc 0.62492[0m
[93maverage test of epoch 48: loss -11.43326 acc 0.65789 roc_auc 0.51385 prc_auc 0.67173[0m
[92maverage training of epoch 49: loss -11.57061 acc 0.66667 roc_auc 0.38600 prc_auc 0.60104[0m
[93maverage test of epoch 49: loss -11.59879 acc 0.65789 roc_auc 0.41538 prc_auc 0.61797[0m
[92maverage training of epoch 50: loss -11.73590 acc 0.66667 roc_auc 0.35480 prc_auc 0.56084[0m
[93maverage test of epoch 50: loss -11.76259 acc 0.65789 roc_auc 0.40308 prc_auc 0.61595[0m
[92maverage training of epoch 51: loss -11.90208 acc 0.66667 roc_auc 0.40600 prc_auc 0.59617[0m
[93maverage test of epoch 51: loss -11.92906 acc 0.65789 roc_auc 0.42923 prc_auc 0.63529[0m
[92maverage training of epoch 52: loss -12.06888 acc 0.66667 roc_auc 0.37860 prc_auc 0.58650[0m
[93maverage test of epoch 52: loss -12.09534 acc 0.65789 roc_auc 0.47385 prc_auc 0.65184[0m
[92maverage training of epoch 53: loss -12.23474 acc 0.66667 roc_auc 0.37560 prc_auc 0.58153[0m
[93maverage test of epoch 53: loss -12.25932 acc 0.65789 roc_auc 0.52000 prc_auc 0.67324[0m
[92maverage training of epoch 54: loss -12.40039 acc 0.66667 roc_auc 0.38960 prc_auc 0.58017[0m
[93maverage test of epoch 54: loss -12.42555 acc 0.65789 roc_auc 0.60923 prc_auc 0.73436[0m
[92maverage training of epoch 55: loss -12.56697 acc 0.66667 roc_auc 0.39070 prc_auc 0.58849[0m
[93maverage test of epoch 55: loss -12.58984 acc 0.65789 roc_auc 0.53077 prc_auc 0.71266[0m
[92maverage training of epoch 56: loss -12.73260 acc 0.66667 roc_auc 0.38470 prc_auc 0.58331[0m
[93maverage test of epoch 56: loss -12.75720 acc 0.65789 roc_auc 0.56154 prc_auc 0.69520[0m
[92maverage training of epoch 57: loss -12.89904 acc 0.66667 roc_auc 0.38760 prc_auc 0.57758[0m
[93maverage test of epoch 57: loss -12.92206 acc 0.65789 roc_auc 0.51231 prc_auc 0.68240[0m
[92maverage training of epoch 58: loss -13.06438 acc 0.66667 roc_auc 0.38720 prc_auc 0.59035[0m
[93maverage test of epoch 58: loss -13.08701 acc 0.65789 roc_auc 0.26154 prc_auc 0.54205[0m
[92maverage training of epoch 59: loss -13.23073 acc 0.66667 roc_auc 0.39000 prc_auc 0.59303[0m
[93maverage test of epoch 59: loss -13.25338 acc 0.65789 roc_auc 0.24308 prc_auc 0.54382[0m
[92maverage training of epoch 60: loss -13.39614 acc 0.66667 roc_auc 0.40320 prc_auc 0.59170[0m
[93maverage test of epoch 60: loss -13.41813 acc 0.65789 roc_auc 0.58154 prc_auc 0.72656[0m
[92maverage training of epoch 61: loss -13.56267 acc 0.66667 roc_auc 0.38920 prc_auc 0.59010[0m
[93maverage test of epoch 61: loss -13.58466 acc 0.65789 roc_auc 0.54308 prc_auc 0.68766[0m
[92maverage training of epoch 62: loss -13.72815 acc 0.66667 roc_auc 0.39000 prc_auc 0.58928[0m
[93maverage test of epoch 62: loss -13.74960 acc 0.65789 roc_auc 0.60154 prc_auc 0.76518[0m
[92maverage training of epoch 63: loss -13.89440 acc 0.66667 roc_auc 0.39010 prc_auc 0.58779[0m
[93maverage test of epoch 63: loss -13.91458 acc 0.65789 roc_auc 0.53692 prc_auc 0.72577[0m
[92maverage training of epoch 64: loss -14.05977 acc 0.66667 roc_auc 0.38070 prc_auc 0.58035[0m
[93maverage test of epoch 64: loss -14.08035 acc 0.65789 roc_auc 0.47692 prc_auc 0.68304[0m
[92maverage training of epoch 65: loss -14.22582 acc 0.66667 roc_auc 0.38770 prc_auc 0.58061[0m
[93maverage test of epoch 65: loss -14.24596 acc 0.65789 roc_auc 0.50615 prc_auc 0.67470[0m
[92maverage training of epoch 66: loss -14.39182 acc 0.66667 roc_auc 0.38680 prc_auc 0.58096[0m
[93maverage test of epoch 66: loss -14.41104 acc 0.65789 roc_auc 0.58000 prc_auc 0.69255[0m
[92maverage training of epoch 67: loss -14.55767 acc 0.66667 roc_auc 0.38090 prc_auc 0.57503[0m
[93maverage test of epoch 67: loss -14.57668 acc 0.65789 roc_auc 0.46615 prc_auc 0.63734[0m
[92maverage training of epoch 68: loss -14.72315 acc 0.66667 roc_auc 0.38590 prc_auc 0.58050[0m
[93maverage test of epoch 68: loss -14.74116 acc 0.65789 roc_auc 0.61538 prc_auc 0.74521[0m
[92maverage training of epoch 69: loss -14.88928 acc 0.66667 roc_auc 0.38540 prc_auc 0.58352[0m
[93maverage test of epoch 69: loss -14.90692 acc 0.65789 roc_auc 0.41385 prc_auc 0.63200[0m
[92maverage training of epoch 70: loss -15.05465 acc 0.66667 roc_auc 0.37190 prc_auc 0.57158[0m
[93maverage test of epoch 70: loss -15.07226 acc 0.65789 roc_auc 0.49231 prc_auc 0.65533[0m
[92maverage training of epoch 71: loss -15.22047 acc 0.66667 roc_auc 0.38800 prc_auc 0.58825[0m
[93maverage test of epoch 71: loss -15.23739 acc 0.65789 roc_auc 0.23692 prc_auc 0.56575[0m
[92maverage training of epoch 72: loss -15.38633 acc 0.66667 roc_auc 0.38110 prc_auc 0.58068[0m
[93maverage test of epoch 72: loss -15.40292 acc 0.65789 roc_auc 0.54154 prc_auc 0.69175[0m
[92maverage training of epoch 73: loss -15.55218 acc 0.66667 roc_auc 0.38890 prc_auc 0.58691[0m
[93maverage test of epoch 73: loss -15.56836 acc 0.65789 roc_auc 0.56000 prc_auc 0.68743[0m
[92maverage training of epoch 74: loss -15.71782 acc 0.66667 roc_auc 0.38430 prc_auc 0.58883[0m
[93maverage test of epoch 74: loss -15.73326 acc 0.65789 roc_auc 0.42923 prc_auc 0.62861[0m
[92maverage training of epoch 75: loss -15.88374 acc 0.66667 roc_auc 0.38400 prc_auc 0.58337[0m
[93maverage test of epoch 75: loss -15.89893 acc 0.65789 roc_auc 0.51385 prc_auc 0.66568[0m
[92maverage training of epoch 76: loss -16.04934 acc 0.66667 roc_auc 0.37810 prc_auc 0.57838[0m
[93maverage test of epoch 76: loss -16.06380 acc 0.65789 roc_auc 0.42615 prc_auc 0.62265[0m
[92maverage training of epoch 77: loss -16.21516 acc 0.66667 roc_auc 0.38520 prc_auc 0.58205[0m
[93maverage test of epoch 77: loss -16.22915 acc 0.65789 roc_auc 0.54000 prc_auc 0.68281[0m
[92maverage training of epoch 78: loss -16.38082 acc 0.66667 roc_auc 0.37760 prc_auc 0.57795[0m
[93maverage test of epoch 78: loss -16.39465 acc 0.65789 roc_auc 0.59231 prc_auc 0.70747[0m
[92maverage training of epoch 79: loss -16.54695 acc 0.66667 roc_auc 0.37910 prc_auc 0.57816[0m
[93maverage test of epoch 79: loss -16.55989 acc 0.65789 roc_auc 0.61692 prc_auc 0.71651[0m
[92maverage training of epoch 80: loss -16.71243 acc 0.66667 roc_auc 0.37610 prc_auc 0.57667[0m
[93maverage test of epoch 80: loss -16.72502 acc 0.65789 roc_auc 0.50154 prc_auc 0.65791[0m
[92maverage training of epoch 81: loss -16.87831 acc 0.66667 roc_auc 0.37890 prc_auc 0.57982[0m
[93maverage test of epoch 81: loss -16.89004 acc 0.65789 roc_auc 0.49231 prc_auc 0.65563[0m
[92maverage training of epoch 82: loss -17.04384 acc 0.66667 roc_auc 0.37710 prc_auc 0.57898[0m
[93maverage test of epoch 82: loss -17.05563 acc 0.65789 roc_auc 0.48308 prc_auc 0.64819[0m
[92maverage training of epoch 83: loss -17.20957 acc 0.66667 roc_auc 0.37740 prc_auc 0.57497[0m
[93maverage test of epoch 83: loss -17.22106 acc 0.65789 roc_auc 0.48308 prc_auc 0.64864[0m
[92maverage training of epoch 84: loss -17.37515 acc 0.66667 roc_auc 0.38080 prc_auc 0.58171[0m
[93maverage test of epoch 84: loss -17.38643 acc 0.65789 roc_auc 0.53692 prc_auc 0.67498[0m
[92maverage training of epoch 85: loss -17.54111 acc 0.66667 roc_auc 0.38170 prc_auc 0.58114[0m
[93maverage test of epoch 85: loss -17.55150 acc 0.65789 roc_auc 0.61538 prc_auc 0.71902[0m
[92maverage training of epoch 86: loss -17.70676 acc 0.66667 roc_auc 0.38180 prc_auc 0.57988[0m
[93maverage test of epoch 86: loss -17.71650 acc 0.65789 roc_auc 0.52308 prc_auc 0.66847[0m
[92maverage training of epoch 87: loss -17.87255 acc 0.66667 roc_auc 0.37800 prc_auc 0.58055[0m
[93maverage test of epoch 87: loss -17.88200 acc 0.65789 roc_auc 0.51077 prc_auc 0.66541[0m
[92maverage training of epoch 88: loss -18.03844 acc 0.66667 roc_auc 0.38380 prc_auc 0.58168[0m
[93maverage test of epoch 88: loss -18.04722 acc 0.65789 roc_auc 0.49692 prc_auc 0.65683[0m
[92maverage training of epoch 89: loss -18.20410 acc 0.66667 roc_auc 0.37490 prc_auc 0.57501[0m
[93maverage test of epoch 89: loss -18.21248 acc 0.65789 roc_auc 0.52000 prc_auc 0.66703[0m
[92maverage training of epoch 90: loss -18.36984 acc 0.66667 roc_auc 0.37700 prc_auc 0.57556[0m
[93maverage test of epoch 90: loss -18.37767 acc 0.65789 roc_auc 0.46000 prc_auc 0.64004[0m
[92maverage training of epoch 91: loss -18.53539 acc 0.66667 roc_auc 0.37930 prc_auc 0.57790[0m
[93maverage test of epoch 91: loss -18.54309 acc 0.65789 roc_auc 0.53846 prc_auc 0.67568[0m
[92maverage training of epoch 92: loss -18.70124 acc 0.66667 roc_auc 0.37860 prc_auc 0.57839[0m
[93maverage test of epoch 92: loss -18.70829 acc 0.65789 roc_auc 0.48000 prc_auc 0.64902[0m
[92maverage training of epoch 93: loss -18.86707 acc 0.66667 roc_auc 0.38360 prc_auc 0.58290[0m
[93maverage test of epoch 93: loss -18.87335 acc 0.65789 roc_auc 0.51077 prc_auc 0.66448[0m
[92maverage training of epoch 94: loss -19.03264 acc 0.66667 roc_auc 0.37520 prc_auc 0.57680[0m
[93maverage test of epoch 94: loss -19.03862 acc 0.65789 roc_auc 0.41692 prc_auc 0.62338[0m
[92maverage training of epoch 95: loss -19.19830 acc 0.66667 roc_auc 0.37760 prc_auc 0.57973[0m
[93maverage test of epoch 95: loss -19.20383 acc 0.65789 roc_auc 0.53538 prc_auc 0.67649[0m
[92maverage training of epoch 96: loss -19.36409 acc 0.66667 roc_auc 0.37680 prc_auc 0.57772[0m
[93maverage test of epoch 96: loss -19.36899 acc 0.65789 roc_auc 0.46000 prc_auc 0.64004[0m
[92maverage training of epoch 97: loss -19.52979 acc 0.66667 roc_auc 0.37850 prc_auc 0.57754[0m
[93maverage test of epoch 97: loss -19.53430 acc 0.65789 roc_auc 0.54000 prc_auc 0.67641[0m
[92maverage training of epoch 98: loss -19.69548 acc 0.66667 roc_auc 0.38020 prc_auc 0.57967[0m
[93maverage test of epoch 98: loss -19.69970 acc 0.65789 roc_auc 0.48000 prc_auc 0.64902[0m
[92maverage training of epoch 99: loss -19.86119 acc 0.66667 roc_auc 0.38440 prc_auc 0.58604[0m
[93maverage test of epoch 99: loss -19.86465 acc 0.65789 roc_auc 0.53846 prc_auc 0.67568[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.68250 acc 0.33775 roc_auc 0.54745 prc_auc 0.72215[0m
[93maverage test of epoch 0: loss -0.81268 acc 0.35135 roc_auc 0.53667 prc_auc 0.71184[0m
[92maverage training of epoch 1: loss -0.95320 acc 0.35099 roc_auc 0.53490 prc_auc 0.70929[0m
[93maverage test of epoch 1: loss -1.08492 acc 0.37838 roc_auc 0.58000 prc_auc 0.79637[0m
[92maverage training of epoch 2: loss -1.23201 acc 0.47682 roc_auc 0.65706 prc_auc 0.81840[0m
[93maverage test of epoch 2: loss -1.35149 acc 0.43243 roc_auc 0.70333 prc_auc 0.82084[0m
[92maverage training of epoch 3: loss -1.57839 acc 0.74172 roc_auc 0.76608 prc_auc 0.88550[0m
[93maverage test of epoch 3: loss -1.75856 acc 0.81081 roc_auc 0.88000 prc_auc 0.93350[0m
[92maverage training of epoch 4: loss -1.98893 acc 0.74834 roc_auc 0.85078 prc_auc 0.91061[0m
[93maverage test of epoch 4: loss -2.16245 acc 0.75676 roc_auc 0.85333 prc_auc 0.91846[0m
[92maverage training of epoch 5: loss -2.33494 acc 0.75497 roc_auc 0.85804 prc_auc 0.89941[0m
[93maverage test of epoch 5: loss -2.47327 acc 0.81081 roc_auc 0.86333 prc_auc 0.92190[0m
[92maverage training of epoch 6: loss -2.65632 acc 0.83444 roc_auc 0.87608 prc_auc 0.91797[0m
[93maverage test of epoch 6: loss -2.76839 acc 0.81081 roc_auc 0.87667 prc_auc 0.93592[0m
[92maverage training of epoch 7: loss -2.89802 acc 0.82781 roc_auc 0.87137 prc_auc 0.90422[0m
[93maverage test of epoch 7: loss -3.01384 acc 0.86486 roc_auc 0.85667 prc_auc 0.91873[0m
[92maverage training of epoch 8: loss -3.15418 acc 0.86093 roc_auc 0.86529 prc_auc 0.90579[0m
[93maverage test of epoch 8: loss -3.19993 acc 0.83784 roc_auc 0.85000 prc_auc 0.91540[0m
[92maverage training of epoch 9: loss -3.40071 acc 0.84768 roc_auc 0.87039 prc_auc 0.88802[0m
[93maverage test of epoch 9: loss -3.47025 acc 0.81081 roc_auc 0.90000 prc_auc 0.95110[0m
[92maverage training of epoch 10: loss -3.61572 acc 0.86093 roc_auc 0.88529 prc_auc 0.93157[0m
[93maverage test of epoch 10: loss -3.70101 acc 0.86486 roc_auc 0.84667 prc_auc 0.87386[0m
[92maverage training of epoch 11: loss -3.83162 acc 0.86755 roc_auc 0.87647 prc_auc 0.91245[0m
[93maverage test of epoch 11: loss -3.94445 acc 0.86486 roc_auc 0.90333 prc_auc 0.94729[0m
[92maverage training of epoch 12: loss -4.02793 acc 0.86093 roc_auc 0.87176 prc_auc 0.88994[0m
[93maverage test of epoch 12: loss -4.10662 acc 0.83784 roc_auc 0.89000 prc_auc 0.93961[0m
[92maverage training of epoch 13: loss -4.18832 acc 0.86093 roc_auc 0.86745 prc_auc 0.90880[0m
[93maverage test of epoch 13: loss -4.19951 acc 0.83784 roc_auc 0.84333 prc_auc 0.89617[0m
[92maverage training of epoch 14: loss -4.38890 acc 0.84106 roc_auc 0.86980 prc_auc 0.88440[0m
[93maverage test of epoch 14: loss -4.42934 acc 0.86486 roc_auc 0.83000 prc_auc 0.89643[0m
[92maverage training of epoch 15: loss -4.57128 acc 0.85430 roc_auc 0.87882 prc_auc 0.89221[0m
[93maverage test of epoch 15: loss -4.61722 acc 0.86486 roc_auc 0.87333 prc_auc 0.94140[0m
[92maverage training of epoch 16: loss -4.71488 acc 0.84768 roc_auc 0.87157 prc_auc 0.89869[0m
[93maverage test of epoch 16: loss -4.77331 acc 0.86486 roc_auc 0.82000 prc_auc 0.88028[0m
[92maverage training of epoch 17: loss -4.90476 acc 0.86093 roc_auc 0.88353 prc_auc 0.89238[0m
[93maverage test of epoch 17: loss -4.82312 acc 0.81081 roc_auc 0.85333 prc_auc 0.91008[0m
[92maverage training of epoch 18: loss -5.08617 acc 0.85430 roc_auc 0.87078 prc_auc 0.88835[0m
[93maverage test of epoch 18: loss -5.05519 acc 0.83784 roc_auc 0.84000 prc_auc 0.91758[0m
[92maverage training of epoch 19: loss -5.21358 acc 0.84768 roc_auc 0.88235 prc_auc 0.90780[0m
[93maverage test of epoch 19: loss -5.25104 acc 0.86486 roc_auc 0.91333 prc_auc 0.96382[0m
[92maverage training of epoch 20: loss -5.39601 acc 0.86093 roc_auc 0.86255 prc_auc 0.89824[0m
[93maverage test of epoch 20: loss -5.29467 acc 0.81081 roc_auc 0.82000 prc_auc 0.90713[0m
[92maverage training of epoch 21: loss -5.55209 acc 0.87417 roc_auc 0.88176 prc_auc 0.91714[0m
[93maverage test of epoch 21: loss -5.44967 acc 0.81081 roc_auc 0.83333 prc_auc 0.90125[0m
[92maverage training of epoch 22: loss -5.71117 acc 0.86755 roc_auc 0.88814 prc_auc 0.91874[0m
[93maverage test of epoch 22: loss -5.70192 acc 0.86486 roc_auc 0.83333 prc_auc 0.90152[0m
[92maverage training of epoch 23: loss -5.88563 acc 0.86755 roc_auc 0.88314 prc_auc 0.90179[0m
[93maverage test of epoch 23: loss -5.84566 acc 0.86486 roc_auc 0.84667 prc_auc 0.91688[0m
[92maverage training of epoch 24: loss -6.04459 acc 0.87417 roc_auc 0.88049 prc_auc 0.89688[0m
[93maverage test of epoch 24: loss -6.03825 acc 0.86486 roc_auc 0.85333 prc_auc 0.91191[0m
[92maverage training of epoch 25: loss -6.19781 acc 0.87417 roc_auc 0.89206 prc_auc 0.90346[0m
[93maverage test of epoch 25: loss -6.11421 acc 0.86486 roc_auc 0.82667 prc_auc 0.89558[0m
[92maverage training of epoch 26: loss -6.38669 acc 0.88079 roc_auc 0.90176 prc_auc 0.92598[0m
[93maverage test of epoch 26: loss -6.24267 acc 0.83784 roc_auc 0.88667 prc_auc 0.94177[0m
[92maverage training of epoch 27: loss -6.58104 acc 0.89404 roc_auc 0.88706 prc_auc 0.91354[0m
[93maverage test of epoch 27: loss -6.48070 acc 0.86486 roc_auc 0.84333 prc_auc 0.91156[0m
[92maverage training of epoch 28: loss -6.64070 acc 0.88742 roc_auc 0.86627 prc_auc 0.88371[0m
[93maverage test of epoch 28: loss -6.59872 acc 0.86486 roc_auc 0.86000 prc_auc 0.92906[0m
[92maverage training of epoch 29: loss -6.86580 acc 0.88079 roc_auc 0.88569 prc_auc 0.88640[0m
[93maverage test of epoch 29: loss -6.70360 acc 0.83784 roc_auc 0.81667 prc_auc 0.89333[0m
[92maverage training of epoch 30: loss -7.02426 acc 0.89404 roc_auc 0.87245 prc_auc 0.88021[0m
[93maverage test of epoch 30: loss -6.86393 acc 0.83784 roc_auc 0.82500 prc_auc 0.90436[0m
[92maverage training of epoch 31: loss -7.16948 acc 0.88742 roc_auc 0.90000 prc_auc 0.92061[0m
[93maverage test of epoch 31: loss -6.93034 acc 0.83784 roc_auc 0.85167 prc_auc 0.89297[0m
[92maverage training of epoch 32: loss -7.29629 acc 0.88079 roc_auc 0.87784 prc_auc 0.89666[0m
[93maverage test of epoch 32: loss -7.08327 acc 0.83784 roc_auc 0.82833 prc_auc 0.90005[0m
[92maverage training of epoch 33: loss -7.45242 acc 0.88742 roc_auc 0.89206 prc_auc 0.90898[0m
[93maverage test of epoch 33: loss -7.09108 acc 0.78378 roc_auc 0.86167 prc_auc 0.91996[0m
[92maverage training of epoch 34: loss -7.59960 acc 0.88742 roc_auc 0.89647 prc_auc 0.91775[0m
[93maverage test of epoch 34: loss -7.43713 acc 0.83784 roc_auc 0.88333 prc_auc 0.94684[0m
[92maverage training of epoch 35: loss -7.73185 acc 0.88079 roc_auc 0.88922 prc_auc 0.91330[0m
[93maverage test of epoch 35: loss -7.55968 acc 0.83784 roc_auc 0.90667 prc_auc 0.96129[0m
[92maverage training of epoch 36: loss -7.91972 acc 0.88742 roc_auc 0.88235 prc_auc 0.87534[0m
[93maverage test of epoch 36: loss -7.58141 acc 0.81081 roc_auc 0.87000 prc_auc 0.91698[0m
[92maverage training of epoch 37: loss -8.06045 acc 0.89404 roc_auc 0.87745 prc_auc 0.88925[0mUsing backend: pytorch

[93maverage test of epoch 37: loss -7.94310 acc 0.86486 roc_auc 0.86333 prc_auc 0.92520[0m
[92maverage training of epoch 38: loss -8.17141 acc 0.89404 roc_auc 0.88716 prc_auc 0.90708[0m
[93maverage test of epoch 38: loss -7.92604 acc 0.83784 roc_auc 0.88167 prc_auc 0.93985[0m
[92maverage training of epoch 39: loss -8.28384 acc 0.88079 roc_auc 0.85618 prc_auc 0.86871[0m
[93maverage test of epoch 39: loss -7.88375 acc 0.78378 roc_auc 0.80833 prc_auc 0.85047[0m
[92maverage training of epoch 40: loss -8.48120 acc 0.89404 roc_auc 0.88922 prc_auc 0.89580[0m
[93maverage test of epoch 40: loss -8.27914 acc 0.86486 roc_auc 0.76333 prc_auc 0.82636[0m
[92maverage training of epoch 41: loss -8.59669 acc 0.89404 roc_auc 0.87618 prc_auc 0.88796[0m
[93maverage test of epoch 41: loss -8.43082 acc 0.83784 roc_auc 0.79667 prc_auc 0.83146[0m
[92maverage training of epoch 42: loss -8.83374 acc 0.88742 roc_auc 0.88324 prc_auc 0.88912[0m
[93maverage test of epoch 42: loss -8.55695 acc 0.83784 roc_auc 0.81833 prc_auc 0.87254[0m
[92maverage training of epoch 43: loss -8.97169 acc 0.89404 roc_auc 0.89569 prc_auc 0.89959[0m
[93maverage test of epoch 43: loss -8.79914 acc 0.86486 roc_auc 0.85333 prc_auc 0.89494[0m
[92maverage training of epoch 44: loss -8.99198 acc 0.88742 roc_auc 0.88245 prc_auc 0.90194[0m
[93maverage test of epoch 44: loss -8.79732 acc 0.78378 roc_auc 0.83167 prc_auc 0.87593[0m
[92maverage training of epoch 45: loss -9.26622 acc 0.90066 roc_auc 0.88324 prc_auc 0.89552[0m
[93maverage test of epoch 45: loss -8.88715 acc 0.83784 roc_auc 0.80333 prc_auc 0.82805[0m
[92maverage training of epoch 46: loss -9.33185 acc 0.88742 roc_auc 0.88186 prc_auc 0.90769[0m
[93maverage test of epoch 46: loss -9.13871 acc 0.83784 roc_auc 0.80333 prc_auc 0.84119[0m
[92maverage training of epoch 47: loss -9.53402 acc 0.89404 roc_auc 0.88167 prc_auc 0.88868[0m
[93maverage test of epoch 47: loss -9.30009 acc 0.86486 roc_auc 0.82667 prc_auc 0.90441[0m
[92maverage training of epoch 48: loss -9.67191 acc 0.89404 roc_auc 0.89647 prc_auc 0.92111[0m
[93maverage test of epoch 48: loss -9.53446 acc 0.86486 roc_auc 0.88833 prc_auc 0.94550[0m
[92maverage training of epoch 49: loss -9.79773 acc 0.88079 roc_auc 0.88539 prc_auc 0.89617[0m
[93maverage test of epoch 49: loss -9.55384 acc 0.83784 roc_auc 0.88333 prc_auc 0.94690[0m
[92maverage training of epoch 50: loss -9.90627 acc 0.88079 roc_auc 0.87725 prc_auc 0.89273[0m
[93maverage test of epoch 50: loss -9.65060 acc 0.81081 roc_auc 0.82000 prc_auc 0.84486[0m
[92maverage training of epoch 51: loss -10.08334 acc 0.88079 roc_auc 0.89020 prc_auc 0.91343[0m
[93maverage test of epoch 51: loss -9.76542 acc 0.83784 roc_auc 0.81667 prc_auc 0.86043[0m
[92maverage training of epoch 52: loss -10.16559 acc 0.88079 roc_auc 0.87843 prc_auc 0.89107[0m
[93maverage test of epoch 52: loss -10.00211 acc 0.83784 roc_auc 0.79333 prc_auc 0.84847[0m
[92maverage training of epoch 53: loss -10.36869 acc 0.89404 roc_auc 0.86902 prc_auc 0.88211[0m
[93maverage test of epoch 53: loss -9.95314 acc 0.78378 roc_auc 0.81333 prc_auc 0.84505[0m
[92maverage training of epoch 54: loss -10.49478 acc 0.88742 roc_auc 0.88647 prc_auc 0.89725[0m
[93maverage test of epoch 54: loss -10.11195 acc 0.81081 roc_auc 0.90667 prc_auc 0.95150[0m
[92maverage training of epoch 55: loss -10.68862 acc 0.89404 roc_auc 0.88627 prc_auc 0.89868[0m
[93maverage test of epoch 55: loss -10.27993 acc 0.81081 roc_auc 0.79667 prc_auc 0.84672[0m
[92maverage training of epoch 56: loss -10.89982 acc 0.90728 roc_auc 0.88176 prc_auc 0.88911[0m
[93maverage test of epoch 56: loss -10.42749 acc 0.81081 roc_auc 0.76167 prc_auc 0.81379[0m
[92maverage training of epoch 57: loss -10.94482 acc 0.88079 roc_auc 0.89020 prc_auc 0.90200[0m
[93maverage test of epoch 57: loss -10.62384 acc 0.83784 roc_auc 0.80833 prc_auc 0.86737[0m
[92maverage training of epoch 58: loss -11.10820 acc 0.89404 roc_auc 0.88559 prc_auc 0.89174[0m
[93maverage test of epoch 58: loss -10.69089 acc 0.81081 roc_auc 0.87333 prc_auc 0.91653[0m
[92maverage training of epoch 59: loss -11.26852 acc 0.88742 roc_auc 0.87784 prc_auc 0.89773[0m
[93maverage test of epoch 59: loss -11.10881 acc 0.86486 roc_auc 0.80167 prc_auc 0.84357[0m
[92maverage training of epoch 60: loss -11.39372 acc 0.88742 roc_auc 0.87324 prc_auc 0.89248[0m
[93maverage test of epoch 60: loss -11.13895 acc 0.83784 roc_auc 0.84333 prc_auc 0.87551[0m
[92maverage training of epoch 61: loss -11.63211 acc 0.90066 roc_auc 0.89059 prc_auc 0.89786[0m
[93maverage test of epoch 61: loss -11.21987 acc 0.81081 roc_auc 0.83667 prc_auc 0.87126[0m
[92maverage training of epoch 62: loss -11.71045 acc 0.89404 roc_auc 0.88137 prc_auc 0.90066[0m
[93maverage test of epoch 62: loss -11.43295 acc 0.83784 roc_auc 0.81333 prc_auc 0.86813[0m
[92maverage training of epoch 63: loss -11.81693 acc 0.88742 roc_auc 0.88343 prc_auc 0.89198[0m
[93maverage test of epoch 63: loss -11.54596 acc 0.86486 roc_auc 0.85167 prc_auc 0.88739[0m
[92maverage training of epoch 64: loss -11.98911 acc 0.89404 roc_auc 0.87441 prc_auc 0.89372[0m
[93maverage test of epoch 64: loss -11.63484 acc 0.83784 roc_auc 0.88333 prc_auc 0.93791[0m
[92maverage training of epoch 65: loss -12.11686 acc 0.89404 roc_auc 0.88765 prc_auc 0.89949[0m
[93maverage test of epoch 65: loss -11.56590 acc 0.81081 roc_auc 0.91167 prc_auc 0.95554[0m
[92maverage training of epoch 66: loss -12.28514 acc 0.88742 roc_auc 0.89402 prc_auc 0.91453[0m
[93maverage test of epoch 66: loss -11.73817 acc 0.83784 roc_auc 0.81333 prc_auc 0.86441[0m
[92maverage training of epoch 67: loss -12.38279 acc 0.89404 roc_auc 0.88000 prc_auc 0.89335[0m
[93maverage test of epoch 67: loss -11.69851 acc 0.78378 roc_auc 0.81333 prc_auc 0.86065[0m
[92maverage training of epoch 68: loss -12.58343 acc 0.88742 roc_auc 0.88735 prc_auc 0.90664[0m
[93maverage test of epoch 68: loss -12.08359 acc 0.81081 roc_auc 0.84833 prc_auc 0.89499[0m
[92maverage training of epoch 69: loss -12.83159 acc 0.90728 roc_auc 0.88343 prc_auc 0.89849[0m
[93maverage test of epoch 69: loss -12.33695 acc 0.83784 roc_auc 0.84333 prc_auc 0.88780[0m
[92maverage training of epoch 70: loss -12.81542 acc 0.88742 roc_auc 0.89029 prc_auc 0.90138[0m
[93maverage test of epoch 70: loss -12.43019 acc 0.83784 roc_auc 0.83000 prc_auc 0.87141[0m
[92maverage training of epoch 71: loss -13.08169 acc 0.90066 roc_auc 0.89500 prc_auc 0.90703[0m
[93maverage test of epoch 71: loss -12.44876 acc 0.81081 roc_auc 0.80833 prc_auc 0.86239[0m
[92maverage training of epoch 72: loss -13.23670 acc 0.90066 roc_auc 0.89078 prc_auc 0.90545[0m
[93maverage test of epoch 72: loss -12.73867 acc 0.81081 roc_auc 0.84500 prc_auc 0.88500[0m
[92maverage training of epoch 73: loss -13.36510 acc 0.90728 roc_auc 0.89020 prc_auc 0.90349[0m
[93maverage test of epoch 73: loss -12.95961 acc 0.83784 roc_auc 0.85500 prc_auc 0.88917[0m
[92maverage training of epoch 74: loss -13.34445 acc 0.88742 roc_auc 0.88569 prc_auc 0.90523[0m
[93maverage test of epoch 74: loss -13.14089 acc 0.86486 roc_auc 0.82500 prc_auc 0.86154[0m
[92maverage training of epoch 75: loss -13.76010 acc 0.91391 roc_auc 0.87559 prc_auc 0.89721[0m
[93maverage test of epoch 75: loss -13.20471 acc 0.83784 roc_auc 0.81833 prc_auc 0.85925[0m
[92maverage training of epoch 76: loss -13.82697 acc 0.90728 roc_auc 0.88363 prc_auc 0.90268[0m
[93maverage test of epoch 76: loss -13.31260 acc 0.83784 roc_auc 0.82167 prc_auc 0.86014[0m
[92maverage training of epoch 77: loss -13.96978 acc 0.90728 roc_auc 0.89853 prc_auc 0.91454[0m
[93maverage test of epoch 77: loss -13.46725 acc 0.83784 roc_auc 0.82667 prc_auc 0.86449[0m
[92maverage training of epoch 78: loss -14.09338 acc 0.90728 roc_auc 0.88882 prc_auc 0.91353[0m
[93maverage test of epoch 78: loss -13.65808 acc 0.83784 roc_auc 0.83000 prc_auc 0.87106[0m
[92maverage training of epoch 79: loss -14.00732 acc 0.88079 roc_auc 0.90069 prc_auc 0.91952[0m
[93maverage test of epoch 79: loss -13.73439 acc 0.83784 roc_auc 0.82167 prc_auc 0.86596[0m
[92maverage training of epoch 80: loss -14.43681 acc 0.90066 roc_auc 0.88794 prc_auc 0.90782[0m
[93maverage test of epoch 80: loss -13.91884 acc 0.86486 roc_auc 0.81500 prc_auc 0.85836[0m
[92maverage training of epoch 81: loss -14.36643 acc 0.88079 roc_auc 0.88382 prc_auc 0.90177[0m
[93maverage test of epoch 81: loss -14.01981 acc 0.83784 roc_auc 0.84500 prc_auc 0.89143[0m
[92maverage training of epoch 82: loss -14.47465 acc 0.88742 roc_auc 0.88843 prc_auc 0.91056[0m
[93maverage test of epoch 82: loss -14.15494 acc 0.83784 roc_auc 0.81667 prc_auc 0.86154[0m
[92maverage training of epoch 83: loss -14.73363 acc 0.89404 roc_auc 0.91000 prc_auc 0.92594[0m
[93maverage test of epoch 83: loss -14.27873 acc 0.83784 roc_auc 0.81667 prc_auc 0.86745[0m
[92maverage training of epoch 84: loss -14.82979 acc 0.88742 roc_auc 0.89333 prc_auc 0.91818[0m
[93maverage test of epoch 84: loss -14.32050 acc 0.81081 roc_auc 0.83167 prc_auc 0.86853[0m
[92maverage training of epoch 85: loss -15.06472 acc 0.90066 roc_auc 0.88196 prc_auc 0.90523[0m
[93maverage test of epoch 85: loss -14.55090 acc 0.83784 roc_auc 0.86000 prc_auc 0.89881[0m
[92maverage training of epoch 86: loss -14.92586 acc 0.88079 roc_auc 0.88706 prc_auc 0.92975[0m
[93maverage test of epoch 86: loss -13.62070 acc 0.75676 roc_auc 0.77000 prc_auc 0.85767[0m
[92maverage training of epoch 87: loss -15.35144 acc 0.90728 roc_auc 0.88059 prc_auc 0.90789[0m
[93maverage test of epoch 87: loss -14.29633 acc 0.78378 roc_auc 0.80167 prc_auc 0.85286[0m
[92maverage training of epoch 88: loss -15.21864 acc 0.88079 roc_auc 0.89676 prc_auc 0.93946[0m
[93maverage test of epoch 88: loss -14.07220 acc 0.78378 roc_auc 0.76000 prc_auc 0.83714[0m
[92maverage training of epoch 89: loss -15.72221 acc 0.90728 roc_auc 0.91333 prc_auc 0.93568[0m
[93maverage test of epoch 89: loss -14.30132 acc 0.78378 roc_auc 0.81667 prc_auc 0.86101[0m
[92maverage training of epoch 90: loss -15.71391 acc 0.90066 roc_auc 0.89863 prc_auc 0.92692[0m
[93maverage test of epoch 90: loss -15.32722 acc 0.86486 roc_auc 0.86333 prc_auc 0.89357[0m
[92maverage training of epoch 91: loss -15.62384 acc 0.88742 roc_auc 0.90706 prc_auc 0.93706[0m
[93maverage test of epoch 91: loss -15.14205 acc 0.81081 roc_auc 0.81167 prc_auc 0.85748[0m
[92maverage training of epoch 92: loss -16.10630 acc 0.90728 roc_auc 0.91147 prc_auc 0.93509[0m
[93maverage test of epoch 92: loss -14.79077 acc 0.78378 roc_auc 0.77333 prc_auc 0.84813[0m
[92maverage training of epoch 93: loss -16.10199 acc 0.90066 roc_auc 0.90451 prc_auc 0.93282[0m
[93maverage test of epoch 93: loss -14.72615 acc 0.78378 roc_auc 0.83167 prc_auc 0.87934[0m
[92maverage training of epoch 94: loss -16.20870 acc 0.90066 roc_auc 0.90108 prc_auc 0.93499[0m
[93maverage test of epoch 94: loss -15.41919 acc 0.81081 roc_auc 0.83000 prc_auc 0.86515[0m
[92maverage training of epoch 95: loss -16.31906 acc 0.88742 roc_auc 0.89549 prc_auc 0.92839[0m
[93maverage test of epoch 95: loss -15.34889 acc 0.81081 roc_auc 0.80167 prc_auc 0.85323[0m
[92maverage training of epoch 96: loss -16.46836 acc 0.88079 roc_auc 0.89784 prc_auc 0.92830[0m
[93maverage test of epoch 96: loss -15.34289 acc 0.78378 roc_auc 0.80667 prc_auc 0.85704[0m
[92maverage training of epoch 97: loss -16.62139 acc 0.89404 roc_auc 0.89794 prc_auc 0.92911[0m
[93maverage test of epoch 97: loss -15.12144 acc 0.75676 roc_auc 0.79500 prc_auc 0.85007[0m
[92maverage training of epoch 98: loss -16.54054 acc 0.87417 roc_auc 0.89304 prc_auc 0.92613[0m
[93maverage test of epoch 98: loss -15.75505 acc 0.78378 roc_auc 0.82667 prc_auc 0.86407[0m
[92maverage training of epoch 99: loss -16.95314 acc 0.89404 roc_auc 0.91314 prc_auc 0.95284[0m
[93maverage test of epoch 99: loss -15.60826 acc 0.78378 roc_auc 0.81333 prc_auc 0.85935[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.74840 acc 0.36424 roc_auc 0.45294 prc_auc 0.63189[0m
[93maverage test of epoch 0: loss -0.91166 acc 0.32432 roc_auc 0.63000 prc_auc 0.79111[0m
[92maverage training of epoch 1: loss -1.04197 acc 0.41060 roc_auc 0.49412 prc_auc 0.67228[0m
[93maverage test of epoch 1: loss -1.16199 acc 0.37838 roc_auc 0.51333 prc_auc 0.72210[0m
[92maverage training of epoch 2: loss -1.28992 acc 0.45033 roc_auc 0.59804 prc_auc 0.75306[0m
[93maverage test of epoch 2: loss -1.39659 acc 0.35135 roc_auc 0.38333 prc_auc 0.62739[0m
[92maverage training of epoch 3: loss -1.50785 acc 0.45033 roc_auc 0.51941 prc_auc 0.69106[0m
[93maverage test of epoch 3: loss -1.61915 acc 0.37838 roc_auc 0.47667 prc_auc 0.68819[0m
[92maverage training of epoch 4: loss -1.73083 acc 0.54967 roc_auc 0.48765 prc_auc 0.68283[0m
[93maverage test of epoch 4: loss -1.84670 acc 0.64865 roc_auc 0.57000 prc_auc 0.74248[0m
[92maverage training of epoch 5: loss -1.94881 acc 0.58940 roc_auc 0.48235 prc_auc 0.69694[0m
[93maverage test of epoch 5: loss -2.06966 acc 0.64865 roc_auc 0.71000 prc_auc 0.86031[0m
[92maverage training of epoch 6: loss -2.17672 acc 0.64901 roc_auc 0.57451 prc_auc 0.75701[0m
[93maverage test of epoch 6: loss -2.27599 acc 0.67568 roc_auc 0.53667 prc_auc 0.76534[0m
[92maverage training of epoch 7: loss -2.39051 acc 0.66225 roc_auc 0.55059 prc_auc 0.73324[0m
[93maverage test of epoch 7: loss -2.50679 acc 0.67568 roc_auc 0.74000 prc_auc 0.89667[0m
[92maverage training of epoch 8: loss -2.60943 acc 0.66225 roc_auc 0.55569 prc_auc 0.71677[0m
[93maverage test of epoch 8: loss -2.72128 acc 0.67568 roc_auc 0.63000 prc_auc 0.81930[0m
[92maverage training of epoch 9: loss -2.81416 acc 0.66225 roc_auc 0.52980 prc_auc 0.72185[0m
[93maverage test of epoch 9: loss -2.93182 acc 0.67568 roc_auc 0.67667 prc_auc 0.83188[0m
[92maverage training of epoch 10: loss -3.03083 acc 0.66225 roc_auc 0.44098 prc_auc 0.62544[0m
[93maverage test of epoch 10: loss -3.14036 acc 0.67568 roc_auc 0.59667 prc_auc 0.79550[0m
[92maverage training of epoch 11: loss -3.23426 acc 0.66225 roc_auc 0.48000 prc_auc 0.68840[0m
[93maverage test of epoch 11: loss -3.34419 acc 0.67568 roc_auc 0.59000 prc_auc 0.78579[0m
[92maverage training of epoch 12: loss -3.43853 acc 0.66225 roc_auc 0.44314 prc_auc 0.61913[0m
[93maverage test of epoch 12: loss -3.55188 acc 0.67568 roc_auc 0.57667 prc_auc 0.74542[0m
[92maverage training of epoch 13: loss -3.64111 acc 0.66225 roc_auc 0.46137 prc_auc 0.62690[0m
[93maverage test of epoch 13: loss -3.75238 acc 0.67568 roc_auc 0.67333 prc_auc 0.75502[0m
[92maverage training of epoch 14: loss -3.83730 acc 0.66225 roc_auc 0.49333 prc_auc 0.65873[0m
[93maverage test of epoch 14: loss -3.93658 acc 0.67568 roc_auc 0.59000 prc_auc 0.79565[0m
[92maverage training of epoch 15: loss -4.02660 acc 0.66225 roc_auc 0.53510 prc_auc 0.67876[0m
[93maverage test of epoch 15: loss -4.13307 acc 0.67568 roc_auc 0.47333 prc_auc 0.71293[0m
[92maverage training of epoch 16: loss -4.21601 acc 0.66225 roc_auc 0.41843 prc_auc 0.62556[0m
[93maverage test of epoch 16: loss -4.33723 acc 0.67568 roc_auc 0.77000 prc_auc 0.85026[0m
[92maverage training of epoch 17: loss -4.40438 acc 0.66225 roc_auc 0.44647 prc_auc 0.65357[0m
[93maverage test of epoch 17: loss -4.51104 acc 0.67568 roc_auc 0.46000 prc_auc 0.65758[0m
[92maverage training of epoch 18: loss -4.59174 acc 0.66225 roc_auc 0.42373 prc_auc 0.62081[0m
[93maverage test of epoch 18: loss -4.69532 acc 0.67568 roc_auc 0.39000 prc_auc 0.62794[0m
[92maverage training of epoch 19: loss -4.77183 acc 0.66225 roc_auc 0.46039 prc_auc 0.67062[0m
[93maverage test of epoch 19: loss -4.87293 acc 0.67568 roc_auc 0.37000 prc_auc 0.60710[0m
[92maverage training of epoch 20: loss -4.94930 acc 0.66225 roc_auc 0.37863 prc_auc 0.58500[0m
[93maverage test of epoch 20: loss -5.05491 acc 0.67568 roc_auc 0.55667 prc_auc 0.71444[0m
[92maverage training of epoch 21: loss -5.12993 acc 0.66225 roc_auc 0.43216 prc_auc 0.61546[0m
[93maverage test of epoch 21: loss -5.23605 acc 0.67568 roc_auc 0.63333 prc_auc 0.76439[0m
[92maverage training of epoch 22: loss -5.30231 acc 0.66225 roc_auc 0.45941 prc_auc 0.64832[0m
[93maverage test of epoch 22: loss -5.41510 acc 0.67568 roc_auc 0.59000 prc_auc 0.74704[0m
[92maverage training of epoch 23: loss -5.48190 acc 0.66225 roc_auc 0.40961 prc_auc 0.59626[0m
[93maverage test of epoch 23: loss -5.58398 acc 0.67568 roc_auc 0.41000 prc_auc 0.67369[0m
[92maverage training of epoch 24: loss -5.65398 acc 0.66225 roc_auc 0.40686 prc_auc 0.59566[0m
[93maverage test of epoch 24: loss -5.76049 acc 0.67568 roc_auc 0.46000 prc_auc 0.71581[0m
[92maverage training of epoch 25: loss -5.83040 acc 0.66225 roc_auc 0.44647 prc_auc 0.63845[0m
[93maverage test of epoch 25: loss -5.93876 acc 0.67568 roc_auc 0.66500 prc_auc 0.82803[0m
[92maverage training of epoch 26: loss -6.00031 acc 0.66225 roc_auc 0.35961 prc_auc 0.56718[0m
[93maverage test of epoch 26: loss -6.11207 acc 0.67568 roc_auc 0.55000 prc_auc 0.70065[0m
[92maverage training of epoch 27: loss -6.17215 acc 0.66225 roc_auc 0.41412 prc_auc 0.62042[0m
[93maverage test of epoch 27: loss -6.28243 acc 0.67568 roc_auc 0.40500 prc_auc 0.63122[0m
[92maverage training of epoch 28: loss -6.34419 acc 0.66225 roc_auc 0.37098 prc_auc 0.57383[0m
[93maverage test of epoch 28: loss -6.45282 acc 0.67568 roc_auc 0.36500 prc_auc 0.65131[0m
[92maverage training of epoch 29: loss -6.51667 acc 0.66225 roc_auc 0.41549 prc_auc 0.62460[0m
[93maverage test of epoch 29: loss -6.62368 acc 0.67568 roc_auc 0.48333 prc_auc 0.64389[0m
[92maverage training of epoch 30: loss -6.68583 acc 0.66225 roc_auc 0.39647 prc_auc 0.59615[0m
[93maverage test of epoch 30: loss -6.79486 acc 0.67568 roc_auc 0.68333 prc_auc 0.76176[0m
[92maverage training of epoch 31: loss -6.85541 acc 0.66225 roc_auc 0.38333 prc_auc 0.60863[0m
[93maverage test of epoch 31: loss -6.96736 acc 0.67568 roc_auc 0.51333 prc_auc 0.73080[0m
[92maverage training of epoch 32: loss -7.02646 acc 0.66225 roc_auc 0.39922 prc_auc 0.60095[0m
[93maverage test of epoch 32: loss -7.13699 acc 0.67568 roc_auc 0.54667 prc_auc 0.79163[0m
[92maverage training of epoch 33: loss -7.19565 acc 0.66225 roc_auc 0.39569 prc_auc 0.59027[0m
[93maverage test of epoch 33: loss -7.30586 acc 0.67568 roc_auc 0.54667 prc_auc 0.72342[0m
[92maverage training of epoch 34: loss -7.36436 acc 0.66225 roc_auc 0.39039 prc_auc 0.57921[0m
[93maverage test of epoch 34: loss -7.47228 acc 0.67568 roc_auc 0.43667 prc_auc 0.67700[0m
[92maverage training of epoch 35: loss -7.53310 acc 0.66225 roc_auc 0.37569 prc_auc 0.57535[0m
[93maverage test of epoch 35: loss -7.64244 acc 0.67568 roc_auc 0.43000 prc_auc 0.67668[0m
[92maverage training of epoch 36: loss -7.69980 acc 0.66225 roc_auc 0.38922 prc_auc 0.59137[0m
[93maverage test of epoch 36: loss -7.81232 acc 0.67568 roc_auc 0.52167 prc_auc 0.73635[0m
[92maverage training of epoch 37: loss -7.86818 acc 0.66225 roc_auc 0.36824 prc_auc 0.57036[0m
[93maverage test of epoch 37: loss -7.98195 acc 0.67568 roc_auc 0.36667 prc_auc 0.63448[0m
[92maverage training of epoch 38: loss -8.03815 acc 0.66225 roc_auc 0.36961 prc_auc 0.56707[0m
[93maverage test of epoch 38: loss -8.15324 acc 0.67568 roc_auc 0.63833 prc_auc 0.81030[0m
[92maverage training of epoch 39: loss -8.20515 acc 0.66225 roc_auc 0.39206 prc_auc 0.59465[0m
[93maverage test of epoch 39: loss -8.32048 acc 0.67568 roc_auc 0.65667 prc_auc 0.79571[0m
[92maverage training of epoch 40: loss -8.37301 acc 0.66225 roc_auc 0.37294 prc_auc 0.57965[0m
[93maverage test of epoch 40: loss -8.48775 acc 0.67568 roc_auc 0.56167 prc_auc 0.74547[0m
[92maverage training of epoch 41: loss -8.54005 acc 0.66225 roc_auc 0.37431 prc_auc 0.57234[0m
[93maverage test of epoch 41: loss -8.65743 acc 0.67568 roc_auc 0.64167 prc_auc 0.80360[0m
[92maverage training of epoch 42: loss -8.70781 acc 0.66225 roc_auc 0.36608 prc_auc 0.57729[0m
[93maverage test of epoch 42: loss -8.82520 acc 0.67568 roc_auc 0.52333 prc_auc 0.72054[0m
[92maverage training of epoch 43: loss -8.87597 acc 0.66225 roc_auc 0.34549 prc_auc 0.55272[0m
[93maverage test of epoch 43: loss -8.99457 acc 0.67568 roc_auc 0.75500 prc_auc 0.89023[0m
[92maverage training of epoch 44: loss -9.04337 acc 0.66225 roc_auc 0.37431 prc_auc 0.57547[0m
[93maverage test of epoch 44: loss -9.15922 acc 0.67568 roc_auc 0.37167 prc_auc 0.64022[0m
[92maverage training of epoch 45: loss -9.21046 acc 0.66225 roc_auc 0.37039 prc_auc 0.56821[0m
[93maverage test of epoch 45: loss -9.32834 acc 0.67568 roc_auc 0.60500 prc_auc 0.76979[0m
[92maverage training of epoch 46: loss -9.37659 acc 0.66225 roc_auc 0.36745 prc_auc 0.56773[0m
[93maverage test of epoch 46: loss -9.49766 acc 0.67568 roc_auc 0.57167 prc_auc 0.72618[0m
[92maverage training of epoch 47: loss -9.54514 acc 0.66225 roc_auc 0.36157 prc_auc 0.56819[0m
[93maverage test of epoch 47: loss -9.66376 acc 0.67568 roc_auc 0.48667 prc_auc 0.75278[0m
[92maverage training of epoch 48: loss -9.71192 acc 0.66225 roc_auc 0.38059 prc_auc 0.58050[0m
[93maverage test of epoch 48: loss -9.83247 acc 0.67568 roc_auc 0.51667 prc_auc 0.72797[0m
[92maverage training of epoch 49: loss -9.87960 acc 0.66225 roc_auc 0.37510 prc_auc 0.57334[0m
[93maverage test of epoch 49: loss -9.99915 acc 0.67568 roc_auc 0.45500 prc_auc 0.72073[0m
[92maverage training of epoch 50: loss -10.04638 acc 0.66225 roc_auc 0.36373 prc_auc 0.56524[0m
[93maverage test of epoch 50: loss -10.16745 acc 0.67568 roc_auc 0.67667 prc_auc 0.81249[0m
[92maverage training of epoch 51: loss -10.21251 acc 0.66225 roc_auc 0.36471 prc_auc 0.56824[0m
[93maverage test of epoch 51: loss -10.33645 acc 0.67568 roc_auc 0.57167 prc_auc 0.77173[0m
[92maverage training of epoch 52: loss -10.37979 acc 0.66225 roc_auc 0.36657 prc_auc 0.56630[0m
[93maverage test of epoch 52: loss -10.50334 acc 0.67568 roc_auc 0.54000 prc_auc 0.69861[0m
[92maverage training of epoch 53: loss -10.54655 acc 0.66225 roc_auc 0.37333 prc_auc 0.57324[0m
[93maverage test of epoch 53: loss -10.66964 acc 0.67568 roc_auc 0.44500 prc_auc 0.66931[0m
[92maverage training of epoch 54: loss -10.71336 acc 0.66225 roc_auc 0.37078 prc_auc 0.56871[0m
[93maverage test of epoch 54: loss -10.83804 acc 0.67568 roc_auc 0.48167 prc_auc 0.65671[0m
[92maverage training of epoch 55: loss -10.88050 acc 0.66225 roc_auc 0.37000 prc_auc 0.57018[0m
[93maverage test of epoch 55: loss -11.00582 acc 0.67568 roc_auc 0.45000 prc_auc 0.66135[0m
[92maverage training of epoch 56: loss -11.04731 acc 0.66225 roc_auc 0.36804 prc_auc 0.56998[0m
[93maverage test of epoch 56: loss -11.17412 acc 0.67568 roc_auc 0.63000 prc_auc 0.74530[0m
[92maverage training of epoch 57: loss -11.21431 acc 0.66225 roc_auc 0.37137 prc_auc 0.56846[0m
[93maverage test of epoch 57: loss -11.34157 acc 0.67568 roc_auc 0.44000 prc_auc 0.63685[0m
[92maverage training of epoch 58: loss -11.38129 acc 0.66225 roc_auc 0.37686 prc_auc 0.57751[0m
[93maverage test of epoch 58: loss -11.50900 acc 0.67568 roc_auc 0.48500 prc_auc 0.66604[0m
[92maverage training of epoch 59: loss -11.54758 acc 0.66225 roc_auc 0.37137 prc_auc 0.57088[0m
[93maverage test of epoch 59: loss -11.67598 acc 0.67568 roc_auc 0.44167 prc_auc 0.70887[0m
[92maverage training of epoch 60: loss -11.71424 acc 0.66225 roc_auc 0.36608 prc_auc 0.56818[0m
[93maverage test of epoch 60: loss -11.84384 acc 0.67568 roc_auc 0.53333 prc_auc 0.71266[0m
[92maverage training of epoch 61: loss -11.88062 acc 0.66225 roc_auc 0.37294 prc_auc 0.57007[0m
[93maverage test of epoch 61: loss -12.01103 acc 0.67568 roc_auc 0.41167 prc_auc 0.60944[0m
[92maverage training of epoch 62: loss -12.04761 acc 0.66225 roc_auc 0.36863 prc_auc 0.57293[0m
[93maverage test of epoch 62: loss -12.17823 acc 0.67568 roc_auc 0.53667 prc_auc 0.71212[0m
[92maverage training of epoch 63: loss -12.21432 acc 0.66225 roc_auc 0.36824 prc_auc 0.57149[0m
[93maverage test of epoch 63: loss -12.34436 acc 0.67568 roc_auc 0.41500 prc_auc 0.64916[0m
[92maverage training of epoch 64: loss -12.38016 acc 0.66225 roc_auc 0.37549 prc_auc 0.57320[0m
[93maverage test of epoch 64: loss -12.51297 acc 0.67568 roc_auc 0.39333 prc_auc 0.63613[0m
[92maverage training of epoch 65: loss -12.54732 acc 0.66225 roc_auc 0.36853 prc_auc 0.56962[0m
[93maverage test of epoch 65: loss -12.68014 acc 0.67568 roc_auc 0.42667 prc_auc 0.65498[0m
[92maverage training of epoch 66: loss -12.71385 acc 0.66225 roc_auc 0.37137 prc_auc 0.57230[0m
[93maverage test of epoch 66: loss -12.84695 acc 0.67568 roc_auc 0.46333 prc_auc 0.68905[0m
[92maverage training of epoch 67: loss -12.88048 acc 0.66225 roc_auc 0.37255 prc_auc 0.57115[0m
[93maverage test of epoch 67: loss -13.01503 acc 0.67568 roc_auc 0.40833 prc_auc 0.63265[0m
[92maverage training of epoch 68: loss -13.04706 acc 0.66225 roc_auc 0.36578 prc_auc 0.56628[0m
[93maverage test of epoch 68: loss -13.18257 acc 0.67568 roc_auc 0.42000 prc_auc 0.64088[0m
[92maverage training of epoch 69: loss -13.21330 acc 0.66225 roc_auc 0.36892 prc_auc 0.56660[0m
[93maverage test of epoch 69: loss -13.34914 acc 0.67568 roc_auc 0.62833 prc_auc 0.72761[0m
[92maverage training of epoch 70: loss -13.37985 acc 0.66225 roc_auc 0.36510 prc_auc 0.56709[0m
[93maverage test of epoch 70: loss -13.51663 acc 0.67568 roc_auc 0.44000 prc_auc 0.63655[0m
[92maverage training of epoch 71: loss -13.54660 acc 0.66225 roc_auc 0.37304 prc_auc 0.57011[0m
[93maverage test of epoch 71: loss -13.68406 acc 0.67568 roc_auc 0.41000 prc_auc 0.64612[0m
[92maverage training of epoch 72: loss -13.71317 acc 0.66225 roc_auc 0.36706 prc_auc 0.56775[0m
[93maverage test of epoch 72: loss -13.85134 acc 0.67568 roc_auc 0.56167 prc_auc 0.71606[0m
[92maverage training of epoch 73: loss -13.87992 acc 0.66225 roc_auc 0.36922 prc_auc 0.56806[0m
[93maverage test of epoch 73: loss -14.01883 acc 0.67568 roc_auc 0.48000 prc_auc 0.66130[0m
[92maverage training of epoch 74: loss -14.04645 acc 0.66225 roc_auc 0.37245 prc_auc 0.57143[0m
[93maverage test of epoch 74: loss -14.18561 acc 0.67568 roc_auc 0.48667 prc_auc 0.68179[0m
[92maverage training of epoch 75: loss -14.21302 acc 0.66225 roc_auc 0.36471 prc_auc 0.56639[0m
[93maverage test of epoch 75: loss -14.35272 acc 0.67568 roc_auc 0.42000 prc_auc 0.64907[0m
[92maverage training of epoch 76: loss -14.37957 acc 0.66225 roc_auc 0.36794 prc_auc 0.56688[0m
[93maverage test of epoch 76: loss -14.51996 acc 0.67568 roc_auc 0.52000 prc_auc 0.73768[0m
[92maverage training of epoch 77: loss -14.54604 acc 0.66225 roc_auc 0.36873 prc_auc 0.56771[0m
[93maverage test of epoch 77: loss -14.68720 acc 0.67568 roc_auc 0.23667 prc_auc 0.54948[0m
[92maverage training of epoch 78: loss -14.71248 acc 0.66225 roc_auc 0.36775 prc_auc 0.56667[0m
[93maverage test of epoch 78: loss -14.85434 acc 0.67568 roc_auc 0.48833 prc_auc 0.66463[0m
[92maverage training of epoch 79: loss -14.87906 acc 0.66225 roc_auc 0.37147 prc_auc 0.56895[0m
[93maverage test of epoch 79: loss -15.02131 acc 0.67568 roc_auc 0.27167 prc_auc 0.56032[0m
[92maverage training of epoch 80: loss -15.04536 acc 0.66225 roc_auc 0.36627 prc_auc 0.56544[0m
[93maverage test of epoch 80: loss -15.18899 acc 0.67568 roc_auc 0.34333 prc_auc 0.59901[0m
[92maverage training of epoch 81: loss -15.21188 acc 0.66225 roc_auc 0.36892 prc_auc 0.56716[0m
[93maverage test of epoch 81: loss -15.35583 acc 0.67568 roc_auc 0.49167 prc_auc 0.71142[0m
[92maverage training of epoch 82: loss -15.37863 acc 0.66225 roc_auc 0.37039 prc_auc 0.56905[0m
[93maverage test of epoch 82: loss -15.52342 acc 0.67568 roc_auc 0.50833 prc_auc 0.68922[0m
[92maverage training of epoch 83: loss -15.54490 acc 0.66225 roc_auc 0.37098 prc_auc 0.57112[0m
[93maverage test of epoch 83: loss -15.69021 acc 0.67568 roc_auc 0.49667 prc_auc 0.68001[0m
[92maverage training of epoch 84: loss -15.71145 acc 0.66225 roc_auc 0.37235 prc_auc 0.57136[0m
[93maverage test of epoch 84: loss -15.85764 acc 0.67568 roc_auc 0.52167 prc_auc 0.71842[0m
[92maverage training of epoch 85: loss -15.87762 acc 0.66225 roc_auc 0.36922 prc_auc 0.56755[0m
[93maverage test of epoch 85: loss -16.02490 acc 0.67568 roc_auc 0.42000 prc_auc 0.63947[0m
[92maverage training of epoch 86: loss -16.04444 acc 0.66225 roc_auc 0.36843 prc_auc 0.56752[0m
[93maverage test of epoch 86: loss -16.19232 acc 0.67568 roc_auc 0.65333 prc_auc 0.75648[0m
[92maverage training of epoch 87: loss -16.21093 acc 0.66225 roc_auc 0.36873 prc_auc 0.56745[0m
[93maverage test of epoch 87: loss -16.35952 acc 0.67568 roc_auc 0.63500 prc_auc 0.76189[0m
[92maverage training of epoch 88: loss -16.37739 acc 0.66225 roc_auc 0.37167 prc_auc 0.57034[0m
[93maverage test of epoch 88: loss -16.52626 acc 0.67568 roc_auc 0.42500 prc_auc 0.63496[0m
[92maverage training of epoch 89: loss -16.54397 acc 0.66225 roc_auc 0.36863 prc_auc 0.56787[0m
[93maverage test of epoch 89: loss -16.69378 acc 0.67568 roc_auc 0.57167 prc_auc 0.71671[0m
[92maverage training of epoch 90: loss -16.71026 acc 0.66225 roc_auc 0.36971 prc_auc 0.57024[0m
[93maverage test of epoch 90: loss -16.86084 acc 0.67568 roc_auc 0.48000 prc_auc 0.68097[0m
[92maverage training of epoch 91: loss -16.87671 acc 0.66225 roc_auc 0.37000 prc_auc 0.56930[0m
[93maverage test of epoch 91: loss -17.02803 acc 0.67568 roc_auc 0.61833 prc_auc 0.74883[0m
[92maverage training of epoch 92: loss -17.04325 acc 0.66225 roc_auc 0.37225 prc_auc 0.57152[0m
[93maverage test of epoch 92: loss -17.19499 acc 0.67568 roc_auc 0.67833 prc_auc 0.84234[0m
[92maverage training of epoch 93: loss -17.20965 acc 0.66225 roc_auc 0.36892 prc_auc 0.56907[0m
[93maverage test of epoch 93: loss -17.36252 acc 0.67568 roc_auc 0.59167 prc_auc 0.75229[0m
[92maverage training of epoch 94: loss -17.37621 acc 0.66225 roc_auc 0.36951 prc_auc 0.56834[0m
[93maverage test of epoch 94: loss -17.52953 acc 0.67568 roc_auc 0.50000 prc_auc 0.69061[0m
[92maverage training of epoch 95: loss -17.54263 acc 0.66225 roc_auc 0.37088 prc_auc 0.57289[0m
[93maverage test of epoch 95: loss -17.69670 acc 0.67568 roc_auc 0.59167 prc_auc 0.74893[0m
[92maverage training of epoch 96: loss -17.70913 acc 0.66225 roc_auc 0.36941 prc_auc 0.56758[0m
[93maverage test of epoch 96: loss -17.86394 acc 0.67568 roc_auc 0.57333 prc_auc 0.72491[0m
[92maverage training of epoch 97: loss -17.87560 acc 0.66225 roc_auc 0.36784 prc_auc 0.56663[0m
[93maverage test of epoch 97: loss -18.03106 acc 0.67568 roc_auc 0.55000 prc_auc 0.70762[0m
[92maverage training of epoch 98: loss -18.04192 acc 0.66225 roc_auc 0.36686 prc_auc 0.56528[0m
[93maverage test of epoch 98: loss -18.19817 acc 0.67568 roc_auc 0.42333 prc_auc 0.64856[0m
[92maverage training of epoch 99: loss -18.20850 acc 0.66225 roc_auc 0.36912 prc_auc 0.56728[0m
[93maverage test of epoch 99: loss -18.36538 acc 0.67568 roc_auc 0.53333 prc_auc 0.69753[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.0003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.68663 ROC_AUC (avg): 0.54749 PRC_AUC (avg): 0.69726 

Average forward propagation time taken(ms): 3.958627060823161
Average backward propagation time taken(ms): 1.5106939301455582

