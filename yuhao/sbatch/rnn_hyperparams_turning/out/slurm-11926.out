# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 1)
('lr', 0.0003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-23-01-16/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-23-01-16/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 16,
 'epochs': 50,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 8,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.0003,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 2,
 'num_workers': 8,
 'number_of_mlp_layer': 1,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-17-23-01-16',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 50, 'learning_rate': 0.0003, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -1.48731 acc 0.66667 roc_auc 0.42100 prc_auc 0.64386[0m
[93maverage test of epoch 0: loss -2.55460 acc 0.65789 roc_auc 0.44615 prc_auc 0.61553[0m
[92maverage training of epoch 1: loss -3.59730 acc 0.66667 roc_auc 0.42380 prc_auc 0.62978[0m
[93maverage test of epoch 1: loss -4.77057 acc 0.65789 roc_auc 0.34462 prc_auc 0.57969[0m
[92maverage training of epoch 2: loss -5.96539 acc 0.66667 roc_auc 0.39030 prc_auc 0.60078[0m
[93maverage test of epoch 2: loss -7.16665 acc 0.65789 roc_auc 0.31385 prc_auc 0.58379[0m
[92maverage training of epoch 3: loss -8.56530 acc 0.66667 roc_auc 0.40090 prc_auc 0.61239[0m
[93maverage test of epoch 3: loss -9.90292 acc 0.65789 roc_auc 0.52923 prc_auc 0.73291[0m
[92maverage training of epoch 4: loss -11.23116 acc 0.66667 roc_auc 0.42420 prc_auc 0.63479[0m
[93maverage test of epoch 4: loss -12.45181 acc 0.65789 roc_auc 0.44923 prc_auc 0.62832[0m
[92maverage training of epoch 5: loss -13.78577 acc 0.66667 roc_auc 0.40660 prc_auc 0.61476[0m
[93maverage test of epoch 5: loss -15.02911 acc 0.65789 roc_auc 0.57077 prc_auc 0.78362[0m
[92maverage training of epoch 6: loss -16.41432 acc 0.66667 roc_auc 0.42540 prc_auc 0.63480[0m
[93maverage test of epoch 6: loss -17.66143 acc 0.65789 roc_auc 0.45846 prc_auc 0.67540[0m
[92maverage training of epoch 7: loss -19.10285 acc 0.66667 roc_auc 0.41250 prc_auc 0.62607[0m
[93maverage test of epoch 7: loss -20.38875 acc 0.65789 roc_auc 0.48308 prc_auc 0.64712[0m
[92maverage training of epoch 8: loss -21.87066 acc 0.66667 roc_auc 0.41820 prc_auc 0.62117[0m
[93maverage test of epoch 8: loss -23.17281 acc 0.65789 roc_auc 0.41846 prc_auc 0.62221[0m
[92maverage training of epoch 9: loss -24.74381 acc 0.66667 roc_auc 0.40590 prc_auc 0.61867[0m
[93maverage test of epoch 9: loss -26.11925 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 10: loss -27.73190 acc 0.66667 roc_auc 0.40410 prc_auc 0.62046[0m
[93maverage test of epoch 10: loss -29.14167 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 11: loss -30.82312 acc 0.66667 roc_auc 0.44000 prc_auc 0.64152[0m
[93maverage test of epoch 11: loss -32.29418 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 12: loss -34.03892 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 12: loss -35.56191 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 13: loss -37.38429 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 13: loss -38.92874 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 14: loss -40.85252 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 14: loss -42.45811 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 15: loss -44.44617 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 15: loss -46.10712 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 16: loss -48.17124 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 16: loss -49.87082 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 17: loss -52.01298 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 17: loss -53.76296 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 18: loss -55.97859 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 18: loss -57.77955 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -60.07681 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 19: loss -61.93033 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -64.29842 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 20: loss -66.19946 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -68.65630 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 21: loss -70.60380 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -73.14573 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 22: loss -75.14388 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -77.76477 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 23: loss -79.81445 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -82.52614 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 24: loss -84.62472 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -87.41975 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 25: loss -89.57376 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -92.45249 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 26: loss -94.65891 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -97.62063 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 27: loss -99.87881 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -102.93046 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 28: loss -105.23293 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -108.37873 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 29: loss -110.72874 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -113.96197 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 30: loss -116.36267 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -119.68057 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 31: loss -122.13265 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -125.53418 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 32: loss -128.02774 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -131.52845 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 33: loss -134.07233 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -137.65852 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -140.25063 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -143.92417 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -146.56545 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -150.32993 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -153.01796 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -156.87510 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -159.60770 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -163.55688 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -166.33831 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -170.37877 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -173.20481 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -177.33805 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -180.21035 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -184.43804 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -187.35535 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -191.67762 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -194.64025 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -199.05458 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -202.06259 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -206.57064 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -209.62185 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -214.22441 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -217.32016 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -222.01866 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -225.15676 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -229.94981 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -233.12869 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -238.01415 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -241.23256 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -246.21442 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -249.47034 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.34219 acc 0.66667 roc_auc 0.47320 prc_auc 0.64614[0m
[93maverage test of epoch 0: loss -0.96743 acc 0.65789 roc_auc 0.40923 prc_auc 0.60081[0m
[92maverage training of epoch 1: loss -1.41320 acc 0.66667 roc_auc 0.48440 prc_auc 0.66454[0m
[93maverage test of epoch 1: loss -1.73957 acc 0.65789 roc_auc 0.51385 prc_auc 0.69047[0m
[92maverage training of epoch 2: loss -2.13177 acc 0.66667 roc_auc 0.46380 prc_auc 0.63233[0m
[93maverage test of epoch 2: loss -2.47208 acc 0.65789 roc_auc 0.54769 prc_auc 0.70269[0m
[92maverage training of epoch 3: loss -2.91214 acc 0.66667 roc_auc 0.42680 prc_auc 0.63950[0m
[93maverage test of epoch 3: loss -3.30367 acc 0.65789 roc_auc 0.46462 prc_auc 0.68926[0m
[92maverage training of epoch 4: loss -3.78894 acc 0.66667 roc_auc 0.45130 prc_auc 0.64750[0m
[93maverage test of epoch 4: loss -4.18980 acc 0.65789 roc_auc 0.56000 prc_auc 0.69773[0m
[92maverage training of epoch 5: loss -4.69559 acc 0.66667 roc_auc 0.44700 prc_auc 0.63080[0m
[93maverage test of epoch 5: loss -5.05962 acc 0.65789 roc_auc 0.45692 prc_auc 0.70973[0m
[92maverage training of epoch 6: loss -5.62992 acc 0.66667 roc_auc 0.43080 prc_auc 0.61991[0m
[93maverage test of epoch 6: loss -6.17063 acc 0.65789 roc_auc 0.51077 prc_auc 0.67361[0m
[92maverage training of epoch 7: loss -7.00119 acc 0.66667 roc_auc 0.47610 prc_auc 0.64136[0m
[93maverage test of epoch 7: loss -7.63407 acc 0.65789 roc_auc 0.38308 prc_auc 0.61236[0m
[92maverage training of epoch 8: loss -8.46384 acc 0.66667 roc_auc 0.43220 prc_auc 0.61573[0m
[93maverage test of epoch 8: loss -9.12358 acc 0.65789 roc_auc 0.56000 prc_auc 0.72463[0m
[92maverage training of epoch 9: loss -9.98456 acc 0.66667 roc_auc 0.43160 prc_auc 0.62672[0m
[93maverage test of epoch 9: loss -10.62939 acc 0.65789 roc_auc 0.38615 prc_auc 0.59484[0m
[92maverage training of epoch 10: loss -11.54053 acc 0.66667 roc_auc 0.45590 prc_auc 0.63700[0m
[93maverage test of epoch 10: loss -12.25039 acc 0.65789 roc_auc 0.59538 prc_auc 0.73861[0m
[92maverage training of epoch 11: loss -13.20941 acc 0.66667 roc_auc 0.44640 prc_auc 0.63579[0m
[93maverage test of epoch 11: loss -13.98884 acc 0.65789 roc_auc 0.52000 prc_auc 0.66703[0m
[92maverage training of epoch 12: loss -15.02033 acc 0.66667 roc_auc 0.46020 prc_auc 0.64151[0m
[93maverage test of epoch 12: loss -15.89015 acc 0.65789 roc_auc 0.56769 prc_auc 0.69215[0m
[92maverage training of epoch 13: loss -16.98549 acc 0.66667 roc_auc 0.46560 prc_auc 0.64705[0m
[93maverage test of epoch 13: loss -17.90187 acc 0.65789 roc_auc 0.48000 prc_auc 0.64902[0m
[92maverage training of epoch 14: loss -19.06899 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 14: loss -20.01747 acc 0.65789 roc_auc 0.59385 prc_auc 0.70346[0m
[92maverage training of epoch 15: loss -21.22493 acc 0.66667 roc_auc 0.52000 prc_auc 0.67568[0m
[93maverage test of epoch 15: loss -22.17395 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 16: loss -23.44650 acc 0.66667 roc_auc 0.47000 prc_auc 0.65378[0m
[93maverage test of epoch 16: loss -24.46354 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 17: loss -25.77466 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 17: loss -26.83558 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 18: loss -28.20726 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 18: loss -29.31730 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -30.73940 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 19: loss -31.87225 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -33.37077 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 20: loss -34.57507 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -36.11679 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 21: loss -37.35504 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -38.96545 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 22: loss -40.25266 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -41.92925 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 23: loss -43.25166 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -44.99034 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 24: loss -46.35598 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -48.14813 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 25: loss -49.56696 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -51.42390 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 26: loss -52.87326 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -54.79617 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 27: loss -56.30034 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -58.28054 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 28: loss -59.82484 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -61.87239 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 29: loss -63.46120 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -65.57651 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 30: loss -67.20381 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -69.38837 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 31: loss -71.06042 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -73.30623 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 32: loss -75.01880 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -77.32874 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 33: loss -79.07722 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -81.45041 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -83.24226 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -85.67794 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -87.50390 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -90.01422 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -91.87768 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -94.45702 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -96.36748 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -99.00929 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -100.96052 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -103.67057 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -105.66341 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -108.44519 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -110.47430 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -113.32943 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -115.40213 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -118.32790 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -120.43613 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -123.43735 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -125.58849 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -128.66139 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -130.84815 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -133.99818 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -136.22585 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -139.44879 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -141.71453 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -145.01397 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -147.32062 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -150.69263 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -153.03703 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -156.48525 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -158.86655 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.66465 acc 0.63333 roc_auc 0.47260 prc_auc 0.67594[0m
[93maverage test of epoch 0: loss -1.03914 acc 0.65789 roc_auc 0.87385 prc_auc 0.93783[0m
[92maverage training of epoch 1: loss -1.40552 acc 0.66667 roc_auc 0.58680 prc_auc 0.73151[0m
[93maverage test of epoch 1: loss -1.93330 acc 0.65789 roc_auc 0.82769 prc_auc 0.85577[0m
[92maverage training of epoch 2: loss -2.64714 acc 0.66667 roc_auc 0.72900 prc_auc 0.79037[0m
[93maverage test of epoch 2: loss -3.47789 acc 0.65789 roc_auc 0.80615 prc_auc 0.87979[0m
[92maverage training of epoch 3: loss -4.31854 acc 0.66667 roc_auc 0.56420 prc_auc 0.69700[0m
[93maverage test of epoch 3: loss -5.11841 acc 0.65789 roc_auc 0.66154 prc_auc 0.81848[0m
[92maverage training of epoch 4: loss -5.95343 acc 0.66667 roc_auc 0.45680 prc_auc 0.66236[0m
[93maverage test of epoch 4: loss -6.75510 acc 0.65789 roc_auc 0.73231 prc_auc 0.85579[0m
[92maverage training of epoch 5: loss -7.65929 acc 0.66667 roc_auc 0.43470 prc_auc 0.63767[0m
[93maverage test of epoch 5: loss -8.49745 acc 0.65789 roc_auc 0.51231 prc_auc 0.76236[0m
[92maverage training of epoch 6: loss -9.48619 acc 0.66667 roc_auc 0.43070 prc_auc 0.63364[0m
[93maverage test of epoch 6: loss -10.34180 acc 0.65789 roc_auc 0.39538 prc_auc 0.61319[0m
[92maverage training of epoch 7: loss -11.38568 acc 0.66667 roc_auc 0.44120 prc_auc 0.64237[0m
[93maverage test of epoch 7: loss -12.23500 acc 0.65789 roc_auc 0.52923 prc_auc 0.69514[0m
[92maverage training of epoch 8: loss -13.32139 acc 0.66667 roc_auc 0.42840 prc_auc 0.63160[0m
[93maverage test of epoch 8: loss -14.24438 acc 0.65789 roc_auc 0.58000 prc_auc 0.69785[0m
[92maverage training of epoch 9: loss -15.35708 acc 0.66667 roc_auc 0.43920 prc_auc 0.64004[0m
[93maverage test of epoch 9: loss -16.30642 acc 0.65789 roc_auc 0.59077 prc_auc 0.70261[0m
[92maverage training of epoch 10: loss -17.47254 acc 0.66667 roc_auc 0.43570 prc_auc 0.63416[0m
[93maverage test of epoch 10: loss -18.42767 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 11: loss -19.66315 acc 0.66667 roc_auc 0.42000 prc_auc 0.63411[0m
[93maverage test of epoch 11: loss -20.64622 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 12: loss -21.94921 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 12: loss -22.96849 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 13: loss -24.32637 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 13: loss -25.39745 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 14: loss -26.80815 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 14: loss -27.91343 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 15: loss -29.38689 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 15: loss -30.52827 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 16: loss -32.08621 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 16: loss -33.27885 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 17: loss -34.88463 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 17: loss -36.12045 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 18: loss -37.79702 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 18: loss -39.06841 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -40.82806 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 19: loss -42.13884 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -43.97380 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 20: loss -45.32982 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -47.21914 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 21: loss -48.62105 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -50.58514 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 22: loss -52.02654 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -54.06165 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 23: loss -55.55029 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -57.65026 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 24: loss -59.18401 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -61.35476 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 25: loss -62.92238 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -65.16062 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 26: loss -66.76216 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -69.07951 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 27: loss -70.71205 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -73.09854 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 28: loss -74.78212 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -77.23792 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 29: loss -78.95465 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -81.47884 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 30: loss -83.23832 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -85.83774 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 31: loss -87.63335 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -90.30658 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 32: loss -92.13801 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -94.88445 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 33: loss -96.75684 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -99.57821 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -101.48607 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -104.38191 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -106.32773 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -109.30007 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -111.28430 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -114.33420 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -116.35139 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -119.47113 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -121.52764 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -124.71991 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -126.80461 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -130.07625 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -132.19540 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -135.54032 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -137.69294 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -141.11368 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -143.30015 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -146.79548 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -149.01564 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -152.58728 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -154.84264 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -158.48884 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -160.77260 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -164.49342 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -166.80226 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -170.59157 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -172.92801 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -176.79219 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -179.15106 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -183.08935 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -185.47565 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.18513 acc 0.33775 roc_auc 0.44882 prc_auc 0.63725[0m
[93maverage test of epoch 0: loss -0.56899 acc 0.32432 roc_auc 0.33333 prc_auc 0.65559[0m
[92maverage training of epoch 1: loss -0.87266 acc 0.38411 roc_auc 0.43784 prc_auc 0.62937[0m
[93maverage test of epoch 1: loss -1.37179 acc 0.70270 roc_auc 0.51333 prc_auc 0.71326[0m
[92maverage training of epoch 2: loss -2.05719 acc 0.66225 roc_auc 0.41451 prc_auc 0.61165[0m
[93maverage test of epoch 2: loss -2.73337 acc 0.67568 roc_auc 0.56333 prc_auc 0.77854[0m
[92maverage training of epoch 3: loss -3.34981 acc 0.66225 roc_auc 0.42176 prc_auc 0.60662[0m
[93maverage test of epoch 3: loss -3.95600 acc 0.67568 roc_auc 0.51333 prc_auc 0.69089[0m
[92maverage training of epoch 4: loss -4.52459 acc 0.66225 roc_auc 0.41980 prc_auc 0.60425[0m
[93maverage test of epoch 4: loss -5.12459 acc 0.67568 roc_auc 0.55000 prc_auc 0.78549[0m
[92maverage training of epoch 5: loss -5.69407 acc 0.66225 roc_auc 0.41843 prc_auc 0.59927[0m
[93maverage test of epoch 5: loss -6.30345 acc 0.67568 roc_auc 0.63000 prc_auc 0.75076[0m
[92maverage training of epoch 6: loss -6.87661 acc 0.66225 roc_auc 0.41804 prc_auc 0.60669[0m
[93maverage test of epoch 6: loss -7.50287 acc 0.67568 roc_auc 0.46333 prc_auc 0.73834[0m
[92maverage training of epoch 7: loss -8.08706 acc 0.66225 roc_auc 0.42235 prc_auc 0.60909[0m
[93maverage test of epoch 7: loss -8.73445 acc 0.67568 roc_auc 0.41667 prc_auc 0.65065[0m
[92maverage training of epoch 8: loss -9.33637 acc 0.66225 roc_auc 0.43275 prc_auc 0.61914[0m
[93maverage test of epoch 8: loss -10.00849 acc 0.67568 roc_auc 0.59333 prc_auc 0.75479[0m
[92maverage training of epoch 9: loss -10.63504 acc 0.66225 roc_auc 0.40412 prc_auc 0.59132[0m
[93maverage test of epoch 9: loss -11.34411 acc 0.67568 roc_auc 0.47667 prc_auc 0.68991[0m
[92maverage training of epoch 10: loss -11.96873 acc 0.66225 roc_auc 0.41765 prc_auc 0.60593[0m
[93maverage test of epoch 10: loss -12.72107 acc 0.67568 roc_auc 0.30000 prc_auc 0.60725[0m
[92maverage training of epoch 11: loss -13.38223 acc 0.66225 roc_auc 0.42510 prc_auc 0.60734[0m
[93maverage test of epoch 11: loss -14.14825 acc 0.67568 roc_auc 0.31333 prc_auc 0.61534[0m
[92maverage training of epoch 12: loss -14.82670 acc 0.66225 roc_auc 0.41824 prc_auc 0.60102[0m
[93maverage test of epoch 12: loss -15.62915 acc 0.67568 roc_auc 0.61333 prc_auc 0.74935[0m
[92maverage training of epoch 13: loss -16.31874 acc 0.66225 roc_auc 0.42431 prc_auc 0.60801[0m
[93maverage test of epoch 13: loss -17.14478 acc 0.67568 roc_auc 0.43833 prc_auc 0.67059[0m
[92maverage training of epoch 14: loss -17.85214 acc 0.66225 roc_auc 0.41373 prc_auc 0.60053[0m
[93maverage test of epoch 14: loss -18.70226 acc 0.67568 roc_auc 0.36667 prc_auc 0.66617[0m
[92maverage training of epoch 15: loss -19.42817 acc 0.66225 roc_auc 0.41520 prc_auc 0.60032[0m
[93maverage test of epoch 15: loss -20.30728 acc 0.67568 roc_auc 0.41167 prc_auc 0.68471[0m
[92maverage training of epoch 16: loss -21.04808 acc 0.66225 roc_auc 0.41216 prc_auc 0.59784[0m
[93maverage test of epoch 16: loss -21.96301 acc 0.67568 roc_auc 0.45667 prc_auc 0.72052[0m
[92maverage training of epoch 17: loss -22.71714 acc 0.66225 roc_auc 0.41382 prc_auc 0.59923[0m
[93maverage test of epoch 17: loss -23.66376 acc 0.67568 roc_auc 0.37667 prc_auc 0.63046[0m
[92maverage training of epoch 18: loss -24.43331 acc 0.66225 roc_auc 0.42029 prc_auc 0.60611[0m
[93maverage test of epoch 18: loss -25.41101 acc 0.67568 roc_auc 0.44333 prc_auc 0.62233[0m
[92maverage training of epoch 19: loss -26.19822 acc 0.66225 roc_auc 0.41118 prc_auc 0.59696[0m
[93maverage test of epoch 19: loss -27.20876 acc 0.67568 roc_auc 0.62500 prc_auc 0.78247[0m
[92maverage training of epoch 20: loss -28.01718 acc 0.66225 roc_auc 0.41206 prc_auc 0.59759[0m
[93maverage test of epoch 20: loss -29.05965 acc 0.67568 roc_auc 0.45500 prc_auc 0.65908[0m
[92maverage training of epoch 21: loss -29.88653 acc 0.66225 roc_auc 0.40353 prc_auc 0.59319[0m
[93maverage test of epoch 21: loss -30.96170 acc 0.67568 roc_auc 0.38167 prc_auc 0.60330[0m
[92maverage training of epoch 22: loss -31.80871 acc 0.66225 roc_auc 0.41127 prc_auc 0.59817[0m
[93maverage test of epoch 22: loss -32.92016 acc 0.67568 roc_auc 0.44000 prc_auc 0.64866[0m
[92maverage training of epoch 23: loss -33.78215 acc 0.66225 roc_auc 0.41137 prc_auc 0.59987[0m
[93maverage test of epoch 23: loss -34.92579 acc 0.67568 roc_auc 0.42167 prc_auc 0.64879[0m
[92maverage training of epoch 24: loss -35.80960 acc 0.66225 roc_auc 0.41392 prc_auc 0.59781[0m
[93maverage test of epoch 24: loss -36.99176 acc 0.67568 roc_auc 0.48500 prc_auc 0.67786[0m
[92maverage training of epoch 25: loss -37.89082 acc 0.66225 roc_auc 0.41284 prc_auc 0.59755[0m
[93maverage test of epoch 25: loss -39.10834 acc 0.67568 roc_auc 0.40833 prc_auc 0.64641[0m
[92maverage training of epoch 26: loss -40.02607 acc 0.66225 roc_auc 0.41186 prc_auc 0.59530[0m
[93maverage test of epoch 26: loss -41.28049 acc 0.67568 roc_auc 0.56333 prc_auc 0.70467[0m
[92maverage training of epoch 27: loss -42.21169 acc 0.66225 roc_auc 0.41039 prc_auc 0.59799[0m
[93maverage test of epoch 27: loss -43.50103 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 28: loss -44.45021 acc 0.66225 roc_auc 0.41304 prc_auc 0.59912[0m
[93maverage test of epoch 28: loss -45.77290 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 29: loss -46.73723 acc 0.66225 roc_auc 0.40598 prc_auc 0.59710[0m
[93maverage test of epoch 29: loss -48.09179 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 30: loss -49.07558 acc 0.66225 roc_auc 0.41137 prc_auc 0.60679[0m
[93maverage test of epoch 30: loss -50.46595 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 31: loss -51.46357 acc 0.66225 roc_auc 0.40314 prc_auc 0.61108[0m
[93maverage test of epoch 31: loss -52.89178 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 32: loss -53.90474 acc 0.66225 roc_auc 0.40539 prc_auc 0.61785[0m
[93maverage test of epoch 32: loss -55.36814 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 33: loss -56.39603 acc 0.66225 roc_auc 0.42245 prc_auc 0.63039[0m
[93maverage test of epoch 33: loss -57.89720 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 34: loss -58.94152 acc 0.66225 roc_auc 0.46618 prc_auc 0.65187[0m
[93maverage test of epoch 34: loss -60.47812 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 35: loss -61.53763 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 35: loss -63.11261 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 36: loss -64.18769 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 36: loss -65.80117 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 37: loss -66.89126 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 37: loss -68.54106 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 38: loss -69.64708 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 38: loss -71.33482 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 39: loss -72.45626 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 39: loss -74.18341 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -75.31846 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 40: loss -77.08444 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -78.23430 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 41: loss -80.03876 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -81.20413 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 42: loss -83.04785 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -84.22734 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 43: loss -86.11139 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -87.30376 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 44: loss -89.22737 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -90.43470 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 45: loss -92.39811 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -93.61862 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 46: loss -95.62282 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -96.85743 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 47: loss -98.90150 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -100.14985 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 48: loss -102.23556 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -103.49636 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 49: loss -105.62339 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss 0.78484 acc 0.33775 roc_auc 0.43157 prc_auc 0.62699[0m
[93maverage test of epoch 0: loss 0.12360 acc 0.32432 roc_auc 0.37333 prc_auc 0.65582[0m
[92maverage training of epoch 1: loss 0.06272 acc 0.33775 roc_auc 0.48078 prc_auc 0.65503[0m
[93maverage test of epoch 1: loss 0.03136 acc 0.32432 roc_auc 0.49333 prc_auc 0.72990[0m
[92maverage training of epoch 2: loss -0.00406 acc 0.33775 roc_auc 0.45686 prc_auc 0.63644[0mUsing backend: pytorch

[93maverage test of epoch 2: loss -0.02501 acc 0.32432 roc_auc 0.45000 prc_auc 0.63130[0m
[92maverage training of epoch 3: loss -0.05645 acc 0.33775 roc_auc 0.42216 prc_auc 0.60356[0m
[93maverage test of epoch 3: loss -0.08140 acc 0.32432 roc_auc 0.49333 prc_auc 0.72556[0m
[92maverage training of epoch 4: loss -0.11488 acc 0.33775 roc_auc 0.51098 prc_auc 0.71249[0m
[93maverage test of epoch 4: loss -0.13012 acc 0.32432 roc_auc 0.42333 prc_auc 0.64672[0m
[92maverage training of epoch 5: loss -0.16536 acc 0.33775 roc_auc 0.47078 prc_auc 0.67165[0m
[93maverage test of epoch 5: loss -0.19607 acc 0.32432 roc_auc 0.61000 prc_auc 0.77504[0m
[92maverage training of epoch 6: loss -0.23281 acc 0.33775 roc_auc 0.59431 prc_auc 0.75598[0m
[93maverage test of epoch 6: loss -0.25219 acc 0.32432 roc_auc 0.43667 prc_auc 0.71128[0m
[92maverage training of epoch 7: loss -0.31189 acc 0.33775 roc_auc 0.60902 prc_auc 0.76387[0m
[93maverage test of epoch 7: loss -0.33753 acc 0.32432 roc_auc 0.49333 prc_auc 0.74767[0m
[92maverage training of epoch 8: loss -0.41055 acc 0.33775 roc_auc 0.63725 prc_auc 0.78614[0m
[93maverage test of epoch 8: loss -0.45375 acc 0.32432 roc_auc 0.58000 prc_auc 0.78971[0m
[92maverage training of epoch 9: loss -0.57222 acc 0.33775 roc_auc 0.74490 prc_auc 0.86133[0m
[93maverage test of epoch 9: loss -0.69038 acc 0.32432 roc_auc 0.93333 prc_auc 0.96916[0m
[92maverage training of epoch 10: loss -0.79477 acc 0.33775 roc_auc 0.81824 prc_auc 0.90409[0m
[93maverage test of epoch 10: loss -0.88946 acc 0.32432 roc_auc 0.81333 prc_auc 0.91223[0m
[92maverage training of epoch 11: loss -1.04364 acc 0.33775 roc_auc 0.82216 prc_auc 0.90353[0m
[93maverage test of epoch 11: loss -1.20569 acc 0.32432 roc_auc 0.95667 prc_auc 0.98229[0m
[92maverage training of epoch 12: loss -1.30232 acc 0.33775 roc_auc 0.82784 prc_auc 0.91123[0m
[93maverage test of epoch 12: loss -1.44091 acc 0.32432 roc_auc 0.77000 prc_auc 0.89975[0m
[92maverage training of epoch 13: loss -1.61991 acc 0.33775 roc_auc 0.84784 prc_auc 0.92402[0m
[93maverage test of epoch 13: loss -1.77591 acc 0.32432 roc_auc 0.79667 prc_auc 0.91421[0m
[92maverage training of epoch 14: loss -1.96284 acc 0.33775 roc_auc 0.82686 prc_auc 0.92105[0m
[93maverage test of epoch 14: loss -2.12762 acc 0.32432 roc_auc 0.80000 prc_auc 0.91063[0m
[92maverage training of epoch 15: loss -2.40749 acc 0.33775 roc_auc 0.69078 prc_auc 0.84159[0m
[93maverage test of epoch 15: loss -2.60011 acc 0.32432 roc_auc 0.51667 prc_auc 0.69840[0m
[92maverage training of epoch 16: loss -2.95547 acc 0.33775 roc_auc 0.60725 prc_auc 0.74048[0m
[93maverage test of epoch 16: loss -3.15856 acc 0.32432 roc_auc 0.49667 prc_auc 0.67805[0m
[92maverage training of epoch 17: loss -3.55815 acc 0.33775 roc_auc 0.57431 prc_auc 0.73478[0m
[93maverage test of epoch 17: loss -3.79499 acc 0.32432 roc_auc 0.63667 prc_auc 0.79434[0m
[92maverage training of epoch 18: loss -4.21510 acc 0.33775 roc_auc 0.59529 prc_auc 0.71281[0m
[93maverage test of epoch 18: loss -4.46715 acc 0.32432 roc_auc 0.48667 prc_auc 0.73015[0m
[92maverage training of epoch 19: loss -4.92059 acc 0.33775 roc_auc 0.57804 prc_auc 0.73521[0m
[93maverage test of epoch 19: loss -5.19987 acc 0.32432 roc_auc 0.52667 prc_auc 0.72164[0m
[92maverage training of epoch 20: loss -5.70052 acc 0.33775 roc_auc 0.55373 prc_auc 0.69830[0m
[93maverage test of epoch 20: loss -6.00718 acc 0.32432 roc_auc 0.37667 prc_auc 0.61163[0m
[92maverage training of epoch 21: loss -6.56554 acc 0.33775 roc_auc 0.55922 prc_auc 0.68737[0m
[93maverage test of epoch 21: loss -6.91238 acc 0.32432 roc_auc 0.59667 prc_auc 0.73481[0m
[92maverage training of epoch 22: loss -7.55105 acc 0.33775 roc_auc 0.56490 prc_auc 0.69511[0m
[93maverage test of epoch 22: loss -7.94881 acc 0.32432 roc_auc 0.54000 prc_auc 0.74917[0m
[92maverage training of epoch 23: loss -8.63680 acc 0.33775 roc_auc 0.58294 prc_auc 0.71426[0m
[93maverage test of epoch 23: loss -9.08340 acc 0.32432 roc_auc 0.50667 prc_auc 0.75139[0m
[92maverage training of epoch 24: loss -9.81367 acc 0.33775 roc_auc 0.57706 prc_auc 0.71423[0m
[93maverage test of epoch 24: loss -10.26870 acc 0.32432 roc_auc 0.45667 prc_auc 0.68591[0m
[92maverage training of epoch 25: loss -11.04312 acc 0.33775 roc_auc 0.56961 prc_auc 0.70377[0m
[93maverage test of epoch 25: loss -11.51335 acc 0.32432 roc_auc 0.53000 prc_auc 0.73515[0m
[92maverage training of epoch 26: loss -12.31980 acc 0.33775 roc_auc 0.57176 prc_auc 0.70822[0m
[93maverage test of epoch 26: loss -12.80309 acc 0.32432 roc_auc 0.56000 prc_auc 0.75320[0m
[92maverage training of epoch 27: loss -13.65032 acc 0.33775 roc_auc 0.58490 prc_auc 0.71681[0m
[93maverage test of epoch 27: loss -14.15647 acc 0.32432 roc_auc 0.35000 prc_auc 0.58899[0m
[92maverage training of epoch 28: loss -15.04037 acc 0.33775 roc_auc 0.58667 prc_auc 0.72286[0m
[93maverage test of epoch 28: loss -15.55832 acc 0.32432 roc_auc 0.51333 prc_auc 0.68272[0m
[92maverage training of epoch 29: loss -16.48551 acc 0.33775 roc_auc 0.57196 prc_auc 0.68796[0m
[93maverage test of epoch 29: loss -17.03452 acc 0.32432 roc_auc 0.34000 prc_auc 0.58803[0m
[92maverage training of epoch 30: loss -17.98844 acc 0.33775 roc_auc 0.55196 prc_auc 0.68639[0m
[93maverage test of epoch 30: loss -18.57549 acc 0.32432 roc_auc 0.48667 prc_auc 0.72460[0m
[92maverage training of epoch 31: loss -19.56274 acc 0.33775 roc_auc 0.58275 prc_auc 0.70579[0m
[93maverage test of epoch 31: loss -20.15216 acc 0.32432 roc_auc 0.58667 prc_auc 0.71462[0m
[92maverage training of epoch 32: loss -21.19687 acc 0.33775 roc_auc 0.57216 prc_auc 0.70155[0m
[93maverage test of epoch 32: loss -21.82183 acc 0.32432 roc_auc 0.59667 prc_auc 0.78786[0m
[92maverage training of epoch 33: loss -22.82319 acc 0.33775 roc_auc 0.56765 prc_auc 0.68815[0m
[93maverage test of epoch 33: loss -23.53219 acc 0.32432 roc_auc 0.47000 prc_auc 0.71170[0m
[92maverage training of epoch 34: loss -24.64544 acc 0.33775 roc_auc 0.56412 prc_auc 0.69461[0m
[93maverage test of epoch 34: loss -25.31589 acc 0.32432 roc_auc 0.48333 prc_auc 0.68166[0m
[92maverage training of epoch 35: loss -26.47101 acc 0.33775 roc_auc 0.55725 prc_auc 0.68697[0m
[93maverage test of epoch 35: loss -27.16502 acc 0.32432 roc_auc 0.37500 prc_auc 0.59703[0m
[92maverage training of epoch 36: loss -28.35279 acc 0.33775 roc_auc 0.54569 prc_auc 0.68431[0m
[93maverage test of epoch 36: loss -29.07201 acc 0.32432 roc_auc 0.47333 prc_auc 0.72183[0m
[92maverage training of epoch 37: loss -30.30061 acc 0.33775 roc_auc 0.56275 prc_auc 0.68592[0m
[93maverage test of epoch 37: loss -31.04415 acc 0.32432 roc_auc 0.46500 prc_auc 0.71387[0m
[92maverage training of epoch 38: loss -32.30771 acc 0.33775 roc_auc 0.54275 prc_auc 0.67322[0m
[93maverage test of epoch 38: loss -33.06867 acc 0.32432 roc_auc 0.44667 prc_auc 0.65759[0m
[92maverage training of epoch 39: loss -34.37446 acc 0.33775 roc_auc 0.54510 prc_auc 0.68398[0m
[93maverage test of epoch 39: loss -35.16231 acc 0.32432 roc_auc 0.60667 prc_auc 0.75180[0m
[92maverage training of epoch 40: loss -36.49633 acc 0.33775 roc_auc 0.52961 prc_auc 0.66080[0m
[93maverage test of epoch 40: loss -37.30367 acc 0.32432 roc_auc 0.64333 prc_auc 0.77382[0m
[92maverage training of epoch 41: loss -38.66032 acc 0.33775 roc_auc 0.52157 prc_auc 0.66679[0m
[93maverage test of epoch 41: loss -39.48551 acc 0.32432 roc_auc 0.70333 prc_auc 0.80086[0m
[92maverage training of epoch 42: loss -40.86266 acc 0.33775 roc_auc 0.47824 prc_auc 0.62385[0m
[93maverage test of epoch 42: loss -41.70220 acc 0.32432 roc_auc 0.63667 prc_auc 0.80949[0m
[92maverage training of epoch 43: loss -43.10460 acc 0.33775 roc_auc 0.46814 prc_auc 0.62678[0m
[93maverage test of epoch 43: loss -43.96328 acc 0.32432 roc_auc 0.47000 prc_auc 0.66500[0m
[92maverage training of epoch 44: loss -45.39132 acc 0.33775 roc_auc 0.45157 prc_auc 0.61329[0m
[93maverage test of epoch 44: loss -46.26655 acc 0.32432 roc_auc 0.58333 prc_auc 0.79477[0m
[92maverage training of epoch 45: loss -47.71808 acc 0.33775 roc_auc 0.46451 prc_auc 0.64071[0m
[93maverage test of epoch 45: loss -48.61637 acc 0.32432 roc_auc 0.68000 prc_auc 0.85962[0m
[92maverage training of epoch 46: loss -50.09230 acc 0.33775 roc_auc 0.45686 prc_auc 0.62080[0m
[93maverage test of epoch 46: loss -51.00883 acc 0.32432 roc_auc 0.52500 prc_auc 0.72160[0m
[92maverage training of epoch 47: loss -52.51246 acc 0.33775 roc_auc 0.46235 prc_auc 0.62176[0m
[93maverage test of epoch 47: loss -53.45111 acc 0.32432 roc_auc 0.34500 prc_auc 0.60192[0m
[92maverage training of epoch 48: loss -54.97938 acc 0.33775 roc_auc 0.44529 prc_auc 0.61473[0m
[93maverage test of epoch 48: loss -55.94302 acc 0.32432 roc_auc 0.65167 prc_auc 0.83839[0m
[92maverage training of epoch 49: loss -57.49820 acc 0.33775 roc_auc 0.44549 prc_auc 0.61604[0m
[93maverage test of epoch 49: loss -58.47976 acc 0.32432 roc_auc 0.49000 prc_auc 0.72978[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 1)
('lr', 0.0003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.59474 ROC_AUC (avg): 0.498 PRC_AUC (avg): 0.67583 

Average forward propagation time taken(ms): 4.257776646693265
Average backward propagation time taken(ms): 1.573589872941539

