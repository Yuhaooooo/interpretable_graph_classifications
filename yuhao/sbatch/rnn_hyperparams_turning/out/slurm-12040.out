# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.0001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-11-09-12/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-11-09-12/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 16,
 'epochs': 100,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 8,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.0001,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 2,
 'num_workers': 8,
 'number_of_mlp_layer': 0,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-18-11-09-12',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 100, 'learning_rate': 0.0001, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.75525 acc 0.64667 roc_auc 0.43240 prc_auc 0.64188[0m
[93maverage test of epoch 0: loss -0.89197 acc 0.65789 roc_auc 0.44000 prc_auc 0.64134[0m
[92maverage training of epoch 1: loss -0.99472 acc 0.66667 roc_auc 0.50360 prc_auc 0.68107[0m
[93maverage test of epoch 1: loss -1.11131 acc 0.65789 roc_auc 0.60615 prc_auc 0.78325[0m
[92maverage training of epoch 2: loss -1.18920 acc 0.66667 roc_auc 0.46100 prc_auc 0.66676[0m
[93maverage test of epoch 2: loss -1.29953 acc 0.65789 roc_auc 0.66769 prc_auc 0.83523[0m
[92maverage training of epoch 3: loss -1.37709 acc 0.66667 roc_auc 0.52380 prc_auc 0.72818[0m
[93maverage test of epoch 3: loss -1.47614 acc 0.65789 roc_auc 0.66154 prc_auc 0.81380[0m
[92maverage training of epoch 4: loss -1.59137 acc 0.66667 roc_auc 0.61500 prc_auc 0.76974[0m
[93maverage test of epoch 4: loss -1.68208 acc 0.65789 roc_auc 0.63385 prc_auc 0.80256[0m
[92maverage training of epoch 5: loss -1.81048 acc 0.66667 roc_auc 0.64320 prc_auc 0.77931[0m
[93maverage test of epoch 5: loss -1.88642 acc 0.65789 roc_auc 0.55692 prc_auc 0.74498[0m
[92maverage training of epoch 6: loss -2.02083 acc 0.66667 roc_auc 0.76420 prc_auc 0.87093[0m
[93maverage test of epoch 6: loss -2.09190 acc 0.65789 roc_auc 0.79692 prc_auc 0.85745[0m
[92maverage training of epoch 7: loss -2.18008 acc 0.66667 roc_auc 0.65360 prc_auc 0.80124[0m
[93maverage test of epoch 7: loss -2.28922 acc 0.65789 roc_auc 0.89846 prc_auc 0.95340[0m
[92maverage training of epoch 8: loss -2.35717 acc 0.66667 roc_auc 0.78620 prc_auc 0.88326[0m
[93maverage test of epoch 8: loss -2.41088 acc 0.65789 roc_auc 0.76923 prc_auc 0.87741[0m
[92maverage training of epoch 9: loss -2.51398 acc 0.66667 roc_auc 0.82980 prc_auc 0.89681[0m
[93maverage test of epoch 9: loss -2.60678 acc 0.65789 roc_auc 0.86462 prc_auc 0.92749[0m
[92maverage training of epoch 10: loss -2.68136 acc 0.66667 roc_auc 0.84320 prc_auc 0.91798[0m
[93maverage test of epoch 10: loss -2.74815 acc 0.65789 roc_auc 0.84000 prc_auc 0.91571[0m
[92maverage training of epoch 11: loss -2.82988 acc 0.66667 roc_auc 0.87560 prc_auc 0.93160[0m
[93maverage test of epoch 11: loss -2.90451 acc 0.65789 roc_auc 0.86154 prc_auc 0.92687[0m
[92maverage training of epoch 12: loss -2.98793 acc 0.68667 roc_auc 0.88340 prc_auc 0.93365[0m
[93maverage test of epoch 12: loss -3.04765 acc 0.65789 roc_auc 0.84308 prc_auc 0.91745[0m
[92maverage training of epoch 13: loss -3.13212 acc 0.73333 roc_auc 0.87360 prc_auc 0.92660[0m
[93maverage test of epoch 13: loss -3.18538 acc 0.78947 roc_auc 0.87692 prc_auc 0.93696[0m
[92maverage training of epoch 14: loss -3.26110 acc 0.79333 roc_auc 0.85640 prc_auc 0.89101[0m
[93maverage test of epoch 14: loss -3.32224 acc 0.78947 roc_auc 0.84000 prc_auc 0.85058[0m
[92maverage training of epoch 15: loss -3.39533 acc 0.82000 roc_auc 0.85380 prc_auc 0.90654[0m
[93maverage test of epoch 15: loss -3.48142 acc 0.78947 roc_auc 0.89231 prc_auc 0.95455[0m
[92maverage training of epoch 16: loss -3.51943 acc 0.83333 roc_auc 0.86400 prc_auc 0.90749[0m
[93maverage test of epoch 16: loss -3.59699 acc 0.81579 roc_auc 0.89538 prc_auc 0.95152[0m
[92maverage training of epoch 17: loss -3.64633 acc 0.83333 roc_auc 0.88640 prc_auc 0.94334[0m
[93maverage test of epoch 17: loss -3.70251 acc 0.81579 roc_auc 0.85538 prc_auc 0.92824[0m
[92maverage training of epoch 18: loss -3.77116 acc 0.82000 roc_auc 0.86720 prc_auc 0.91206[0m
[93maverage test of epoch 18: loss -3.83472 acc 0.84211 roc_auc 0.86769 prc_auc 0.93893[0m
[92maverage training of epoch 19: loss -3.89238 acc 0.84667 roc_auc 0.89480 prc_auc 0.93976[0m
[93maverage test of epoch 19: loss -3.92239 acc 0.78947 roc_auc 0.88000 prc_auc 0.93821[0m
[92maverage training of epoch 20: loss -3.99344 acc 0.84667 roc_auc 0.87460 prc_auc 0.92487[0m
[93maverage test of epoch 20: loss -4.02235 acc 0.78947 roc_auc 0.89846 prc_auc 0.95389[0m
[92maverage training of epoch 21: loss -4.10865 acc 0.84000 roc_auc 0.89360 prc_auc 0.93853[0m
[93maverage test of epoch 21: loss -4.12257 acc 0.81579 roc_auc 0.85231 prc_auc 0.93462[0m
[92maverage training of epoch 22: loss -4.20692 acc 0.84000 roc_auc 0.90300 prc_auc 0.94578[0m
[93maverage test of epoch 22: loss -4.22116 acc 0.78947 roc_auc 0.89846 prc_auc 0.94900[0m
[92maverage training of epoch 23: loss -4.27078 acc 0.83333 roc_auc 0.85800 prc_auc 0.90412[0m
[93maverage test of epoch 23: loss -4.27920 acc 0.78947 roc_auc 0.81846 prc_auc 0.91809[0m
[92maverage training of epoch 24: loss -4.41715 acc 0.85333 roc_auc 0.90260 prc_auc 0.94662[0m
[93maverage test of epoch 24: loss -4.40524 acc 0.78947 roc_auc 0.88615 prc_auc 0.93718[0m
[92maverage training of epoch 25: loss -4.50633 acc 0.83333 roc_auc 0.88000 prc_auc 0.92920[0m
[93maverage test of epoch 25: loss -4.51765 acc 0.81579 roc_auc 0.86462 prc_auc 0.93309[0m
[92maverage training of epoch 26: loss -4.58544 acc 0.84000 roc_auc 0.87740 prc_auc 0.92873[0m
[93maverage test of epoch 26: loss -4.60563 acc 0.81579 roc_auc 0.83692 prc_auc 0.89977[0m
[92maverage training of epoch 27: loss -4.65987 acc 0.84000 roc_auc 0.85140 prc_auc 0.90577[0m
[93maverage test of epoch 27: loss -4.69460 acc 0.81579 roc_auc 0.88615 prc_auc 0.95293[0m
[92maverage training of epoch 28: loss -4.77481 acc 0.84000 roc_auc 0.88120 prc_auc 0.91763[0m
[93maverage test of epoch 28: loss -4.78900 acc 0.81579 roc_auc 0.84000 prc_auc 0.92536[0m
[92maverage training of epoch 29: loss -4.86942 acc 0.85333 roc_auc 0.86560 prc_auc 0.91699[0m
[93maverage test of epoch 29: loss -4.88837 acc 0.81579 roc_auc 0.88615 prc_auc 0.95229[0m
[92maverage training of epoch 30: loss -4.94041 acc 0.82667 roc_auc 0.89080 prc_auc 0.93706[0m
[93maverage test of epoch 30: loss -5.01479 acc 0.84211 roc_auc 0.82462 prc_auc 0.89104[0m
[92maverage training of epoch 31: loss -5.05181 acc 0.82667 roc_auc 0.86440 prc_auc 0.88902[0m
[93maverage test of epoch 31: loss -5.02579 acc 0.78947 roc_auc 0.84615 prc_auc 0.90809[0m
[92maverage training of epoch 32: loss -5.12998 acc 0.82667 roc_auc 0.87240 prc_auc 0.93030[0m
[93maverage test of epoch 32: loss -5.11968 acc 0.78947 roc_auc 0.89846 prc_auc 0.95380[0m
[92maverage training of epoch 33: loss -5.23588 acc 0.84000 roc_auc 0.89980 prc_auc 0.94733[0m
[93maverage test of epoch 33: loss -5.23478 acc 0.81579 roc_auc 0.87077 prc_auc 0.94413[0m
[92maverage training of epoch 34: loss -5.32951 acc 0.83333 roc_auc 0.89640 prc_auc 0.93986[0m
[93maverage test of epoch 34: loss -5.45935 acc 0.86842 roc_auc 0.88615 prc_auc 0.93999[0m
[92maverage training of epoch 35: loss -5.40395 acc 0.84000 roc_auc 0.86720 prc_auc 0.92266[0m
[93maverage test of epoch 35: loss -5.37718 acc 0.78947 roc_auc 0.86154 prc_auc 0.93900[0m
[92maverage training of epoch 36: loss -5.51018 acc 0.85333 roc_auc 0.87040 prc_auc 0.90906[0m
[93maverage test of epoch 36: loss -5.52550 acc 0.81579 roc_auc 0.91077 prc_auc 0.95807[0m
[92maverage training of epoch 37: loss -5.60145 acc 0.84000 roc_auc 0.86920 prc_auc 0.92203[0m
[93maverage test of epoch 37: loss -5.68107 acc 0.84211 roc_auc 0.88615 prc_auc 0.94099[0m
[92maverage training of epoch 38: loss -5.67896 acc 0.82667 roc_auc 0.89900 prc_auc 0.94361[0m
[93maverage test of epoch 38: loss -5.67716 acc 0.81579 roc_auc 0.82154 prc_auc 0.88735[0m
[92maverage training of epoch 39: loss -5.79930 acc 0.85333 roc_auc 0.84860 prc_auc 0.90293[0m
[93maverage test of epoch 39: loss -5.76410 acc 0.81579 roc_auc 0.84308 prc_auc 0.92426[0m
[92maverage training of epoch 40: loss -5.82919 acc 0.80667 roc_auc 0.87760 prc_auc 0.92715[0m
[93maverage test of epoch 40: loss -5.92001 acc 0.81579 roc_auc 0.87385 prc_auc 0.94147[0m
[92maverage training of epoch 41: loss -5.94572 acc 0.83333 roc_auc 0.83960 prc_auc 0.88227[0m
[93maverage test of epoch 41: loss -5.91281 acc 0.78947 roc_auc 0.84615 prc_auc 0.91981[0m
[92maverage training of epoch 42: loss -6.14019 acc 0.86000 roc_auc 0.87140 prc_auc 0.91386[0m
[93maverage test of epoch 42: loss -6.07024 acc 0.81579 roc_auc 0.84923 prc_auc 0.92822[0m
[92maverage training of epoch 43: loss -6.14274 acc 0.82667 roc_auc 0.87940 prc_auc 0.93243[0m
[93maverage test of epoch 43: loss -6.18983 acc 0.81579 roc_auc 0.90462 prc_auc 0.95418[0m
[92maverage training of epoch 44: loss -6.22731 acc 0.82667 roc_auc 0.84300 prc_auc 0.89440[0m
[93maverage test of epoch 44: loss -6.28373 acc 0.81579 roc_auc 0.88000 prc_auc 0.93136[0m
[92maverage training of epoch 45: loss -6.39573 acc 0.84667 roc_auc 0.88480 prc_auc 0.93315[0m
[93maverage test of epoch 45: loss -6.35743 acc 0.81579 roc_auc 0.85538 prc_auc 0.93570[0m
[92maverage training of epoch 46: loss -6.44070 acc 0.84667 roc_auc 0.81260 prc_auc 0.88211[0m
[93maverage test of epoch 46: loss -6.49471 acc 0.81579 roc_auc 0.85538 prc_auc 0.92671[0m
[92maverage training of epoch 47: loss -6.58674 acc 0.86000 roc_auc 0.80960 prc_auc 0.85501[0m
[93maverage test of epoch 47: loss -6.55082 acc 0.81579 roc_auc 0.85538 prc_auc 0.89284[0m
[92maverage training of epoch 48: loss -6.67906 acc 0.85333 roc_auc 0.85520 prc_auc 0.89636[0m
[93maverage test of epoch 48: loss -6.63448 acc 0.81579 roc_auc 0.87077 prc_auc 0.93756[0m
[92maverage training of epoch 49: loss -6.74890 acc 0.84000 roc_auc 0.86140 prc_auc 0.90825[0m
[93maverage test of epoch 49: loss -6.73498 acc 0.81579 roc_auc 0.82769 prc_auc 0.91086[0m
[92maverage training of epoch 50: loss -6.90119 acc 0.85333 roc_auc 0.87080 prc_auc 0.91413[0m
[93maverage test of epoch 50: loss -6.83469 acc 0.81579 roc_auc 0.80923 prc_auc 0.86350[0m
[92maverage training of epoch 51: loss -6.89242 acc 0.83333 roc_auc 0.84500 prc_auc 0.88577[0m
[93maverage test of epoch 51: loss -6.90873 acc 0.81579 roc_auc 0.83385 prc_auc 0.92313[0m
[92maverage training of epoch 52: loss -7.06409 acc 0.84667 roc_auc 0.84850 prc_auc 0.91214[0m
[93maverage test of epoch 52: loss -7.02376 acc 0.81579 roc_auc 0.87077 prc_auc 0.93725[0m
[92maverage training of epoch 53: loss -7.11086 acc 0.82667 roc_auc 0.80240 prc_auc 0.83504[0m
[93maverage test of epoch 53: loss -7.10748 acc 0.81579 roc_auc 0.84923 prc_auc 0.91780[0m
[92maverage training of epoch 54: loss -7.25308 acc 0.85333 roc_auc 0.80920 prc_auc 0.83346[0m
[93maverage test of epoch 54: loss -7.21151 acc 0.81579 roc_auc 0.80308 prc_auc 0.87102[0m
[92maverage training of epoch 55: loss -7.31108 acc 0.83333 roc_auc 0.80600 prc_auc 0.84169[0m
[93maverage test of epoch 55: loss -7.32786 acc 0.81579 roc_auc 0.86462 prc_auc 0.92667[0m
[92maverage training of epoch 56: loss -7.39969 acc 0.84000 roc_auc 0.83980 prc_auc 0.89912[0m
[93maverage test of epoch 56: loss -7.31568 acc 0.78947 roc_auc 0.81538 prc_auc 0.83515[0m
[92maverage training of epoch 57: loss -7.50185 acc 0.82667 roc_auc 0.83540 prc_auc 0.85250[0m
[93maverage test of epoch 57: loss -7.51196 acc 0.81579 roc_auc 0.88308 prc_auc 0.93898[0m
[92maverage training of epoch 58: loss -7.63460 acc 0.84667 roc_auc 0.87040 prc_auc 0.92909[0m
[93maverage test of epoch 58: loss -7.57564 acc 0.81579 roc_auc 0.81231 prc_auc 0.89041[0m
[92maverage training of epoch 59: loss -7.74272 acc 0.85333 roc_auc 0.81510 prc_auc 0.85307[0m
[93maverage test of epoch 59: loss -7.66757 acc 0.81579 roc_auc 0.77538 prc_auc 0.82639[0m
[92maverage training of epoch 60: loss -7.76352 acc 0.82000 roc_auc 0.86380 prc_auc 0.91725[0m
[93maverage test of epoch 60: loss -7.76532 acc 0.81579 roc_auc 0.85231 prc_auc 0.93563[0m
[92maverage training of epoch 61: loss -7.88912 acc 0.84000 roc_auc 0.81460 prc_auc 0.88852[0m
[93maverage test of epoch 61: loss -7.87851 acc 0.81579 roc_auc 0.82462 prc_auc 0.88189[0m
[92maverage training of epoch 62: loss -7.97355 acc 0.83333 roc_auc 0.86600 prc_auc 0.90197[0m
[93maverage test of epoch 62: loss -8.03800 acc 0.84211 roc_auc 0.83385 prc_auc 0.90290[0m
[92maverage training of epoch 63: loss -8.11855 acc 0.85333 roc_auc 0.84910 prc_auc 0.90424[0m
[93maverage test of epoch 63: loss -8.02353 acc 0.81579 roc_auc 0.81077 prc_auc 0.87517[0m
[92maverage training of epoch 64: loss -8.17984 acc 0.82667 roc_auc 0.86380 prc_auc 0.91544[0m
[93maverage test of epoch 64: loss -8.13448 acc 0.81579 roc_auc 0.82462 prc_auc 0.89439[0m
[92maverage training of epoch 65: loss -8.30056 acc 0.84667 roc_auc 0.81040 prc_auc 0.84290[0m
[93maverage test of epoch 65: loss -8.22892 acc 0.81579 roc_auc 0.79692 prc_auc 0.89394[0m
[92maverage training of epoch 66: loss -8.38910 acc 0.84667 roc_auc 0.88170 prc_auc 0.91942[0m
[93maverage test of epoch 66: loss -8.31870 acc 0.81579 roc_auc 0.84000 prc_auc 0.91412[0m
[92maverage training of epoch 67: loss -8.53626 acc 0.86000 roc_auc 0.79390 prc_auc 0.84633[0m
[93maverage test of epoch 67: loss -8.42197 acc 0.81579 roc_auc 0.84923 prc_auc 0.88261[0m
[92maverage training of epoch 68: loss -8.55811 acc 0.83333 roc_auc 0.82640 prc_auc 0.87477[0m
[93maverage test of epoch 68: loss -8.50697 acc 0.81579 roc_auc 0.80000 prc_auc 0.88269[0m
[92maverage training of epoch 69: loss -8.70943 acc 0.84667 roc_auc 0.87140 prc_auc 0.91403[0m
[93maverage test of epoch 69: loss -8.51673 acc 0.81579 roc_auc 0.78769 prc_auc 0.88203[0m
[92maverage training of epoch 70: loss -8.76548 acc 0.84000 roc_auc 0.81660 prc_auc 0.85713[0m
[93maverage test of epoch 70: loss -8.60348 acc 0.78947 roc_auc 0.82462 prc_auc 0.90091[0m
[92maverage training of epoch 71: loss -8.89799 acc 0.84667 roc_auc 0.81000 prc_auc 0.86603[0m
[93maverage test of epoch 71: loss -8.77489 acc 0.81579 roc_auc 0.81231 prc_auc 0.88422[0m
[92maverage training of epoch 72: loss -8.98006 acc 0.84667 roc_auc 0.79650 prc_auc 0.80498[0m
[93maverage test of epoch 72: loss -8.85521 acc 0.78947 roc_auc 0.79692 prc_auc 0.87301[0m
[92maverage training of epoch 73: loss -9.03504 acc 0.84000 roc_auc 0.84300 prc_auc 0.87595[0m
[93maverage test of epoch 73: loss -8.96242 acc 0.84211 roc_auc 0.83077 prc_auc 0.91976[0m
[92maverage training of epoch 74: loss -9.15881 acc 0.84667 roc_auc 0.81310 prc_auc 0.85439[0m
[93maverage test of epoch 74: loss -8.97976 acc 0.81579 roc_auc 0.82769 prc_auc 0.89639[0m
[92maverage training of epoch 75: loss -9.22843 acc 0.84000 roc_auc 0.80320 prc_auc 0.83918[0m
[93maverage test of epoch 75: loss -9.11158 acc 0.78947 roc_auc 0.87077 prc_auc 0.93614[0m
[92maverage training of epoch 76: loss -9.31179 acc 0.83333 roc_auc 0.81040 prc_auc 0.84497[0m
[93maverage test of epoch 76: loss -9.22305 acc 0.81579 roc_auc 0.78154 prc_auc 0.84672[0m
[92maverage training of epoch 77: loss -9.44996 acc 0.85333 roc_auc 0.84440 prc_auc 0.87757[0m
[93maverage test of epoch 77: loss -9.30828 acc 0.81579 roc_auc 0.76000 prc_auc 0.86195[0m
[92maverage training of epoch 78: loss -9.51083 acc 0.84000 roc_auc 0.80380 prc_auc 0.84432[0m
[93maverage test of epoch 78: loss -9.41468 acc 0.81579 roc_auc 0.81538 prc_auc 0.89794[0m
[92maverage training of epoch 79: loss -9.62904 acc 0.85333 roc_auc 0.84180 prc_auc 0.90523[0m
[93maverage test of epoch 79: loss -9.51851 acc 0.81579 roc_auc 0.82769 prc_auc 0.89622[0m
[92maverage training of epoch 80: loss -9.77267 acc 0.86000 roc_auc 0.86620 prc_auc 0.89285[0m
[93maverage test of epoch 80: loss -9.62371 acc 0.81579 roc_auc 0.85077 prc_auc 0.91560[0m
[92maverage training of epoch 81: loss -9.82646 acc 0.85333 roc_auc 0.81070 prc_auc 0.85971[0m
[93maverage test of epoch 81: loss -9.68780 acc 0.81579 roc_auc 0.79385 prc_auc 0.88236[0m
[92maverage training of epoch 82: loss -9.96281 acc 0.84667 roc_auc 0.80930 prc_auc 0.81152[0m
[93maverage test of epoch 82: loss -9.87863 acc 0.84211 roc_auc 0.81385 prc_auc 0.91020[0m
[92maverage training of epoch 83: loss -10.00262 acc 0.85333 roc_auc 0.82340 prc_auc 0.85625[0m
[93maverage test of epoch 83: loss -9.96252 acc 0.84211 roc_auc 0.84000 prc_auc 0.90286[0m
[92maverage training of epoch 84: loss -10.03890 acc 0.84667 roc_auc 0.83240 prc_auc 0.84835[0m
[93maverage test of epoch 84: loss -9.96418 acc 0.81579 roc_auc 0.73077 prc_auc 0.77545[0m
[92maverage training of epoch 85: loss -10.17842 acc 0.84000 roc_auc 0.81780 prc_auc 0.83581[0m
[93maverage test of epoch 85: loss -10.11907 acc 0.81579 roc_auc 0.77385 prc_auc 0.86334[0m
[92maverage training of epoch 86: loss -10.27171 acc 0.84667 roc_auc 0.78660 prc_auc 0.82276[0m
[93maverage test of epoch 86: loss -10.13356 acc 0.81579 roc_auc 0.75692 prc_auc 0.83925[0m
[92maverage training of epoch 87: loss -10.36644 acc 0.84667 roc_auc 0.82660 prc_auc 0.87038[0m
[93maverage test of epoch 87: loss -10.29733 acc 0.81579 roc_auc 0.84000 prc_auc 0.89750[0m
[92maverage training of epoch 88: loss -10.41311 acc 0.84667 roc_auc 0.84240 prc_auc 0.86103[0m
[93maverage test of epoch 88: loss -10.36613 acc 0.81579 roc_auc 0.82154 prc_auc 0.87883[0m
[92maverage training of epoch 89: loss -10.45821 acc 0.84667 roc_auc 0.80520 prc_auc 0.83700[0m
[93maverage test of epoch 89: loss -10.31975 acc 0.81579 roc_auc 0.68308 prc_auc 0.77810[0m
[92maverage training of epoch 90: loss -10.62557 acc 0.84000 roc_auc 0.81400 prc_auc 0.85619[0m
[93maverage test of epoch 90: loss -10.56113 acc 0.81579 roc_auc 0.84000 prc_auc 0.91555[0m
[92maverage training of epoch 91: loss -10.75573 acc 0.84667 roc_auc 0.78580 prc_auc 0.82883[0m
[93maverage test of epoch 91: loss -10.59874 acc 0.81579 roc_auc 0.84923 prc_auc 0.91308[0m
[92maverage training of epoch 92: loss -10.83026 acc 0.84667 roc_auc 0.77100 prc_auc 0.81199[0m
[93maverage test of epoch 92: loss -10.67869 acc 0.81579 roc_auc 0.80615 prc_auc 0.89710[0m
[92maverage training of epoch 93: loss -10.86590 acc 0.83333 roc_auc 0.85370 prc_auc 0.88625[0m
[93maverage test of epoch 93: loss -10.77567 acc 0.81579 roc_auc 0.81077 prc_auc 0.87010[0m
[92maverage training of epoch 94: loss -10.95899 acc 0.84000 roc_auc 0.83340 prc_auc 0.86933[0m
[93maverage test of epoch 94: loss -10.86206 acc 0.81579 roc_auc 0.82154 prc_auc 0.87887[0m
[92maverage training of epoch 95: loss -11.10224 acc 0.84667 roc_auc 0.78490 prc_auc 0.82977[0m
[93maverage test of epoch 95: loss -10.94007 acc 0.81579 roc_auc 0.74769 prc_auc 0.77444[0m
[92maverage training of epoch 96: loss -11.20139 acc 0.84000 roc_auc 0.77840 prc_auc 0.82183[0m
[93maverage test of epoch 96: loss -11.03530 acc 0.81579 roc_auc 0.80000 prc_auc 0.88694[0m
[92maverage training of epoch 97: loss -11.29095 acc 0.84667 roc_auc 0.79640 prc_auc 0.83324[0m
[93maverage test of epoch 97: loss -11.12681 acc 0.81579 roc_auc 0.78308 prc_auc 0.85136[0m
[92maverage training of epoch 98: loss -11.39858 acc 0.84667 roc_auc 0.83960 prc_auc 0.87926[0m
[93maverage test of epoch 98: loss -11.27670 acc 0.81579 roc_auc 0.81846 prc_auc 0.85540[0m
[92maverage training of epoch 99: loss -11.45299 acc 0.84667 roc_auc 0.79740 prc_auc 0.83825[0m
[93maverage test of epoch 99: loss -11.31157 acc 0.81579 roc_auc 0.86154 prc_auc 0.93229[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.89660 acc 0.66667 roc_auc 0.45560 prc_auc 0.64731[0m
[93maverage test of epoch 0: loss -1.09867 acc 0.65789 roc_auc 0.33846 prc_auc 0.58718[0m
[92maverage training of epoch 1: loss -1.32125 acc 0.66667 roc_auc 0.44620 prc_auc 0.63433[0m
[93maverage test of epoch 1: loss -1.52342 acc 0.65789 roc_auc 0.38462 prc_auc 0.62976[0m
[92maverage training of epoch 2: loss -1.76322 acc 0.66667 roc_auc 0.45560 prc_auc 0.65698[0m
[93maverage test of epoch 2: loss -1.97937 acc 0.65789 roc_auc 0.24615 prc_auc 0.54437[0m
[92maverage training of epoch 3: loss -2.34076 acc 0.66667 roc_auc 0.47740 prc_auc 0.67589[0m
[93maverage test of epoch 3: loss -2.73697 acc 0.65789 roc_auc 0.55385 prc_auc 0.76816[0m
[92maverage training of epoch 4: loss -3.08895 acc 0.66667 roc_auc 0.50140 prc_auc 0.68812[0m
[93maverage test of epoch 4: loss -3.37565 acc 0.65789 roc_auc 0.47077 prc_auc 0.64639[0m
[92maverage training of epoch 5: loss -3.60162 acc 0.66667 roc_auc 0.45320 prc_auc 0.65389[0m
[93maverage test of epoch 5: loss -3.79607 acc 0.65789 roc_auc 0.60000 prc_auc 0.74977[0m
[92maverage training of epoch 6: loss -3.96555 acc 0.66667 roc_auc 0.44780 prc_auc 0.62058[0m
[93maverage test of epoch 6: loss -4.13537 acc 0.65789 roc_auc 0.62769 prc_auc 0.78803[0m
[92maverage training of epoch 7: loss -4.30179 acc 0.66667 roc_auc 0.54220 prc_auc 0.70307[0m
[93maverage test of epoch 7: loss -4.40972 acc 0.65789 roc_auc 0.48000 prc_auc 0.69188[0m
[92maverage training of epoch 8: loss -4.57149 acc 0.66667 roc_auc 0.48360 prc_auc 0.67054[0m
[93maverage test of epoch 8: loss -4.65453 acc 0.65789 roc_auc 0.29538 prc_auc 0.54977[0m
[92maverage training of epoch 9: loss -4.81457 acc 0.66667 roc_auc 0.50700 prc_auc 0.68185[0m
[93maverage test of epoch 9: loss -4.88419 acc 0.65789 roc_auc 0.40000 prc_auc 0.66284[0m
[92maverage training of epoch 10: loss -5.03772 acc 0.66667 roc_auc 0.50120 prc_auc 0.67162[0m
[93maverage test of epoch 10: loss -5.11121 acc 0.65789 roc_auc 0.47692 prc_auc 0.62656[0m
[92maverage training of epoch 11: loss -5.22457 acc 0.66667 roc_auc 0.47520 prc_auc 0.68210[0m
[93maverage test of epoch 11: loss -5.28385 acc 0.65789 roc_auc 0.56615 prc_auc 0.77054[0m
[92maverage training of epoch 12: loss -5.41517 acc 0.66667 roc_auc 0.49040 prc_auc 0.68574[0m
[93maverage test of epoch 12: loss -5.45132 acc 0.65789 roc_auc 0.58462 prc_auc 0.74219[0m
[92maverage training of epoch 13: loss -5.57549 acc 0.66667 roc_auc 0.53680 prc_auc 0.70817[0m
[93maverage test of epoch 13: loss -5.64179 acc 0.65789 roc_auc 0.51385 prc_auc 0.75056[0m
[92maverage training of epoch 14: loss -5.73626 acc 0.66667 roc_auc 0.55600 prc_auc 0.72705[0m
[93maverage test of epoch 14: loss -5.78129 acc 0.65789 roc_auc 0.52000 prc_auc 0.66868[0m
[92maverage training of epoch 15: loss -5.87782 acc 0.66667 roc_auc 0.51000 prc_auc 0.69694[0m
[93maverage test of epoch 15: loss -5.88889 acc 0.65789 roc_auc 0.39077 prc_auc 0.61582[0m
[92maverage training of epoch 16: loss -6.00467 acc 0.66667 roc_auc 0.47120 prc_auc 0.67235[0m
[93maverage test of epoch 16: loss -6.06135 acc 0.65789 roc_auc 0.54154 prc_auc 0.69351[0m
[92maverage training of epoch 17: loss -6.15195 acc 0.66667 roc_auc 0.52820 prc_auc 0.69078[0m
[93maverage test of epoch 17: loss -6.18366 acc 0.65789 roc_auc 0.31077 prc_auc 0.62843[0m
[92maverage training of epoch 18: loss -6.27719 acc 0.66667 roc_auc 0.49600 prc_auc 0.68007[0m
[93maverage test of epoch 18: loss -6.32538 acc 0.65789 roc_auc 0.69846 prc_auc 0.83037[0m
[92maverage training of epoch 19: loss -6.40118 acc 0.66667 roc_auc 0.56080 prc_auc 0.69182[0m
[93maverage test of epoch 19: loss -6.41759 acc 0.65789 roc_auc 0.31385 prc_auc 0.55564[0m
[92maverage training of epoch 20: loss -6.51827 acc 0.66667 roc_auc 0.42120 prc_auc 0.62367[0m
[93maverage test of epoch 20: loss -6.56676 acc 0.65789 roc_auc 0.66462 prc_auc 0.83126[0m
[92maverage training of epoch 21: loss -6.63722 acc 0.66667 roc_auc 0.40840 prc_auc 0.60882[0m
[93maverage test of epoch 21: loss -6.66339 acc 0.65789 roc_auc 0.50154 prc_auc 0.69742[0m
[92maverage training of epoch 22: loss -6.75275 acc 0.66667 roc_auc 0.47500 prc_auc 0.65924[0m
[93maverage test of epoch 22: loss -6.77663 acc 0.65789 roc_auc 0.34462 prc_auc 0.55780[0m
[92maverage training of epoch 23: loss -6.87334 acc 0.66667 roc_auc 0.49640 prc_auc 0.65330[0m
[93maverage test of epoch 23: loss -6.90713 acc 0.65789 roc_auc 0.57538 prc_auc 0.74715[0m
[92maverage training of epoch 24: loss -6.98767 acc 0.66667 roc_auc 0.43900 prc_auc 0.63536[0m
[93maverage test of epoch 24: loss -7.02267 acc 0.65789 roc_auc 0.65231 prc_auc 0.73055[0m
[92maverage training of epoch 25: loss -7.10001 acc 0.66667 roc_auc 0.42560 prc_auc 0.63200[0m
[93maverage test of epoch 25: loss -7.12456 acc 0.65789 roc_auc 0.38769 prc_auc 0.60126[0m
[92maverage training of epoch 26: loss -7.20562 acc 0.66667 roc_auc 0.52560 prc_auc 0.68691[0m
[93maverage test of epoch 26: loss -7.23460 acc 0.65789 roc_auc 0.44769 prc_auc 0.65783[0m
[92maverage training of epoch 27: loss -7.31765 acc 0.66667 roc_auc 0.51620 prc_auc 0.69563[0m
[93maverage test of epoch 27: loss -7.33979 acc 0.65789 roc_auc 0.47385 prc_auc 0.63828[0m
[92maverage training of epoch 28: loss -7.42799 acc 0.66667 roc_auc 0.50520 prc_auc 0.68839[0m
[93maverage test of epoch 28: loss -7.44613 acc 0.65789 roc_auc 0.61231 prc_auc 0.77106[0m
[92maverage training of epoch 29: loss -7.53430 acc 0.66667 roc_auc 0.49610 prc_auc 0.65366[0m
[93maverage test of epoch 29: loss -7.55573 acc 0.65789 roc_auc 0.55077 prc_auc 0.74807[0m
[92maverage training of epoch 30: loss -7.63902 acc 0.66667 roc_auc 0.44740 prc_auc 0.61570[0m
[93maverage test of epoch 30: loss -7.66315 acc 0.65789 roc_auc 0.60308 prc_auc 0.76099[0m
[92maverage training of epoch 31: loss -7.74701 acc 0.66667 roc_auc 0.49660 prc_auc 0.66219[0m
[93maverage test of epoch 31: loss -7.77092 acc 0.65789 roc_auc 0.67077 prc_auc 0.81835[0m
[92maverage training of epoch 32: loss -7.85233 acc 0.66667 roc_auc 0.41410 prc_auc 0.59061[0m
[93maverage test of epoch 32: loss -7.87842 acc 0.65789 roc_auc 0.58769 prc_auc 0.69312[0m
[92maverage training of epoch 33: loss -7.95331 acc 0.66667 roc_auc 0.46930 prc_auc 0.62621[0m
[93maverage test of epoch 33: loss -7.98166 acc 0.65789 roc_auc 0.49538 prc_auc 0.68320[0m
[92maverage training of epoch 34: loss -8.05845 acc 0.66667 roc_auc 0.43480 prc_auc 0.62597[0m
[93maverage test of epoch 34: loss -8.08362 acc 0.65789 roc_auc 0.59077 prc_auc 0.75841[0m
[92maverage training of epoch 35: loss -8.16411 acc 0.66667 roc_auc 0.50580 prc_auc 0.69032[0m
[93maverage test of epoch 35: loss -8.18197 acc 0.65789 roc_auc 0.49077 prc_auc 0.66514[0m
[92maverage training of epoch 36: loss -8.26888 acc 0.66667 roc_auc 0.45540 prc_auc 0.62757[0m
[93maverage test of epoch 36: loss -8.28484 acc 0.65789 roc_auc 0.48923 prc_auc 0.71533[0m
[92maverage training of epoch 37: loss -8.37251 acc 0.66667 roc_auc 0.45880 prc_auc 0.64121[0m
[93maverage test of epoch 37: loss -8.39408 acc 0.65789 roc_auc 0.70923 prc_auc 0.85209[0m
[92maverage training of epoch 38: loss -8.47395 acc 0.66667 roc_auc 0.47180 prc_auc 0.64648[0m
[93maverage test of epoch 38: loss -8.49429 acc 0.65789 roc_auc 0.61692 prc_auc 0.73769[0m
[92maverage training of epoch 39: loss -8.57575 acc 0.66667 roc_auc 0.44520 prc_auc 0.62348[0m
[93maverage test of epoch 39: loss -8.59976 acc 0.65789 roc_auc 0.77538 prc_auc 0.88051[0m
[92maverage training of epoch 40: loss -8.67786 acc 0.66667 roc_auc 0.44050 prc_auc 0.64245[0m
[93maverage test of epoch 40: loss -8.69280 acc 0.65789 roc_auc 0.56000 prc_auc 0.66528[0m
[92maverage training of epoch 41: loss -8.77874 acc 0.66667 roc_auc 0.45220 prc_auc 0.62014[0m
[93maverage test of epoch 41: loss -8.80320 acc 0.65789 roc_auc 0.66615 prc_auc 0.78939[0m
[92maverage training of epoch 42: loss -8.88380 acc 0.66667 roc_auc 0.45260 prc_auc 0.63331[0m
[93maverage test of epoch 42: loss -8.89875 acc 0.65789 roc_auc 0.62154 prc_auc 0.77980[0m
[92maverage training of epoch 43: loss -8.98395 acc 0.66667 roc_auc 0.47080 prc_auc 0.64673[0m
[93maverage test of epoch 43: loss -8.99918 acc 0.65789 roc_auc 0.60308 prc_auc 0.71112[0m
[92maverage training of epoch 44: loss -9.08853 acc 0.66667 roc_auc 0.47640 prc_auc 0.62986[0m
[93maverage test of epoch 44: loss -9.10098 acc 0.65789 roc_auc 0.49231 prc_auc 0.68792[0m
[92maverage training of epoch 45: loss -9.18768 acc 0.66667 roc_auc 0.41800 prc_auc 0.61121[0m
[93maverage test of epoch 45: loss -9.20522 acc 0.65789 roc_auc 0.46154 prc_auc 0.66756[0m
[92maverage training of epoch 46: loss -9.28757 acc 0.66667 roc_auc 0.43960 prc_auc 0.62746[0m
[93maverage test of epoch 46: loss -9.30516 acc 0.65789 roc_auc 0.43538 prc_auc 0.64570[0m
[92maverage training of epoch 47: loss -9.38850 acc 0.66667 roc_auc 0.43890 prc_auc 0.61939[0m
[93maverage test of epoch 47: loss -9.40750 acc 0.65789 roc_auc 0.54462 prc_auc 0.67342[0m
[92maverage training of epoch 48: loss -9.49173 acc 0.66667 roc_auc 0.43400 prc_auc 0.61399[0m
[93maverage test of epoch 48: loss -9.50746 acc 0.65789 roc_auc 0.60000 prc_auc 0.79992[0m
[92maverage training of epoch 49: loss -9.59225 acc 0.66667 roc_auc 0.43860 prc_auc 0.62745[0m
[93maverage test of epoch 49: loss -9.60839 acc 0.65789 roc_auc 0.54154 prc_auc 0.71894[0m
[92maverage training of epoch 50: loss -9.69305 acc 0.66667 roc_auc 0.43320 prc_auc 0.62355[0m
[93maverage test of epoch 50: loss -9.70788 acc 0.65789 roc_auc 0.51077 prc_auc 0.68257[0m
[92maverage training of epoch 51: loss -9.79307 acc 0.66667 roc_auc 0.49230 prc_auc 0.64090[0m
[93maverage test of epoch 51: loss -9.80835 acc 0.65789 roc_auc 0.47385 prc_auc 0.63794[0m
[92maverage training of epoch 52: loss -9.89549 acc 0.66667 roc_auc 0.44070 prc_auc 0.62357[0m
[93maverage test of epoch 52: loss -9.90794 acc 0.65789 roc_auc 0.55538 prc_auc 0.68468[0m
[92maverage training of epoch 53: loss -9.99465 acc 0.66667 roc_auc 0.43750 prc_auc 0.62782[0m
[93maverage test of epoch 53: loss -10.01060 acc 0.65789 roc_auc 0.59231 prc_auc 0.73950[0m
[92maverage training of epoch 54: loss -10.09448 acc 0.66667 roc_auc 0.43010 prc_auc 0.60467[0m
[93maverage test of epoch 54: loss -10.10898 acc 0.65789 roc_auc 0.49231 prc_auc 0.70456[0m
[92maverage training of epoch 55: loss -10.19544 acc 0.66667 roc_auc 0.44140 prc_auc 0.60580[0m
[93maverage test of epoch 55: loss -10.21019 acc 0.65789 roc_auc 0.46154 prc_auc 0.63194[0m
[92maverage training of epoch 56: loss -10.29589 acc 0.66667 roc_auc 0.42710 prc_auc 0.62805[0m
[93maverage test of epoch 56: loss -10.30942 acc 0.65789 roc_auc 0.48615 prc_auc 0.68724[0m
[92maverage training of epoch 57: loss -10.39648 acc 0.66667 roc_auc 0.45310 prc_auc 0.62105[0m
[93maverage test of epoch 57: loss -10.40765 acc 0.65789 roc_auc 0.53385 prc_auc 0.74194[0m
[92maverage training of epoch 58: loss -10.49652 acc 0.66667 roc_auc 0.43830 prc_auc 0.61687[0m
[93maverage test of epoch 58: loss -10.50995 acc 0.65789 roc_auc 0.42308 prc_auc 0.63754[0m
[92maverage training of epoch 59: loss -10.59629 acc 0.66667 roc_auc 0.43130 prc_auc 0.61758[0m
[93maverage test of epoch 59: loss -10.60818 acc 0.65789 roc_auc 0.48462 prc_auc 0.67647[0m
[92maverage training of epoch 60: loss -10.69693 acc 0.66667 roc_auc 0.42540 prc_auc 0.61468[0m
[93maverage test of epoch 60: loss -10.70729 acc 0.65789 roc_auc 0.56462 prc_auc 0.68322[0m
[92maverage training of epoch 61: loss -10.79607 acc 0.66667 roc_auc 0.42620 prc_auc 0.62781[0m
[93maverage test of epoch 61: loss -10.80895 acc 0.65789 roc_auc 0.53231 prc_auc 0.72466[0m
[92maverage training of epoch 62: loss -10.89585 acc 0.66667 roc_auc 0.43370 prc_auc 0.62571[0m
[93maverage test of epoch 62: loss -10.90861 acc 0.65789 roc_auc 0.42308 prc_auc 0.64927[0m
[92maverage training of epoch 63: loss -10.99605 acc 0.66667 roc_auc 0.41730 prc_auc 0.60772[0m
[93maverage test of epoch 63: loss -11.00736 acc 0.65789 roc_auc 0.42308 prc_auc 0.63893[0m
[92maverage training of epoch 64: loss -11.09694 acc 0.66667 roc_auc 0.41950 prc_auc 0.61113[0m
[93maverage test of epoch 64: loss -11.10783 acc 0.65789 roc_auc 0.54308 prc_auc 0.76961[0m
[92maverage training of epoch 65: loss -11.19554 acc 0.66667 roc_auc 0.42870 prc_auc 0.61616[0m
[93maverage test of epoch 65: loss -11.20832 acc 0.65789 roc_auc 0.52615 prc_auc 0.69369[0m
[92maverage training of epoch 66: loss -11.29622 acc 0.66667 roc_auc 0.43310 prc_auc 0.61372[0m
[93maverage test of epoch 66: loss -11.30667 acc 0.65789 roc_auc 0.49231 prc_auc 0.67283[0m
[92maverage training of epoch 67: loss -11.39647 acc 0.66667 roc_auc 0.42550 prc_auc 0.60878[0m
[93maverage test of epoch 67: loss -11.40665 acc 0.65789 roc_auc 0.48000 prc_auc 0.70765[0m
[92maverage training of epoch 68: loss -11.49544 acc 0.66667 roc_auc 0.42230 prc_auc 0.60370[0m
[93maverage test of epoch 68: loss -11.50683 acc 0.65789 roc_auc 0.42615 prc_auc 0.61147[0m
[92maverage training of epoch 69: loss -11.59639 acc 0.66667 roc_auc 0.42780 prc_auc 0.61361[0m
[93maverage test of epoch 69: loss -11.60573 acc 0.65789 roc_auc 0.54154 prc_auc 0.71537[0m
[92maverage training of epoch 70: loss -11.69528 acc 0.66667 roc_auc 0.43140 prc_auc 0.62107[0m
[93maverage test of epoch 70: loss -11.70514 acc 0.65789 roc_auc 0.46769 prc_auc 0.65936[0m
[92maverage training of epoch 71: loss -11.79559 acc 0.66667 roc_auc 0.42660 prc_auc 0.60837[0m
[93maverage test of epoch 71: loss -11.80353 acc 0.65789 roc_auc 0.33385 prc_auc 0.56593[0m
[92maverage training of epoch 72: loss -11.89546 acc 0.66667 roc_auc 0.45060 prc_auc 0.64706[0m
[93maverage test of epoch 72: loss -11.90365 acc 0.65789 roc_auc 0.50923 prc_auc 0.67375[0m
[92maverage training of epoch 73: loss -11.99456 acc 0.66667 roc_auc 0.41680 prc_auc 0.61864[0m
[93maverage test of epoch 73: loss -12.00228 acc 0.65789 roc_auc 0.52462 prc_auc 0.70241[0m
[92maverage training of epoch 74: loss -12.09465 acc 0.66667 roc_auc 0.43200 prc_auc 0.61567[0m
[93maverage test of epoch 74: loss -12.10095 acc 0.65789 roc_auc 0.43846 prc_auc 0.65471[0m
[92maverage training of epoch 75: loss -12.19446 acc 0.66667 roc_auc 0.43270 prc_auc 0.61208[0m
[93maverage test of epoch 75: loss -12.20206 acc 0.65789 roc_auc 0.68462 prc_auc 0.76348[0m
[92maverage training of epoch 76: loss -12.29364 acc 0.66667 roc_auc 0.42240 prc_auc 0.61415[0m
[93maverage test of epoch 76: loss -12.30144 acc 0.65789 roc_auc 0.56615 prc_auc 0.74901[0m
[92maverage training of epoch 77: loss -12.39366 acc 0.66667 roc_auc 0.41710 prc_auc 0.59772[0m
[93maverage test of epoch 77: loss -12.40060 acc 0.65789 roc_auc 0.64154 prc_auc 0.76146[0m
[92maverage training of epoch 78: loss -12.49315 acc 0.66667 roc_auc 0.41800 prc_auc 0.60234[0m
[93maverage test of epoch 78: loss -12.49983 acc 0.65789 roc_auc 0.41538 prc_auc 0.59919[0m
[92maverage training of epoch 79: loss -12.59255 acc 0.66667 roc_auc 0.43300 prc_auc 0.60564[0m
[93maverage test of epoch 79: loss -12.59892 acc 0.65789 roc_auc 0.33538 prc_auc 0.55197[0m
[92maverage training of epoch 80: loss -12.69239 acc 0.66667 roc_auc 0.41920 prc_auc 0.60628[0m
[93maverage test of epoch 80: loss -12.69906 acc 0.65789 roc_auc 0.50308 prc_auc 0.66752[0m
[92maverage training of epoch 81: loss -12.79207 acc 0.66667 roc_auc 0.41780 prc_auc 0.58993[0m
[93maverage test of epoch 81: loss -12.79787 acc 0.65789 roc_auc 0.49538 prc_auc 0.73701[0m
[92maverage training of epoch 82: loss -12.89133 acc 0.66667 roc_auc 0.42370 prc_auc 0.60922[0m
[93maverage test of epoch 82: loss -12.89702 acc 0.65789 roc_auc 0.41231 prc_auc 0.59610[0m
[92maverage training of epoch 83: loss -12.99139 acc 0.66667 roc_auc 0.43140 prc_auc 0.61227[0m
[93maverage test of epoch 83: loss -12.99679 acc 0.65789 roc_auc 0.50000 prc_auc 0.63583[0m
[92maverage training of epoch 84: loss -13.09087 acc 0.66667 roc_auc 0.42310 prc_auc 0.59842[0m
[93maverage test of epoch 84: loss -13.09506 acc 0.65789 roc_auc 0.53077 prc_auc 0.65442[0m
[92maverage training of epoch 85: loss -13.19030 acc 0.66667 roc_auc 0.42840 prc_auc 0.61594[0m
[93maverage test of epoch 85: loss -13.19525 acc 0.65789 roc_auc 0.30615 prc_auc 0.55428[0m
[92maverage training of epoch 86: loss -13.28984 acc 0.66667 roc_auc 0.41990 prc_auc 0.60983[0m
[93maverage test of epoch 86: loss -13.29411 acc 0.65789 roc_auc 0.43077 prc_auc 0.62539[0m
[92maverage training of epoch 87: loss -13.38941 acc 0.66667 roc_auc 0.42670 prc_auc 0.60938[0m
[93maverage test of epoch 87: loss -13.39332 acc 0.65789 roc_auc 0.51692 prc_auc 0.69095[0m
[92maverage training of epoch 88: loss -13.48886 acc 0.66667 roc_auc 0.43610 prc_auc 0.63356[0m
[93maverage test of epoch 88: loss -13.49293 acc 0.65789 roc_auc 0.38154 prc_auc 0.60526[0m
[92maverage training of epoch 89: loss -13.58857 acc 0.66667 roc_auc 0.42320 prc_auc 0.60639[0m
[93maverage test of epoch 89: loss -13.59211 acc 0.65789 roc_auc 0.50154 prc_auc 0.65250[0m
[92maverage training of epoch 90: loss -13.68803 acc 0.66667 roc_auc 0.41870 prc_auc 0.59603[0m
[93maverage test of epoch 90: loss -13.69154 acc 0.65789 roc_auc 0.60154 prc_auc 0.76456[0m
[92maverage training of epoch 91: loss -13.78743 acc 0.66667 roc_auc 0.41800 prc_auc 0.59620[0m
[93maverage test of epoch 91: loss -13.79063 acc 0.65789 roc_auc 0.60154 prc_auc 0.70217[0m
[92maverage training of epoch 92: loss -13.88705 acc 0.66667 roc_auc 0.41630 prc_auc 0.60386[0m
[93maverage test of epoch 92: loss -13.88978 acc 0.65789 roc_auc 0.48769 prc_auc 0.70722[0m
[92maverage training of epoch 93: loss -13.98634 acc 0.66667 roc_auc 0.42030 prc_auc 0.60228[0m
[93maverage test of epoch 93: loss -13.98928 acc 0.65789 roc_auc 0.49538 prc_auc 0.71950[0m
[92maverage training of epoch 94: loss -14.08595 acc 0.66667 roc_auc 0.41760 prc_auc 0.59347[0m
[93maverage test of epoch 94: loss -14.08823 acc 0.65789 roc_auc 0.43231 prc_auc 0.65152[0m
[92maverage training of epoch 95: loss -14.18543 acc 0.66667 roc_auc 0.42690 prc_auc 0.61726[0m
[93maverage test of epoch 95: loss -14.18758 acc 0.65789 roc_auc 0.54154 prc_auc 0.68272[0m
[92maverage training of epoch 96: loss -14.28502 acc 0.66667 roc_auc 0.42030 prc_auc 0.60606[0m
[93maverage test of epoch 96: loss -14.28679 acc 0.65789 roc_auc 0.51231 prc_auc 0.68449[0m
[92maverage training of epoch 97: loss -14.38437 acc 0.66667 roc_auc 0.41630 prc_auc 0.60827[0m
[93maverage test of epoch 97: loss -14.38575 acc 0.65789 roc_auc 0.27231 prc_auc 0.53397[0m
[92maverage training of epoch 98: loss -14.48405 acc 0.66667 roc_auc 0.42470 prc_auc 0.60680[0m
[93maverage test of epoch 98: loss -14.48512 acc 0.65789 roc_auc 0.43692 prc_auc 0.67227[0m
[92maverage training of epoch 99: loss -14.58353 acc 0.66667 roc_auc 0.42320 prc_auc 0.60234[0m
[93maverage test of epoch 99: loss -14.58429 acc 0.65789 roc_auc 0.46615 prc_auc 0.62806[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss 0.07633 acc 0.40000 roc_auc 0.39840 prc_auc 0.63164[0m
[93maverage test of epoch 0: loss -0.02596 acc 0.47368 roc_auc 0.60615 prc_auc 0.76784[0m
[92maverage training of epoch 1: loss -0.10345 acc 0.52667 roc_auc 0.50020 prc_auc 0.69341[0m
[93maverage test of epoch 1: loss -0.19199 acc 0.55263 roc_auc 0.50769 prc_auc 0.72601[0m
[92maverage training of epoch 2: loss -0.26473 acc 0.58667 roc_auc 0.43640 prc_auc 0.65340[0m
[93maverage test of epoch 2: loss -0.35409 acc 0.65789 roc_auc 0.53538 prc_auc 0.65364[0m
[92maverage training of epoch 3: loss -0.43605 acc 0.66000 roc_auc 0.49940 prc_auc 0.69298[0m
[93maverage test of epoch 3: loss -0.50026 acc 0.65789 roc_auc 0.41231 prc_auc 0.64361[0m
[92maverage training of epoch 4: loss -0.58864 acc 0.66667 roc_auc 0.44240 prc_auc 0.65133[0m
[93maverage test of epoch 4: loss -0.69203 acc 0.65789 roc_auc 0.73231 prc_auc 0.85184[0m
[92maverage training of epoch 5: loss -0.75099 acc 0.66667 roc_auc 0.52740 prc_auc 0.71091[0m
[93maverage test of epoch 5: loss -0.82772 acc 0.65789 roc_auc 0.61231 prc_auc 0.76978[0m
[92maverage training of epoch 6: loss -0.90078 acc 0.66667 roc_auc 0.54760 prc_auc 0.72145[0m
[93maverage test of epoch 6: loss -0.98356 acc 0.65789 roc_auc 0.70154 prc_auc 0.84266[0m
[92maverage training of epoch 7: loss -1.05901 acc 0.66667 roc_auc 0.52060 prc_auc 0.70349[0m
[93maverage test of epoch 7: loss -1.14484 acc 0.65789 roc_auc 0.71385 prc_auc 0.83758[0m
[92maverage training of epoch 8: loss -1.23521 acc 0.66667 roc_auc 0.59700 prc_auc 0.75863[0m
[93maverage test of epoch 8: loss -1.32399 acc 0.65789 roc_auc 0.63077 prc_auc 0.76970[0m
[92maverage training of epoch 9: loss -1.45735 acc 0.66667 roc_auc 0.64480 prc_auc 0.82383[0m
[93maverage test of epoch 9: loss -1.56587 acc 0.65789 roc_auc 0.73538 prc_auc 0.88537[0m
[92maverage training of epoch 10: loss -1.68718 acc 0.66667 roc_auc 0.58720 prc_auc 0.74505[0m
[93maverage test of epoch 10: loss -1.79007 acc 0.65789 roc_auc 0.63385 prc_auc 0.79311[0m
[92maverage training of epoch 11: loss -1.88538 acc 0.66667 roc_auc 0.52260 prc_auc 0.70810[0m
[93maverage test of epoch 11: loss -1.97530 acc 0.65789 roc_auc 0.66769 prc_auc 0.84983[0m
[92maverage training of epoch 12: loss -2.04533 acc 0.66667 roc_auc 0.51160 prc_auc 0.68797[0m
[93maverage test of epoch 12: loss -2.11355 acc 0.65789 roc_auc 0.54769 prc_auc 0.69119[0m
[92maverage training of epoch 13: loss -2.18476 acc 0.66667 roc_auc 0.48440 prc_auc 0.64440[0m
[93maverage test of epoch 13: loss -2.24991 acc 0.65789 roc_auc 0.70462 prc_auc 0.85470[0m
[92maverage training of epoch 14: loss -2.31151 acc 0.66667 roc_auc 0.53760 prc_auc 0.70212[0m
[93maverage test of epoch 14: loss -2.36209 acc 0.65789 roc_auc 0.60000 prc_auc 0.76131[0m
[92maverage training of epoch 15: loss -2.42837 acc 0.66667 roc_auc 0.41380 prc_auc 0.64853[0m
[93maverage test of epoch 15: loss -2.46588 acc 0.65789 roc_auc 0.32000 prc_auc 0.61516[0m
[92maverage training of epoch 16: loss -2.54099 acc 0.66667 roc_auc 0.39560 prc_auc 0.61949[0m
[93maverage test of epoch 16: loss -2.58256 acc 0.65789 roc_auc 0.54462 prc_auc 0.68486[0m
[92maverage training of epoch 17: loss -2.65697 acc 0.66667 roc_auc 0.53080 prc_auc 0.67084[0m
[93maverage test of epoch 17: loss -2.69442 acc 0.65789 roc_auc 0.38769 prc_auc 0.67243[0m
[92maverage training of epoch 18: loss -2.75748 acc 0.66667 roc_auc 0.40660 prc_auc 0.66009[0m
[93maverage test of epoch 18: loss -2.80767 acc 0.65789 roc_auc 0.61231 prc_auc 0.78271[0m
[92maverage training of epoch 19: loss -2.86587 acc 0.66667 roc_auc 0.48900 prc_auc 0.67615[0m
[93maverage test of epoch 19: loss -2.90909 acc 0.65789 roc_auc 0.62462 prc_auc 0.81680[0m
[92maverage training of epoch 20: loss -2.97335 acc 0.66667 roc_auc 0.55700 prc_auc 0.70327[0m
[93maverage test of epoch 20: loss -3.00867 acc 0.65789 roc_auc 0.44615 prc_auc 0.64459[0m
[92maverage training of epoch 21: loss -3.06788 acc 0.66667 roc_auc 0.41040 prc_auc 0.63056[0m
[93maverage test of epoch 21: loss -3.09639 acc 0.65789 roc_auc 0.35692 prc_auc 0.62463[0m
[92maverage training of epoch 22: loss -3.17549 acc 0.66667 roc_auc 0.51160 prc_auc 0.66267[0m
[93maverage test of epoch 22: loss -3.20794 acc 0.65789 roc_auc 0.46462 prc_auc 0.68529[0m
[92maverage training of epoch 23: loss -3.27354 acc 0.66667 roc_auc 0.49760 prc_auc 0.67213[0m
[93maverage test of epoch 23: loss -3.31512 acc 0.65789 roc_auc 0.60308 prc_auc 0.77115[0m
[92maverage training of epoch 24: loss -3.37235 acc 0.66667 roc_auc 0.47180 prc_auc 0.64532[0m
[93maverage test of epoch 24: loss -3.41115 acc 0.65789 roc_auc 0.59692 prc_auc 0.75739[0m
[92maverage training of epoch 25: loss -3.47323 acc 0.66667 roc_auc 0.53300 prc_auc 0.67760[0m
[93maverage test of epoch 25: loss -3.51120 acc 0.65789 roc_auc 0.59692 prc_auc 0.76627[0m
[92maverage training of epoch 26: loss -3.56859 acc 0.66667 roc_auc 0.43600 prc_auc 0.65707[0m
[93maverage test of epoch 26: loss -3.60609 acc 0.65789 roc_auc 0.57538 prc_auc 0.68283[0m
[92maverage training of epoch 27: loss -3.66860 acc 0.66667 roc_auc 0.54020 prc_auc 0.68343[0m
[93maverage test of epoch 27: loss -3.71080 acc 0.65789 roc_auc 0.61231 prc_auc 0.74858[0m
[92maverage training of epoch 28: loss -3.76354 acc 0.66667 roc_auc 0.38680 prc_auc 0.57853[0m
[93maverage test of epoch 28: loss -3.79592 acc 0.65789 roc_auc 0.34769 prc_auc 0.65487[0m
[92maverage training of epoch 29: loss -3.86642 acc 0.66667 roc_auc 0.50940 prc_auc 0.69596[0m
[93maverage test of epoch 29: loss -3.90315 acc 0.65789 roc_auc 0.60000 prc_auc 0.72073[0m
[92maverage training of epoch 30: loss -3.96671 acc 0.66667 roc_auc 0.50600 prc_auc 0.67622[0m
[93maverage test of epoch 30: loss -4.00771 acc 0.65789 roc_auc 0.60308 prc_auc 0.80007[0m
[92maverage training of epoch 31: loss -4.06969 acc 0.66667 roc_auc 0.46140 prc_auc 0.67722[0m
[93maverage test of epoch 31: loss -4.10185 acc 0.65789 roc_auc 0.39385 prc_auc 0.59765[0m
[92maverage training of epoch 32: loss -4.17625 acc 0.66667 roc_auc 0.37360 prc_auc 0.58710[0m
[93maverage test of epoch 32: loss -4.22483 acc 0.65789 roc_auc 0.60308 prc_auc 0.80920[0m
[92maverage training of epoch 33: loss -4.29272 acc 0.66667 roc_auc 0.51460 prc_auc 0.70477[0m
[93maverage test of epoch 33: loss -4.31773 acc 0.65789 roc_auc 0.35077 prc_auc 0.60382[0m
[92maverage training of epoch 34: loss -4.41011 acc 0.66667 roc_auc 0.43600 prc_auc 0.64734[0m
[93maverage test of epoch 34: loss -4.45837 acc 0.65789 roc_auc 0.61231 prc_auc 0.74838[0m
[92maverage training of epoch 35: loss -4.53262 acc 0.66667 roc_auc 0.45800 prc_auc 0.66970[0m
[93maverage test of epoch 35: loss -4.56367 acc 0.65789 roc_auc 0.44000 prc_auc 0.63365[0m
[92maverage training of epoch 36: loss -4.65451 acc 0.66667 roc_auc 0.44460 prc_auc 0.65526[0m
[93maverage test of epoch 36: loss -4.69475 acc 0.65789 roc_auc 0.48308 prc_auc 0.68444[0m
[92maverage training of epoch 37: loss -4.78115 acc 0.66667 roc_auc 0.47720 prc_auc 0.69013[0m
[93maverage test of epoch 37: loss -4.81965 acc 0.65789 roc_auc 0.48923 prc_auc 0.65123[0m
[92maverage training of epoch 38: loss -4.90155 acc 0.66667 roc_auc 0.48200 prc_auc 0.64120[0m
[93maverage test of epoch 38: loss -4.93552 acc 0.65789 roc_auc 0.49538 prc_auc 0.69398[0m
[92maverage training of epoch 39: loss -5.01806 acc 0.66667 roc_auc 0.44340 prc_auc 0.62839[0m
[93maverage test of epoch 39: loss -5.05291 acc 0.65789 roc_auc 0.58769 prc_auc 0.76509[0m
[92maverage training of epoch 40: loss -5.13563 acc 0.66667 roc_auc 0.45860 prc_auc 0.63566[0m
[93maverage test of epoch 40: loss -5.17285 acc 0.65789 roc_auc 0.63692 prc_auc 0.73873[0m
[92maverage training of epoch 41: loss -5.25080 acc 0.66667 roc_auc 0.46610 prc_auc 0.61787[0m
[93maverage test of epoch 41: loss -5.27747 acc 0.65789 roc_auc 0.55077 prc_auc 0.74453[0m
[92maverage training of epoch 42: loss -5.35957 acc 0.66667 roc_auc 0.38450 prc_auc 0.58514[0m
[93maverage test of epoch 42: loss -5.38574 acc 0.65789 roc_auc 0.51385 prc_auc 0.65619[0m
[92maverage training of epoch 43: loss -5.46925 acc 0.66667 roc_auc 0.50060 prc_auc 0.66102[0m
[93maverage test of epoch 43: loss -5.49267 acc 0.65789 roc_auc 0.57846 prc_auc 0.74243[0m
[92maverage training of epoch 44: loss -5.57768 acc 0.66667 roc_auc 0.47440 prc_auc 0.64195[0m
[93maverage test of epoch 44: loss -5.60106 acc 0.65789 roc_auc 0.49231 prc_auc 0.68260[0m
[92maverage training of epoch 45: loss -5.67751 acc 0.66667 roc_auc 0.34880 prc_auc 0.58815[0m
[93maverage test of epoch 45: loss -5.70768 acc 0.65789 roc_auc 0.58462 prc_auc 0.73727[0m
[92maverage training of epoch 46: loss -5.79106 acc 0.66667 roc_auc 0.51700 prc_auc 0.66424[0m
[93maverage test of epoch 46: loss -5.81756 acc 0.65789 roc_auc 0.53846 prc_auc 0.73833[0m
[92maverage training of epoch 47: loss -5.89467 acc 0.66667 roc_auc 0.37070 prc_auc 0.57106[0m
[93maverage test of epoch 47: loss -5.92252 acc 0.65789 roc_auc 0.66154 prc_auc 0.80048[0m
[92maverage training of epoch 48: loss -6.00115 acc 0.66667 roc_auc 0.47740 prc_auc 0.63392[0m
[93maverage test of epoch 48: loss -6.02278 acc 0.65789 roc_auc 0.63385 prc_auc 0.72192[0m
[92maverage training of epoch 49: loss -6.10502 acc 0.66667 roc_auc 0.46560 prc_auc 0.62084[0m
[93maverage test of epoch 49: loss -6.12863 acc 0.65789 roc_auc 0.45846 prc_auc 0.61866[0m
[92maverage training of epoch 50: loss -6.20813 acc 0.66667 roc_auc 0.41130 prc_auc 0.59713[0m
[93maverage test of epoch 50: loss -6.22699 acc 0.65789 roc_auc 0.40923 prc_auc 0.63741[0m
[92maverage training of epoch 51: loss -6.31329 acc 0.66667 roc_auc 0.43480 prc_auc 0.62569[0m
[93maverage test of epoch 51: loss -6.32897 acc 0.65789 roc_auc 0.61231 prc_auc 0.80565[0m
[92maverage training of epoch 52: loss -6.41629 acc 0.66667 roc_auc 0.49360 prc_auc 0.65959[0m
[93maverage test of epoch 52: loss -6.43204 acc 0.65789 roc_auc 0.42154 prc_auc 0.62538[0m
[92maverage training of epoch 53: loss -6.51670 acc 0.66667 roc_auc 0.45920 prc_auc 0.63860[0m
[93maverage test of epoch 53: loss -6.53766 acc 0.65789 roc_auc 0.53231 prc_auc 0.70884[0m
[92maverage training of epoch 54: loss -6.62099 acc 0.66667 roc_auc 0.45800 prc_auc 0.63397[0m
[93maverage test of epoch 54: loss -6.63773 acc 0.65789 roc_auc 0.47692 prc_auc 0.67975[0m
[92maverage training of epoch 55: loss -6.72250 acc 0.66667 roc_auc 0.46840 prc_auc 0.63433[0m
[93maverage test of epoch 55: loss -6.74273 acc 0.65789 roc_auc 0.40615 prc_auc 0.67807[0m
[92maverage training of epoch 56: loss -6.82531 acc 0.66667 roc_auc 0.44040 prc_auc 0.64272[0m
[93maverage test of epoch 56: loss -6.84506 acc 0.65789 roc_auc 0.59692 prc_auc 0.75132[0m
[92maverage training of epoch 57: loss -6.92556 acc 0.66667 roc_auc 0.43080 prc_auc 0.62527[0m
[93maverage test of epoch 57: loss -6.94479 acc 0.65789 roc_auc 0.73231 prc_auc 0.83701[0m
[92maverage training of epoch 58: loss -7.02800 acc 0.66667 roc_auc 0.41020 prc_auc 0.61997[0m
[93maverage test of epoch 58: loss -7.04208 acc 0.65789 roc_auc 0.36615 prc_auc 0.59473[0m
[92maverage training of epoch 59: loss -7.12731 acc 0.66667 roc_auc 0.38400 prc_auc 0.61529[0m
[93maverage test of epoch 59: loss -7.14743 acc 0.65789 roc_auc 0.49231 prc_auc 0.65920[0m
[92maverage training of epoch 60: loss -7.22956 acc 0.66667 roc_auc 0.41010 prc_auc 0.59186[0m
[93maverage test of epoch 60: loss -7.24655 acc 0.65789 roc_auc 0.34615 prc_auc 0.57008[0m
[92maverage training of epoch 61: loss -7.33240 acc 0.66667 roc_auc 0.42220 prc_auc 0.60796[0m
[93maverage test of epoch 61: loss -7.34846 acc 0.65789 roc_auc 0.50154 prc_auc 0.66882[0m
[92maverage training of epoch 62: loss -7.43203 acc 0.66667 roc_auc 0.44920 prc_auc 0.63288[0m
[93maverage test of epoch 62: loss -7.44954 acc 0.65789 roc_auc 0.43231 prc_auc 0.67655[0m
[92maverage training of epoch 63: loss -7.53298 acc 0.66667 roc_auc 0.39310 prc_auc 0.62233[0m
[93maverage test of epoch 63: loss -7.55008 acc 0.65789 roc_auc 0.61231 prc_auc 0.69989[0m
[92maverage training of epoch 64: loss -7.63350 acc 0.66667 roc_auc 0.41340 prc_auc 0.61898[0m
[93maverage test of epoch 64: loss -7.64751 acc 0.65789 roc_auc 0.39692 prc_auc 0.64130[0m
[92maverage training of epoch 65: loss -7.73423 acc 0.66667 roc_auc 0.39160 prc_auc 0.59613[0m
[93maverage test of epoch 65: loss -7.74989 acc 0.65789 roc_auc 0.52462 prc_auc 0.76976[0m
[92maverage training of epoch 66: loss -7.83526 acc 0.66667 roc_auc 0.41010 prc_auc 0.61277[0m
[93maverage test of epoch 66: loss -7.84918 acc 0.65789 roc_auc 0.45692 prc_auc 0.60660[0m
[92maverage training of epoch 67: loss -7.93564 acc 0.66667 roc_auc 0.39350 prc_auc 0.59767[0m
[93maverage test of epoch 67: loss -7.94944 acc 0.65789 roc_auc 0.62769 prc_auc 0.79022[0m
[92maverage training of epoch 68: loss -8.03537 acc 0.66667 roc_auc 0.40070 prc_auc 0.61966[0m
[93maverage test of epoch 68: loss -8.04988 acc 0.65789 roc_auc 0.41077 prc_auc 0.60473[0m
[92maverage training of epoch 69: loss -8.13715 acc 0.66667 roc_auc 0.40210 prc_auc 0.59467[0m
[93maverage test of epoch 69: loss -8.14984 acc 0.65789 roc_auc 0.49231 prc_auc 0.64646[0m
[92maverage training of epoch 70: loss -8.23740 acc 0.66667 roc_auc 0.36540 prc_auc 0.57662[0m
[93maverage test of epoch 70: loss -8.25057 acc 0.65789 roc_auc 0.47231 prc_auc 0.67321[0m
[92maverage training of epoch 71: loss -8.33721 acc 0.66667 roc_auc 0.39610 prc_auc 0.59578[0m
[93maverage test of epoch 71: loss -8.35021 acc 0.65789 roc_auc 0.50923 prc_auc 0.72653[0m
[92maverage training of epoch 72: loss -8.43682 acc 0.66667 roc_auc 0.39690 prc_auc 0.58943[0m
[93maverage test of epoch 72: loss -8.45002 acc 0.65789 roc_auc 0.48462 prc_auc 0.69217[0m
[92maverage training of epoch 73: loss -8.53686 acc 0.66667 roc_auc 0.40270 prc_auc 0.59313[0m
[93maverage test of epoch 73: loss -8.54983 acc 0.65789 roc_auc 0.20769 prc_auc 0.50946[0m
[92maverage training of epoch 74: loss -8.63742 acc 0.66667 roc_auc 0.39400 prc_auc 0.58765[0m
[93maverage test of epoch 74: loss -8.64818 acc 0.65789 roc_auc 0.47538 prc_auc 0.65975[0m
[92maverage training of epoch 75: loss -8.73688 acc 0.66667 roc_auc 0.39420 prc_auc 0.59687[0m
[93maverage test of epoch 75: loss -8.74874 acc 0.65789 roc_auc 0.40000 prc_auc 0.65846[0m
[92maverage training of epoch 76: loss -8.83660 acc 0.66667 roc_auc 0.37720 prc_auc 0.58468[0m
[93maverage test of epoch 76: loss -8.84767 acc 0.65789 roc_auc 0.51846 prc_auc 0.69750[0m
[92maverage training of epoch 77: loss -8.93678 acc 0.66667 roc_auc 0.38490 prc_auc 0.57637[0m
[93maverage test of epoch 77: loss -8.94755 acc 0.65789 roc_auc 0.51231 prc_auc 0.67273[0m
[92maverage training of epoch 78: loss -9.03674 acc 0.66667 roc_auc 0.41230 prc_auc 0.61386[0m
[93maverage test of epoch 78: loss -9.04827 acc 0.65789 roc_auc 0.59692 prc_auc 0.72006[0m
[92maverage training of epoch 79: loss -9.13622 acc 0.66667 roc_auc 0.37920 prc_auc 0.59058[0m
[93maverage test of epoch 79: loss -9.14644 acc 0.65789 roc_auc 0.50154 prc_auc 0.70234[0m
[92maverage training of epoch 80: loss -9.23614 acc 0.66667 roc_auc 0.38640 prc_auc 0.59351[0m
[93maverage test of epoch 80: loss -9.24723 acc 0.65789 roc_auc 0.55538 prc_auc 0.74761[0m
[92maverage training of epoch 81: loss -9.33627 acc 0.66667 roc_auc 0.42900 prc_auc 0.62015[0m
[93maverage test of epoch 81: loss -9.34628 acc 0.65789 roc_auc 0.49692 prc_auc 0.64732[0m
[92maverage training of epoch 82: loss -9.43560 acc 0.66667 roc_auc 0.37050 prc_auc 0.57319[0m
[93maverage test of epoch 82: loss -9.44582 acc 0.65789 roc_auc 0.50615 prc_auc 0.70970[0m
[92maverage training of epoch 83: loss -9.53565 acc 0.66667 roc_auc 0.38640 prc_auc 0.59463[0m
[93maverage test of epoch 83: loss -9.54548 acc 0.65789 roc_auc 0.49231 prc_auc 0.69427[0m
[92maverage training of epoch 84: loss -9.63536 acc 0.66667 roc_auc 0.37880 prc_auc 0.58383[0m
[93maverage test of epoch 84: loss -9.64477 acc 0.65789 roc_auc 0.50769 prc_auc 0.67162[0m
[92maverage training of epoch 85: loss -9.73524 acc 0.66667 roc_auc 0.37530 prc_auc 0.58228[0m
[93maverage test of epoch 85: loss -9.74416 acc 0.65789 roc_auc 0.53538 prc_auc 0.72297[0m
[92maverage training of epoch 86: loss -9.83458 acc 0.66667 roc_auc 0.39430 prc_auc 0.59104[0m
[93maverage test of epoch 86: loss -9.84395 acc 0.65789 roc_auc 0.60000 prc_auc 0.74028[0m
[92maverage training of epoch 87: loss -9.93486 acc 0.66667 roc_auc 0.38550 prc_auc 0.59249[0m
[93maverage test of epoch 87: loss -9.94260 acc 0.65789 roc_auc 0.51077 prc_auc 0.76761[0m
[92maverage training of epoch 88: loss -10.03442 acc 0.66667 roc_auc 0.37590 prc_auc 0.57564[0m
[93maverage test of epoch 88: loss -10.04251 acc 0.65789 roc_auc 0.57385 prc_auc 0.77485[0m
[92maverage training of epoch 89: loss -10.13390 acc 0.66667 roc_auc 0.39650 prc_auc 0.59655[0m
[93maverage test of epoch 89: loss -10.14167 acc 0.65789 roc_auc 0.64308 prc_auc 0.76485[0m
[92maverage training of epoch 90: loss -10.23368 acc 0.66667 roc_auc 0.39690 prc_auc 0.58792[0m
[93maverage test of epoch 90: loss -10.24133 acc 0.65789 roc_auc 0.55846 prc_auc 0.69396[0m
[92maverage training of epoch 91: loss -10.33295 acc 0.66667 roc_auc 0.38580 prc_auc 0.58455[0m
[93maverage test of epoch 91: loss -10.34023 acc 0.65789 roc_auc 0.66000 prc_auc 0.77785[0m
[92maverage training of epoch 92: loss -10.43280 acc 0.66667 roc_auc 0.38700 prc_auc 0.59075[0m
[93maverage test of epoch 92: loss -10.43916 acc 0.65789 roc_auc 0.55077 prc_auc 0.70424[0m
[92maverage training of epoch 93: loss -10.53233 acc 0.66667 roc_auc 0.38160 prc_auc 0.59113[0m
[93maverage test of epoch 93: loss -10.53893 acc 0.65789 roc_auc 0.55846 prc_auc 0.72885[0m
[92maverage training of epoch 94: loss -10.63188 acc 0.66667 roc_auc 0.40080 prc_auc 0.58988[0m
[93maverage test of epoch 94: loss -10.63792 acc 0.65789 roc_auc 0.49846 prc_auc 0.63646[0m
[92maverage training of epoch 95: loss -10.73138 acc 0.66667 roc_auc 0.39820 prc_auc 0.60430[0m
[93maverage test of epoch 95: loss -10.73705 acc 0.65789 roc_auc 0.50615 prc_auc 0.63831[0m
[92maverage training of epoch 96: loss -10.83095 acc 0.66667 roc_auc 0.37360 prc_auc 0.57405[0m
[93maverage test of epoch 96: loss -10.83690 acc 0.65789 roc_auc 0.49077 prc_auc 0.68109[0m
[92maverage training of epoch 97: loss -10.93060 acc 0.66667 roc_auc 0.37890 prc_auc 0.57421[0m
[93maverage test of epoch 97: loss -10.93559 acc 0.65789 roc_auc 0.58154 prc_auc 0.68321[0m
[92maverage training of epoch 98: loss -11.02981 acc 0.66667 roc_auc 0.38610 prc_auc 0.58469[0m
[93maverage test of epoch 98: loss -11.03510 acc 0.65789 roc_auc 0.36615 prc_auc 0.58095[0m
[92maverage training of epoch 99: loss -11.12945 acc 0.66667 roc_auc 0.37850 prc_auc 0.58182[0m
[93maverage test of epoch 99: loss -11.13456 acc 0.65789 roc_auc 0.62000 prc_auc 0.74223[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss 0.53086 acc 0.33775 roc_auc 0.42294 prc_auc 0.62057[0m
[93maverage test of epoch 0: loss 0.28634 acc 0.32432 roc_auc 0.46333 prc_auc 0.68422[0m
[92maverage training of epoch 1: loss 0.01504 acc 0.33775 roc_auc 0.49255 prc_auc 0.70337[0m
[93maverage test of epoch 1: loss -0.21355 acc 0.32432 roc_auc 0.68667 prc_auc 0.84153[0m
[92maverage training of epoch 2: loss -0.41480 acc 0.33775 roc_auc 0.58745 prc_auc 0.76764[0m
[93maverage test of epoch 2: loss -0.57935 acc 0.32432 roc_auc 0.72667 prc_auc 0.86776[0m
[92maverage training of epoch 3: loss -0.70362 acc 0.41060 roc_auc 0.71471 prc_auc 0.85533[0m
[93maverage test of epoch 3: loss -0.80932 acc 0.37838 roc_auc 0.81000 prc_auc 0.91784[0m
[92maverage training of epoch 4: loss -0.91162 acc 0.54967 roc_auc 0.73549 prc_auc 0.85349[0m
[93maverage test of epoch 4: loss -1.02496 acc 0.64865 roc_auc 0.78333 prc_auc 0.89457[0m
[92maverage training of epoch 5: loss -1.15399 acc 0.73510 roc_auc 0.81686 prc_auc 0.89956[0m
[93maverage test of epoch 5: loss -1.23666 acc 0.70270 roc_auc 0.79000 prc_auc 0.89293[0m
[92maverage training of epoch 6: loss -1.39381 acc 0.76821 roc_auc 0.87275 prc_auc 0.93535[0m
[93maverage test of epoch 6: loss -1.47178 acc 0.72973 roc_auc 0.81667 prc_auc 0.90606[0m
[92maverage training of epoch 7: loss -1.64728 acc 0.73510 roc_auc 0.87098 prc_auc 0.92732[0m
[93maverage test of epoch 7: loss -1.76594 acc 0.70270 roc_auc 0.86333 prc_auc 0.92560[0m
[92maverage training of epoch 8: loss -1.91310 acc 0.71523 roc_auc 0.87686 prc_auc 0.93344[0m
[93maverage test of epoch 8: loss -2.01079 acc 0.64865 roc_auc 0.84667 prc_auc 0.92007[0m
[92maverage training of epoch 9: loss -2.19644 acc 0.71523 roc_auc 0.87765 prc_auc 0.92568[0m
[93maverage test of epoch 9: loss -2.32184 acc 0.72973 roc_auc 0.84333 prc_auc 0.90684[0m
[92maverage training of epoch 10: loss -2.48365 acc 0.75497 roc_auc 0.87784 prc_auc 0.93212[0m
[93maverage test of epoch 10: loss -2.59623 acc 0.70270 roc_auc 0.85667 prc_auc 0.92749[0m
[92maverage training of epoch 11: loss -2.74640 acc 0.78146 roc_auc 0.88314 prc_auc 0.93125[0m
[93maverage test of epoch 11: loss -2.80031 acc 0.72973 roc_auc 0.84333 prc_auc 0.90401[0m
[92maverage training of epoch 12: loss -2.96293 acc 0.78146 roc_auc 0.87863 prc_auc 0.93346[0m
[93maverage test of epoch 12: loss -3.01407 acc 0.78378 roc_auc 0.83667 prc_auc 0.90766[0m
[92maverage training of epoch 13: loss -3.16487 acc 0.80132 roc_auc 0.88255 prc_auc 0.93173[0m
[93maverage test of epoch 13: loss -3.19301 acc 0.75676 roc_auc 0.86667 prc_auc 0.93578[0m
[92maverage training of epoch 14: loss -3.34355 acc 0.83444 roc_auc 0.88784 prc_auc 0.94314[0m
[93maverage test of epoch 14: loss -3.29898 acc 0.75676 roc_auc 0.86000 prc_auc 0.92368[0m
[92maverage training of epoch 15: loss -3.47747 acc 0.82119 roc_auc 0.87961 prc_auc 0.92311[0m
[93maverage test of epoch 15: loss -3.39616 acc 0.75676 roc_auc 0.85000 prc_auc 0.91116[0m
[92maverage training of epoch 16: loss -3.63346 acc 0.83444 roc_auc 0.89255 prc_auc 0.93896[0m
[93maverage test of epoch 16: loss -3.54294 acc 0.78378 roc_auc 0.81000 prc_auc 0.85787[0m
[92maverage training of epoch 17: loss -3.75400 acc 0.84106 roc_auc 0.86412 prc_auc 0.91154[0m
[93maverage test of epoch 17: loss -3.64575 acc 0.78378 roc_auc 0.83000 prc_auc 0.89842[0m
[92maverage training of epoch 18: loss -3.90032 acc 0.82119 roc_auc 0.90353 prc_auc 0.95194[0m
[93maverage test of epoch 18: loss -3.76192 acc 0.78378 roc_auc 0.82000 prc_auc 0.89255[0m
[92maverage training of epoch 19: loss -4.03608 acc 0.84768 roc_auc 0.85961 prc_auc 0.90694[0m
[93maverage test of epoch 19: loss -3.88589 acc 0.78378 roc_auc 0.79667 prc_auc 0.86852[0m
[92maverage training of epoch 20: loss -4.15200 acc 0.84768 roc_auc 0.89725 prc_auc 0.93966[0m
[93maverage test of epoch 20: loss -4.00831 acc 0.78378 roc_auc 0.86667 prc_auc 0.92222[0m
[92maverage training of epoch 21: loss -4.25252 acc 0.83444 roc_auc 0.87020 prc_auc 0.92365[0m
[93maverage test of epoch 21: loss -4.09454 acc 0.78378 roc_auc 0.79000 prc_auc 0.89267[0m
[92maverage training of epoch 22: loss -4.35122 acc 0.83444 roc_auc 0.84490 prc_auc 0.88583[0m
[93maverage test of epoch 22: loss -4.20868 acc 0.81081 roc_auc 0.80667 prc_auc 0.83656[0m
[92maverage training of epoch 23: loss -4.47977 acc 0.83444 roc_auc 0.88255 prc_auc 0.92958[0m
[93maverage test of epoch 23: loss -4.32186 acc 0.81081 roc_auc 0.79000 prc_auc 0.87332[0m
[92maverage training of epoch 24: loss -4.57581 acc 0.83444 roc_auc 0.88549 prc_auc 0.92028[0m
[93maverage test of epoch 24: loss -4.38964 acc 0.81081 roc_auc 0.75000 prc_auc 0.82646[0m
[92maverage training of epoch 25: loss -4.68689 acc 0.84106 roc_auc 0.90059 prc_auc 0.93989[0m
[93maverage test of epoch 25: loss -4.47884 acc 0.78378 roc_auc 0.83333 prc_auc 0.90714[0m
[92maverage training of epoch 26: loss -4.77402 acc 0.84106 roc_auc 0.86304 prc_auc 0.91669[0m
[93maverage test of epoch 26: loss -4.60075 acc 0.78378 roc_auc 0.80667 prc_auc 0.87466[0m
[92maverage training of epoch 27: loss -4.87651 acc 0.83444 roc_auc 0.88255 prc_auc 0.92744[0m
[93maverage test of epoch 27: loss -4.69248 acc 0.78378 roc_auc 0.78000 prc_auc 0.87776[0m
[92maverage training of epoch 28: loss -5.00234 acc 0.84106 roc_auc 0.88059 prc_auc 0.93083[0m
[93maverage test of epoch 28: loss -4.81187 acc 0.78378 roc_auc 0.83000 prc_auc 0.91629[0m
[92maverage training of epoch 29: loss -5.08619 acc 0.84106 roc_auc 0.88167 prc_auc 0.93338[0m
[93maverage test of epoch 29: loss -4.88566 acc 0.78378 roc_auc 0.79333 prc_auc 0.87742[0m
[92maverage training of epoch 30: loss -5.18211 acc 0.83444 roc_auc 0.88990 prc_auc 0.93316[0m
[93maverage test of epoch 30: loss -5.02213 acc 0.78378 roc_auc 0.86500 prc_auc 0.92134[0m
[92maverage training of epoch 31: loss -5.31066 acc 0.84106 roc_auc 0.89706 prc_auc 0.93226[0m
[93maverage test of epoch 31: loss -5.08525 acc 0.78378 roc_auc 0.75333 prc_auc 0.80161[0m
[92maverage training of epoch 32: loss -5.37270 acc 0.83444 roc_auc 0.88059 prc_auc 0.92334[0m
[93maverage test of epoch 32: loss -5.17319 acc 0.78378 roc_auc 0.83667 prc_auc 0.92102[0m
[92maverage training of epoch 33: loss -5.48396 acc 0.84768 roc_auc 0.86657 prc_auc 0.92209[0m
[93maverage test of epoch 33: loss -5.27058 acc 0.78378 roc_auc 0.74333 prc_auc 0.82586[0m
[92maverage training of epoch 34: loss -5.57858 acc 0.84106 roc_auc 0.88382 prc_auc 0.91720[0m
[93maverage test of epoch 34: loss -5.39173 acc 0.78378 roc_auc 0.85333 prc_auc 0.89918[0m
[92maverage training of epoch 35: loss -5.69703 acc 0.84106 roc_auc 0.87686 prc_auc 0.91594[0m
[93maverage test of epoch 35: loss -5.45251 acc 0.78378 roc_auc 0.84667 prc_auc 0.91610[0m
[92maverage training of epoch 36: loss -5.77076 acc 0.84106 roc_auc 0.86186 prc_auc 0.91665[0m
[93maverage test of epoch 36: loss -5.53349 acc 0.78378 roc_auc 0.81667 prc_auc 0.85835[0m
[92maverage training of epoch 37: loss -5.84852 acc 0.84106 roc_auc 0.88706 prc_auc 0.93150[0m
[93maverage test of epoch 37: loss -5.60433 acc 0.78378 roc_auc 0.77333 prc_auc 0.86610[0m
[92maverage training of epoch 38: loss -5.92282 acc 0.84106 roc_auc 0.85529 prc_auc 0.89835[0m
[93maverage test of epoch 38: loss -5.75670 acc 0.81081 roc_auc 0.84000 prc_auc 0.88787[0mUsing backend: pytorch

[92maverage training of epoch 39: loss -6.04313 acc 0.84768 roc_auc 0.88363 prc_auc 0.92455[0m
[93maverage test of epoch 39: loss -5.81606 acc 0.81081 roc_auc 0.87667 prc_auc 0.93846[0m
[92maverage training of epoch 40: loss -6.12129 acc 0.84106 roc_auc 0.87529 prc_auc 0.92217[0m
[93maverage test of epoch 40: loss -5.93107 acc 0.81081 roc_auc 0.85333 prc_auc 0.92059[0m
[92maverage training of epoch 41: loss -6.22337 acc 0.84768 roc_auc 0.88637 prc_auc 0.93449[0m
[93maverage test of epoch 41: loss -6.01953 acc 0.81081 roc_auc 0.83500 prc_auc 0.90818[0m
[92maverage training of epoch 42: loss -6.29135 acc 0.84106 roc_auc 0.88755 prc_auc 0.92779[0m
[93maverage test of epoch 42: loss -6.10713 acc 0.81081 roc_auc 0.79833 prc_auc 0.85176[0m
[92maverage training of epoch 43: loss -6.38002 acc 0.84106 roc_auc 0.88882 prc_auc 0.93062[0m
[93maverage test of epoch 43: loss -6.20566 acc 0.81081 roc_auc 0.79333 prc_auc 0.86068[0m
[92maverage training of epoch 44: loss -6.42554 acc 0.82781 roc_auc 0.90696 prc_auc 0.94862[0m
[93maverage test of epoch 44: loss -6.25550 acc 0.81081 roc_auc 0.84000 prc_auc 0.90977[0m
[92maverage training of epoch 45: loss -6.53978 acc 0.82781 roc_auc 0.87373 prc_auc 0.90806[0m
[93maverage test of epoch 45: loss -6.33032 acc 0.81081 roc_auc 0.79333 prc_auc 0.87097[0m
[92maverage training of epoch 46: loss -6.58389 acc 0.82781 roc_auc 0.88725 prc_auc 0.93406[0m
[93maverage test of epoch 46: loss -6.40723 acc 0.78378 roc_auc 0.80500 prc_auc 0.89974[0m
[92maverage training of epoch 47: loss -6.72552 acc 0.84106 roc_auc 0.90863 prc_auc 0.94146[0m
[93maverage test of epoch 47: loss -6.53691 acc 0.81081 roc_auc 0.87667 prc_auc 0.94816[0m
[92maverage training of epoch 48: loss -6.73775 acc 0.83444 roc_auc 0.86961 prc_auc 0.92129[0m
[93maverage test of epoch 48: loss -6.59104 acc 0.81081 roc_auc 0.77000 prc_auc 0.87959[0m
[92maverage training of epoch 49: loss -6.83950 acc 0.83444 roc_auc 0.89549 prc_auc 0.94513[0m
[93maverage test of epoch 49: loss -6.69291 acc 0.81081 roc_auc 0.82167 prc_auc 0.91391[0m
[92maverage training of epoch 50: loss -6.95132 acc 0.83444 roc_auc 0.87294 prc_auc 0.92066[0m
[93maverage test of epoch 50: loss -6.77624 acc 0.81081 roc_auc 0.79667 prc_auc 0.83319[0m
[92maverage training of epoch 51: loss -7.02905 acc 0.83444 roc_auc 0.88520 prc_auc 0.93550[0m
[93maverage test of epoch 51: loss -6.87006 acc 0.81081 roc_auc 0.74500 prc_auc 0.82526[0m
[92maverage training of epoch 52: loss -7.10212 acc 0.84106 roc_auc 0.88902 prc_auc 0.93512[0m
[93maverage test of epoch 52: loss -6.92194 acc 0.81081 roc_auc 0.77667 prc_auc 0.88036[0m
[92maverage training of epoch 53: loss -7.24841 acc 0.84768 roc_auc 0.84980 prc_auc 0.88344[0m
[93maverage test of epoch 53: loss -7.02091 acc 0.81081 roc_auc 0.76167 prc_auc 0.82022[0m
[92maverage training of epoch 54: loss -7.25031 acc 0.82781 roc_auc 0.87382 prc_auc 0.91016[0m
[93maverage test of epoch 54: loss -7.12802 acc 0.81081 roc_auc 0.83667 prc_auc 0.92225[0m
[92maverage training of epoch 55: loss -7.37805 acc 0.84106 roc_auc 0.89873 prc_auc 0.94976[0m
[93maverage test of epoch 55: loss -7.22091 acc 0.81081 roc_auc 0.77667 prc_auc 0.88027[0m
[92maverage training of epoch 56: loss -7.44248 acc 0.84106 roc_auc 0.90343 prc_auc 0.93904[0m
[93maverage test of epoch 56: loss -7.27837 acc 0.81081 roc_auc 0.80667 prc_auc 0.86526[0m
[92maverage training of epoch 57: loss -7.56997 acc 0.83444 roc_auc 0.91255 prc_auc 0.95063[0m
[93maverage test of epoch 57: loss -7.36365 acc 0.81081 roc_auc 0.78500 prc_auc 0.83664[0m
[92maverage training of epoch 58: loss -7.63789 acc 0.83444 roc_auc 0.88265 prc_auc 0.93398[0m
[93maverage test of epoch 58: loss -7.46301 acc 0.81081 roc_auc 0.78333 prc_auc 0.85523[0m
[92maverage training of epoch 59: loss -7.72982 acc 0.84106 roc_auc 0.90471 prc_auc 0.95468[0m
[93maverage test of epoch 59: loss -7.54568 acc 0.81081 roc_auc 0.84500 prc_auc 0.92250[0m
[92maverage training of epoch 60: loss -7.77168 acc 0.84106 roc_auc 0.86225 prc_auc 0.92478[0m
[93maverage test of epoch 60: loss -7.62775 acc 0.81081 roc_auc 0.76667 prc_auc 0.83983[0m
[92maverage training of epoch 61: loss -7.88115 acc 0.84106 roc_auc 0.88412 prc_auc 0.93512[0m
[93maverage test of epoch 61: loss -7.69913 acc 0.81081 roc_auc 0.75333 prc_auc 0.82836[0m
[92maverage training of epoch 62: loss -7.98113 acc 0.82781 roc_auc 0.87275 prc_auc 0.92021[0m
[93maverage test of epoch 62: loss -7.79327 acc 0.81081 roc_auc 0.79667 prc_auc 0.88205[0m
[92maverage training of epoch 63: loss -8.09132 acc 0.84106 roc_auc 0.89382 prc_auc 0.94324[0m
[93maverage test of epoch 63: loss -7.85683 acc 0.81081 roc_auc 0.78167 prc_auc 0.86785[0m
[92maverage training of epoch 64: loss -8.14576 acc 0.84106 roc_auc 0.89402 prc_auc 0.94047[0m
[93maverage test of epoch 64: loss -7.94488 acc 0.81081 roc_auc 0.78167 prc_auc 0.84545[0m
[92maverage training of epoch 65: loss -8.20587 acc 0.83444 roc_auc 0.90941 prc_auc 0.95777[0m
[93maverage test of epoch 65: loss -7.99013 acc 0.81081 roc_auc 0.83667 prc_auc 0.91222[0m
[92maverage training of epoch 66: loss -8.36746 acc 0.84768 roc_auc 0.88725 prc_auc 0.93178[0m
[93maverage test of epoch 66: loss -8.06630 acc 0.81081 roc_auc 0.75000 prc_auc 0.83198[0m
[92maverage training of epoch 67: loss -8.43692 acc 0.84768 roc_auc 0.88225 prc_auc 0.92392[0m
[93maverage test of epoch 67: loss -8.18199 acc 0.81081 roc_auc 0.76833 prc_auc 0.83366[0m
[92maverage training of epoch 68: loss -8.38677 acc 0.82781 roc_auc 0.90745 prc_auc 0.94821[0m
[93maverage test of epoch 68: loss -8.27556 acc 0.81081 roc_auc 0.84000 prc_auc 0.91028[0m
[92maverage training of epoch 69: loss -8.58882 acc 0.84106 roc_auc 0.88588 prc_auc 0.93771[0m
[93maverage test of epoch 69: loss -8.35197 acc 0.81081 roc_auc 0.85333 prc_auc 0.93638[0m
[92maverage training of epoch 70: loss -8.64881 acc 0.83444 roc_auc 0.89922 prc_auc 0.93885[0m
[93maverage test of epoch 70: loss -8.43516 acc 0.81081 roc_auc 0.75333 prc_auc 0.79825[0m
[92maverage training of epoch 71: loss -8.70350 acc 0.84106 roc_auc 0.89235 prc_auc 0.93173[0m
[93maverage test of epoch 71: loss -8.51075 acc 0.81081 roc_auc 0.80167 prc_auc 0.90366[0m
[92maverage training of epoch 72: loss -8.81450 acc 0.84106 roc_auc 0.87441 prc_auc 0.91003[0m
[93maverage test of epoch 72: loss -8.57629 acc 0.81081 roc_auc 0.75667 prc_auc 0.84422[0m
[92maverage training of epoch 73: loss -8.87152 acc 0.83444 roc_auc 0.89480 prc_auc 0.93155[0m
[93maverage test of epoch 73: loss -8.66083 acc 0.81081 roc_auc 0.72500 prc_auc 0.79231[0m
[92maverage training of epoch 74: loss -8.92453 acc 0.84106 roc_auc 0.89186 prc_auc 0.93177[0m
[93maverage test of epoch 74: loss -8.73394 acc 0.81081 roc_auc 0.75000 prc_auc 0.85802[0m
[92maverage training of epoch 75: loss -9.11963 acc 0.84768 roc_auc 0.90716 prc_auc 0.94233[0m
[93maverage test of epoch 75: loss -8.83053 acc 0.81081 roc_auc 0.79000 prc_auc 0.85005[0m
[92maverage training of epoch 76: loss -9.07195 acc 0.83444 roc_auc 0.87186 prc_auc 0.92178[0m
[93maverage test of epoch 76: loss -8.90415 acc 0.81081 roc_auc 0.68500 prc_auc 0.75353[0m
[92maverage training of epoch 77: loss -9.25549 acc 0.84768 roc_auc 0.87265 prc_auc 0.90688[0m
[93maverage test of epoch 77: loss -8.99342 acc 0.81081 roc_auc 0.76000 prc_auc 0.81514[0m
[92maverage training of epoch 78: loss -9.33182 acc 0.84768 roc_auc 0.89382 prc_auc 0.93728[0m
[93maverage test of epoch 78: loss -9.06111 acc 0.81081 roc_auc 0.79333 prc_auc 0.88357[0m
[92maverage training of epoch 79: loss -9.44922 acc 0.84106 roc_auc 0.91814 prc_auc 0.96125[0m
[93maverage test of epoch 79: loss -9.17510 acc 0.81081 roc_auc 0.76500 prc_auc 0.84728[0m
[92maverage training of epoch 80: loss -9.57859 acc 0.85430 roc_auc 0.88412 prc_auc 0.92646[0m
[93maverage test of epoch 80: loss -9.21531 acc 0.81081 roc_auc 0.74667 prc_auc 0.82895[0m
[92maverage training of epoch 81: loss -9.52064 acc 0.84106 roc_auc 0.89422 prc_auc 0.94308[0m
[93maverage test of epoch 81: loss -9.31883 acc 0.81081 roc_auc 0.82500 prc_auc 0.85620[0m
[92maverage training of epoch 82: loss -9.66265 acc 0.84106 roc_auc 0.87049 prc_auc 0.90891[0m
[93maverage test of epoch 82: loss -9.38992 acc 0.81081 roc_auc 0.82833 prc_auc 0.89679[0m
[92maverage training of epoch 83: loss -9.78369 acc 0.85430 roc_auc 0.88804 prc_auc 0.91823[0m
[93maverage test of epoch 83: loss -9.45808 acc 0.81081 roc_auc 0.81833 prc_auc 0.91356[0m
[92maverage training of epoch 84: loss -9.85213 acc 0.84768 roc_auc 0.88951 prc_auc 0.93178[0m
[93maverage test of epoch 84: loss -9.47328 acc 0.81081 roc_auc 0.74667 prc_auc 0.82578[0m
[92maverage training of epoch 85: loss -9.77964 acc 0.82781 roc_auc 0.90882 prc_auc 0.94878[0m
[93maverage test of epoch 85: loss -9.62410 acc 0.81081 roc_auc 0.81167 prc_auc 0.85027[0m
[92maverage training of epoch 86: loss -10.08522 acc 0.86093 roc_auc 0.89294 prc_auc 0.93688[0m
[93maverage test of epoch 86: loss -9.67953 acc 0.81081 roc_auc 0.78833 prc_auc 0.86610[0m
[92maverage training of epoch 87: loss -10.10207 acc 0.85430 roc_auc 0.92206 prc_auc 0.95376[0m
[93maverage test of epoch 87: loss -9.78334 acc 0.81081 roc_auc 0.82333 prc_auc 0.88391[0m
[92maverage training of epoch 88: loss -10.12620 acc 0.84768 roc_auc 0.90951 prc_auc 0.94142[0m
[93maverage test of epoch 88: loss -9.80167 acc 0.81081 roc_auc 0.83500 prc_auc 0.89144[0m
[92maverage training of epoch 89: loss -10.31978 acc 0.86093 roc_auc 0.90225 prc_auc 0.93982[0m
[93maverage test of epoch 89: loss -9.93490 acc 0.81081 roc_auc 0.76667 prc_auc 0.83589[0m
[92maverage training of epoch 90: loss -10.41214 acc 0.86755 roc_auc 0.90422 prc_auc 0.93252[0m
[93maverage test of epoch 90: loss -10.00468 acc 0.81081 roc_auc 0.77500 prc_auc 0.84569[0m
[92maverage training of epoch 91: loss -10.44093 acc 0.85430 roc_auc 0.88539 prc_auc 0.91998[0m
[93maverage test of epoch 91: loss -10.08473 acc 0.81081 roc_auc 0.79167 prc_auc 0.86187[0m
[92maverage training of epoch 92: loss -10.50540 acc 0.84768 roc_auc 0.89814 prc_auc 0.92914[0m
[93maverage test of epoch 92: loss -10.14489 acc 0.81081 roc_auc 0.84500 prc_auc 0.91015[0m
[92maverage training of epoch 93: loss -10.67126 acc 0.86755 roc_auc 0.89225 prc_auc 0.91903[0m
[93maverage test of epoch 93: loss -10.24723 acc 0.81081 roc_auc 0.80833 prc_auc 0.88207[0m
[92maverage training of epoch 94: loss -10.69983 acc 0.86093 roc_auc 0.87520 prc_auc 0.90899[0m
[93maverage test of epoch 94: loss -10.32478 acc 0.81081 roc_auc 0.81000 prc_auc 0.86321[0m
[92maverage training of epoch 95: loss -10.75187 acc 0.85430 roc_auc 0.89824 prc_auc 0.93028[0m
[93maverage test of epoch 95: loss -10.22943 acc 0.81081 roc_auc 0.83167 prc_auc 0.89120[0m
[92maverage training of epoch 96: loss -10.94030 acc 0.86093 roc_auc 0.89235 prc_auc 0.91491[0m
[93maverage test of epoch 96: loss -10.45605 acc 0.81081 roc_auc 0.73000 prc_auc 0.81089[0m
[92maverage training of epoch 97: loss -11.01634 acc 0.86093 roc_auc 0.89716 prc_auc 0.93471[0m
[93maverage test of epoch 97: loss -10.52199 acc 0.81081 roc_auc 0.82333 prc_auc 0.89067[0m
[92maverage training of epoch 98: loss -11.10441 acc 0.86093 roc_auc 0.89637 prc_auc 0.92565[0m
[93maverage test of epoch 98: loss -10.61864 acc 0.81081 roc_auc 0.80333 prc_auc 0.86724[0m
[92maverage training of epoch 99: loss -11.19153 acc 0.86755 roc_auc 0.89294 prc_auc 0.92973[0m
[93maverage test of epoch 99: loss -10.52678 acc 0.81081 roc_auc 0.74333 prc_auc 0.81309[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.24550 acc 0.35762 roc_auc 0.51275 prc_auc 0.68074[0m
[93maverage test of epoch 0: loss -0.44066 acc 0.29730 roc_auc 0.64000 prc_auc 0.74862[0m
[92maverage training of epoch 1: loss -0.62254 acc 0.43709 roc_auc 0.43412 prc_auc 0.61279[0m
[93maverage test of epoch 1: loss -0.79557 acc 0.62162 roc_auc 0.53333 prc_auc 0.70139[0m
[92maverage training of epoch 2: loss -0.94006 acc 0.61589 roc_auc 0.43569 prc_auc 0.63291[0m
[93maverage test of epoch 2: loss -1.08745 acc 0.67568 roc_auc 0.54000 prc_auc 0.71039[0m
[92maverage training of epoch 3: loss -1.22254 acc 0.66225 roc_auc 0.44529 prc_auc 0.65916[0m
[93maverage test of epoch 3: loss -1.35630 acc 0.67568 roc_auc 0.59667 prc_auc 0.77135[0m
[92maverage training of epoch 4: loss -1.47115 acc 0.66225 roc_auc 0.49275 prc_auc 0.68945[0m
[93maverage test of epoch 4: loss -1.62359 acc 0.67568 roc_auc 0.38000 prc_auc 0.60025[0m
[92maverage training of epoch 5: loss -1.76718 acc 0.66225 roc_auc 0.50922 prc_auc 0.69072[0m
[93maverage test of epoch 5: loss -1.93277 acc 0.67568 roc_auc 0.44667 prc_auc 0.68380[0m
[92maverage training of epoch 6: loss -2.13396 acc 0.66225 roc_auc 0.46608 prc_auc 0.65201[0m
[93maverage test of epoch 6: loss -2.36173 acc 0.67568 roc_auc 0.56667 prc_auc 0.78018[0m
[92maverage training of epoch 7: loss -2.60209 acc 0.66225 roc_auc 0.45373 prc_auc 0.64719[0m
[93maverage test of epoch 7: loss -2.88912 acc 0.67568 roc_auc 0.71000 prc_auc 0.83668[0m
[92maverage training of epoch 8: loss -3.13047 acc 0.66225 roc_auc 0.48569 prc_auc 0.62877[0m
[93maverage test of epoch 8: loss -3.41885 acc 0.67568 roc_auc 0.53667 prc_auc 0.70122[0m
[92maverage training of epoch 9: loss -3.62940 acc 0.66225 roc_auc 0.47667 prc_auc 0.63122[0m
[93maverage test of epoch 9: loss -3.87851 acc 0.67568 roc_auc 0.52000 prc_auc 0.68688[0m
[92maverage training of epoch 10: loss -4.01942 acc 0.66225 roc_auc 0.42745 prc_auc 0.62322[0m
[93maverage test of epoch 10: loss -4.18593 acc 0.67568 roc_auc 0.61333 prc_auc 0.72455[0m
[92maverage training of epoch 11: loss -4.30152 acc 0.66225 roc_auc 0.47314 prc_auc 0.63578[0m
[93maverage test of epoch 11: loss -4.43210 acc 0.67568 roc_auc 0.26667 prc_auc 0.55345[0m
[92maverage training of epoch 12: loss -4.54140 acc 0.66225 roc_auc 0.44510 prc_auc 0.65065[0m
[93maverage test of epoch 12: loss -4.66405 acc 0.67568 roc_auc 0.59000 prc_auc 0.72971[0m
[92maverage training of epoch 13: loss -4.73911 acc 0.66225 roc_auc 0.44961 prc_auc 0.64413[0m
[93maverage test of epoch 13: loss -4.84707 acc 0.67568 roc_auc 0.31333 prc_auc 0.60484[0m
[92maverage training of epoch 14: loss -4.91025 acc 0.66225 roc_auc 0.51863 prc_auc 0.69302[0m
[93maverage test of epoch 14: loss -5.01727 acc 0.67568 roc_auc 0.49667 prc_auc 0.66274[0m
[92maverage training of epoch 15: loss -5.07337 acc 0.66225 roc_auc 0.47941 prc_auc 0.67435[0m
[93maverage test of epoch 15: loss -5.16845 acc 0.67568 roc_auc 0.47667 prc_auc 0.72572[0m
[92maverage training of epoch 16: loss -5.21698 acc 0.66225 roc_auc 0.37353 prc_auc 0.58802[0m
[93maverage test of epoch 16: loss -5.28946 acc 0.67568 roc_auc 0.37000 prc_auc 0.63358[0m
[92maverage training of epoch 17: loss -5.36711 acc 0.66225 roc_auc 0.41000 prc_auc 0.62282[0m
[93maverage test of epoch 17: loss -5.43909 acc 0.67568 roc_auc 0.43333 prc_auc 0.69457[0m
[92maverage training of epoch 18: loss -5.50603 acc 0.66225 roc_auc 0.44745 prc_auc 0.64989[0m
[93maverage test of epoch 18: loss -5.58826 acc 0.67568 roc_auc 0.33667 prc_auc 0.62302[0m
[92maverage training of epoch 19: loss -5.62727 acc 0.66225 roc_auc 0.44098 prc_auc 0.62715[0m
[93maverage test of epoch 19: loss -5.71541 acc 0.67568 roc_auc 0.38333 prc_auc 0.61603[0m
[92maverage training of epoch 20: loss -5.76057 acc 0.66225 roc_auc 0.46510 prc_auc 0.65598[0m
[93maverage test of epoch 20: loss -5.84079 acc 0.67568 roc_auc 0.43333 prc_auc 0.63523[0m
[92maverage training of epoch 21: loss -5.88466 acc 0.66225 roc_auc 0.45353 prc_auc 0.61441[0m
[93maverage test of epoch 21: loss -5.97151 acc 0.67568 roc_auc 0.35667 prc_auc 0.57818[0m
[92maverage training of epoch 22: loss -5.99997 acc 0.66225 roc_auc 0.47235 prc_auc 0.64799[0m
[93maverage test of epoch 22: loss -6.07817 acc 0.67568 roc_auc 0.41000 prc_auc 0.62064[0m
[92maverage training of epoch 23: loss -6.11526 acc 0.66225 roc_auc 0.47157 prc_auc 0.67836[0m
[93maverage test of epoch 23: loss -6.19749 acc 0.67568 roc_auc 0.56000 prc_auc 0.69791[0m
[92maverage training of epoch 24: loss -6.23039 acc 0.66225 roc_auc 0.44275 prc_auc 0.62164[0m
[93maverage test of epoch 24: loss -6.30263 acc 0.67568 roc_auc 0.62667 prc_auc 0.77356[0m
[92maverage training of epoch 25: loss -6.34254 acc 0.66225 roc_auc 0.45863 prc_auc 0.63932[0m
[93maverage test of epoch 25: loss -6.43507 acc 0.67568 roc_auc 0.59667 prc_auc 0.73401[0m
[92maverage training of epoch 26: loss -6.44890 acc 0.66225 roc_auc 0.39441 prc_auc 0.61197[0m
[93maverage test of epoch 26: loss -6.53306 acc 0.67568 roc_auc 0.58333 prc_auc 0.76173[0m
[92maverage training of epoch 27: loss -6.56565 acc 0.66225 roc_auc 0.37529 prc_auc 0.60203[0m
[93maverage test of epoch 27: loss -6.64281 acc 0.67568 roc_auc 0.45667 prc_auc 0.64993[0m
[92maverage training of epoch 28: loss -6.67639 acc 0.66225 roc_auc 0.43235 prc_auc 0.60666[0m
[93maverage test of epoch 28: loss -6.75259 acc 0.67568 roc_auc 0.46000 prc_auc 0.61826[0m
[92maverage training of epoch 29: loss -6.78124 acc 0.66225 roc_auc 0.43333 prc_auc 0.60534[0m
[93maverage test of epoch 29: loss -6.85767 acc 0.67568 roc_auc 0.43667 prc_auc 0.65639[0m
[92maverage training of epoch 30: loss -6.89169 acc 0.66225 roc_auc 0.46912 prc_auc 0.61626[0m
[93maverage test of epoch 30: loss -6.97004 acc 0.67568 roc_auc 0.56000 prc_auc 0.70932[0m
[92maverage training of epoch 31: loss -6.99467 acc 0.66225 roc_auc 0.40333 prc_auc 0.60788[0m
[93maverage test of epoch 31: loss -7.07582 acc 0.67568 roc_auc 0.46000 prc_auc 0.71840[0m
[92maverage training of epoch 32: loss -7.10099 acc 0.66225 roc_auc 0.44647 prc_auc 0.61926[0m
[93maverage test of epoch 32: loss -7.18523 acc 0.67568 roc_auc 0.51000 prc_auc 0.70085[0m
[92maverage training of epoch 33: loss -7.20888 acc 0.66225 roc_auc 0.40863 prc_auc 0.58573[0m
[93maverage test of epoch 33: loss -7.28194 acc 0.67568 roc_auc 0.46667 prc_auc 0.68346[0m
[92maverage training of epoch 34: loss -7.31190 acc 0.66225 roc_auc 0.38206 prc_auc 0.59399[0m
[93maverage test of epoch 34: loss -7.39639 acc 0.67568 roc_auc 0.50000 prc_auc 0.69362[0m
[92maverage training of epoch 35: loss -7.41732 acc 0.66225 roc_auc 0.36804 prc_auc 0.57213[0m
[93maverage test of epoch 35: loss -7.50098 acc 0.67568 roc_auc 0.59333 prc_auc 0.77713[0m
[92maverage training of epoch 36: loss -7.52275 acc 0.66225 roc_auc 0.40373 prc_auc 0.58328[0m
[93maverage test of epoch 36: loss -7.60140 acc 0.67568 roc_auc 0.51333 prc_auc 0.73063[0m
[92maverage training of epoch 37: loss -7.62560 acc 0.66225 roc_auc 0.40137 prc_auc 0.58359[0m
[93maverage test of epoch 37: loss -7.70702 acc 0.67568 roc_auc 0.54000 prc_auc 0.68611[0m
[92maverage training of epoch 38: loss -7.73009 acc 0.66225 roc_auc 0.45098 prc_auc 0.62308[0m
[93maverage test of epoch 38: loss -7.80994 acc 0.67568 roc_auc 0.61333 prc_auc 0.71847[0m
[92maverage training of epoch 39: loss -7.83134 acc 0.66225 roc_auc 0.35941 prc_auc 0.55901[0m
[93maverage test of epoch 39: loss -7.91554 acc 0.67568 roc_auc 0.40333 prc_auc 0.64741[0m
[92maverage training of epoch 40: loss -7.93092 acc 0.66225 roc_auc 0.37980 prc_auc 0.59273[0m
[93maverage test of epoch 40: loss -8.01284 acc 0.67568 roc_auc 0.40333 prc_auc 0.62191[0m
[92maverage training of epoch 41: loss -8.03457 acc 0.66225 roc_auc 0.40284 prc_auc 0.59664[0m
[93maverage test of epoch 41: loss -8.11726 acc 0.67568 roc_auc 0.35000 prc_auc 0.66817[0m
[92maverage training of epoch 42: loss -8.13947 acc 0.66225 roc_auc 0.39647 prc_auc 0.58402[0m
[93maverage test of epoch 42: loss -8.22563 acc 0.67568 roc_auc 0.50333 prc_auc 0.70411[0m
[92maverage training of epoch 43: loss -8.24400 acc 0.66225 roc_auc 0.38667 prc_auc 0.58919[0m
[93maverage test of epoch 43: loss -8.32740 acc 0.67568 roc_auc 0.39500 prc_auc 0.63526[0m
[92maverage training of epoch 44: loss -8.34340 acc 0.66225 roc_auc 0.38608 prc_auc 0.58046[0m
[93maverage test of epoch 44: loss -8.42735 acc 0.67568 roc_auc 0.71333 prc_auc 0.83465[0m
[92maverage training of epoch 45: loss -8.44384 acc 0.66225 roc_auc 0.37725 prc_auc 0.59627[0m
[93maverage test of epoch 45: loss -8.53028 acc 0.67568 roc_auc 0.46333 prc_auc 0.68773[0m
[92maverage training of epoch 46: loss -8.54684 acc 0.66225 roc_auc 0.37902 prc_auc 0.58499[0m
[93maverage test of epoch 46: loss -8.63130 acc 0.67568 roc_auc 0.36500 prc_auc 0.62628[0m
[92maverage training of epoch 47: loss -8.64986 acc 0.66225 roc_auc 0.37118 prc_auc 0.57891[0m
[93maverage test of epoch 47: loss -8.73569 acc 0.67568 roc_auc 0.37833 prc_auc 0.60333[0m
[92maverage training of epoch 48: loss -8.75103 acc 0.66225 roc_auc 0.38275 prc_auc 0.57429[0m
[93maverage test of epoch 48: loss -8.83256 acc 0.67568 roc_auc 0.46333 prc_auc 0.61868[0m
[92maverage training of epoch 49: loss -8.85063 acc 0.66225 roc_auc 0.37647 prc_auc 0.57554[0m
[93maverage test of epoch 49: loss -8.93887 acc 0.67568 roc_auc 0.41000 prc_auc 0.65190[0m
[92maverage training of epoch 50: loss -8.95401 acc 0.66225 roc_auc 0.38451 prc_auc 0.57687[0m
[93maverage test of epoch 50: loss -9.03805 acc 0.67568 roc_auc 0.57667 prc_auc 0.76057[0m
[92maverage training of epoch 51: loss -9.05474 acc 0.66225 roc_auc 0.38706 prc_auc 0.60304[0m
[93maverage test of epoch 51: loss -9.14049 acc 0.67568 roc_auc 0.43833 prc_auc 0.61948[0m
[92maverage training of epoch 52: loss -9.15661 acc 0.66225 roc_auc 0.39304 prc_auc 0.58845[0m
[93maverage test of epoch 52: loss -9.24083 acc 0.67568 roc_auc 0.43333 prc_auc 0.64290[0m
[92maverage training of epoch 53: loss -9.25391 acc 0.66225 roc_auc 0.38255 prc_auc 0.57992[0m
[93maverage test of epoch 53: loss -9.34330 acc 0.67568 roc_auc 0.60667 prc_auc 0.79267[0m
[92maverage training of epoch 54: loss -9.35714 acc 0.66225 roc_auc 0.38137 prc_auc 0.58758[0m
[93maverage test of epoch 54: loss -9.44343 acc 0.67568 roc_auc 0.53833 prc_auc 0.71718[0m
[92maverage training of epoch 55: loss -9.45773 acc 0.66225 roc_auc 0.37059 prc_auc 0.57898[0m
[93maverage test of epoch 55: loss -9.54605 acc 0.67568 roc_auc 0.40167 prc_auc 0.63323[0m
[92maverage training of epoch 56: loss -9.55925 acc 0.66225 roc_auc 0.39529 prc_auc 0.58282[0m
[93maverage test of epoch 56: loss -9.64636 acc 0.67568 roc_auc 0.51333 prc_auc 0.70812[0m
[92maverage training of epoch 57: loss -9.65953 acc 0.66225 roc_auc 0.36578 prc_auc 0.57378[0m
[93maverage test of epoch 57: loss -9.74891 acc 0.67568 roc_auc 0.58667 prc_auc 0.72300[0m
[92maverage training of epoch 58: loss -9.76054 acc 0.66225 roc_auc 0.39843 prc_auc 0.58646[0m
[93maverage test of epoch 58: loss -9.84862 acc 0.67568 roc_auc 0.41667 prc_auc 0.63746[0m
[92maverage training of epoch 59: loss -9.86028 acc 0.66225 roc_auc 0.36382 prc_auc 0.57466[0m
[93maverage test of epoch 59: loss -9.95050 acc 0.67568 roc_auc 0.53667 prc_auc 0.69979[0m
[92maverage training of epoch 60: loss -9.96143 acc 0.66225 roc_auc 0.36314 prc_auc 0.57702[0m
[93maverage test of epoch 60: loss -10.04955 acc 0.67568 roc_auc 0.47833 prc_auc 0.67142[0m
[92maverage training of epoch 61: loss -10.06089 acc 0.66225 roc_auc 0.37647 prc_auc 0.58418[0m
[93maverage test of epoch 61: loss -10.15053 acc 0.67568 roc_auc 0.37167 prc_auc 0.60573[0m
[92maverage training of epoch 62: loss -10.16122 acc 0.66225 roc_auc 0.37588 prc_auc 0.57415[0m
[93maverage test of epoch 62: loss -10.25310 acc 0.67568 roc_auc 0.47333 prc_auc 0.67811[0m
[92maverage training of epoch 63: loss -10.26240 acc 0.66225 roc_auc 0.37451 prc_auc 0.57162[0m
[93maverage test of epoch 63: loss -10.35336 acc 0.67568 roc_auc 0.78833 prc_auc 0.89337[0m
[92maverage training of epoch 64: loss -10.36232 acc 0.66225 roc_auc 0.36069 prc_auc 0.56189[0m
[93maverage test of epoch 64: loss -10.45340 acc 0.67568 roc_auc 0.58000 prc_auc 0.76320[0m
[92maverage training of epoch 65: loss -10.46315 acc 0.66225 roc_auc 0.36804 prc_auc 0.57699[0m
[93maverage test of epoch 65: loss -10.55481 acc 0.67568 roc_auc 0.55000 prc_auc 0.68358[0m
[92maverage training of epoch 66: loss -10.56387 acc 0.66225 roc_auc 0.36029 prc_auc 0.58415[0m
[93maverage test of epoch 66: loss -10.65460 acc 0.67568 roc_auc 0.50667 prc_auc 0.74413[0m
[92maverage training of epoch 67: loss -10.66421 acc 0.66225 roc_auc 0.37020 prc_auc 0.56923[0m
[93maverage test of epoch 67: loss -10.75741 acc 0.67568 roc_auc 0.63000 prc_auc 0.75133[0m
[92maverage training of epoch 68: loss -10.76445 acc 0.66225 roc_auc 0.35941 prc_auc 0.56346[0m
[93maverage test of epoch 68: loss -10.85696 acc 0.67568 roc_auc 0.52000 prc_auc 0.69685[0m
[92maverage training of epoch 69: loss -10.86392 acc 0.66225 roc_auc 0.36775 prc_auc 0.58586[0m
[93maverage test of epoch 69: loss -10.95785 acc 0.67568 roc_auc 0.51500 prc_auc 0.77645[0m
[92maverage training of epoch 70: loss -10.96459 acc 0.66225 roc_auc 0.37775 prc_auc 0.57620[0m
[93maverage test of epoch 70: loss -11.05841 acc 0.67568 roc_auc 0.40333 prc_auc 0.65510[0m
[92maverage training of epoch 71: loss -11.06478 acc 0.66225 roc_auc 0.37441 prc_auc 0.56981[0m
[93maverage test of epoch 71: loss -11.15902 acc 0.67568 roc_auc 0.44667 prc_auc 0.65679[0m
[92maverage training of epoch 72: loss -11.16525 acc 0.66225 roc_auc 0.36745 prc_auc 0.57646[0m
[93maverage test of epoch 72: loss -11.25933 acc 0.67568 roc_auc 0.47333 prc_auc 0.73825[0m
[92maverage training of epoch 73: loss -11.26535 acc 0.66225 roc_auc 0.36804 prc_auc 0.56665[0m
[93maverage test of epoch 73: loss -11.36087 acc 0.67568 roc_auc 0.59667 prc_auc 0.73081[0m
[92maverage training of epoch 74: loss -11.36494 acc 0.66225 roc_auc 0.36451 prc_auc 0.57021[0m
[93maverage test of epoch 74: loss -11.46099 acc 0.67568 roc_auc 0.45333 prc_auc 0.66108[0m
[92maverage training of epoch 75: loss -11.46564 acc 0.66225 roc_auc 0.38373 prc_auc 0.57688[0m
[93maverage test of epoch 75: loss -11.56152 acc 0.67568 roc_auc 0.32333 prc_auc 0.57469[0m
[92maverage training of epoch 76: loss -11.56568 acc 0.66225 roc_auc 0.37137 prc_auc 0.57728[0m
[93maverage test of epoch 76: loss -11.66170 acc 0.67568 roc_auc 0.49833 prc_auc 0.66120[0m
[92maverage training of epoch 77: loss -11.66530 acc 0.66225 roc_auc 0.36735 prc_auc 0.56631[0m
[93maverage test of epoch 77: loss -11.76215 acc 0.67568 roc_auc 0.60167 prc_auc 0.78708[0m
[92maverage training of epoch 78: loss -11.76566 acc 0.66225 roc_auc 0.37284 prc_auc 0.57311[0m
[93maverage test of epoch 78: loss -11.86290 acc 0.67568 roc_auc 0.50833 prc_auc 0.66760[0m
[92maverage training of epoch 79: loss -11.86559 acc 0.66225 roc_auc 0.36696 prc_auc 0.56393[0m
[93maverage test of epoch 79: loss -11.96315 acc 0.67568 roc_auc 0.53833 prc_auc 0.69196[0m
[92maverage training of epoch 80: loss -11.96593 acc 0.66225 roc_auc 0.36971 prc_auc 0.56896[0m
[93maverage test of epoch 80: loss -12.06309 acc 0.67568 roc_auc 0.48667 prc_auc 0.65832[0m
[92maverage training of epoch 81: loss -12.06594 acc 0.66225 roc_auc 0.36804 prc_auc 0.56833[0m
[93maverage test of epoch 81: loss -12.16382 acc 0.67568 roc_auc 0.55833 prc_auc 0.72838[0m
[92maverage training of epoch 82: loss -12.16567 acc 0.66225 roc_auc 0.36431 prc_auc 0.57047[0m
[93maverage test of epoch 82: loss -12.26486 acc 0.67568 roc_auc 0.50333 prc_auc 0.71516[0m
[92maverage training of epoch 83: loss -12.26592 acc 0.66225 roc_auc 0.36990 prc_auc 0.57047[0m
[93maverage test of epoch 83: loss -12.36480 acc 0.67568 roc_auc 0.41667 prc_auc 0.61222[0m
[92maverage training of epoch 84: loss -12.36578 acc 0.66225 roc_auc 0.36824 prc_auc 0.56915[0m
[93maverage test of epoch 84: loss -12.46592 acc 0.67568 roc_auc 0.52667 prc_auc 0.72535[0m
[92maverage training of epoch 85: loss -12.46606 acc 0.66225 roc_auc 0.37039 prc_auc 0.57110[0m
[93maverage test of epoch 85: loss -12.56613 acc 0.67568 roc_auc 0.61333 prc_auc 0.76226[0m
[92maverage training of epoch 86: loss -12.56581 acc 0.66225 roc_auc 0.37137 prc_auc 0.56920[0m
[93maverage test of epoch 86: loss -12.66576 acc 0.67568 roc_auc 0.48500 prc_auc 0.69152[0m
[92maverage training of epoch 87: loss -12.66603 acc 0.66225 roc_auc 0.37706 prc_auc 0.57654[0m
[93maverage test of epoch 87: loss -12.76675 acc 0.67568 roc_auc 0.31500 prc_auc 0.59515[0m
[92maverage training of epoch 88: loss -12.76576 acc 0.66225 roc_auc 0.36206 prc_auc 0.56289[0m
[93maverage test of epoch 88: loss -12.86735 acc 0.67568 roc_auc 0.47333 prc_auc 0.64977[0m
[92maverage training of epoch 89: loss -12.86583 acc 0.66225 roc_auc 0.37010 prc_auc 0.56817[0m
[93maverage test of epoch 89: loss -12.96747 acc 0.67568 roc_auc 0.48667 prc_auc 0.67040[0m
[92maverage training of epoch 90: loss -12.96561 acc 0.66225 roc_auc 0.37265 prc_auc 0.57699[0m
[93maverage test of epoch 90: loss -13.06795 acc 0.67568 roc_auc 0.46000 prc_auc 0.65215[0m
[92maverage training of epoch 91: loss -13.06572 acc 0.66225 roc_auc 0.37235 prc_auc 0.57239[0m
[93maverage test of epoch 91: loss -13.16825 acc 0.67568 roc_auc 0.56500 prc_auc 0.71962[0m
[92maverage training of epoch 92: loss -13.16575 acc 0.66225 roc_auc 0.36912 prc_auc 0.57120[0m
[93maverage test of epoch 92: loss -13.26849 acc 0.67568 roc_auc 0.46833 prc_auc 0.65865[0m
[92maverage training of epoch 93: loss -13.26562 acc 0.66225 roc_auc 0.37255 prc_auc 0.57379[0m
[93maverage test of epoch 93: loss -13.36867 acc 0.67568 roc_auc 0.39333 prc_auc 0.60115[0m
[92maverage training of epoch 94: loss -13.36549 acc 0.66225 roc_auc 0.36794 prc_auc 0.56840[0m
[93maverage test of epoch 94: loss -13.46926 acc 0.67568 roc_auc 0.38500 prc_auc 0.66351[0m
[92maverage training of epoch 95: loss -13.46550 acc 0.66225 roc_auc 0.36873 prc_auc 0.57254[0m
[93maverage test of epoch 95: loss -13.56968 acc 0.67568 roc_auc 0.43000 prc_auc 0.62931[0m
[92maverage training of epoch 96: loss -13.56538 acc 0.66225 roc_auc 0.36216 prc_auc 0.56374[0m
[93maverage test of epoch 96: loss -13.67026 acc 0.67568 roc_auc 0.74833 prc_auc 0.84455[0m
[92maverage training of epoch 97: loss -13.66532 acc 0.66225 roc_auc 0.37245 prc_auc 0.57150[0m
[93maverage test of epoch 97: loss -13.77050 acc 0.67568 roc_auc 0.37833 prc_auc 0.63210[0m
[92maverage training of epoch 98: loss -13.76539 acc 0.66225 roc_auc 0.36784 prc_auc 0.56839[0m
[93maverage test of epoch 98: loss -13.87070 acc 0.67568 roc_auc 0.40500 prc_auc 0.65258[0m
[92maverage training of epoch 99: loss -13.86514 acc 0.66225 roc_auc 0.36882 prc_auc 0.56780[0m
[93maverage test of epoch 99: loss -13.97114 acc 0.67568 roc_auc 0.58667 prc_auc 0.76646[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.0001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.72361 ROC_AUC (avg): 0.65554 PRC_AUC (avg): 0.77643 

Average forward propagation time taken(ms): 3.975785665177178
Average backward propagation time taken(ms): 1.522770634900501

