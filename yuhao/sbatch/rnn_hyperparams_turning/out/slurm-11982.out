# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-04-05-38/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-04-05-38/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 16,
 'epochs': 100,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 8,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.001,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 1,
 'num_workers': 8,
 'number_of_mlp_layer': 0,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-18-04-05-38',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 100, 'learning_rate': 0.001, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -1.19514 acc 0.45333 roc_auc 0.42480 prc_auc 0.63668[0m
[93maverage test of epoch 0: loss -2.14204 acc 0.65789 roc_auc 0.56615 prc_auc 0.79509[0m
[92maverage training of epoch 1: loss -3.22064 acc 0.66667 roc_auc 0.40720 prc_auc 0.62340[0m
[93maverage test of epoch 1: loss -4.28413 acc 0.65789 roc_auc 0.87846 prc_auc 0.93781[0m
[92maverage training of epoch 2: loss -5.04852 acc 0.66667 roc_auc 0.38820 prc_auc 0.60419[0m
[93maverage test of epoch 2: loss -5.68280 acc 0.65789 roc_auc 0.87231 prc_auc 0.93534[0m
[92maverage training of epoch 3: loss -6.29327 acc 0.66667 roc_auc 0.42000 prc_auc 0.63500[0m
[93maverage test of epoch 3: loss -6.85054 acc 0.65789 roc_auc 0.86769 prc_auc 0.93736[0m
[92maverage training of epoch 4: loss -7.46139 acc 0.66667 roc_auc 0.42900 prc_auc 0.64146[0m
[93maverage test of epoch 4: loss -8.02654 acc 0.65789 roc_auc 0.87385 prc_auc 0.94252[0m
[92maverage training of epoch 5: loss -8.63738 acc 0.66667 roc_auc 0.38280 prc_auc 0.60998[0m
[93maverage test of epoch 5: loss -9.19135 acc 0.65789 roc_auc 0.87846 prc_auc 0.94346[0m
[92maverage training of epoch 6: loss -9.78156 acc 0.66667 roc_auc 0.37060 prc_auc 0.58658[0m
[93maverage test of epoch 6: loss -10.31123 acc 0.65789 roc_auc 0.87231 prc_auc 0.94166[0m
[92maverage training of epoch 7: loss -10.88572 acc 0.66667 roc_auc 0.36640 prc_auc 0.57930[0m
[93maverage test of epoch 7: loss -11.39652 acc 0.65789 roc_auc 0.86462 prc_auc 0.92033[0m
[92maverage training of epoch 8: loss -11.96183 acc 0.66667 roc_auc 0.36080 prc_auc 0.56516[0m
[93maverage test of epoch 8: loss -12.45901 acc 0.65789 roc_auc 0.80000 prc_auc 0.86316[0m
[92maverage training of epoch 9: loss -13.01906 acc 0.66667 roc_auc 0.35900 prc_auc 0.56353[0m
[93maverage test of epoch 9: loss -13.50589 acc 0.65789 roc_auc 0.72000 prc_auc 0.80842[0m
[92maverage training of epoch 10: loss -14.06302 acc 0.66667 roc_auc 0.35780 prc_auc 0.56257[0m
[93maverage test of epoch 10: loss -14.54153 acc 0.65789 roc_auc 0.76000 prc_auc 0.83579[0m
[92maverage training of epoch 11: loss -15.09724 acc 0.66667 roc_auc 0.35750 prc_auc 0.56208[0m
[93maverage test of epoch 11: loss -15.56878 acc 0.65789 roc_auc 0.68000 prc_auc 0.78105[0m
[92maverage training of epoch 12: loss -16.12408 acc 0.66667 roc_auc 0.35710 prc_auc 0.56207[0m
[93maverage test of epoch 12: loss -16.58959 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 13: loss -17.14517 acc 0.66667 roc_auc 0.35710 prc_auc 0.56196[0m
[93maverage test of epoch 13: loss -17.60533 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 14: loss -18.16173 acc 0.66667 roc_auc 0.35700 prc_auc 0.56185[0m
[93maverage test of epoch 14: loss -18.61701 acc 0.65789 roc_auc 0.52000 prc_auc 0.67158[0m
[92maverage training of epoch 15: loss -19.17461 acc 0.66667 roc_auc 0.35730 prc_auc 0.56172[0m
[93maverage test of epoch 15: loss -19.62542 acc 0.65789 roc_auc 0.52000 prc_auc 0.67158[0m
[92maverage training of epoch 16: loss -20.18452 acc 0.66667 roc_auc 0.35750 prc_auc 0.56165[0m
[93maverage test of epoch 16: loss -20.63114 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 17: loss -21.19198 acc 0.66667 roc_auc 0.35690 prc_auc 0.56167[0m
[93maverage test of epoch 17: loss -21.63464 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 18: loss -22.19741 acc 0.66667 roc_auc 0.35740 prc_auc 0.56237[0m
[93maverage test of epoch 18: loss -22.63631 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -23.20115 acc 0.66667 roc_auc 0.35790 prc_auc 0.56341[0m
[93maverage test of epoch 19: loss -23.63643 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -24.20347 acc 0.66667 roc_auc 0.35770 prc_auc 0.56280[0m
[93maverage test of epoch 20: loss -24.63525 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -25.20459 acc 0.66667 roc_auc 0.35760 prc_auc 0.56505[0m
[93maverage test of epoch 21: loss -25.63299 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -26.20470 acc 0.66667 roc_auc 0.35820 prc_auc 0.56251[0m
[93maverage test of epoch 22: loss -26.62979 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -27.20395 acc 0.66667 roc_auc 0.35990 prc_auc 0.56552[0m
[93maverage test of epoch 23: loss -27.62581 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -28.20248 acc 0.66667 roc_auc 0.35960 prc_auc 0.56616[0m
[93maverage test of epoch 24: loss -28.62116 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -29.20038 acc 0.66667 roc_auc 0.35510 prc_auc 0.56600[0m
[93maverage test of epoch 25: loss -29.61594 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -30.19776 acc 0.66667 roc_auc 0.35900 prc_auc 0.56838[0m
[93maverage test of epoch 26: loss -30.61024 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -31.19469 acc 0.66667 roc_auc 0.36290 prc_auc 0.57637[0m
[93maverage test of epoch 27: loss -31.60411 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -32.19122 acc 0.66667 roc_auc 0.35680 prc_auc 0.56894[0m
[93maverage test of epoch 28: loss -32.59763 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -33.18742 acc 0.66667 roc_auc 0.36410 prc_auc 0.57688[0m
[93maverage test of epoch 29: loss -33.59083 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -34.18334 acc 0.66667 roc_auc 0.37160 prc_auc 0.58715[0m
[93maverage test of epoch 30: loss -34.58378 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -35.17901 acc 0.66667 roc_auc 0.36300 prc_auc 0.58518[0m
[93maverage test of epoch 31: loss -35.57651 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -36.17447 acc 0.66667 roc_auc 0.36290 prc_auc 0.58935[0m
[93maverage test of epoch 32: loss -36.56903 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -37.16974 acc 0.66667 roc_auc 0.36410 prc_auc 0.59343[0m
[93maverage test of epoch 33: loss -37.56137 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -38.16486 acc 0.66667 roc_auc 0.39420 prc_auc 0.62590[0m
[93maverage test of epoch 34: loss -38.55358 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -39.15984 acc 0.66667 roc_auc 0.36880 prc_auc 0.60448[0m
[93maverage test of epoch 35: loss -39.54566 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -40.15469 acc 0.66667 roc_auc 0.41540 prc_auc 0.62872[0m
[93maverage test of epoch 36: loss -40.53762 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -41.14944 acc 0.66667 roc_auc 0.42380 prc_auc 0.63316[0m
[93maverage test of epoch 37: loss -41.52949 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -42.14411 acc 0.66667 roc_auc 0.36170 prc_auc 0.61668[0m
[93maverage test of epoch 38: loss -42.52128 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -43.13870 acc 0.66667 roc_auc 0.40000 prc_auc 0.64000[0m
[93maverage test of epoch 39: loss -43.51300 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -44.13322 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -44.50465 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -45.12769 acc 0.66667 roc_auc 0.43000 prc_auc 0.63767[0m
[93maverage test of epoch 41: loss -45.49625 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -46.12210 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -46.48780 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -47.11647 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -47.47932 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -48.11080 acc 0.66667 roc_auc 0.37500 prc_auc 0.63506[0m
[93maverage test of epoch 44: loss -48.47080 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -49.10510 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -49.46224 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -50.09937 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -50.45366 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -51.09361 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -51.44506 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -52.08783 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -52.43643 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -53.08203 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -53.42778 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 50: loss -54.07621 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 50: loss -54.41911 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 51: loss -55.07037 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 51: loss -55.41043 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 52: loss -56.06451 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 52: loss -56.40173 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 53: loss -57.05864 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 53: loss -57.39302 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 54: loss -58.05276 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 54: loss -58.38430 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 55: loss -59.04687 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 55: loss -59.37556 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 56: loss -60.04097 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 56: loss -60.36681 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 57: loss -61.03505 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 57: loss -61.35806 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 58: loss -62.02914 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 58: loss -62.34930 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 59: loss -63.02321 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 59: loss -63.34054 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 60: loss -64.01728 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 60: loss -64.33177 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 61: loss -65.01135 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 61: loss -65.32300 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 62: loss -66.00541 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 62: loss -66.31423 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 63: loss -66.99947 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 63: loss -67.30546 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 64: loss -67.99353 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 64: loss -68.29667 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 65: loss -68.98758 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 65: loss -69.28788 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 66: loss -69.98163 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 66: loss -70.27909 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 67: loss -70.97567 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 67: loss -71.27029 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 68: loss -71.96970 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 68: loss -72.26149 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 69: loss -72.96373 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 69: loss -73.25268 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 70: loss -73.95775 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 70: loss -74.24385 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 71: loss -74.95177 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 71: loss -75.23503 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 72: loss -75.94578 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 72: loss -76.22620 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 73: loss -76.93979 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 73: loss -77.21738 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 74: loss -77.93379 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 74: loss -78.20854 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 75: loss -78.92779 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 75: loss -79.19970 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 76: loss -79.92179 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 76: loss -80.19086 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 77: loss -80.91579 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 77: loss -81.18202 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 78: loss -81.90977 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 78: loss -82.17317 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 79: loss -82.90376 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 79: loss -83.16431 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 80: loss -83.89774 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 80: loss -84.15545 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 81: loss -84.89172 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 81: loss -85.14659 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 82: loss -85.88569 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 82: loss -86.13772 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 83: loss -86.87966 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 83: loss -87.12885 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 84: loss -87.87362 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 84: loss -88.11998 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 85: loss -88.86759 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 85: loss -89.11110 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 86: loss -89.86155 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 86: loss -90.10223 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 87: loss -90.85550 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 87: loss -91.09334 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 88: loss -91.84945 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 88: loss -92.08445 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 89: loss -92.84340 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 89: loss -93.07556 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -93.83735 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 90: loss -94.06666 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 91: loss -94.83129 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 91: loss -95.05776 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 92: loss -95.82522 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 92: loss -96.04886 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 93: loss -96.81916 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 93: loss -97.03995 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 94: loss -97.81309 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 94: loss -98.03104 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 95: loss -98.80701 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 95: loss -99.02213 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 96: loss -99.80093 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 96: loss -100.01320 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 97: loss -100.79484 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 97: loss -101.00428 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 98: loss -101.78876 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 98: loss -101.99536 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -102.78266 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 99: loss -102.98641 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -1.22922 acc 0.66667 roc_auc 0.46820 prc_auc 0.65576[0m
[93maverage test of epoch 0: loss -2.94545 acc 0.65789 roc_auc 0.53231 prc_auc 0.73435[0m
[92maverage training of epoch 1: loss -4.46297 acc 0.66667 roc_auc 0.43160 prc_auc 0.60901[0m
[93maverage test of epoch 1: loss -5.45891 acc 0.65789 roc_auc 0.69231 prc_auc 0.83898[0m
[92maverage training of epoch 2: loss -6.08969 acc 0.66667 roc_auc 0.42440 prc_auc 0.61097[0m
[93maverage test of epoch 2: loss -6.65771 acc 0.65789 roc_auc 0.56154 prc_auc 0.77355[0m
[92maverage training of epoch 3: loss -7.27431 acc 0.66667 roc_auc 0.40020 prc_auc 0.60299[0m
[93maverage test of epoch 3: loss -7.89928 acc 0.65789 roc_auc 0.17692 prc_auc 0.55224[0m
[92maverage training of epoch 4: loss -8.53795 acc 0.66667 roc_auc 0.41320 prc_auc 0.59551[0m
[93maverage test of epoch 4: loss -9.11989 acc 0.65789 roc_auc 0.19077 prc_auc 0.56346[0m
[92maverage training of epoch 5: loss -9.70780 acc 0.66667 roc_auc 0.41980 prc_auc 0.60403[0m
[93maverage test of epoch 5: loss -10.24586 acc 0.65789 roc_auc 0.16923 prc_auc 0.58458[0m
[92maverage training of epoch 6: loss -10.81373 acc 0.66667 roc_auc 0.42020 prc_auc 0.60491[0m
[93maverage test of epoch 6: loss -11.32952 acc 0.65789 roc_auc 0.23538 prc_auc 0.66118[0m
[92maverage training of epoch 7: loss -11.88769 acc 0.66667 roc_auc 0.42030 prc_auc 0.60491[0m
[93maverage test of epoch 7: loss -12.38915 acc 0.65789 roc_auc 0.35692 prc_auc 0.64702[0m
[92maverage training of epoch 8: loss -12.94217 acc 0.66667 roc_auc 0.42030 prc_auc 0.60470[0m
[93maverage test of epoch 8: loss -13.43316 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 9: loss -13.98349 acc 0.66667 roc_auc 0.42030 prc_auc 0.60470[0m
[93maverage test of epoch 9: loss -14.46622 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 10: loss -15.01535 acc 0.66667 roc_auc 0.42020 prc_auc 0.60455[0m
[93maverage test of epoch 10: loss -15.49122 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 11: loss -16.04013 acc 0.66667 roc_auc 0.42020 prc_auc 0.60458[0m
[93maverage test of epoch 11: loss -16.51007 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 12: loss -17.05946 acc 0.66667 roc_auc 0.42010 prc_auc 0.60497[0m
[93maverage test of epoch 12: loss -17.52413 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 13: loss -18.07448 acc 0.66667 roc_auc 0.42010 prc_auc 0.60497[0m
[93maverage test of epoch 13: loss -18.53439 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 14: loss -19.08606 acc 0.66667 roc_auc 0.42020 prc_auc 0.60494[0m
[93maverage test of epoch 14: loss -19.54157 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 15: loss -20.09485 acc 0.66667 roc_auc 0.42030 prc_auc 0.60458[0m
[93maverage test of epoch 15: loss -20.54624 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 16: loss -21.10136 acc 0.66667 roc_auc 0.42030 prc_auc 0.60461[0m
[93maverage test of epoch 16: loss -21.54886 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 17: loss -22.10598 acc 0.66667 roc_auc 0.42020 prc_auc 0.60548[0m
[93maverage test of epoch 17: loss -22.54977 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 18: loss -23.10903 acc 0.66667 roc_auc 0.42040 prc_auc 0.60558[0m
[93maverage test of epoch 18: loss -23.54925 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 19: loss -24.11077 acc 0.66667 roc_auc 0.42040 prc_auc 0.60566[0m
[93maverage test of epoch 19: loss -24.54753 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 20: loss -25.11139 acc 0.66667 roc_auc 0.42050 prc_auc 0.60553[0m
[93maverage test of epoch 20: loss -25.54480 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 21: loss -26.11109 acc 0.66667 roc_auc 0.42060 prc_auc 0.60447[0m
[93maverage test of epoch 21: loss -26.54122 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -27.11000 acc 0.66667 roc_auc 0.42110 prc_auc 0.60631[0m
[93maverage test of epoch 22: loss -27.53692 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -28.10823 acc 0.66667 roc_auc 0.42010 prc_auc 0.60247[0m
[93maverage test of epoch 23: loss -28.53200 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 24: loss -29.10589 acc 0.66667 roc_auc 0.42010 prc_auc 0.60503[0m
[93maverage test of epoch 24: loss -29.52656 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -30.10307 acc 0.66667 roc_auc 0.42100 prc_auc 0.60417[0m
[93maverage test of epoch 25: loss -30.52067 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -31.09983 acc 0.66667 roc_auc 0.41940 prc_auc 0.60106[0m
[93maverage test of epoch 26: loss -31.51440 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -32.09624 acc 0.66667 roc_auc 0.42070 prc_auc 0.60096[0m
[93maverage test of epoch 27: loss -32.50779 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 28: loss -33.09233 acc 0.66667 roc_auc 0.42160 prc_auc 0.60476[0m
[93maverage test of epoch 28: loss -33.50091 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -34.08817 acc 0.66667 roc_auc 0.41980 prc_auc 0.60371[0m
[93maverage test of epoch 29: loss -34.49378 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -35.08378 acc 0.66667 roc_auc 0.42390 prc_auc 0.60985[0m
[93maverage test of epoch 30: loss -35.48645 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -36.07919 acc 0.66667 roc_auc 0.42360 prc_auc 0.60659[0m
[93maverage test of epoch 31: loss -36.47893 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -37.07444 acc 0.66667 roc_auc 0.42450 prc_auc 0.60955[0m
[93maverage test of epoch 32: loss -37.47127 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -38.06954 acc 0.66667 roc_auc 0.42970 prc_auc 0.61590[0m
[93maverage test of epoch 33: loss -38.46346 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -39.06452 acc 0.66667 roc_auc 0.42630 prc_auc 0.62011[0m
[93maverage test of epoch 34: loss -39.45555 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -40.05939 acc 0.66667 roc_auc 0.43650 prc_auc 0.62779[0m
[93maverage test of epoch 35: loss -40.44753 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -41.05416 acc 0.66667 roc_auc 0.45980 prc_auc 0.64223[0m
[93maverage test of epoch 36: loss -41.43941 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -42.04885 acc 0.66667 roc_auc 0.45700 prc_auc 0.64225[0m
[93maverage test of epoch 37: loss -42.43123 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -43.04346 acc 0.66667 roc_auc 0.46910 prc_auc 0.65176[0m
[93maverage test of epoch 38: loss -43.42297 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -44.03802 acc 0.66667 roc_auc 0.46220 prc_auc 0.64797[0m
[93maverage test of epoch 39: loss -44.41466 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -45.03252 acc 0.66667 roc_auc 0.46500 prc_auc 0.65168[0m
[93maverage test of epoch 40: loss -45.40630 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -46.02698 acc 0.66667 roc_auc 0.48000 prc_auc 0.65797[0m
[93maverage test of epoch 41: loss -46.39790 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -47.02139 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -47.38947 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -48.01578 acc 0.66667 roc_auc 0.49500 prc_auc 0.66445[0m
[93maverage test of epoch 43: loss -48.38100 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -49.01013 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -49.37250 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -50.00446 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -50.36399 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -50.99877 acc 0.66667 roc_auc 0.46000 prc_auc 0.64965[0m
[93maverage test of epoch 46: loss -51.35544 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -51.99305 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -52.34687 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -52.98731 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -53.33829 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -53.98155 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -54.32969 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 50: loss -54.97578 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 50: loss -55.32107 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 51: loss -55.96999 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 51: loss -56.31244 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 52: loss -56.96419 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 52: loss -57.30380 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 53: loss -57.95838 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 53: loss -58.29515 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 54: loss -58.95257 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 54: loss -59.28649 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 55: loss -59.94673 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 55: loss -60.27781 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 56: loss -60.94089 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 56: loss -61.26913 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 57: loss -61.93503 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 57: loss -62.26043 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 58: loss -62.92917 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 58: loss -63.25172 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 59: loss -63.92329 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 59: loss -64.24300 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 60: loss -64.91739 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 60: loss -65.23426 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 61: loss -65.91149 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 61: loss -66.22553 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 62: loss -66.90558 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 62: loss -67.21678 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 63: loss -67.89967 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 63: loss -68.20802 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 64: loss -68.89374 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 64: loss -69.19926 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 65: loss -69.88781 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 65: loss -70.19048 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 66: loss -70.88187 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 66: loss -71.18171 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 67: loss -71.87593 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 67: loss -72.17293 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 68: loss -72.86998 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 68: loss -73.16414 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 69: loss -73.86403 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 69: loss -74.15534 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 70: loss -74.85807 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 70: loss -75.14656 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 71: loss -75.85211 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 71: loss -76.13776 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 72: loss -76.84614 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 72: loss -77.12895 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 73: loss -77.84017 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 73: loss -78.12014 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 74: loss -78.83419 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 74: loss -79.11133 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 75: loss -79.82821 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 75: loss -80.10251 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 76: loss -80.82223 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 76: loss -81.09368 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 77: loss -81.81624 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 77: loss -82.08485 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 78: loss -82.81024 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 78: loss -83.07601 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 79: loss -83.80424 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 79: loss -84.06718 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 80: loss -84.79823 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 80: loss -85.05833 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 81: loss -85.79223 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 81: loss -86.04949 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 82: loss -86.78621 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 82: loss -87.04063 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 83: loss -87.78020 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 83: loss -88.03179 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 84: loss -88.77418 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 84: loss -89.02293 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 85: loss -89.76816 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 85: loss -90.01407 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 86: loss -90.76213 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 86: loss -91.00521 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 87: loss -91.75611 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 87: loss -91.99634 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 88: loss -92.75008 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 88: loss -92.98747 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 89: loss -93.74404 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 89: loss -93.97860 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -94.73800 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 90: loss -94.96971 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 91: loss -95.73195 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 91: loss -95.96083 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 92: loss -96.72590 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 92: loss -96.95194 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 93: loss -97.71984 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 93: loss -97.94304 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 94: loss -98.71378 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 94: loss -98.93414 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 95: loss -99.70771 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 95: loss -99.92523 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 96: loss -100.70164 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 96: loss -100.91632 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 97: loss -101.69556 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 97: loss -101.90741 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 98: loss -102.68947 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 98: loss -102.89848 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -103.68338 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 99: loss -103.88956 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -1.35275 acc 0.66667 roc_auc 0.43740 prc_auc 0.64990[0m
[93maverage test of epoch 0: loss -2.31782 acc 0.65789 roc_auc 0.95385 prc_auc 0.97886[0m
[92maverage training of epoch 1: loss -3.19916 acc 0.66667 roc_auc 0.44210 prc_auc 0.64653[0m
[93maverage test of epoch 1: loss -4.11372 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 2: loss -4.97608 acc 0.66667 roc_auc 0.41390 prc_auc 0.62271[0m
[93maverage test of epoch 2: loss -5.68734 acc 0.65789 roc_auc 0.95077 prc_auc 0.97702[0m
[92maverage training of epoch 3: loss -6.44609 acc 0.66667 roc_auc 0.40060 prc_auc 0.61110[0m
[93maverage test of epoch 3: loss -7.05100 acc 0.65789 roc_auc 0.95846 prc_auc 0.97574[0m
[92maverage training of epoch 4: loss -7.72046 acc 0.66667 roc_auc 0.38980 prc_auc 0.60373[0m
[93maverage test of epoch 4: loss -8.25165 acc 0.65789 roc_auc 0.94308 prc_auc 0.96232[0m
[92maverage training of epoch 5: loss -8.88577 acc 0.66667 roc_auc 0.38620 prc_auc 0.60062[0m
[93maverage test of epoch 5: loss -9.38232 acc 0.65789 roc_auc 0.86462 prc_auc 0.87965[0m
[92maverage training of epoch 6: loss -9.99891 acc 0.66667 roc_auc 0.38610 prc_auc 0.59971[0m
[93maverage test of epoch 6: loss -10.47451 acc 0.65789 roc_auc 0.92000 prc_auc 0.94526[0m
[92maverage training of epoch 7: loss -11.08127 acc 0.66667 roc_auc 0.38490 prc_auc 0.59300[0m
[93maverage test of epoch 7: loss -11.54236 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 8: loss -12.14338 acc 0.66667 roc_auc 0.38350 prc_auc 0.59082[0m
[93maverage test of epoch 8: loss -12.59352 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 9: loss -13.19123 acc 0.66667 roc_auc 0.37970 prc_auc 0.58602[0m
[93maverage test of epoch 9: loss -13.63263 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 10: loss -14.22860 acc 0.66667 roc_auc 0.38010 prc_auc 0.57854[0m
[93maverage test of epoch 10: loss -14.66269 acc 0.65789 roc_auc 0.74923 prc_auc 0.79432[0m
[92maverage training of epoch 11: loss -15.25800 acc 0.66667 roc_auc 0.38260 prc_auc 0.58101[0m
[93maverage test of epoch 11: loss -15.68580 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 12: loss -16.28119 acc 0.66667 roc_auc 0.37990 prc_auc 0.58318[0m
[93maverage test of epoch 12: loss -16.70343 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 13: loss -17.29947 acc 0.66667 roc_auc 0.38170 prc_auc 0.58282[0m
[93maverage test of epoch 13: loss -17.71669 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 14: loss -18.31380 acc 0.66667 roc_auc 0.37130 prc_auc 0.58027[0m
[93maverage test of epoch 14: loss -18.72640 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 15: loss -19.32491 acc 0.66667 roc_auc 0.38670 prc_auc 0.59247[0m
[93maverage test of epoch 15: loss -19.73321 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 16: loss -20.33337 acc 0.66667 roc_auc 0.38580 prc_auc 0.59400[0m
[93maverage test of epoch 16: loss -20.73763 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 17: loss -21.33963 acc 0.66667 roc_auc 0.37510 prc_auc 0.59163[0m
[93maverage test of epoch 17: loss -21.74006 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 18: loss -22.34408 acc 0.66667 roc_auc 0.38990 prc_auc 0.60425[0m
[93maverage test of epoch 18: loss -22.74083 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -23.34699 acc 0.66667 roc_auc 0.39400 prc_auc 0.60775[0m
[93maverage test of epoch 19: loss -23.74020 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -24.34861 acc 0.66667 roc_auc 0.40940 prc_auc 0.61722[0m
[93maverage test of epoch 20: loss -24.73839 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -25.34915 acc 0.66667 roc_auc 0.43580 prc_auc 0.63240[0m
[93maverage test of epoch 21: loss -25.73559 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -26.34877 acc 0.66667 roc_auc 0.44020 prc_auc 0.63795[0m
[93maverage test of epoch 22: loss -26.73195 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -27.34761 acc 0.66667 roc_auc 0.44670 prc_auc 0.64103[0m
[93maverage test of epoch 23: loss -27.72758 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -28.34577 acc 0.66667 roc_auc 0.44500 prc_auc 0.64353[0m
[93maverage test of epoch 24: loss -28.72260 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -29.34337 acc 0.66667 roc_auc 0.44000 prc_auc 0.64157[0m
[93maverage test of epoch 25: loss -29.71709 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -30.34048 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 26: loss -30.71113 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -31.33716 acc 0.66667 roc_auc 0.49500 prc_auc 0.66445[0m
[93maverage test of epoch 27: loss -31.70479 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -32.33350 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 28: loss -32.69812 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -33.32952 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 29: loss -33.69116 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -34.32528 acc 0.66667 roc_auc 0.44500 prc_auc 0.64353[0m
[93maverage test of epoch 30: loss -34.68396 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -35.32081 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 31: loss -35.67655 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -36.31614 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 32: loss -36.66895 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -37.31130 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 33: loss -37.66120 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -38.30633 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -38.65332 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -39.30121 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -39.64531 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -40.29599 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -40.63721 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -41.29068 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -41.62901 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -42.28529 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -42.62075 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -43.27982 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -43.61241 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -44.27429 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -44.60401 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -45.26871 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -45.59557 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -46.26307 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -46.58707 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -47.25740 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -47.57854 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -48.25168 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -48.56998 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -49.24594 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -49.56138 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -50.24016 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -50.55276 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -51.23436 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -51.54410 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -52.22854 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -52.53543 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -53.22269 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -53.52674 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 50: loss -54.21683 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 50: loss -54.51803 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 51: loss -55.21094 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 51: loss -55.50930 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 52: loss -56.20504 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 52: loss -56.50056 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 53: loss -57.19913 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 53: loss -57.49180 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 54: loss -58.19321 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 54: loss -58.48303 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 55: loss -59.18727 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 55: loss -59.47425 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 56: loss -60.18132 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 56: loss -60.46547 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 57: loss -61.17536 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 57: loss -61.45666 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 58: loss -62.16939 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 58: loss -62.44785 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 59: loss -63.16341 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 59: loss -63.43903 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 60: loss -64.15743 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 60: loss -64.43020 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 61: loss -65.15143 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 61: loss -65.42136 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 62: loss -66.14542 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 62: loss -66.41251 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 63: loss -67.13941 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 63: loss -67.40366 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 64: loss -68.13338 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 64: loss -68.39479 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 65: loss -69.12735 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 65: loss -69.38592 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 66: loss -70.12131 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 66: loss -70.37704 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 67: loss -71.11526 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 67: loss -71.36815 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 68: loss -72.10921 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 68: loss -72.35926 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 69: loss -73.10315 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 69: loss -73.35036 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 70: loss -74.09709 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 70: loss -74.34147 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 71: loss -75.09102 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 71: loss -75.33255 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 72: loss -76.08494 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 72: loss -76.32363 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 73: loss -77.07885 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 73: loss -77.31471 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 74: loss -78.07277 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 74: loss -78.30578 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 75: loss -79.06667 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 75: loss -79.29686 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 76: loss -80.06058 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 76: loss -80.28792 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 77: loss -81.05448 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 77: loss -81.27898 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 78: loss -82.04838 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 78: loss -82.27004 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 79: loss -83.04227 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 79: loss -83.26110 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 80: loss -84.03615 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 80: loss -84.25214 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 81: loss -85.03004 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 81: loss -85.24319 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 82: loss -86.02392 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 82: loss -86.23423 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 83: loss -87.01780 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 83: loss -87.22527 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 84: loss -88.01167 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 84: loss -88.21631 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 85: loss -89.00554 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 85: loss -89.20734 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 86: loss -89.99941 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 86: loss -90.19837 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 87: loss -90.99328 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 87: loss -91.18941 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 88: loss -91.98715 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 88: loss -92.18043 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 89: loss -92.98101 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 89: loss -93.17146 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -93.97487 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 90: loss -94.16248 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 91: loss -94.96873 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 91: loss -95.15349 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 92: loss -95.96258 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 92: loss -96.14450 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 93: loss -96.95642 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 93: loss -97.13550 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 94: loss -97.95026 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 94: loss -98.12650 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 95: loss -98.94409 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 95: loss -99.11751 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 96: loss -99.93793 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 96: loss -100.10849 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 97: loss -100.93175 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 97: loss -101.09948 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 98: loss -101.92557 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 98: loss -102.09045 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -102.91939 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 99: loss -103.08142 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -1.44197 acc 0.66225 roc_auc 0.42137 prc_auc 0.61290[0m
[93maverage test of epoch 0: loss -2.50422 acc 0.67568 roc_auc 0.83333 prc_auc 0.91751[0m
[92maverage training of epoch 1: loss -3.48850 acc 0.66225 roc_auc 0.42863 prc_auc 0.61164[0m
[93maverage test of epoch 1: loss -4.61888 acc 0.67568 roc_auc 0.84833 prc_auc 0.92548[0m
[92maverage training of epoch 2: loss -5.43437 acc 0.66225 roc_auc 0.40216 prc_auc 0.59622[0m
[93maverage test of epoch 2: loss -6.28013 acc 0.67568 roc_auc 0.85833 prc_auc 0.92419[0m
[92maverage training of epoch 3: loss -6.85292 acc 0.66225 roc_auc 0.39206 prc_auc 0.58775[0m
[93maverage test of epoch 3: loss -7.55454 acc 0.67568 roc_auc 0.86000 prc_auc 0.92404[0m
[92maverage training of epoch 4: loss -8.06046 acc 0.66225 roc_auc 0.38608 prc_auc 0.57750[0m
[93maverage test of epoch 4: loss -8.71937 acc 0.67568 roc_auc 0.86167 prc_auc 0.91588[0m
[92maverage training of epoch 5: loss -9.19269 acc 0.66225 roc_auc 0.38265 prc_auc 0.57532[0m
[93maverage test of epoch 5: loss -9.83283 acc 0.67568 roc_auc 0.84333 prc_auc 0.89024[0m
[92maverage training of epoch 6: loss -10.28580 acc 0.66225 roc_auc 0.38069 prc_auc 0.57316[0m
[93maverage test of epoch 6: loss -10.91661 acc 0.67568 roc_auc 0.84000 prc_auc 0.87252[0m
[92maverage training of epoch 7: loss -11.35503 acc 0.66225 roc_auc 0.37843 prc_auc 0.57178[0m
[93maverage test of epoch 7: loss -11.98123 acc 0.67568 roc_auc 0.66000 prc_auc 0.76849[0m
[92maverage training of epoch 8: loss -12.40829 acc 0.66225 roc_auc 0.37784 prc_auc 0.57109[0m
[93maverage test of epoch 8: loss -13.03255 acc 0.67568 roc_auc 0.72000 prc_auc 0.80439[0m
[92maverage training of epoch 9: loss -13.45021 acc 0.66225 roc_auc 0.37716 prc_auc 0.57087[0m
[93maverage test of epoch 9: loss -14.07420 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 10: loss -14.48374 acc 0.66225 roc_auc 0.37676 prc_auc 0.57007[0m
[93maverage test of epoch 10: loss -15.10856 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 11: loss -15.51086 acc 0.66225 roc_auc 0.37667 prc_auc 0.57100[0m
[93maverage test of epoch 11: loss -16.13729 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 12: loss -16.53298 acc 0.66225 roc_auc 0.37657 prc_auc 0.57030[0m
[93maverage test of epoch 12: loss -17.16157 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 13: loss -17.55113 acc 0.66225 roc_auc 0.37647 prc_auc 0.57048[0m
[93maverage test of epoch 13: loss -18.18230 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 14: loss -18.56608 acc 0.66225 roc_auc 0.37598 prc_auc 0.57063[0m
[93maverage test of epoch 14: loss -19.20014 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 15: loss -19.57842 acc 0.66225 roc_auc 0.37618 prc_auc 0.57188[0m
[93maverage test of epoch 15: loss -20.21561 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 16: loss -20.58861 acc 0.66225 roc_auc 0.37578 prc_auc 0.57151[0m
[93maverage test of epoch 16: loss -21.22914 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 17: loss -21.59702 acc 0.66225 roc_auc 0.37510 prc_auc 0.57160[0m
[93maverage test of epoch 17: loss -22.24104 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 18: loss -22.60395 acc 0.66225 roc_auc 0.37667 prc_auc 0.57343[0m
[93maverage test of epoch 18: loss -23.25158 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 19: loss -23.60965 acc 0.66225 roc_auc 0.37676 prc_auc 0.57133[0m
[93maverage test of epoch 19: loss -24.26098 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 20: loss -24.61429 acc 0.66225 roc_auc 0.37676 prc_auc 0.57318[0m
[93maverage test of epoch 20: loss -25.26942 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 21: loss -25.61805 acc 0.66225 roc_auc 0.37588 prc_auc 0.57449[0m
[93maverage test of epoch 21: loss -26.27705 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 22: loss -26.62107 acc 0.66225 roc_auc 0.37647 prc_auc 0.57652[0m
[93maverage test of epoch 22: loss -27.28399 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 23: loss -27.62344 acc 0.66225 roc_auc 0.37539 prc_auc 0.57513[0m
[93maverage test of epoch 23: loss -28.29034 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 24: loss -28.62528 acc 0.66225 roc_auc 0.37402 prc_auc 0.57990[0m
[93maverage test of epoch 24: loss -29.29619 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 25: loss -29.62665 acc 0.66225 roc_auc 0.37137 prc_auc 0.57740[0m
[93maverage test of epoch 25: loss -30.30161 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 26: loss -30.62763 acc 0.66225 roc_auc 0.37794 prc_auc 0.58639[0m
[93maverage test of epoch 26: loss -31.30666 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 27: loss -31.62827 acc 0.66225 roc_auc 0.38794 prc_auc 0.59488[0m
[93maverage test of epoch 27: loss -32.31141 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 28: loss -32.62861 acc 0.66225 roc_auc 0.38294 prc_auc 0.59435[0m
[93maverage test of epoch 28: loss -33.31588 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 29: loss -33.62872 acc 0.66225 roc_auc 0.38814 prc_auc 0.60271[0m
[93maverage test of epoch 29: loss -34.32013 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 30: loss -34.62861 acc 0.66225 roc_auc 0.43951 prc_auc 0.63208[0m
[93maverage test of epoch 30: loss -35.32417 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 31: loss -35.62832 acc 0.66225 roc_auc 0.36284 prc_auc 0.60009[0m
[93maverage test of epoch 31: loss -36.32805 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 32: loss -36.62787 acc 0.66225 roc_auc 0.42784 prc_auc 0.63226[0m
[93maverage test of epoch 32: loss -37.33178 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 33: loss -37.62727 acc 0.66225 roc_auc 0.39088 prc_auc 0.61963[0m
[93maverage test of epoch 33: loss -38.33537 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 34: loss -38.62656 acc 0.66225 roc_auc 0.35931 prc_auc 0.62372[0m
[93maverage test of epoch 34: loss -39.33885 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 35: loss -39.62574 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 35: loss -40.34225 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0mUsing backend: pytorch
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))

[92maverage training of epoch 36: loss -40.62484 acc 0.66225 roc_auc 0.43745 prc_auc 0.63606[0m
[93maverage test of epoch 36: loss -41.34555 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 37: loss -41.62386 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 37: loss -42.34879 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 38: loss -42.62282 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 38: loss -43.35197 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 39: loss -43.62171 acc 0.66225 roc_auc 0.44176 prc_auc 0.64652[0m
[93maverage test of epoch 39: loss -44.35509 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -44.62055 acc 0.66225 roc_auc 0.48441 prc_auc 0.65536[0m
[93maverage test of epoch 40: loss -45.35816 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -45.61935 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 41: loss -46.36119 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -46.61811 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 42: loss -47.36419 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -47.61685 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 43: loss -48.36716 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -48.61555 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 44: loss -49.37011 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -49.61424 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 45: loss -50.37302 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -50.61289 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 46: loss -51.37592 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -51.61153 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 47: loss -52.37880 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -52.61015 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 48: loss -53.38166 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -53.60875 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 49: loss -54.38451 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 50: loss -54.60734 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 50: loss -55.38734 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 51: loss -55.60591 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 51: loss -56.39015 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 52: loss -56.60447 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 52: loss -57.39296 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 53: loss -57.60301 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 53: loss -58.39574 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 54: loss -58.60155 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 54: loss -59.39853 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 55: loss -59.60007 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 55: loss -60.40130 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 56: loss -60.59858 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 56: loss -61.40405 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 57: loss -61.59708 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 57: loss -62.40679 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 58: loss -62.59556 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 58: loss -63.40953 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 59: loss -63.59404 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 59: loss -64.41224 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 60: loss -64.59250 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 60: loss -65.41494 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 61: loss -65.59095 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 61: loss -66.41764 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 62: loss -66.58938 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 62: loss -67.42033 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 63: loss -67.58781 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 63: loss -68.42299 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 64: loss -68.58623 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 64: loss -69.42567 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 65: loss -69.58464 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 65: loss -70.42833 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 66: loss -70.58305 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 66: loss -71.43098 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 67: loss -71.58145 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 67: loss -72.43363 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 68: loss -72.57984 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 68: loss -73.43628 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 69: loss -73.57823 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 69: loss -74.43891 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 70: loss -74.57662 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 70: loss -75.44155 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 71: loss -75.57499 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 71: loss -76.44418 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 72: loss -76.57337 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 72: loss -77.44680 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 73: loss -77.57174 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 73: loss -78.44942 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 74: loss -78.57010 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 74: loss -79.45203 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 75: loss -79.56846 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 75: loss -80.45464 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 76: loss -80.56682 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 76: loss -81.45725 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 77: loss -81.56518 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 77: loss -82.45986 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 78: loss -82.56353 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 78: loss -83.46245 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 79: loss -83.56188 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 79: loss -84.46506 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 80: loss -84.56022 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 80: loss -85.46766 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 81: loss -85.55856 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 81: loss -86.47024 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 82: loss -86.55690 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 82: loss -87.47284 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 83: loss -87.55524 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 83: loss -88.47542 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 84: loss -88.55357 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 84: loss -89.47800 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 85: loss -89.55190 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 85: loss -90.48059 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 86: loss -90.55022 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 86: loss -91.48315 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 87: loss -91.54854 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 87: loss -92.48573 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 88: loss -92.54686 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 88: loss -93.48830 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 89: loss -93.54517 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 89: loss -94.49086 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 90: loss -94.54348 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 90: loss -95.49341 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 91: loss -95.54178 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 91: loss -96.49597 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 92: loss -96.54007 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 92: loss -97.49851 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 93: loss -97.53836 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 93: loss -98.50105 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 94: loss -98.53665 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 94: loss -99.50359 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 95: loss -99.53492 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 95: loss -100.50611 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 96: loss -100.53319 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 96: loss -101.50864 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 97: loss -101.53146 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 97: loss -102.51116 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 98: loss -102.52972 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 98: loss -103.51368 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 99: loss -103.52798 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 99: loss -104.51617 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -0.55256 acc 0.65563 roc_auc 0.50137 prc_auc 0.71154[0m
[93maverage test of epoch 0: loss -1.26280 acc 0.67568 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 1: loss -2.09533 acc 0.66225 roc_auc 0.78686 prc_auc 0.87558[0m
[93maverage test of epoch 1: loss -3.13055 acc 0.67568 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 2: loss -3.66051 acc 0.73510 roc_auc 0.80569 prc_auc 0.86852[0m
[93maverage test of epoch 2: loss -4.36364 acc 0.81081 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 3: loss -4.85243 acc 0.83444 roc_auc 0.76588 prc_auc 0.82443[0m
[93maverage test of epoch 3: loss -5.38817 acc 0.81081 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 4: loss -5.88375 acc 0.82119 roc_auc 0.76000 prc_auc 0.82738[0m
[93maverage test of epoch 4: loss -6.52787 acc 0.83784 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 5: loss -6.95882 acc 0.84768 roc_auc 0.77804 prc_auc 0.82090[0m
[93maverage test of epoch 5: loss -7.36579 acc 0.81081 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 6: loss -7.88226 acc 0.84768 roc_auc 0.76588 prc_auc 0.80737[0m
[93maverage test of epoch 6: loss -8.48186 acc 0.83784 roc_auc 0.94833 prc_auc 0.97770[0m
[92maverage training of epoch 7: loss -8.77722 acc 0.84768 roc_auc 0.78402 prc_auc 0.81491[0m
[93maverage test of epoch 7: loss -9.39215 acc 0.83784 roc_auc 0.94667 prc_auc 0.97610[0m
[92maverage training of epoch 8: loss -9.74650 acc 0.84768 roc_auc 0.77245 prc_auc 0.81655[0m
[93maverage test of epoch 8: loss -10.30821 acc 0.83784 roc_auc 0.94333 prc_auc 0.97415[0m
[92maverage training of epoch 9: loss -10.60297 acc 0.84106 roc_auc 0.75431 prc_auc 0.79524[0m
[93maverage test of epoch 9: loss -11.21220 acc 0.83784 roc_auc 0.94000 prc_auc 0.96912[0m
[92maverage training of epoch 10: loss -11.51436 acc 0.84768 roc_auc 0.77137 prc_auc 0.81205[0m
[93maverage test of epoch 10: loss -12.10090 acc 0.83784 roc_auc 0.80333 prc_auc 0.84711[0m
[92maverage training of epoch 11: loss -12.34319 acc 0.84106 roc_auc 0.75392 prc_auc 0.79755[0m
[93maverage test of epoch 11: loss -12.98202 acc 0.83784 roc_auc 0.77333 prc_auc 0.82479[0m
[92maverage training of epoch 12: loss -13.19848 acc 0.84106 roc_auc 0.75284 prc_auc 0.79311[0m
[93maverage test of epoch 12: loss -13.85306 acc 0.83784 roc_auc 0.77333 prc_auc 0.82479[0m
[92maverage training of epoch 13: loss -14.04641 acc 0.84106 roc_auc 0.75941 prc_auc 0.81006[0m
[93maverage test of epoch 13: loss -14.71708 acc 0.83784 roc_auc 0.77333 prc_auc 0.82479[0m
[92maverage training of epoch 14: loss -14.90833 acc 0.86093 roc_auc 0.79608 prc_auc 0.83510[0m
[93maverage test of epoch 14: loss -15.16988 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 15: loss -15.75310 acc 0.85430 roc_auc 0.78010 prc_auc 0.82912[0m
[93maverage test of epoch 15: loss -15.99601 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 16: loss -16.70638 acc 0.85430 roc_auc 0.80608 prc_auc 0.84617[0m
[93maverage test of epoch 16: loss -16.82849 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 17: loss -17.34580 acc 0.85430 roc_auc 0.80598 prc_auc 0.84966[0m
[93maverage test of epoch 17: loss -17.64166 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 18: loss -17.48056 acc 0.81457 roc_auc 0.80275 prc_auc 0.85679[0m
[93maverage test of epoch 18: loss -18.43081 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 19: loss -19.09721 acc 0.85430 roc_auc 0.80873 prc_auc 0.85073[0m
[93maverage test of epoch 19: loss -19.25063 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 20: loss -20.12354 acc 0.87417 roc_auc 0.85049 prc_auc 0.88314[0m
[93maverage test of epoch 20: loss -20.59128 acc 0.83784 roc_auc 0.77333 prc_auc 0.82479[0m
[92maverage training of epoch 21: loss -20.79892 acc 0.86755 roc_auc 0.83843 prc_auc 0.87367[0m
[93maverage test of epoch 21: loss -21.42782 acc 0.83784 roc_auc 0.77333 prc_auc 0.82479[0m
[92maverage training of epoch 22: loss -21.58586 acc 0.85430 roc_auc 0.81206 prc_auc 0.85168[0m
[93maverage test of epoch 22: loss -21.69041 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 23: loss -22.47511 acc 0.86755 roc_auc 0.84412 prc_auc 0.88037[0m
[93maverage test of epoch 23: loss -22.49972 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 24: loss -23.54898 acc 0.88079 roc_auc 0.84255 prc_auc 0.87572[0m
[93maverage test of epoch 24: loss -23.31789 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 25: loss -23.88388 acc 0.85430 roc_auc 0.82461 prc_auc 0.86373[0m
[93maverage test of epoch 25: loss -24.12080 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 26: loss -24.94998 acc 0.86093 roc_auc 0.82216 prc_auc 0.85950[0m
[93maverage test of epoch 26: loss -24.93177 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 27: loss -25.77593 acc 0.86093 roc_auc 0.82216 prc_auc 0.85950[0m
[93maverage test of epoch 27: loss -25.74253 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 28: loss -26.60116 acc 0.86093 roc_auc 0.82235 prc_auc 0.85956[0m
[93maverage test of epoch 28: loss -26.55269 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 29: loss -27.42596 acc 0.86093 roc_auc 0.82235 prc_auc 0.85956[0m
[93maverage test of epoch 29: loss -27.36230 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 30: loss -28.25038 acc 0.86093 roc_auc 0.82235 prc_auc 0.85956[0m
[93maverage test of epoch 30: loss -28.17145 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 31: loss -29.07445 acc 0.86093 roc_auc 0.82235 prc_auc 0.85956[0m
[93maverage test of epoch 31: loss -28.98022 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 32: loss -29.89821 acc 0.86093 roc_auc 0.82255 prc_auc 0.85962[0m
[93maverage test of epoch 32: loss -29.78863 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 33: loss -30.72166 acc 0.86093 roc_auc 0.82275 prc_auc 0.85968[0m
[93maverage test of epoch 33: loss -30.59675 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 34: loss -31.54481 acc 0.86093 roc_auc 0.82314 prc_auc 0.85979[0m
[93maverage test of epoch 34: loss -31.40460 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 35: loss -31.30285 acc 0.74172 roc_auc 0.81745 prc_auc 0.86241[0m
[93maverage test of epoch 35: loss -32.38905 acc 0.67568 roc_auc 0.90500 prc_auc 0.93756[0m
[92maverage training of epoch 36: loss -32.63813 acc 0.66225 roc_auc 0.82667 prc_auc 0.86444[0m
[93maverage test of epoch 36: loss -33.26482 acc 0.67568 roc_auc 0.80333 prc_auc 0.84711[0m
[92maverage training of epoch 37: loss -33.54797 acc 0.70861 roc_auc 0.78765 prc_auc 0.83186[0m
[93maverage test of epoch 37: loss -33.30247 acc 0.86486 roc_auc 0.90167 prc_auc 0.93597[0m
[92maverage training of epoch 38: loss -34.48524 acc 0.86093 roc_auc 0.82912 prc_auc 0.86504[0m
[93maverage test of epoch 38: loss -35.17815 acc 0.83784 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 39: loss -35.56016 acc 0.86093 roc_auc 0.82255 prc_auc 0.85960[0m
[93maverage test of epoch 39: loss -35.42007 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 40: loss -35.83571 acc 0.85430 roc_auc 0.83392 prc_auc 0.87075[0m
[93maverage test of epoch 40: loss -36.21341 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 41: loss -37.20159 acc 0.86093 roc_auc 0.82294 prc_auc 0.85971[0m
[93maverage test of epoch 41: loss -37.01957 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 42: loss -38.02247 acc 0.86093 roc_auc 0.82314 prc_auc 0.85976[0m
[93maverage test of epoch 42: loss -37.82593 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 43: loss -38.84314 acc 0.86093 roc_auc 0.82314 prc_auc 0.85976[0m
[93maverage test of epoch 43: loss -38.63223 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 44: loss -39.66375 acc 0.86093 roc_auc 0.82275 prc_auc 0.85968[0m
[93maverage test of epoch 44: loss -39.43846 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 45: loss -40.48431 acc 0.86093 roc_auc 0.82294 prc_auc 0.85974[0m
[93maverage test of epoch 45: loss -40.24462 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 46: loss -41.30484 acc 0.86093 roc_auc 0.82314 prc_auc 0.85980[0m
[93maverage test of epoch 46: loss -41.05072 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 47: loss -42.12533 acc 0.86093 roc_auc 0.82333 prc_auc 0.85985[0m
[93maverage test of epoch 47: loss -41.85676 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 48: loss -42.94580 acc 0.86093 roc_auc 0.82392 prc_auc 0.85998[0m
[93maverage test of epoch 48: loss -42.66275 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 49: loss -43.76623 acc 0.86093 roc_auc 0.82392 prc_auc 0.85998[0m
[93maverage test of epoch 49: loss -43.46871 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 50: loss -44.58663 acc 0.86093 roc_auc 0.82431 prc_auc 0.86009[0m
[93maverage test of epoch 50: loss -44.27462 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 51: loss -45.40698 acc 0.86093 roc_auc 0.82412 prc_auc 0.86003[0m
[93maverage test of epoch 51: loss -45.08050 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 52: loss -46.22730 acc 0.86093 roc_auc 0.82431 prc_auc 0.86010[0m
[93maverage test of epoch 52: loss -45.88633 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 53: loss -47.04757 acc 0.86093 roc_auc 0.82431 prc_auc 0.86010[0m
[93maverage test of epoch 53: loss -46.69214 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 54: loss -47.86780 acc 0.86093 roc_auc 0.82431 prc_auc 0.86010[0m
[93maverage test of epoch 54: loss -47.49793 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 55: loss -48.68798 acc 0.86093 roc_auc 0.82431 prc_auc 0.86009[0m
[93maverage test of epoch 55: loss -48.30368 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 56: loss -49.50811 acc 0.86093 roc_auc 0.82431 prc_auc 0.86009[0m
[93maverage test of epoch 56: loss -49.10942 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 57: loss -50.32820 acc 0.86093 roc_auc 0.82431 prc_auc 0.86009[0m
[93maverage test of epoch 57: loss -49.91513 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 58: loss -51.14824 acc 0.86093 roc_auc 0.82431 prc_auc 0.86009[0m
[93maverage test of epoch 58: loss -50.72083 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 59: loss -51.96824 acc 0.86093 roc_auc 0.82431 prc_auc 0.86009[0m
[93maverage test of epoch 59: loss -51.52650 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 60: loss -52.78819 acc 0.86093 roc_auc 0.82431 prc_auc 0.86009[0m
[93maverage test of epoch 60: loss -52.33215 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 61: loss -53.60810 acc 0.86093 roc_auc 0.82451 prc_auc 0.86016[0m
[93maverage test of epoch 61: loss -53.13779 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 62: loss -54.42796 acc 0.86093 roc_auc 0.82490 prc_auc 0.86030[0m
[93maverage test of epoch 62: loss -53.94341 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 63: loss -55.24779 acc 0.86093 roc_auc 0.82490 prc_auc 0.86030[0m
[93maverage test of epoch 63: loss -54.74901 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 64: loss -56.06758 acc 0.86093 roc_auc 0.82490 prc_auc 0.86030[0m
[93maverage test of epoch 64: loss -55.55459 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 65: loss -56.88734 acc 0.86093 roc_auc 0.82490 prc_auc 0.86030[0m
[93maverage test of epoch 65: loss -56.36016 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 66: loss -57.70706 acc 0.86093 roc_auc 0.82490 prc_auc 0.86030[0m
[93maverage test of epoch 66: loss -57.16571 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 67: loss -58.52675 acc 0.86093 roc_auc 0.82490 prc_auc 0.86030[0m
[93maverage test of epoch 67: loss -57.97125 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 68: loss -59.34642 acc 0.86093 roc_auc 0.82490 prc_auc 0.86030[0m
[93maverage test of epoch 68: loss -58.77677 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 69: loss -60.16605 acc 0.86093 roc_auc 0.82490 prc_auc 0.86030[0m
[93maverage test of epoch 69: loss -59.58229 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 70: loss -60.98566 acc 0.86093 roc_auc 0.82490 prc_auc 0.86030[0m
[93maverage test of epoch 70: loss -60.38780 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 71: loss -61.80525 acc 0.86093 roc_auc 0.82490 prc_auc 0.86030[0m
[93maverage test of epoch 71: loss -61.19329 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 72: loss -62.62482 acc 0.86093 roc_auc 0.82490 prc_auc 0.86030[0m
[93maverage test of epoch 72: loss -61.99879 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 73: loss -62.16699 acc 0.76159 roc_auc 0.66029 prc_auc 0.74456[0m
[93maverage test of epoch 73: loss -61.87873 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 74: loss -61.55105 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 74: loss -62.87629 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 75: loss -62.56925 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 75: loss -63.87938 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 76: loss -63.56809 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 76: loss -64.88245 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 77: loss -64.56689 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 77: loss -65.88549 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 78: loss -65.56566 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 78: loss -66.88853 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 79: loss -66.56451 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 79: loss -67.89393 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 80: loss -67.50023 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 80: loss -68.89367 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 81: loss -68.56126 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 81: loss -69.90838 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 82: loss -69.66615 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 82: loss -70.84463 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 83: loss -70.73189 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 83: loss -71.77502 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 84: loss -71.69086 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 84: loss -72.70331 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 85: loss -72.65091 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 85: loss -73.65234 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 86: loss -73.61783 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 86: loss -74.61467 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 87: loss -74.59657 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 87: loss -75.57502 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 88: loss -75.56648 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 88: loss -76.53201 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 89: loss -76.52876 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 89: loss -77.48853 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 90: loss -77.48828 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 90: loss -78.44538 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 91: loss -78.44638 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 91: loss -79.40245 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 92: loss -79.40366 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 92: loss -80.35974 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 93: loss -80.36031 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 93: loss -81.31719 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 94: loss -81.31616 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 94: loss -82.27532 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 95: loss -82.27078 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 95: loss -83.23447 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 96: loss -83.22339 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 96: loss -84.19205 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 97: loss -84.17567 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 97: loss -85.15075 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 98: loss -85.13396 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 98: loss -86.11623 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 99: loss -86.09806 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 99: loss -87.09060 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.66501 ROC_AUC (avg): 0.5 PRC_AUC (avg): 0.66501 

Average forward propagation time taken(ms): 2.496691815879432
Average backward propagation time taken(ms): 0.8785207010719668

