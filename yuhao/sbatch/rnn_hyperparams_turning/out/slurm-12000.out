# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 1)
('lr', 0.0001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-05-57-06/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-05-57-06/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 8,
 'epochs': 100,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 4,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.0001,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 2,
 'num_workers': 8,
 'number_of_mlp_layer': 1,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-18-05-57-06',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 100, 'learning_rate': 0.0001, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss 0.17154 acc 0.33333 roc_auc 0.56880 prc_auc 0.71091[0m
[93maverage test of epoch 0: loss 0.13088 acc 0.34211 roc_auc 0.54615 prc_auc 0.72536[0m
[92maverage training of epoch 1: loss 0.10255 acc 0.33333 roc_auc 0.45240 prc_auc 0.65501[0m
[93maverage test of epoch 1: loss 0.05688 acc 0.34211 roc_auc 0.57846 prc_auc 0.72273[0m
[92maverage training of epoch 2: loss 0.02592 acc 0.33333 roc_auc 0.55260 prc_auc 0.69450[0m
[93maverage test of epoch 2: loss -0.01147 acc 0.34211 roc_auc 0.36923 prc_auc 0.59820[0m
[92maverage training of epoch 3: loss -0.02174 acc 0.33333 roc_auc 0.48520 prc_auc 0.68956[0m
[93maverage test of epoch 3: loss -0.03536 acc 0.34211 roc_auc 0.27692 prc_auc 0.56751[0m
[92maverage training of epoch 4: loss -0.04109 acc 0.33333 roc_auc 0.44480 prc_auc 0.63969[0m
[93maverage test of epoch 4: loss -0.05653 acc 0.34211 roc_auc 0.46462 prc_auc 0.66074[0m
[92maverage training of epoch 5: loss -0.05735 acc 0.33333 roc_auc 0.41500 prc_auc 0.64579[0m
[93maverage test of epoch 5: loss -0.07577 acc 0.34211 roc_auc 0.63077 prc_auc 0.73238[0m
[92maverage training of epoch 6: loss -0.07457 acc 0.33333 roc_auc 0.43120 prc_auc 0.61541[0m
[93maverage test of epoch 6: loss -0.08569 acc 0.34211 roc_auc 0.39385 prc_auc 0.66159[0m
[92maverage training of epoch 7: loss -0.08984 acc 0.33333 roc_auc 0.37300 prc_auc 0.57878[0m
[93maverage test of epoch 7: loss -0.10495 acc 0.34211 roc_auc 0.51077 prc_auc 0.65591[0m
[92maverage training of epoch 8: loss -0.10378 acc 0.33333 roc_auc 0.40900 prc_auc 0.59137[0m
[93maverage test of epoch 8: loss -0.11458 acc 0.34211 roc_auc 0.52000 prc_auc 0.68233[0m
[92maverage training of epoch 9: loss -0.11587 acc 0.33333 roc_auc 0.38090 prc_auc 0.57085[0m
[93maverage test of epoch 9: loss -0.12750 acc 0.34211 roc_auc 0.58154 prc_auc 0.70607[0m
[92maverage training of epoch 10: loss -0.12728 acc 0.33333 roc_auc 0.36920 prc_auc 0.56846[0m
[93maverage test of epoch 10: loss -0.13796 acc 0.34211 roc_auc 0.44000 prc_auc 0.63096[0m
[92maverage training of epoch 11: loss -0.13913 acc 0.33333 roc_auc 0.38160 prc_auc 0.57223[0m
[93maverage test of epoch 11: loss -0.14907 acc 0.34211 roc_auc 0.49538 prc_auc 0.65683[0m
[92maverage training of epoch 12: loss -0.14954 acc 0.33333 roc_auc 0.31720 prc_auc 0.54985[0m
[93maverage test of epoch 12: loss -0.16057 acc 0.34211 roc_auc 0.48000 prc_auc 0.64902[0m
[92maverage training of epoch 13: loss -0.16154 acc 0.33333 roc_auc 0.38320 prc_auc 0.57010[0m
[93maverage test of epoch 13: loss -0.17169 acc 0.34211 roc_auc 0.44000 prc_auc 0.63096[0m
[92maverage training of epoch 14: loss -0.17283 acc 0.33333 roc_auc 0.43020 prc_auc 0.58998[0m
[93maverage test of epoch 14: loss -0.18258 acc 0.34211 roc_auc 0.46000 prc_auc 0.64004[0m
[92maverage training of epoch 15: loss -0.18329 acc 0.33333 roc_auc 0.37840 prc_auc 0.57273[0m
[93maverage test of epoch 15: loss -0.19387 acc 0.34211 roc_auc 0.46000 prc_auc 0.64004[0m
[92maverage training of epoch 16: loss -0.19482 acc 0.33333 roc_auc 0.40880 prc_auc 0.58425[0m
[93maverage test of epoch 16: loss -0.20379 acc 0.34211 roc_auc 0.45538 prc_auc 0.63825[0m
[92maverage training of epoch 17: loss -0.20578 acc 0.33333 roc_auc 0.38360 prc_auc 0.57333[0m
[93maverage test of epoch 17: loss -0.21601 acc 0.34211 roc_auc 0.48000 prc_auc 0.64902[0m
[92maverage training of epoch 18: loss -0.21660 acc 0.33333 roc_auc 0.37620 prc_auc 0.57014[0m
[93maverage test of epoch 18: loss -0.22709 acc 0.34211 roc_auc 0.52000 prc_auc 0.66703[0m
[92maverage training of epoch 19: loss -0.22784 acc 0.33333 roc_auc 0.40420 prc_auc 0.58165[0m
[93maverage test of epoch 19: loss -0.23775 acc 0.34211 roc_auc 0.48000 prc_auc 0.64902[0m
[92maverage training of epoch 20: loss -0.23884 acc 0.33333 roc_auc 0.38900 prc_auc 0.57456[0m
[93maverage test of epoch 20: loss -0.24909 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -0.24965 acc 0.33333 roc_auc 0.35380 prc_auc 0.56106[0m
[93maverage test of epoch 21: loss -0.25986 acc 0.34211 roc_auc 0.48000 prc_auc 0.64902[0m
[92maverage training of epoch 22: loss -0.26085 acc 0.33333 roc_auc 0.36200 prc_auc 0.56391[0m
[93maverage test of epoch 22: loss -0.27112 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -0.27199 acc 0.33333 roc_auc 0.36160 prc_auc 0.56161[0m
[93maverage test of epoch 23: loss -0.28214 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -0.28298 acc 0.33333 roc_auc 0.36140 prc_auc 0.56486[0m
[93maverage test of epoch 24: loss -0.29318 acc 0.34211 roc_auc 0.53846 prc_auc 0.67568[0m
[92maverage training of epoch 25: loss -0.29421 acc 0.33333 roc_auc 0.36280 prc_auc 0.56325[0m
[93maverage test of epoch 25: loss -0.30417 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -0.30514 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 26: loss -0.31519 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -0.31613 acc 0.33333 roc_auc 0.38200 prc_auc 0.57291[0m
[93maverage test of epoch 27: loss -0.32596 acc 0.34211 roc_auc 0.48000 prc_auc 0.64902[0m
[92maverage training of epoch 28: loss -0.32715 acc 0.33333 roc_auc 0.34940 prc_auc 0.55947[0m
[93maverage test of epoch 28: loss -0.33721 acc 0.34211 roc_auc 0.48000 prc_auc 0.64902[0m
[92maverage training of epoch 29: loss -0.33832 acc 0.33333 roc_auc 0.36460 prc_auc 0.56407[0m
[93maverage test of epoch 29: loss -0.34802 acc 0.34211 roc_auc 0.48000 prc_auc 0.64902[0m
[92maverage training of epoch 30: loss -0.34932 acc 0.33333 roc_auc 0.35560 prc_auc 0.56116[0m
[93maverage test of epoch 30: loss -0.35926 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -0.36035 acc 0.33333 roc_auc 0.35520 prc_auc 0.56143[0m
[93maverage test of epoch 31: loss -0.37027 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -0.37141 acc 0.33333 roc_auc 0.34940 prc_auc 0.55854[0m
[93maverage test of epoch 32: loss -0.38129 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -0.38248 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 33: loss -0.39231 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -0.39353 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 34: loss -0.40332 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -0.40457 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 35: loss -0.41434 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -0.41562 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 36: loss -0.42521 acc 0.34211 roc_auc 0.48000 prc_auc 0.64902[0m
[92maverage training of epoch 37: loss -0.42662 acc 0.33333 roc_auc 0.35420 prc_auc 0.56112[0m
[93maverage test of epoch 37: loss -0.43637 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -0.43772 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 38: loss -0.44739 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -0.44874 acc 0.33333 roc_auc 0.35360 prc_auc 0.56092[0m
[93maverage test of epoch 39: loss -0.45848 acc 0.34211 roc_auc 0.53846 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -0.45982 acc 0.33333 roc_auc 0.35710 prc_auc 0.56188[0m
[93maverage test of epoch 40: loss -0.46942 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -0.47086 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 41: loss -0.48044 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -0.48191 acc 0.33333 roc_auc 0.35780 prc_auc 0.56213[0m
[93maverage test of epoch 42: loss -0.49146 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -0.49296 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 43: loss -0.50239 acc 0.34211 roc_auc 0.48000 prc_auc 0.64902[0m
[92maverage training of epoch 44: loss -0.50401 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 44: loss -0.51349 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -0.51506 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 45: loss -0.52451 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -0.52608 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 46: loss -0.53552 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -0.53715 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 47: loss -0.54654 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -0.54820 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 48: loss -0.55756 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -0.55928 acc 0.33333 roc_auc 0.36320 prc_auc 0.56344[0m
[93maverage test of epoch 49: loss -0.56857 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 50: loss -0.57027 acc 0.33333 roc_auc 0.34660 prc_auc 0.55804[0m
[93maverage test of epoch 50: loss -0.57959 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 51: loss -0.58134 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 51: loss -0.59060 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 52: loss -0.59239 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 52: loss -0.60162 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 53: loss -0.60344 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 53: loss -0.61264 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 54: loss -0.61448 acc 0.33333 roc_auc 0.35520 prc_auc 0.56143[0m
[93maverage test of epoch 54: loss -0.62365 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 55: loss -0.62554 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 55: loss -0.63467 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 56: loss -0.63658 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 56: loss -0.64569 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 57: loss -0.64763 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 57: loss -0.65670 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 58: loss -0.65868 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 58: loss -0.66772 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 59: loss -0.66973 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 59: loss -0.67874 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 60: loss -0.68077 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 60: loss -0.68975 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 61: loss -0.69182 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 61: loss -0.70077 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 62: loss -0.70287 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 62: loss -0.71179 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 63: loss -0.71392 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 63: loss -0.72280 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 64: loss -0.72497 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 64: loss -0.73382 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 65: loss -0.73601 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 65: loss -0.74484 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 66: loss -0.74706 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 66: loss -0.75585 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 67: loss -0.75811 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 67: loss -0.76687 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 68: loss -0.76916 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 68: loss -0.77788 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 69: loss -0.78021 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 69: loss -0.78890 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 70: loss -0.79125 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 70: loss -0.79992 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 71: loss -0.80230 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 71: loss -0.81093 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 72: loss -0.81335 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 72: loss -0.82195 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 73: loss -0.82440 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 73: loss -0.83297 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 74: loss -0.83545 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 74: loss -0.84398 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 75: loss -0.84649 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 75: loss -0.85500 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 76: loss -0.85754 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 76: loss -0.86602 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 77: loss -0.86859 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 77: loss -0.87703 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 78: loss -0.87964 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 78: loss -0.88811 acc 0.34211 roc_auc 0.53846 prc_auc 0.67568[0m
[92maverage training of epoch 79: loss -0.89068 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 79: loss -0.89906 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 80: loss -0.90169 acc 0.33333 roc_auc 0.36340 prc_auc 0.57400[0m
[93maverage test of epoch 80: loss -0.91008 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 81: loss -0.91278 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 81: loss -0.92110 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 82: loss -0.92383 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 82: loss -0.93211 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 83: loss -0.93488 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 83: loss -0.94313 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 84: loss -0.94592 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 84: loss -0.95414 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 85: loss -0.95697 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 85: loss -0.96516 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 86: loss -0.96802 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 86: loss -0.97618 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 87: loss -0.97907 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 87: loss -0.98719 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 88: loss -0.99011 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 88: loss -0.99810 acc 0.34211 roc_auc 0.52000 prc_auc 0.67158[0m
[92maverage training of epoch 89: loss -1.00116 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 89: loss -1.00923 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -1.01221 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 90: loss -1.02024 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 91: loss -1.02326 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 91: loss -1.03121 acc 0.34211 roc_auc 0.52000 prc_auc 0.67158[0m
[92maverage training of epoch 92: loss -1.03430 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 92: loss -1.04227 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 93: loss -1.04531 acc 0.33333 roc_auc 0.36180 prc_auc 0.57330[0m
[93maverage test of epoch 93: loss -1.05329 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 94: loss -1.05640 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 94: loss -1.06431 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 95: loss -1.06745 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 95: loss -1.07532 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 96: loss -1.07849 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 96: loss -1.08634 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 97: loss -1.08954 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 97: loss -1.09735 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 98: loss -1.10059 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 98: loss -1.10837 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -1.11164 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 99: loss -1.11939 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.45396 acc 0.33333 roc_auc 0.46680 prc_auc 0.65255[0m
[93maverage test of epoch 0: loss -0.55817 acc 0.34211 roc_auc 0.58769 prc_auc 0.72138[0m
[92maverage training of epoch 1: loss -0.67319 acc 0.33333 roc_auc 0.42440 prc_auc 0.62160[0m
[93maverage test of epoch 1: loss -0.79139 acc 0.34211 roc_auc 0.34462 prc_auc 0.57146[0m
[92maverage training of epoch 2: loss -0.91055 acc 0.33333 roc_auc 0.48320 prc_auc 0.65728[0m
[93maverage test of epoch 2: loss -1.03960 acc 0.34211 roc_auc 0.54462 prc_auc 0.66051[0m
[92maverage training of epoch 3: loss -1.14082 acc 0.33333 roc_auc 0.53760 prc_auc 0.69379[0m
[93maverage test of epoch 3: loss -1.27978 acc 0.34211 roc_auc 0.47077 prc_auc 0.68197[0m
[92maverage training of epoch 4: loss -1.37521 acc 0.33333 roc_auc 0.53740 prc_auc 0.72697[0m
[93maverage test of epoch 4: loss -1.50602 acc 0.34211 roc_auc 0.45846 prc_auc 0.65195[0m
[92maverage training of epoch 5: loss -1.62877 acc 0.33333 roc_auc 0.46260 prc_auc 0.63548[0m
[93maverage test of epoch 5: loss -1.74657 acc 0.34211 roc_auc 0.51692 prc_auc 0.70061[0m
[92maverage training of epoch 6: loss -1.86443 acc 0.33333 roc_auc 0.49860 prc_auc 0.67503[0m
[93maverage test of epoch 6: loss -2.00043 acc 0.34211 roc_auc 0.46769 prc_auc 0.66784[0m
[92maverage training of epoch 7: loss -2.09232 acc 0.33333 roc_auc 0.51060 prc_auc 0.66799[0m
[93maverage test of epoch 7: loss -2.20855 acc 0.34211 roc_auc 0.56000 prc_auc 0.68785[0m
[92maverage training of epoch 8: loss -2.31581 acc 0.33333 roc_auc 0.49740 prc_auc 0.65223[0m
[93maverage test of epoch 8: loss -2.43737 acc 0.34211 roc_auc 0.29538 prc_auc 0.59443[0m
[92maverage training of epoch 9: loss -2.53925 acc 0.33333 roc_auc 0.53100 prc_auc 0.70379[0m
[93maverage test of epoch 9: loss -2.66496 acc 0.34211 roc_auc 0.48000 prc_auc 0.66937[0m
[92maverage training of epoch 10: loss -2.77652 acc 0.33333 roc_auc 0.45400 prc_auc 0.65122[0m
[93maverage test of epoch 10: loss -2.90579 acc 0.34211 roc_auc 0.44615 prc_auc 0.64515[0m
[92maverage training of epoch 11: loss -3.00976 acc 0.33333 roc_auc 0.50640 prc_auc 0.67630[0m
[93maverage test of epoch 11: loss -3.16002 acc 0.34211 roc_auc 0.38769 prc_auc 0.63056[0m
[92maverage training of epoch 12: loss -3.24544 acc 0.33333 roc_auc 0.51160 prc_auc 0.69980[0m
[93maverage test of epoch 12: loss -3.39079 acc 0.34211 roc_auc 0.63385 prc_auc 0.76908[0m
[92maverage training of epoch 13: loss -3.47168 acc 0.33333 roc_auc 0.43860 prc_auc 0.61014[0m
[93maverage test of epoch 13: loss -3.62310 acc 0.34211 roc_auc 0.33538 prc_auc 0.58907[0m
[92maverage training of epoch 14: loss -3.71666 acc 0.33333 roc_auc 0.50960 prc_auc 0.68263[0m
[93maverage test of epoch 14: loss -3.87215 acc 0.34211 roc_auc 0.74154 prc_auc 0.84386[0m
[92maverage training of epoch 15: loss -3.95836 acc 0.33333 roc_auc 0.57520 prc_auc 0.73141[0m
[93maverage test of epoch 15: loss -4.09914 acc 0.34211 roc_auc 0.49846 prc_auc 0.74680[0m
[92maverage training of epoch 16: loss -4.19909 acc 0.33333 roc_auc 0.50880 prc_auc 0.68764[0m
[93maverage test of epoch 16: loss -4.33229 acc 0.34211 roc_auc 0.46154 prc_auc 0.67666[0m
[92maverage training of epoch 17: loss -4.43629 acc 0.33333 roc_auc 0.47580 prc_auc 0.65282[0m
[93maverage test of epoch 17: loss -4.58529 acc 0.34211 roc_auc 0.40615 prc_auc 0.67699[0m
[92maverage training of epoch 18: loss -4.68861 acc 0.33333 roc_auc 0.49460 prc_auc 0.67870[0m
[93maverage test of epoch 18: loss -4.82552 acc 0.34211 roc_auc 0.26462 prc_auc 0.59346[0m
[92maverage training of epoch 19: loss -4.93183 acc 0.33333 roc_auc 0.55620 prc_auc 0.73460[0m
[93maverage test of epoch 19: loss -5.05583 acc 0.34211 roc_auc 0.48615 prc_auc 0.68698[0m
[92maverage training of epoch 20: loss -5.16309 acc 0.33333 roc_auc 0.50440 prc_auc 0.67547[0m
[93maverage test of epoch 20: loss -5.33879 acc 0.34211 roc_auc 0.56923 prc_auc 0.71350[0m
[92maverage training of epoch 21: loss -5.41353 acc 0.33333 roc_auc 0.52960 prc_auc 0.68433[0m
[93maverage test of epoch 21: loss -5.56853 acc 0.34211 roc_auc 0.52308 prc_auc 0.69154[0m
[92maverage training of epoch 22: loss -5.67384 acc 0.33333 roc_auc 0.49740 prc_auc 0.68214[0m
[93maverage test of epoch 22: loss -5.80359 acc 0.34211 roc_auc 0.30462 prc_auc 0.56461[0m
[92maverage training of epoch 23: loss -5.91102 acc 0.33333 roc_auc 0.48380 prc_auc 0.64139[0m
[93maverage test of epoch 23: loss -6.07373 acc 0.34211 roc_auc 0.48000 prc_auc 0.68586[0m
[92maverage training of epoch 24: loss -6.16162 acc 0.33333 roc_auc 0.46260 prc_auc 0.63255[0m
[93maverage test of epoch 24: loss -6.31958 acc 0.34211 roc_auc 0.53538 prc_auc 0.77771[0m
[92maverage training of epoch 25: loss -6.41296 acc 0.33333 roc_auc 0.55760 prc_auc 0.71696[0m
[93maverage test of epoch 25: loss -6.58012 acc 0.34211 roc_auc 0.49538 prc_auc 0.70979[0m
[92maverage training of epoch 26: loss -6.67241 acc 0.33333 roc_auc 0.54320 prc_auc 0.68943[0m
[93maverage test of epoch 26: loss -6.83087 acc 0.34211 roc_auc 0.41231 prc_auc 0.62875[0m
[92maverage training of epoch 27: loss -6.91913 acc 0.33333 roc_auc 0.53720 prc_auc 0.68978[0m
[93maverage test of epoch 27: loss -7.06750 acc 0.34211 roc_auc 0.42154 prc_auc 0.67562[0m
[92maverage training of epoch 28: loss -7.19113 acc 0.33333 roc_auc 0.54420 prc_auc 0.70387[0m
[93maverage test of epoch 28: loss -7.34688 acc 0.34211 roc_auc 0.41538 prc_auc 0.61256[0m
[92maverage training of epoch 29: loss -7.43365 acc 0.33333 roc_auc 0.49580 prc_auc 0.67833[0m
[93maverage test of epoch 29: loss -7.61854 acc 0.34211 roc_auc 0.37231 prc_auc 0.61171[0m
[92maverage training of epoch 30: loss -7.70672 acc 0.33333 roc_auc 0.47020 prc_auc 0.66215[0m
[93maverage test of epoch 30: loss -7.88054 acc 0.34211 roc_auc 0.53846 prc_auc 0.68858[0m
[92maverage training of epoch 31: loss -7.97219 acc 0.33333 roc_auc 0.54420 prc_auc 0.70106[0m
[93maverage test of epoch 31: loss -8.14802 acc 0.34211 roc_auc 0.40308 prc_auc 0.67109[0m
[92maverage training of epoch 32: loss -8.24994 acc 0.33333 roc_auc 0.50820 prc_auc 0.64787[0m
[93maverage test of epoch 32: loss -8.42132 acc 0.34211 roc_auc 0.44923 prc_auc 0.65746[0m
[92maverage training of epoch 33: loss -8.52144 acc 0.33333 roc_auc 0.51300 prc_auc 0.66210[0m
[93maverage test of epoch 33: loss -8.69120 acc 0.34211 roc_auc 0.33846 prc_auc 0.57717[0m
[92maverage training of epoch 34: loss -8.80531 acc 0.33333 roc_auc 0.48100 prc_auc 0.64261[0m
[93maverage test of epoch 34: loss -8.97708 acc 0.34211 roc_auc 0.39385 prc_auc 0.61401[0m
[92maverage training of epoch 35: loss -9.06947 acc 0.33333 roc_auc 0.54120 prc_auc 0.67264[0m
[93maverage test of epoch 35: loss -9.24832 acc 0.34211 roc_auc 0.54769 prc_auc 0.64925[0m
[92maverage training of epoch 36: loss -9.35346 acc 0.33333 roc_auc 0.56600 prc_auc 0.73825[0m
[93maverage test of epoch 36: loss -9.54280 acc 0.34211 roc_auc 0.56923 prc_auc 0.74279[0m
[92maverage training of epoch 37: loss -9.63250 acc 0.33333 roc_auc 0.49100 prc_auc 0.68026[0m
[93maverage test of epoch 37: loss -9.80360 acc 0.34211 roc_auc 0.37385 prc_auc 0.60265[0m
[92maverage training of epoch 38: loss -9.92803 acc 0.33333 roc_auc 0.51240 prc_auc 0.70592[0m
[93maverage test of epoch 38: loss -10.11376 acc 0.34211 roc_auc 0.40000 prc_auc 0.65820[0m
[92maverage training of epoch 39: loss -10.21912 acc 0.33333 roc_auc 0.51100 prc_auc 0.70327[0m
[93maverage test of epoch 39: loss -10.40559 acc 0.34211 roc_auc 0.35077 prc_auc 0.64724[0m
[92maverage training of epoch 40: loss -10.51510 acc 0.33333 roc_auc 0.52580 prc_auc 0.70481[0m
[93maverage test of epoch 40: loss -10.69099 acc 0.34211 roc_auc 0.40923 prc_auc 0.63851[0m
[92maverage training of epoch 41: loss -10.80238 acc 0.33333 roc_auc 0.51820 prc_auc 0.66457[0m
[93maverage test of epoch 41: loss -10.99384 acc 0.34211 roc_auc 0.57692 prc_auc 0.70419[0m
[92maverage training of epoch 42: loss -11.10308 acc 0.33333 roc_auc 0.52880 prc_auc 0.68007[0m
[93maverage test of epoch 42: loss -11.28956 acc 0.34211 roc_auc 0.39077 prc_auc 0.62625[0m
[92maverage training of epoch 43: loss -11.39682 acc 0.33333 roc_auc 0.51160 prc_auc 0.72500[0m
[93maverage test of epoch 43: loss -11.58675 acc 0.34211 roc_auc 0.58462 prc_auc 0.73493[0m
[92maverage training of epoch 44: loss -11.70690 acc 0.33333 roc_auc 0.53860 prc_auc 0.71170[0m
[93maverage test of epoch 44: loss -11.90277 acc 0.34211 roc_auc 0.25538 prc_auc 0.52736[0m
[92maverage training of epoch 45: loss -12.01936 acc 0.33333 roc_auc 0.48860 prc_auc 0.66041[0m
[93maverage test of epoch 45: loss -12.20717 acc 0.34211 roc_auc 0.57538 prc_auc 0.81044[0m
[92maverage training of epoch 46: loss -12.31825 acc 0.33333 roc_auc 0.46590 prc_auc 0.63967[0m
[93maverage test of epoch 46: loss -12.51950 acc 0.34211 roc_auc 0.55385 prc_auc 0.75805[0m
[92maverage training of epoch 47: loss -12.63517 acc 0.33333 roc_auc 0.44820 prc_auc 0.61303[0m
[93maverage test of epoch 47: loss -12.83012 acc 0.34211 roc_auc 0.44154 prc_auc 0.63136[0m
[92maverage training of epoch 48: loss -12.94417 acc 0.33333 roc_auc 0.49020 prc_auc 0.66467[0m
[93maverage test of epoch 48: loss -13.15796 acc 0.34211 roc_auc 0.62462 prc_auc 0.74053[0m
[92maverage training of epoch 49: loss -13.27014 acc 0.33333 roc_auc 0.49460 prc_auc 0.69589[0m
[93maverage test of epoch 49: loss -13.47763 acc 0.34211 roc_auc 0.53231 prc_auc 0.72378[0m
[92maverage training of epoch 50: loss -13.58858 acc 0.33333 roc_auc 0.50660 prc_auc 0.66760[0m
[93maverage test of epoch 50: loss -13.80315 acc 0.34211 roc_auc 0.35077 prc_auc 0.56880[0m
[92maverage training of epoch 51: loss -13.91582 acc 0.33333 roc_auc 0.52880 prc_auc 0.69443[0m
[93maverage test of epoch 51: loss -14.11633 acc 0.34211 roc_auc 0.48308 prc_auc 0.69122[0m
[92maverage training of epoch 52: loss -14.24037 acc 0.33333 roc_auc 0.45180 prc_auc 0.63292[0m
[93maverage test of epoch 52: loss -14.45274 acc 0.34211 roc_auc 0.57231 prc_auc 0.73024[0m
[92maverage training of epoch 53: loss -14.57489 acc 0.33333 roc_auc 0.50150 prc_auc 0.66582[0m
[93maverage test of epoch 53: loss -14.78955 acc 0.34211 roc_auc 0.45692 prc_auc 0.67461[0m
[92maverage training of epoch 54: loss -14.90545 acc 0.33333 roc_auc 0.48440 prc_auc 0.65529[0m
[93maverage test of epoch 54: loss -15.12635 acc 0.34211 roc_auc 0.57231 prc_auc 0.78869[0m
[92maverage training of epoch 55: loss -15.24415 acc 0.33333 roc_auc 0.48200 prc_auc 0.66160[0m
[93maverage test of epoch 55: loss -15.46253 acc 0.34211 roc_auc 0.64462 prc_auc 0.79440[0m
[92maverage training of epoch 56: loss -15.57970 acc 0.33333 roc_auc 0.47530 prc_auc 0.65212[0m
[93maverage test of epoch 56: loss -15.79873 acc 0.34211 roc_auc 0.50769 prc_auc 0.68292[0m
[92maverage training of epoch 57: loss -15.92450 acc 0.33333 roc_auc 0.42440 prc_auc 0.61067[0m
[93maverage test of epoch 57: loss -16.13647 acc 0.34211 roc_auc 0.30769 prc_auc 0.55056[0m
[92maverage training of epoch 58: loss -16.27019 acc 0.33333 roc_auc 0.49820 prc_auc 0.71224[0m
[93maverage test of epoch 58: loss -16.48211 acc 0.34211 roc_auc 0.58462 prc_auc 0.73178[0m
[92maverage training of epoch 59: loss -16.61552 acc 0.33333 roc_auc 0.44340 prc_auc 0.64434[0m
[93maverage test of epoch 59: loss -16.83004 acc 0.34211 roc_auc 0.46000 prc_auc 0.62891[0m
[92maverage training of epoch 60: loss -16.96482 acc 0.33333 roc_auc 0.46250 prc_auc 0.63928[0m
[93maverage test of epoch 60: loss -17.18560 acc 0.34211 roc_auc 0.35077 prc_auc 0.56448[0m
[92maverage training of epoch 61: loss -17.31729 acc 0.33333 roc_auc 0.43540 prc_auc 0.64716[0m
[93maverage test of epoch 61: loss -17.54307 acc 0.34211 roc_auc 0.56923 prc_auc 0.70566[0m
[92maverage training of epoch 62: loss -17.67785 acc 0.33333 roc_auc 0.46460 prc_auc 0.64105[0m
[93maverage test of epoch 62: loss -17.89676 acc 0.34211 roc_auc 0.44462 prc_auc 0.67787[0m
[92maverage training of epoch 63: loss -18.03848 acc 0.33333 roc_auc 0.43170 prc_auc 0.62482[0m
[93maverage test of epoch 63: loss -18.26115 acc 0.34211 roc_auc 0.40923 prc_auc 0.62981[0m
[92maverage training of epoch 64: loss -18.39909 acc 0.33333 roc_auc 0.49760 prc_auc 0.69308[0m
[93maverage test of epoch 64: loss -18.62876 acc 0.34211 roc_auc 0.40308 prc_auc 0.65299[0m
[92maverage training of epoch 65: loss -18.75870 acc 0.33333 roc_auc 0.48670 prc_auc 0.64988[0m
[93maverage test of epoch 65: loss -18.99047 acc 0.34211 roc_auc 0.47077 prc_auc 0.65840[0m
[92maverage training of epoch 66: loss -19.12760 acc 0.33333 roc_auc 0.45320 prc_auc 0.63613[0m
[93maverage test of epoch 66: loss -19.36481 acc 0.34211 roc_auc 0.52462 prc_auc 0.69870[0m
[92maverage training of epoch 67: loss -19.50385 acc 0.33333 roc_auc 0.39370 prc_auc 0.60937[0m
[93maverage test of epoch 67: loss -19.74102 acc 0.34211 roc_auc 0.45538 prc_auc 0.66579[0m
[92maverage training of epoch 68: loss -19.87574 acc 0.33333 roc_auc 0.43420 prc_auc 0.67478[0m
[93maverage test of epoch 68: loss -20.11452 acc 0.34211 roc_auc 0.36308 prc_auc 0.60432[0m
[92maverage training of epoch 69: loss -20.25220 acc 0.33333 roc_auc 0.36630 prc_auc 0.58362[0m
[93maverage test of epoch 69: loss -20.49373 acc 0.34211 roc_auc 0.33846 prc_auc 0.56374[0m
[92maverage training of epoch 70: loss -20.63444 acc 0.33333 roc_auc 0.46060 prc_auc 0.65208[0m
[93maverage test of epoch 70: loss -20.87730 acc 0.34211 roc_auc 0.49231 prc_auc 0.67420[0m
[92maverage training of epoch 71: loss -21.01928 acc 0.33333 roc_auc 0.47620 prc_auc 0.66390[0m
[93maverage test of epoch 71: loss -21.26396 acc 0.34211 roc_auc 0.44923 prc_auc 0.65503[0m
[92maverage training of epoch 72: loss -21.40656 acc 0.33333 roc_auc 0.41530 prc_auc 0.62507[0m
[93maverage test of epoch 72: loss -21.64899 acc 0.34211 roc_auc 0.19077 prc_auc 0.53738[0m
[92maverage training of epoch 73: loss -21.79633 acc 0.33333 roc_auc 0.45510 prc_auc 0.66518[0m
[93maverage test of epoch 73: loss -22.04018 acc 0.34211 roc_auc 0.44769 prc_auc 0.67500[0m
[92maverage training of epoch 74: loss -22.18962 acc 0.33333 roc_auc 0.42060 prc_auc 0.65103[0m
[93maverage test of epoch 74: loss -22.43973 acc 0.34211 roc_auc 0.54923 prc_auc 0.74123[0m
[92maverage training of epoch 75: loss -22.58808 acc 0.33333 roc_auc 0.44000 prc_auc 0.62834[0m
[93maverage test of epoch 75: loss -22.83893 acc 0.34211 roc_auc 0.48462 prc_auc 0.67520[0m
[92maverage training of epoch 76: loss -22.98511 acc 0.33333 roc_auc 0.37480 prc_auc 0.63668[0m
[93maverage test of epoch 76: loss -23.23655 acc 0.34211 roc_auc 0.45231 prc_auc 0.66083[0m
[92maverage training of epoch 77: loss -23.39636 acc 0.33333 roc_auc 0.40800 prc_auc 0.62090[0m
[93maverage test of epoch 77: loss -23.66033 acc 0.34211 roc_auc 0.47692 prc_auc 0.65386[0m
[92maverage training of epoch 78: loss -23.83371 acc 0.33333 roc_auc 0.40310 prc_auc 0.58785[0m
[93maverage test of epoch 78: loss -24.10709 acc 0.34211 roc_auc 0.68615 prc_auc 0.79894[0m
[92maverage training of epoch 79: loss -24.28076 acc 0.33333 roc_auc 0.40950 prc_auc 0.60012[0m
[93maverage test of epoch 79: loss -24.55954 acc 0.34211 roc_auc 0.59538 prc_auc 0.76324[0m
[92maverage training of epoch 80: loss -24.73736 acc 0.33333 roc_auc 0.43000 prc_auc 0.62621[0m
[93maverage test of epoch 80: loss -25.01545 acc 0.34211 roc_auc 0.54615 prc_auc 0.73148[0m
[92maverage training of epoch 81: loss -25.19518 acc 0.33333 roc_auc 0.41080 prc_auc 0.60839[0m
[93maverage test of epoch 81: loss -25.47788 acc 0.34211 roc_auc 0.48923 prc_auc 0.68642[0m
[92maverage training of epoch 82: loss -25.66101 acc 0.33333 roc_auc 0.41860 prc_auc 0.61455[0m
[93maverage test of epoch 82: loss -25.94028 acc 0.34211 roc_auc 0.54000 prc_auc 0.70958[0m
[92maverage training of epoch 83: loss -26.13312 acc 0.33333 roc_auc 0.41460 prc_auc 0.59827[0m
[93maverage test of epoch 83: loss -26.41769 acc 0.34211 roc_auc 0.58769 prc_auc 0.77664[0m
[92maverage training of epoch 84: loss -26.60829 acc 0.33333 roc_auc 0.42500 prc_auc 0.61781[0m
[93maverage test of epoch 84: loss -26.89549 acc 0.34211 roc_auc 0.38769 prc_auc 0.59955[0m
[92maverage training of epoch 85: loss -27.08911 acc 0.33333 roc_auc 0.43620 prc_auc 0.61099[0m
[93maverage test of epoch 85: loss -27.37450 acc 0.34211 roc_auc 0.60615 prc_auc 0.71497[0m
[92maverage training of epoch 86: loss -27.57093 acc 0.33333 roc_auc 0.41260 prc_auc 0.60037[0m
[93maverage test of epoch 86: loss -27.86550 acc 0.34211 roc_auc 0.78154 prc_auc 0.87012[0m
[92maverage training of epoch 87: loss -28.06043 acc 0.33333 roc_auc 0.43420 prc_auc 0.62301[0m
[93maverage test of epoch 87: loss -28.35257 acc 0.34211 roc_auc 0.54308 prc_auc 0.68965[0m
[92maverage training of epoch 88: loss -28.55435 acc 0.33333 roc_auc 0.42200 prc_auc 0.59953[0m
[93maverage test of epoch 88: loss -28.84813 acc 0.34211 roc_auc 0.35385 prc_auc 0.60724[0m
[92maverage training of epoch 89: loss -29.05142 acc 0.33333 roc_auc 0.42540 prc_auc 0.61346[0m
[93maverage test of epoch 89: loss -29.34828 acc 0.34211 roc_auc 0.68769 prc_auc 0.80802[0m
[92maverage training of epoch 90: loss -29.55128 acc 0.33333 roc_auc 0.42260 prc_auc 0.61890[0m
[93maverage test of epoch 90: loss -29.84929 acc 0.34211 roc_auc 0.38154 prc_auc 0.62017[0m
[92maverage training of epoch 91: loss -30.05767 acc 0.33333 roc_auc 0.41930 prc_auc 0.60701[0m
[93maverage test of epoch 91: loss -30.35958 acc 0.34211 roc_auc 0.44154 prc_auc 0.65105[0m
[92maverage training of epoch 92: loss -30.56560 acc 0.33333 roc_auc 0.41820 prc_auc 0.62515[0m
[93maverage test of epoch 92: loss -30.87058 acc 0.34211 roc_auc 0.71385 prc_auc 0.84371[0m
[92maverage training of epoch 93: loss -31.08299 acc 0.33333 roc_auc 0.41930 prc_auc 0.61496[0m
[93maverage test of epoch 93: loss -31.38614 acc 0.34211 roc_auc 0.63385 prc_auc 0.76053[0m
[92maverage training of epoch 94: loss -31.60364 acc 0.33333 roc_auc 0.42120 prc_auc 0.60290[0m
[93maverage test of epoch 94: loss -31.90914 acc 0.34211 roc_auc 0.62923 prc_auc 0.73796[0m
[92maverage training of epoch 95: loss -32.12769 acc 0.33333 roc_auc 0.41630 prc_auc 0.59627[0m
[93maverage test of epoch 95: loss -32.43623 acc 0.34211 roc_auc 0.31538 prc_auc 0.56101[0m
[92maverage training of epoch 96: loss -32.65583 acc 0.33333 roc_auc 0.41300 prc_auc 0.59623[0m
[93maverage test of epoch 96: loss -32.96597 acc 0.34211 roc_auc 0.53385 prc_auc 0.73782[0m
[92maverage training of epoch 97: loss -33.18756 acc 0.33333 roc_auc 0.40900 prc_auc 0.59749[0m
[93maverage test of epoch 97: loss -33.50175 acc 0.34211 roc_auc 0.41846 prc_auc 0.61639[0m
[92maverage training of epoch 98: loss -33.72737 acc 0.33333 roc_auc 0.41690 prc_auc 0.59765[0m
[93maverage test of epoch 98: loss -34.04157 acc 0.34211 roc_auc 0.40000 prc_auc 0.66149[0m
[92maverage training of epoch 99: loss -34.27048 acc 0.33333 roc_auc 0.42140 prc_auc 0.62047[0m
[93maverage test of epoch 99: loss -34.58667 acc 0.34211 roc_auc 0.51385 prc_auc 0.65106[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.90112 acc 0.33333 roc_auc 0.51280 prc_auc 0.72697[0m
[93maverage test of epoch 0: loss -1.03468 acc 0.34211 roc_auc 0.71385 prc_auc 0.79325[0m
[92maverage training of epoch 1: loss -1.15193 acc 0.33333 roc_auc 0.54500 prc_auc 0.70004[0m
[93maverage test of epoch 1: loss -1.30051 acc 0.34211 roc_auc 0.35077 prc_auc 0.56255[0m
[92maverage training of epoch 2: loss -1.43764 acc 0.33333 roc_auc 0.46760 prc_auc 0.64763[0m
[93maverage test of epoch 2: loss -1.57596 acc 0.34211 roc_auc 0.34154 prc_auc 0.56077[0m
[92maverage training of epoch 3: loss -1.67578 acc 0.33333 roc_auc 0.51220 prc_auc 0.69727[0m
[93maverage test of epoch 3: loss -1.80481 acc 0.34211 roc_auc 0.62769 prc_auc 0.72973[0m
[92maverage training of epoch 4: loss -1.86636 acc 0.33333 roc_auc 0.50540 prc_auc 0.66879[0m
[93maverage test of epoch 4: loss -1.97266 acc 0.34211 roc_auc 0.45538 prc_auc 0.69542[0m
[92maverage training of epoch 5: loss -2.05566 acc 0.33333 roc_auc 0.45900 prc_auc 0.65781[0m
[93maverage test of epoch 5: loss -2.15144 acc 0.34211 roc_auc 0.36308 prc_auc 0.59755[0m
[92maverage training of epoch 6: loss -2.23695 acc 0.33333 roc_auc 0.46300 prc_auc 0.66522[0m
[93maverage test of epoch 6: loss -2.34774 acc 0.34211 roc_auc 0.37231 prc_auc 0.66825[0m
[92maverage training of epoch 7: loss -2.42450 acc 0.33333 roc_auc 0.51080 prc_auc 0.66235[0m
[93maverage test of epoch 7: loss -2.54053 acc 0.34211 roc_auc 0.65846 prc_auc 0.83050[0m
[92maverage training of epoch 8: loss -2.60946 acc 0.33333 roc_auc 0.51700 prc_auc 0.69029[0m
[93maverage test of epoch 8: loss -2.71410 acc 0.34211 roc_auc 0.38769 prc_auc 0.67060[0m
[92maverage training of epoch 9: loss -2.78492 acc 0.33333 roc_auc 0.54020 prc_auc 0.69567[0m
[93maverage test of epoch 9: loss -2.88428 acc 0.34211 roc_auc 0.52615 prc_auc 0.72438[0m
[92maverage training of epoch 10: loss -2.97503 acc 0.33333 roc_auc 0.52560 prc_auc 0.71095[0m
[93maverage test of epoch 10: loss -3.09278 acc 0.34211 roc_auc 0.58769 prc_auc 0.76764[0m
[92maverage training of epoch 11: loss -3.16662 acc 0.33333 roc_auc 0.61660 prc_auc 0.74168[0m
[93maverage test of epoch 11: loss -3.32695 acc 0.34211 roc_auc 0.73846 prc_auc 0.80299[0m
[92maverage training of epoch 12: loss -3.37364 acc 0.33333 roc_auc 0.53800 prc_auc 0.72467[0m
[93maverage test of epoch 12: loss -3.51400 acc 0.34211 roc_auc 0.68923 prc_auc 0.77628[0m
[92maverage training of epoch 13: loss -3.57765 acc 0.33333 roc_auc 0.56460 prc_auc 0.74557[0m
[93maverage test of epoch 13: loss -3.67677 acc 0.34211 roc_auc 0.52308 prc_auc 0.75622[0m
[92maverage training of epoch 14: loss -3.77549 acc 0.33333 roc_auc 0.55560 prc_auc 0.74880[0m
[93maverage test of epoch 14: loss -3.88560 acc 0.34211 roc_auc 0.54769 prc_auc 0.74862[0m
[92maverage training of epoch 15: loss -3.95327 acc 0.33333 roc_auc 0.47940 prc_auc 0.67593[0m
[93maverage test of epoch 15: loss -4.08465 acc 0.34211 roc_auc 0.48923 prc_auc 0.64046[0m
[92maverage training of epoch 16: loss -4.15215 acc 0.33333 roc_auc 0.50680 prc_auc 0.70940[0m
[93maverage test of epoch 16: loss -4.28351 acc 0.34211 roc_auc 0.55385 prc_auc 0.72025[0m
[92maverage training of epoch 17: loss -4.35254 acc 0.33333 roc_auc 0.55440 prc_auc 0.73829[0m
[93maverage test of epoch 17: loss -4.48301 acc 0.34211 roc_auc 0.59385 prc_auc 0.77638[0m
[92maverage training of epoch 18: loss -4.54473 acc 0.33333 roc_auc 0.53020 prc_auc 0.68475[0m
[93maverage test of epoch 18: loss -4.69530 acc 0.34211 roc_auc 0.57846 prc_auc 0.73353[0m
[92maverage training of epoch 19: loss -4.77146 acc 0.33333 roc_auc 0.57720 prc_auc 0.73569[0m
[93maverage test of epoch 19: loss -4.93252 acc 0.34211 roc_auc 0.44000 prc_auc 0.63236[0m
[92maverage training of epoch 20: loss -5.01910 acc 0.33333 roc_auc 0.54100 prc_auc 0.73588[0m
[93maverage test of epoch 20: loss -5.20352 acc 0.34211 roc_auc 0.60615 prc_auc 0.68597[0m
[92maverage training of epoch 21: loss -5.27952 acc 0.33333 roc_auc 0.51180 prc_auc 0.66922[0m
[93maverage test of epoch 21: loss -5.43106 acc 0.34211 roc_auc 0.52000 prc_auc 0.71080[0m
[92maverage training of epoch 22: loss -5.53364 acc 0.33333 roc_auc 0.52720 prc_auc 0.67212[0m
[93maverage test of epoch 22: loss -5.69680 acc 0.34211 roc_auc 0.64000 prc_auc 0.71787[0m
[92maverage training of epoch 23: loss -5.79135 acc 0.33333 roc_auc 0.51040 prc_auc 0.71102[0m
[93maverage test of epoch 23: loss -5.93932 acc 0.34211 roc_auc 0.61231 prc_auc 0.74851[0m
[92maverage training of epoch 24: loss -6.06345 acc 0.33333 roc_auc 0.51180 prc_auc 0.72534[0m
[93maverage test of epoch 24: loss -6.22535 acc 0.34211 roc_auc 0.55077 prc_auc 0.76717[0m
[92maverage training of epoch 25: loss -6.34091 acc 0.33333 roc_auc 0.50740 prc_auc 0.66383[0m
[93maverage test of epoch 25: loss -6.51580 acc 0.34211 roc_auc 0.53231 prc_auc 0.72302[0m
[92maverage training of epoch 26: loss -6.60751 acc 0.33333 roc_auc 0.51380 prc_auc 0.69626[0m
[93maverage test of epoch 26: loss -6.76810 acc 0.34211 roc_auc 0.38462 prc_auc 0.59664[0m
[92maverage training of epoch 27: loss -6.88275 acc 0.33333 roc_auc 0.61780 prc_auc 0.77486[0m
[93maverage test of epoch 27: loss -7.06060 acc 0.34211 roc_auc 0.51077 prc_auc 0.73237[0m
[92maverage training of epoch 28: loss -7.16774 acc 0.33333 roc_auc 0.53280 prc_auc 0.69668[0m
[93maverage test of epoch 28: loss -7.33320 acc 0.34211 roc_auc 0.33231 prc_auc 0.58911[0m
[92maverage training of epoch 29: loss -7.45163 acc 0.33333 roc_auc 0.47460 prc_auc 0.65308[0m
[93maverage test of epoch 29: loss -7.63007 acc 0.34211 roc_auc 0.43077 prc_auc 0.63081[0m
[92maverage training of epoch 30: loss -7.74206 acc 0.33333 roc_auc 0.52900 prc_auc 0.69281[0m
[93maverage test of epoch 30: loss -7.90104 acc 0.34211 roc_auc 0.35385 prc_auc 0.57310[0m
[92maverage training of epoch 31: loss -8.02276 acc 0.33333 roc_auc 0.56780 prc_auc 0.73346[0m
[93maverage test of epoch 31: loss -8.21852 acc 0.34211 roc_auc 0.48615 prc_auc 0.70829[0m
[92maverage training of epoch 32: loss -8.31561 acc 0.33333 roc_auc 0.60620 prc_auc 0.78350[0m
[93maverage test of epoch 32: loss -8.50334 acc 0.34211 roc_auc 0.47692 prc_auc 0.71239[0m
[92maverage training of epoch 33: loss -8.60978 acc 0.33333 roc_auc 0.49060 prc_auc 0.66274[0m
[93maverage test of epoch 33: loss -8.80303 acc 0.34211 roc_auc 0.39385 prc_auc 0.65241[0m
[92maverage training of epoch 34: loss -8.90800 acc 0.33333 roc_auc 0.47800 prc_auc 0.64402[0m
[93maverage test of epoch 34: loss -9.10084 acc 0.34211 roc_auc 0.50462 prc_auc 0.69831[0m
[92maverage training of epoch 35: loss -9.20018 acc 0.33333 roc_auc 0.49700 prc_auc 0.64507[0m
[93maverage test of epoch 35: loss -9.38726 acc 0.34211 roc_auc 0.26769 prc_auc 0.53092[0m
[92maverage training of epoch 36: loss -9.51021 acc 0.33333 roc_auc 0.54180 prc_auc 0.71652[0m
[93maverage test of epoch 36: loss -9.69060 acc 0.34211 roc_auc 0.38769 prc_auc 0.60967[0m
[92maverage training of epoch 37: loss -9.81772 acc 0.33333 roc_auc 0.45800 prc_auc 0.68424[0m
[93maverage test of epoch 37: loss -10.01734 acc 0.34211 roc_auc 0.53538 prc_auc 0.68026[0m
[92maverage training of epoch 38: loss -10.13402 acc 0.33333 roc_auc 0.50060 prc_auc 0.66294[0m
[93maverage test of epoch 38: loss -10.35069 acc 0.34211 roc_auc 0.46154 prc_auc 0.70040[0m
[92maverage training of epoch 39: loss -10.44829 acc 0.33333 roc_auc 0.54580 prc_auc 0.72192[0m
[93maverage test of epoch 39: loss -10.64403 acc 0.34211 roc_auc 0.57538 prc_auc 0.74903[0m
[92maverage training of epoch 40: loss -10.77612 acc 0.33333 roc_auc 0.52740 prc_auc 0.69659[0m
[93maverage test of epoch 40: loss -10.98624 acc 0.34211 roc_auc 0.43385 prc_auc 0.67410[0m
[92maverage training of epoch 41: loss -11.10521 acc 0.33333 roc_auc 0.54940 prc_auc 0.72242[0m
[93maverage test of epoch 41: loss -11.32572 acc 0.34211 roc_auc 0.43077 prc_auc 0.70370[0m
[92maverage training of epoch 42: loss -11.42441 acc 0.33333 roc_auc 0.54340 prc_auc 0.69446[0m
[93maverage test of epoch 42: loss -11.64114 acc 0.34211 roc_auc 0.54462 prc_auc 0.73942[0m
[92maverage training of epoch 43: loss -11.76156 acc 0.33333 roc_auc 0.52060 prc_auc 0.64471[0m
[93maverage test of epoch 43: loss -11.97321 acc 0.34211 roc_auc 0.39077 prc_auc 0.58839[0m
[92maverage training of epoch 44: loss -12.09670 acc 0.33333 roc_auc 0.52260 prc_auc 0.71742[0m
[93maverage test of epoch 44: loss -12.31666 acc 0.34211 roc_auc 0.55077 prc_auc 0.69943[0m
[92maverage training of epoch 45: loss -12.43814 acc 0.33333 roc_auc 0.54700 prc_auc 0.71477[0m
[93maverage test of epoch 45: loss -12.65814 acc 0.34211 roc_auc 0.54615 prc_auc 0.75292[0m
[92maverage training of epoch 46: loss -12.78401 acc 0.33333 roc_auc 0.54160 prc_auc 0.69049[0m
[93maverage test of epoch 46: loss -13.01673 acc 0.34211 roc_auc 0.44308 prc_auc 0.66461[0m
[92maverage training of epoch 47: loss -13.14136 acc 0.33333 roc_auc 0.50960 prc_auc 0.66184[0m
[93maverage test of epoch 47: loss -13.36889 acc 0.34211 roc_auc 0.55692 prc_auc 0.68991[0m
[92maverage training of epoch 48: loss -13.49569 acc 0.33333 roc_auc 0.58820 prc_auc 0.74700[0m
[93maverage test of epoch 48: loss -13.72651 acc 0.34211 roc_auc 0.46462 prc_auc 0.61550[0m
[92maverage training of epoch 49: loss -13.85874 acc 0.33333 roc_auc 0.54380 prc_auc 0.73091[0m
[93maverage test of epoch 49: loss -14.08317 acc 0.34211 roc_auc 0.42769 prc_auc 0.61372[0m
[92maverage training of epoch 50: loss -14.22342 acc 0.33333 roc_auc 0.54380 prc_auc 0.69822[0m
[93maverage test of epoch 50: loss -14.46642 acc 0.34211 roc_auc 0.54462 prc_auc 0.71864[0m
[92maverage training of epoch 51: loss -14.59714 acc 0.33333 roc_auc 0.49880 prc_auc 0.65541[0m
[93maverage test of epoch 51: loss -14.83805 acc 0.34211 roc_auc 0.44615 prc_auc 0.64376[0m
[92maverage training of epoch 52: loss -14.97283 acc 0.33333 roc_auc 0.52940 prc_auc 0.70003[0m
[93maverage test of epoch 52: loss -15.20958 acc 0.34211 roc_auc 0.46000 prc_auc 0.66568[0m
[92maverage training of epoch 53: loss -15.35202 acc 0.33333 roc_auc 0.53160 prc_auc 0.70453[0m
[93maverage test of epoch 53: loss -15.60448 acc 0.34211 roc_auc 0.59385 prc_auc 0.77704[0m
[92maverage training of epoch 54: loss -15.73657 acc 0.33333 roc_auc 0.54980 prc_auc 0.69182[0m
[93maverage test of epoch 54: loss -15.98338 acc 0.34211 roc_auc 0.59077 prc_auc 0.77603[0m
[92maverage training of epoch 55: loss -16.13040 acc 0.33333 roc_auc 0.55160 prc_auc 0.72834[0m
[93maverage test of epoch 55: loss -16.38549 acc 0.34211 roc_auc 0.58000 prc_auc 0.74544[0m
[92maverage training of epoch 56: loss -16.52522 acc 0.33333 roc_auc 0.53520 prc_auc 0.69554[0m
[93maverage test of epoch 56: loss -16.78846 acc 0.34211 roc_auc 0.46462 prc_auc 0.70614[0m
[92maverage training of epoch 57: loss -16.92265 acc 0.33333 roc_auc 0.48320 prc_auc 0.64684[0m
[93maverage test of epoch 57: loss -17.19642 acc 0.34211 roc_auc 0.26462 prc_auc 0.52758[0m
[92maverage training of epoch 58: loss -17.33199 acc 0.33333 roc_auc 0.55140 prc_auc 0.67924[0m
[93maverage test of epoch 58: loss -17.60617 acc 0.34211 roc_auc 0.48000 prc_auc 0.67015[0m
[92maverage training of epoch 59: loss -17.73984 acc 0.33333 roc_auc 0.54120 prc_auc 0.71551[0m
[93maverage test of epoch 59: loss -18.02059 acc 0.34211 roc_auc 0.44154 prc_auc 0.60635[0m
[92maverage training of epoch 60: loss -18.16357 acc 0.33333 roc_auc 0.50720 prc_auc 0.68074[0m
[93maverage test of epoch 60: loss -18.44616 acc 0.34211 roc_auc 0.52769 prc_auc 0.73229[0m
[92maverage training of epoch 61: loss -18.57798 acc 0.33333 roc_auc 0.48700 prc_auc 0.67580[0m
[93maverage test of epoch 61: loss -18.85245 acc 0.34211 roc_auc 0.37846 prc_auc 0.58859[0m
[92maverage training of epoch 62: loss -19.01207 acc 0.33333 roc_auc 0.45960 prc_auc 0.63770[0m
[93maverage test of epoch 62: loss -19.29303 acc 0.34211 roc_auc 0.48923 prc_auc 0.67013[0m
[92maverage training of epoch 63: loss -19.44557 acc 0.33333 roc_auc 0.48500 prc_auc 0.63490[0m
[93maverage test of epoch 63: loss -19.72555 acc 0.34211 roc_auc 0.43692 prc_auc 0.65793[0m
[92maverage training of epoch 64: loss -19.88082 acc 0.33333 roc_auc 0.52800 prc_auc 0.71059[0m
[93maverage test of epoch 64: loss -20.16699 acc 0.34211 roc_auc 0.38615 prc_auc 0.60883[0m
[92maverage training of epoch 65: loss -20.32274 acc 0.33333 roc_auc 0.55630 prc_auc 0.74395[0m
[93maverage test of epoch 65: loss -20.61621 acc 0.34211 roc_auc 0.62769 prc_auc 0.74814[0m
[92maverage training of epoch 66: loss -20.77499 acc 0.33333 roc_auc 0.51570 prc_auc 0.69980[0m
[93maverage test of epoch 66: loss -21.06135 acc 0.34211 roc_auc 0.42462 prc_auc 0.63765[0m
[92maverage training of epoch 67: loss -21.22995 acc 0.33333 roc_auc 0.49640 prc_auc 0.67634[0m
[93maverage test of epoch 67: loss -21.52248 acc 0.34211 roc_auc 0.58154 prc_auc 0.74506[0m
[92maverage training of epoch 68: loss -21.68400 acc 0.33333 roc_auc 0.46620 prc_auc 0.64815[0m
[93maverage test of epoch 68: loss -21.98891 acc 0.34211 roc_auc 0.54769 prc_auc 0.69089[0m
[92maverage training of epoch 69: loss -22.15373 acc 0.33333 roc_auc 0.50100 prc_auc 0.66672[0m
[93maverage test of epoch 69: loss -22.45392 acc 0.34211 roc_auc 0.44000 prc_auc 0.60344[0m
[92maverage training of epoch 70: loss -22.62076 acc 0.33333 roc_auc 0.50560 prc_auc 0.67371[0m
[93maverage test of epoch 70: loss -22.91982 acc 0.34211 roc_auc 0.56615 prc_auc 0.75822[0m
[92maverage training of epoch 71: loss -23.09393 acc 0.33333 roc_auc 0.46830 prc_auc 0.65320[0m
[93maverage test of epoch 71: loss -23.41201 acc 0.34211 roc_auc 0.51231 prc_auc 0.67060[0m
[92maverage training of epoch 72: loss -23.57875 acc 0.33333 roc_auc 0.48580 prc_auc 0.66828[0m
[93maverage test of epoch 72: loss -23.88943 acc 0.34211 roc_auc 0.50923 prc_auc 0.69765[0m
[92maverage training of epoch 73: loss -24.06197 acc 0.33333 roc_auc 0.44970 prc_auc 0.62789[0m
[93maverage test of epoch 73: loss -24.37304 acc 0.34211 roc_auc 0.53692 prc_auc 0.72416[0m
[92maverage training of epoch 74: loss -24.55327 acc 0.33333 roc_auc 0.44840 prc_auc 0.61729[0m
[93maverage test of epoch 74: loss -24.87483 acc 0.34211 roc_auc 0.42769 prc_auc 0.63295[0m
[92maverage training of epoch 75: loss -25.04741 acc 0.33333 roc_auc 0.44860 prc_auc 0.64459[0m
[93maverage test of epoch 75: loss -25.36774 acc 0.34211 roc_auc 0.58308 prc_auc 0.73813[0m
[92maverage training of epoch 76: loss -25.55337 acc 0.33333 roc_auc 0.48200 prc_auc 0.67718[0m
[93maverage test of epoch 76: loss -25.87831 acc 0.34211 roc_auc 0.60615 prc_auc 0.74528[0m
[92maverage training of epoch 77: loss -26.05387 acc 0.33333 roc_auc 0.48100 prc_auc 0.66043[0m
[93maverage test of epoch 77: loss -26.38173 acc 0.34211 roc_auc 0.41846 prc_auc 0.64877[0m
[92maverage training of epoch 78: loss -26.57048 acc 0.33333 roc_auc 0.49900 prc_auc 0.69894[0m
[93maverage test of epoch 78: loss -26.89682 acc 0.34211 roc_auc 0.75538 prc_auc 0.79574[0m
[92maverage training of epoch 79: loss -27.08596 acc 0.33333 roc_auc 0.47500 prc_auc 0.68119[0m
[93maverage test of epoch 79: loss -27.41978 acc 0.34211 roc_auc 0.64000 prc_auc 0.74311[0m
[92maverage training of epoch 80: loss -27.60676 acc 0.33333 roc_auc 0.43490 prc_auc 0.61488[0m
[93maverage test of epoch 80: loss -27.94685 acc 0.34211 roc_auc 0.48769 prc_auc 0.68029[0m
[92maverage training of epoch 81: loss -28.13587 acc 0.33333 roc_auc 0.48180 prc_auc 0.66254[0m
[93maverage test of epoch 81: loss -28.47737 acc 0.34211 roc_auc 0.44923 prc_auc 0.66069[0m
[92maverage training of epoch 82: loss -28.66623 acc 0.33333 roc_auc 0.43120 prc_auc 0.62081[0m
[93maverage test of epoch 82: loss -29.01487 acc 0.34211 roc_auc 0.63538 prc_auc 0.81970[0m
[92maverage training of epoch 83: loss -29.20439 acc 0.33333 roc_auc 0.45100 prc_auc 0.64891[0m
[93maverage test of epoch 83: loss -29.55463 acc 0.34211 roc_auc 0.48462 prc_auc 0.67886[0m
[92maverage training of epoch 84: loss -29.74761 acc 0.33333 roc_auc 0.45280 prc_auc 0.64501[0m
[93maverage test of epoch 84: loss -30.09583 acc 0.34211 roc_auc 0.52000 prc_auc 0.72127[0m
[92maverage training of epoch 85: loss -30.29676 acc 0.33333 roc_auc 0.47000 prc_auc 0.65193[0m
[93maverage test of epoch 85: loss -30.64874 acc 0.34211 roc_auc 0.48769 prc_auc 0.65332[0m
[92maverage training of epoch 86: loss -30.84900 acc 0.33333 roc_auc 0.45040 prc_auc 0.64026[0m
[93maverage test of epoch 86: loss -31.20621 acc 0.34211 roc_auc 0.40769 prc_auc 0.69075[0m
[92maverage training of epoch 87: loss -31.40656 acc 0.33333 roc_auc 0.45400 prc_auc 0.63633[0m
[93maverage test of epoch 87: loss -31.76118 acc 0.34211 roc_auc 0.65385 prc_auc 0.77780[0m
[92maverage training of epoch 88: loss -31.96796 acc 0.33333 roc_auc 0.43040 prc_auc 0.61788[0m
[93maverage test of epoch 88: loss -32.32520 acc 0.34211 roc_auc 0.65385 prc_auc 0.78460[0m
[92maverage training of epoch 89: loss -32.53452 acc 0.33333 roc_auc 0.45500 prc_auc 0.65493[0m
[93maverage test of epoch 89: loss -32.89695 acc 0.34211 roc_auc 0.53385 prc_auc 0.72371[0m
[92maverage training of epoch 90: loss -33.10414 acc 0.33333 roc_auc 0.44160 prc_auc 0.64926[0m
[93maverage test of epoch 90: loss -33.47023 acc 0.34211 roc_auc 0.58769 prc_auc 0.73806[0m
[92maverage training of epoch 91: loss -33.68004 acc 0.33333 roc_auc 0.43620 prc_auc 0.63582[0m
[93maverage test of epoch 91: loss -34.05028 acc 0.34211 roc_auc 0.44154 prc_auc 0.65597[0m
[92maverage training of epoch 92: loss -34.26234 acc 0.33333 roc_auc 0.44080 prc_auc 0.63366[0m
[93maverage test of epoch 92: loss -34.63460 acc 0.34211 roc_auc 0.60462 prc_auc 0.76543[0m
[92maverage training of epoch 93: loss -34.84794 acc 0.33333 roc_auc 0.43210 prc_auc 0.63178[0m
[93maverage test of epoch 93: loss -35.22067 acc 0.34211 roc_auc 0.43385 prc_auc 0.63240[0m
[92maverage training of epoch 94: loss -35.43756 acc 0.33333 roc_auc 0.43540 prc_auc 0.63236[0m
[93maverage test of epoch 94: loss -35.81527 acc 0.34211 roc_auc 0.33077 prc_auc 0.55834[0m
[92maverage training of epoch 95: loss -36.03500 acc 0.33333 roc_auc 0.42980 prc_auc 0.64593[0m
[93maverage test of epoch 95: loss -36.41466 acc 0.34211 roc_auc 0.65692 prc_auc 0.80593[0m
[92maverage training of epoch 96: loss -36.63366 acc 0.33333 roc_auc 0.42200 prc_auc 0.62656[0m
[93maverage test of epoch 96: loss -37.01124 acc 0.34211 roc_auc 0.56615 prc_auc 0.73023[0m
[92maverage training of epoch 97: loss -37.24040 acc 0.33333 roc_auc 0.42760 prc_auc 0.61722[0m
[93maverage test of epoch 97: loss -37.62635 acc 0.34211 roc_auc 0.36769 prc_auc 0.63536[0m
[92maverage training of epoch 98: loss -37.85250 acc 0.33333 roc_auc 0.40900 prc_auc 0.61047[0m
[93maverage test of epoch 98: loss -38.24039 acc 0.34211 roc_auc 0.67846 prc_auc 0.78692[0m
[92maverage training of epoch 99: loss -38.46742 acc 0.33333 roc_auc 0.43330 prc_auc 0.63292[0m
[93maverage test of epoch 99: loss -38.85889 acc 0.34211 roc_auc 0.43538 prc_auc 0.64535[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.19081 acc 0.66225 roc_auc 0.51373 prc_auc 0.68076[0m
[93maverage test of epoch 0: loss -0.22379 acc 0.67568 roc_auc 0.31667 prc_auc 0.57138[0m
[92maverage training of epoch 1: loss -0.25369 acc 0.66225 roc_auc 0.53608 prc_auc 0.66328[0m
[93maverage test of epoch 1: loss -0.29086 acc 0.67568 roc_auc 0.37333 prc_auc 0.60395[0m
[92maverage training of epoch 2: loss -0.32306 acc 0.66225 roc_auc 0.52510 prc_auc 0.65941[0m
[93maverage test of epoch 2: loss -0.37238 acc 0.67568 roc_auc 0.67667 prc_auc 0.83256[0m
[92maverage training of epoch 3: loss -0.41469 acc 0.66225 roc_auc 0.55863 prc_auc 0.69044[0m
[93maverage test of epoch 3: loss -0.46014 acc 0.67568 roc_auc 0.43667 prc_auc 0.68837[0m
[92maverage training of epoch 4: loss -0.53061 acc 0.52318 roc_auc 0.51216 prc_auc 0.70706[0m
[93maverage test of epoch 4: loss -0.62826 acc 0.32432 roc_auc 0.42333 prc_auc 0.66261[0m
[92maverage training of epoch 5: loss -0.75941 acc 0.33775 roc_auc 0.54373 prc_auc 0.73407[0m
[93maverage test of epoch 5: loss -0.88123 acc 0.32432 roc_auc 0.47667 prc_auc 0.69677[0m
[92maverage training of epoch 6: loss -0.97790 acc 0.33775 roc_auc 0.40275 prc_auc 0.59825[0m
[93maverage test of epoch 6: loss -1.08298 acc 0.32432 roc_auc 0.41333 prc_auc 0.63035[0m
[92maverage training of epoch 7: loss -1.20642 acc 0.33775 roc_auc 0.55157 prc_auc 0.70280[0m
[93maverage test of epoch 7: loss -1.32759 acc 0.32432 roc_auc 0.61667 prc_auc 0.77020[0m
[92maverage training of epoch 8: loss -1.40963 acc 0.33775 roc_auc 0.44078 prc_auc 0.62282[0m
[93maverage test of epoch 8: loss -1.53008 acc 0.32432 roc_auc 0.61667 prc_auc 0.78545[0m
[92maverage training of epoch 9: loss -1.64878 acc 0.33775 roc_auc 0.53373 prc_auc 0.68182[0m
[93maverage test of epoch 9: loss -1.75728 acc 0.32432 roc_auc 0.51667 prc_auc 0.68584[0m
[92maverage training of epoch 10: loss -1.89702 acc 0.33775 roc_auc 0.53275 prc_auc 0.68338[0m
[93maverage test of epoch 10: loss -1.95784 acc 0.32432 roc_auc 0.45333 prc_auc 0.65149[0m
[92maverage training of epoch 11: loss -2.13542 acc 0.33775 roc_auc 0.53824 prc_auc 0.70985[0m
[93maverage test of epoch 11: loss -2.23910 acc 0.32432 roc_auc 0.54333 prc_auc 0.74525[0m
[92maverage training of epoch 12: loss -2.37688 acc 0.33775 roc_auc 0.54157 prc_auc 0.67516[0m
[93maverage test of epoch 12: loss -2.48557 acc 0.32432 roc_auc 0.56667 prc_auc 0.79268[0m
[92maverage training of epoch 13: loss -2.60462 acc 0.33775 roc_auc 0.56235 prc_auc 0.73490[0m
[93maverage test of epoch 13: loss -2.65782 acc 0.32432 roc_auc 0.26333 prc_auc 0.57074[0m
[92maverage training of epoch 14: loss -2.80563 acc 0.33775 roc_auc 0.56333 prc_auc 0.68761[0m
[93maverage test of epoch 14: loss -2.85781 acc 0.32432 roc_auc 0.48333 prc_auc 0.74375[0m
[92maverage training of epoch 15: loss -3.00822 acc 0.33775 roc_auc 0.52549 prc_auc 0.68916[0m
[93maverage test of epoch 15: loss -3.06802 acc 0.32432 roc_auc 0.46000 prc_auc 0.69758[0m
[92maverage training of epoch 16: loss -3.20698 acc 0.33775 roc_auc 0.47706 prc_auc 0.66865[0m
[93maverage test of epoch 16: loss -3.25144 acc 0.32432 roc_auc 0.60667 prc_auc 0.76237[0m
[92maverage training of epoch 17: loss -3.40424 acc 0.33775 roc_auc 0.50000 prc_auc 0.64472[0m
[93maverage test of epoch 17: loss -3.47145 acc 0.32432 roc_auc 0.49333 prc_auc 0.68124[0m
[92maverage training of epoch 18: loss -3.62504 acc 0.33775 roc_auc 0.49843 prc_auc 0.67267[0m
[93maverage test of epoch 18: loss -3.67067 acc 0.32432 roc_auc 0.51000 prc_auc 0.67186[0m
[92maverage training of epoch 19: loss -3.83634 acc 0.33775 roc_auc 0.41196 prc_auc 0.62080[0m
[93maverage test of epoch 19: loss -3.86043 acc 0.32432 roc_auc 0.18667 prc_auc 0.55396[0m
[92maverage training of epoch 20: loss -4.04453 acc 0.33775 roc_auc 0.46431 prc_auc 0.64929[0m
[93maverage test of epoch 20: loss -4.09343 acc 0.32432 roc_auc 0.50333 prc_auc 0.68950[0m
[92maverage training of epoch 21: loss -4.25989 acc 0.33775 roc_auc 0.55471 prc_auc 0.70275[0m
[93maverage test of epoch 21: loss -4.31582 acc 0.32432 roc_auc 0.47667 prc_auc 0.70492[0m
[92maverage training of epoch 22: loss -4.45499 acc 0.33775 roc_auc 0.51490 prc_auc 0.69717[0m
[93maverage test of epoch 22: loss -4.51572 acc 0.32432 roc_auc 0.46000 prc_auc 0.71006[0m
[92maverage training of epoch 23: loss -4.66940 acc 0.33775 roc_auc 0.54000 prc_auc 0.71220[0m
[93maverage test of epoch 23: loss -4.72810 acc 0.32432 roc_auc 0.58333 prc_auc 0.69729[0m
[92maverage training of epoch 24: loss -4.87329 acc 0.33775 roc_auc 0.52196 prc_auc 0.70121[0m
[93maverage test of epoch 24: loss -4.91748 acc 0.32432 roc_auc 0.41667 prc_auc 0.66975[0m
[92maverage training of epoch 25: loss -5.07682 acc 0.33775 roc_auc 0.46510 prc_auc 0.66099[0m
[93maverage test of epoch 25: loss -5.15457 acc 0.32432 roc_auc 0.39667 prc_auc 0.66015[0m
[92maverage training of epoch 26: loss -5.30106 acc 0.33775 roc_auc 0.54216 prc_auc 0.71340[0m
[93maverage test of epoch 26: loss -5.34381 acc 0.32432 roc_auc 0.53333 prc_auc 0.74622[0m
[92maverage training of epoch 27: loss -5.50460 acc 0.33775 roc_auc 0.39863 prc_auc 0.58636[0m
[93maverage test of epoch 27: loss -5.55981 acc 0.32432 roc_auc 0.64000 prc_auc 0.81008[0m
[92maverage training of epoch 28: loss -5.73095 acc 0.33775 roc_auc 0.51235 prc_auc 0.65895[0m
[93maverage test of epoch 28: loss -5.76568 acc 0.32432 roc_auc 0.50000 prc_auc 0.66981[0m
[92maverage training of epoch 29: loss -5.93990 acc 0.33775 roc_auc 0.54745 prc_auc 0.70042[0m
[93maverage test of epoch 29: loss -6.00152 acc 0.32432 roc_auc 0.57667 prc_auc 0.72864[0m
[92maverage training of epoch 30: loss -6.15987 acc 0.33775 roc_auc 0.46725 prc_auc 0.64145[0m
[93maverage test of epoch 30: loss -6.21574 acc 0.32432 roc_auc 0.56000 prc_auc 0.79533[0m
[92maverage training of epoch 31: loss -6.38950 acc 0.33775 roc_auc 0.46137 prc_auc 0.62397[0m
[93maverage test of epoch 31: loss -6.44527 acc 0.32432 roc_auc 0.52667 prc_auc 0.69020[0m
[92maverage training of epoch 32: loss -6.62004 acc 0.33775 roc_auc 0.47294 prc_auc 0.66454[0m
[93maverage test of epoch 32: loss -6.67109 acc 0.32432 roc_auc 0.54667 prc_auc 0.70887[0m
[92maverage training of epoch 33: loss -6.85842 acc 0.33775 roc_auc 0.45098 prc_auc 0.64551[0m
[93maverage test of epoch 33: loss -6.90410 acc 0.32432 roc_auc 0.43333 prc_auc 0.70286[0m
[92maverage training of epoch 34: loss -7.08474 acc 0.33775 roc_auc 0.48451 prc_auc 0.69706[0m
[93maverage test of epoch 34: loss -7.13036 acc 0.32432 roc_auc 0.53000 prc_auc 0.71409[0m
[92maverage training of epoch 35: loss -7.31895 acc 0.33775 roc_auc 0.51765 prc_auc 0.68018[0m
[93maverage test of epoch 35: loss -7.36590 acc 0.32432 roc_auc 0.38667 prc_auc 0.62692[0m
[92maverage training of epoch 36: loss -7.55830 acc 0.33775 roc_auc 0.53882 prc_auc 0.69622[0mUsing backend: pytorch

[93maverage test of epoch 36: loss -7.60599 acc 0.32432 roc_auc 0.49667 prc_auc 0.67747[0m
[92maverage training of epoch 37: loss -7.79621 acc 0.33775 roc_auc 0.51314 prc_auc 0.66541[0m
[93maverage test of epoch 37: loss -7.84418 acc 0.32432 roc_auc 0.48333 prc_auc 0.70863[0m
[92maverage training of epoch 38: loss -8.05750 acc 0.33775 roc_auc 0.53157 prc_auc 0.70801[0m
[93maverage test of epoch 38: loss -8.09209 acc 0.32432 roc_auc 0.64667 prc_auc 0.83549[0m
[92maverage training of epoch 39: loss -8.29991 acc 0.33775 roc_auc 0.50686 prc_auc 0.67002[0m
[93maverage test of epoch 39: loss -8.35244 acc 0.32432 roc_auc 0.47333 prc_auc 0.69467[0m
[92maverage training of epoch 40: loss -8.54837 acc 0.33775 roc_auc 0.52882 prc_auc 0.67092[0m
[93maverage test of epoch 40: loss -8.60530 acc 0.32432 roc_auc 0.55000 prc_auc 0.79314[0m
[92maverage training of epoch 41: loss -8.80445 acc 0.33775 roc_auc 0.46588 prc_auc 0.65516[0m
[93maverage test of epoch 41: loss -8.85557 acc 0.32432 roc_auc 0.33333 prc_auc 0.57427[0m
[92maverage training of epoch 42: loss -9.06414 acc 0.33775 roc_auc 0.54343 prc_auc 0.70121[0m
[93maverage test of epoch 42: loss -9.12076 acc 0.32432 roc_auc 0.55667 prc_auc 0.75983[0m
[92maverage training of epoch 43: loss -9.32927 acc 0.33775 roc_auc 0.54451 prc_auc 0.67097[0m
[93maverage test of epoch 43: loss -9.39009 acc 0.32432 roc_auc 0.68000 prc_auc 0.81945[0m
[92maverage training of epoch 44: loss -9.59661 acc 0.33775 roc_auc 0.51157 prc_auc 0.69230[0m
[93maverage test of epoch 44: loss -9.65947 acc 0.32432 roc_auc 0.62333 prc_auc 0.81054[0m
[92maverage training of epoch 45: loss -9.86885 acc 0.33775 roc_auc 0.48373 prc_auc 0.65745[0m
[93maverage test of epoch 45: loss -9.93350 acc 0.32432 roc_auc 0.54000 prc_auc 0.79672[0m
[92maverage training of epoch 46: loss -10.14030 acc 0.33775 roc_auc 0.49255 prc_auc 0.68677[0m
[93maverage test of epoch 46: loss -10.19370 acc 0.32432 roc_auc 0.50667 prc_auc 0.66688[0m
[92maverage training of epoch 47: loss -10.42241 acc 0.33775 roc_auc 0.51461 prc_auc 0.70497[0m
[93maverage test of epoch 47: loss -10.47918 acc 0.32432 roc_auc 0.44333 prc_auc 0.69958[0m
[92maverage training of epoch 48: loss -10.70569 acc 0.33775 roc_auc 0.50137 prc_auc 0.66019[0m
[93maverage test of epoch 48: loss -10.76746 acc 0.32432 roc_auc 0.57333 prc_auc 0.75105[0m
[92maverage training of epoch 49: loss -10.98141 acc 0.33775 roc_auc 0.50235 prc_auc 0.66489[0m
[93maverage test of epoch 49: loss -11.03667 acc 0.32432 roc_auc 0.39667 prc_auc 0.64121[0m
[92maverage training of epoch 50: loss -11.27070 acc 0.33775 roc_auc 0.49176 prc_auc 0.66231[0m
[93maverage test of epoch 50: loss -11.32841 acc 0.32432 roc_auc 0.43000 prc_auc 0.63074[0m
[92maverage training of epoch 51: loss -11.56345 acc 0.33775 roc_auc 0.49078 prc_auc 0.69213[0m
[93maverage test of epoch 51: loss -11.61923 acc 0.32432 roc_auc 0.37000 prc_auc 0.64479[0m
[92maverage training of epoch 52: loss -11.86041 acc 0.33775 roc_auc 0.52294 prc_auc 0.67066[0m
[93maverage test of epoch 52: loss -11.91334 acc 0.32432 roc_auc 0.37000 prc_auc 0.61168[0m
[92maverage training of epoch 53: loss -12.15880 acc 0.33775 roc_auc 0.50745 prc_auc 0.72386[0m
[93maverage test of epoch 53: loss -12.22778 acc 0.32432 roc_auc 0.54833 prc_auc 0.74780[0m
[92maverage training of epoch 54: loss -12.46024 acc 0.33775 roc_auc 0.48980 prc_auc 0.66477[0m
[93maverage test of epoch 54: loss -12.52124 acc 0.32432 roc_auc 0.60333 prc_auc 0.79639[0m
[92maverage training of epoch 55: loss -12.76190 acc 0.33775 roc_auc 0.53431 prc_auc 0.69079[0m
[93maverage test of epoch 55: loss -12.82970 acc 0.32432 roc_auc 0.46333 prc_auc 0.68305[0m
[92maverage training of epoch 56: loss -13.07555 acc 0.33775 roc_auc 0.49608 prc_auc 0.67714[0m
[93maverage test of epoch 56: loss -13.14007 acc 0.32432 roc_auc 0.41833 prc_auc 0.63893[0m
[92maverage training of epoch 57: loss -13.38285 acc 0.33775 roc_auc 0.44176 prc_auc 0.62549[0m
[93maverage test of epoch 57: loss -13.45203 acc 0.32432 roc_auc 0.46833 prc_auc 0.63269[0m
[92maverage training of epoch 58: loss -13.69574 acc 0.33775 roc_auc 0.49843 prc_auc 0.67917[0m
[93maverage test of epoch 58: loss -13.77178 acc 0.32432 roc_auc 0.61667 prc_auc 0.77648[0m
[92maverage training of epoch 59: loss -14.02284 acc 0.33775 roc_auc 0.46765 prc_auc 0.65800[0m
[93maverage test of epoch 59: loss -14.09072 acc 0.32432 roc_auc 0.33667 prc_auc 0.58581[0m
[92maverage training of epoch 60: loss -14.34295 acc 0.33775 roc_auc 0.49647 prc_auc 0.66368[0m
[93maverage test of epoch 60: loss -14.41888 acc 0.32432 roc_auc 0.61500 prc_auc 0.73268[0m
[92maverage training of epoch 61: loss -14.66596 acc 0.33775 roc_auc 0.49961 prc_auc 0.67468[0m
[93maverage test of epoch 61: loss -14.74666 acc 0.32432 roc_auc 0.55667 prc_auc 0.71735[0m
[92maverage training of epoch 62: loss -15.00000 acc 0.33775 roc_auc 0.46284 prc_auc 0.64435[0m
[93maverage test of epoch 62: loss -15.06922 acc 0.32432 roc_auc 0.52167 prc_auc 0.68922[0m
[92maverage training of epoch 63: loss -15.33158 acc 0.33775 roc_auc 0.47882 prc_auc 0.66694[0m
[93maverage test of epoch 63: loss -15.39702 acc 0.32432 roc_auc 0.49667 prc_auc 0.65186[0m
[92maverage training of epoch 64: loss -15.67030 acc 0.33775 roc_auc 0.43902 prc_auc 0.63487[0m
[93maverage test of epoch 64: loss -15.74358 acc 0.32432 roc_auc 0.50667 prc_auc 0.65139[0m
[92maverage training of epoch 65: loss -16.00952 acc 0.33775 roc_auc 0.51412 prc_auc 0.68629[0m
[93maverage test of epoch 65: loss -16.08771 acc 0.32432 roc_auc 0.51667 prc_auc 0.70449[0m
[92maverage training of epoch 66: loss -16.35443 acc 0.33775 roc_auc 0.52608 prc_auc 0.68249[0m
[93maverage test of epoch 66: loss -16.42943 acc 0.32432 roc_auc 0.59500 prc_auc 0.79202[0m
[92maverage training of epoch 67: loss -16.70022 acc 0.33775 roc_auc 0.46412 prc_auc 0.66951[0m
[93maverage test of epoch 67: loss -16.77456 acc 0.32432 roc_auc 0.58500 prc_auc 0.81063[0m
[92maverage training of epoch 68: loss -17.04885 acc 0.33775 roc_auc 0.48784 prc_auc 0.67169[0m
[93maverage test of epoch 68: loss -17.12389 acc 0.32432 roc_auc 0.49333 prc_auc 0.71077[0m
[92maverage training of epoch 69: loss -17.40210 acc 0.33775 roc_auc 0.48118 prc_auc 0.64604[0m
[93maverage test of epoch 69: loss -17.48279 acc 0.32432 roc_auc 0.41833 prc_auc 0.62892[0m
[92maverage training of epoch 70: loss -17.75894 acc 0.33775 roc_auc 0.42137 prc_auc 0.65673[0m
[93maverage test of epoch 70: loss -17.83766 acc 0.32432 roc_auc 0.56833 prc_auc 0.79471[0m
[92maverage training of epoch 71: loss -18.11583 acc 0.33775 roc_auc 0.44412 prc_auc 0.61327[0m
[93maverage test of epoch 71: loss -18.19951 acc 0.32432 roc_auc 0.62167 prc_auc 0.81823[0m
[92maverage training of epoch 72: loss -18.48240 acc 0.33775 roc_auc 0.46990 prc_auc 0.66170[0m
[93maverage test of epoch 72: loss -18.56576 acc 0.32432 roc_auc 0.56000 prc_auc 0.74176[0m
[92maverage training of epoch 73: loss -18.84498 acc 0.33775 roc_auc 0.44431 prc_auc 0.63453[0m
[93maverage test of epoch 73: loss -18.93701 acc 0.32432 roc_auc 0.39167 prc_auc 0.70877[0m
[92maverage training of epoch 74: loss -19.21345 acc 0.33775 roc_auc 0.45275 prc_auc 0.63898[0m
[93maverage test of epoch 74: loss -19.30135 acc 0.32432 roc_auc 0.65333 prc_auc 0.78958[0m
[92maverage training of epoch 75: loss -19.58690 acc 0.33775 roc_auc 0.42804 prc_auc 0.62445[0m
[93maverage test of epoch 75: loss -19.67643 acc 0.32432 roc_auc 0.53667 prc_auc 0.75810[0m
[92maverage training of epoch 76: loss -19.96189 acc 0.33775 roc_auc 0.46873 prc_auc 0.66321[0m
[93maverage test of epoch 76: loss -20.05496 acc 0.32432 roc_auc 0.34667 prc_auc 0.65799[0m
[92maverage training of epoch 77: loss -20.33955 acc 0.33775 roc_auc 0.47627 prc_auc 0.67363[0m
[93maverage test of epoch 77: loss -20.42490 acc 0.32432 roc_auc 0.59667 prc_auc 0.74569[0m
[92maverage training of epoch 78: loss -20.71827 acc 0.33775 roc_auc 0.45549 prc_auc 0.64242[0m
[93maverage test of epoch 78: loss -20.80160 acc 0.32432 roc_auc 0.48167 prc_auc 0.62623[0m
[92maverage training of epoch 79: loss -21.10131 acc 0.33775 roc_auc 0.40216 prc_auc 0.58860[0m
[93maverage test of epoch 79: loss -21.18987 acc 0.32432 roc_auc 0.65667 prc_auc 0.79040[0m
[92maverage training of epoch 80: loss -21.48535 acc 0.33775 roc_auc 0.44049 prc_auc 0.64078[0m
[93maverage test of epoch 80: loss -21.58032 acc 0.32432 roc_auc 0.77667 prc_auc 0.86650[0m
[92maverage training of epoch 81: loss -21.87245 acc 0.33775 roc_auc 0.43725 prc_auc 0.63308[0m
[93maverage test of epoch 81: loss -21.96577 acc 0.32432 roc_auc 0.39500 prc_auc 0.62290[0m
[92maverage training of epoch 82: loss -22.26269 acc 0.33775 roc_auc 0.40667 prc_auc 0.60903[0m
[93maverage test of epoch 82: loss -22.35776 acc 0.32432 roc_auc 0.51500 prc_auc 0.72560[0m
[92maverage training of epoch 83: loss -22.65615 acc 0.33775 roc_auc 0.40627 prc_auc 0.63760[0m
[93maverage test of epoch 83: loss -22.75306 acc 0.32432 roc_auc 0.55333 prc_auc 0.74111[0m
[92maverage training of epoch 84: loss -23.05220 acc 0.33775 roc_auc 0.43647 prc_auc 0.64840[0m
[93maverage test of epoch 84: loss -23.14753 acc 0.32432 roc_auc 0.57667 prc_auc 0.75025[0m
[92maverage training of epoch 85: loss -23.45298 acc 0.33775 roc_auc 0.44608 prc_auc 0.65489[0m
[93maverage test of epoch 85: loss -23.54723 acc 0.32432 roc_auc 0.57167 prc_auc 0.68319[0m
[92maverage training of epoch 86: loss -23.85493 acc 0.33775 roc_auc 0.42245 prc_auc 0.63376[0m
[93maverage test of epoch 86: loss -23.95356 acc 0.32432 roc_auc 0.46000 prc_auc 0.63979[0m
[92maverage training of epoch 87: loss -24.26046 acc 0.33775 roc_auc 0.43765 prc_auc 0.64636[0m
[93maverage test of epoch 87: loss -24.35515 acc 0.32432 roc_auc 0.51667 prc_auc 0.72008[0m
[92maverage training of epoch 88: loss -24.66731 acc 0.33775 roc_auc 0.40490 prc_auc 0.58556[0m
[93maverage test of epoch 88: loss -24.77156 acc 0.32432 roc_auc 0.48167 prc_auc 0.69100[0m
[92maverage training of epoch 89: loss -25.08253 acc 0.33775 roc_auc 0.40353 prc_auc 0.62380[0m
[93maverage test of epoch 89: loss -25.18525 acc 0.32432 roc_auc 0.56167 prc_auc 0.70402[0m
[92maverage training of epoch 90: loss -25.49521 acc 0.33775 roc_auc 0.41706 prc_auc 0.63087[0m
[93maverage test of epoch 90: loss -25.60040 acc 0.32432 roc_auc 0.36500 prc_auc 0.63409[0m
[92maverage training of epoch 91: loss -25.91301 acc 0.33775 roc_auc 0.39529 prc_auc 0.59300[0m
[93maverage test of epoch 91: loss -26.01966 acc 0.32432 roc_auc 0.58000 prc_auc 0.70753[0m
[92maverage training of epoch 92: loss -26.33286 acc 0.33775 roc_auc 0.41735 prc_auc 0.60894[0m
[93maverage test of epoch 92: loss -26.44116 acc 0.32432 roc_auc 0.51000 prc_auc 0.72731[0m
[92maverage training of epoch 93: loss -26.75957 acc 0.33775 roc_auc 0.39314 prc_auc 0.61729[0m
[93maverage test of epoch 93: loss -26.86967 acc 0.32432 roc_auc 0.55000 prc_auc 0.75860[0m
[92maverage training of epoch 94: loss -27.18714 acc 0.33775 roc_auc 0.36294 prc_auc 0.58594[0m
[93maverage test of epoch 94: loss -27.29955 acc 0.32432 roc_auc 0.42500 prc_auc 0.68013[0m
[92maverage training of epoch 95: loss -27.61842 acc 0.33775 roc_auc 0.39686 prc_auc 0.61440[0m
[93maverage test of epoch 95: loss -27.73201 acc 0.32432 roc_auc 0.53333 prc_auc 0.70207[0m
[92maverage training of epoch 96: loss -28.05269 acc 0.33775 roc_auc 0.38902 prc_auc 0.63311[0m
[93maverage test of epoch 96: loss -28.16746 acc 0.32432 roc_auc 0.43667 prc_auc 0.67051[0m
[92maverage training of epoch 97: loss -28.49008 acc 0.33775 roc_auc 0.37147 prc_auc 0.61837[0m
[93maverage test of epoch 97: loss -28.60831 acc 0.32432 roc_auc 0.54000 prc_auc 0.69930[0m
[92maverage training of epoch 98: loss -28.93109 acc 0.33775 roc_auc 0.37598 prc_auc 0.61086[0m
[93maverage test of epoch 98: loss -29.05006 acc 0.32432 roc_auc 0.46000 prc_auc 0.72895[0m
[92maverage training of epoch 99: loss -29.37530 acc 0.33775 roc_auc 0.37716 prc_auc 0.60091[0m
[93maverage test of epoch 99: loss -29.49532 acc 0.32432 roc_auc 0.57333 prc_auc 0.73959[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss 0.14372 acc 0.33775 roc_auc 0.45549 prc_auc 0.65449[0m
[93maverage test of epoch 0: loss 0.12987 acc 0.32432 roc_auc 0.51333 prc_auc 0.73074[0m
[92maverage training of epoch 1: loss -0.01229 acc 0.33775 roc_auc 0.41275 prc_auc 0.62114[0m
[93maverage test of epoch 1: loss -0.28913 acc 0.32432 roc_auc 0.32333 prc_auc 0.62238[0m
[92maverage training of epoch 2: loss -0.66162 acc 0.47682 roc_auc 0.44941 prc_auc 0.65229[0m
[93maverage test of epoch 2: loss -1.05857 acc 0.67568 roc_auc 0.70333 prc_auc 0.86164[0m
[92maverage training of epoch 3: loss -1.47189 acc 0.66225 roc_auc 0.49510 prc_auc 0.66449[0m
[93maverage test of epoch 3: loss -2.02116 acc 0.67568 roc_auc 0.59667 prc_auc 0.72549[0m
[92maverage training of epoch 4: loss -2.33015 acc 0.66225 roc_auc 0.45176 prc_auc 0.63418[0m
[93maverage test of epoch 4: loss -2.68293 acc 0.67568 roc_auc 0.61667 prc_auc 0.76781[0m
[92maverage training of epoch 5: loss -2.86873 acc 0.66225 roc_auc 0.45647 prc_auc 0.64773[0m
[93maverage test of epoch 5: loss -3.09547 acc 0.67568 roc_auc 0.63000 prc_auc 0.74284[0m
[92maverage training of epoch 6: loss -3.23462 acc 0.66225 roc_auc 0.45078 prc_auc 0.63660[0m
[93maverage test of epoch 6: loss -3.44119 acc 0.67568 roc_auc 0.61000 prc_auc 0.83206[0m
[92maverage training of epoch 7: loss -3.55198 acc 0.66225 roc_auc 0.49569 prc_auc 0.67768[0m
[93maverage test of epoch 7: loss -3.73205 acc 0.67568 roc_auc 0.44000 prc_auc 0.68691[0m
[92maverage training of epoch 8: loss -3.85710 acc 0.66225 roc_auc 0.38294 prc_auc 0.60562[0m
[93maverage test of epoch 8: loss -4.04910 acc 0.67568 roc_auc 0.46667 prc_auc 0.64269[0m
[92maverage training of epoch 9: loss -4.15965 acc 0.66225 roc_auc 0.49765 prc_auc 0.65343[0m
[93maverage test of epoch 9: loss -4.35000 acc 0.67568 roc_auc 0.45667 prc_auc 0.68393[0m
[92maverage training of epoch 10: loss -4.44587 acc 0.66225 roc_auc 0.44294 prc_auc 0.64929[0m
[93maverage test of epoch 10: loss -4.63713 acc 0.67568 roc_auc 0.47333 prc_auc 0.67462[0m
[92maverage training of epoch 11: loss -4.74694 acc 0.66225 roc_auc 0.45059 prc_auc 0.63627[0m
[93maverage test of epoch 11: loss -4.93883 acc 0.67568 roc_auc 0.32000 prc_auc 0.58646[0m
[92maverage training of epoch 12: loss -5.04093 acc 0.66225 roc_auc 0.39686 prc_auc 0.60650[0m
[93maverage test of epoch 12: loss -5.23589 acc 0.67568 roc_auc 0.42333 prc_auc 0.64845[0m
[92maverage training of epoch 13: loss -5.32648 acc 0.66225 roc_auc 0.45314 prc_auc 0.64756[0m
[93maverage test of epoch 13: loss -5.54084 acc 0.67568 roc_auc 0.73000 prc_auc 0.81196[0m
[92maverage training of epoch 14: loss -5.62300 acc 0.66225 roc_auc 0.44157 prc_auc 0.64509[0m
[93maverage test of epoch 14: loss -5.83439 acc 0.67568 roc_auc 0.53000 prc_auc 0.69907[0m
[92maverage training of epoch 15: loss -5.92472 acc 0.66225 roc_auc 0.36843 prc_auc 0.60327[0m
[93maverage test of epoch 15: loss -6.12247 acc 0.67568 roc_auc 0.57333 prc_auc 0.75291[0m
[92maverage training of epoch 16: loss -6.22206 acc 0.66225 roc_auc 0.38627 prc_auc 0.59659[0m
[93maverage test of epoch 16: loss -6.44312 acc 0.67568 roc_auc 0.53333 prc_auc 0.70687[0m
[92maverage training of epoch 17: loss -6.53657 acc 0.66225 roc_auc 0.43745 prc_auc 0.63198[0m
[93maverage test of epoch 17: loss -6.76098 acc 0.67568 roc_auc 0.57000 prc_auc 0.72751[0m
[92maverage training of epoch 18: loss -6.83767 acc 0.66225 roc_auc 0.42137 prc_auc 0.62874[0m
[93maverage test of epoch 18: loss -7.05554 acc 0.67568 roc_auc 0.57333 prc_auc 0.70621[0m
[92maverage training of epoch 19: loss -7.16198 acc 0.66225 roc_auc 0.37304 prc_auc 0.60864[0m
[93maverage test of epoch 19: loss -7.37968 acc 0.67568 roc_auc 0.64667 prc_auc 0.80699[0m
[92maverage training of epoch 20: loss -7.48272 acc 0.66225 roc_auc 0.43000 prc_auc 0.62513[0m
[93maverage test of epoch 20: loss -7.67852 acc 0.67568 roc_auc 0.45333 prc_auc 0.66386[0m
[92maverage training of epoch 21: loss -7.79281 acc 0.66225 roc_auc 0.42549 prc_auc 0.61977[0m
[93maverage test of epoch 21: loss -8.03172 acc 0.67568 roc_auc 0.64000 prc_auc 0.81359[0m
[92maverage training of epoch 22: loss -8.12559 acc 0.66225 roc_auc 0.47882 prc_auc 0.65738[0m
[93maverage test of epoch 22: loss -8.34462 acc 0.67568 roc_auc 0.61333 prc_auc 0.76312[0m
[92maverage training of epoch 23: loss -8.45900 acc 0.66225 roc_auc 0.44275 prc_auc 0.62090[0m
[93maverage test of epoch 23: loss -8.70810 acc 0.67568 roc_auc 0.52000 prc_auc 0.76333[0m
[92maverage training of epoch 24: loss -8.78420 acc 0.66225 roc_auc 0.43931 prc_auc 0.63668[0m
[93maverage test of epoch 24: loss -9.02838 acc 0.67568 roc_auc 0.55333 prc_auc 0.78495[0m
[92maverage training of epoch 25: loss -9.12964 acc 0.66225 roc_auc 0.42373 prc_auc 0.62341[0m
[93maverage test of epoch 25: loss -9.36418 acc 0.67568 roc_auc 0.45500 prc_auc 0.72052[0m
[92maverage training of epoch 26: loss -9.47718 acc 0.66225 roc_auc 0.43569 prc_auc 0.62625[0m
[93maverage test of epoch 26: loss -9.73416 acc 0.67568 roc_auc 0.60167 prc_auc 0.78292[0m
[92maverage training of epoch 27: loss -9.81986 acc 0.66225 roc_auc 0.40294 prc_auc 0.62923[0m
[93maverage test of epoch 27: loss -10.07535 acc 0.67568 roc_auc 0.46333 prc_auc 0.73737[0m
[92maverage training of epoch 28: loss -10.16867 acc 0.66225 roc_auc 0.41804 prc_auc 0.62469[0m
[93maverage test of epoch 28: loss -10.43420 acc 0.67568 roc_auc 0.52000 prc_auc 0.74089[0m
[92maverage training of epoch 29: loss -10.53220 acc 0.66225 roc_auc 0.44971 prc_auc 0.63326[0m
[93maverage test of epoch 29: loss -10.80928 acc 0.67568 roc_auc 0.50167 prc_auc 0.71632[0m
[92maverage training of epoch 30: loss -10.89627 acc 0.66225 roc_auc 0.47922 prc_auc 0.67384[0m
[93maverage test of epoch 30: loss -11.16934 acc 0.67568 roc_auc 0.30833 prc_auc 0.60951[0m
[92maverage training of epoch 31: loss -11.26751 acc 0.66225 roc_auc 0.46186 prc_auc 0.65108[0m
[93maverage test of epoch 31: loss -11.53233 acc 0.67568 roc_auc 0.64667 prc_auc 0.78613[0m
[92maverage training of epoch 32: loss -11.62789 acc 0.66225 roc_auc 0.43784 prc_auc 0.64078[0m
[93maverage test of epoch 32: loss -11.91394 acc 0.67568 roc_auc 0.53667 prc_auc 0.72598[0m
[92maverage training of epoch 33: loss -12.00589 acc 0.66225 roc_auc 0.42127 prc_auc 0.63367[0m
[93maverage test of epoch 33: loss -12.29791 acc 0.67568 roc_auc 0.54667 prc_auc 0.69730[0m
[92maverage training of epoch 34: loss -12.39186 acc 0.66225 roc_auc 0.41745 prc_auc 0.60587[0m
[93maverage test of epoch 34: loss -12.66797 acc 0.67568 roc_auc 0.36333 prc_auc 0.62598[0m
[92maverage training of epoch 35: loss -12.77853 acc 0.66225 roc_auc 0.38765 prc_auc 0.59458[0m
[93maverage test of epoch 35: loss -13.07272 acc 0.67568 roc_auc 0.59833 prc_auc 0.77506[0m
[92maverage training of epoch 36: loss -13.16852 acc 0.66225 roc_auc 0.42431 prc_auc 0.64502[0m
[93maverage test of epoch 36: loss -13.46630 acc 0.67568 roc_auc 0.64833 prc_auc 0.77140[0m
[92maverage training of epoch 37: loss -13.56546 acc 0.66225 roc_auc 0.46010 prc_auc 0.63332[0m
[93maverage test of epoch 37: loss -13.87302 acc 0.67568 roc_auc 0.33000 prc_auc 0.59689[0m
[92maverage training of epoch 38: loss -13.96149 acc 0.66225 roc_auc 0.44373 prc_auc 0.61020[0m
[93maverage test of epoch 38: loss -14.27631 acc 0.67568 roc_auc 0.42000 prc_auc 0.64887[0m
[92maverage training of epoch 39: loss -14.36956 acc 0.66225 roc_auc 0.42716 prc_auc 0.64154[0m
[93maverage test of epoch 39: loss -14.69662 acc 0.67568 roc_auc 0.72167 prc_auc 0.82332[0m
[92maverage training of epoch 40: loss -14.78442 acc 0.66225 roc_auc 0.40010 prc_auc 0.60994[0m
[93maverage test of epoch 40: loss -15.10257 acc 0.67568 roc_auc 0.57500 prc_auc 0.74412[0m
[92maverage training of epoch 41: loss -15.19585 acc 0.66225 roc_auc 0.41863 prc_auc 0.60644[0m
[93maverage test of epoch 41: loss -15.50728 acc 0.67568 roc_auc 0.60000 prc_auc 0.73706[0m
[92maverage training of epoch 42: loss -15.61333 acc 0.66225 roc_auc 0.41686 prc_auc 0.60761[0m
[93maverage test of epoch 42: loss -15.93944 acc 0.67568 roc_auc 0.56500 prc_auc 0.71001[0m
[92maverage training of epoch 43: loss -16.04377 acc 0.66225 roc_auc 0.43245 prc_auc 0.62583[0m
[93maverage test of epoch 43: loss -16.37530 acc 0.67568 roc_auc 0.47167 prc_auc 0.68253[0m
[92maverage training of epoch 44: loss -16.47961 acc 0.66225 roc_auc 0.44441 prc_auc 0.64370[0m
[93maverage test of epoch 44: loss -16.81069 acc 0.67568 roc_auc 0.56000 prc_auc 0.72775[0m
[92maverage training of epoch 45: loss -16.90939 acc 0.66225 roc_auc 0.43471 prc_auc 0.62065[0m
[93maverage test of epoch 45: loss -17.25142 acc 0.67568 roc_auc 0.43667 prc_auc 0.64982[0m
[92maverage training of epoch 46: loss -17.34809 acc 0.66225 roc_auc 0.40657 prc_auc 0.62751[0m
[93maverage test of epoch 46: loss -17.70644 acc 0.67568 roc_auc 0.34667 prc_auc 0.60775[0m
[92maverage training of epoch 47: loss -17.79593 acc 0.66225 roc_auc 0.42627 prc_auc 0.62616[0m
[93maverage test of epoch 47: loss -18.15517 acc 0.67568 roc_auc 0.56833 prc_auc 0.69518[0m
[92maverage training of epoch 48: loss -18.24380 acc 0.66225 roc_auc 0.40333 prc_auc 0.60090[0m
[93maverage test of epoch 48: loss -18.61210 acc 0.67568 roc_auc 0.54167 prc_auc 0.69024[0m
[92maverage training of epoch 49: loss -18.70068 acc 0.66225 roc_auc 0.40137 prc_auc 0.59516[0m
[93maverage test of epoch 49: loss -19.07218 acc 0.67568 roc_auc 0.55833 prc_auc 0.68806[0m
[92maverage training of epoch 50: loss -19.16122 acc 0.66225 roc_auc 0.42608 prc_auc 0.61573[0m
[93maverage test of epoch 50: loss -19.54583 acc 0.67568 roc_auc 0.52333 prc_auc 0.67352[0m
[92maverage training of epoch 51: loss -19.63281 acc 0.66225 roc_auc 0.43216 prc_auc 0.63188[0m
[93maverage test of epoch 51: loss -20.01138 acc 0.67568 roc_auc 0.54167 prc_auc 0.70506[0m
[92maverage training of epoch 52: loss -20.10320 acc 0.66225 roc_auc 0.40284 prc_auc 0.59837[0m
[93maverage test of epoch 52: loss -20.47793 acc 0.67568 roc_auc 0.40500 prc_auc 0.62386[0m
[92maverage training of epoch 53: loss -20.57978 acc 0.66225 roc_auc 0.40657 prc_auc 0.60463[0m
[93maverage test of epoch 53: loss -20.96332 acc 0.67568 roc_auc 0.44167 prc_auc 0.64927[0m
[92maverage training of epoch 54: loss -21.05978 acc 0.66225 roc_auc 0.40931 prc_auc 0.60673[0m
[93maverage test of epoch 54: loss -21.46270 acc 0.67568 roc_auc 0.41667 prc_auc 0.64123[0m
[92maverage training of epoch 55: loss -21.54345 acc 0.66225 roc_auc 0.40059 prc_auc 0.60194[0m
[93maverage test of epoch 55: loss -21.94061 acc 0.67568 roc_auc 0.62333 prc_auc 0.75328[0m
[92maverage training of epoch 56: loss -22.03757 acc 0.66225 roc_auc 0.39676 prc_auc 0.59820[0m
[93maverage test of epoch 56: loss -22.44810 acc 0.67568 roc_auc 0.55000 prc_auc 0.69813[0m
[92maverage training of epoch 57: loss -22.53247 acc 0.66225 roc_auc 0.41657 prc_auc 0.61477[0m
[93maverage test of epoch 57: loss -22.94432 acc 0.67568 roc_auc 0.30667 prc_auc 0.59495[0m
[92maverage training of epoch 58: loss -23.03018 acc 0.66225 roc_auc 0.39431 prc_auc 0.59399[0m
[93maverage test of epoch 58: loss -23.45267 acc 0.67568 roc_auc 0.63333 prc_auc 0.74981[0m
[92maverage training of epoch 59: loss -23.53887 acc 0.66225 roc_auc 0.40480 prc_auc 0.60280[0m
[93maverage test of epoch 59: loss -23.96131 acc 0.67568 roc_auc 0.51000 prc_auc 0.68014[0m
[92maverage training of epoch 60: loss -24.04411 acc 0.66225 roc_auc 0.40529 prc_auc 0.61048[0m
[93maverage test of epoch 60: loss -24.46686 acc 0.67568 roc_auc 0.64167 prc_auc 0.74571[0m
[92maverage training of epoch 61: loss -24.55576 acc 0.66225 roc_auc 0.38490 prc_auc 0.59389[0m
[93maverage test of epoch 61: loss -24.99406 acc 0.67568 roc_auc 0.60667 prc_auc 0.72641[0m
[92maverage training of epoch 62: loss -25.07715 acc 0.66225 roc_auc 0.41422 prc_auc 0.61079[0m
[93maverage test of epoch 62: loss -25.51425 acc 0.67568 roc_auc 0.46333 prc_auc 0.66009[0m
[92maverage training of epoch 63: loss -25.59861 acc 0.66225 roc_auc 0.37824 prc_auc 0.60090[0m
[93maverage test of epoch 63: loss -26.04330 acc 0.67568 roc_auc 0.50333 prc_auc 0.67714[0m
[92maverage training of epoch 64: loss -26.12732 acc 0.66225 roc_auc 0.43882 prc_auc 0.63369[0m
[93maverage test of epoch 64: loss -26.57560 acc 0.67568 roc_auc 0.46000 prc_auc 0.65863[0m
[92maverage training of epoch 65: loss -26.65844 acc 0.66225 roc_auc 0.43294 prc_auc 0.62916[0m
[93maverage test of epoch 65: loss -27.11807 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 66: loss -27.19232 acc 0.66225 roc_auc 0.44059 prc_auc 0.63489[0m
[93maverage test of epoch 66: loss -27.65548 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 67: loss -27.73370 acc 0.66225 roc_auc 0.39706 prc_auc 0.62002[0m
[93maverage test of epoch 67: loss -28.20237 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 68: loss -28.27767 acc 0.66225 roc_auc 0.43265 prc_auc 0.63415[0m
[93maverage test of epoch 68: loss -28.75362 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 69: loss -28.83387 acc 0.66225 roc_auc 0.46843 prc_auc 0.64851[0m
[93maverage test of epoch 69: loss -29.30958 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 70: loss -29.38724 acc 0.66225 roc_auc 0.46784 prc_auc 0.64829[0m
[93maverage test of epoch 70: loss -29.87376 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 71: loss -29.94892 acc 0.66225 roc_auc 0.39588 prc_auc 0.62295[0m
[93maverage test of epoch 71: loss -30.43926 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 72: loss -30.51606 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 72: loss -31.01199 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 73: loss -31.08262 acc 0.66225 roc_auc 0.39049 prc_auc 0.62223[0m
[93maverage test of epoch 73: loss -31.58322 acc 0.67568 roc_auc 0.48000 prc_auc 0.66703[0m
[92maverage training of epoch 74: loss -31.65750 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 74: loss -32.16502 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 75: loss -32.23645 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 75: loss -32.75345 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 76: loss -32.82337 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 76: loss -33.34493 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 77: loss -33.41262 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 77: loss -33.93610 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 78: loss -34.00674 acc 0.66225 roc_auc 0.47363 prc_auc 0.65071[0m
[93maverage test of epoch 78: loss -34.54076 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 79: loss -34.60536 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 79: loss -35.14346 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 80: loss -35.21062 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 80: loss -35.75179 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 81: loss -35.82082 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 81: loss -36.37003 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 82: loss -36.43265 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 82: loss -36.98533 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 83: loss -37.05126 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 83: loss -37.61433 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 84: loss -37.67479 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 84: loss -38.24262 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 85: loss -38.30286 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 85: loss -38.87659 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 86: loss -38.93534 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 86: loss -39.51598 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 87: loss -39.57530 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 87: loss -40.15900 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 88: loss -40.21685 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 88: loss -40.80836 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 89: loss -40.86522 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 89: loss -41.46120 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 90: loss -41.51765 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 90: loss -42.12240 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 91: loss -42.17684 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 91: loss -42.78298 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 92: loss -42.83859 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 92: loss -43.45572 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 93: loss -43.50737 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 93: loss -44.12677 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 94: loss -44.17943 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 94: loss -44.81009 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 95: loss -44.85927 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 95: loss -45.49200 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 96: loss -45.54244 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 96: loss -46.18392 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 97: loss -46.23048 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 97: loss -46.87927 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 98: loss -46.92460 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 98: loss -47.57830 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 99: loss -47.62305 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 99: loss -48.28360 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 1)
('lr', 0.0001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.40526 ROC_AUC (avg): 0.50451 PRC_AUC (avg): 0.67391 

Average forward propagation time taken(ms): 4.296833962006513
Average backward propagation time taken(ms): 1.581622659223931

