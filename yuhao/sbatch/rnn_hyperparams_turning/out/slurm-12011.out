# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.0003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-07-23-27/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-07-23-27/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 8,
 'epochs': 100,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 8,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.0003,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 2,
 'num_workers': 8,
 'number_of_mlp_layer': 0,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-18-07-23-27',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 100, 'learning_rate': 0.0003, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.42151 acc 0.66667 roc_auc 0.43840 prc_auc 0.63045[0m
[93maverage test of epoch 0: loss -0.87386 acc 0.65789 roc_auc 0.61231 prc_auc 0.69349[0m
[92maverage training of epoch 1: loss -1.37927 acc 0.66667 roc_auc 0.43300 prc_auc 0.62682[0m
[93maverage test of epoch 1: loss -1.93580 acc 0.65789 roc_auc 0.69231 prc_auc 0.81562[0m
[92maverage training of epoch 2: loss -2.32973 acc 0.66667 roc_auc 0.47360 prc_auc 0.66214[0m
[93maverage test of epoch 2: loss -2.65246 acc 0.65789 roc_auc 0.47692 prc_auc 0.73185[0m
[92maverage training of epoch 3: loss -2.90989 acc 0.66667 roc_auc 0.39940 prc_auc 0.62550[0m
[93maverage test of epoch 3: loss -3.13849 acc 0.65789 roc_auc 0.35385 prc_auc 0.56985[0m
[92maverage training of epoch 4: loss -3.35368 acc 0.66667 roc_auc 0.38340 prc_auc 0.60801[0m
[93maverage test of epoch 4: loss -3.53372 acc 0.65789 roc_auc 0.57538 prc_auc 0.70979[0m
[92maverage training of epoch 5: loss -3.73254 acc 0.66667 roc_auc 0.41360 prc_auc 0.62100[0m
[93maverage test of epoch 5: loss -3.90492 acc 0.65789 roc_auc 0.71385 prc_auc 0.82632[0m
[92maverage training of epoch 6: loss -4.11539 acc 0.66667 roc_auc 0.40660 prc_auc 0.61580[0m
[93maverage test of epoch 6: loss -4.30770 acc 0.65789 roc_auc 0.39385 prc_auc 0.66078[0m
[92maverage training of epoch 7: loss -4.50815 acc 0.66667 roc_auc 0.34430 prc_auc 0.58286[0m
[93maverage test of epoch 7: loss -4.69589 acc 0.65789 roc_auc 0.52923 prc_auc 0.67111[0m
[92maverage training of epoch 8: loss -4.89847 acc 0.66667 roc_auc 0.45300 prc_auc 0.61990[0m
[93maverage test of epoch 8: loss -5.06500 acc 0.65789 roc_auc 0.67692 prc_auc 0.76906[0m
[92maverage training of epoch 9: loss -5.26269 acc 0.66667 roc_auc 0.41320 prc_auc 0.64164[0m
[93maverage test of epoch 9: loss -5.41935 acc 0.65789 roc_auc 0.48923 prc_auc 0.65929[0m
[92maverage training of epoch 10: loss -5.61620 acc 0.66667 roc_auc 0.38100 prc_auc 0.58843[0m
[93maverage test of epoch 10: loss -5.76172 acc 0.65789 roc_auc 0.39692 prc_auc 0.62716[0m
[92maverage training of epoch 11: loss -5.96730 acc 0.66667 roc_auc 0.40140 prc_auc 0.58982[0m
[93maverage test of epoch 11: loss -6.11654 acc 0.65789 roc_auc 0.55692 prc_auc 0.73683[0m
[92maverage training of epoch 12: loss -6.30929 acc 0.66667 roc_auc 0.38840 prc_auc 0.60414[0m
[93maverage test of epoch 12: loss -6.44904 acc 0.65789 roc_auc 0.40000 prc_auc 0.61544[0m
[92maverage training of epoch 13: loss -6.64445 acc 0.66667 roc_auc 0.43020 prc_auc 0.62432[0m
[93maverage test of epoch 13: loss -6.78507 acc 0.65789 roc_auc 0.56000 prc_auc 0.67846[0m
[92maverage training of epoch 14: loss -6.97473 acc 0.66667 roc_auc 0.38580 prc_auc 0.58723[0m
[93maverage test of epoch 14: loss -7.11313 acc 0.65789 roc_auc 0.64308 prc_auc 0.83547[0m
[92maverage training of epoch 15: loss -7.29759 acc 0.66667 roc_auc 0.41140 prc_auc 0.62088[0m
[93maverage test of epoch 15: loss -7.43100 acc 0.65789 roc_auc 0.58462 prc_auc 0.75748[0m
[92maverage training of epoch 16: loss -7.62151 acc 0.66667 roc_auc 0.41520 prc_auc 0.59326[0m
[93maverage test of epoch 16: loss -7.74582 acc 0.65789 roc_auc 0.58154 prc_auc 0.76296[0m
[92maverage training of epoch 17: loss -7.93436 acc 0.66667 roc_auc 0.36580 prc_auc 0.57170[0m
[93maverage test of epoch 17: loss -8.06175 acc 0.65789 roc_auc 0.54769 prc_auc 0.75044[0m
[92maverage training of epoch 18: loss -8.25372 acc 0.66667 roc_auc 0.38260 prc_auc 0.58442[0m
[93maverage test of epoch 18: loss -8.37593 acc 0.65789 roc_auc 0.47231 prc_auc 0.63842[0m
[92maverage training of epoch 19: loss -8.56648 acc 0.66667 roc_auc 0.38900 prc_auc 0.59391[0m
[93maverage test of epoch 19: loss -8.68477 acc 0.65789 roc_auc 0.36923 prc_auc 0.63284[0m
[92maverage training of epoch 20: loss -8.87532 acc 0.66667 roc_auc 0.42080 prc_auc 0.60026[0m
[93maverage test of epoch 20: loss -8.98849 acc 0.65789 roc_auc 0.49846 prc_auc 0.67567[0m
[92maverage training of epoch 21: loss -9.18451 acc 0.66667 roc_auc 0.38980 prc_auc 0.59457[0m
[93maverage test of epoch 21: loss -9.30185 acc 0.65789 roc_auc 0.66769 prc_auc 0.83704[0m
[92maverage training of epoch 22: loss -9.49011 acc 0.66667 roc_auc 0.38680 prc_auc 0.57828[0m
[93maverage test of epoch 22: loss -9.60876 acc 0.65789 roc_auc 0.67538 prc_auc 0.79813[0m
[92maverage training of epoch 23: loss -9.79873 acc 0.66667 roc_auc 0.38750 prc_auc 0.59461[0m
[93maverage test of epoch 23: loss -9.91312 acc 0.65789 roc_auc 0.52308 prc_auc 0.74468[0m
[92maverage training of epoch 24: loss -10.10247 acc 0.66667 roc_auc 0.35680 prc_auc 0.57120[0m
[93maverage test of epoch 24: loss -10.21270 acc 0.65789 roc_auc 0.54923 prc_auc 0.70497[0m
[92maverage training of epoch 25: loss -10.40687 acc 0.66667 roc_auc 0.35560 prc_auc 0.56772[0m
[93maverage test of epoch 25: loss -10.51885 acc 0.65789 roc_auc 0.58923 prc_auc 0.79638[0m
[92maverage training of epoch 26: loss -10.71107 acc 0.66667 roc_auc 0.38630 prc_auc 0.60155[0m
[93maverage test of epoch 26: loss -10.81946 acc 0.65789 roc_auc 0.52462 prc_auc 0.75798[0m
[92maverage training of epoch 27: loss -11.01251 acc 0.66667 roc_auc 0.36180 prc_auc 0.57471[0m
[93maverage test of epoch 27: loss -11.12274 acc 0.65789 roc_auc 0.44615 prc_auc 0.68933[0m
[92maverage training of epoch 28: loss -11.31680 acc 0.66667 roc_auc 0.36800 prc_auc 0.57134[0m
[93maverage test of epoch 28: loss -11.42466 acc 0.65789 roc_auc 0.67231 prc_auc 0.77166[0m
[92maverage training of epoch 29: loss -11.61832 acc 0.66667 roc_auc 0.37180 prc_auc 0.57158[0m
[93maverage test of epoch 29: loss -11.72497 acc 0.65789 roc_auc 0.46000 prc_auc 0.67037[0m
[92maverage training of epoch 30: loss -11.91972 acc 0.66667 roc_auc 0.36540 prc_auc 0.57673[0m
[93maverage test of epoch 30: loss -12.02607 acc 0.65789 roc_auc 0.33231 prc_auc 0.61041[0m
[92maverage training of epoch 31: loss -12.22075 acc 0.66667 roc_auc 0.38160 prc_auc 0.59045[0m
[93maverage test of epoch 31: loss -12.32684 acc 0.65789 roc_auc 0.50000 prc_auc 0.71830[0m
[92maverage training of epoch 32: loss -12.52156 acc 0.66667 roc_auc 0.37430 prc_auc 0.58326[0m
[93maverage test of epoch 32: loss -12.62417 acc 0.65789 roc_auc 0.49846 prc_auc 0.64444[0m
[92maverage training of epoch 33: loss -12.82156 acc 0.66667 roc_auc 0.36030 prc_auc 0.58024[0m
[93maverage test of epoch 33: loss -12.92470 acc 0.65789 roc_auc 0.52154 prc_auc 0.66997[0m
[92maverage training of epoch 34: loss -13.12204 acc 0.66667 roc_auc 0.35920 prc_auc 0.57473[0m
[93maverage test of epoch 34: loss -13.22205 acc 0.65789 roc_auc 0.50308 prc_auc 0.74287[0m
[92maverage training of epoch 35: loss -13.42192 acc 0.66667 roc_auc 0.36640 prc_auc 0.57195[0m
[93maverage test of epoch 35: loss -13.52251 acc 0.65789 roc_auc 0.50154 prc_auc 0.66046[0m
[92maverage training of epoch 36: loss -13.72158 acc 0.66667 roc_auc 0.37210 prc_auc 0.58197[0m
[93maverage test of epoch 36: loss -13.82180 acc 0.65789 roc_auc 0.39538 prc_auc 0.61089[0m
[92maverage training of epoch 37: loss -14.02088 acc 0.66667 roc_auc 0.36450 prc_auc 0.57240[0m
[93maverage test of epoch 37: loss -14.11977 acc 0.65789 roc_auc 0.50923 prc_auc 0.71300[0m
[92maverage training of epoch 38: loss -14.32050 acc 0.66667 roc_auc 0.35600 prc_auc 0.56525[0m
[93maverage test of epoch 38: loss -14.41882 acc 0.65789 roc_auc 0.73692 prc_auc 0.83854[0m
[92maverage training of epoch 39: loss -14.61932 acc 0.66667 roc_auc 0.36290 prc_auc 0.57068[0m
[93maverage test of epoch 39: loss -14.71580 acc 0.65789 roc_auc 0.44154 prc_auc 0.63659[0m
[92maverage training of epoch 40: loss -14.91857 acc 0.66667 roc_auc 0.35070 prc_auc 0.55912[0m
[93maverage test of epoch 40: loss -15.01489 acc 0.65789 roc_auc 0.62615 prc_auc 0.76990[0m
[92maverage training of epoch 41: loss -15.21806 acc 0.66667 roc_auc 0.35580 prc_auc 0.56239[0m
[93maverage test of epoch 41: loss -15.31339 acc 0.65789 roc_auc 0.49231 prc_auc 0.66153[0m
[92maverage training of epoch 42: loss -15.51721 acc 0.66667 roc_auc 0.35710 prc_auc 0.56290[0m
[93maverage test of epoch 42: loss -15.61053 acc 0.65789 roc_auc 0.41846 prc_auc 0.61895[0m
[92maverage training of epoch 43: loss -15.81567 acc 0.66667 roc_auc 0.36310 prc_auc 0.57211[0m
[93maverage test of epoch 43: loss -15.90839 acc 0.65789 roc_auc 0.47077 prc_auc 0.65173[0m
[92maverage training of epoch 44: loss -16.11474 acc 0.66667 roc_auc 0.35900 prc_auc 0.56955[0m
[93maverage test of epoch 44: loss -16.20683 acc 0.65789 roc_auc 0.53538 prc_auc 0.67339[0m
[92maverage training of epoch 45: loss -16.41369 acc 0.66667 roc_auc 0.35790 prc_auc 0.56481[0m
[93maverage test of epoch 45: loss -16.50521 acc 0.65789 roc_auc 0.67385 prc_auc 0.77249[0m
[92maverage training of epoch 46: loss -16.71265 acc 0.66667 roc_auc 0.36180 prc_auc 0.56736[0m
[93maverage test of epoch 46: loss -16.80256 acc 0.65789 roc_auc 0.49231 prc_auc 0.63931[0m
[92maverage training of epoch 47: loss -17.01083 acc 0.66667 roc_auc 0.36110 prc_auc 0.56644[0m
[93maverage test of epoch 47: loss -17.10041 acc 0.65789 roc_auc 0.52615 prc_auc 0.68842[0m
[92maverage training of epoch 48: loss -17.31001 acc 0.66667 roc_auc 0.35570 prc_auc 0.56131[0m
[93maverage test of epoch 48: loss -17.39857 acc 0.65789 roc_auc 0.58000 prc_auc 0.71318[0m
[92maverage training of epoch 49: loss -17.60850 acc 0.66667 roc_auc 0.35360 prc_auc 0.56094[0m
[93maverage test of epoch 49: loss -17.69574 acc 0.65789 roc_auc 0.48769 prc_auc 0.64333[0m
[92maverage training of epoch 50: loss -17.90692 acc 0.66667 roc_auc 0.35710 prc_auc 0.56319[0m
[93maverage test of epoch 50: loss -17.99374 acc 0.65789 roc_auc 0.55538 prc_auc 0.72283[0m
[92maverage training of epoch 51: loss -18.20526 acc 0.66667 roc_auc 0.35620 prc_auc 0.56432[0m
[93maverage test of epoch 51: loss -18.29198 acc 0.65789 roc_auc 0.53846 prc_auc 0.69424[0m
[92maverage training of epoch 52: loss -18.50411 acc 0.66667 roc_auc 0.36060 prc_auc 0.56522[0m
[93maverage test of epoch 52: loss -18.58889 acc 0.65789 roc_auc 0.51077 prc_auc 0.65011[0m
[92maverage training of epoch 53: loss -18.80275 acc 0.66667 roc_auc 0.35910 prc_auc 0.56381[0m
[93maverage test of epoch 53: loss -18.88688 acc 0.65789 roc_auc 0.58154 prc_auc 0.70916[0m
[92maverage training of epoch 54: loss -19.10092 acc 0.66667 roc_auc 0.35910 prc_auc 0.56401[0m
[93maverage test of epoch 54: loss -19.18428 acc 0.65789 roc_auc 0.36154 prc_auc 0.60623[0m
[92maverage training of epoch 55: loss -19.39946 acc 0.66667 roc_auc 0.35750 prc_auc 0.56534[0m
[93maverage test of epoch 55: loss -19.48213 acc 0.65789 roc_auc 0.54615 prc_auc 0.68159[0m
[92maverage training of epoch 56: loss -19.69797 acc 0.66667 roc_auc 0.36190 prc_auc 0.56553[0m
[93maverage test of epoch 56: loss -19.77933 acc 0.65789 roc_auc 0.43846 prc_auc 0.63460[0m
[92maverage training of epoch 57: loss -19.99599 acc 0.66667 roc_auc 0.35950 prc_auc 0.56644[0m
[93maverage test of epoch 57: loss -20.07725 acc 0.65789 roc_auc 0.65692 prc_auc 0.77108[0m
[92maverage training of epoch 58: loss -20.29460 acc 0.66667 roc_auc 0.36010 prc_auc 0.56596[0m
[93maverage test of epoch 58: loss -20.37451 acc 0.65789 roc_auc 0.35538 prc_auc 0.59891[0m
[92maverage training of epoch 59: loss -20.59308 acc 0.66667 roc_auc 0.35940 prc_auc 0.56633[0m
[93maverage test of epoch 59: loss -20.67224 acc 0.65789 roc_auc 0.42462 prc_auc 0.62624[0m
[92maverage training of epoch 60: loss -20.89148 acc 0.66667 roc_auc 0.35870 prc_auc 0.56531[0m
[93maverage test of epoch 60: loss -20.96977 acc 0.65789 roc_auc 0.57231 prc_auc 0.69419[0m
[92maverage training of epoch 61: loss -21.18981 acc 0.66667 roc_auc 0.35990 prc_auc 0.56650[0m
[93maverage test of epoch 61: loss -21.26739 acc 0.65789 roc_auc 0.55846 prc_auc 0.68517[0m
[92maverage training of epoch 62: loss -21.48823 acc 0.66667 roc_auc 0.36540 prc_auc 0.56881[0m
[93maverage test of epoch 62: loss -21.56491 acc 0.65789 roc_auc 0.48000 prc_auc 0.64888[0m
[92maverage training of epoch 63: loss -21.78660 acc 0.66667 roc_auc 0.35640 prc_auc 0.56338[0m
[93maverage test of epoch 63: loss -21.86244 acc 0.65789 roc_auc 0.56000 prc_auc 0.68608[0m
[92maverage training of epoch 64: loss -22.08497 acc 0.66667 roc_auc 0.35950 prc_auc 0.56786[0m
[93maverage test of epoch 64: loss -22.15983 acc 0.65789 roc_auc 0.51385 prc_auc 0.66487[0m
[92maverage training of epoch 65: loss -22.38323 acc 0.66667 roc_auc 0.35840 prc_auc 0.56585[0m
[93maverage test of epoch 65: loss -22.45746 acc 0.65789 roc_auc 0.60000 prc_auc 0.70656[0m
[92maverage training of epoch 66: loss -22.68167 acc 0.66667 roc_auc 0.35840 prc_auc 0.56582[0m
[93maverage test of epoch 66: loss -22.75471 acc 0.65789 roc_auc 0.49846 prc_auc 0.65720[0m
[92maverage training of epoch 67: loss -22.97994 acc 0.66667 roc_auc 0.35760 prc_auc 0.56648[0m
[93maverage test of epoch 67: loss -23.05222 acc 0.65789 roc_auc 0.51385 prc_auc 0.66487[0m
[92maverage training of epoch 68: loss -23.27833 acc 0.66667 roc_auc 0.35960 prc_auc 0.56712[0m
[93maverage test of epoch 68: loss -23.34960 acc 0.65789 roc_auc 0.51846 prc_auc 0.66632[0m
[92maverage training of epoch 69: loss -23.57655 acc 0.66667 roc_auc 0.35800 prc_auc 0.56649[0m
[93maverage test of epoch 69: loss -23.64732 acc 0.65789 roc_auc 0.49385 prc_auc 0.65514[0m
[92maverage training of epoch 70: loss -23.87488 acc 0.66667 roc_auc 0.35830 prc_auc 0.56769[0m
[93maverage test of epoch 70: loss -23.94444 acc 0.65789 roc_auc 0.57692 prc_auc 0.69444[0m
[92maverage training of epoch 71: loss -24.17313 acc 0.66667 roc_auc 0.36100 prc_auc 0.56914[0m
[93maverage test of epoch 71: loss -24.24210 acc 0.65789 roc_auc 0.53846 prc_auc 0.67568[0m
[92maverage training of epoch 72: loss -24.47148 acc 0.66667 roc_auc 0.36170 prc_auc 0.57048[0m
[93maverage test of epoch 72: loss -24.53959 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 73: loss -24.76970 acc 0.66667 roc_auc 0.36150 prc_auc 0.56981[0m
[93maverage test of epoch 73: loss -24.83695 acc 0.65789 roc_auc 0.48000 prc_auc 0.64902[0m
[92maverage training of epoch 74: loss -25.06812 acc 0.66667 roc_auc 0.35730 prc_auc 0.56713[0m
[93maverage test of epoch 74: loss -25.13450 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 75: loss -25.36642 acc 0.66667 roc_auc 0.36180 prc_auc 0.57314[0m
[93maverage test of epoch 75: loss -25.43178 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 76: loss -25.66468 acc 0.66667 roc_auc 0.35890 prc_auc 0.57072[0m
[93maverage test of epoch 76: loss -25.72912 acc 0.65789 roc_auc 0.49385 prc_auc 0.65514[0m
[92maverage training of epoch 77: loss -25.96305 acc 0.66667 roc_auc 0.35840 prc_auc 0.56923[0m
[93maverage test of epoch 77: loss -26.02667 acc 0.65789 roc_auc 0.48000 prc_auc 0.64902[0m
[92maverage training of epoch 78: loss -26.26132 acc 0.66667 roc_auc 0.35880 prc_auc 0.56992[0m
[93maverage test of epoch 78: loss -26.32418 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 79: loss -26.55964 acc 0.66667 roc_auc 0.35810 prc_auc 0.57208[0m
[93maverage test of epoch 79: loss -26.62167 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 80: loss -26.85791 acc 0.66667 roc_auc 0.35740 prc_auc 0.57149[0m
[93maverage test of epoch 80: loss -26.91908 acc 0.65789 roc_auc 0.57692 prc_auc 0.69444[0m
[92maverage training of epoch 81: loss -27.15615 acc 0.66667 roc_auc 0.36270 prc_auc 0.57563[0m
[93maverage test of epoch 81: loss -27.21656 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 82: loss -27.45448 acc 0.66667 roc_auc 0.36440 prc_auc 0.57699[0m
[93maverage test of epoch 82: loss -27.51396 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 83: loss -27.75266 acc 0.66667 roc_auc 0.36440 prc_auc 0.57768[0m
[93maverage test of epoch 83: loss -27.81136 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 84: loss -28.05094 acc 0.66667 roc_auc 0.36680 prc_auc 0.58001[0m
[93maverage test of epoch 84: loss -28.10890 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 85: loss -28.34928 acc 0.66667 roc_auc 0.36210 prc_auc 0.57938[0m
[93maverage test of epoch 85: loss -28.40628 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 86: loss -28.64756 acc 0.66667 roc_auc 0.35720 prc_auc 0.57647[0m
[93maverage test of epoch 86: loss -28.70372 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 87: loss -28.94584 acc 0.66667 roc_auc 0.37240 prc_auc 0.58675[0m
[93maverage test of epoch 87: loss -29.00094 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 88: loss -29.24412 acc 0.66667 roc_auc 0.36260 prc_auc 0.58202[0m
[93maverage test of epoch 88: loss -29.29854 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 89: loss -29.54237 acc 0.66667 roc_auc 0.37010 prc_auc 0.58852[0m
[93maverage test of epoch 89: loss -29.59592 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -29.84061 acc 0.66667 roc_auc 0.36560 prc_auc 0.58759[0m
[93maverage test of epoch 90: loss -29.89329 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 91: loss -30.13889 acc 0.66667 roc_auc 0.35900 prc_auc 0.58870[0m
[93maverage test of epoch 91: loss -30.19077 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 92: loss -30.43720 acc 0.66667 roc_auc 0.35910 prc_auc 0.58910[0m
[93maverage test of epoch 92: loss -30.48823 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 93: loss -30.73549 acc 0.66667 roc_auc 0.36350 prc_auc 0.59348[0m
[93maverage test of epoch 93: loss -30.78564 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 94: loss -31.03370 acc 0.66667 roc_auc 0.38160 prc_auc 0.60338[0m
[93maverage test of epoch 94: loss -31.08306 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 95: loss -31.33199 acc 0.66667 roc_auc 0.36800 prc_auc 0.59713[0m
[93maverage test of epoch 95: loss -31.38042 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 96: loss -31.63026 acc 0.66667 roc_auc 0.36250 prc_auc 0.59631[0m
[93maverage test of epoch 96: loss -31.67777 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 97: loss -31.92857 acc 0.66667 roc_auc 0.37850 prc_auc 0.60437[0m
[93maverage test of epoch 97: loss -31.97510 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 98: loss -32.22672 acc 0.66667 roc_auc 0.37840 prc_auc 0.60514[0m
[93maverage test of epoch 98: loss -32.27265 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -32.52505 acc 0.66667 roc_auc 0.37510 prc_auc 0.61321[0m
[93maverage test of epoch 99: loss -32.57013 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.66921 acc 0.56667 roc_auc 0.46360 prc_auc 0.64505[0m
[93maverage test of epoch 0: loss -1.19355 acc 0.65789 roc_auc 0.51692 prc_auc 0.75686[0m
[92maverage training of epoch 1: loss -1.74258 acc 0.66667 roc_auc 0.47580 prc_auc 0.65379[0m
[93maverage test of epoch 1: loss -2.37886 acc 0.65789 roc_auc 0.40615 prc_auc 0.61993[0m
[92maverage training of epoch 2: loss -2.96112 acc 0.66667 roc_auc 0.46160 prc_auc 0.65680[0m
[93maverage test of epoch 2: loss -3.41677 acc 0.65789 roc_auc 0.49538 prc_auc 0.69968[0m
[92maverage training of epoch 3: loss -3.77217 acc 0.66667 roc_auc 0.44500 prc_auc 0.64538[0m
[93maverage test of epoch 3: loss -4.06833 acc 0.65789 roc_auc 0.59077 prc_auc 0.71238[0m
[92maverage training of epoch 4: loss -4.37440 acc 0.66667 roc_auc 0.44320 prc_auc 0.62449[0m
[93maverage test of epoch 4: loss -4.64268 acc 0.65789 roc_auc 0.39692 prc_auc 0.58564[0m
[92maverage training of epoch 5: loss -4.97542 acc 0.66667 roc_auc 0.44480 prc_auc 0.62727[0m
[93maverage test of epoch 5: loss -5.22191 acc 0.65789 roc_auc 0.60308 prc_auc 0.75428[0m
[92maverage training of epoch 6: loss -5.46663 acc 0.66667 roc_auc 0.45060 prc_auc 0.64049[0m
[93maverage test of epoch 6: loss -5.63988 acc 0.65789 roc_auc 0.39077 prc_auc 0.60285[0m
[92maverage training of epoch 7: loss -5.87119 acc 0.66667 roc_auc 0.51260 prc_auc 0.68195[0m
[93maverage test of epoch 7: loss -6.01833 acc 0.65789 roc_auc 0.57538 prc_auc 0.74869[0m
[92maverage training of epoch 8: loss -6.23507 acc 0.66667 roc_auc 0.43500 prc_auc 0.62352[0m
[93maverage test of epoch 8: loss -6.38078 acc 0.65789 roc_auc 0.52154 prc_auc 0.67448[0m
[92maverage training of epoch 9: loss -6.59073 acc 0.66667 roc_auc 0.45840 prc_auc 0.63223[0m
[93maverage test of epoch 9: loss -6.72248 acc 0.65789 roc_auc 0.81231 prc_auc 0.91482[0m
[92maverage training of epoch 10: loss -6.92563 acc 0.66667 roc_auc 0.40480 prc_auc 0.59660[0m
[93maverage test of epoch 10: loss -7.04744 acc 0.65789 roc_auc 0.44308 prc_auc 0.69439[0m
[92maverage training of epoch 11: loss -7.25550 acc 0.66667 roc_auc 0.42360 prc_auc 0.61293[0m
[93maverage test of epoch 11: loss -7.37610 acc 0.65789 roc_auc 0.32308 prc_auc 0.56949[0m
[92maverage training of epoch 12: loss -7.57843 acc 0.66667 roc_auc 0.45100 prc_auc 0.62684[0m
[93maverage test of epoch 12: loss -7.69384 acc 0.65789 roc_auc 0.48000 prc_auc 0.62978[0m
[92maverage training of epoch 13: loss -7.89625 acc 0.66667 roc_auc 0.42240 prc_auc 0.62173[0m
[93maverage test of epoch 13: loss -8.01279 acc 0.65789 roc_auc 0.58923 prc_auc 0.69122[0m
[92maverage training of epoch 14: loss -8.21338 acc 0.66667 roc_auc 0.45250 prc_auc 0.62801[0m
[93maverage test of epoch 14: loss -8.32614 acc 0.65789 roc_auc 0.48462 prc_auc 0.69145[0m
[92maverage training of epoch 15: loss -8.52763 acc 0.66667 roc_auc 0.42520 prc_auc 0.62872[0m
[93maverage test of epoch 15: loss -8.63557 acc 0.65789 roc_auc 0.46923 prc_auc 0.66786[0m
[92maverage training of epoch 16: loss -8.83667 acc 0.66667 roc_auc 0.44610 prc_auc 0.62891[0m
[93maverage test of epoch 16: loss -8.94835 acc 0.65789 roc_auc 0.64769 prc_auc 0.74986[0m
[92maverage training of epoch 17: loss -9.14733 acc 0.66667 roc_auc 0.42070 prc_auc 0.61683[0m
[93maverage test of epoch 17: loss -9.25504 acc 0.65789 roc_auc 0.55692 prc_auc 0.65460[0m
[92maverage training of epoch 18: loss -9.45380 acc 0.66667 roc_auc 0.43120 prc_auc 0.60511[0m
[93maverage test of epoch 18: loss -9.55858 acc 0.65789 roc_auc 0.45538 prc_auc 0.63849[0m
[92maverage training of epoch 19: loss -9.76094 acc 0.66667 roc_auc 0.43530 prc_auc 0.61506[0m
[93maverage test of epoch 19: loss -9.86713 acc 0.65789 roc_auc 0.50769 prc_auc 0.71544[0m
[92maverage training of epoch 20: loss -10.06506 acc 0.66667 roc_auc 0.42110 prc_auc 0.60091[0m
[93maverage test of epoch 20: loss -10.16808 acc 0.65789 roc_auc 0.64769 prc_auc 0.79341[0m
[92maverage training of epoch 21: loss -10.36967 acc 0.66667 roc_auc 0.43010 prc_auc 0.61309[0m
[93maverage test of epoch 21: loss -10.47101 acc 0.65789 roc_auc 0.48462 prc_auc 0.69211[0m
[92maverage training of epoch 22: loss -10.67320 acc 0.66667 roc_auc 0.43250 prc_auc 0.61455[0m
[93maverage test of epoch 22: loss -10.77327 acc 0.65789 roc_auc 0.55538 prc_auc 0.76832[0m
[92maverage training of epoch 23: loss -10.97652 acc 0.66667 roc_auc 0.43550 prc_auc 0.62214[0m
[93maverage test of epoch 23: loss -11.07442 acc 0.65789 roc_auc 0.40462 prc_auc 0.58939[0m
[92maverage training of epoch 24: loss -11.27780 acc 0.66667 roc_auc 0.42980 prc_auc 0.62528[0m
[93maverage test of epoch 24: loss -11.37667 acc 0.65789 roc_auc 0.38923 prc_auc 0.59814[0m
[92maverage training of epoch 25: loss -11.58111 acc 0.66667 roc_auc 0.43170 prc_auc 0.60618[0m
[93maverage test of epoch 25: loss -11.67667 acc 0.65789 roc_auc 0.41385 prc_auc 0.63379[0m
[92maverage training of epoch 26: loss -11.88204 acc 0.66667 roc_auc 0.43430 prc_auc 0.60884[0m
[93maverage test of epoch 26: loss -11.97769 acc 0.65789 roc_auc 0.41692 prc_auc 0.61281[0m
[92maverage training of epoch 27: loss -12.18215 acc 0.66667 roc_auc 0.41500 prc_auc 0.59799[0m
[93maverage test of epoch 27: loss -12.27827 acc 0.65789 roc_auc 0.57538 prc_auc 0.77541[0m
[92maverage training of epoch 28: loss -12.48353 acc 0.66667 roc_auc 0.42260 prc_auc 0.61544[0m
[93maverage test of epoch 28: loss -12.57768 acc 0.65789 roc_auc 0.45846 prc_auc 0.63683[0m
[92maverage training of epoch 29: loss -12.78441 acc 0.66667 roc_auc 0.42680 prc_auc 0.61417[0m
[93maverage test of epoch 29: loss -12.87645 acc 0.65789 roc_auc 0.37231 prc_auc 0.60268[0m
[92maverage training of epoch 30: loss -13.08476 acc 0.66667 roc_auc 0.42560 prc_auc 0.60376[0m
[93maverage test of epoch 30: loss -13.17735 acc 0.65789 roc_auc 0.38769 prc_auc 0.61576[0m
[92maverage training of epoch 31: loss -13.38455 acc 0.66667 roc_auc 0.41900 prc_auc 0.60573[0m
[93maverage test of epoch 31: loss -13.47583 acc 0.65789 roc_auc 0.55385 prc_auc 0.68134[0m
[92maverage training of epoch 32: loss -13.68379 acc 0.66667 roc_auc 0.43200 prc_auc 0.61905[0m
[93maverage test of epoch 32: loss -13.77428 acc 0.65789 roc_auc 0.63385 prc_auc 0.73734[0m
[92maverage training of epoch 33: loss -13.98366 acc 0.66667 roc_auc 0.42450 prc_auc 0.61002[0m
[93maverage test of epoch 33: loss -14.07251 acc 0.65789 roc_auc 0.60154 prc_auc 0.71402[0m
[92maverage training of epoch 34: loss -14.28277 acc 0.66667 roc_auc 0.41280 prc_auc 0.59833[0m
[93maverage test of epoch 34: loss -14.37141 acc 0.65789 roc_auc 0.55692 prc_auc 0.72193[0m
[92maverage training of epoch 35: loss -14.58207 acc 0.66667 roc_auc 0.43150 prc_auc 0.61349[0m
[93maverage test of epoch 35: loss -14.66857 acc 0.65789 roc_auc 0.47692 prc_auc 0.69191[0m
[92maverage training of epoch 36: loss -14.88133 acc 0.66667 roc_auc 0.42500 prc_auc 0.60833[0m
[93maverage test of epoch 36: loss -14.96792 acc 0.65789 roc_auc 0.45538 prc_auc 0.63407[0m
[92maverage training of epoch 37: loss -15.18056 acc 0.66667 roc_auc 0.41900 prc_auc 0.59427[0m
[93maverage test of epoch 37: loss -15.26656 acc 0.65789 roc_auc 0.40154 prc_auc 0.60367[0m
[92maverage training of epoch 38: loss -15.48039 acc 0.66667 roc_auc 0.42860 prc_auc 0.60471[0m
[93maverage test of epoch 38: loss -15.56436 acc 0.65789 roc_auc 0.42000 prc_auc 0.59850[0m
[92maverage training of epoch 39: loss -15.77871 acc 0.66667 roc_auc 0.41410 prc_auc 0.60027[0m
[93maverage test of epoch 39: loss -15.86227 acc 0.65789 roc_auc 0.51385 prc_auc 0.72460[0m
[92maverage training of epoch 40: loss -16.07742 acc 0.66667 roc_auc 0.42230 prc_auc 0.60255[0m
[93maverage test of epoch 40: loss -16.16124 acc 0.65789 roc_auc 0.64462 prc_auc 0.76451[0m
[92maverage training of epoch 41: loss -16.37643 acc 0.66667 roc_auc 0.42230 prc_auc 0.60753[0m
[93maverage test of epoch 41: loss -16.45844 acc 0.65789 roc_auc 0.39692 prc_auc 0.60242[0m
[92maverage training of epoch 42: loss -16.67542 acc 0.66667 roc_auc 0.42460 prc_auc 0.61200[0m
[93maverage test of epoch 42: loss -16.75656 acc 0.65789 roc_auc 0.52615 prc_auc 0.69526[0m
[92maverage training of epoch 43: loss -16.97395 acc 0.66667 roc_auc 0.42160 prc_auc 0.60888[0m
[93maverage test of epoch 43: loss -17.05445 acc 0.65789 roc_auc 0.60923 prc_auc 0.76655[0m
[92maverage training of epoch 44: loss -17.27242 acc 0.66667 roc_auc 0.41880 prc_auc 0.60290[0m
[93maverage test of epoch 44: loss -17.35216 acc 0.65789 roc_auc 0.64923 prc_auc 0.77544[0m
[92maverage training of epoch 45: loss -17.57118 acc 0.66667 roc_auc 0.42570 prc_auc 0.60254[0m
[93maverage test of epoch 45: loss -17.65038 acc 0.65789 roc_auc 0.42769 prc_auc 0.62300[0m
[92maverage training of epoch 46: loss -17.87001 acc 0.66667 roc_auc 0.42490 prc_auc 0.60513[0m
[93maverage test of epoch 46: loss -17.94816 acc 0.65789 roc_auc 0.64462 prc_auc 0.75491[0m
[92maverage training of epoch 47: loss -18.16867 acc 0.66667 roc_auc 0.42260 prc_auc 0.60766[0m
[93maverage test of epoch 47: loss -18.24556 acc 0.65789 roc_auc 0.52615 prc_auc 0.68016[0m
[92maverage training of epoch 48: loss -18.46740 acc 0.66667 roc_auc 0.41790 prc_auc 0.60112[0m
[93maverage test of epoch 48: loss -18.54298 acc 0.65789 roc_auc 0.37385 prc_auc 0.59732[0m
[92maverage training of epoch 49: loss -18.76572 acc 0.66667 roc_auc 0.42150 prc_auc 0.60687[0m
[93maverage test of epoch 49: loss -18.84145 acc 0.65789 roc_auc 0.50769 prc_auc 0.66199[0m
[92maverage training of epoch 50: loss -19.06436 acc 0.66667 roc_auc 0.41590 prc_auc 0.59848[0m
[93maverage test of epoch 50: loss -19.13833 acc 0.65789 roc_auc 0.54154 prc_auc 0.68170[0m
[92maverage training of epoch 51: loss -19.36274 acc 0.66667 roc_auc 0.41670 prc_auc 0.59769[0m
[93maverage test of epoch 51: loss -19.43629 acc 0.65789 roc_auc 0.54769 prc_auc 0.68458[0m
[92maverage training of epoch 52: loss -19.66113 acc 0.66667 roc_auc 0.42080 prc_auc 0.60184[0m
[93maverage test of epoch 52: loss -19.73383 acc 0.65789 roc_auc 0.56154 prc_auc 0.68686[0m
[92maverage training of epoch 53: loss -19.95955 acc 0.66667 roc_auc 0.41930 prc_auc 0.60191[0m
[93maverage test of epoch 53: loss -20.03097 acc 0.65789 roc_auc 0.60923 prc_auc 0.71411[0m
[92maverage training of epoch 54: loss -20.25806 acc 0.66667 roc_auc 0.41820 prc_auc 0.59848[0m
[93maverage test of epoch 54: loss -20.32870 acc 0.65789 roc_auc 0.49846 prc_auc 0.65758[0m
[92maverage training of epoch 55: loss -20.55644 acc 0.66667 roc_auc 0.41790 prc_auc 0.59680[0m
[93maverage test of epoch 55: loss -20.62655 acc 0.65789 roc_auc 0.58000 prc_auc 0.70183[0m
[92maverage training of epoch 56: loss -20.85505 acc 0.66667 roc_auc 0.41780 prc_auc 0.60374[0m
[93maverage test of epoch 56: loss -20.92405 acc 0.65789 roc_auc 0.43692 prc_auc 0.63111[0m
[92maverage training of epoch 57: loss -21.15333 acc 0.66667 roc_auc 0.42420 prc_auc 0.60725[0m
[93maverage test of epoch 57: loss -21.22166 acc 0.65789 roc_auc 0.54615 prc_auc 0.68045[0m
[92maverage training of epoch 58: loss -21.45169 acc 0.66667 roc_auc 0.41680 prc_auc 0.59867[0m
[93maverage test of epoch 58: loss -21.51910 acc 0.65789 roc_auc 0.51846 prc_auc 0.66632[0m
[92maverage training of epoch 59: loss -21.75021 acc 0.66667 roc_auc 0.41590 prc_auc 0.59714[0m
[93maverage test of epoch 59: loss -21.81679 acc 0.65789 roc_auc 0.48000 prc_auc 0.64902[0m
[92maverage training of epoch 60: loss -22.04853 acc 0.66667 roc_auc 0.41880 prc_auc 0.59957[0m
[93maverage test of epoch 60: loss -22.11429 acc 0.65789 roc_auc 0.51846 prc_auc 0.66632[0m
[92maverage training of epoch 61: loss -22.34693 acc 0.66667 roc_auc 0.41710 prc_auc 0.59857[0m
[93maverage test of epoch 61: loss -22.41177 acc 0.65789 roc_auc 0.55538 prc_auc 0.68395[0m
[92maverage training of epoch 62: loss -22.64536 acc 0.66667 roc_auc 0.41970 prc_auc 0.60439[0m
[93maverage test of epoch 62: loss -22.70925 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 63: loss -22.94355 acc 0.66667 roc_auc 0.42180 prc_auc 0.60359[0m
[93maverage test of epoch 63: loss -23.00663 acc 0.65789 roc_auc 0.61385 prc_auc 0.71388[0m
[92maverage training of epoch 64: loss -23.24202 acc 0.66667 roc_auc 0.42160 prc_auc 0.60602[0m
[93maverage test of epoch 64: loss -23.30430 acc 0.65789 roc_auc 0.48000 prc_auc 0.64902[0m
[92maverage training of epoch 65: loss -23.54033 acc 0.66667 roc_auc 0.42080 prc_auc 0.60329[0m
[93maverage test of epoch 65: loss -23.60179 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 66: loss -23.83871 acc 0.66667 roc_auc 0.42720 prc_auc 0.60968[0m
[93maverage test of epoch 66: loss -23.89915 acc 0.65789 roc_auc 0.49846 prc_auc 0.65720[0m
[92maverage training of epoch 67: loss -24.13708 acc 0.66667 roc_auc 0.42630 prc_auc 0.61147[0m
[93maverage test of epoch 67: loss -24.19665 acc 0.65789 roc_auc 0.49846 prc_auc 0.65720[0m
[92maverage training of epoch 68: loss -24.43540 acc 0.66667 roc_auc 0.41960 prc_auc 0.60499[0m
[93maverage test of epoch 68: loss -24.49414 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 69: loss -24.73368 acc 0.66667 roc_auc 0.42090 prc_auc 0.60724[0m
[93maverage test of epoch 69: loss -24.79164 acc 0.65789 roc_auc 0.53846 prc_auc 0.67568[0m
[92maverage training of epoch 70: loss -25.03206 acc 0.66667 roc_auc 0.42040 prc_auc 0.60627[0m
[93maverage test of epoch 70: loss -25.08923 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 71: loss -25.33026 acc 0.66667 roc_auc 0.42710 prc_auc 0.61013[0m
[93maverage test of epoch 71: loss -25.38675 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 72: loss -25.62867 acc 0.66667 roc_auc 0.42960 prc_auc 0.61256[0m
[93maverage test of epoch 72: loss -25.68393 acc 0.65789 roc_auc 0.52308 prc_auc 0.66917[0m
[92maverage training of epoch 73: loss -25.92702 acc 0.66667 roc_auc 0.42730 prc_auc 0.61314[0m
[93maverage test of epoch 73: loss -25.98156 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 74: loss -26.22529 acc 0.66667 roc_auc 0.42450 prc_auc 0.61038[0m
[93maverage test of epoch 74: loss -26.27899 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 75: loss -26.52365 acc 0.66667 roc_auc 0.42690 prc_auc 0.61481[0m
[93maverage test of epoch 75: loss -26.57657 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 76: loss -26.82185 acc 0.66667 roc_auc 0.42550 prc_auc 0.61282[0m
[93maverage test of epoch 76: loss -26.87398 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 77: loss -27.12025 acc 0.66667 roc_auc 0.42930 prc_auc 0.61723[0m
[93maverage test of epoch 77: loss -27.17140 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 78: loss -27.41856 acc 0.66667 roc_auc 0.43820 prc_auc 0.62126[0m
[93maverage test of epoch 78: loss -27.46889 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 79: loss -27.71685 acc 0.66667 roc_auc 0.44290 prc_auc 0.62869[0m
[93maverage test of epoch 79: loss -27.76631 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 80: loss -28.01511 acc 0.66667 roc_auc 0.42540 prc_auc 0.62142[0m
[93maverage test of epoch 80: loss -28.06372 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 81: loss -28.31343 acc 0.66667 roc_auc 0.42640 prc_auc 0.61865[0m
[93maverage test of epoch 81: loss -28.36111 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 82: loss -28.61172 acc 0.66667 roc_auc 0.44380 prc_auc 0.62888[0m
[93maverage test of epoch 82: loss -28.65861 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 83: loss -28.91002 acc 0.66667 roc_auc 0.43320 prc_auc 0.62368[0m
[93maverage test of epoch 83: loss -28.95605 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 84: loss -29.20837 acc 0.66667 roc_auc 0.42410 prc_auc 0.61822[0m
[93maverage test of epoch 84: loss -29.25360 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 85: loss -29.50665 acc 0.66667 roc_auc 0.44790 prc_auc 0.63553[0m
[93maverage test of epoch 85: loss -29.55097 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 86: loss -29.80490 acc 0.66667 roc_auc 0.44860 prc_auc 0.63544[0m
[93maverage test of epoch 86: loss -29.84834 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 87: loss -30.10323 acc 0.66667 roc_auc 0.42780 prc_auc 0.62308[0m
[93maverage test of epoch 87: loss -30.14596 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 88: loss -30.40150 acc 0.66667 roc_auc 0.44520 prc_auc 0.63472[0m
[93maverage test of epoch 88: loss -30.44334 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 89: loss -30.69980 acc 0.66667 roc_auc 0.43780 prc_auc 0.63297[0m
[93maverage test of epoch 89: loss -30.74063 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -30.99817 acc 0.66667 roc_auc 0.43270 prc_auc 0.63000[0m
[93maverage test of epoch 90: loss -31.03828 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 91: loss -31.29644 acc 0.66667 roc_auc 0.46100 prc_auc 0.64548[0m
[93maverage test of epoch 91: loss -31.33565 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 92: loss -31.59471 acc 0.66667 roc_auc 0.46850 prc_auc 0.65128[0m
[93maverage test of epoch 92: loss -31.63315 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 93: loss -31.89298 acc 0.66667 roc_auc 0.46660 prc_auc 0.65021[0m
[93maverage test of epoch 93: loss -31.93057 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 94: loss -32.19131 acc 0.66667 roc_auc 0.47420 prc_auc 0.65405[0m
[93maverage test of epoch 94: loss -32.22792 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 95: loss -32.48954 acc 0.66667 roc_auc 0.44680 prc_auc 0.64029[0m
[93maverage test of epoch 95: loss -32.52545 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 96: loss -32.78789 acc 0.66667 roc_auc 0.46000 prc_auc 0.64965[0m
[93maverage test of epoch 96: loss -32.82281 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 97: loss -33.08621 acc 0.66667 roc_auc 0.40620 prc_auc 0.62554[0m
[93maverage test of epoch 97: loss -33.12025 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 98: loss -33.38444 acc 0.66667 roc_auc 0.45500 prc_auc 0.64797[0m
[93maverage test of epoch 98: loss -33.41778 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -33.68276 acc 0.66667 roc_auc 0.47000 prc_auc 0.65379[0m
[93maverage test of epoch 99: loss -33.71511 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss 0.15156 acc 0.53333 roc_auc 0.45640 prc_auc 0.65575[0m
[93maverage test of epoch 0: loss -0.48632 acc 0.65789 roc_auc 0.45846 prc_auc 0.64225[0m
[92maverage training of epoch 1: loss -1.06765 acc 0.66667 roc_auc 0.47720 prc_auc 0.67251[0m
[93maverage test of epoch 1: loss -1.60584 acc 0.65789 roc_auc 0.72615 prc_auc 0.79864[0m
[92maverage training of epoch 2: loss -2.22287 acc 0.66667 roc_auc 0.42440 prc_auc 0.61457[0m
[93maverage test of epoch 2: loss -2.80494 acc 0.65789 roc_auc 0.34154 prc_auc 0.58668[0m
[92maverage training of epoch 3: loss -3.25214 acc 0.66667 roc_auc 0.41120 prc_auc 0.60860[0m
[93maverage test of epoch 3: loss -3.60201 acc 0.65789 roc_auc 0.45231 prc_auc 0.62479[0m
[92maverage training of epoch 4: loss -3.86870 acc 0.66667 roc_auc 0.40360 prc_auc 0.62023[0m
[93maverage test of epoch 4: loss -4.07968 acc 0.65789 roc_auc 0.55692 prc_auc 0.72003[0m
[92maverage training of epoch 5: loss -4.30540 acc 0.66667 roc_auc 0.51020 prc_auc 0.69921[0m
[93maverage test of epoch 5: loss -4.48441 acc 0.65789 roc_auc 0.65538 prc_auc 0.77521[0m
[92maverage training of epoch 6: loss -4.72331 acc 0.66667 roc_auc 0.47730 prc_auc 0.65356[0m
[93maverage test of epoch 6: loss -4.94045 acc 0.65789 roc_auc 0.61538 prc_auc 0.77087[0m
[92maverage training of epoch 7: loss -5.22479 acc 0.66667 roc_auc 0.42720 prc_auc 0.61925[0m
[93maverage test of epoch 7: loss -5.45678 acc 0.65789 roc_auc 0.39077 prc_auc 0.63953[0m
[92maverage training of epoch 8: loss -5.77215 acc 0.66667 roc_auc 0.43540 prc_auc 0.62008[0m
[93maverage test of epoch 8: loss -5.96984 acc 0.65789 roc_auc 0.39692 prc_auc 0.57632[0m
[92maverage training of epoch 9: loss -6.19459 acc 0.66667 roc_auc 0.46080 prc_auc 0.64937[0m
[93maverage test of epoch 9: loss -6.35590 acc 0.65789 roc_auc 0.52923 prc_auc 0.70263[0m
[92maverage training of epoch 10: loss -6.56287 acc 0.66667 roc_auc 0.42740 prc_auc 0.63721[0m
[93maverage test of epoch 10: loss -6.69838 acc 0.65789 roc_auc 0.53231 prc_auc 0.67340[0m
[92maverage training of epoch 11: loss -6.89148 acc 0.66667 roc_auc 0.45440 prc_auc 0.67218[0m
[93maverage test of epoch 11: loss -7.03238 acc 0.65789 roc_auc 0.52923 prc_auc 0.72664[0m
[92maverage training of epoch 12: loss -7.22036 acc 0.66667 roc_auc 0.54040 prc_auc 0.69497[0m
[93maverage test of epoch 12: loss -7.33084 acc 0.65789 roc_auc 0.48000 prc_auc 0.65625[0m
[92maverage training of epoch 13: loss -7.52522 acc 0.66667 roc_auc 0.41300 prc_auc 0.62267[0m
[93maverage test of epoch 13: loss -7.65110 acc 0.65789 roc_auc 0.65846 prc_auc 0.77539[0m
[92maverage training of epoch 14: loss -7.83541 acc 0.66667 roc_auc 0.48240 prc_auc 0.65969[0m
[93maverage test of epoch 14: loss -7.95057 acc 0.65789 roc_auc 0.42154 prc_auc 0.60082[0m
[92maverage training of epoch 15: loss -8.15086 acc 0.66667 roc_auc 0.48300 prc_auc 0.68036[0m
[93maverage test of epoch 15: loss -8.28507 acc 0.65789 roc_auc 0.45231 prc_auc 0.65437[0m
[92maverage training of epoch 16: loss -8.47485 acc 0.66667 roc_auc 0.52400 prc_auc 0.69155[0m
[93maverage test of epoch 16: loss -8.61520 acc 0.65789 roc_auc 0.66462 prc_auc 0.80899[0m
[92maverage training of epoch 17: loss -8.80315 acc 0.66667 roc_auc 0.49980 prc_auc 0.67692[0m
[93maverage test of epoch 17: loss -8.93990 acc 0.65789 roc_auc 0.59385 prc_auc 0.71461[0m
[92maverage training of epoch 18: loss -9.12865 acc 0.66667 roc_auc 0.38510 prc_auc 0.59963[0m
[93maverage test of epoch 18: loss -9.27611 acc 0.65789 roc_auc 0.53846 prc_auc 0.72378[0m
[92maverage training of epoch 19: loss -9.47304 acc 0.66667 roc_auc 0.43730 prc_auc 0.65546[0m
[93maverage test of epoch 19: loss -9.61386 acc 0.65789 roc_auc 0.56000 prc_auc 0.73884[0m
[92maverage training of epoch 20: loss -9.80791 acc 0.66667 roc_auc 0.48220 prc_auc 0.65635[0m
[93maverage test of epoch 20: loss -9.93751 acc 0.65789 roc_auc 0.53538 prc_auc 0.73851[0m
[92maverage training of epoch 21: loss -10.13788 acc 0.66667 roc_auc 0.41520 prc_auc 0.65131[0m
[93maverage test of epoch 21: loss -10.26087 acc 0.65789 roc_auc 0.48615 prc_auc 0.68072[0m
[92maverage training of epoch 22: loss -10.46023 acc 0.66667 roc_auc 0.44380 prc_auc 0.64512[0m
[93maverage test of epoch 22: loss -10.58675 acc 0.65789 roc_auc 0.48000 prc_auc 0.69643[0m
[92maverage training of epoch 23: loss -10.78188 acc 0.66667 roc_auc 0.38520 prc_auc 0.59223[0m
[93maverage test of epoch 23: loss -10.90795 acc 0.65789 roc_auc 0.57231 prc_auc 0.76822[0m
[92maverage training of epoch 24: loss -11.09984 acc 0.66667 roc_auc 0.42960 prc_auc 0.68629[0m
[93maverage test of epoch 24: loss -11.22045 acc 0.65789 roc_auc 0.59077 prc_auc 0.71913[0m
[92maverage training of epoch 25: loss -11.41155 acc 0.66667 roc_auc 0.37820 prc_auc 0.58296[0m
[93maverage test of epoch 25: loss -11.53151 acc 0.65789 roc_auc 0.33538 prc_auc 0.55240[0m
[92maverage training of epoch 26: loss -11.72485 acc 0.66667 roc_auc 0.39160 prc_auc 0.59189[0m
[93maverage test of epoch 26: loss -11.84362 acc 0.65789 roc_auc 0.50769 prc_auc 0.68335[0m
[92maverage training of epoch 27: loss -12.03510 acc 0.66667 roc_auc 0.37390 prc_auc 0.60358[0m
[93maverage test of epoch 27: loss -12.15374 acc 0.65789 roc_auc 0.47077 prc_auc 0.62212[0m
[92maverage training of epoch 28: loss -12.34303 acc 0.66667 roc_auc 0.36550 prc_auc 0.57020[0m
[93maverage test of epoch 28: loss -12.45557 acc 0.65789 roc_auc 0.47231 prc_auc 0.66535[0m
[92maverage training of epoch 29: loss -12.65031 acc 0.66667 roc_auc 0.39110 prc_auc 0.60305[0m
[93maverage test of epoch 29: loss -12.76199 acc 0.65789 roc_auc 0.44615 prc_auc 0.67197[0m
[92maverage training of epoch 30: loss -12.95562 acc 0.66667 roc_auc 0.38750 prc_auc 0.60342[0m
[93maverage test of epoch 30: loss -13.06784 acc 0.65789 roc_auc 0.53077 prc_auc 0.72406[0m
[92maverage training of epoch 31: loss -13.26092 acc 0.66667 roc_auc 0.39160 prc_auc 0.62142[0m
[93maverage test of epoch 31: loss -13.37142 acc 0.65789 roc_auc 0.44462 prc_auc 0.61424[0m
[92maverage training of epoch 32: loss -13.56521 acc 0.66667 roc_auc 0.36250 prc_auc 0.56224[0m
[93maverage test of epoch 32: loss -13.67219 acc 0.65789 roc_auc 0.50308 prc_auc 0.71308[0m
[92maverage training of epoch 33: loss -13.86738 acc 0.66667 roc_auc 0.38560 prc_auc 0.58183[0m
[93maverage test of epoch 33: loss -13.97630 acc 0.65789 roc_auc 0.34923 prc_auc 0.58176[0m
[92maverage training of epoch 34: loss -14.16966 acc 0.66667 roc_auc 0.37170 prc_auc 0.57242[0m
[93maverage test of epoch 34: loss -14.27779 acc 0.65789 roc_auc 0.50154 prc_auc 0.63673[0m
[92maverage training of epoch 35: loss -14.47294 acc 0.66667 roc_auc 0.37430 prc_auc 0.58385[0m
[93maverage test of epoch 35: loss -14.57657 acc 0.65789 roc_auc 0.33385 prc_auc 0.61551[0m
[92maverage training of epoch 36: loss -14.77519 acc 0.66667 roc_auc 0.37950 prc_auc 0.57874[0m
[93maverage test of epoch 36: loss -14.87758 acc 0.65789 roc_auc 0.51077 prc_auc 0.67004[0m
[92maverage training of epoch 37: loss -15.07551 acc 0.66667 roc_auc 0.37870 prc_auc 0.57862[0m
[93maverage test of epoch 37: loss -15.18138 acc 0.65789 roc_auc 0.71385 prc_auc 0.81532[0m
[92maverage training of epoch 38: loss -15.37705 acc 0.66667 roc_auc 0.38510 prc_auc 0.58510[0m
[93maverage test of epoch 38: loss -15.47774 acc 0.65789 roc_auc 0.66308 prc_auc 0.77835[0m
[92maverage training of epoch 39: loss -15.67656 acc 0.66667 roc_auc 0.38450 prc_auc 0.58365[0m
[93maverage test of epoch 39: loss -15.77879 acc 0.65789 roc_auc 0.37385 prc_auc 0.62634[0m
[92maverage training of epoch 40: loss -15.97676 acc 0.66667 roc_auc 0.38910 prc_auc 0.59396[0m
[93maverage test of epoch 40: loss -16.07697 acc 0.65789 roc_auc 0.43846 prc_auc 0.65577[0m
[92maverage training of epoch 41: loss -16.27694 acc 0.66667 roc_auc 0.38570 prc_auc 0.59611[0m
[93maverage test of epoch 41: loss -16.37640 acc 0.65789 roc_auc 0.46923 prc_auc 0.63996[0m
[92maverage training of epoch 42: loss -16.57729 acc 0.66667 roc_auc 0.37210 prc_auc 0.56922[0m
[93maverage test of epoch 42: loss -16.67401 acc 0.65789 roc_auc 0.67538 prc_auc 0.81345[0m
[92maverage training of epoch 43: loss -16.87684 acc 0.66667 roc_auc 0.38060 prc_auc 0.58665[0m
[93maverage test of epoch 43: loss -16.97416 acc 0.65789 roc_auc 0.44462 prc_auc 0.66510[0m
[92maverage training of epoch 44: loss -17.17650 acc 0.66667 roc_auc 0.38090 prc_auc 0.57891[0m
[93maverage test of epoch 44: loss -17.27264 acc 0.65789 roc_auc 0.44615 prc_auc 0.68182[0m
[92maverage training of epoch 45: loss -17.47583 acc 0.66667 roc_auc 0.38090 prc_auc 0.59000[0m
[93maverage test of epoch 45: loss -17.57133 acc 0.65789 roc_auc 0.44154 prc_auc 0.61052[0m
[92maverage training of epoch 46: loss -17.77490 acc 0.66667 roc_auc 0.38440 prc_auc 0.58514[0m
[93maverage test of epoch 46: loss -17.87018 acc 0.65789 roc_auc 0.48308 prc_auc 0.65731[0m
[92maverage training of epoch 47: loss -18.07395 acc 0.66667 roc_auc 0.37730 prc_auc 0.58098[0m
[93maverage test of epoch 47: loss -18.16783 acc 0.65789 roc_auc 0.47231 prc_auc 0.68294[0m
[92maverage training of epoch 48: loss -18.37307 acc 0.66667 roc_auc 0.37880 prc_auc 0.57455[0m
[93maverage test of epoch 48: loss -18.46598 acc 0.65789 roc_auc 0.47846 prc_auc 0.68420[0m
[92maverage training of epoch 49: loss -18.67289 acc 0.66667 roc_auc 0.37900 prc_auc 0.57549[0m
[93maverage test of epoch 49: loss -18.76412 acc 0.65789 roc_auc 0.47077 prc_auc 0.63327[0m
[92maverage training of epoch 50: loss -18.97113 acc 0.66667 roc_auc 0.38020 prc_auc 0.58303[0m
[93maverage test of epoch 50: loss -19.06218 acc 0.65789 roc_auc 0.63692 prc_auc 0.79867[0m
[92maverage training of epoch 51: loss -19.26976 acc 0.66667 roc_auc 0.37830 prc_auc 0.57401[0m
[93maverage test of epoch 51: loss -19.36025 acc 0.65789 roc_auc 0.43077 prc_auc 0.66937[0m
[92maverage training of epoch 52: loss -19.56891 acc 0.66667 roc_auc 0.37590 prc_auc 0.57572[0m
[93maverage test of epoch 52: loss -19.65749 acc 0.65789 roc_auc 0.65385 prc_auc 0.77098[0m
[92maverage training of epoch 53: loss -19.86796 acc 0.66667 roc_auc 0.37560 prc_auc 0.57378[0m
[93maverage test of epoch 53: loss -19.95623 acc 0.65789 roc_auc 0.44308 prc_auc 0.63708[0m
[92maverage training of epoch 54: loss -20.16639 acc 0.66667 roc_auc 0.37620 prc_auc 0.57386[0m
[93maverage test of epoch 54: loss -20.25395 acc 0.65789 roc_auc 0.42154 prc_auc 0.61769[0m
[92maverage training of epoch 55: loss -20.46504 acc 0.66667 roc_auc 0.37830 prc_auc 0.57429[0m
[93maverage test of epoch 55: loss -20.55164 acc 0.65789 roc_auc 0.47385 prc_auc 0.65031[0m
[92maverage training of epoch 56: loss -20.76371 acc 0.66667 roc_auc 0.37700 prc_auc 0.57557[0m
[93maverage test of epoch 56: loss -20.84937 acc 0.65789 roc_auc 0.40000 prc_auc 0.62529[0m
[92maverage training of epoch 57: loss -21.06222 acc 0.66667 roc_auc 0.37990 prc_auc 0.58195[0m
[93maverage test of epoch 57: loss -21.14747 acc 0.65789 roc_auc 0.59846 prc_auc 0.70931[0m
[92maverage training of epoch 58: loss -21.36074 acc 0.66667 roc_auc 0.37660 prc_auc 0.58054[0m
[93maverage test of epoch 58: loss -21.44495 acc 0.65789 roc_auc 0.62154 prc_auc 0.72222[0m
[92maverage training of epoch 59: loss -21.65920 acc 0.66667 roc_auc 0.37500 prc_auc 0.57185[0m
[93maverage test of epoch 59: loss -21.74242 acc 0.65789 roc_auc 0.53846 prc_auc 0.67820[0m
[92maverage training of epoch 60: loss -21.95764 acc 0.66667 roc_auc 0.38090 prc_auc 0.57543[0m
[93maverage test of epoch 60: loss -22.04039 acc 0.65789 roc_auc 0.56154 prc_auc 0.68688[0m
[92maverage training of epoch 61: loss -22.25644 acc 0.66667 roc_auc 0.37750 prc_auc 0.57949[0m
[93maverage test of epoch 61: loss -22.33756 acc 0.65789 roc_auc 0.47385 prc_auc 0.64608[0m
[92maverage training of epoch 62: loss -22.55480 acc 0.66667 roc_auc 0.37610 prc_auc 0.57432[0m
[93maverage test of epoch 62: loss -22.63553 acc 0.65789 roc_auc 0.44154 prc_auc 0.63317[0m
[92maverage training of epoch 63: loss -22.85325 acc 0.66667 roc_auc 0.37700 prc_auc 0.57765[0m
[93maverage test of epoch 63: loss -22.93325 acc 0.65789 roc_auc 0.44308 prc_auc 0.63289[0m
[92maverage training of epoch 64: loss -23.15157 acc 0.66667 roc_auc 0.37630 prc_auc 0.57784[0m
[93maverage test of epoch 64: loss -23.23064 acc 0.65789 roc_auc 0.48462 prc_auc 0.65337[0m
[92maverage training of epoch 65: loss -23.44999 acc 0.66667 roc_auc 0.37640 prc_auc 0.57478[0m
[93maverage test of epoch 65: loss -23.52815 acc 0.65789 roc_auc 0.50923 prc_auc 0.66254[0m
[92maverage training of epoch 66: loss -23.74845 acc 0.66667 roc_auc 0.37670 prc_auc 0.57554[0m
[93maverage test of epoch 66: loss -23.82549 acc 0.65789 roc_auc 0.61231 prc_auc 0.71354[0m
[92maverage training of epoch 67: loss -24.04692 acc 0.66667 roc_auc 0.37820 prc_auc 0.57556[0m
[93maverage test of epoch 67: loss -24.12330 acc 0.65789 roc_auc 0.56615 prc_auc 0.69384[0m
[92maverage training of epoch 68: loss -24.34491 acc 0.66667 roc_auc 0.38000 prc_auc 0.58365[0m
[93maverage test of epoch 68: loss -24.42044 acc 0.65789 roc_auc 0.51077 prc_auc 0.66343[0m
[92maverage training of epoch 69: loss -24.64348 acc 0.66667 roc_auc 0.37410 prc_auc 0.57339[0m
[93maverage test of epoch 69: loss -24.71839 acc 0.65789 roc_auc 0.49538 prc_auc 0.65583[0m
[92maverage training of epoch 70: loss -24.94179 acc 0.66667 roc_auc 0.37850 prc_auc 0.57856[0m
[93maverage test of epoch 70: loss -25.01550 acc 0.65789 roc_auc 0.55692 prc_auc 0.68460[0m
[92maverage training of epoch 71: loss -25.24011 acc 0.66667 roc_auc 0.38180 prc_auc 0.58062[0m
[93maverage test of epoch 71: loss -25.31342 acc 0.65789 roc_auc 0.63385 prc_auc 0.72450[0m
[92maverage training of epoch 72: loss -25.53838 acc 0.66667 roc_auc 0.37880 prc_auc 0.57843[0m
[93maverage test of epoch 72: loss -25.61094 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 73: loss -25.83686 acc 0.66667 roc_auc 0.37690 prc_auc 0.57643[0m
[93maverage test of epoch 73: loss -25.90824 acc 0.65789 roc_auc 0.58462 prc_auc 0.70243[0m
[92maverage training of epoch 74: loss -26.13522 acc 0.66667 roc_auc 0.37690 prc_auc 0.57958[0m
[93maverage test of epoch 74: loss -26.20563 acc 0.65789 roc_auc 0.41846 prc_auc 0.62370[0m
[92maverage training of epoch 75: loss -26.43350 acc 0.66667 roc_auc 0.37480 prc_auc 0.57792[0m
[93maverage test of epoch 75: loss -26.50298 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 76: loss -26.73178 acc 0.66667 roc_auc 0.38030 prc_auc 0.58252[0m
[93maverage test of epoch 76: loss -26.80043 acc 0.65789 roc_auc 0.53846 prc_auc 0.67568[0m
[92maverage training of epoch 77: loss -27.03010 acc 0.66667 roc_auc 0.37910 prc_auc 0.58227[0m
[93maverage test of epoch 77: loss -27.09780 acc 0.65789 roc_auc 0.53692 prc_auc 0.67498[0m
[92maverage training of epoch 78: loss -27.32839 acc 0.66667 roc_auc 0.38160 prc_auc 0.58748[0m
[93maverage test of epoch 78: loss -27.39542 acc 0.65789 roc_auc 0.59538 prc_auc 0.70396[0m
[92maverage training of epoch 79: loss -27.62664 acc 0.66667 roc_auc 0.37930 prc_auc 0.58515[0m
[93maverage test of epoch 79: loss -27.69274 acc 0.65789 roc_auc 0.46000 prc_auc 0.64004[0m
[92maverage training of epoch 80: loss -27.92490 acc 0.66667 roc_auc 0.37970 prc_auc 0.58367[0m
[93maverage test of epoch 80: loss -27.99043 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 81: loss -28.22332 acc 0.66667 roc_auc 0.38340 prc_auc 0.58966[0m
[93maverage test of epoch 81: loss -28.28784 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 82: loss -28.52155 acc 0.66667 roc_auc 0.36970 prc_auc 0.57814[0m
[93maverage test of epoch 82: loss -28.58521 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 83: loss -28.81986 acc 0.66667 roc_auc 0.37460 prc_auc 0.58061[0m
[93maverage test of epoch 83: loss -28.88265 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 84: loss -29.11813 acc 0.66667 roc_auc 0.37880 prc_auc 0.58269[0m
[93maverage test of epoch 84: loss -29.18008 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 85: loss -29.41643 acc 0.66667 roc_auc 0.37740 prc_auc 0.58425[0m
[93maverage test of epoch 85: loss -29.47747 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 86: loss -29.71473 acc 0.66667 roc_auc 0.38420 prc_auc 0.58728[0m
[93maverage test of epoch 86: loss -29.77487 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 87: loss -30.01301 acc 0.66667 roc_auc 0.38230 prc_auc 0.58740[0m
[93maverage test of epoch 87: loss -30.07238 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 88: loss -30.31125 acc 0.66667 roc_auc 0.38580 prc_auc 0.59011[0m
[93maverage test of epoch 88: loss -30.36977 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 89: loss -30.60953 acc 0.66667 roc_auc 0.38670 prc_auc 0.58937[0m
[93maverage test of epoch 89: loss -30.66700 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -30.90773 acc 0.66667 roc_auc 0.39130 prc_auc 0.59468[0m
[93maverage test of epoch 90: loss -30.96440 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 91: loss -31.20598 acc 0.66667 roc_auc 0.37390 prc_auc 0.58607[0m
[93maverage test of epoch 91: loss -31.26208 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 92: loss -31.50420 acc 0.66667 roc_auc 0.38510 prc_auc 0.59208[0m
[93maverage test of epoch 92: loss -31.55937 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 93: loss -31.80255 acc 0.66667 roc_auc 0.38520 prc_auc 0.59210[0m
[93maverage test of epoch 93: loss -31.85689 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 94: loss -32.10079 acc 0.66667 roc_auc 0.39090 prc_auc 0.59895[0m
[93maverage test of epoch 94: loss -32.15420 acc 0.65789 roc_auc 0.59538 prc_auc 0.70396[0m
[92maverage training of epoch 95: loss -32.39909 acc 0.66667 roc_auc 0.39200 prc_auc 0.59753[0m
[93maverage test of epoch 95: loss -32.45165 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 96: loss -32.69734 acc 0.66667 roc_auc 0.37840 prc_auc 0.59318[0m
[93maverage test of epoch 96: loss -32.74910 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 97: loss -32.99555 acc 0.66667 roc_auc 0.38810 prc_auc 0.59927[0m
[93maverage test of epoch 97: loss -33.04640 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 98: loss -33.29388 acc 0.66667 roc_auc 0.40070 prc_auc 0.60524[0m
[93maverage test of epoch 98: loss -33.34383 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -33.59212 acc 0.66667 roc_auc 0.39220 prc_auc 0.60441[0m
[93maverage test of epoch 99: loss -33.64100 acc 0.65789 roc_auc 0.43692 prc_auc 0.63111[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.21363 acc 0.33775 roc_auc 0.40431 prc_auc 0.62456[0m
[93maverage test of epoch 0: loss -0.46745 acc 0.35135 roc_auc 0.57000 prc_auc 0.76384[0m
[92maverage training of epoch 1: loss -0.65133 acc 0.56291 roc_auc 0.51275 prc_auc 0.70242[0m
[93maverage test of epoch 1: loss -0.86358 acc 0.64865 roc_auc 0.64000 prc_auc 0.82413[0m
[92maverage training of epoch 2: loss -1.02035 acc 0.66225 roc_auc 0.45765 prc_auc 0.64182[0m
[93maverage test of epoch 2: loss -1.37152 acc 0.67568 roc_auc 0.65333 prc_auc 0.79950[0m
[92maverage training of epoch 3: loss -1.55628 acc 0.66225 roc_auc 0.47373 prc_auc 0.65771[0m
[93maverage test of epoch 3: loss -1.84968 acc 0.67568 roc_auc 0.39000 prc_auc 0.66476[0m
[92maverage training of epoch 4: loss -2.06491 acc 0.66225 roc_auc 0.47745 prc_auc 0.65686[0m
[93maverage test of epoch 4: loss -2.36618 acc 0.67568 roc_auc 0.60333 prc_auc 0.78890[0m
[92maverage training of epoch 5: loss -2.53248 acc 0.66225 roc_auc 0.52843 prc_auc 0.69443[0m
[93maverage test of epoch 5: loss -2.81404 acc 0.67568 roc_auc 0.44333 prc_auc 0.73361[0m
[92maverage training of epoch 6: loss -2.97347 acc 0.66225 roc_auc 0.49275 prc_auc 0.66717[0m
[93maverage test of epoch 6: loss -3.33289 acc 0.67568 roc_auc 0.68000 prc_auc 0.83139[0m
[92maverage training of epoch 7: loss -3.48505 acc 0.66225 roc_auc 0.55725 prc_auc 0.71793[0m
[93maverage test of epoch 7: loss -3.85688 acc 0.67568 roc_auc 0.71000 prc_auc 0.85162[0m
[92maverage training of epoch 8: loss -4.02526 acc 0.66225 roc_auc 0.62039 prc_auc 0.78525[0m
[93maverage test of epoch 8: loss -4.37068 acc 0.67568 roc_auc 0.65000 prc_auc 0.82034[0m
[92maverage training of epoch 9: loss -4.50053 acc 0.66225 roc_auc 0.67314 prc_auc 0.77893[0m
[93maverage test of epoch 9: loss -4.77567 acc 0.67568 roc_auc 0.71667 prc_auc 0.87031[0m
[92maverage training of epoch 10: loss -4.89711 acc 0.66225 roc_auc 0.71882 prc_auc 0.82183[0m
[93maverage test of epoch 10: loss -5.20431 acc 0.67568 roc_auc 0.80667 prc_auc 0.86132[0m
[92maverage training of epoch 11: loss -5.28421 acc 0.66225 roc_auc 0.81078 prc_auc 0.85688[0m
[93maverage test of epoch 11: loss -5.58988 acc 0.67568 roc_auc 0.88667 prc_auc 0.94680[0m
[92maverage training of epoch 12: loss -5.69186 acc 0.66225 roc_auc 0.85569 prc_auc 0.91037[0m
[93maverage test of epoch 12: loss -5.96616 acc 0.67568 roc_auc 0.82667 prc_auc 0.88579[0m
[92maverage training of epoch 13: loss -6.14989 acc 0.68874 roc_auc 0.90598 prc_auc 0.95017[0m
[93maverage test of epoch 13: loss -6.37107 acc 0.72973 roc_auc 0.81333 prc_auc 0.87075[0m
[92maverage training of epoch 14: loss -6.49796 acc 0.76159 roc_auc 0.89549 prc_auc 0.93378[0m
[93maverage test of epoch 14: loss -6.63968 acc 0.70270 roc_auc 0.81500 prc_auc 0.88105[0m
[92maverage training of epoch 15: loss -6.86534 acc 0.78808 roc_auc 0.90843 prc_auc 0.94845[0m
[93maverage test of epoch 15: loss -7.07160 acc 0.72973 roc_auc 0.86000 prc_auc 0.89591[0m
[92maverage training of epoch 16: loss -7.15863 acc 0.80132 roc_auc 0.90549 prc_auc 0.94800[0m
[93maverage test of epoch 16: loss -7.33535 acc 0.75676 roc_auc 0.88000 prc_auc 0.94173[0m
[92maverage training of epoch 17: loss -7.49302 acc 0.82119 roc_auc 0.89333 prc_auc 0.92933[0m
[93maverage test of epoch 17: loss -7.72919 acc 0.78378 roc_auc 0.88167 prc_auc 0.93302[0m
[92maverage training of epoch 18: loss -7.79944 acc 0.82119 roc_auc 0.92745 prc_auc 0.96549[0m
[93maverage test of epoch 18: loss -7.92700 acc 0.75676 roc_auc 0.88333 prc_auc 0.94641[0m
[92maverage training of epoch 19: loss -8.11536 acc 0.82781 roc_auc 0.88794 prc_auc 0.93392[0m
[93maverage test of epoch 19: loss -8.26166 acc 0.78378 roc_auc 0.84667 prc_auc 0.90008[0m
[92maverage training of epoch 20: loss -8.40889 acc 0.82119 roc_auc 0.92480 prc_auc 0.95987[0m
[93maverage test of epoch 20: loss -8.54267 acc 0.75676 roc_auc 0.81333 prc_auc 0.87326[0m
[92maverage training of epoch 21: loss -8.70950 acc 0.83444 roc_auc 0.93745 prc_auc 0.96627[0m
[93maverage test of epoch 21: loss -8.84926 acc 0.78378 roc_auc 0.87333 prc_auc 0.93619[0m
[92maverage training of epoch 22: loss -8.93235 acc 0.82781 roc_auc 0.91412 prc_auc 0.95286[0m
[93maverage test of epoch 22: loss -9.12062 acc 0.78378 roc_auc 0.86667 prc_auc 0.93321[0m
[92maverage training of epoch 23: loss -9.19342 acc 0.81457 roc_auc 0.90412 prc_auc 0.94349[0m
[93maverage test of epoch 23: loss -9.38085 acc 0.75676 roc_auc 0.89667 prc_auc 0.95067[0m
[92maverage training of epoch 24: loss -9.47044 acc 0.83444 roc_auc 0.89676 prc_auc 0.94253[0m
[93maverage test of epoch 24: loss -9.63940 acc 0.75676 roc_auc 0.80500 prc_auc 0.86871[0m
[92maverage training of epoch 25: loss -9.76109 acc 0.82119 roc_auc 0.91824 prc_auc 0.94732[0m
[93maverage test of epoch 25: loss -9.93884 acc 0.78378 roc_auc 0.82667 prc_auc 0.90419[0m
[92maverage training of epoch 26: loss -10.05922 acc 0.83444 roc_auc 0.88775 prc_auc 0.92916[0m
[93maverage test of epoch 26: loss -10.12001 acc 0.75676 roc_auc 0.89833 prc_auc 0.95374[0m
[92maverage training of epoch 27: loss -10.38885 acc 0.86093 roc_auc 0.91853 prc_auc 0.95487[0m
[93maverage test of epoch 27: loss -10.50014 acc 0.75676 roc_auc 0.86333 prc_auc 0.92775[0m
[92maverage training of epoch 28: loss -10.64301 acc 0.85430 roc_auc 0.92618 prc_auc 0.96582[0m
[93maverage test of epoch 28: loss -10.76563 acc 0.81081 roc_auc 0.83667 prc_auc 0.85777[0m
[92maverage training of epoch 29: loss -10.95658 acc 0.84768 roc_auc 0.90794 prc_auc 0.94425[0m
[93maverage test of epoch 29: loss -10.96838 acc 0.78378 roc_auc 0.85667 prc_auc 0.90807[0m
[92maverage training of epoch 30: loss -11.19274 acc 0.86093 roc_auc 0.88814 prc_auc 0.91610[0m
[93maverage test of epoch 30: loss -11.36693 acc 0.81081 roc_auc 0.87833 prc_auc 0.94311[0m
[92maverage training of epoch 31: loss -11.51810 acc 0.86093 roc_auc 0.91912 prc_auc 0.95738[0m
[93maverage test of epoch 31: loss -11.61978 acc 0.81081 roc_auc 0.80167 prc_auc 0.85307[0m
[92maverage training of epoch 32: loss -11.72719 acc 0.84768 roc_auc 0.92471 prc_auc 0.95901[0m
[93maverage test of epoch 32: loss -11.91741 acc 0.81081 roc_auc 0.85667 prc_auc 0.91200[0m
[92maverage training of epoch 33: loss -12.02214 acc 0.84768 roc_auc 0.91824 prc_auc 0.95987[0m
[93maverage test of epoch 33: loss -12.15370 acc 0.81081 roc_auc 0.89500 prc_auc 0.92891[0m
[92maverage training of epoch 34: loss -12.41372 acc 0.86093 roc_auc 0.91775 prc_auc 0.95580[0m
[93maverage test of epoch 34: loss -12.47882 acc 0.78378 roc_auc 0.84500 prc_auc 0.88642[0m
[92maverage training of epoch 35: loss -12.66086 acc 0.88079 roc_auc 0.92892 prc_auc 0.95865[0m
[93maverage test of epoch 35: loss -12.74344 acc 0.78378 roc_auc 0.83833 prc_auc 0.88542[0m
[92maverage training of epoch 36: loss -13.00942 acc 0.87417 roc_auc 0.90922 prc_auc 0.94170[0m
[93maverage test of epoch 36: loss -13.04397 acc 0.81081 roc_auc 0.80667 prc_auc 0.85548[0mUsing backend: pytorch

[92maverage training of epoch 37: loss -13.29276 acc 0.86755 roc_auc 0.93225 prc_auc 0.95800[0m
[93maverage test of epoch 37: loss -13.28157 acc 0.75676 roc_auc 0.83167 prc_auc 0.86823[0m
[92maverage training of epoch 38: loss -13.43151 acc 0.84768 roc_auc 0.90637 prc_auc 0.94427[0m
[93maverage test of epoch 38: loss -13.57233 acc 0.81081 roc_auc 0.78500 prc_auc 0.83651[0m
[92maverage training of epoch 39: loss -13.74815 acc 0.88079 roc_auc 0.91343 prc_auc 0.93471[0m
[93maverage test of epoch 39: loss -13.90860 acc 0.83784 roc_auc 0.82333 prc_auc 0.87646[0m
[92maverage training of epoch 40: loss -14.08131 acc 0.88742 roc_auc 0.91176 prc_auc 0.94646[0m
[93maverage test of epoch 40: loss -14.13471 acc 0.81081 roc_auc 0.78167 prc_auc 0.82914[0m
[92maverage training of epoch 41: loss -14.33279 acc 0.86755 roc_auc 0.91980 prc_auc 0.94761[0m
[93maverage test of epoch 41: loss -14.45510 acc 0.83784 roc_auc 0.76667 prc_auc 0.82167[0m
[92maverage training of epoch 42: loss -14.52652 acc 0.86755 roc_auc 0.91363 prc_auc 0.95074[0m
[93maverage test of epoch 42: loss -14.68274 acc 0.83784 roc_auc 0.81667 prc_auc 0.87389[0m
[92maverage training of epoch 43: loss -14.90974 acc 0.87417 roc_auc 0.89412 prc_auc 0.91893[0m
[93maverage test of epoch 43: loss -14.94568 acc 0.83784 roc_auc 0.80500 prc_auc 0.85576[0m
[92maverage training of epoch 44: loss -15.19160 acc 0.88079 roc_auc 0.90784 prc_auc 0.93336[0m
[93maverage test of epoch 44: loss -15.15696 acc 0.81081 roc_auc 0.83667 prc_auc 0.88862[0m
[92maverage training of epoch 45: loss -15.46270 acc 0.87417 roc_auc 0.89480 prc_auc 0.92245[0m
[93maverage test of epoch 45: loss -15.40085 acc 0.78378 roc_auc 0.80833 prc_auc 0.85661[0m
[92maverage training of epoch 46: loss -15.77604 acc 0.88079 roc_auc 0.90343 prc_auc 0.93162[0m
[93maverage test of epoch 46: loss -15.69850 acc 0.81081 roc_auc 0.83000 prc_auc 0.87106[0m
[92maverage training of epoch 47: loss -15.93582 acc 0.88079 roc_auc 0.91559 prc_auc 0.94425[0m
[93maverage test of epoch 47: loss -16.02975 acc 0.81081 roc_auc 0.82000 prc_auc 0.86829[0m
[92maverage training of epoch 48: loss -16.37661 acc 0.88742 roc_auc 0.92343 prc_auc 0.95279[0m
[93maverage test of epoch 48: loss -16.23660 acc 0.83784 roc_auc 0.79167 prc_auc 0.85797[0m
[92maverage training of epoch 49: loss -16.65398 acc 0.88742 roc_auc 0.91627 prc_auc 0.94657[0m
[93maverage test of epoch 49: loss -16.57360 acc 0.81081 roc_auc 0.81667 prc_auc 0.86182[0m
[92maverage training of epoch 50: loss -16.88340 acc 0.90066 roc_auc 0.91314 prc_auc 0.94410[0m
[93maverage test of epoch 50: loss -16.71637 acc 0.83784 roc_auc 0.80167 prc_auc 0.85979[0m
[92maverage training of epoch 51: loss -17.17240 acc 0.88742 roc_auc 0.90608 prc_auc 0.93586[0m
[93maverage test of epoch 51: loss -17.16542 acc 0.81081 roc_auc 0.83833 prc_auc 0.87606[0m
[92maverage training of epoch 52: loss -17.43522 acc 0.89404 roc_auc 0.90882 prc_auc 0.93761[0m
[93maverage test of epoch 52: loss -17.40253 acc 0.83784 roc_auc 0.81167 prc_auc 0.86305[0m
[92maverage training of epoch 53: loss -17.81082 acc 0.90066 roc_auc 0.89422 prc_auc 0.92451[0m
[93maverage test of epoch 53: loss -17.49103 acc 0.78378 roc_auc 0.78667 prc_auc 0.83899[0m
[92maverage training of epoch 54: loss -18.07984 acc 0.88079 roc_auc 0.90588 prc_auc 0.93333[0m
[93maverage test of epoch 54: loss -17.89904 acc 0.81081 roc_auc 0.80500 prc_auc 0.85995[0m
[92maverage training of epoch 55: loss -18.26423 acc 0.88079 roc_auc 0.90755 prc_auc 0.93880[0m
[93maverage test of epoch 55: loss -18.22691 acc 0.83784 roc_auc 0.79833 prc_auc 0.85948[0m
[92maverage training of epoch 56: loss -18.63145 acc 0.90066 roc_auc 0.91627 prc_auc 0.94447[0m
[93maverage test of epoch 56: loss -18.53375 acc 0.83784 roc_auc 0.82167 prc_auc 0.86665[0m
[92maverage training of epoch 57: loss -18.86705 acc 0.88079 roc_auc 0.90765 prc_auc 0.93784[0m
[93maverage test of epoch 57: loss -18.90356 acc 0.83784 roc_auc 0.82500 prc_auc 0.86704[0m
[92maverage training of epoch 58: loss -19.02527 acc 0.87417 roc_auc 0.90157 prc_auc 0.93158[0m
[93maverage test of epoch 58: loss -19.09397 acc 0.83784 roc_auc 0.82167 prc_auc 0.87151[0m
[92maverage training of epoch 59: loss -19.45163 acc 0.88742 roc_auc 0.90304 prc_auc 0.93706[0m
[93maverage test of epoch 59: loss -19.33765 acc 0.83784 roc_auc 0.80333 prc_auc 0.85592[0m
[92maverage training of epoch 60: loss -19.68771 acc 0.88079 roc_auc 0.90167 prc_auc 0.93097[0m
[93maverage test of epoch 60: loss -19.35084 acc 0.81081 roc_auc 0.81667 prc_auc 0.86322[0m
[92maverage training of epoch 61: loss -19.99376 acc 0.90066 roc_auc 0.91186 prc_auc 0.94693[0m
[93maverage test of epoch 61: loss -19.68775 acc 0.83784 roc_auc 0.80500 prc_auc 0.86091[0m
[92maverage training of epoch 62: loss -20.27642 acc 0.89404 roc_auc 0.90814 prc_auc 0.94048[0m
[93maverage test of epoch 62: loss -20.13523 acc 0.83784 roc_auc 0.81333 prc_auc 0.86681[0m
[92maverage training of epoch 63: loss -20.45061 acc 0.88742 roc_auc 0.89529 prc_auc 0.92837[0m
[93maverage test of epoch 63: loss -20.46164 acc 0.83784 roc_auc 0.80333 prc_auc 0.84711[0m
[92maverage training of epoch 64: loss -20.89423 acc 0.89404 roc_auc 0.89118 prc_auc 0.92315[0m
[93maverage test of epoch 64: loss -20.74100 acc 0.83784 roc_auc 0.80833 prc_auc 0.86830[0m
[92maverage training of epoch 65: loss -20.99619 acc 0.88742 roc_auc 0.90569 prc_auc 0.93880[0m
[93maverage test of epoch 65: loss -20.67641 acc 0.81081 roc_auc 0.79667 prc_auc 0.86171[0m
[92maverage training of epoch 66: loss -21.56236 acc 0.91391 roc_auc 0.89510 prc_auc 0.92808[0m
[93maverage test of epoch 66: loss -21.02225 acc 0.83784 roc_auc 0.81667 prc_auc 0.86722[0m
[92maverage training of epoch 67: loss -21.77679 acc 0.88742 roc_auc 0.91578 prc_auc 0.94873[0m
[93maverage test of epoch 67: loss -21.55005 acc 0.83784 roc_auc 0.83500 prc_auc 0.87217[0m
[92maverage training of epoch 68: loss -21.94760 acc 0.90728 roc_auc 0.90088 prc_auc 0.93229[0m
[93maverage test of epoch 68: loss -21.74625 acc 0.86486 roc_auc 0.83333 prc_auc 0.87209[0m
[92maverage training of epoch 69: loss -22.10431 acc 0.88079 roc_auc 0.88059 prc_auc 0.91318[0m
[93maverage test of epoch 69: loss -22.11278 acc 0.83784 roc_auc 0.79000 prc_auc 0.84312[0m
[92maverage training of epoch 70: loss -22.70645 acc 0.92053 roc_auc 0.90078 prc_auc 0.92717[0m
[93maverage test of epoch 70: loss -22.37598 acc 0.83784 roc_auc 0.79000 prc_auc 0.84312[0m
[92maverage training of epoch 71: loss -22.73602 acc 0.89404 roc_auc 0.87627 prc_auc 0.90651[0m
[93maverage test of epoch 71: loss -22.60335 acc 0.81081 roc_auc 0.79667 prc_auc 0.84512[0m
[92maverage training of epoch 72: loss -23.15782 acc 0.90728 roc_auc 0.89235 prc_auc 0.92435[0m
[93maverage test of epoch 72: loss -22.59424 acc 0.83784 roc_auc 0.79333 prc_auc 0.84155[0m
[92maverage training of epoch 73: loss -23.42363 acc 0.91391 roc_auc 0.90608 prc_auc 0.93442[0m
[93maverage test of epoch 73: loss -23.03410 acc 0.83784 roc_auc 0.77667 prc_auc 0.83635[0m
[92maverage training of epoch 74: loss -23.69729 acc 0.90066 roc_auc 0.88373 prc_auc 0.91542[0m
[93maverage test of epoch 74: loss -23.42609 acc 0.83784 roc_auc 0.78667 prc_auc 0.83957[0m
[92maverage training of epoch 75: loss -23.88933 acc 0.90066 roc_auc 0.89275 prc_auc 0.92376[0m
[93maverage test of epoch 75: loss -23.76421 acc 0.83784 roc_auc 0.77667 prc_auc 0.83982[0m
[92maverage training of epoch 76: loss -24.05142 acc 0.88079 roc_auc 0.88118 prc_auc 0.91291[0m
[93maverage test of epoch 76: loss -24.02019 acc 0.83784 roc_auc 0.79333 prc_auc 0.84428[0m
[92maverage training of epoch 77: loss -24.63317 acc 0.91391 roc_auc 0.88686 prc_auc 0.91725[0m
[93maverage test of epoch 77: loss -24.03529 acc 0.83784 roc_auc 0.81000 prc_auc 0.84631[0m
[92maverage training of epoch 78: loss -24.72815 acc 0.89404 roc_auc 0.87392 prc_auc 0.90615[0m
[93maverage test of epoch 78: loss -24.57073 acc 0.83784 roc_auc 0.78667 prc_auc 0.84221[0m
[92maverage training of epoch 79: loss -25.05311 acc 0.91391 roc_auc 0.90265 prc_auc 0.93289[0m
[93maverage test of epoch 79: loss -24.85080 acc 0.83784 roc_auc 0.78667 prc_auc 0.84221[0m
[92maverage training of epoch 80: loss -25.47159 acc 0.90728 roc_auc 0.89441 prc_auc 0.92547[0m
[93maverage test of epoch 80: loss -24.93646 acc 0.83784 roc_auc 0.82333 prc_auc 0.86878[0m
[92maverage training of epoch 81: loss -25.66144 acc 0.90066 roc_auc 0.89314 prc_auc 0.92418[0m
[93maverage test of epoch 81: loss -25.58699 acc 0.86486 roc_auc 0.85833 prc_auc 0.88274[0m
[92maverage training of epoch 82: loss -26.13390 acc 0.92715 roc_auc 0.90314 prc_auc 0.93429[0m
[93maverage test of epoch 82: loss -25.64255 acc 0.83784 roc_auc 0.79333 prc_auc 0.84408[0m
[92maverage training of epoch 83: loss -26.06531 acc 0.89404 roc_auc 0.89098 prc_auc 0.92306[0m
[93maverage test of epoch 83: loss -25.95502 acc 0.83784 roc_auc 0.81333 prc_auc 0.85014[0m
[92maverage training of epoch 84: loss -26.54955 acc 0.91391 roc_auc 0.89676 prc_auc 0.93166[0m
[93maverage test of epoch 84: loss -25.82865 acc 0.81081 roc_auc 0.77667 prc_auc 0.83635[0m
[92maverage training of epoch 85: loss -26.91441 acc 0.91391 roc_auc 0.89725 prc_auc 0.92645[0m
[93maverage test of epoch 85: loss -25.97542 acc 0.81081 roc_auc 0.78333 prc_auc 0.83804[0m
[92maverage training of epoch 86: loss -27.06649 acc 0.90728 roc_auc 0.89343 prc_auc 0.92482[0m
[93maverage test of epoch 86: loss -26.40626 acc 0.83784 roc_auc 0.77667 prc_auc 0.83647[0m
[92maverage training of epoch 87: loss -27.49324 acc 0.92053 roc_auc 0.90333 prc_auc 0.93426[0m
[93maverage test of epoch 87: loss -26.65939 acc 0.81081 roc_auc 0.78000 prc_auc 0.83772[0m
[92maverage training of epoch 88: loss -27.72805 acc 0.92053 roc_auc 0.90363 prc_auc 0.93408[0m
[93maverage test of epoch 88: loss -26.81764 acc 0.78378 roc_auc 0.73000 prc_auc 0.80557[0m
[92maverage training of epoch 89: loss -27.95225 acc 0.90728 roc_auc 0.87373 prc_auc 0.90755[0m
[93maverage test of epoch 89: loss -27.58382 acc 0.83784 roc_auc 0.79667 prc_auc 0.84512[0m
[92maverage training of epoch 90: loss -28.33390 acc 0.91391 roc_auc 0.90098 prc_auc 0.92762[0m
[93maverage test of epoch 90: loss -27.49664 acc 0.83784 roc_auc 0.79000 prc_auc 0.83996[0m
[92maverage training of epoch 91: loss -28.42671 acc 0.90728 roc_auc 0.89549 prc_auc 0.92513[0m
[93maverage test of epoch 91: loss -28.14351 acc 0.83784 roc_auc 0.79667 prc_auc 0.84512[0m
[92maverage training of epoch 92: loss -28.76253 acc 0.90728 roc_auc 0.87431 prc_auc 0.90715[0m
[93maverage test of epoch 92: loss -28.42855 acc 0.83784 roc_auc 0.78333 prc_auc 0.84137[0m
[92maverage training of epoch 93: loss -29.07382 acc 0.90728 roc_auc 0.88608 prc_auc 0.91705[0m
[93maverage test of epoch 93: loss -28.85597 acc 0.86486 roc_auc 0.85833 prc_auc 0.88261[0m
[92maverage training of epoch 94: loss -29.45761 acc 0.92053 roc_auc 0.89549 prc_auc 0.92585[0m
[93maverage test of epoch 94: loss -28.85262 acc 0.83784 roc_auc 0.78333 prc_auc 0.83847[0m
[92maverage training of epoch 95: loss -29.67337 acc 0.91391 roc_auc 0.88627 prc_auc 0.91715[0m
[93maverage test of epoch 95: loss -28.82040 acc 0.81081 roc_auc 0.77000 prc_auc 0.83470[0m
[92maverage training of epoch 96: loss -29.97285 acc 0.92053 roc_auc 0.89196 prc_auc 0.92450[0m
[93maverage test of epoch 96: loss -29.33120 acc 0.83784 roc_auc 0.80667 prc_auc 0.86505[0m
[92maverage training of epoch 97: loss -30.36250 acc 0.92715 roc_auc 0.90667 prc_auc 0.93529[0m
[93maverage test of epoch 97: loss -30.03430 acc 0.86486 roc_auc 0.83500 prc_auc 0.87512[0m
[92maverage training of epoch 98: loss -30.39197 acc 0.89404 roc_auc 0.88422 prc_auc 0.91603[0m
[93maverage test of epoch 98: loss -29.40766 acc 0.78378 roc_auc 0.74000 prc_auc 0.80864[0m
[92maverage training of epoch 99: loss -30.84485 acc 0.91391 roc_auc 0.89667 prc_auc 0.92623[0m
[93maverage test of epoch 99: loss -30.07926 acc 0.83784 roc_auc 0.81667 prc_auc 0.86778[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.06058 acc 0.56291 roc_auc 0.37980 prc_auc 0.58710[0m
[93maverage test of epoch 0: loss -0.81040 acc 0.67568 roc_auc 0.56000 prc_auc 0.75326[0m
[92maverage training of epoch 1: loss -1.18172 acc 0.66225 roc_auc 0.42412 prc_auc 0.62382[0m
[93maverage test of epoch 1: loss -1.53994 acc 0.67568 roc_auc 0.54667 prc_auc 0.74152[0m
[92maverage training of epoch 2: loss -1.80307 acc 0.66225 roc_auc 0.40588 prc_auc 0.62272[0m
[93maverage test of epoch 2: loss -2.09503 acc 0.67568 roc_auc 0.56667 prc_auc 0.73201[0m
[92maverage training of epoch 3: loss -2.37311 acc 0.66225 roc_auc 0.42157 prc_auc 0.63628[0m
[93maverage test of epoch 3: loss -2.68569 acc 0.67568 roc_auc 0.33333 prc_auc 0.61653[0m
[92maverage training of epoch 4: loss -2.92018 acc 0.66225 roc_auc 0.40902 prc_auc 0.60193[0m
[93maverage test of epoch 4: loss -3.21966 acc 0.67568 roc_auc 0.53667 prc_auc 0.76771[0m
[92maverage training of epoch 5: loss -3.43371 acc 0.66225 roc_auc 0.42275 prc_auc 0.63386[0m
[93maverage test of epoch 5: loss -3.73837 acc 0.67568 roc_auc 0.59667 prc_auc 0.74047[0m
[92maverage training of epoch 6: loss -3.94837 acc 0.66225 roc_auc 0.38020 prc_auc 0.59307[0m
[93maverage test of epoch 6: loss -4.27389 acc 0.67568 roc_auc 0.62333 prc_auc 0.77232[0m
[92maverage training of epoch 7: loss -4.46477 acc 0.66225 roc_auc 0.43118 prc_auc 0.62468[0m
[93maverage test of epoch 7: loss -4.74729 acc 0.67568 roc_auc 0.32667 prc_auc 0.57468[0m
[92maverage training of epoch 8: loss -4.92122 acc 0.66225 roc_auc 0.38941 prc_auc 0.60038[0m
[93maverage test of epoch 8: loss -5.18690 acc 0.67568 roc_auc 0.44000 prc_auc 0.68364[0m
[92maverage training of epoch 9: loss -5.33866 acc 0.66225 roc_auc 0.40588 prc_auc 0.60798[0m
[93maverage test of epoch 9: loss -5.58731 acc 0.67568 roc_auc 0.44333 prc_auc 0.68044[0m
[92maverage training of epoch 10: loss -5.71595 acc 0.66225 roc_auc 0.44431 prc_auc 0.63472[0m
[93maverage test of epoch 10: loss -5.96938 acc 0.67568 roc_auc 0.74833 prc_auc 0.82477[0m
[92maverage training of epoch 11: loss -6.08687 acc 0.66225 roc_auc 0.39216 prc_auc 0.59275[0m
[93maverage test of epoch 11: loss -6.33038 acc 0.67568 roc_auc 0.71333 prc_auc 0.82516[0m
[92maverage training of epoch 12: loss -6.43661 acc 0.66225 roc_auc 0.39480 prc_auc 0.59633[0m
[93maverage test of epoch 12: loss -6.67393 acc 0.67568 roc_auc 0.67667 prc_auc 0.79217[0m
[92maverage training of epoch 13: loss -6.78027 acc 0.66225 roc_auc 0.36529 prc_auc 0.56989[0m
[93maverage test of epoch 13: loss -7.01387 acc 0.67568 roc_auc 0.61333 prc_auc 0.83707[0m
[92maverage training of epoch 14: loss -7.11294 acc 0.66225 roc_auc 0.37225 prc_auc 0.57260[0m
[93maverage test of epoch 14: loss -7.34571 acc 0.67568 roc_auc 0.52667 prc_auc 0.76085[0m
[92maverage training of epoch 15: loss -7.44636 acc 0.66225 roc_auc 0.41686 prc_auc 0.60013[0m
[93maverage test of epoch 15: loss -7.67431 acc 0.67568 roc_auc 0.45833 prc_auc 0.69239[0m
[92maverage training of epoch 16: loss -7.76858 acc 0.66225 roc_auc 0.37324 prc_auc 0.57185[0m
[93maverage test of epoch 16: loss -7.99304 acc 0.67568 roc_auc 0.47667 prc_auc 0.65630[0m
[92maverage training of epoch 17: loss -8.08245 acc 0.66225 roc_auc 0.38167 prc_auc 0.57716[0m
[93maverage test of epoch 17: loss -8.31064 acc 0.67568 roc_auc 0.39500 prc_auc 0.70375[0m
[92maverage training of epoch 18: loss -8.40474 acc 0.66225 roc_auc 0.35010 prc_auc 0.55149[0m
[93maverage test of epoch 18: loss -8.63095 acc 0.67568 roc_auc 0.58833 prc_auc 0.74237[0m
[92maverage training of epoch 19: loss -8.71956 acc 0.66225 roc_auc 0.36539 prc_auc 0.56656[0m
[93maverage test of epoch 19: loss -8.94599 acc 0.67568 roc_auc 0.58000 prc_auc 0.77915[0m
[92maverage training of epoch 20: loss -9.02935 acc 0.66225 roc_auc 0.38078 prc_auc 0.57214[0m
[93maverage test of epoch 20: loss -9.25832 acc 0.67568 roc_auc 0.48000 prc_auc 0.63400[0m
[92maverage training of epoch 21: loss -9.34141 acc 0.66225 roc_auc 0.35039 prc_auc 0.57415[0m
[93maverage test of epoch 21: loss -9.57084 acc 0.67568 roc_auc 0.52000 prc_auc 0.73119[0m
[92maverage training of epoch 22: loss -9.65053 acc 0.66225 roc_auc 0.37304 prc_auc 0.58103[0m
[93maverage test of epoch 22: loss -9.87898 acc 0.67568 roc_auc 0.31500 prc_auc 0.59822[0m
[92maverage training of epoch 23: loss -9.95956 acc 0.66225 roc_auc 0.38147 prc_auc 0.58338[0m
[93maverage test of epoch 23: loss -10.18760 acc 0.67568 roc_auc 0.49667 prc_auc 0.68791[0m
[92maverage training of epoch 24: loss -10.26584 acc 0.66225 roc_auc 0.37961 prc_auc 0.57528[0m
[93maverage test of epoch 24: loss -10.49778 acc 0.67568 roc_auc 0.40500 prc_auc 0.67267[0m
[92maverage training of epoch 25: loss -10.57193 acc 0.66225 roc_auc 0.37196 prc_auc 0.59083[0m
[93maverage test of epoch 25: loss -10.80422 acc 0.67568 roc_auc 0.51833 prc_auc 0.69521[0m
[92maverage training of epoch 26: loss -10.87447 acc 0.66225 roc_auc 0.35382 prc_auc 0.55922[0m
[93maverage test of epoch 26: loss -11.11086 acc 0.67568 roc_auc 0.69167 prc_auc 0.82272[0m
[92maverage training of epoch 27: loss -11.18060 acc 0.66225 roc_auc 0.37245 prc_auc 0.57725[0m
[93maverage test of epoch 27: loss -11.41341 acc 0.67568 roc_auc 0.59167 prc_auc 0.79120[0m
[92maverage training of epoch 28: loss -11.48432 acc 0.66225 roc_auc 0.35118 prc_auc 0.55904[0m
[93maverage test of epoch 28: loss -11.71765 acc 0.67568 roc_auc 0.50500 prc_auc 0.71708[0m
[92maverage training of epoch 29: loss -11.78753 acc 0.66225 roc_auc 0.37108 prc_auc 0.56689[0m
[93maverage test of epoch 29: loss -12.02460 acc 0.67568 roc_auc 0.34167 prc_auc 0.59481[0m
[92maverage training of epoch 30: loss -12.09078 acc 0.66225 roc_auc 0.36745 prc_auc 0.57157[0m
[93maverage test of epoch 30: loss -12.32909 acc 0.67568 roc_auc 0.67000 prc_auc 0.75335[0m
[92maverage training of epoch 31: loss -12.39261 acc 0.66225 roc_auc 0.35716 prc_auc 0.56116[0m
[93maverage test of epoch 31: loss -12.63025 acc 0.67568 roc_auc 0.51000 prc_auc 0.70702[0m
[92maverage training of epoch 32: loss -12.69542 acc 0.66225 roc_auc 0.36529 prc_auc 0.57157[0m
[93maverage test of epoch 32: loss -12.93574 acc 0.67568 roc_auc 0.56667 prc_auc 0.75388[0m
[92maverage training of epoch 33: loss -12.99737 acc 0.66225 roc_auc 0.38147 prc_auc 0.57680[0m
[93maverage test of epoch 33: loss -13.23770 acc 0.67568 roc_auc 0.44333 prc_auc 0.62866[0m
[92maverage training of epoch 34: loss -13.29923 acc 0.66225 roc_auc 0.36725 prc_auc 0.56880[0m
[93maverage test of epoch 34: loss -13.54103 acc 0.67568 roc_auc 0.74000 prc_auc 0.84060[0m
[92maverage training of epoch 35: loss -13.60064 acc 0.66225 roc_auc 0.36157 prc_auc 0.56594[0m
[93maverage test of epoch 35: loss -13.84220 acc 0.67568 roc_auc 0.62167 prc_auc 0.75862[0m
[92maverage training of epoch 36: loss -13.90188 acc 0.66225 roc_auc 0.37441 prc_auc 0.57006[0m
[93maverage test of epoch 36: loss -14.14531 acc 0.67568 roc_auc 0.42667 prc_auc 0.64205[0m
[92maverage training of epoch 37: loss -14.20286 acc 0.66225 roc_auc 0.36451 prc_auc 0.56514[0m
[93maverage test of epoch 37: loss -14.44761 acc 0.67568 roc_auc 0.43667 prc_auc 0.67219[0m
[92maverage training of epoch 38: loss -14.50407 acc 0.66225 roc_auc 0.37324 prc_auc 0.57351[0m
[93maverage test of epoch 38: loss -14.75052 acc 0.67568 roc_auc 0.57167 prc_auc 0.70142[0m
[92maverage training of epoch 39: loss -14.80383 acc 0.66225 roc_auc 0.36608 prc_auc 0.57589[0m
[93maverage test of epoch 39: loss -15.05142 acc 0.67568 roc_auc 0.42333 prc_auc 0.61552[0m
[92maverage training of epoch 40: loss -15.10519 acc 0.66225 roc_auc 0.37029 prc_auc 0.57206[0m
[93maverage test of epoch 40: loss -15.35346 acc 0.67568 roc_auc 0.41667 prc_auc 0.60658[0m
[92maverage training of epoch 41: loss -15.40568 acc 0.66225 roc_auc 0.37569 prc_auc 0.57211[0m
[93maverage test of epoch 41: loss -15.65499 acc 0.67568 roc_auc 0.50167 prc_auc 0.67973[0m
[92maverage training of epoch 42: loss -15.70602 acc 0.66225 roc_auc 0.36696 prc_auc 0.56734[0m
[93maverage test of epoch 42: loss -15.95685 acc 0.67568 roc_auc 0.44667 prc_auc 0.65745[0m
[92maverage training of epoch 43: loss -16.00613 acc 0.66225 roc_auc 0.36588 prc_auc 0.57610[0m
[93maverage test of epoch 43: loss -16.25825 acc 0.67568 roc_auc 0.41833 prc_auc 0.63383[0m
[92maverage training of epoch 44: loss -16.30638 acc 0.66225 roc_auc 0.37657 prc_auc 0.57659[0m
[93maverage test of epoch 44: loss -16.55945 acc 0.67568 roc_auc 0.29833 prc_auc 0.60005[0m
[92maverage training of epoch 45: loss -16.60659 acc 0.66225 roc_auc 0.36843 prc_auc 0.56958[0m
[93maverage test of epoch 45: loss -16.86117 acc 0.67568 roc_auc 0.65333 prc_auc 0.79001[0m
[92maverage training of epoch 46: loss -16.90722 acc 0.66225 roc_auc 0.36637 prc_auc 0.56676[0m
[93maverage test of epoch 46: loss -17.16226 acc 0.67568 roc_auc 0.59500 prc_auc 0.74945[0m
[92maverage training of epoch 47: loss -17.20712 acc 0.66225 roc_auc 0.37069 prc_auc 0.56947[0m
[93maverage test of epoch 47: loss -17.46398 acc 0.67568 roc_auc 0.59667 prc_auc 0.76243[0m
[92maverage training of epoch 48: loss -17.50680 acc 0.66225 roc_auc 0.36598 prc_auc 0.56783[0m
[93maverage test of epoch 48: loss -17.76546 acc 0.67568 roc_auc 0.64833 prc_auc 0.77565[0m
[92maverage training of epoch 49: loss -17.80653 acc 0.66225 roc_auc 0.36480 prc_auc 0.56476[0m
[93maverage test of epoch 49: loss -18.06666 acc 0.67568 roc_auc 0.44500 prc_auc 0.65123[0m
[92maverage training of epoch 50: loss -18.10697 acc 0.66225 roc_auc 0.37157 prc_auc 0.57056[0m
[93maverage test of epoch 50: loss -18.36807 acc 0.67568 roc_auc 0.66667 prc_auc 0.76608[0m
[92maverage training of epoch 51: loss -18.40696 acc 0.66225 roc_auc 0.36873 prc_auc 0.56819[0m
[93maverage test of epoch 51: loss -18.66892 acc 0.67568 roc_auc 0.46000 prc_auc 0.65446[0m
[92maverage training of epoch 52: loss -18.70690 acc 0.66225 roc_auc 0.36971 prc_auc 0.57057[0m
[93maverage test of epoch 52: loss -18.97013 acc 0.67568 roc_auc 0.46833 prc_auc 0.67404[0m
[92maverage training of epoch 53: loss -19.00656 acc 0.66225 roc_auc 0.37078 prc_auc 0.57366[0m
[93maverage test of epoch 53: loss -19.27089 acc 0.67568 roc_auc 0.44333 prc_auc 0.64675[0m
[92maverage training of epoch 54: loss -19.30624 acc 0.66225 roc_auc 0.36745 prc_auc 0.57286[0m
[93maverage test of epoch 54: loss -19.57226 acc 0.67568 roc_auc 0.65333 prc_auc 0.75312[0m
[92maverage training of epoch 55: loss -19.60609 acc 0.66225 roc_auc 0.36627 prc_auc 0.56931[0m
[93maverage test of epoch 55: loss -19.87371 acc 0.67568 roc_auc 0.51500 prc_auc 0.68238[0m
[92maverage training of epoch 56: loss -19.90624 acc 0.66225 roc_auc 0.36647 prc_auc 0.56719[0m
[93maverage test of epoch 56: loss -20.17444 acc 0.67568 roc_auc 0.39833 prc_auc 0.63107[0m
[92maverage training of epoch 57: loss -20.20602 acc 0.66225 roc_auc 0.36922 prc_auc 0.56909[0m
[93maverage test of epoch 57: loss -20.47579 acc 0.67568 roc_auc 0.61167 prc_auc 0.72869[0m
[92maverage training of epoch 58: loss -20.50552 acc 0.66225 roc_auc 0.36853 prc_auc 0.56768[0m
[93maverage test of epoch 58: loss -20.77662 acc 0.67568 roc_auc 0.57167 prc_auc 0.70941[0m
[92maverage training of epoch 59: loss -20.80529 acc 0.66225 roc_auc 0.36912 prc_auc 0.56983[0m
[93maverage test of epoch 59: loss -21.07759 acc 0.67568 roc_auc 0.46000 prc_auc 0.65828[0m
[92maverage training of epoch 60: loss -21.10504 acc 0.66225 roc_auc 0.36794 prc_auc 0.57034[0m
[93maverage test of epoch 60: loss -21.37841 acc 0.67568 roc_auc 0.51333 prc_auc 0.68271[0m
[92maverage training of epoch 61: loss -21.40493 acc 0.66225 roc_auc 0.36804 prc_auc 0.56917[0m
[93maverage test of epoch 61: loss -21.67956 acc 0.67568 roc_auc 0.34000 prc_auc 0.62036[0m
[92maverage training of epoch 62: loss -21.70465 acc 0.66225 roc_auc 0.37069 prc_auc 0.57000[0m
[93maverage test of epoch 62: loss -21.98084 acc 0.67568 roc_auc 0.52167 prc_auc 0.68531[0m
[92maverage training of epoch 63: loss -22.00422 acc 0.66225 roc_auc 0.36882 prc_auc 0.56948[0m
[93maverage test of epoch 63: loss -22.28144 acc 0.67568 roc_auc 0.56333 prc_auc 0.70467[0m
[92maverage training of epoch 64: loss -22.30393 acc 0.66225 roc_auc 0.36716 prc_auc 0.56850[0m
[93maverage test of epoch 64: loss -22.58254 acc 0.67568 roc_auc 0.38167 prc_auc 0.62907[0m
[92maverage training of epoch 65: loss -22.60370 acc 0.66225 roc_auc 0.36775 prc_auc 0.57231[0m
[93maverage test of epoch 65: loss -22.88345 acc 0.67568 roc_auc 0.52833 prc_auc 0.68846[0m
[92maverage training of epoch 66: loss -22.90331 acc 0.66225 roc_auc 0.36843 prc_auc 0.56812[0m
[93maverage test of epoch 66: loss -23.18432 acc 0.67568 roc_auc 0.50667 prc_auc 0.67862[0m
[92maverage training of epoch 67: loss -23.20312 acc 0.66225 roc_auc 0.36853 prc_auc 0.56950[0m
[93maverage test of epoch 67: loss -23.48563 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 68: loss -23.50271 acc 0.66225 roc_auc 0.36745 prc_auc 0.57308[0m
[93maverage test of epoch 68: loss -23.78663 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 69: loss -23.80248 acc 0.66225 roc_auc 0.36775 prc_auc 0.56965[0m
[93maverage test of epoch 69: loss -24.08743 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 70: loss -24.10209 acc 0.66225 roc_auc 0.37157 prc_auc 0.57372[0m
[93maverage test of epoch 70: loss -24.38825 acc 0.67568 roc_auc 0.52167 prc_auc 0.68531[0m
[92maverage training of epoch 71: loss -24.40169 acc 0.66225 roc_auc 0.36627 prc_auc 0.57028[0m
[93maverage test of epoch 71: loss -24.68915 acc 0.67568 roc_auc 0.50833 prc_auc 0.67936[0m
[92maverage training of epoch 72: loss -24.70142 acc 0.66225 roc_auc 0.37039 prc_auc 0.57601[0m
[93maverage test of epoch 72: loss -24.99015 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 73: loss -25.00100 acc 0.66225 roc_auc 0.36833 prc_auc 0.57186[0m
[93maverage test of epoch 73: loss -25.29100 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 74: loss -25.30062 acc 0.66225 roc_auc 0.36549 prc_auc 0.57405[0m
[93maverage test of epoch 74: loss -25.59198 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 75: loss -25.60034 acc 0.66225 roc_auc 0.36990 prc_auc 0.57545[0m
[93maverage test of epoch 75: loss -25.89267 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 76: loss -25.90001 acc 0.66225 roc_auc 0.36882 prc_auc 0.57391[0m
[93maverage test of epoch 76: loss -26.19379 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 77: loss -26.19955 acc 0.66225 roc_auc 0.37186 prc_auc 0.57879[0m
[93maverage test of epoch 77: loss -26.49478 acc 0.67568 roc_auc 0.50167 prc_auc 0.67641[0m
[92maverage training of epoch 78: loss -26.49921 acc 0.66225 roc_auc 0.36686 prc_auc 0.57589[0m
[93maverage test of epoch 78: loss -26.79567 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 79: loss -26.79881 acc 0.66225 roc_auc 0.37598 prc_auc 0.58384[0m
[93maverage test of epoch 79: loss -27.09655 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 80: loss -27.09842 acc 0.66225 roc_auc 0.37735 prc_auc 0.58350[0m
[93maverage test of epoch 80: loss -27.39728 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 81: loss -27.39814 acc 0.66225 roc_auc 0.37029 prc_auc 0.57837[0m
[93maverage test of epoch 81: loss -27.69834 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 82: loss -27.69774 acc 0.66225 roc_auc 0.37618 prc_auc 0.58575[0m
[93maverage test of epoch 82: loss -27.99908 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 83: loss -27.99732 acc 0.66225 roc_auc 0.36863 prc_auc 0.57760[0m
[93maverage test of epoch 83: loss -28.30003 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 84: loss -28.29700 acc 0.66225 roc_auc 0.37392 prc_auc 0.58337[0m
[93maverage test of epoch 84: loss -28.60111 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 85: loss -28.59652 acc 0.66225 roc_auc 0.37422 prc_auc 0.58543[0m
[93maverage test of epoch 85: loss -28.90199 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 86: loss -28.89617 acc 0.66225 roc_auc 0.37657 prc_auc 0.58796[0m
[93maverage test of epoch 86: loss -29.20275 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 87: loss -29.19588 acc 0.66225 roc_auc 0.38716 prc_auc 0.59438[0m
[93maverage test of epoch 87: loss -29.50370 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 88: loss -29.49545 acc 0.66225 roc_auc 0.37510 prc_auc 0.58650[0m
[93maverage test of epoch 88: loss -29.80453 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 89: loss -29.79509 acc 0.66225 roc_auc 0.37882 prc_auc 0.59185[0m
[93maverage test of epoch 89: loss -30.10551 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 90: loss -30.09474 acc 0.66225 roc_auc 0.38059 prc_auc 0.59290[0m
[93maverage test of epoch 90: loss -30.40644 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 91: loss -30.39439 acc 0.66225 roc_auc 0.37127 prc_auc 0.59041[0m
[93maverage test of epoch 91: loss -30.70726 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 92: loss -30.69394 acc 0.66225 roc_auc 0.36892 prc_auc 0.59149[0m
[93maverage test of epoch 92: loss -31.00812 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 93: loss -30.99354 acc 0.66225 roc_auc 0.39588 prc_auc 0.60721[0m
[93maverage test of epoch 93: loss -31.30905 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 94: loss -31.29317 acc 0.66225 roc_auc 0.39294 prc_auc 0.60294[0m
[93maverage test of epoch 94: loss -31.60987 acc 0.67568 roc_auc 0.44000 prc_auc 0.65049[0m
[92maverage training of epoch 95: loss -31.59277 acc 0.66225 roc_auc 0.40657 prc_auc 0.61959[0m
[93maverage test of epoch 95: loss -31.91083 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 96: loss -31.89239 acc 0.66225 roc_auc 0.37431 prc_auc 0.59791[0m
[93maverage test of epoch 96: loss -32.21173 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 97: loss -32.19203 acc 0.66225 roc_auc 0.37696 prc_auc 0.60161[0m
[93maverage test of epoch 97: loss -32.51241 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 98: loss -32.49161 acc 0.66225 roc_auc 0.36941 prc_auc 0.60253[0m
[93maverage test of epoch 98: loss -32.81329 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 99: loss -32.79121 acc 0.66225 roc_auc 0.42245 prc_auc 0.62502[0m
[93maverage test of epoch 99: loss -33.11431 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.0003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.69744 ROC_AUC (avg): 0.55072 PRC_AUC (avg): 0.69807 

Average forward propagation time taken(ms): 3.982295978280817
Average backward propagation time taken(ms): 1.5175824671629279

