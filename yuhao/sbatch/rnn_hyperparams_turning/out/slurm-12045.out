# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 1)
('lr', 0.0001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-11-46-26/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-11-46-26/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 16,
 'epochs': 100,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 8,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.0001,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 2,
 'num_workers': 8,
 'number_of_mlp_layer': 1,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-18-11-46-26',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 100, 'learning_rate': 0.0001, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.91447 acc 0.66667 roc_auc 0.44800 prc_auc 0.68504[0m
[93maverage test of epoch 0: loss -1.15586 acc 0.65789 roc_auc 0.44615 prc_auc 0.61568[0m
[92maverage training of epoch 1: loss -1.50143 acc 0.66667 roc_auc 0.42780 prc_auc 0.65579[0m
[93maverage test of epoch 1: loss -1.87607 acc 0.65789 roc_auc 0.40000 prc_auc 0.61859[0m
[92maverage training of epoch 2: loss -2.26885 acc 0.66667 roc_auc 0.42080 prc_auc 0.64313[0m
[93maverage test of epoch 2: loss -2.66284 acc 0.65789 roc_auc 0.48615 prc_auc 0.68366[0m
[92maverage training of epoch 3: loss -3.06046 acc 0.66667 roc_auc 0.42360 prc_auc 0.61779[0m
[93maverage test of epoch 3: loss -3.34971 acc 0.65789 roc_auc 0.64923 prc_auc 0.80553[0m
[92maverage training of epoch 4: loss -3.73265 acc 0.66667 roc_auc 0.45760 prc_auc 0.66310[0m
[93maverage test of epoch 4: loss -4.11549 acc 0.65789 roc_auc 0.29538 prc_auc 0.57258[0m
[92maverage training of epoch 5: loss -4.58503 acc 0.66667 roc_auc 0.39440 prc_auc 0.62166[0m
[93maverage test of epoch 5: loss -4.98128 acc 0.65789 roc_auc 0.62769 prc_auc 0.79300[0m
[92maverage training of epoch 6: loss -5.38778 acc 0.66667 roc_auc 0.42160 prc_auc 0.62407[0m
[93maverage test of epoch 6: loss -5.72121 acc 0.65789 roc_auc 0.26769 prc_auc 0.54481[0m
[92maverage training of epoch 7: loss -6.18061 acc 0.66667 roc_auc 0.42670 prc_auc 0.60803[0m
[93maverage test of epoch 7: loss -6.51261 acc 0.65789 roc_auc 0.53846 prc_auc 0.69913[0m
[92maverage training of epoch 8: loss -6.98837 acc 0.66667 roc_auc 0.40330 prc_auc 0.60775[0m
[93maverage test of epoch 8: loss -7.34289 acc 0.65789 roc_auc 0.35692 prc_auc 0.57376[0m
[92maverage training of epoch 9: loss -7.85089 acc 0.66667 roc_auc 0.47150 prc_auc 0.69567[0m
[93maverage test of epoch 9: loss -8.24297 acc 0.65789 roc_auc 0.42462 prc_auc 0.60896[0m
[92maverage training of epoch 10: loss -8.71651 acc 0.66667 roc_auc 0.41000 prc_auc 0.61807[0m
[93maverage test of epoch 10: loss -9.07020 acc 0.65789 roc_auc 0.51385 prc_auc 0.71442[0m
[92maverage training of epoch 11: loss -9.50638 acc 0.66667 roc_auc 0.35430 prc_auc 0.57954[0m
[93maverage test of epoch 11: loss -9.88017 acc 0.65789 roc_auc 0.56923 prc_auc 0.69612[0m
[92maverage training of epoch 12: loss -10.29580 acc 0.66667 roc_auc 0.41600 prc_auc 0.65843[0m
[93maverage test of epoch 12: loss -10.65954 acc 0.65789 roc_auc 0.49538 prc_auc 0.63890[0m
[92maverage training of epoch 13: loss -11.08023 acc 0.66667 roc_auc 0.40130 prc_auc 0.61693[0m
[93maverage test of epoch 13: loss -11.39271 acc 0.65789 roc_auc 0.55077 prc_auc 0.71567[0m
[92maverage training of epoch 14: loss -11.86648 acc 0.66667 roc_auc 0.45540 prc_auc 0.65222[0m
[93maverage test of epoch 14: loss -12.19395 acc 0.65789 roc_auc 0.67231 prc_auc 0.79440[0m
[92maverage training of epoch 15: loss -12.63512 acc 0.66667 roc_auc 0.44490 prc_auc 0.65851[0m
[93maverage test of epoch 15: loss -12.95699 acc 0.65789 roc_auc 0.47231 prc_auc 0.67782[0m
[92maverage training of epoch 16: loss -13.42138 acc 0.66667 roc_auc 0.43170 prc_auc 0.64112[0m
[93maverage test of epoch 16: loss -13.72547 acc 0.65789 roc_auc 0.46923 prc_auc 0.67834[0m
[92maverage training of epoch 17: loss -14.20549 acc 0.66667 roc_auc 0.43080 prc_auc 0.64588[0m
[93maverage test of epoch 17: loss -14.51888 acc 0.65789 roc_auc 0.56308 prc_auc 0.75883[0m
[92maverage training of epoch 18: loss -14.99710 acc 0.66667 roc_auc 0.40940 prc_auc 0.61836[0m
[93maverage test of epoch 18: loss -15.32905 acc 0.65789 roc_auc 0.50462 prc_auc 0.66941[0m
[92maverage training of epoch 19: loss -15.81141 acc 0.66667 roc_auc 0.41860 prc_auc 0.63983[0m
[93maverage test of epoch 19: loss -16.14739 acc 0.65789 roc_auc 0.62769 prc_auc 0.80044[0m
[92maverage training of epoch 20: loss -16.61611 acc 0.66667 roc_auc 0.40920 prc_auc 0.60955[0m
[93maverage test of epoch 20: loss -16.94199 acc 0.65789 roc_auc 0.40615 prc_auc 0.63599[0m
[92maverage training of epoch 21: loss -17.44295 acc 0.66667 roc_auc 0.39810 prc_auc 0.63541[0m
[93maverage test of epoch 21: loss -17.76070 acc 0.65789 roc_auc 0.48308 prc_auc 0.64716[0m
[92maverage training of epoch 22: loss -18.27519 acc 0.66667 roc_auc 0.40870 prc_auc 0.60705[0m
[93maverage test of epoch 22: loss -18.60082 acc 0.65789 roc_auc 0.50154 prc_auc 0.69769[0m
[92maverage training of epoch 23: loss -19.10921 acc 0.66667 roc_auc 0.45000 prc_auc 0.64195[0m
[93maverage test of epoch 23: loss -19.43886 acc 0.65789 roc_auc 0.54923 prc_auc 0.69334[0m
[92maverage training of epoch 24: loss -19.96413 acc 0.66667 roc_auc 0.40010 prc_auc 0.62214[0m
[93maverage test of epoch 24: loss -20.28605 acc 0.65789 roc_auc 0.46000 prc_auc 0.65436[0m
[92maverage training of epoch 25: loss -20.82474 acc 0.66667 roc_auc 0.41180 prc_auc 0.61969[0m
[93maverage test of epoch 25: loss -21.15850 acc 0.65789 roc_auc 0.52615 prc_auc 0.70178[0m
[92maverage training of epoch 26: loss -21.69050 acc 0.66667 roc_auc 0.40430 prc_auc 0.60869[0m
[93maverage test of epoch 26: loss -22.03591 acc 0.65789 roc_auc 0.42154 prc_auc 0.62036[0m
[92maverage training of epoch 27: loss -22.57298 acc 0.66667 roc_auc 0.40210 prc_auc 0.61702[0m
[93maverage test of epoch 27: loss -22.91328 acc 0.65789 roc_auc 0.41692 prc_auc 0.62104[0m
[92maverage training of epoch 28: loss -23.46469 acc 0.66667 roc_auc 0.42030 prc_auc 0.63478[0m
[93maverage test of epoch 28: loss -23.79727 acc 0.65789 roc_auc 0.52154 prc_auc 0.66775[0m
[92maverage training of epoch 29: loss -24.37330 acc 0.66667 roc_auc 0.40700 prc_auc 0.62051[0m
[93maverage test of epoch 29: loss -24.69939 acc 0.65789 roc_auc 0.42462 prc_auc 0.62567[0m
[92maverage training of epoch 30: loss -25.29331 acc 0.66667 roc_auc 0.42110 prc_auc 0.62789[0m
[93maverage test of epoch 30: loss -25.63917 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -26.22009 acc 0.66667 roc_auc 0.42390 prc_auc 0.63325[0m
[93maverage test of epoch 31: loss -26.57311 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -27.16039 acc 0.66667 roc_auc 0.39000 prc_auc 0.62310[0m
[93maverage test of epoch 32: loss -27.49728 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -28.12423 acc 0.66667 roc_auc 0.42000 prc_auc 0.63401[0m
[93maverage test of epoch 33: loss -28.46415 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -29.09274 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -29.44487 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -30.06699 acc 0.66667 roc_auc 0.40000 prc_auc 0.62951[0m
[93maverage test of epoch 35: loss -30.42461 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -31.06286 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -31.42362 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -32.07485 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -32.43115 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -33.09469 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -33.46101 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -34.13013 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -34.49601 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -35.17523 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -35.54719 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -36.24386 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -36.60997 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -37.32582 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -37.70181 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -38.41859 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -38.80043 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -39.52448 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -39.90771 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -40.64226 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -41.03246 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -41.78483 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -42.17563 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -42.93613 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -43.32646 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -44.09971 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -44.49239 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -45.28695 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -45.68086 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 50: loss -46.48244 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 50: loss -46.87153 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 51: loss -47.68775 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 51: loss -48.08780 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 52: loss -48.91227 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 52: loss -49.31580 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 53: loss -50.14692 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 53: loss -50.55200 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 54: loss -51.39698 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 54: loss -51.80515 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 55: loss -52.66553 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 55: loss -53.06983 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 56: loss -53.94348 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 56: loss -54.35148 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 57: loss -55.24007 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 57: loss -55.64916 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 58: loss -56.54793 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 58: loss -56.95937 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 59: loss -57.87307 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 59: loss -58.28709 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 60: loss -59.20999 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 60: loss -59.62929 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 61: loss -60.56642 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 61: loss -60.98885 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 62: loss -61.93207 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 62: loss -62.35606 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 63: loss -63.31481 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 63: loss -63.74007 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 64: loss -64.71589 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 64: loss -65.14500 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 65: loss -66.13250 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 65: loss -66.55871 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 66: loss -67.55887 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 66: loss -67.98946 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 67: loss -69.00416 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 67: loss -69.43890 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 68: loss -70.46486 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 68: loss -70.90066 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 69: loss -71.93935 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 69: loss -72.37514 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 70: loss -73.42917 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 70: loss -73.86992 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 71: loss -74.93457 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 71: loss -75.37584 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 72: loss -76.45441 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 72: loss -76.89780 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 73: loss -77.99049 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 73: loss -78.43470 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 74: loss -79.54182 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 74: loss -79.98795 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 75: loss -81.10739 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 75: loss -81.55688 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 76: loss -82.69094 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 76: loss -83.13948 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 77: loss -84.28768 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 77: loss -84.74041 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 78: loss -85.90069 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 78: loss -86.35459 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 79: loss -87.52827 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 79: loss -87.98353 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 80: loss -89.17198 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 80: loss -89.62722 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 81: loss -90.83088 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 81: loss -91.28799 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 82: loss -92.50489 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 82: loss -92.96336 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 83: loss -94.19526 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 83: loss -94.65535 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 84: loss -95.89995 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 84: loss -96.36236 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 85: loss -97.62080 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 85: loss -98.08254 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 86: loss -99.35681 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 86: loss -99.81962 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 87: loss -101.10856 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 87: loss -101.57410 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 88: loss -102.87491 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 88: loss -103.34164 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 89: loss -104.65589 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 89: loss -105.12393 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -106.45267 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 90: loss -106.92076 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 91: loss -108.26405 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 91: loss -108.73358 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 92: loss -110.09046 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 92: loss -110.55997 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 93: loss -111.93202 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 93: loss -112.40314 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 94: loss -113.78914 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 94: loss -114.26014 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 95: loss -115.66147 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 95: loss -116.13352 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 96: loss -117.54885 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 96: loss -118.02042 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 97: loss -119.45121 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 97: loss -119.92516 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 98: loss -121.36904 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 98: loss -121.84332 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -123.30212 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 99: loss -123.77665 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss 0.15593 acc 0.66667 roc_auc 0.52140 prc_auc 0.68864[0m
[93maverage test of epoch 0: loss -0.13130 acc 0.65789 roc_auc 0.60000 prc_auc 0.77449[0m
[92maverage training of epoch 1: loss -0.44087 acc 0.66667 roc_auc 0.50880 prc_auc 0.69559[0m
[93maverage test of epoch 1: loss -0.69007 acc 0.65789 roc_auc 0.75692 prc_auc 0.87189[0m
[92maverage training of epoch 2: loss -0.89872 acc 0.66667 roc_auc 0.56460 prc_auc 0.75122[0m
[93maverage test of epoch 2: loss -1.08826 acc 0.65789 roc_auc 0.73538 prc_auc 0.85378[0m
[92maverage training of epoch 3: loss -1.28222 acc 0.66667 roc_auc 0.62940 prc_auc 0.79740[0m
[93maverage test of epoch 3: loss -1.45810 acc 0.65789 roc_auc 0.70769 prc_auc 0.85902[0m
[92maverage training of epoch 4: loss -1.62490 acc 0.66667 roc_auc 0.66100 prc_auc 0.83102[0m
[93maverage test of epoch 4: loss -1.76404 acc 0.65789 roc_auc 0.79077 prc_auc 0.89809[0m
[92maverage training of epoch 5: loss -1.94385 acc 0.66667 roc_auc 0.73720 prc_auc 0.87542[0m
[93maverage test of epoch 5: loss -2.07664 acc 0.65789 roc_auc 0.83385 prc_auc 0.90965[0m
[92maverage training of epoch 6: loss -2.23824 acc 0.66667 roc_auc 0.76160 prc_auc 0.88767[0m
[93maverage test of epoch 6: loss -2.37804 acc 0.65789 roc_auc 0.84000 prc_auc 0.91166[0m
[92maverage training of epoch 7: loss -2.54677 acc 0.66667 roc_auc 0.81020 prc_auc 0.91845[0m
[93maverage test of epoch 7: loss -2.68392 acc 0.65789 roc_auc 0.84308 prc_auc 0.92039[0m
[92maverage training of epoch 8: loss -2.86460 acc 0.66667 roc_auc 0.79900 prc_auc 0.90659[0m
[93maverage test of epoch 8: loss -2.99821 acc 0.65789 roc_auc 0.85538 prc_auc 0.92905[0m
[92maverage training of epoch 9: loss -3.20253 acc 0.66667 roc_auc 0.76600 prc_auc 0.88814[0m
[93maverage test of epoch 9: loss -3.36579 acc 0.65789 roc_auc 0.83077 prc_auc 0.91165[0m
[92maverage training of epoch 10: loss -3.56130 acc 0.66667 roc_auc 0.82500 prc_auc 0.91487[0m
[93maverage test of epoch 10: loss -3.72653 acc 0.65789 roc_auc 0.81538 prc_auc 0.91081[0m
[92maverage training of epoch 11: loss -3.95695 acc 0.66667 roc_auc 0.79880 prc_auc 0.90667[0m
[93maverage test of epoch 11: loss -4.12179 acc 0.65789 roc_auc 0.86462 prc_auc 0.93956[0m
[92maverage training of epoch 12: loss -4.37343 acc 0.66667 roc_auc 0.78800 prc_auc 0.90025[0m
[93maverage test of epoch 12: loss -4.48641 acc 0.65789 roc_auc 0.78462 prc_auc 0.90227[0m
[92maverage training of epoch 13: loss -4.79893 acc 0.66667 roc_auc 0.80420 prc_auc 0.90903[0m
[93maverage test of epoch 13: loss -4.98182 acc 0.65789 roc_auc 0.72308 prc_auc 0.86659[0m
[92maverage training of epoch 14: loss -5.21079 acc 0.66667 roc_auc 0.72540 prc_auc 0.86657[0m
[93maverage test of epoch 14: loss -5.40307 acc 0.65789 roc_auc 0.86462 prc_auc 0.92744[0m
[92maverage training of epoch 15: loss -5.63368 acc 0.66667 roc_auc 0.75220 prc_auc 0.86802[0m
[93maverage test of epoch 15: loss -5.77834 acc 0.65789 roc_auc 0.73231 prc_auc 0.87094[0m
[92maverage training of epoch 16: loss -6.02220 acc 0.66667 roc_auc 0.74360 prc_auc 0.86427[0m
[93maverage test of epoch 16: loss -6.16788 acc 0.65789 roc_auc 0.72308 prc_auc 0.85844[0m
[92maverage training of epoch 17: loss -6.40940 acc 0.66667 roc_auc 0.75020 prc_auc 0.87575[0m
[93maverage test of epoch 17: loss -6.60191 acc 0.65789 roc_auc 0.78769 prc_auc 0.89320[0m
[92maverage training of epoch 18: loss -6.80961 acc 0.66667 roc_auc 0.79720 prc_auc 0.90676[0m
[93maverage test of epoch 18: loss -6.96346 acc 0.65789 roc_auc 0.81846 prc_auc 0.91502[0m
[92maverage training of epoch 19: loss -7.19759 acc 0.66667 roc_auc 0.77860 prc_auc 0.89497[0m
[93maverage test of epoch 19: loss -7.34638 acc 0.65789 roc_auc 0.82769 prc_auc 0.91370[0m
[92maverage training of epoch 20: loss -7.60162 acc 0.66667 roc_auc 0.83620 prc_auc 0.92114[0m
[93maverage test of epoch 20: loss -7.70301 acc 0.65789 roc_auc 0.87385 prc_auc 0.92795[0m
[92maverage training of epoch 21: loss -8.01178 acc 0.66667 roc_auc 0.88140 prc_auc 0.93886[0m
[93maverage test of epoch 21: loss -8.12878 acc 0.65789 roc_auc 0.90154 prc_auc 0.94495[0m
[92maverage training of epoch 22: loss -8.40949 acc 0.66667 roc_auc 0.88940 prc_auc 0.94350[0m
[93maverage test of epoch 22: loss -8.53846 acc 0.65789 roc_auc 0.89231 prc_auc 0.94977[0m
[92maverage training of epoch 23: loss -8.79049 acc 0.66667 roc_auc 0.87620 prc_auc 0.93148[0m
[93maverage test of epoch 23: loss -8.92377 acc 0.65789 roc_auc 0.90154 prc_auc 0.92139[0m
[92maverage training of epoch 24: loss -9.17185 acc 0.66667 roc_auc 0.89730 prc_auc 0.92489[0m
[93maverage test of epoch 24: loss -9.22874 acc 0.65789 roc_auc 0.89231 prc_auc 0.93854[0m
[92maverage training of epoch 25: loss -9.54050 acc 0.66667 roc_auc 0.89140 prc_auc 0.93364[0m
[93maverage test of epoch 25: loss -9.60644 acc 0.65789 roc_auc 0.88000 prc_auc 0.89660[0m
[92maverage training of epoch 26: loss -9.91592 acc 0.66667 roc_auc 0.86100 prc_auc 0.93355[0m
[93maverage test of epoch 26: loss -10.11538 acc 0.65789 roc_auc 0.92000 prc_auc 0.96386[0m
[92maverage training of epoch 27: loss -10.29339 acc 0.66667 roc_auc 0.87640 prc_auc 0.93524[0m
[93maverage test of epoch 27: loss -10.39762 acc 0.65789 roc_auc 0.91692 prc_auc 0.95529[0m
[92maverage training of epoch 28: loss -10.69919 acc 0.66667 roc_auc 0.89260 prc_auc 0.92759[0m
[93maverage test of epoch 28: loss -10.78263 acc 0.65789 roc_auc 0.87077 prc_auc 0.87747[0m
[92maverage training of epoch 29: loss -11.11630 acc 0.66667 roc_auc 0.88740 prc_auc 0.94193[0m
[93maverage test of epoch 29: loss -11.17341 acc 0.65789 roc_auc 0.91231 prc_auc 0.93824[0m
[92maverage training of epoch 30: loss -11.45882 acc 0.66667 roc_auc 0.87160 prc_auc 0.91341[0m
[93maverage test of epoch 30: loss -11.62557 acc 0.65789 roc_auc 0.92462 prc_auc 0.95647[0m
[92maverage training of epoch 31: loss -11.93950 acc 0.66667 roc_auc 0.90130 prc_auc 0.93035[0m
[93maverage test of epoch 31: loss -11.96798 acc 0.65789 roc_auc 0.87231 prc_auc 0.88045[0m
[92maverage training of epoch 32: loss -12.30752 acc 0.66667 roc_auc 0.88150 prc_auc 0.92892[0m
[93maverage test of epoch 32: loss -12.45672 acc 0.65789 roc_auc 0.89231 prc_auc 0.89156[0m
[92maverage training of epoch 33: loss -12.67130 acc 0.66667 roc_auc 0.85880 prc_auc 0.93374[0m
[93maverage test of epoch 33: loss -12.76553 acc 0.65789 roc_auc 0.89538 prc_auc 0.94751[0m
[92maverage training of epoch 34: loss -13.12455 acc 0.66667 roc_auc 0.88640 prc_auc 0.94149[0m
[93maverage test of epoch 34: loss -13.20662 acc 0.65789 roc_auc 0.94154 prc_auc 0.97239[0m
[92maverage training of epoch 35: loss -13.52744 acc 0.66667 roc_auc 0.86750 prc_auc 0.92566[0m
[93maverage test of epoch 35: loss -13.55220 acc 0.65789 roc_auc 0.86462 prc_auc 0.91540[0m
[92maverage training of epoch 36: loss -13.91135 acc 0.66667 roc_auc 0.84980 prc_auc 0.92079[0m
[93maverage test of epoch 36: loss -14.17839 acc 0.65789 roc_auc 0.92308 prc_auc 0.95910[0m
[92maverage training of epoch 37: loss -14.43082 acc 0.66667 roc_auc 0.88100 prc_auc 0.92552[0m
[93maverage test of epoch 37: loss -14.58548 acc 0.65789 roc_auc 0.86000 prc_auc 0.90588[0m
[92maverage training of epoch 38: loss -14.94106 acc 0.66667 roc_auc 0.89490 prc_auc 0.92302[0m
[93maverage test of epoch 38: loss -15.04121 acc 0.65789 roc_auc 0.89692 prc_auc 0.93560[0m
[92maverage training of epoch 39: loss -15.33858 acc 0.66667 roc_auc 0.88160 prc_auc 0.92363[0m
[93maverage test of epoch 39: loss -15.45239 acc 0.65789 roc_auc 0.88000 prc_auc 0.91654[0m
[92maverage training of epoch 40: loss -15.84421 acc 0.66667 roc_auc 0.88560 prc_auc 0.93229[0m
[93maverage test of epoch 40: loss -15.90416 acc 0.65789 roc_auc 0.90308 prc_auc 0.92871[0m
[92maverage training of epoch 41: loss -16.27671 acc 0.66667 roc_auc 0.87330 prc_auc 0.92087[0m
[93maverage test of epoch 41: loss -16.29891 acc 0.65789 roc_auc 0.86923 prc_auc 0.90055[0m
[92maverage training of epoch 42: loss -16.70825 acc 0.66667 roc_auc 0.86530 prc_auc 0.90816[0m
[93maverage test of epoch 42: loss -16.88436 acc 0.65789 roc_auc 0.89231 prc_auc 0.92211[0m
[92maverage training of epoch 43: loss -17.23659 acc 0.66667 roc_auc 0.86870 prc_auc 0.92126[0m
[93maverage test of epoch 43: loss -17.43223 acc 0.65789 roc_auc 0.91692 prc_auc 0.95043[0m
[92maverage training of epoch 44: loss -17.73611 acc 0.66667 roc_auc 0.89470 prc_auc 0.92737[0m
[93maverage test of epoch 44: loss -17.87587 acc 0.65789 roc_auc 0.89077 prc_auc 0.92029[0m
[92maverage training of epoch 45: loss -18.23079 acc 0.66667 roc_auc 0.88010 prc_auc 0.91676[0m
[93maverage test of epoch 45: loss -18.34105 acc 0.65789 roc_auc 0.80462 prc_auc 0.82947[0m
[92maverage training of epoch 46: loss -18.73817 acc 0.66667 roc_auc 0.87090 prc_auc 0.90999[0m
[93maverage test of epoch 46: loss -18.71978 acc 0.65789 roc_auc 0.84462 prc_auc 0.86163[0m
[92maverage training of epoch 47: loss -19.25148 acc 0.66667 roc_auc 0.89210 prc_auc 0.93300[0m
[93maverage test of epoch 47: loss -19.46897 acc 0.65789 roc_auc 0.86462 prc_auc 0.88230[0m
[92maverage training of epoch 48: loss -19.74244 acc 0.66667 roc_auc 0.88700 prc_auc 0.93058[0m
[93maverage test of epoch 48: loss -19.93802 acc 0.65789 roc_auc 0.89538 prc_auc 0.90430[0m
[92maverage training of epoch 49: loss -20.33542 acc 0.66667 roc_auc 0.90340 prc_auc 0.93194[0m
[93maverage test of epoch 49: loss -20.25863 acc 0.65789 roc_auc 0.83846 prc_auc 0.85619[0m
[92maverage training of epoch 50: loss -20.85136 acc 0.66667 roc_auc 0.89270 prc_auc 0.92679[0m
[93maverage test of epoch 50: loss -20.96606 acc 0.65789 roc_auc 0.86462 prc_auc 0.87862[0m
[92maverage training of epoch 51: loss -21.32484 acc 0.66667 roc_auc 0.87540 prc_auc 0.91475[0m
[93maverage test of epoch 51: loss -21.61650 acc 0.65789 roc_auc 0.83385 prc_auc 0.85267[0m
[92maverage training of epoch 52: loss -21.91471 acc 0.66667 roc_auc 0.88000 prc_auc 0.92070[0m
[93maverage test of epoch 52: loss -22.06032 acc 0.65789 roc_auc 0.75846 prc_auc 0.79925[0m
[92maverage training of epoch 53: loss -22.46850 acc 0.66667 roc_auc 0.87290 prc_auc 0.91546[0m
[93maverage test of epoch 53: loss -22.54641 acc 0.65789 roc_auc 0.80308 prc_auc 0.84202[0m
[92maverage training of epoch 54: loss -23.04806 acc 0.66667 roc_auc 0.84430 prc_auc 0.88544[0m
[93maverage test of epoch 54: loss -23.24457 acc 0.65789 roc_auc 0.79692 prc_auc 0.82573[0m
[92maverage training of epoch 55: loss -23.69570 acc 0.66667 roc_auc 0.84720 prc_auc 0.87920[0m
[93maverage test of epoch 55: loss -23.77620 acc 0.65789 roc_auc 0.76923 prc_auc 0.80645[0m
[92maverage training of epoch 56: loss -24.24975 acc 0.66667 roc_auc 0.77740 prc_auc 0.82649[0m
[93maverage test of epoch 56: loss -24.50264 acc 0.65789 roc_auc 0.76923 prc_auc 0.80645[0m
[92maverage training of epoch 57: loss -24.76541 acc 0.66667 roc_auc 0.74650 prc_auc 0.80852[0m
[93maverage test of epoch 57: loss -25.10200 acc 0.65789 roc_auc 0.76923 prc_auc 0.80645[0m
[92maverage training of epoch 58: loss -25.48740 acc 0.66667 roc_auc 0.81860 prc_auc 0.85665[0m
[93maverage test of epoch 58: loss -25.59269 acc 0.65789 roc_auc 0.69231 prc_auc 0.75758[0m
[92maverage training of epoch 59: loss -26.02673 acc 0.66667 roc_auc 0.78390 prc_auc 0.83402[0m
[93maverage test of epoch 59: loss -26.42697 acc 0.65789 roc_auc 0.80769 prc_auc 0.83333[0m
[92maverage training of epoch 60: loss -26.67149 acc 0.66667 roc_auc 0.77190 prc_auc 0.82081[0m
[93maverage test of epoch 60: loss -26.97906 acc 0.65789 roc_auc 0.76923 prc_auc 0.80645[0m
[92maverage training of epoch 61: loss -27.22047 acc 0.66667 roc_auc 0.75650 prc_auc 0.81637[0m
[93maverage test of epoch 61: loss -27.68931 acc 0.65789 roc_auc 0.80769 prc_auc 0.83333[0m
[92maverage training of epoch 62: loss -27.80413 acc 0.66667 roc_auc 0.71710 prc_auc 0.78298[0m
[93maverage test of epoch 62: loss -28.28485 acc 0.65789 roc_auc 0.76923 prc_auc 0.80645[0m
[92maverage training of epoch 63: loss -28.56697 acc 0.66667 roc_auc 0.74140 prc_auc 0.80029[0m
[93maverage test of epoch 63: loss -28.90570 acc 0.65789 roc_auc 0.73077 prc_auc 0.78125[0m
[92maverage training of epoch 64: loss -29.13684 acc 0.66667 roc_auc 0.75830 prc_auc 0.81667[0m
[93maverage test of epoch 64: loss -29.71124 acc 0.65789 roc_auc 0.80769 prc_auc 0.83333[0m
[92maverage training of epoch 65: loss -29.95439 acc 0.66667 roc_auc 0.78010 prc_auc 0.82556[0m
[93maverage test of epoch 65: loss -30.28337 acc 0.65789 roc_auc 0.76923 prc_auc 0.80645[0m
[92maverage training of epoch 66: loss -30.67478 acc 0.66667 roc_auc 0.73530 prc_auc 0.79214[0m
[93maverage test of epoch 66: loss -30.81619 acc 0.65789 roc_auc 0.65385 prc_auc 0.73529[0m
[92maverage training of epoch 67: loss -31.35247 acc 0.66667 roc_auc 0.73940 prc_auc 0.79655[0m
[93maverage test of epoch 67: loss -31.63446 acc 0.65789 roc_auc 0.73077 prc_auc 0.78125[0m
[92maverage training of epoch 68: loss -31.87584 acc 0.66667 roc_auc 0.68940 prc_auc 0.76699[0m
[93maverage test of epoch 68: loss -32.34863 acc 0.65789 roc_auc 0.69231 prc_auc 0.75758[0m
[92maverage training of epoch 69: loss -32.76355 acc 0.66667 roc_auc 0.80000 prc_auc 0.83810[0m
[93maverage test of epoch 69: loss -33.14088 acc 0.65789 roc_auc 0.76923 prc_auc 0.80645[0m
[92maverage training of epoch 70: loss -33.41615 acc 0.66667 roc_auc 0.73500 prc_auc 0.79283[0m
[93maverage test of epoch 70: loss -33.85038 acc 0.65789 roc_auc 0.73077 prc_auc 0.78125[0m
[92maverage training of epoch 71: loss -34.23419 acc 0.66667 roc_auc 0.61500 prc_auc 0.72216[0m
[93maverage test of epoch 71: loss -34.69212 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 72: loss -34.98392 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 72: loss -35.29122 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 73: loss -35.65375 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 73: loss -36.11485 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 74: loss -36.32679 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 74: loss -36.98630 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 75: loss -37.26091 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 75: loss -37.59168 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 76: loss -37.95003 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 76: loss -38.54852 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 77: loss -38.85630 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 77: loss -39.42531 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 78: loss -39.61219 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 78: loss -40.01853 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 79: loss -40.54942 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 79: loss -40.89580 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 80: loss -41.28453 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 80: loss -41.60525 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 81: loss -41.98833 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 81: loss -42.73749 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 82: loss -42.84675 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 82: loss -43.34558 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 83: loss -43.75733 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 83: loss -44.26348 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 84: loss -44.50734 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 84: loss -45.16016 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 85: loss -45.57267 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 85: loss -46.11444 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 86: loss -46.20149 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 86: loss -47.07082 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 87: loss -47.11023 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 87: loss -47.97420 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 88: loss -48.04597 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 88: loss -48.74022 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 89: loss -49.05105 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 89: loss -49.75123 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -50.01532 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 90: loss -50.37154 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 91: loss -50.84012 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 91: loss -51.50545 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 92: loss -51.85966 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 92: loss -52.59159 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 93: loss -52.80916 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 93: loss -53.50772 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 94: loss -53.95135 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 94: loss -54.42225 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 95: loss -55.00076 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 95: loss -55.26570 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 96: loss -55.81184 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 96: loss -56.38061 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 97: loss -56.89768 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 97: loss -57.48290 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 98: loss -57.94430 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 98: loss -58.39000 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -58.95288 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 99: loss -59.62283 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.44728 acc 0.56000 roc_auc 0.48860 prc_auc 0.68486[0m
[93maverage test of epoch 0: loss -0.55531 acc 0.63158 roc_auc 0.44923 prc_auc 0.65627[0m
[92maverage training of epoch 1: loss -0.68365 acc 0.66667 roc_auc 0.49140 prc_auc 0.68011[0m
[93maverage test of epoch 1: loss -0.80529 acc 0.65789 roc_auc 0.65538 prc_auc 0.77701[0m
[92maverage training of epoch 2: loss -0.92121 acc 0.66667 roc_auc 0.58680 prc_auc 0.74643[0m
[93maverage test of epoch 2: loss -1.08211 acc 0.65789 roc_auc 0.91385 prc_auc 0.95294[0m
[92maverage training of epoch 3: loss -1.16710 acc 0.66667 roc_auc 0.67420 prc_auc 0.77085[0m
[93maverage test of epoch 3: loss -1.31429 acc 0.65789 roc_auc 0.84308 prc_auc 0.87696[0m
[92maverage training of epoch 4: loss -1.43726 acc 0.66667 roc_auc 0.75700 prc_auc 0.81286[0m
[93maverage test of epoch 4: loss -1.61504 acc 0.65789 roc_auc 0.97231 prc_auc 0.98751[0m
[92maverage training of epoch 5: loss -1.80366 acc 0.66667 roc_auc 0.75840 prc_auc 0.80966[0m
[93maverage test of epoch 5: loss -2.02550 acc 0.65789 roc_auc 0.94769 prc_auc 0.98004[0m
[92maverage training of epoch 6: loss -2.20158 acc 0.66667 roc_auc 0.75620 prc_auc 0.80487[0m
[93maverage test of epoch 6: loss -2.45555 acc 0.65789 roc_auc 0.92923 prc_auc 0.96473[0m
[92maverage training of epoch 7: loss -2.68365 acc 0.66667 roc_auc 0.82360 prc_auc 0.84748[0m
[93maverage test of epoch 7: loss -2.97969 acc 0.65789 roc_auc 0.87692 prc_auc 0.92606[0m
[92maverage training of epoch 8: loss -3.22330 acc 0.66667 roc_auc 0.82080 prc_auc 0.83382[0m
[93maverage test of epoch 8: loss -3.50289 acc 0.65789 roc_auc 0.88308 prc_auc 0.92500[0m
[92maverage training of epoch 9: loss -3.73333 acc 0.66667 roc_auc 0.83840 prc_auc 0.89024[0m
[93maverage test of epoch 9: loss -3.99716 acc 0.65789 roc_auc 0.91385 prc_auc 0.95235[0m
[92maverage training of epoch 10: loss -4.21175 acc 0.66667 roc_auc 0.81020 prc_auc 0.85089[0m
[93maverage test of epoch 10: loss -4.43051 acc 0.65789 roc_auc 0.86154 prc_auc 0.89768[0m
[92maverage training of epoch 11: loss -4.69163 acc 0.66667 roc_auc 0.79320 prc_auc 0.83622[0m
[93maverage test of epoch 11: loss -4.93406 acc 0.65789 roc_auc 0.86769 prc_auc 0.92029[0m
[92maverage training of epoch 12: loss -5.15148 acc 0.66667 roc_auc 0.74300 prc_auc 0.80208[0m
[93maverage test of epoch 12: loss -5.38857 acc 0.65789 roc_auc 0.86154 prc_auc 0.90517[0m
[92maverage training of epoch 13: loss -5.67335 acc 0.66667 roc_auc 0.63370 prc_auc 0.76203[0m
[93maverage test of epoch 13: loss -5.86717 acc 0.65789 roc_auc 0.72308 prc_auc 0.87115[0m
[92maverage training of epoch 14: loss -6.17227 acc 0.66667 roc_auc 0.47320 prc_auc 0.66350[0m
[93maverage test of epoch 14: loss -6.35980 acc 0.65789 roc_auc 0.50154 prc_auc 0.75067[0m
[92maverage training of epoch 15: loss -6.68232 acc 0.66667 roc_auc 0.50430 prc_auc 0.66863[0m
[93maverage test of epoch 15: loss -6.87893 acc 0.65789 roc_auc 0.58769 prc_auc 0.79123[0m
[92maverage training of epoch 16: loss -7.19777 acc 0.66667 roc_auc 0.45120 prc_auc 0.66995[0m
[93maverage test of epoch 16: loss -7.38862 acc 0.65789 roc_auc 0.72308 prc_auc 0.83932[0m
[92maverage training of epoch 17: loss -7.72825 acc 0.66667 roc_auc 0.45530 prc_auc 0.65719[0m
[93maverage test of epoch 17: loss -7.89832 acc 0.65789 roc_auc 0.60615 prc_auc 0.76347[0m
[92maverage training of epoch 18: loss -8.27285 acc 0.66667 roc_auc 0.46280 prc_auc 0.67916[0m
[93maverage test of epoch 18: loss -8.47052 acc 0.65789 roc_auc 0.67692 prc_auc 0.83453[0m
[92maverage training of epoch 19: loss -8.79620 acc 0.66667 roc_auc 0.45190 prc_auc 0.62316[0m
[93maverage test of epoch 19: loss -9.00311 acc 0.65789 roc_auc 0.57692 prc_auc 0.74469[0m
[92maverage training of epoch 20: loss -9.37249 acc 0.66667 roc_auc 0.44610 prc_auc 0.64452[0m
[93maverage test of epoch 20: loss -9.55920 acc 0.65789 roc_auc 0.62615 prc_auc 0.78818[0m
[92maverage training of epoch 21: loss -9.92473 acc 0.66667 roc_auc 0.46000 prc_auc 0.66580[0m
[93maverage test of epoch 21: loss -10.10534 acc 0.65789 roc_auc 0.45077 prc_auc 0.67685[0m
[92maverage training of epoch 22: loss -10.49413 acc 0.66667 roc_auc 0.48220 prc_auc 0.67977[0m
[93maverage test of epoch 22: loss -10.67305 acc 0.65789 roc_auc 0.48308 prc_auc 0.66774[0m
[92maverage training of epoch 23: loss -11.05890 acc 0.66667 roc_auc 0.44080 prc_auc 0.62517[0m
[93maverage test of epoch 23: loss -11.26416 acc 0.65789 roc_auc 0.60923 prc_auc 0.74430[0m
[92maverage training of epoch 24: loss -11.62995 acc 0.66667 roc_auc 0.42470 prc_auc 0.63055[0m
[93maverage test of epoch 24: loss -11.83032 acc 0.65789 roc_auc 0.44308 prc_auc 0.68508[0m
[92maverage training of epoch 25: loss -12.21644 acc 0.66667 roc_auc 0.43050 prc_auc 0.63919[0m
[93maverage test of epoch 25: loss -12.40021 acc 0.65789 roc_auc 0.54000 prc_auc 0.71487[0m
[92maverage training of epoch 26: loss -12.80918 acc 0.66667 roc_auc 0.46490 prc_auc 0.65904[0m
[93maverage test of epoch 26: loss -12.97247 acc 0.65789 roc_auc 0.37385 prc_auc 0.59007[0m
[92maverage training of epoch 27: loss -13.41349 acc 0.66667 roc_auc 0.45580 prc_auc 0.65702[0m
[93maverage test of epoch 27: loss -13.61715 acc 0.65789 roc_auc 0.62615 prc_auc 0.71780[0m
[92maverage training of epoch 28: loss -14.02042 acc 0.66667 roc_auc 0.42700 prc_auc 0.63029[0m
[93maverage test of epoch 28: loss -14.22027 acc 0.65789 roc_auc 0.64000 prc_auc 0.75124[0m
[92maverage training of epoch 29: loss -14.63413 acc 0.66667 roc_auc 0.43070 prc_auc 0.63388[0m
[93maverage test of epoch 29: loss -14.84214 acc 0.65789 roc_auc 0.39846 prc_auc 0.61621[0m
[92maverage training of epoch 30: loss -15.25342 acc 0.66667 roc_auc 0.45810 prc_auc 0.64573[0m
[93maverage test of epoch 30: loss -15.48198 acc 0.65789 roc_auc 0.45692 prc_auc 0.63923[0m
[92maverage training of epoch 31: loss -15.89685 acc 0.66667 roc_auc 0.43310 prc_auc 0.63916[0m
[93maverage test of epoch 31: loss -16.08917 acc 0.65789 roc_auc 0.62154 prc_auc 0.73181[0m
[92maverage training of epoch 32: loss -16.54243 acc 0.66667 roc_auc 0.50840 prc_auc 0.67036[0m
[93maverage test of epoch 32: loss -16.74799 acc 0.65789 roc_auc 0.61538 prc_auc 0.71429[0m
[92maverage training of epoch 33: loss -17.19879 acc 0.66667 roc_auc 0.50990 prc_auc 0.67167[0m
[93maverage test of epoch 33: loss -17.37545 acc 0.65789 roc_auc 0.44615 prc_auc 0.63743[0m
[92maverage training of epoch 34: loss -17.84082 acc 0.66667 roc_auc 0.51000 prc_auc 0.67114[0m
[93maverage test of epoch 34: loss -18.04207 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -18.51548 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -18.73636 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -19.19716 acc 0.66667 roc_auc 0.45500 prc_auc 0.64817[0m
[93maverage test of epoch 36: loss -19.40399 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -19.88360 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -20.09454 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -20.59140 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -20.78323 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -21.29981 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -21.50197 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -22.02796 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -22.22030 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -22.74934 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -22.96600 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -23.49806 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -23.70518 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -24.25115 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -24.46782 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -25.02589 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -25.24170 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -25.79938 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -26.02337 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -26.59437 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -26.81551 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -27.39302 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -27.61638 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -28.20373 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -28.43329 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -29.03756 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -29.25330 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 50: loss -29.86996 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 50: loss -30.10563 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 51: loss -30.72395 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 51: loss -30.94789 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 52: loss -31.58346 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 52: loss -31.81359 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 53: loss -32.45994 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 53: loss -32.69288 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 54: loss -33.34416 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 54: loss -33.58600 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 55: loss -34.24423 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 55: loss -34.46522 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 56: loss -35.15469 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 56: loss -35.39398 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 57: loss -36.07805 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 57: loss -36.32198 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 58: loss -37.01477 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 58: loss -37.25472 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 59: loss -37.96259 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 59: loss -38.20981 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 60: loss -38.92360 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 60: loss -39.16893 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 61: loss -39.89702 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 61: loss -40.14666 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 62: loss -40.88388 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 62: loss -41.13056 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 63: loss -41.88092 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 63: loss -42.13252 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 64: loss -42.89213 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 64: loss -43.13640 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 65: loss -43.91423 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 65: loss -44.16693 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 66: loss -44.94743 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 66: loss -45.20078 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 67: loss -45.99428 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 67: loss -46.24990 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 68: loss -47.05615 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 68: loss -47.31127 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 69: loss -48.12672 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 69: loss -48.38540 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 70: loss -49.21096 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 70: loss -49.47027 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 71: loss -50.30899 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 71: loss -50.56806 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 72: loss -51.41745 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 72: loss -51.67945 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 73: loss -52.53724 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 73: loss -52.80181 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 74: loss -53.67390 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 74: loss -53.93900 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 75: loss -54.82170 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 75: loss -55.08587 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 76: loss -55.97993 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 76: loss -56.24621 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 77: loss -57.15153 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 77: loss -57.41730 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 78: loss -58.33568 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 78: loss -58.60415 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 79: loss -59.53012 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 79: loss -59.79681 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 80: loss -60.73736 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 80: loss -61.00585 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 81: loss -61.95609 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 81: loss -62.22516 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 82: loss -63.18699 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 82: loss -63.45616 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 83: loss -64.42998 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 83: loss -64.70104 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 84: loss -65.68448 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 84: loss -65.95577 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 85: loss -66.95219 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 85: loss -67.22219 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 86: loss -68.23163 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 86: loss -68.50133 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 87: loss -69.52337 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 87: loss -69.79636 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 88: loss -70.82723 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 88: loss -71.10011 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 89: loss -72.14392 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 89: loss -72.41712 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -73.47135 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 90: loss -73.74645 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 91: loss -74.81358 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 91: loss -75.08783 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 92: loss -76.16629 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 92: loss -76.44208 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 93: loss -77.53309 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 93: loss -77.80862 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 94: loss -78.91072 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 94: loss -79.18768 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 95: loss -80.30233 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 95: loss -80.57924 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 96: loss -81.70558 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 96: loss -81.98094 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 97: loss -83.12146 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 97: loss -83.39816 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 98: loss -84.54929 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 98: loss -84.82614 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -85.98971 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 99: loss -86.26676 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss 0.15630 acc 0.33775 roc_auc 0.54490 prc_auc 0.68196[0m
[93maverage test of epoch 0: loss -0.11137 acc 0.32432 roc_auc 0.44000 prc_auc 0.62575[0m
[92maverage training of epoch 1: loss -0.28432 acc 0.33775 roc_auc 0.44882 prc_auc 0.64193[0m
[93maverage test of epoch 1: loss -0.40531 acc 0.32432 roc_auc 0.62000 prc_auc 0.78759[0m
[92maverage training of epoch 2: loss -0.49454 acc 0.33775 roc_auc 0.40000 prc_auc 0.59198[0m
[93maverage test of epoch 2: loss -0.58748 acc 0.32432 roc_auc 0.55667 prc_auc 0.77966[0m
[92maverage training of epoch 3: loss -0.67419 acc 0.33775 roc_auc 0.45529 prc_auc 0.66756[0m
[93maverage test of epoch 3: loss -0.77129 acc 0.32432 roc_auc 0.41667 prc_auc 0.62264[0m
[92maverage training of epoch 4: loss -0.94807 acc 0.33775 roc_auc 0.47608 prc_auc 0.64185[0m
[93maverage test of epoch 4: loss -1.19619 acc 0.32432 roc_auc 0.58333 prc_auc 0.79150[0m
[92maverage training of epoch 5: loss -1.43839 acc 0.44371 roc_auc 0.49020 prc_auc 0.66300[0m
[93maverage test of epoch 5: loss -1.66977 acc 0.59459 roc_auc 0.44667 prc_auc 0.65931[0m
[92maverage training of epoch 6: loss -1.90398 acc 0.62914 roc_auc 0.47373 prc_auc 0.67351[0m
[93maverage test of epoch 6: loss -2.13389 acc 0.67568 roc_auc 0.57000 prc_auc 0.76393[0m
[92maverage training of epoch 7: loss -2.35487 acc 0.66225 roc_auc 0.46529 prc_auc 0.64938[0m
[93maverage test of epoch 7: loss -2.58761 acc 0.67568 roc_auc 0.38000 prc_auc 0.61099[0m
[92maverage training of epoch 8: loss -2.78935 acc 0.66225 roc_auc 0.40294 prc_auc 0.61615[0m
[93maverage test of epoch 8: loss -2.99576 acc 0.67568 roc_auc 0.54000 prc_auc 0.71988[0m
[92maverage training of epoch 9: loss -3.17200 acc 0.66225 roc_auc 0.41373 prc_auc 0.59727[0m
[93maverage test of epoch 9: loss -3.34115 acc 0.67568 roc_auc 0.50333 prc_auc 0.70688[0m
[92maverage training of epoch 10: loss -3.51767 acc 0.66225 roc_auc 0.39922 prc_auc 0.59417[0m
[93maverage test of epoch 10: loss -3.69314 acc 0.67568 roc_auc 0.54667 prc_auc 0.75805[0m
[92maverage training of epoch 11: loss -3.84832 acc 0.66225 roc_auc 0.38765 prc_auc 0.59095[0m
[93maverage test of epoch 11: loss -4.02951 acc 0.67568 roc_auc 0.68333 prc_auc 0.85552[0m
[92maverage training of epoch 12: loss -4.18294 acc 0.66225 roc_auc 0.40059 prc_auc 0.60259[0m
[93maverage test of epoch 12: loss -4.35643 acc 0.67568 roc_auc 0.37333 prc_auc 0.64182[0m
[92maverage training of epoch 13: loss -4.52368 acc 0.66225 roc_auc 0.39824 prc_auc 0.57852[0m
[93maverage test of epoch 13: loss -4.70442 acc 0.67568 roc_auc 0.47000 prc_auc 0.65984[0m
[92maverage training of epoch 14: loss -4.85724 acc 0.66225 roc_auc 0.39314 prc_auc 0.60221[0m
[93maverage test of epoch 14: loss -5.04113 acc 0.67568 roc_auc 0.44000 prc_auc 0.65074[0m
[92maverage training of epoch 15: loss -5.19696 acc 0.66225 roc_auc 0.43510 prc_auc 0.63384[0m
[93maverage test of epoch 15: loss -5.37976 acc 0.67568 roc_auc 0.55000 prc_auc 0.72819[0m
[92maverage training of epoch 16: loss -5.53332 acc 0.66225 roc_auc 0.43098 prc_auc 0.62871[0m
[93maverage test of epoch 16: loss -5.72176 acc 0.67568 roc_auc 0.55667 prc_auc 0.71470[0m
[92maverage training of epoch 17: loss -5.87643 acc 0.66225 roc_auc 0.49510 prc_auc 0.65182[0m
[93maverage test of epoch 17: loss -6.05606 acc 0.67568 roc_auc 0.51667 prc_auc 0.72484[0m
[92maverage training of epoch 18: loss -6.21981 acc 0.66225 roc_auc 0.41412 prc_auc 0.59763[0m
[93maverage test of epoch 18: loss -6.41512 acc 0.67568 roc_auc 0.61333 prc_auc 0.76299[0m
[92maverage training of epoch 19: loss -6.57502 acc 0.66225 roc_auc 0.46471 prc_auc 0.65031[0m
[93maverage test of epoch 19: loss -6.76908 acc 0.67568 roc_auc 0.58000 prc_auc 0.77585[0m
[92maverage training of epoch 20: loss -6.94078 acc 0.66225 roc_auc 0.40922 prc_auc 0.60490[0m
[93maverage test of epoch 20: loss -7.14918 acc 0.67568 roc_auc 0.53333 prc_auc 0.71248[0m
[92maverage training of epoch 21: loss -7.30804 acc 0.66225 roc_auc 0.42686 prc_auc 0.61184[0m
[93maverage test of epoch 21: loss -7.52157 acc 0.67568 roc_auc 0.50667 prc_auc 0.73118[0m
[92maverage training of epoch 22: loss -7.68120 acc 0.66225 roc_auc 0.41314 prc_auc 0.62071[0m
[93maverage test of epoch 22: loss -7.88665 acc 0.67568 roc_auc 0.59000 prc_auc 0.74475[0m
[92maverage training of epoch 23: loss -8.05588 acc 0.66225 roc_auc 0.41882 prc_auc 0.60719[0m
[93maverage test of epoch 23: loss -8.26921 acc 0.67568 roc_auc 0.60333 prc_auc 0.80988[0m
[92maverage training of epoch 24: loss -8.43548 acc 0.66225 roc_auc 0.41255 prc_auc 0.60322[0m
[93maverage test of epoch 24: loss -8.64883 acc 0.67568 roc_auc 0.58333 prc_auc 0.70413[0m
[92maverage training of epoch 25: loss -8.82106 acc 0.66225 roc_auc 0.42765 prc_auc 0.60903[0m
[93maverage test of epoch 25: loss -9.03526 acc 0.67568 roc_auc 0.37333 prc_auc 0.60084[0m
[92maverage training of epoch 26: loss -9.21016 acc 0.66225 roc_auc 0.41392 prc_auc 0.61222[0m
[93maverage test of epoch 26: loss -9.43270 acc 0.67568 roc_auc 0.51000 prc_auc 0.71605[0m
[92maverage training of epoch 27: loss -9.59768 acc 0.66225 roc_auc 0.39961 prc_auc 0.59593[0m
[93maverage test of epoch 27: loss -9.82991 acc 0.67568 roc_auc 0.59667 prc_auc 0.80082[0m
[92maverage training of epoch 28: loss -9.99770 acc 0.66225 roc_auc 0.41686 prc_auc 0.61209[0m
[93maverage test of epoch 28: loss -10.22969 acc 0.67568 roc_auc 0.62333 prc_auc 0.72477[0m
[92maverage training of epoch 29: loss -10.39880 acc 0.66225 roc_auc 0.42010 prc_auc 0.60667[0m
[93maverage test of epoch 29: loss -10.63286 acc 0.67568 roc_auc 0.54667 prc_auc 0.69505[0m
[92maverage training of epoch 30: loss -10.80674 acc 0.66225 roc_auc 0.42529 prc_auc 0.60710[0m
[93maverage test of epoch 30: loss -11.04311 acc 0.67568 roc_auc 0.42333 prc_auc 0.64667[0m
[92maverage training of epoch 31: loss -11.21650 acc 0.66225 roc_auc 0.41000 prc_auc 0.60230[0m
[93maverage test of epoch 31: loss -11.46077 acc 0.67568 roc_auc 0.52667 prc_auc 0.71987[0m
[92maverage training of epoch 32: loss -11.63720 acc 0.66225 roc_auc 0.42333 prc_auc 0.60361[0m
[93maverage test of epoch 32: loss -11.88417 acc 0.67568 roc_auc 0.49667 prc_auc 0.71929[0m
[92maverage training of epoch 33: loss -12.05989 acc 0.66225 roc_auc 0.42529 prc_auc 0.61454[0m
[93maverage test of epoch 33: loss -12.30865 acc 0.67568 roc_auc 0.47333 prc_auc 0.66400[0m
[92maverage training of epoch 34: loss -12.48661 acc 0.66225 roc_auc 0.43588 prc_auc 0.61482[0m
[93maverage test of epoch 34: loss -12.74170 acc 0.67568 roc_auc 0.61667 prc_auc 0.76656[0mUsing backend: pytorch

[92maverage training of epoch 35: loss -12.91940 acc 0.66225 roc_auc 0.42843 prc_auc 0.61511[0m
[93maverage test of epoch 35: loss -13.17822 acc 0.67568 roc_auc 0.51667 prc_auc 0.68742[0m
[92maverage training of epoch 36: loss -13.35812 acc 0.66225 roc_auc 0.41451 prc_auc 0.59944[0m
[93maverage test of epoch 36: loss -13.61889 acc 0.67568 roc_auc 0.61000 prc_auc 0.72012[0m
[92maverage training of epoch 37: loss -13.79979 acc 0.66225 roc_auc 0.40902 prc_auc 0.59437[0m
[93maverage test of epoch 37: loss -14.06455 acc 0.67568 roc_auc 0.41167 prc_auc 0.65317[0m
[92maverage training of epoch 38: loss -14.24613 acc 0.66225 roc_auc 0.40902 prc_auc 0.60035[0m
[93maverage test of epoch 38: loss -14.51749 acc 0.67568 roc_auc 0.33167 prc_auc 0.61445[0m
[92maverage training of epoch 39: loss -14.69764 acc 0.66225 roc_auc 0.41284 prc_auc 0.59929[0m
[93maverage test of epoch 39: loss -14.97571 acc 0.67568 roc_auc 0.52667 prc_auc 0.69043[0m
[92maverage training of epoch 40: loss -15.15472 acc 0.66225 roc_auc 0.41824 prc_auc 0.60148[0m
[93maverage test of epoch 40: loss -15.43188 acc 0.67568 roc_auc 0.29833 prc_auc 0.58285[0m
[92maverage training of epoch 41: loss -15.61653 acc 0.66225 roc_auc 0.42255 prc_auc 0.60826[0m
[93maverage test of epoch 41: loss -15.89956 acc 0.67568 roc_auc 0.54000 prc_auc 0.73521[0m
[92maverage training of epoch 42: loss -16.08197 acc 0.66225 roc_auc 0.39451 prc_auc 0.58755[0m
[93maverage test of epoch 42: loss -16.36863 acc 0.67568 roc_auc 0.51833 prc_auc 0.72596[0m
[92maverage training of epoch 43: loss -16.55164 acc 0.66225 roc_auc 0.40922 prc_auc 0.59400[0m
[93maverage test of epoch 43: loss -16.84414 acc 0.67568 roc_auc 0.50833 prc_auc 0.67857[0m
[92maverage training of epoch 44: loss -17.02868 acc 0.66225 roc_auc 0.42637 prc_auc 0.61682[0m
[93maverage test of epoch 44: loss -17.32447 acc 0.67568 roc_auc 0.66667 prc_auc 0.75975[0m
[92maverage training of epoch 45: loss -17.51005 acc 0.66225 roc_auc 0.41647 prc_auc 0.60153[0m
[93maverage test of epoch 45: loss -17.80952 acc 0.67568 roc_auc 0.44000 prc_auc 0.64625[0m
[92maverage training of epoch 46: loss -17.99644 acc 0.66225 roc_auc 0.41196 prc_auc 0.59979[0m
[93maverage test of epoch 46: loss -18.30336 acc 0.67568 roc_auc 0.36000 prc_auc 0.58499[0m
[92maverage training of epoch 47: loss -18.48734 acc 0.66225 roc_auc 0.42255 prc_auc 0.60580[0m
[93maverage test of epoch 47: loss -18.79964 acc 0.67568 roc_auc 0.37833 prc_auc 0.65894[0m
[92maverage training of epoch 48: loss -18.98627 acc 0.66225 roc_auc 0.41127 prc_auc 0.59856[0m
[93maverage test of epoch 48: loss -19.30016 acc 0.67568 roc_auc 0.52167 prc_auc 0.70416[0m
[92maverage training of epoch 49: loss -19.48851 acc 0.66225 roc_auc 0.40725 prc_auc 0.59762[0m
[93maverage test of epoch 49: loss -19.80697 acc 0.67568 roc_auc 0.37000 prc_auc 0.61008[0m
[92maverage training of epoch 50: loss -19.99861 acc 0.66225 roc_auc 0.42539 prc_auc 0.60666[0m
[93maverage test of epoch 50: loss -20.32424 acc 0.67568 roc_auc 0.64833 prc_auc 0.81947[0m
[92maverage training of epoch 51: loss -20.51296 acc 0.66225 roc_auc 0.41569 prc_auc 0.60142[0m
[93maverage test of epoch 51: loss -20.84338 acc 0.67568 roc_auc 0.44000 prc_auc 0.65061[0m
[92maverage training of epoch 52: loss -21.03323 acc 0.66225 roc_auc 0.41647 prc_auc 0.60223[0m
[93maverage test of epoch 52: loss -21.36838 acc 0.67568 roc_auc 0.57333 prc_auc 0.73791[0m
[92maverage training of epoch 53: loss -21.55896 acc 0.66225 roc_auc 0.40539 prc_auc 0.59300[0m
[93maverage test of epoch 53: loss -21.89912 acc 0.67568 roc_auc 0.51000 prc_auc 0.69395[0m
[92maverage training of epoch 54: loss -22.09145 acc 0.66225 roc_auc 0.41078 prc_auc 0.59693[0m
[93maverage test of epoch 54: loss -22.43666 acc 0.67568 roc_auc 0.53667 prc_auc 0.73024[0m
[92maverage training of epoch 55: loss -22.63029 acc 0.66225 roc_auc 0.41255 prc_auc 0.59657[0m
[93maverage test of epoch 55: loss -22.97998 acc 0.67568 roc_auc 0.43500 prc_auc 0.62008[0m
[92maverage training of epoch 56: loss -23.17410 acc 0.66225 roc_auc 0.41990 prc_auc 0.60964[0m
[93maverage test of epoch 56: loss -23.53061 acc 0.67568 roc_auc 0.60833 prc_auc 0.77679[0m
[92maverage training of epoch 57: loss -23.72391 acc 0.66225 roc_auc 0.41245 prc_auc 0.59943[0m
[93maverage test of epoch 57: loss -24.08330 acc 0.67568 roc_auc 0.57167 prc_auc 0.72613[0m
[92maverage training of epoch 58: loss -24.28070 acc 0.66225 roc_auc 0.41000 prc_auc 0.59683[0m
[93maverage test of epoch 58: loss -24.64729 acc 0.67568 roc_auc 0.58167 prc_auc 0.77911[0m
[92maverage training of epoch 59: loss -24.84267 acc 0.66225 roc_auc 0.41186 prc_auc 0.59924[0m
[93maverage test of epoch 59: loss -25.21309 acc 0.67568 roc_auc 0.52167 prc_auc 0.69043[0m
[92maverage training of epoch 60: loss -25.41068 acc 0.66225 roc_auc 0.41529 prc_auc 0.60168[0m
[93maverage test of epoch 60: loss -25.78712 acc 0.67568 roc_auc 0.60000 prc_auc 0.74612[0m
[92maverage training of epoch 61: loss -25.98431 acc 0.66225 roc_auc 0.41647 prc_auc 0.59996[0m
[93maverage test of epoch 61: loss -26.36654 acc 0.67568 roc_auc 0.52000 prc_auc 0.72657[0m
[92maverage training of epoch 62: loss -26.56477 acc 0.66225 roc_auc 0.41049 prc_auc 0.59616[0m
[93maverage test of epoch 62: loss -26.95150 acc 0.67568 roc_auc 0.49333 prc_auc 0.65378[0m
[92maverage training of epoch 63: loss -27.15107 acc 0.66225 roc_auc 0.41059 prc_auc 0.59650[0m
[93maverage test of epoch 63: loss -27.54350 acc 0.67568 roc_auc 0.46167 prc_auc 0.67888[0m
[92maverage training of epoch 64: loss -27.74299 acc 0.66225 roc_auc 0.41441 prc_auc 0.59796[0m
[93maverage test of epoch 64: loss -28.14150 acc 0.67568 roc_auc 0.49333 prc_auc 0.65886[0m
[92maverage training of epoch 65: loss -28.34192 acc 0.66225 roc_auc 0.41451 prc_auc 0.59867[0m
[93maverage test of epoch 65: loss -28.74506 acc 0.67568 roc_auc 0.49167 prc_auc 0.68142[0m
[92maverage training of epoch 66: loss -28.94631 acc 0.66225 roc_auc 0.41275 prc_auc 0.59581[0m
[93maverage test of epoch 66: loss -29.35552 acc 0.67568 roc_auc 0.35333 prc_auc 0.63385[0m
[92maverage training of epoch 67: loss -29.55676 acc 0.66225 roc_auc 0.41216 prc_auc 0.59723[0m
[93maverage test of epoch 67: loss -29.97039 acc 0.67568 roc_auc 0.66000 prc_auc 0.83033[0m
[92maverage training of epoch 68: loss -30.17329 acc 0.66225 roc_auc 0.41402 prc_auc 0.59846[0m
[93maverage test of epoch 68: loss -30.59311 acc 0.67568 roc_auc 0.34167 prc_auc 0.60406[0m
[92maverage training of epoch 69: loss -30.79614 acc 0.66225 roc_auc 0.41343 prc_auc 0.59857[0m
[93maverage test of epoch 69: loss -31.22131 acc 0.67568 roc_auc 0.47167 prc_auc 0.66347[0m
[92maverage training of epoch 70: loss -31.42497 acc 0.66225 roc_auc 0.41412 prc_auc 0.59790[0m
[93maverage test of epoch 70: loss -31.85535 acc 0.67568 roc_auc 0.52000 prc_auc 0.69086[0m
[92maverage training of epoch 71: loss -32.05999 acc 0.66225 roc_auc 0.41039 prc_auc 0.59707[0m
[93maverage test of epoch 71: loss -32.49653 acc 0.67568 roc_auc 0.39500 prc_auc 0.62900[0m
[92maverage training of epoch 72: loss -32.70075 acc 0.66225 roc_auc 0.41020 prc_auc 0.59672[0m
[93maverage test of epoch 72: loss -33.14365 acc 0.67568 roc_auc 0.57833 prc_auc 0.71335[0m
[92maverage training of epoch 73: loss -33.34758 acc 0.66225 roc_auc 0.41088 prc_auc 0.59574[0m
[93maverage test of epoch 73: loss -33.79596 acc 0.67568 roc_auc 0.51167 prc_auc 0.67980[0m
[92maverage training of epoch 74: loss -34.00137 acc 0.66225 roc_auc 0.41157 prc_auc 0.59868[0m
[93maverage test of epoch 74: loss -34.45484 acc 0.67568 roc_auc 0.38667 prc_auc 0.62794[0m
[92maverage training of epoch 75: loss -34.66045 acc 0.66225 roc_auc 0.41392 prc_auc 0.59701[0m
[93maverage test of epoch 75: loss -35.11962 acc 0.67568 roc_auc 0.49500 prc_auc 0.67491[0m
[92maverage training of epoch 76: loss -35.32607 acc 0.66225 roc_auc 0.41147 prc_auc 0.59654[0m
[93maverage test of epoch 76: loss -35.79040 acc 0.67568 roc_auc 0.50000 prc_auc 0.67606[0m
[92maverage training of epoch 77: loss -35.99794 acc 0.66225 roc_auc 0.41431 prc_auc 0.59697[0m
[93maverage test of epoch 77: loss -36.46821 acc 0.67568 roc_auc 0.48000 prc_auc 0.66703[0m
[92maverage training of epoch 78: loss -36.67563 acc 0.66225 roc_auc 0.41343 prc_auc 0.59569[0m
[93maverage test of epoch 78: loss -37.15140 acc 0.67568 roc_auc 0.50167 prc_auc 0.67641[0m
[92maverage training of epoch 79: loss -37.35932 acc 0.66225 roc_auc 0.41392 prc_auc 0.59790[0m
[93maverage test of epoch 79: loss -37.84143 acc 0.67568 roc_auc 0.56667 prc_auc 0.70656[0m
[92maverage training of epoch 80: loss -38.04892 acc 0.66225 roc_auc 0.41147 prc_auc 0.59896[0m
[93maverage test of epoch 80: loss -38.53675 acc 0.67568 roc_auc 0.52167 prc_auc 0.68531[0m
[92maverage training of epoch 81: loss -38.74450 acc 0.66225 roc_auc 0.41667 prc_auc 0.59831[0m
[93maverage test of epoch 81: loss -39.23754 acc 0.67568 roc_auc 0.52167 prc_auc 0.68531[0m
[92maverage training of epoch 82: loss -39.44555 acc 0.66225 roc_auc 0.41735 prc_auc 0.59911[0m
[93maverage test of epoch 82: loss -39.94454 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 83: loss -40.15224 acc 0.66225 roc_auc 0.41304 prc_auc 0.59880[0m
[93maverage test of epoch 83: loss -40.65722 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 84: loss -40.86492 acc 0.66225 roc_auc 0.41118 prc_auc 0.59941[0m
[93maverage test of epoch 84: loss -41.37514 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 85: loss -41.58304 acc 0.66225 roc_auc 0.40471 prc_auc 0.59452[0m
[93maverage test of epoch 85: loss -42.09958 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 86: loss -42.30735 acc 0.66225 roc_auc 0.41814 prc_auc 0.60368[0m
[93maverage test of epoch 86: loss -42.82942 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 87: loss -43.03715 acc 0.66225 roc_auc 0.41627 prc_auc 0.59983[0m
[93maverage test of epoch 87: loss -43.56512 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 88: loss -43.77321 acc 0.66225 roc_auc 0.41706 prc_auc 0.60663[0m
[93maverage test of epoch 88: loss -44.30682 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 89: loss -44.51493 acc 0.66225 roc_auc 0.40990 prc_auc 0.60182[0m
[93maverage test of epoch 89: loss -45.05437 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 90: loss -45.26244 acc 0.66225 roc_auc 0.42088 prc_auc 0.60862[0m
[93maverage test of epoch 90: loss -45.80775 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 91: loss -46.01588 acc 0.66225 roc_auc 0.41078 prc_auc 0.60586[0m
[93maverage test of epoch 91: loss -46.56716 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 92: loss -46.77533 acc 0.66225 roc_auc 0.40814 prc_auc 0.60494[0m
[93maverage test of epoch 92: loss -47.33295 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 93: loss -47.54075 acc 0.66225 roc_auc 0.40500 prc_auc 0.60849[0m
[93maverage test of epoch 93: loss -48.10441 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 94: loss -48.31213 acc 0.66225 roc_auc 0.42461 prc_auc 0.62066[0m
[93maverage test of epoch 94: loss -48.88174 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 95: loss -49.08951 acc 0.66225 roc_auc 0.41127 prc_auc 0.61594[0m
[93maverage test of epoch 95: loss -49.66519 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 96: loss -49.87284 acc 0.66225 roc_auc 0.42755 prc_auc 0.62734[0m
[93maverage test of epoch 96: loss -50.45441 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 97: loss -50.66204 acc 0.66225 roc_auc 0.40049 prc_auc 0.61636[0m
[93maverage test of epoch 97: loss -51.25001 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 98: loss -51.45740 acc 0.66225 roc_auc 0.41824 prc_auc 0.62287[0m
[93maverage test of epoch 98: loss -52.05169 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 99: loss -52.25864 acc 0.66225 roc_auc 0.43265 prc_auc 0.63415[0m
[93maverage test of epoch 99: loss -52.86015 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss 1.56772 acc 0.33775 roc_auc 0.52471 prc_auc 0.68654[0m
[93maverage test of epoch 0: loss 1.04663 acc 0.32432 roc_auc 0.47667 prc_auc 0.66119[0m
[92maverage training of epoch 1: loss 0.46273 acc 0.33775 roc_auc 0.43765 prc_auc 0.63102[0m
[93maverage test of epoch 1: loss 0.22772 acc 0.32432 roc_auc 0.44000 prc_auc 0.69117[0m
[92maverage training of epoch 2: loss 0.14517 acc 0.33775 roc_auc 0.54412 prc_auc 0.70844[0m
[93maverage test of epoch 2: loss 0.11927 acc 0.32432 roc_auc 0.54333 prc_auc 0.67828[0m
[92maverage training of epoch 3: loss 0.08338 acc 0.33775 roc_auc 0.53725 prc_auc 0.72202[0m
[93maverage test of epoch 3: loss 0.07759 acc 0.32432 roc_auc 0.59000 prc_auc 0.70808[0m
[92maverage training of epoch 4: loss 0.05573 acc 0.33775 roc_auc 0.49882 prc_auc 0.70417[0m
[93maverage test of epoch 4: loss 0.04819 acc 0.32432 roc_auc 0.67333 prc_auc 0.79007[0m
[92maverage training of epoch 5: loss 0.03228 acc 0.33775 roc_auc 0.58549 prc_auc 0.70779[0m
[93maverage test of epoch 5: loss 0.03102 acc 0.32432 roc_auc 0.53000 prc_auc 0.72671[0m
[92maverage training of epoch 6: loss 0.00950 acc 0.33775 roc_auc 0.55902 prc_auc 0.70891[0m
[93maverage test of epoch 6: loss 0.01620 acc 0.32432 roc_auc 0.37000 prc_auc 0.68022[0m
[92maverage training of epoch 7: loss -0.00228 acc 0.33775 roc_auc 0.43098 prc_auc 0.63296[0m
[93maverage test of epoch 7: loss -0.01632 acc 0.32432 roc_auc 0.60000 prc_auc 0.79803[0m
[92maverage training of epoch 8: loss -0.02882 acc 0.33775 roc_auc 0.54431 prc_auc 0.72238[0m
[93maverage test of epoch 8: loss -0.03739 acc 0.32432 roc_auc 0.60333 prc_auc 0.78653[0m
[92maverage training of epoch 9: loss -0.04667 acc 0.33775 roc_auc 0.55608 prc_auc 0.73618[0m
[93maverage test of epoch 9: loss -0.04580 acc 0.32432 roc_auc 0.46000 prc_auc 0.69927[0m
[92maverage training of epoch 10: loss -0.06381 acc 0.33775 roc_auc 0.51647 prc_auc 0.67121[0m
[93maverage test of epoch 10: loss -0.07717 acc 0.32432 roc_auc 0.69333 prc_auc 0.82262[0m
[92maverage training of epoch 11: loss -0.07959 acc 0.33775 roc_auc 0.50784 prc_auc 0.65894[0m
[93maverage test of epoch 11: loss -0.09267 acc 0.32432 roc_auc 0.58000 prc_auc 0.78881[0m
[92maverage training of epoch 12: loss -0.10348 acc 0.33775 roc_auc 0.58255 prc_auc 0.73894[0m
[93maverage test of epoch 12: loss -0.10629 acc 0.32432 roc_auc 0.60667 prc_auc 0.77152[0m
[92maverage training of epoch 13: loss -0.12183 acc 0.33775 roc_auc 0.56706 prc_auc 0.75169[0m
[93maverage test of epoch 13: loss -0.13165 acc 0.32432 roc_auc 0.68333 prc_auc 0.81128[0m
[92maverage training of epoch 14: loss -0.13828 acc 0.33775 roc_auc 0.56725 prc_auc 0.70163[0m
[93maverage test of epoch 14: loss -0.15199 acc 0.32432 roc_auc 0.74667 prc_auc 0.84774[0m
[92maverage training of epoch 15: loss -0.15634 acc 0.33775 roc_auc 0.59392 prc_auc 0.74303[0m
[93maverage test of epoch 15: loss -0.15876 acc 0.32432 roc_auc 0.55000 prc_auc 0.76701[0m
[92maverage training of epoch 16: loss -0.17543 acc 0.33775 roc_auc 0.54157 prc_auc 0.72769[0m
[93maverage test of epoch 16: loss -0.18316 acc 0.32432 roc_auc 0.62000 prc_auc 0.75247[0m
[92maverage training of epoch 17: loss -0.19420 acc 0.34437 roc_auc 0.54373 prc_auc 0.71974[0m
[93maverage test of epoch 17: loss -0.19920 acc 0.32432 roc_auc 0.52333 prc_auc 0.78691[0m
[92maverage training of epoch 18: loss -0.21455 acc 0.33775 roc_auc 0.51667 prc_auc 0.69429[0m
[93maverage test of epoch 18: loss -0.21972 acc 0.32432 roc_auc 0.55000 prc_auc 0.73953[0m
[92maverage training of epoch 19: loss -0.24057 acc 0.33775 roc_auc 0.57549 prc_auc 0.73175[0m
[93maverage test of epoch 19: loss -0.24799 acc 0.32432 roc_auc 0.64000 prc_auc 0.80576[0m
[92maverage training of epoch 20: loss -0.27360 acc 0.33775 roc_auc 0.69000 prc_auc 0.81714[0m
[93maverage test of epoch 20: loss -0.27671 acc 0.32432 roc_auc 0.69333 prc_auc 0.83203[0m
[92maverage training of epoch 21: loss -0.29704 acc 0.33775 roc_auc 0.64373 prc_auc 0.78676[0m
[93maverage test of epoch 21: loss -0.31053 acc 0.32432 roc_auc 0.76667 prc_auc 0.86979[0m
[92maverage training of epoch 22: loss -0.33062 acc 0.33775 roc_auc 0.73471 prc_auc 0.86217[0m
[93maverage test of epoch 22: loss -0.34123 acc 0.32432 roc_auc 0.78667 prc_auc 0.89491[0m
[92maverage training of epoch 23: loss -0.35954 acc 0.33775 roc_auc 0.66412 prc_auc 0.82228[0m
[93maverage test of epoch 23: loss -0.37201 acc 0.32432 roc_auc 0.74667 prc_auc 0.87283[0m
[92maverage training of epoch 24: loss -0.40661 acc 0.33775 roc_auc 0.75020 prc_auc 0.86492[0m
[93maverage test of epoch 24: loss -0.40447 acc 0.32432 roc_auc 0.67333 prc_auc 0.85105[0m
[92maverage training of epoch 25: loss -0.44615 acc 0.35099 roc_auc 0.76882 prc_auc 0.86799[0m
[93maverage test of epoch 25: loss -0.48222 acc 0.32432 roc_auc 0.82667 prc_auc 0.92272[0m
[92maverage training of epoch 26: loss -0.52899 acc 0.35099 roc_auc 0.85333 prc_auc 0.91966[0m
[93maverage test of epoch 26: loss -0.53663 acc 0.32432 roc_auc 0.80000 prc_auc 0.91647[0m
[92maverage training of epoch 27: loss -0.57989 acc 0.33775 roc_auc 0.85549 prc_auc 0.91803[0m
[93maverage test of epoch 27: loss -0.62569 acc 0.32432 roc_auc 0.91333 prc_auc 0.96377[0m
[92maverage training of epoch 28: loss -0.64646 acc 0.34437 roc_auc 0.84118 prc_auc 0.91777[0m
[93maverage test of epoch 28: loss -0.69149 acc 0.32432 roc_auc 0.92333 prc_auc 0.96428[0m
[92maverage training of epoch 29: loss -0.72030 acc 0.33775 roc_auc 0.87980 prc_auc 0.94205[0m
[93maverage test of epoch 29: loss -0.72908 acc 0.32432 roc_auc 0.86333 prc_auc 0.94672[0m
[92maverage training of epoch 30: loss -0.75820 acc 0.33775 roc_auc 0.85569 prc_auc 0.91543[0m
[93maverage test of epoch 30: loss -0.81496 acc 0.32432 roc_auc 0.88333 prc_auc 0.95616[0m
[92maverage training of epoch 31: loss -0.81500 acc 0.33775 roc_auc 0.85118 prc_auc 0.92621[0m
[93maverage test of epoch 31: loss -0.87387 acc 0.32432 roc_auc 0.93667 prc_auc 0.97162[0m
[92maverage training of epoch 32: loss -0.88892 acc 0.33775 roc_auc 0.86098 prc_auc 0.92810[0m
[93maverage test of epoch 32: loss -0.90750 acc 0.32432 roc_auc 0.88000 prc_auc 0.94936[0m
[92maverage training of epoch 33: loss -0.97178 acc 0.33775 roc_auc 0.88569 prc_auc 0.94505[0m
[93maverage test of epoch 33: loss -1.03596 acc 0.32432 roc_auc 0.89667 prc_auc 0.95920[0m
[92maverage training of epoch 34: loss -1.02879 acc 0.33775 roc_auc 0.89588 prc_auc 0.94821[0m
[93maverage test of epoch 34: loss -1.07700 acc 0.32432 roc_auc 0.94667 prc_auc 0.97919[0m
[92maverage training of epoch 35: loss -1.10581 acc 0.33775 roc_auc 0.89941 prc_auc 0.94748[0m
[93maverage test of epoch 35: loss -1.14497 acc 0.32432 roc_auc 0.91667 prc_auc 0.96711[0m
[92maverage training of epoch 36: loss -1.14767 acc 0.33775 roc_auc 0.88020 prc_auc 0.93766[0m
[93maverage test of epoch 36: loss -1.20858 acc 0.32432 roc_auc 0.85333 prc_auc 0.94295[0m
[92maverage training of epoch 37: loss -1.22498 acc 0.33775 roc_auc 0.86157 prc_auc 0.92695[0m
[93maverage test of epoch 37: loss -1.28465 acc 0.32432 roc_auc 0.93667 prc_auc 0.97385[0m
[92maverage training of epoch 38: loss -1.28865 acc 0.33775 roc_auc 0.88020 prc_auc 0.93954[0m
[93maverage test of epoch 38: loss -1.36770 acc 0.32432 roc_auc 0.89667 prc_auc 0.96161[0m
[92maverage training of epoch 39: loss -1.38868 acc 0.33775 roc_auc 0.88804 prc_auc 0.94591[0m
[93maverage test of epoch 39: loss -1.38820 acc 0.32432 roc_auc 0.90000 prc_auc 0.95897[0m
[92maverage training of epoch 40: loss -1.43525 acc 0.33775 roc_auc 0.91078 prc_auc 0.95694[0m
[93maverage test of epoch 40: loss -1.51040 acc 0.32432 roc_auc 0.93333 prc_auc 0.97440[0m
[92maverage training of epoch 41: loss -1.51496 acc 0.33775 roc_auc 0.91216 prc_auc 0.95749[0m
[93maverage test of epoch 41: loss -1.59737 acc 0.32432 roc_auc 0.97000 prc_auc 0.98941[0m
[92maverage training of epoch 42: loss -1.58500 acc 0.33775 roc_auc 0.91157 prc_auc 0.95630[0m
[93maverage test of epoch 42: loss -1.61890 acc 0.32432 roc_auc 0.96000 prc_auc 0.98314[0m
[92maverage training of epoch 43: loss -1.60899 acc 0.33775 roc_auc 0.89824 prc_auc 0.94310[0m
[93maverage test of epoch 43: loss -1.65568 acc 0.32432 roc_auc 0.91000 prc_auc 0.96445[0m
[92maverage training of epoch 44: loss -1.75525 acc 0.33775 roc_auc 0.91706 prc_auc 0.95920[0m
[93maverage test of epoch 44: loss -1.80569 acc 0.32432 roc_auc 0.93000 prc_auc 0.97006[0m
[92maverage training of epoch 45: loss -1.81264 acc 0.33775 roc_auc 0.89235 prc_auc 0.94454[0m
[93maverage test of epoch 45: loss -1.83601 acc 0.32432 roc_auc 0.92333 prc_auc 0.96708[0m
[92maverage training of epoch 46: loss -1.89939 acc 0.33775 roc_auc 0.89314 prc_auc 0.95047[0m
[93maverage test of epoch 46: loss -1.94612 acc 0.32432 roc_auc 0.84333 prc_auc 0.93682[0m
[92maverage training of epoch 47: loss -2.01176 acc 0.33775 roc_auc 0.89039 prc_auc 0.94871[0m
[93maverage test of epoch 47: loss -2.06326 acc 0.32432 roc_auc 0.90000 prc_auc 0.96084[0m
[92maverage training of epoch 48: loss -2.07808 acc 0.33775 roc_auc 0.89078 prc_auc 0.94304[0m
[93maverage test of epoch 48: loss -2.04905 acc 0.32432 roc_auc 0.91000 prc_auc 0.96320[0m
[92maverage training of epoch 49: loss -2.14204 acc 0.33775 roc_auc 0.88176 prc_auc 0.93337[0m
[93maverage test of epoch 49: loss -2.18053 acc 0.32432 roc_auc 0.90000 prc_auc 0.95584[0m
[92maverage training of epoch 50: loss -2.26257 acc 0.33775 roc_auc 0.86882 prc_auc 0.92883[0m
[93maverage test of epoch 50: loss -2.35455 acc 0.32432 roc_auc 0.83000 prc_auc 0.93517[0m
[92maverage training of epoch 51: loss -2.34059 acc 0.33775 roc_auc 0.88275 prc_auc 0.94244[0m
[93maverage test of epoch 51: loss -2.47297 acc 0.32432 roc_auc 0.84667 prc_auc 0.94011[0m
[92maverage training of epoch 52: loss -2.49423 acc 0.33775 roc_auc 0.92157 prc_auc 0.96224[0m
[93maverage test of epoch 52: loss -2.57368 acc 0.32432 roc_auc 0.95667 prc_auc 0.98000[0m
[92maverage training of epoch 53: loss -2.61349 acc 0.33775 roc_auc 0.87510 prc_auc 0.93679[0m
[93maverage test of epoch 53: loss -2.69242 acc 0.32432 roc_auc 0.90667 prc_auc 0.95452[0m
[92maverage training of epoch 54: loss -2.73741 acc 0.33775 roc_auc 0.89333 prc_auc 0.94546[0m
[93maverage test of epoch 54: loss -2.81642 acc 0.32432 roc_auc 0.89667 prc_auc 0.96084[0m
[92maverage training of epoch 55: loss -2.91200 acc 0.33775 roc_auc 0.85627 prc_auc 0.93540[0m
[93maverage test of epoch 55: loss -2.93561 acc 0.32432 roc_auc 0.81333 prc_auc 0.91615[0m
[92maverage training of epoch 56: loss -3.03748 acc 0.33775 roc_auc 0.82255 prc_auc 0.91062[0m
[93maverage test of epoch 56: loss -3.06559 acc 0.32432 roc_auc 0.76333 prc_auc 0.89741[0m
[92maverage training of epoch 57: loss -3.22345 acc 0.33775 roc_auc 0.76314 prc_auc 0.88612[0m
[93maverage test of epoch 57: loss -3.22271 acc 0.32432 roc_auc 0.72000 prc_auc 0.85422[0m
[92maverage training of epoch 58: loss -3.38831 acc 0.33775 roc_auc 0.64118 prc_auc 0.81001[0m
[93maverage test of epoch 58: loss -3.41005 acc 0.32432 roc_auc 0.65667 prc_auc 0.82246[0m
[92maverage training of epoch 59: loss -3.59046 acc 0.33775 roc_auc 0.61235 prc_auc 0.77932[0m
[93maverage test of epoch 59: loss -3.58944 acc 0.32432 roc_auc 0.60333 prc_auc 0.71058[0m
[92maverage training of epoch 60: loss -3.77860 acc 0.33775 roc_auc 0.60255 prc_auc 0.73217[0m
[93maverage test of epoch 60: loss -3.78223 acc 0.32432 roc_auc 0.61667 prc_auc 0.73689[0m
[92maverage training of epoch 61: loss -3.96958 acc 0.33775 roc_auc 0.58706 prc_auc 0.70302[0m
[93maverage test of epoch 61: loss -3.97636 acc 0.32432 roc_auc 0.40333 prc_auc 0.65958[0m
[92maverage training of epoch 62: loss -4.16770 acc 0.33775 roc_auc 0.49471 prc_auc 0.65282[0m
[93maverage test of epoch 62: loss -4.18005 acc 0.32432 roc_auc 0.55000 prc_auc 0.75518[0m
[92maverage training of epoch 63: loss -4.38649 acc 0.33775 roc_auc 0.61235 prc_auc 0.74010[0m
[93maverage test of epoch 63: loss -4.39774 acc 0.32432 roc_auc 0.69333 prc_auc 0.79368[0m
[92maverage training of epoch 64: loss -4.59655 acc 0.33775 roc_auc 0.56941 prc_auc 0.72923[0m
[93maverage test of epoch 64: loss -4.61652 acc 0.32432 roc_auc 0.64667 prc_auc 0.76780[0m
[92maverage training of epoch 65: loss -4.82472 acc 0.33775 roc_auc 0.57275 prc_auc 0.70953[0m
[93maverage test of epoch 65: loss -4.83737 acc 0.32432 roc_auc 0.67333 prc_auc 0.80039[0m
[92maverage training of epoch 66: loss -5.05552 acc 0.33775 roc_auc 0.56941 prc_auc 0.70728[0m
[93maverage test of epoch 66: loss -5.06725 acc 0.32432 roc_auc 0.54667 prc_auc 0.74332[0m
[92maverage training of epoch 67: loss -5.30120 acc 0.33775 roc_auc 0.56863 prc_auc 0.69793[0m
[93maverage test of epoch 67: loss -5.30129 acc 0.32432 roc_auc 0.45333 prc_auc 0.67746[0m
[92maverage training of epoch 68: loss -5.54140 acc 0.33775 roc_auc 0.55333 prc_auc 0.68093[0m
[93maverage test of epoch 68: loss -5.57162 acc 0.32432 roc_auc 0.52000 prc_auc 0.73509[0m
[92maverage training of epoch 69: loss -5.80685 acc 0.33775 roc_auc 0.58078 prc_auc 0.70395[0m
[93maverage test of epoch 69: loss -5.84184 acc 0.32432 roc_auc 0.42000 prc_auc 0.69412[0m
[92maverage training of epoch 70: loss -6.07466 acc 0.33775 roc_auc 0.55480 prc_auc 0.70911[0m
[93maverage test of epoch 70: loss -6.10400 acc 0.32432 roc_auc 0.58000 prc_auc 0.77780[0m
[92maverage training of epoch 71: loss -6.34125 acc 0.33775 roc_auc 0.53941 prc_auc 0.68958[0m
[93maverage test of epoch 71: loss -6.36608 acc 0.32432 roc_auc 0.39333 prc_auc 0.66649[0m
[92maverage training of epoch 72: loss -6.62216 acc 0.33775 roc_auc 0.61216 prc_auc 0.74211[0m
[93maverage test of epoch 72: loss -6.65035 acc 0.32432 roc_auc 0.60000 prc_auc 0.77660[0m
[92maverage training of epoch 73: loss -6.90979 acc 0.33775 roc_auc 0.56294 prc_auc 0.70752[0m
[93maverage test of epoch 73: loss -6.92432 acc 0.32432 roc_auc 0.44333 prc_auc 0.62788[0m
[92maverage training of epoch 74: loss -7.19009 acc 0.33775 roc_auc 0.52137 prc_auc 0.66324[0m
[93maverage test of epoch 74: loss -7.22246 acc 0.32432 roc_auc 0.82000 prc_auc 0.90708[0m
[92maverage training of epoch 75: loss -7.48816 acc 0.33775 roc_auc 0.60176 prc_auc 0.74677[0m
[93maverage test of epoch 75: loss -7.50165 acc 0.32432 roc_auc 0.60667 prc_auc 0.78476[0m
[92maverage training of epoch 76: loss -7.77824 acc 0.33775 roc_auc 0.51804 prc_auc 0.68136[0m
[93maverage test of epoch 76: loss -7.79703 acc 0.32432 roc_auc 0.44333 prc_auc 0.72631[0m
[92maverage training of epoch 77: loss -8.08479 acc 0.33775 roc_auc 0.54922 prc_auc 0.71240[0m
[93maverage test of epoch 77: loss -8.10539 acc 0.32432 roc_auc 0.54000 prc_auc 0.79379[0m
[92maverage training of epoch 78: loss -8.39193 acc 0.33775 roc_auc 0.56549 prc_auc 0.72447[0m
[93maverage test of epoch 78: loss -8.40494 acc 0.32432 roc_auc 0.46333 prc_auc 0.72792[0m
[92maverage training of epoch 79: loss -8.70479 acc 0.33775 roc_auc 0.55431 prc_auc 0.71083[0m
[93maverage test of epoch 79: loss -8.72087 acc 0.32432 roc_auc 0.48333 prc_auc 0.68673[0m
[92maverage training of epoch 80: loss -9.02371 acc 0.33775 roc_auc 0.58196 prc_auc 0.72386[0m
[93maverage test of epoch 80: loss -9.03860 acc 0.32432 roc_auc 0.62667 prc_auc 0.76865[0m
[92maverage training of epoch 81: loss -9.34213 acc 0.33775 roc_auc 0.58353 prc_auc 0.74695[0m
[93maverage test of epoch 81: loss -9.36773 acc 0.32432 roc_auc 0.45333 prc_auc 0.66577[0m
[92maverage training of epoch 82: loss -9.67797 acc 0.33775 roc_auc 0.56569 prc_auc 0.72421[0m
[93maverage test of epoch 82: loss -9.68835 acc 0.32432 roc_auc 0.55000 prc_auc 0.71741[0m
[92maverage training of epoch 83: loss -10.01430 acc 0.33775 roc_auc 0.56922 prc_auc 0.74114[0m
[93maverage test of epoch 83: loss -10.03608 acc 0.32432 roc_auc 0.66667 prc_auc 0.79169[0m
[92maverage training of epoch 84: loss -10.35472 acc 0.33775 roc_auc 0.55804 prc_auc 0.70074[0m
[93maverage test of epoch 84: loss -10.36855 acc 0.32432 roc_auc 0.41333 prc_auc 0.69944[0m
[92maverage training of epoch 85: loss -10.70123 acc 0.33775 roc_auc 0.54902 prc_auc 0.67720[0m
[93maverage test of epoch 85: loss -10.71289 acc 0.32432 roc_auc 0.43667 prc_auc 0.69475[0m
[92maverage training of epoch 86: loss -11.05728 acc 0.33775 roc_auc 0.58863 prc_auc 0.73450[0m
[93maverage test of epoch 86: loss -11.08391 acc 0.32432 roc_auc 0.58667 prc_auc 0.77528[0m
[92maverage training of epoch 87: loss -11.42111 acc 0.33775 roc_auc 0.54647 prc_auc 0.71176[0m
[93maverage test of epoch 87: loss -11.42470 acc 0.32432 roc_auc 0.40000 prc_auc 0.63262[0m
[92maverage training of epoch 88: loss -11.78267 acc 0.33775 roc_auc 0.50843 prc_auc 0.63794[0m
[93maverage test of epoch 88: loss -11.79527 acc 0.32432 roc_auc 0.43167 prc_auc 0.64617[0m
[92maverage training of epoch 89: loss -12.16242 acc 0.33775 roc_auc 0.55490 prc_auc 0.68025[0m
[93maverage test of epoch 89: loss -12.17758 acc 0.32432 roc_auc 0.45333 prc_auc 0.73076[0m
[92maverage training of epoch 90: loss -12.53997 acc 0.33775 roc_auc 0.54353 prc_auc 0.67902[0m
[93maverage test of epoch 90: loss -12.55581 acc 0.32432 roc_auc 0.50000 prc_auc 0.73182[0m
[92maverage training of epoch 91: loss -12.92589 acc 0.33775 roc_auc 0.57412 prc_auc 0.73383[0m
[93maverage test of epoch 91: loss -12.94255 acc 0.32432 roc_auc 0.52667 prc_auc 0.71762[0m
[92maverage training of epoch 92: loss -13.31742 acc 0.33775 roc_auc 0.56471 prc_auc 0.70592[0m
[93maverage test of epoch 92: loss -13.34019 acc 0.32432 roc_auc 0.42000 prc_auc 0.64993[0m
[92maverage training of epoch 93: loss -13.65473 acc 0.33775 roc_auc 0.54843 prc_auc 0.69418[0m
[93maverage test of epoch 93: loss -13.73677 acc 0.32432 roc_auc 0.41333 prc_auc 0.64894[0m
[92maverage training of epoch 94: loss -14.12457 acc 0.33775 roc_auc 0.54588 prc_auc 0.68072[0m
[93maverage test of epoch 94: loss -14.14447 acc 0.32432 roc_auc 0.57000 prc_auc 0.71287[0m
[92maverage training of epoch 95: loss -14.53531 acc 0.33775 roc_auc 0.53882 prc_auc 0.67463[0m
[93maverage test of epoch 95: loss -14.55300 acc 0.32432 roc_auc 0.42333 prc_auc 0.64776[0m
[92maverage training of epoch 96: loss -14.95354 acc 0.33775 roc_auc 0.54902 prc_auc 0.68109[0m
[93maverage test of epoch 96: loss -14.97572 acc 0.32432 roc_auc 0.43000 prc_auc 0.64586[0m
[92maverage training of epoch 97: loss -15.38437 acc 0.33775 roc_auc 0.59333 prc_auc 0.73040[0m
[93maverage test of epoch 97: loss -15.41010 acc 0.32432 roc_auc 0.57333 prc_auc 0.73291[0m
[92maverage training of epoch 98: loss -15.81440 acc 0.33775 roc_auc 0.56118 prc_auc 0.69630[0m
[93maverage test of epoch 98: loss -15.84040 acc 0.32432 roc_auc 0.57000 prc_auc 0.73110[0m
[92maverage training of epoch 99: loss -16.25460 acc 0.33775 roc_auc 0.60020 prc_auc 0.72730[0m
[93maverage test of epoch 99: loss -16.27911 acc 0.32432 roc_auc 0.56667 prc_auc 0.70984[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 1)
('lr', 0.0001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.59474 ROC_AUC (avg): 0.51333 PRC_AUC (avg): 0.67184 

Average forward propagation time taken(ms): 4.270742588105875
Average backward propagation time taken(ms): 1.5780911701520848

