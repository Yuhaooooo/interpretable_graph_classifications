# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 2)
('lr', 0.0003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-19-25-50/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-19-25-50/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 16,
 'epochs': 50,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 8,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.0003,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 1,
 'num_workers': 8,
 'number_of_mlp_layer': 2,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-17-19-25-50',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 50, 'learning_rate': 0.0003, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=8, bias=True)
    (ReLU1): ReLU()
    (Linear2): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss 0.10702 acc 0.33333 roc_auc 0.61200 prc_auc 0.79600[0m
[93maverage test of epoch 0: loss -0.35916 acc 0.34211 roc_auc 0.86462 prc_auc 0.93409[0m
[92maverage training of epoch 1: loss -0.72785 acc 0.33333 roc_auc 0.77020 prc_auc 0.88923[0m
[93maverage test of epoch 1: loss -1.14880 acc 0.34211 roc_auc 0.86154 prc_auc 0.93308[0m
[92maverage training of epoch 2: loss -1.41937 acc 0.33333 roc_auc 0.82540 prc_auc 0.91794[0m
[93maverage test of epoch 2: loss -1.76937 acc 0.34211 roc_auc 0.86462 prc_auc 0.93409[0m
[92maverage training of epoch 3: loss -2.06296 acc 0.33333 roc_auc 0.84020 prc_auc 0.92514[0m
[93maverage test of epoch 3: loss -2.53265 acc 0.34211 roc_auc 0.87385 prc_auc 0.93759[0m
[92maverage training of epoch 4: loss -3.01204 acc 0.33333 roc_auc 0.79300 prc_auc 0.90763[0m
[93maverage test of epoch 4: loss -3.73951 acc 0.34211 roc_auc 0.86462 prc_auc 0.93813[0m
[92maverage training of epoch 5: loss -4.48629 acc 0.33333 roc_auc 0.70100 prc_auc 0.86349[0m
[93maverage test of epoch 5: loss -5.59045 acc 0.34211 roc_auc 0.85846 prc_auc 0.93430[0m
[92maverage training of epoch 6: loss -6.72936 acc 0.33333 roc_auc 0.60240 prc_auc 0.76639[0m
[93maverage test of epoch 6: loss -8.19106 acc 0.34211 roc_auc 0.87385 prc_auc 0.94350[0m
[92maverage training of epoch 7: loss -9.58174 acc 0.33333 roc_auc 0.57820 prc_auc 0.73096[0m
[93maverage test of epoch 7: loss -11.32075 acc 0.34211 roc_auc 0.88615 prc_auc 0.95070[0m
[92maverage training of epoch 8: loss -12.97092 acc 0.33333 roc_auc 0.57060 prc_auc 0.71799[0m
[93maverage test of epoch 8: loss -15.01237 acc 0.34211 roc_auc 0.89385 prc_auc 0.95578[0m
[92maverage training of epoch 9: loss -16.99036 acc 0.33333 roc_auc 0.56020 prc_auc 0.70438[0m
[93maverage test of epoch 9: loss -19.43357 acc 0.34211 roc_auc 0.91385 prc_auc 0.96155[0m
[92maverage training of epoch 10: loss -21.84366 acc 0.33333 roc_auc 0.57220 prc_auc 0.71818[0m
[93maverage test of epoch 10: loss -24.79070 acc 0.34211 roc_auc 0.89846 prc_auc 0.95562[0m
[92maverage training of epoch 11: loss -27.76265 acc 0.33333 roc_auc 0.57580 prc_auc 0.72237[0m
[93maverage test of epoch 11: loss -31.33589 acc 0.34211 roc_auc 0.88769 prc_auc 0.94819[0m
[92maverage training of epoch 12: loss -34.88870 acc 0.33333 roc_auc 0.57660 prc_auc 0.72348[0m
[93maverage test of epoch 12: loss -39.07859 acc 0.34211 roc_auc 0.88154 prc_auc 0.94373[0m
[92maverage training of epoch 13: loss -43.22955 acc 0.33333 roc_auc 0.57680 prc_auc 0.72372[0m
[93maverage test of epoch 13: loss -48.06845 acc 0.34211 roc_auc 0.86308 prc_auc 0.93185[0m
[92maverage training of epoch 14: loss -52.74643 acc 0.33333 roc_auc 0.57680 prc_auc 0.72372[0m
[93maverage test of epoch 14: loss -58.13228 acc 0.34211 roc_auc 0.79231 prc_auc 0.89480[0m
[92maverage training of epoch 15: loss -63.26930 acc 0.33333 roc_auc 0.57540 prc_auc 0.72169[0m
[93maverage test of epoch 15: loss -69.21192 acc 0.34211 roc_auc 0.75538 prc_auc 0.87861[0m
[92maverage training of epoch 16: loss -74.86526 acc 0.33333 roc_auc 0.57350 prc_auc 0.71915[0m
[93maverage test of epoch 16: loss -81.39730 acc 0.34211 roc_auc 0.78462 prc_auc 0.87402[0m
[92maverage training of epoch 17: loss -87.60160 acc 0.33333 roc_auc 0.57260 prc_auc 0.71833[0m
[93maverage test of epoch 17: loss -94.76974 acc 0.34211 roc_auc 0.83231 prc_auc 0.89279[0m
[92maverage training of epoch 18: loss -101.59475 acc 0.33333 roc_auc 0.57360 prc_auc 0.71886[0m
[93maverage test of epoch 18: loss -109.47024 acc 0.34211 roc_auc 0.66154 prc_auc 0.80527[0m
[92maverage training of epoch 19: loss -116.99453 acc 0.33333 roc_auc 0.57500 prc_auc 0.72012[0m
[93maverage test of epoch 19: loss -125.65679 acc 0.34211 roc_auc 0.42769 prc_auc 0.67720[0m
[92maverage training of epoch 20: loss -133.95574 acc 0.33333 roc_auc 0.57700 prc_auc 0.72266[0m
[93maverage test of epoch 20: loss -143.47333 acc 0.34211 roc_auc 0.71077 prc_auc 0.80856[0m
[92maverage training of epoch 21: loss -152.54067 acc 0.33333 roc_auc 0.57720 prc_auc 0.72327[0m
[93maverage test of epoch 21: loss -162.89598 acc 0.34211 roc_auc 0.63231 prc_auc 0.74149[0m
[92maverage training of epoch 22: loss -172.69743 acc 0.33333 roc_auc 0.57440 prc_auc 0.72017[0m
[93maverage test of epoch 22: loss -183.88757 acc 0.34211 roc_auc 0.56615 prc_auc 0.73342[0m
[92maverage training of epoch 23: loss -194.43028 acc 0.33333 roc_auc 0.57130 prc_auc 0.71721[0m
[93maverage test of epoch 23: loss -206.47850 acc 0.34211 roc_auc 0.44000 prc_auc 0.67853[0m
[92maverage training of epoch 24: loss -217.80038 acc 0.33333 roc_auc 0.56460 prc_auc 0.71110[0m
[93maverage test of epoch 24: loss -230.74778 acc 0.34211 roc_auc 0.58462 prc_auc 0.71714[0m
[92maverage training of epoch 25: loss -242.90664 acc 0.33333 roc_auc 0.55500 prc_auc 0.70282[0m
[93maverage test of epoch 25: loss -256.83039 acc 0.34211 roc_auc 0.60000 prc_auc 0.76173[0m
[92maverage training of epoch 26: loss -269.92749 acc 0.33333 roc_auc 0.54240 prc_auc 0.69306[0m
[93maverage test of epoch 26: loss -284.93526 acc 0.34211 roc_auc 0.56000 prc_auc 0.69895[0m
[92maverage training of epoch 27: loss -299.04938 acc 0.33333 roc_auc 0.52150 prc_auc 0.67337[0m
[93maverage test of epoch 27: loss -315.21335 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -330.42242 acc 0.33333 roc_auc 0.47870 prc_auc 0.64413[0m
[93maverage test of epoch 28: loss -347.81737 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -364.20160 acc 0.33333 roc_auc 0.44890 prc_auc 0.61616[0m
[93maverage test of epoch 29: loss -382.90120 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -400.53600 acc 0.33333 roc_auc 0.43740 prc_auc 0.62639[0m
[93maverage test of epoch 30: loss -420.60137 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -439.49418 acc 0.33333 roc_auc 0.42420 prc_auc 0.62095[0m
[93maverage test of epoch 31: loss -460.85253 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -480.94605 acc 0.33333 roc_auc 0.38720 prc_auc 0.60376[0m
[93maverage test of epoch 32: loss -503.53620 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -524.84910 acc 0.33333 roc_auc 0.37100 prc_auc 0.59049[0m
[93maverage test of epoch 33: loss -548.69341 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -571.26706 acc 0.33333 roc_auc 0.37430 prc_auc 0.58528[0m
[93maverage test of epoch 34: loss -596.39970 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -620.27455 acc 0.33333 roc_auc 0.36760 prc_auc 0.57866[0m
[93maverage test of epoch 35: loss -646.72831 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -671.94535 acc 0.33333 roc_auc 0.36180 prc_auc 0.57477[0m
[93maverage test of epoch 36: loss -699.75296 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -726.35303 acc 0.33333 roc_auc 0.35990 prc_auc 0.57154[0m
[93maverage test of epoch 37: loss -755.54705 acc 0.34211 roc_auc 0.52000 prc_auc 0.67158[0m
[92maverage training of epoch 38: loss -783.57231 acc 0.33333 roc_auc 0.36000 prc_auc 0.57009[0m
[93maverage test of epoch 38: loss -814.18600 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -843.67752 acc 0.33333 roc_auc 0.36120 prc_auc 0.56898[0m
[93maverage test of epoch 39: loss -875.74177 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -906.74175 acc 0.33333 roc_auc 0.36220 prc_auc 0.56856[0m
[93maverage test of epoch 40: loss -940.29088 acc 0.34211 roc_auc 0.52000 prc_auc 0.67158[0m
[92maverage training of epoch 41: loss -972.84072 acc 0.33333 roc_auc 0.36240 prc_auc 0.56825[0m
[93maverage test of epoch 41: loss -1007.90320 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -1042.04556 acc 0.33333 roc_auc 0.36300 prc_auc 0.56794[0m
[93maverage test of epoch 42: loss -1078.65529 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -1114.43267 acc 0.33333 roc_auc 0.35980 prc_auc 0.56408[0m
[93maverage test of epoch 43: loss -1152.62111 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -1190.07447 acc 0.33333 roc_auc 0.35760 prc_auc 0.56507[0m
[93maverage test of epoch 44: loss -1229.87106 acc 0.34211 roc_auc 0.48000 prc_auc 0.64902[0m
[92maverage training of epoch 45: loss -1269.04503 acc 0.33333 roc_auc 0.35880 prc_auc 0.56618[0m
[93maverage test of epoch 45: loss -1310.48086 acc 0.34211 roc_auc 0.52000 prc_auc 0.67158[0m
[92maverage training of epoch 46: loss -1351.41622 acc 0.33333 roc_auc 0.35880 prc_auc 0.56758[0m
[93maverage test of epoch 46: loss -1394.52140 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -1437.26240 acc 0.33333 roc_auc 0.35940 prc_auc 0.56793[0m
[93maverage test of epoch 47: loss -1482.06786 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -1526.65608 acc 0.33333 roc_auc 0.36100 prc_auc 0.56980[0m
[93maverage test of epoch 48: loss -1573.19143 acc 0.34211 roc_auc 0.52000 prc_auc 0.67158[0m
[92maverage training of epoch 49: loss -1619.67160 acc 0.33333 roc_auc 0.36080 prc_auc 0.56967[0m
[93maverage test of epoch 49: loss -1667.96733 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=8, bias=True)
    (ReLU1): ReLU()
    (Linear2): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -1.67707 acc 0.52000 roc_auc 0.46820 prc_auc 0.64880[0m
[93maverage test of epoch 0: loss -2.48969 acc 0.65789 roc_auc 0.77846 prc_auc 0.87865[0m
[92maverage training of epoch 1: loss -3.60564 acc 0.66667 roc_auc 0.40840 prc_auc 0.59829[0m
[93maverage test of epoch 1: loss -4.78224 acc 0.65789 roc_auc 0.48923 prc_auc 0.66782[0m
[92maverage training of epoch 2: loss -6.09586 acc 0.66667 roc_auc 0.38540 prc_auc 0.58243[0m
[93maverage test of epoch 2: loss -7.48555 acc 0.65789 roc_auc 0.16000 prc_auc 0.54843[0m
[92maverage training of epoch 3: loss -8.90099 acc 0.66667 roc_auc 0.42200 prc_auc 0.60929[0m
[93maverage test of epoch 3: loss -10.40240 acc 0.65789 roc_auc 0.16000 prc_auc 0.53597[0m
[92maverage training of epoch 4: loss -12.02648 acc 0.66667 roc_auc 0.44200 prc_auc 0.62545[0m
[93maverage test of epoch 4: loss -13.75444 acc 0.65789 roc_auc 0.28308 prc_auc 0.58705[0m
[92maverage training of epoch 5: loss -15.67307 acc 0.66667 roc_auc 0.45300 prc_auc 0.63625[0m
[93maverage test of epoch 5: loss -17.70669 acc 0.65789 roc_auc 0.39385 prc_auc 0.64243[0m
[92maverage training of epoch 6: loss -19.98305 acc 0.66667 roc_auc 0.46310 prc_auc 0.64341[0m
[93maverage test of epoch 6: loss -22.37442 acc 0.65789 roc_auc 0.49231 prc_auc 0.68206[0m
[92maverage training of epoch 7: loss -25.06472 acc 0.66667 roc_auc 0.46800 prc_auc 0.64778[0m
[93maverage test of epoch 7: loss -27.86720 acc 0.65789 roc_auc 0.51692 prc_auc 0.71078[0m
[92maverage training of epoch 8: loss -31.02044 acc 0.66667 roc_auc 0.46880 prc_auc 0.64771[0m
[93maverage test of epoch 8: loss -34.27966 acc 0.65789 roc_auc 0.42000 prc_auc 0.62178[0m
[92maverage training of epoch 9: loss -38.00234 acc 0.66667 roc_auc 0.46870 prc_auc 0.64801[0m
[93maverage test of epoch 9: loss -41.92091 acc 0.65789 roc_auc 0.48000 prc_auc 0.65448[0m
[92maverage training of epoch 10: loss -46.68085 acc 0.66667 roc_auc 0.45520 prc_auc 0.63184[0m
[93maverage test of epoch 10: loss -51.41233 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 11: loss -56.55782 acc 0.66667 roc_auc 0.48000 prc_auc 0.65793[0m
[93maverage test of epoch 11: loss -61.70163 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 12: loss -67.43566 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 12: loss -73.13535 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 13: loss -79.52059 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 13: loss -85.80819 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 14: loss -92.85798 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 14: loss -99.72584 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 15: loss -107.45415 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 15: loss -114.91513 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 16: loss -123.34777 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 16: loss -131.41668 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 17: loss -140.58433 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 17: loss -149.28575 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 18: loss -159.22307 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 18: loss -168.58224 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -179.32373 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 19: loss -189.36547 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -200.94560 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 20: loss -211.69437 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -224.14763 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 21: loss -235.62718 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -248.98731 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 22: loss -261.22096 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -275.52274 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 23: loss -288.53436 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -303.81304 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 24: loss -317.62634 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -333.91729 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 25: loss -348.55603 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -365.89471 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 26: loss -381.38212 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -399.80383 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 27: loss -416.16292 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -435.70383 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 28: loss -452.95787 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -473.65386 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 29: loss -491.82577 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -513.71254 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 30: loss -532.82438 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -555.93845 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 31: loss -576.01277 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -600.39016 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 32: loss -621.44933 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -647.12756 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 33: loss -669.19415 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -696.20909 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -719.30417 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -747.69207 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -771.83753 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -801.63727 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -826.85476 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -858.10266 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -884.41389 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -917.14626 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -944.57111 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -978.82657 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -1007.38725 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -1043.20417 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -1072.92131 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -1110.33577 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -1141.22913 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -1180.27882 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -1212.36854 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -1253.09158 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -1286.39791 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -1328.83382 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -1363.37796 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -1407.56524 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -1443.36552 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -1489.34004 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -1526.41560 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -1574.21595 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -1612.58584 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -1662.25307 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -1701.93719 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -1753.50778 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -1794.52458 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=8, bias=True)
    (ReLU1): ReLU()
    (Linear2): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.22234 acc 0.33333 roc_auc 0.46820 prc_auc 0.67800[0m
[93maverage test of epoch 0: loss -0.47461 acc 0.34211 roc_auc 0.94769 prc_auc 0.97662[0m
[92maverage training of epoch 1: loss -0.71894 acc 0.33333 roc_auc 0.58960 prc_auc 0.76310[0m
[93maverage test of epoch 1: loss -1.03380 acc 0.34211 roc_auc 0.94769 prc_auc 0.97662[0m
[92maverage training of epoch 2: loss -1.44471 acc 0.33333 roc_auc 0.45180 prc_auc 0.62785[0m
[93maverage test of epoch 2: loss -1.95411 acc 0.34211 roc_auc 0.93846 prc_auc 0.97308[0m
[92maverage training of epoch 3: loss -2.63668 acc 0.33333 roc_auc 0.37680 prc_auc 0.58183[0m
[93maverage test of epoch 3: loss -3.45247 acc 0.34211 roc_auc 0.23692 prc_auc 0.61545[0m
[92maverage training of epoch 4: loss -4.50269 acc 0.33333 roc_auc 0.39820 prc_auc 0.60712[0m
[93maverage test of epoch 4: loss -5.73141 acc 0.34211 roc_auc 0.60769 prc_auc 0.82369[0m
[92maverage training of epoch 5: loss -7.07889 acc 0.58667 roc_auc 0.40880 prc_auc 0.61278[0m
[93maverage test of epoch 5: loss -8.46288 acc 0.65789 roc_auc 0.93692 prc_auc 0.97512[0m
[92maverage training of epoch 6: loss -9.91084 acc 0.66667 roc_auc 0.41560 prc_auc 0.61747[0m
[93maverage test of epoch 6: loss -11.41369 acc 0.65789 roc_auc 0.95692 prc_auc 0.98092[0m
[92maverage training of epoch 7: loss -13.01567 acc 0.66667 roc_auc 0.42180 prc_auc 0.62180[0m
[93maverage test of epoch 7: loss -14.65886 acc 0.65789 roc_auc 0.95692 prc_auc 0.98092[0m
[92maverage training of epoch 8: loss -16.41755 acc 0.66667 roc_auc 0.42680 prc_auc 0.62664[0m
[93maverage test of epoch 8: loss -18.21642 acc 0.65789 roc_auc 0.95692 prc_auc 0.97950[0m
[92maverage training of epoch 9: loss -20.16476 acc 0.66667 roc_auc 0.43040 prc_auc 0.63092[0m
[93maverage test of epoch 9: loss -22.14900 acc 0.65789 roc_auc 0.95538 prc_auc 0.96917[0m
[92maverage training of epoch 10: loss -24.31583 acc 0.66667 roc_auc 0.43500 prc_auc 0.63527[0m
[93maverage test of epoch 10: loss -26.51035 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 11: loss -28.92193 acc 0.66667 roc_auc 0.44100 prc_auc 0.64017[0m
[93maverage test of epoch 11: loss -31.34945 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 12: loss -34.03070 acc 0.66667 roc_auc 0.44250 prc_auc 0.63500[0m
[93maverage test of epoch 12: loss -36.71215 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 13: loss -39.68048 acc 0.66667 roc_auc 0.43890 prc_auc 0.63192[0m
[93maverage test of epoch 13: loss -42.62112 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 14: loss -45.88005 acc 0.66667 roc_auc 0.42910 prc_auc 0.62925[0m
[93maverage test of epoch 14: loss -49.07076 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 15: loss -52.60299 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 15: loss -56.02143 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 16: loss -59.83508 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 16: loss -63.48999 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 17: loss -67.59766 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 17: loss -71.49787 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 18: loss -75.91223 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 18: loss -80.06881 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -84.83431 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 19: loss -89.29766 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -94.46867 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 20: loss -99.28235 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -104.90314 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 21: loss -110.11510 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -116.23652 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 22: loss -121.89979 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -128.55366 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 23: loss -134.67292 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -141.78284 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 24: loss -148.31072 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -155.88095 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 25: loss -162.82858 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -170.87576 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 26: loss -178.25612 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -186.79701 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 27: loss -194.62302 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -203.67417 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 28: loss -211.95841 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -221.53653 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 29: loss -230.29175 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -240.41361 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 30: loss -249.65232 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -260.33510 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 31: loss -270.07016 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -281.33032 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 32: loss -291.57392 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -303.42918 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 33: loss -314.19394 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -326.66095 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -337.95890 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -351.05460 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -362.89763 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -376.63939 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -389.04039 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -403.44603 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -416.41712 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -431.50255 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -445.05392 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -460.83807 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -474.98353 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -491.48287 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -506.23311 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -523.46664 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -538.83425 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -556.81766 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -572.81205 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -591.56316 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -608.19740 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -627.73618 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -645.02287 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -665.36624 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -683.31554 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -704.47938 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -723.09984 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -745.10301 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -764.40768 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -787.26839 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -807.26856 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -831.00446 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -851.70979 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=8, bias=True)
    (ReLU1): ReLU()
    (Linear2): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss 0.36412 acc 0.51656 roc_auc 0.41843 prc_auc 0.60285[0m
[93maverage test of epoch 0: loss -0.05105 acc 0.67568 roc_auc 0.78000 prc_auc 0.88029[0m
[92maverage training of epoch 1: loss -0.19310 acc 0.66225 roc_auc 0.38529 prc_auc 0.58195[0m
[93maverage test of epoch 1: loss -0.39742 acc 0.67568 roc_auc 0.14000 prc_auc 0.50635[0m
[92maverage training of epoch 2: loss -0.75245 acc 0.66225 roc_auc 0.42294 prc_auc 0.59613[0m
[93maverage test of epoch 2: loss -1.19657 acc 0.67568 roc_auc 0.18667 prc_auc 0.55343[0m
[92maverage training of epoch 3: loss -1.75814 acc 0.66225 roc_auc 0.44961 prc_auc 0.62821[0m
[93maverage test of epoch 3: loss -2.43805 acc 0.64865 roc_auc 0.34000 prc_auc 0.67890[0m
[92maverage training of epoch 4: loss -3.28968 acc 0.33775 roc_auc 0.41216 prc_auc 0.60525[0m
[93maverage test of epoch 4: loss -4.17976 acc 0.32432 roc_auc 0.19333 prc_auc 0.56228[0m
[92maverage training of epoch 5: loss -5.11234 acc 0.33775 roc_auc 0.36765 prc_auc 0.58757[0m
[93maverage test of epoch 5: loss -6.10215 acc 0.32432 roc_auc 0.72667 prc_auc 0.86353[0m
[92maverage training of epoch 6: loss -7.15388 acc 0.33113 roc_auc 0.35686 prc_auc 0.57522[0m
[93maverage test of epoch 6: loss -8.25759 acc 0.32432 roc_auc 0.80833 prc_auc 0.89901[0m
[92maverage training of epoch 7: loss -9.44525 acc 0.54967 roc_auc 0.37216 prc_auc 0.57301[0m
[93maverage test of epoch 7: loss -10.73806 acc 0.67568 roc_auc 0.53000 prc_auc 0.78159[0m
[92maverage training of epoch 8: loss -12.12521 acc 0.66225 roc_auc 0.37490 prc_auc 0.56952[0m
[93maverage test of epoch 8: loss -13.63103 acc 0.67568 roc_auc 0.79000 prc_auc 0.89543[0m
[92maverage training of epoch 9: loss -15.24247 acc 0.66225 roc_auc 0.37294 prc_auc 0.56654[0m
[93maverage test of epoch 9: loss -17.00629 acc 0.67568 roc_auc 0.79333 prc_auc 0.88922[0m
[92maverage training of epoch 10: loss -18.89605 acc 0.66225 roc_auc 0.37510 prc_auc 0.57289[0m
[93maverage test of epoch 10: loss -20.96379 acc 0.67568 roc_auc 0.81833 prc_auc 0.89871[0m
[92maverage training of epoch 11: loss -23.15862 acc 0.66225 roc_auc 0.37392 prc_auc 0.57236[0m
[93maverage test of epoch 11: loss -25.54965 acc 0.67568 roc_auc 0.85667 prc_auc 0.91919[0m
[92maverage training of epoch 12: loss -28.05523 acc 0.66225 roc_auc 0.37549 prc_auc 0.57230[0m
[93maverage test of epoch 12: loss -30.77742 acc 0.67568 roc_auc 0.85000 prc_auc 0.90648[0m
[92maverage training of epoch 13: loss -33.58809 acc 0.66225 roc_auc 0.37255 prc_auc 0.56700[0m
[93maverage test of epoch 13: loss -36.62458 acc 0.67568 roc_auc 0.67000 prc_auc 0.76934[0m
[92maverage training of epoch 14: loss -39.72394 acc 0.66225 roc_auc 0.37510 prc_auc 0.57009[0m
[93maverage test of epoch 14: loss -43.08091 acc 0.67568 roc_auc 0.79500 prc_auc 0.85044[0m
[92maverage training of epoch 15: loss -46.47581 acc 0.66225 roc_auc 0.37686 prc_auc 0.57008[0m
[93maverage test of epoch 15: loss -50.15296 acc 0.67568 roc_auc 0.58000 prc_auc 0.71644[0m
[92maverage training of epoch 16: loss -53.84420 acc 0.66225 roc_auc 0.37961 prc_auc 0.57186[0m
[93maverage test of epoch 16: loss -57.85355 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 17: loss -61.85553 acc 0.66225 roc_auc 0.38137 prc_auc 0.57321[0m
[93maverage test of epoch 17: loss -66.21524 acc 0.67568 roc_auc 0.62000 prc_auc 0.73612[0m
[92maverage training of epoch 18: loss -70.54139 acc 0.66225 roc_auc 0.38137 prc_auc 0.57375[0m
[93maverage test of epoch 18: loss -75.26901 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 19: loss -79.93215 acc 0.66225 roc_auc 0.38245 prc_auc 0.57390[0m
[93maverage test of epoch 19: loss -85.04513 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 20: loss -90.05789 acc 0.66225 roc_auc 0.38353 prc_auc 0.57481[0m
[93maverage test of epoch 20: loss -95.57370 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 21: loss -100.94852 acc 0.66225 roc_auc 0.38647 prc_auc 0.57745[0m
[93maverage test of epoch 21: loss -106.88467 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 22: loss -112.63376 acc 0.66225 roc_auc 0.38480 prc_auc 0.58214[0m
[93maverage test of epoch 22: loss -119.00781 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 23: loss -125.14327 acc 0.66225 roc_auc 0.39157 prc_auc 0.59697[0m
[93maverage test of epoch 23: loss -131.97297 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 24: loss -138.50677 acc 0.66225 roc_auc 0.44373 prc_auc 0.63527[0m
[93maverage test of epoch 24: loss -145.80993 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 25: loss -152.75387 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 25: loss -160.54813 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 26: loss -167.91352 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 26: loss -176.21679 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 27: loss -184.01537 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 27: loss -192.84596 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 28: loss -201.08901 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 28: loss -210.46493 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 29: loss -219.16371 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 29: loss -229.10338 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 30: loss -238.26927 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 30: loss -248.79148 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 31: loss -258.43582 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 31: loss -269.55936 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 32: loss -279.69341 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 32: loss -291.43766 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 33: loss -302.07193 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 33: loss -314.45531 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 34: loss -325.60154 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 34: loss -338.64353 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 35: loss -350.31095 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 35: loss -364.02992 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 36: loss -376.22973 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 36: loss -390.64589 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 37: loss -403.38763 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 37: loss -418.51923 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 38: loss -431.81432 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 38: loss -447.68227 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 39: loss -461.54119 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 39: loss -478.16558 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -492.59788 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 40: loss -509.99766 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -525.01191 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 41: loss -543.20587 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -558.81320 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 42: loss -577.82269 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -594.03336 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 43: loss -613.87926 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -630.70200 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 44: loss -651.40491 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -668.85091 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 45: loss -690.43118 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -708.50858 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 46: loss -730.98670 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -749.70469 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 47: loss -773.10102 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -792.46809 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 48: loss -816.80345 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -836.82967 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 49: loss -862.12647 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=8, bias=True)
    (ReLU1): ReLU()
    (Linear2): Linear(in_features=8, out_features=2, bias=True)
  )
)}Using backend: pytorch
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))

DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.15196 acc 0.43046 roc_auc 0.38627 prc_auc 0.59391[0m
[93maverage test of epoch 0: loss -0.27637 acc 0.67568 roc_auc 0.94000 prc_auc 0.97574[0m
[92maverage training of epoch 1: loss -0.36793 acc 0.65563 roc_auc 0.40255 prc_auc 0.60947[0m
[93maverage test of epoch 1: loss -0.48228 acc 0.67568 roc_auc 0.94167 prc_auc 0.97574[0m
[92maverage training of epoch 2: loss -0.63162 acc 0.65563 roc_auc 0.56667 prc_auc 0.71296[0m
[93maverage test of epoch 2: loss -0.82245 acc 0.67568 roc_auc 0.94667 prc_auc 0.97843[0m
[92maverage training of epoch 3: loss -1.16171 acc 0.66225 roc_auc 0.43804 prc_auc 0.64173[0m
[93maverage test of epoch 3: loss -1.68554 acc 0.67568 roc_auc 0.94333 prc_auc 0.97705[0m
[92maverage training of epoch 4: loss -2.54356 acc 0.66225 roc_auc 0.40255 prc_auc 0.60745[0m
[93maverage test of epoch 4: loss -3.63202 acc 0.67568 roc_auc 0.94667 prc_auc 0.97890[0m
[92maverage training of epoch 5: loss -5.00993 acc 0.66225 roc_auc 0.41392 prc_auc 0.60840[0m
[93maverage test of epoch 5: loss -6.60663 acc 0.67568 roc_auc 0.95000 prc_auc 0.98064[0m
[92maverage training of epoch 6: loss -8.17236 acc 0.66225 roc_auc 0.41569 prc_auc 0.61023[0m
[93maverage test of epoch 6: loss -9.85324 acc 0.67568 roc_auc 0.94667 prc_auc 0.97910[0m
[92maverage training of epoch 7: loss -11.47280 acc 0.66225 roc_auc 0.41745 prc_auc 0.61176[0m
[93maverage test of epoch 7: loss -13.26979 acc 0.67568 roc_auc 0.94333 prc_auc 0.97395[0m
[92maverage training of epoch 8: loss -15.04764 acc 0.66225 roc_auc 0.41412 prc_auc 0.60903[0m
[93maverage test of epoch 8: loss -17.15855 acc 0.67568 roc_auc 0.95000 prc_auc 0.97155[0m
[92maverage training of epoch 9: loss -19.43782 acc 0.66225 roc_auc 0.41745 prc_auc 0.61102[0m
[93maverage test of epoch 9: loss -22.18177 acc 0.67568 roc_auc 0.80000 prc_auc 0.85455[0m
[92maverage training of epoch 10: loss -24.98139 acc 0.66225 roc_auc 0.41863 prc_auc 0.61282[0m
[93maverage test of epoch 10: loss -28.28740 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 11: loss -31.47407 acc 0.66225 roc_auc 0.41804 prc_auc 0.61060[0m
[93maverage test of epoch 11: loss -35.16977 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 12: loss -38.61119 acc 0.66225 roc_auc 0.41598 prc_auc 0.61006[0m
[93maverage test of epoch 12: loss -42.64615 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 13: loss -46.36524 acc 0.66225 roc_auc 0.45637 prc_auc 0.63892[0m
[93maverage test of epoch 13: loss -50.76201 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 14: loss -54.77160 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 14: loss -59.55416 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 15: loss -63.87649 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 15: loss -69.07186 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 16: loss -73.72458 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 16: loss -79.35655 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 17: loss -84.35514 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 17: loss -90.44639 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 18: loss -95.80552 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 18: loss -102.37729 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 19: loss -108.11021 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 19: loss -115.18399 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 20: loss -121.30383 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 20: loss -128.90083 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 21: loss -135.41996 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 21: loss -143.56245 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 22: loss -150.49514 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 22: loss -159.20360 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 23: loss -166.56200 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 23: loss -175.85895 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 24: loss -183.65561 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 24: loss -193.56294 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 25: loss -201.81023 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 25: loss -212.34996 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 26: loss -221.06017 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 26: loss -232.25454 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 27: loss -241.43966 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 27: loss -253.31089 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 28: loss -262.98284 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 28: loss -275.55333 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 29: loss -285.72386 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 29: loss -299.01619 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 30: loss -309.69677 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 30: loss -323.73341 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 31: loss -334.93495 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 31: loss -349.73833 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 32: loss -361.47202 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 32: loss -377.06490 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 33: loss -389.34209 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 33: loss -405.74779 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 34: loss -418.57906 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 34: loss -435.82062 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 35: loss -449.21724 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 35: loss -467.31830 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 36: loss -481.29060 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 36: loss -500.27413 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 37: loss -514.83212 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 37: loss -534.72185 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 38: loss -549.87690 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 38: loss -570.69688 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 39: loss -586.45825 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 39: loss -608.23179 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -624.60970 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 40: loss -647.36153 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -664.36655 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 41: loss -688.12016 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -705.75967 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 42: loss -730.53825 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -748.82348 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 43: loss -774.65284 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -793.59319 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 44: loss -820.49766 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -840.10258 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 45: loss -868.10682 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -888.38455 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 46: loss -917.51287 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -938.47248 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 47: loss -968.75055 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -990.40208 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 48: loss -1021.85523 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -1044.20621 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 49: loss -1076.85838 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 2)
('lr', 0.0003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.60185 ROC_AUC (avg): 0.5 PRC_AUC (avg): 0.66501 

Average forward propagation time taken(ms): 3.143108228784935
Average backward propagation time taken(ms): 1.0107670181511883

