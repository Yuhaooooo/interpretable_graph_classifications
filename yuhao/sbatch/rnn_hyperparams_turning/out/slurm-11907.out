# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-21-45-41/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-21-45-41/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 16,
 'epochs': 50,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 4,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.001,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 2,
 'num_workers': 8,
 'number_of_mlp_layer': 0,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-17-21-45-41',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 50, 'learning_rate': 0.001, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -0.05373 acc 0.66667 roc_auc 0.43580 prc_auc 0.63977[0m
[93maverage test of epoch 0: loss -0.78550 acc 0.65789 roc_auc 0.62154 prc_auc 0.82810[0m
[92maverage training of epoch 1: loss -1.49398 acc 0.66667 roc_auc 0.44200 prc_auc 0.63016[0m
[93maverage test of epoch 1: loss -2.09068 acc 0.65789 roc_auc 0.51692 prc_auc 0.68719[0m
[92maverage training of epoch 2: loss -2.59203 acc 0.66667 roc_auc 0.38860 prc_auc 0.59836[0m
[93maverage test of epoch 2: loss -2.96354 acc 0.65789 roc_auc 0.30769 prc_auc 0.59564[0m
[92maverage training of epoch 3: loss -3.34952 acc 0.66667 roc_auc 0.41120 prc_auc 0.61414[0m
[93maverage test of epoch 3: loss -3.67399 acc 0.65789 roc_auc 0.63385 prc_auc 0.80756[0m
[92maverage training of epoch 4: loss -4.04770 acc 0.66667 roc_auc 0.38880 prc_auc 0.60192[0m
[93maverage test of epoch 4: loss -4.35485 acc 0.65789 roc_auc 0.36000 prc_auc 0.62269[0m
[92maverage training of epoch 5: loss -4.71713 acc 0.66667 roc_auc 0.36900 prc_auc 0.57679[0m
[93maverage test of epoch 5: loss -5.01276 acc 0.65789 roc_auc 0.44308 prc_auc 0.68719[0m
[92maverage training of epoch 6: loss -5.35461 acc 0.66667 roc_auc 0.35980 prc_auc 0.57474[0m
[93maverage test of epoch 6: loss -5.63593 acc 0.65789 roc_auc 0.61231 prc_auc 0.74166[0m
[92maverage training of epoch 7: loss -5.97427 acc 0.66667 roc_auc 0.35320 prc_auc 0.57082[0m
[93maverage test of epoch 7: loss -6.24880 acc 0.65789 roc_auc 0.39231 prc_auc 0.58757[0m
[92maverage training of epoch 8: loss -6.57752 acc 0.66667 roc_auc 0.38040 prc_auc 0.59396[0m
[93maverage test of epoch 8: loss -6.83883 acc 0.65789 roc_auc 0.54923 prc_auc 0.69741[0m
[92maverage training of epoch 9: loss -7.16853 acc 0.66667 roc_auc 0.37930 prc_auc 0.57926[0m
[93maverage test of epoch 9: loss -7.42755 acc 0.65789 roc_auc 0.60308 prc_auc 0.77939[0m
[92maverage training of epoch 10: loss -7.75425 acc 0.66667 roc_auc 0.37100 prc_auc 0.58021[0m
[93maverage test of epoch 10: loss -8.00364 acc 0.65789 roc_auc 0.62154 prc_auc 0.78601[0m
[92maverage training of epoch 11: loss -8.33030 acc 0.66667 roc_auc 0.34940 prc_auc 0.55707[0m
[93maverage test of epoch 11: loss -8.58181 acc 0.65789 roc_auc 0.66000 prc_auc 0.77265[0m
[92maverage training of epoch 12: loss -8.90479 acc 0.66667 roc_auc 0.36160 prc_auc 0.57711[0m
[93maverage test of epoch 12: loss -9.14843 acc 0.65789 roc_auc 0.53538 prc_auc 0.66721[0m
[92maverage training of epoch 13: loss -9.47454 acc 0.66667 roc_auc 0.35760 prc_auc 0.56750[0m
[93maverage test of epoch 13: loss -9.71652 acc 0.65789 roc_auc 0.55385 prc_auc 0.72780[0m
[92maverage training of epoch 14: loss -10.04141 acc 0.66667 roc_auc 0.37060 prc_auc 0.56949[0m
[93maverage test of epoch 14: loss -10.27874 acc 0.65789 roc_auc 0.36769 prc_auc 0.60320[0m
[92maverage training of epoch 15: loss -10.60722 acc 0.66667 roc_auc 0.36630 prc_auc 0.56597[0m
[93maverage test of epoch 15: loss -10.84265 acc 0.65789 roc_auc 0.32000 prc_auc 0.56854[0m
[92maverage training of epoch 16: loss -11.17038 acc 0.66667 roc_auc 0.36250 prc_auc 0.56749[0m
[93maverage test of epoch 16: loss -11.40030 acc 0.65789 roc_auc 0.63692 prc_auc 0.80499[0m
[92maverage training of epoch 17: loss -11.73183 acc 0.66667 roc_auc 0.35660 prc_auc 0.56294[0m
[93maverage test of epoch 17: loss -11.96066 acc 0.65789 roc_auc 0.55846 prc_auc 0.67961[0m
[92maverage training of epoch 18: loss -12.29194 acc 0.66667 roc_auc 0.35730 prc_auc 0.56692[0m
[93maverage test of epoch 18: loss -12.51877 acc 0.65789 roc_auc 0.52154 prc_auc 0.68659[0m
[92maverage training of epoch 19: loss -12.84894 acc 0.66667 roc_auc 0.36150 prc_auc 0.56949[0m
[93maverage test of epoch 19: loss -13.07601 acc 0.65789 roc_auc 0.51077 prc_auc 0.65548[0m
[92maverage training of epoch 20: loss -13.40959 acc 0.66667 roc_auc 0.36200 prc_auc 0.56666[0m
[93maverage test of epoch 20: loss -13.63197 acc 0.65789 roc_auc 0.47846 prc_auc 0.64774[0m
[92maverage training of epoch 21: loss -13.96565 acc 0.66667 roc_auc 0.35880 prc_auc 0.56288[0m
[93maverage test of epoch 21: loss -14.18750 acc 0.65789 roc_auc 0.52154 prc_auc 0.66798[0m
[92maverage training of epoch 22: loss -14.52152 acc 0.66667 roc_auc 0.35760 prc_auc 0.56286[0m
[93maverage test of epoch 22: loss -14.74129 acc 0.65789 roc_auc 0.43846 prc_auc 0.65500[0m
[92maverage training of epoch 23: loss -15.07831 acc 0.66667 roc_auc 0.35940 prc_auc 0.56464[0m
[93maverage test of epoch 23: loss -15.29507 acc 0.65789 roc_auc 0.45385 prc_auc 0.63279[0m
[92maverage training of epoch 24: loss -15.63343 acc 0.66667 roc_auc 0.36030 prc_auc 0.56697[0m
[93maverage test of epoch 24: loss -15.84946 acc 0.65789 roc_auc 0.47077 prc_auc 0.64454[0m
[92maverage training of epoch 25: loss -16.18827 acc 0.66667 roc_auc 0.36010 prc_auc 0.56437[0m
[93maverage test of epoch 25: loss -16.40170 acc 0.65789 roc_auc 0.47385 prc_auc 0.64916[0m
[92maverage training of epoch 26: loss -16.74281 acc 0.66667 roc_auc 0.35860 prc_auc 0.56415[0m
[93maverage test of epoch 26: loss -16.95519 acc 0.65789 roc_auc 0.50769 prc_auc 0.66866[0m
[92maverage training of epoch 27: loss -17.29775 acc 0.66667 roc_auc 0.35740 prc_auc 0.56272[0m
[93maverage test of epoch 27: loss -17.50756 acc 0.65789 roc_auc 0.46000 prc_auc 0.63809[0m
[92maverage training of epoch 28: loss -17.85178 acc 0.66667 roc_auc 0.35950 prc_auc 0.56489[0m
[93maverage test of epoch 28: loss -18.05997 acc 0.65789 roc_auc 0.41231 prc_auc 0.60603[0m
[92maverage training of epoch 29: loss -18.40556 acc 0.66667 roc_auc 0.35740 prc_auc 0.56554[0m
[93maverage test of epoch 29: loss -18.61195 acc 0.65789 roc_auc 0.43538 prc_auc 0.62760[0m
[92maverage training of epoch 30: loss -18.95861 acc 0.66667 roc_auc 0.35800 prc_auc 0.56345[0m
[93maverage test of epoch 30: loss -19.16483 acc 0.65789 roc_auc 0.64615 prc_auc 0.73867[0m
[92maverage training of epoch 31: loss -19.51217 acc 0.66667 roc_auc 0.35470 prc_auc 0.56143[0m
[93maverage test of epoch 31: loss -19.71609 acc 0.65789 roc_auc 0.60308 prc_auc 0.70785[0m
[92maverage training of epoch 32: loss -20.06608 acc 0.66667 roc_auc 0.36020 prc_auc 0.56706[0m
[93maverage test of epoch 32: loss -20.26762 acc 0.65789 roc_auc 0.51385 prc_auc 0.66561[0m
[92maverage training of epoch 33: loss -20.61916 acc 0.66667 roc_auc 0.36000 prc_auc 0.56695[0m
[93maverage test of epoch 33: loss -20.81871 acc 0.65789 roc_auc 0.56462 prc_auc 0.69632[0m
[92maverage training of epoch 34: loss -21.17203 acc 0.66667 roc_auc 0.35560 prc_auc 0.56338[0m
[93maverage test of epoch 34: loss -21.37104 acc 0.65789 roc_auc 0.50769 prc_auc 0.66140[0m
[92maverage training of epoch 35: loss -21.72477 acc 0.66667 roc_auc 0.35860 prc_auc 0.56665[0m
[93maverage test of epoch 35: loss -21.92174 acc 0.65789 roc_auc 0.41385 prc_auc 0.62079[0m
[92maverage training of epoch 36: loss -22.27800 acc 0.66667 roc_auc 0.36280 prc_auc 0.56820[0m
[93maverage test of epoch 36: loss -22.47257 acc 0.65789 roc_auc 0.44462 prc_auc 0.63601[0m
[92maverage training of epoch 37: loss -22.83089 acc 0.66667 roc_auc 0.36350 prc_auc 0.57061[0m
[93maverage test of epoch 37: loss -23.02465 acc 0.65789 roc_auc 0.52154 prc_auc 0.66775[0m
[92maverage training of epoch 38: loss -23.38371 acc 0.66667 roc_auc 0.36050 prc_auc 0.57369[0m
[93maverage test of epoch 38: loss -23.57493 acc 0.65789 roc_auc 0.46308 prc_auc 0.64323[0m
[92maverage training of epoch 39: loss -23.93648 acc 0.66667 roc_auc 0.35940 prc_auc 0.56865[0m
[93maverage test of epoch 39: loss -24.12643 acc 0.65789 roc_auc 0.48000 prc_auc 0.64902[0m
[92maverage training of epoch 40: loss -24.48897 acc 0.66667 roc_auc 0.36160 prc_auc 0.57043[0m
[93maverage test of epoch 40: loss -24.67774 acc 0.65789 roc_auc 0.55538 prc_auc 0.68395[0m
[92maverage training of epoch 41: loss -25.04153 acc 0.66667 roc_auc 0.36210 prc_auc 0.57122[0m
[93maverage test of epoch 41: loss -25.22798 acc 0.65789 roc_auc 0.48000 prc_auc 0.64902[0m
[92maverage training of epoch 42: loss -25.59410 acc 0.66667 roc_auc 0.35840 prc_auc 0.57049[0m
[93maverage test of epoch 42: loss -25.77955 acc 0.65789 roc_auc 0.46000 prc_auc 0.64041[0m
[92maverage training of epoch 43: loss -26.14655 acc 0.66667 roc_auc 0.36250 prc_auc 0.57520[0m
[93maverage test of epoch 43: loss -26.33088 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -26.69909 acc 0.66667 roc_auc 0.36010 prc_auc 0.57745[0m
[93maverage test of epoch 44: loss -26.88152 acc 0.65789 roc_auc 0.51846 prc_auc 0.66632[0m
[92maverage training of epoch 45: loss -27.25159 acc 0.66667 roc_auc 0.36810 prc_auc 0.58550[0m
[93maverage test of epoch 45: loss -27.43231 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -27.80403 acc 0.66667 roc_auc 0.37240 prc_auc 0.58770[0m
[93maverage test of epoch 46: loss -27.98298 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -28.35620 acc 0.66667 roc_auc 0.36060 prc_auc 0.58264[0m
[93maverage test of epoch 47: loss -28.53404 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -28.90874 acc 0.66667 roc_auc 0.36590 prc_auc 0.58849[0m
[93maverage test of epoch 48: loss -29.08483 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -29.46095 acc 0.66667 roc_auc 0.36620 prc_auc 0.58988[0m
[93maverage test of epoch 49: loss -29.63579 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss 0.18973 acc 0.33333 roc_auc 0.47940 prc_auc 0.64729[0m
[93maverage test of epoch 0: loss -1.06765 acc 0.36842 roc_auc 0.51385 prc_auc 0.74534[0m
[92maverage training of epoch 1: loss -2.00261 acc 0.66667 roc_auc 0.47860 prc_auc 0.67943[0m
[93maverage test of epoch 1: loss -2.61280 acc 0.65789 roc_auc 0.45231 prc_auc 0.65048[0m
[92maverage training of epoch 2: loss -3.01960 acc 0.66667 roc_auc 0.42680 prc_auc 0.61305[0m
[93maverage test of epoch 2: loss -3.38598 acc 0.65789 roc_auc 0.38769 prc_auc 0.61558[0m
[92maverage training of epoch 3: loss -3.69415 acc 0.66667 roc_auc 0.41860 prc_auc 0.60844[0m
[93maverage test of epoch 3: loss -3.97860 acc 0.65789 roc_auc 0.43692 prc_auc 0.64736[0m
[92maverage training of epoch 4: loss -4.26732 acc 0.66667 roc_auc 0.44980 prc_auc 0.62415[0m
[93maverage test of epoch 4: loss -4.53329 acc 0.65789 roc_auc 0.72308 prc_auc 0.85267[0m
[92maverage training of epoch 5: loss -4.83315 acc 0.66667 roc_auc 0.46700 prc_auc 0.64546[0m
[93maverage test of epoch 5: loss -5.14773 acc 0.65789 roc_auc 0.44308 prc_auc 0.71678[0m
[92maverage training of epoch 6: loss -5.66576 acc 0.66667 roc_auc 0.47180 prc_auc 0.66266[0m
[93maverage test of epoch 6: loss -6.11324 acc 0.65789 roc_auc 0.40923 prc_auc 0.62852[0m
[92maverage training of epoch 7: loss -6.51999 acc 0.66667 roc_auc 0.43760 prc_auc 0.61559[0m
[93maverage test of epoch 7: loss -6.84555 acc 0.65789 roc_auc 0.50154 prc_auc 0.66583[0m
[92maverage training of epoch 8: loss -7.21096 acc 0.66667 roc_auc 0.44260 prc_auc 0.62293[0m
[93maverage test of epoch 8: loss -7.51376 acc 0.65789 roc_auc 0.39692 prc_auc 0.59065[0m
[92maverage training of epoch 9: loss -7.85559 acc 0.66667 roc_auc 0.41720 prc_auc 0.59705[0m
[93maverage test of epoch 9: loss -8.13870 acc 0.65789 roc_auc 0.47385 prc_auc 0.64352[0m
[92maverage training of epoch 10: loss -8.47782 acc 0.66667 roc_auc 0.43800 prc_auc 0.64032[0m
[93maverage test of epoch 10: loss -8.74196 acc 0.65789 roc_auc 0.41846 prc_auc 0.65218[0m
[92maverage training of epoch 11: loss -9.07989 acc 0.66667 roc_auc 0.44360 prc_auc 0.62875[0m
[93maverage test of epoch 11: loss -9.33906 acc 0.65789 roc_auc 0.50615 prc_auc 0.72038[0m
[92maverage training of epoch 12: loss -9.66935 acc 0.66667 roc_auc 0.40410 prc_auc 0.60534[0m
[93maverage test of epoch 12: loss -9.92364 acc 0.65789 roc_auc 0.43692 prc_auc 0.69135[0m
[92maverage training of epoch 13: loss -10.25458 acc 0.66667 roc_auc 0.43060 prc_auc 0.61554[0m
[93maverage test of epoch 13: loss -10.50308 acc 0.65789 roc_auc 0.48000 prc_auc 0.63772[0m
[92maverage training of epoch 14: loss -10.83300 acc 0.66667 roc_auc 0.42590 prc_auc 0.60613[0m
[93maverage test of epoch 14: loss -11.07972 acc 0.65789 roc_auc 0.49231 prc_auc 0.68142[0m
[92maverage training of epoch 15: loss -11.40584 acc 0.66667 roc_auc 0.40990 prc_auc 0.59205[0m
[93maverage test of epoch 15: loss -11.64968 acc 0.65789 roc_auc 0.57692 prc_auc 0.77864[0m
[92maverage training of epoch 16: loss -11.97925 acc 0.66667 roc_auc 0.43120 prc_auc 0.61111[0m
[93maverage test of epoch 16: loss -12.21664 acc 0.65789 roc_auc 0.41231 prc_auc 0.63685[0m
[92maverage training of epoch 17: loss -12.54472 acc 0.66667 roc_auc 0.42160 prc_auc 0.60104[0m
[93maverage test of epoch 17: loss -12.77617 acc 0.65789 roc_auc 0.59385 prc_auc 0.70307[0m
[92maverage training of epoch 18: loss -13.11061 acc 0.66667 roc_auc 0.40670 prc_auc 0.59565[0m
[93maverage test of epoch 18: loss -13.34591 acc 0.65789 roc_auc 0.66923 prc_auc 0.79531[0m
[92maverage training of epoch 19: loss -13.67402 acc 0.66667 roc_auc 0.42070 prc_auc 0.60998[0m
[93maverage test of epoch 19: loss -13.90337 acc 0.65789 roc_auc 0.46769 prc_auc 0.62879[0m
[92maverage training of epoch 20: loss -14.23676 acc 0.66667 roc_auc 0.42990 prc_auc 0.60792[0m
[93maverage test of epoch 20: loss -14.46378 acc 0.65789 roc_auc 0.68000 prc_auc 0.82935[0m
[92maverage training of epoch 21: loss -14.79509 acc 0.66667 roc_auc 0.41710 prc_auc 0.59996[0m
[93maverage test of epoch 21: loss -15.02205 acc 0.65789 roc_auc 0.58308 prc_auc 0.68982[0m
[92maverage training of epoch 22: loss -15.35522 acc 0.66667 roc_auc 0.41590 prc_auc 0.59971[0m
[93maverage test of epoch 22: loss -15.57954 acc 0.65789 roc_auc 0.39538 prc_auc 0.58887[0m
[92maverage training of epoch 23: loss -15.91369 acc 0.66667 roc_auc 0.42360 prc_auc 0.61908[0m
[93maverage test of epoch 23: loss -16.13568 acc 0.65789 roc_auc 0.46308 prc_auc 0.62407[0m
[92maverage training of epoch 24: loss -16.47013 acc 0.66667 roc_auc 0.42550 prc_auc 0.60877[0m
[93maverage test of epoch 24: loss -16.69215 acc 0.65789 roc_auc 0.52000 prc_auc 0.66290[0m
[92maverage training of epoch 25: loss -17.02729 acc 0.66667 roc_auc 0.42750 prc_auc 0.60913[0m
[93maverage test of epoch 25: loss -17.24578 acc 0.65789 roc_auc 0.44769 prc_auc 0.63479[0m
[92maverage training of epoch 26: loss -17.58321 acc 0.66667 roc_auc 0.42610 prc_auc 0.60104[0m
[93maverage test of epoch 26: loss -17.80018 acc 0.65789 roc_auc 0.50615 prc_auc 0.65453[0m
[92maverage training of epoch 27: loss -18.13862 acc 0.66667 roc_auc 0.42220 prc_auc 0.60550[0m
[93maverage test of epoch 27: loss -18.35201 acc 0.65789 roc_auc 0.57538 prc_auc 0.69492[0m
[92maverage training of epoch 28: loss -18.69362 acc 0.66667 roc_auc 0.42020 prc_auc 0.60703[0m
[93maverage test of epoch 28: loss -18.90705 acc 0.65789 roc_auc 0.59538 prc_auc 0.70353[0m
[92maverage training of epoch 29: loss -19.24849 acc 0.66667 roc_auc 0.42740 prc_auc 0.60596[0m
[93maverage test of epoch 29: loss -19.46022 acc 0.65789 roc_auc 0.52000 prc_auc 0.67122[0m
[92maverage training of epoch 30: loss -19.80347 acc 0.66667 roc_auc 0.41880 prc_auc 0.60984[0m
[93maverage test of epoch 30: loss -20.01354 acc 0.65789 roc_auc 0.57231 prc_auc 0.69822[0m
[92maverage training of epoch 31: loss -20.35720 acc 0.66667 roc_auc 0.41780 prc_auc 0.60168[0m
[93maverage test of epoch 31: loss -20.56515 acc 0.65789 roc_auc 0.44923 prc_auc 0.63465[0m
[92maverage training of epoch 32: loss -20.91105 acc 0.66667 roc_auc 0.41820 prc_auc 0.60053[0m
[93maverage test of epoch 32: loss -21.11732 acc 0.65789 roc_auc 0.58308 prc_auc 0.70852[0m
[92maverage training of epoch 33: loss -21.46511 acc 0.66667 roc_auc 0.42070 prc_auc 0.60313[0m
[93maverage test of epoch 33: loss -21.66960 acc 0.65789 roc_auc 0.55385 prc_auc 0.69164[0m
[92maverage training of epoch 34: loss -22.01871 acc 0.66667 roc_auc 0.42280 prc_auc 0.60665[0m
[93maverage test of epoch 34: loss -22.22151 acc 0.65789 roc_auc 0.38154 prc_auc 0.60311[0m
[92maverage training of epoch 35: loss -22.57205 acc 0.66667 roc_auc 0.42190 prc_auc 0.60160[0m
[93maverage test of epoch 35: loss -22.77348 acc 0.65789 roc_auc 0.49692 prc_auc 0.65645[0m
[92maverage training of epoch 36: loss -23.12527 acc 0.66667 roc_auc 0.41950 prc_auc 0.60215[0m
[93maverage test of epoch 36: loss -23.32514 acc 0.65789 roc_auc 0.48154 prc_auc 0.65193[0m
[92maverage training of epoch 37: loss -23.67831 acc 0.66667 roc_auc 0.42120 prc_auc 0.60772[0m
[93maverage test of epoch 37: loss -23.87663 acc 0.65789 roc_auc 0.53385 prc_auc 0.67461[0m
[92maverage training of epoch 38: loss -24.23130 acc 0.66667 roc_auc 0.42160 prc_auc 0.60934[0m
[93maverage test of epoch 38: loss -24.42804 acc 0.65789 roc_auc 0.47692 prc_auc 0.64771[0m
[92maverage training of epoch 39: loss -24.78463 acc 0.66667 roc_auc 0.42110 prc_auc 0.60773[0m
[93maverage test of epoch 39: loss -24.97932 acc 0.65789 roc_auc 0.53846 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -25.33751 acc 0.66667 roc_auc 0.42300 prc_auc 0.60835[0m
[93maverage test of epoch 40: loss -25.53027 acc 0.65789 roc_auc 0.50462 prc_auc 0.66009[0m
[92maverage training of epoch 41: loss -25.89008 acc 0.66667 roc_auc 0.42200 prc_auc 0.60179[0m
[93maverage test of epoch 41: loss -26.08148 acc 0.65789 roc_auc 0.48000 prc_auc 0.64902[0m
[92maverage training of epoch 42: loss -26.44300 acc 0.66667 roc_auc 0.42210 prc_auc 0.60371[0m
[93maverage test of epoch 42: loss -26.63312 acc 0.65789 roc_auc 0.53846 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -26.99536 acc 0.66667 roc_auc 0.42350 prc_auc 0.60428[0m
[93maverage test of epoch 43: loss -27.18381 acc 0.65789 roc_auc 0.48000 prc_auc 0.64902[0m
[92maverage training of epoch 44: loss -27.54790 acc 0.66667 roc_auc 0.42400 prc_auc 0.60931[0m
[93maverage test of epoch 44: loss -27.73428 acc 0.65789 roc_auc 0.55692 prc_auc 0.68460[0m
[92maverage training of epoch 45: loss -28.10043 acc 0.66667 roc_auc 0.41710 prc_auc 0.60211[0m
[93maverage test of epoch 45: loss -28.28554 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -28.65319 acc 0.66667 roc_auc 0.42050 prc_auc 0.60616[0m
[93maverage test of epoch 46: loss -28.83673 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -29.20562 acc 0.66667 roc_auc 0.42060 prc_auc 0.60817[0m
[93maverage test of epoch 47: loss -29.38798 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -29.75832 acc 0.66667 roc_auc 0.42260 prc_auc 0.60463[0m
[93maverage test of epoch 48: loss -29.93875 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -30.31063 acc 0.66667 roc_auc 0.42920 prc_auc 0.61702[0m
[93maverage test of epoch 49: loss -30.48955 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -1.20963 acc 0.68000 roc_auc 0.44660 prc_auc 0.65483[0m
[93maverage test of epoch 0: loss -2.16617 acc 0.65789 roc_auc 0.67385 prc_auc 0.75332[0m
[92maverage training of epoch 1: loss -3.06986 acc 0.66667 roc_auc 0.46760 prc_auc 0.67538[0m
[93maverage test of epoch 1: loss -3.80801 acc 0.65789 roc_auc 0.64923 prc_auc 0.80269[0m
[92maverage training of epoch 2: loss -4.28276 acc 0.66667 roc_auc 0.42320 prc_auc 0.59724[0m
[93maverage test of epoch 2: loss -4.66089 acc 0.65789 roc_auc 0.35385 prc_auc 0.63220[0m
[92maverage training of epoch 3: loss -5.06071 acc 0.66667 roc_auc 0.39740 prc_auc 0.59700[0m
[93maverage test of epoch 3: loss -5.37934 acc 0.65789 roc_auc 0.44923 prc_auc 0.69080[0m
[92maverage training of epoch 4: loss -5.74580 acc 0.66667 roc_auc 0.42580 prc_auc 0.61484[0m
[93maverage test of epoch 4: loss -6.02406 acc 0.65789 roc_auc 0.60308 prc_auc 0.76413[0m
[92maverage training of epoch 5: loss -6.36956 acc 0.66667 roc_auc 0.41960 prc_auc 0.62341[0m
[93maverage test of epoch 5: loss -6.64831 acc 0.65789 roc_auc 0.64154 prc_auc 0.72290[0m
[92maverage training of epoch 6: loss -6.97997 acc 0.66667 roc_auc 0.37380 prc_auc 0.58943[0m
[93maverage test of epoch 6: loss -7.23811 acc 0.65789 roc_auc 0.56615 prc_auc 0.73475[0m
[92maverage training of epoch 7: loss -7.57764 acc 0.66667 roc_auc 0.39020 prc_auc 0.58551[0m
[93maverage test of epoch 7: loss -7.82797 acc 0.65789 roc_auc 0.55385 prc_auc 0.75054[0m
[92maverage training of epoch 8: loss -8.16683 acc 0.66667 roc_auc 0.42120 prc_auc 0.61262[0m
[93maverage test of epoch 8: loss -8.41175 acc 0.65789 roc_auc 0.40462 prc_auc 0.62405[0m
[92maverage training of epoch 9: loss -8.74174 acc 0.66667 roc_auc 0.39490 prc_auc 0.58677[0m
[93maverage test of epoch 9: loss -8.98537 acc 0.65789 roc_auc 0.35385 prc_auc 0.57544[0m
[92maverage training of epoch 10: loss -9.31851 acc 0.66667 roc_auc 0.37720 prc_auc 0.58572[0m
[93maverage test of epoch 10: loss -9.55462 acc 0.65789 roc_auc 0.54462 prc_auc 0.71212[0m
[92maverage training of epoch 11: loss -9.88270 acc 0.66667 roc_auc 0.37980 prc_auc 0.58284[0m
[93maverage test of epoch 11: loss -10.12073 acc 0.65789 roc_auc 0.54308 prc_auc 0.65179[0m
[92maverage training of epoch 12: loss -10.45338 acc 0.66667 roc_auc 0.39560 prc_auc 0.59610[0m
[93maverage test of epoch 12: loss -10.69171 acc 0.65789 roc_auc 0.73231 prc_auc 0.82793[0m
[92maverage training of epoch 13: loss -11.01990 acc 0.66667 roc_auc 0.37860 prc_auc 0.57677[0m
[93maverage test of epoch 13: loss -11.25049 acc 0.65789 roc_auc 0.50769 prc_auc 0.66630[0m
[92maverage training of epoch 14: loss -11.58154 acc 0.66667 roc_auc 0.37710 prc_auc 0.58103[0m
[93maverage test of epoch 14: loss -11.81041 acc 0.65789 roc_auc 0.57231 prc_auc 0.71718[0m
[92maverage training of epoch 15: loss -12.14306 acc 0.66667 roc_auc 0.37850 prc_auc 0.57529[0m
[93maverage test of epoch 15: loss -12.36760 acc 0.65789 roc_auc 0.45077 prc_auc 0.63293[0m
[92maverage training of epoch 16: loss -12.70124 acc 0.66667 roc_auc 0.38610 prc_auc 0.59511[0m
[93maverage test of epoch 16: loss -12.92616 acc 0.65789 roc_auc 0.55385 prc_auc 0.68151[0m
[92maverage training of epoch 17: loss -13.26212 acc 0.66667 roc_auc 0.37090 prc_auc 0.57774[0m
[93maverage test of epoch 17: loss -13.48357 acc 0.65789 roc_auc 0.52769 prc_auc 0.66533[0m
[92maverage training of epoch 18: loss -13.81746 acc 0.66667 roc_auc 0.37050 prc_auc 0.57861[0m
[93maverage test of epoch 18: loss -14.04091 acc 0.65789 roc_auc 0.39077 prc_auc 0.61310[0m
[92maverage training of epoch 19: loss -14.37559 acc 0.66667 roc_auc 0.37620 prc_auc 0.58118[0m
[93maverage test of epoch 19: loss -14.59326 acc 0.65789 roc_auc 0.44615 prc_auc 0.62706[0m
[92maverage training of epoch 20: loss -14.93304 acc 0.66667 roc_auc 0.37650 prc_auc 0.57479[0m
[93maverage test of epoch 20: loss -15.14861 acc 0.65789 roc_auc 0.54923 prc_auc 0.67074[0m
[92maverage training of epoch 21: loss -15.48771 acc 0.66667 roc_auc 0.37870 prc_auc 0.57635[0m
[93maverage test of epoch 21: loss -15.70141 acc 0.65789 roc_auc 0.36769 prc_auc 0.58863[0m
[92maverage training of epoch 22: loss -16.04457 acc 0.66667 roc_auc 0.37060 prc_auc 0.56840[0m
[93maverage test of epoch 22: loss -16.25607 acc 0.65789 roc_auc 0.52615 prc_auc 0.65628[0m
[92maverage training of epoch 23: loss -16.59901 acc 0.66667 roc_auc 0.39000 prc_auc 0.58459[0m
[93maverage test of epoch 23: loss -16.80903 acc 0.65789 roc_auc 0.48615 prc_auc 0.65246[0m
[92maverage training of epoch 24: loss -17.15320 acc 0.66667 roc_auc 0.37480 prc_auc 0.57619[0m
[93maverage test of epoch 24: loss -17.36329 acc 0.65789 roc_auc 0.55846 prc_auc 0.68365[0m
[92maverage training of epoch 25: loss -17.70758 acc 0.66667 roc_auc 0.37490 prc_auc 0.57899[0m
[93maverage test of epoch 25: loss -17.91534 acc 0.65789 roc_auc 0.59692 prc_auc 0.71288[0m
[92maverage training of epoch 26: loss -18.26131 acc 0.66667 roc_auc 0.37320 prc_auc 0.57280[0m
[93maverage test of epoch 26: loss -18.46648 acc 0.65789 roc_auc 0.48462 prc_auc 0.64021[0m
[92maverage training of epoch 27: loss -18.81557 acc 0.66667 roc_auc 0.38200 prc_auc 0.58002[0m
[93maverage test of epoch 27: loss -19.01746 acc 0.65789 roc_auc 0.56923 prc_auc 0.71291[0m
[92maverage training of epoch 28: loss -19.36856 acc 0.66667 roc_auc 0.38290 prc_auc 0.57809[0m
[93maverage test of epoch 28: loss -19.57138 acc 0.65789 roc_auc 0.58000 prc_auc 0.70074[0m
[92maverage training of epoch 29: loss -19.92282 acc 0.66667 roc_auc 0.37970 prc_auc 0.58071[0m
[93maverage test of epoch 29: loss -20.12192 acc 0.65789 roc_auc 0.40308 prc_auc 0.61430[0m
[92maverage training of epoch 30: loss -20.47575 acc 0.66667 roc_auc 0.37020 prc_auc 0.57083[0m
[93maverage test of epoch 30: loss -20.67549 acc 0.65789 roc_auc 0.49077 prc_auc 0.65403[0m
[92maverage training of epoch 31: loss -21.02917 acc 0.66667 roc_auc 0.38060 prc_auc 0.57741[0m
[93maverage test of epoch 31: loss -21.22656 acc 0.65789 roc_auc 0.51846 prc_auc 0.66684[0m
[92maverage training of epoch 32: loss -21.58311 acc 0.66667 roc_auc 0.37770 prc_auc 0.57821[0m
[93maverage test of epoch 32: loss -21.77575 acc 0.65789 roc_auc 0.48154 prc_auc 0.65157[0m
[92maverage training of epoch 33: loss -22.13587 acc 0.66667 roc_auc 0.38580 prc_auc 0.58662[0m
[93maverage test of epoch 33: loss -22.32955 acc 0.65789 roc_auc 0.38154 prc_auc 0.61212[0m
[92maverage training of epoch 34: loss -22.68841 acc 0.66667 roc_auc 0.37610 prc_auc 0.57852[0m
[93maverage test of epoch 34: loss -22.88055 acc 0.65789 roc_auc 0.44000 prc_auc 0.63209[0m
[92maverage training of epoch 35: loss -23.24126 acc 0.66667 roc_auc 0.37910 prc_auc 0.58018[0m
[93maverage test of epoch 35: loss -23.43214 acc 0.65789 roc_auc 0.47231 prc_auc 0.64584[0m
[92maverage training of epoch 36: loss -23.79396 acc 0.66667 roc_auc 0.37580 prc_auc 0.58297[0m
[93maverage test of epoch 36: loss -23.98187 acc 0.65789 roc_auc 0.49846 prc_auc 0.65720[0m
[92maverage training of epoch 37: loss -24.34645 acc 0.66667 roc_auc 0.38020 prc_auc 0.58286[0m
[93maverage test of epoch 37: loss -24.53415 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -24.89976 acc 0.66667 roc_auc 0.38180 prc_auc 0.58430[0m
[93maverage test of epoch 38: loss -25.08519 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -25.45198 acc 0.66667 roc_auc 0.37260 prc_auc 0.58045[0m
[93maverage test of epoch 39: loss -25.63589 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -26.00447 acc 0.66667 roc_auc 0.37580 prc_auc 0.58736[0m
[93maverage test of epoch 40: loss -26.18708 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -26.55688 acc 0.66667 roc_auc 0.37850 prc_auc 0.58664[0m
[93maverage test of epoch 41: loss -26.73805 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -27.10958 acc 0.66667 roc_auc 0.39370 prc_auc 0.59864[0m
[93maverage test of epoch 42: loss -27.28866 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -27.66217 acc 0.66667 roc_auc 0.38380 prc_auc 0.59267[0m
[93maverage test of epoch 43: loss -27.83991 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -28.21461 acc 0.66667 roc_auc 0.38660 prc_auc 0.59866[0m
[93maverage test of epoch 44: loss -28.39083 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -28.76719 acc 0.66667 roc_auc 0.38850 prc_auc 0.59870[0m
[93maverage test of epoch 45: loss -28.94159 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -29.31936 acc 0.66667 roc_auc 0.39930 prc_auc 0.61174[0m
[93maverage test of epoch 46: loss -29.49223 acc 0.65789 roc_auc 0.49846 prc_auc 0.65720[0m
[92maverage training of epoch 47: loss -29.87180 acc 0.66667 roc_auc 0.37740 prc_auc 0.59689[0m
[93maverage test of epoch 47: loss -30.04302 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -30.42415 acc 0.66667 roc_auc 0.38560 prc_auc 0.60611[0m
[93maverage test of epoch 48: loss -30.59404 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -30.97647 acc 0.66667 roc_auc 0.39180 prc_auc 0.60981[0m
[93maverage test of epoch 49: loss -31.14473 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -0.98815 acc 0.38411 roc_auc 0.51255 prc_auc 0.71612[0m
[93maverage test of epoch 0: loss -1.43993 acc 0.54054 roc_auc 0.65000 prc_auc 0.83354[0m
[92maverage training of epoch 1: loss -2.02356 acc 0.66887 roc_auc 0.72824 prc_auc 0.82715[0m
[93maverage test of epoch 1: loss -2.59145 acc 0.70270 roc_auc 0.85333 prc_auc 0.89597[0m
[92maverage training of epoch 2: loss -2.99045 acc 0.74834 roc_auc 0.83039 prc_auc 0.87883[0m
[93maverage test of epoch 2: loss -3.37767 acc 0.78378 roc_auc 0.84000 prc_auc 0.89032[0m
[92maverage training of epoch 3: loss -3.74222 acc 0.82119 roc_auc 0.86176 prc_auc 0.90220[0m
[93maverage test of epoch 3: loss -4.05083 acc 0.81081 roc_auc 0.84667 prc_auc 0.90107[0m
[92maverage training of epoch 4: loss -4.43404 acc 0.84106 roc_auc 0.86098 prc_auc 0.88123[0m
[93maverage test of epoch 4: loss -4.59375 acc 0.78378 roc_auc 0.82333 prc_auc 0.87406[0m
[92maverage training of epoch 5: loss -4.93051 acc 0.82781 roc_auc 0.85098 prc_auc 0.87841[0m
[93maverage test of epoch 5: loss -5.17832 acc 0.81081 roc_auc 0.87000 prc_auc 0.93002[0m
[92maverage training of epoch 6: loss -5.54644 acc 0.84106 roc_auc 0.85961 prc_auc 0.87906[0m
[93maverage test of epoch 6: loss -5.67958 acc 0.78378 roc_auc 0.83000 prc_auc 0.89015[0m
[92maverage training of epoch 7: loss -6.10065 acc 0.86093 roc_auc 0.86098 prc_auc 0.87112[0m
[93maverage test of epoch 7: loss -6.14367 acc 0.81081 roc_auc 0.87333 prc_auc 0.93547[0m
[92maverage training of epoch 8: loss -6.65665 acc 0.86755 roc_auc 0.85765 prc_auc 0.87882[0m
[93maverage test of epoch 8: loss -6.61903 acc 0.78378 roc_auc 0.86000 prc_auc 0.92558[0m
[92maverage training of epoch 9: loss -7.14619 acc 0.87417 roc_auc 0.85843 prc_auc 0.87768[0m
[93maverage test of epoch 9: loss -7.04370 acc 0.78378 roc_auc 0.86500 prc_auc 0.93325[0m
[92maverage training of epoch 10: loss -7.69898 acc 0.86755 roc_auc 0.86373 prc_auc 0.86237[0m
[93maverage test of epoch 10: loss -7.54032 acc 0.78378 roc_auc 0.86667 prc_auc 0.93765[0m
[92maverage training of epoch 11: loss -8.20408 acc 0.88079 roc_auc 0.85588 prc_auc 0.85408[0m
[93maverage test of epoch 11: loss -8.07450 acc 0.81081 roc_auc 0.85833 prc_auc 0.92362[0m
[92maverage training of epoch 12: loss -8.70692 acc 0.87417 roc_auc 0.85941 prc_auc 0.85667[0m
[93maverage test of epoch 12: loss -8.36685 acc 0.75676 roc_auc 0.88000 prc_auc 0.94062[0m
[92maverage training of epoch 13: loss -9.24090 acc 0.88742 roc_auc 0.86412 prc_auc 0.86179[0m
[93maverage test of epoch 13: loss -8.79950 acc 0.75676 roc_auc 0.82500 prc_auc 0.88523[0m
[92maverage training of epoch 14: loss -9.66212 acc 0.87417 roc_auc 0.84735 prc_auc 0.85028[0m
[93maverage test of epoch 14: loss -9.42063 acc 0.78378 roc_auc 0.85667 prc_auc 0.89704[0m
[92maverage training of epoch 15: loss -10.16160 acc 0.89404 roc_auc 0.86520 prc_auc 0.88033[0m
[93maverage test of epoch 15: loss -10.03470 acc 0.81081 roc_auc 0.84500 prc_auc 0.91869[0m
[92maverage training of epoch 16: loss -10.53735 acc 0.87417 roc_auc 0.86314 prc_auc 0.86813[0m
[93maverage test of epoch 16: loss -10.39057 acc 0.81081 roc_auc 0.88000 prc_auc 0.94144[0m
[92maverage training of epoch 17: loss -11.09910 acc 0.88742 roc_auc 0.85716 prc_auc 0.87185[0m
[93maverage test of epoch 17: loss -10.91813 acc 0.81081 roc_auc 0.76167 prc_auc 0.81427[0m
[92maverage training of epoch 18: loss -11.51551 acc 0.87417 roc_auc 0.85588 prc_auc 0.87496[0m
[93maverage test of epoch 18: loss -11.24214 acc 0.78378 roc_auc 0.87167 prc_auc 0.91480[0m
[92maverage training of epoch 19: loss -12.06863 acc 0.88742 roc_auc 0.85088 prc_auc 0.87186[0m
[93maverage test of epoch 19: loss -11.79965 acc 0.78378 roc_auc 0.79500 prc_auc 0.85078[0m
[92maverage training of epoch 20: loss -12.65138 acc 0.90066 roc_auc 0.85304 prc_auc 0.85692[0m
[93maverage test of epoch 20: loss -12.23608 acc 0.78378 roc_auc 0.78500 prc_auc 0.85089[0m
[92maverage training of epoch 21: loss -13.10556 acc 0.90066 roc_auc 0.85049 prc_auc 0.86088[0m
[93maverage test of epoch 21: loss -12.62350 acc 0.78378 roc_auc 0.82833 prc_auc 0.87326[0m
[92maverage training of epoch 22: loss -13.36382 acc 0.86093 roc_auc 0.86500 prc_auc 0.87698[0m
[93maverage test of epoch 22: loss -13.33301 acc 0.81081 roc_auc 0.79667 prc_auc 0.84512[0m
[92maverage training of epoch 23: loss -13.95949 acc 0.88079 roc_auc 0.85471 prc_auc 0.86667[0m
[93maverage test of epoch 23: loss -13.53600 acc 0.78378 roc_auc 0.78667 prc_auc 0.84245[0m
[92maverage training of epoch 24: loss -14.48388 acc 0.89404 roc_auc 0.84814 prc_auc 0.86543[0m
[93maverage test of epoch 24: loss -14.10894 acc 0.81081 roc_auc 0.85333 prc_auc 0.89452[0m
[92maverage training of epoch 25: loss -14.85917 acc 0.87417 roc_auc 0.86137 prc_auc 0.89111[0m
[93maverage test of epoch 25: loss -14.59875 acc 0.81081 roc_auc 0.81500 prc_auc 0.86986[0m
[92maverage training of epoch 26: loss -15.52484 acc 0.90066 roc_auc 0.86039 prc_auc 0.88169[0m
[93maverage test of epoch 26: loss -14.90054 acc 0.81081 roc_auc 0.75167 prc_auc 0.81513[0m
[92maverage training of epoch 27: loss -15.89906 acc 0.88742 roc_auc 0.86931 prc_auc 0.89502[0m
[93maverage test of epoch 27: loss -15.52633 acc 0.81081 roc_auc 0.79333 prc_auc 0.84401[0m
[92maverage training of epoch 28: loss -16.32018 acc 0.88079 roc_auc 0.85843 prc_auc 0.88514[0m
[93maverage test of epoch 28: loss -16.11464 acc 0.81081 roc_auc 0.80833 prc_auc 0.86830[0m
[92maverage training of epoch 29: loss -16.92743 acc 0.90066 roc_auc 0.88422 prc_auc 0.91192[0m
[93maverage test of epoch 29: loss -16.42735 acc 0.81081 roc_auc 0.81500 prc_auc 0.86996[0m
[92maverage training of epoch 30: loss -17.23229 acc 0.87417 roc_auc 0.87608 prc_auc 0.90177[0m
[93maverage test of epoch 30: loss -16.73031 acc 0.78378 roc_auc 0.82167 prc_auc 0.87151[0m
[92maverage training of epoch 31: loss -17.59132 acc 0.86755 roc_auc 0.88735 prc_auc 0.91178[0m
[93maverage test of epoch 31: loss -17.41917 acc 0.81081 roc_auc 0.78000 prc_auc 0.83726[0m
[92maverage training of epoch 32: loss -18.03733 acc 0.86755 roc_auc 0.89225 prc_auc 0.92022[0m
[93maverage test of epoch 32: loss -18.20442 acc 0.86486 roc_auc 0.81667 prc_auc 0.86745[0m
[92maverage training of epoch 33: loss -18.69347 acc 0.88079 roc_auc 0.89549 prc_auc 0.91527[0m
[93maverage test of epoch 33: loss -18.36652 acc 0.81081 roc_auc 0.76667 prc_auc 0.83055[0m
[92maverage training of epoch 34: loss -19.01677 acc 0.86755 roc_auc 0.88216 prc_auc 0.90609[0m
[93maverage test of epoch 34: loss -18.87272 acc 0.81081 roc_auc 0.77000 prc_auc 0.83816[0m
[92maverage training of epoch 35: loss -19.62784 acc 0.87417 roc_auc 0.88353 prc_auc 0.90767[0m
[93maverage test of epoch 35: loss -19.35875 acc 0.81081 roc_auc 0.78333 prc_auc 0.84170[0m
[92maverage training of epoch 36: loss -19.91724 acc 0.87417 roc_auc 0.91784 prc_auc 0.94094[0m
[93maverage test of epoch 36: loss -20.06178 acc 0.83784 roc_auc 0.82833 prc_auc 0.87398[0m
[92maverage training of epoch 37: loss -20.79257 acc 0.88742 roc_auc 0.90961 prc_auc 0.93445[0m
[93maverage test of epoch 37: loss -20.32739 acc 0.81081 roc_auc 0.82167 prc_auc 0.87184[0m
[92maverage training of epoch 38: loss -21.11306 acc 0.88742 roc_auc 0.91431 prc_auc 0.93531[0m
[93maverage test of epoch 38: loss -20.46150 acc 0.81081 roc_auc 0.74500 prc_auc 0.81349[0m
[92maverage training of epoch 39: loss -21.74323 acc 0.90728 roc_auc 0.90608 prc_auc 0.93317[0m
[93maverage test of epoch 39: loss -21.00451 acc 0.81081 roc_auc 0.74500 prc_auc 0.81371[0m
[92maverage training of epoch 40: loss -22.20404 acc 0.90728 roc_auc 0.90627 prc_auc 0.93240[0m
[93maverage test of epoch 40: loss -21.55067 acc 0.81081 roc_auc 0.77333 prc_auc 0.83897[0m
[92maverage training of epoch 41: loss -22.75023 acc 0.90066 roc_auc 0.91157 prc_auc 0.93491[0m
[93maverage test of epoch 41: loss -21.97181 acc 0.81081 roc_auc 0.79000 prc_auc 0.84348[0m
[92maverage training of epoch 42: loss -23.38703 acc 0.90728 roc_auc 0.92039 prc_auc 0.93837[0m
[93maverage test of epoch 42: loss -22.35980 acc 0.81081 roc_auc 0.74500 prc_auc 0.81371[0m
[92maverage training of epoch 43: loss -23.69960 acc 0.90066 roc_auc 0.91667 prc_auc 0.93662[0m
[93maverage test of epoch 43: loss -22.73843 acc 0.81081 roc_auc 0.75167 prc_auc 0.81549[0m
[92maverage training of epoch 44: loss -24.31991 acc 0.90066 roc_auc 0.91873 prc_auc 0.93796[0m
[93maverage test of epoch 44: loss -23.32998 acc 0.81081 roc_auc 0.79333 prc_auc 0.84428[0m
[92maverage training of epoch 45: loss -24.56904 acc 0.89404 roc_auc 0.90569 prc_auc 0.92706[0m
[93maverage test of epoch 45: loss -23.74145 acc 0.81081 roc_auc 0.75833 prc_auc 0.81699[0m
[92maverage training of epoch 46: loss -25.13483 acc 0.90728 roc_auc 0.91176 prc_auc 0.94096[0m
[93maverage test of epoch 46: loss -24.08610 acc 0.78378 roc_auc 0.74167 prc_auc 0.81258[0m
[92maverage training of epoch 47: loss -25.84058 acc 0.91391 roc_auc 0.91471 prc_auc 0.93699[0m
[93maverage test of epoch 47: loss -24.99362 acc 0.83784 roc_auc 0.78667 prc_auc 0.84273[0m
[92maverage training of epoch 48: loss -26.32090 acc 0.91391 roc_auc 0.93118 prc_auc 0.94797[0m
[93maverage test of epoch 48: loss -24.76858 acc 0.78378 roc_auc 0.70000 prc_auc 0.78577[0m
[92maverage training of epoch 49: loss -26.61581 acc 0.90728 roc_auc 0.90549 prc_auc 0.92749[0m
[93maverage test of epoch 49: loss -25.59833 acc 0.81081 roc_auc 0.73833 prc_auc 0.81183[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -1.05125 acc 0.49007 roc_auc 0.47294 prc_auc 0.65939[0m
[93maverage test of epoch 0: loss -1.44978 acc 0.32432 roc_auc 0.56667 prc_auc 0.70510[0m
[92maverage training of epoch 1: loss -1.81326 acc 0.50993 roc_auc 0.44647 prc_auc 0.63388[0m
[93maverage test of epoch 1: loss -2.20458 acc 0.67568 roc_auc 0.69667 prc_auc 0.86569[0m
[92maverage training of epoch 2: loss -2.55028 acc 0.64238 roc_auc 0.40333 prc_auc 0.60361[0m
[93maverage test of epoch 2: loss -2.93653 acc 0.67568 roc_auc 0.60667 prc_auc 0.75623[0m
[92maverage training of epoch 3: loss -3.27850 acc 0.66225 roc_auc 0.39627 prc_auc 0.61423[0m
[93maverage test of epoch 3: loss -3.65816 acc 0.67568 roc_auc 0.50667 prc_auc 0.74355[0m
[92maverage training of epoch 4: loss -3.97986 acc 0.66225 roc_auc 0.39431 prc_auc 0.59008[0m
[93maverage test of epoch 4: loss -4.34274 acc 0.67568 roc_auc 0.71667 prc_auc 0.86795[0m
[92maverage training of epoch 5: loss -4.64380 acc 0.66225 roc_auc 0.39059 prc_auc 0.59186[0mUsing backend: pytorch

[93maverage test of epoch 5: loss -4.98640 acc 0.67568 roc_auc 0.58667 prc_auc 0.75690[0m
[92maverage training of epoch 6: loss -5.27598 acc 0.66225 roc_auc 0.37196 prc_auc 0.57537[0m
[93maverage test of epoch 6: loss -5.60615 acc 0.67568 roc_auc 0.71333 prc_auc 0.87321[0m
[92maverage training of epoch 7: loss -5.88570 acc 0.66225 roc_auc 0.38412 prc_auc 0.59327[0m
[93maverage test of epoch 7: loss -6.20639 acc 0.67568 roc_auc 0.49667 prc_auc 0.69832[0m
[92maverage training of epoch 8: loss -6.48490 acc 0.66225 roc_auc 0.37725 prc_auc 0.57608[0m
[93maverage test of epoch 8: loss -6.80701 acc 0.67568 roc_auc 0.45667 prc_auc 0.69937[0m
[92maverage training of epoch 9: loss -7.07257 acc 0.66225 roc_auc 0.36078 prc_auc 0.56704[0m
[93maverage test of epoch 9: loss -7.39357 acc 0.67568 roc_auc 0.56167 prc_auc 0.76325[0m
[92maverage training of epoch 10: loss -7.65551 acc 0.66225 roc_auc 0.37745 prc_auc 0.57424[0m
[93maverage test of epoch 10: loss -7.98015 acc 0.67568 roc_auc 0.58333 prc_auc 0.77242[0m
[92maverage training of epoch 11: loss -8.23117 acc 0.66225 roc_auc 0.37784 prc_auc 0.59001[0m
[93maverage test of epoch 11: loss -8.55595 acc 0.67568 roc_auc 0.52333 prc_auc 0.79644[0m
[92maverage training of epoch 12: loss -8.80608 acc 0.66225 roc_auc 0.37529 prc_auc 0.57715[0m
[93maverage test of epoch 12: loss -9.13083 acc 0.67568 roc_auc 0.50333 prc_auc 0.69430[0m
[92maverage training of epoch 13: loss -9.37618 acc 0.66225 roc_auc 0.36275 prc_auc 0.56300[0m
[93maverage test of epoch 13: loss -9.70404 acc 0.67568 roc_auc 0.47000 prc_auc 0.65268[0m
[92maverage training of epoch 14: loss -9.94411 acc 0.66225 roc_auc 0.36765 prc_auc 0.56369[0m
[93maverage test of epoch 14: loss -10.27350 acc 0.67568 roc_auc 0.69167 prc_auc 0.81018[0m
[92maverage training of epoch 15: loss -10.51115 acc 0.66225 roc_auc 0.36990 prc_auc 0.56579[0m
[93maverage test of epoch 15: loss -10.83996 acc 0.67568 roc_auc 0.54167 prc_auc 0.73556[0m
[92maverage training of epoch 16: loss -11.07500 acc 0.66225 roc_auc 0.37235 prc_auc 0.57125[0m
[93maverage test of epoch 16: loss -11.40605 acc 0.67568 roc_auc 0.52000 prc_auc 0.72038[0m
[92maverage training of epoch 17: loss -11.63754 acc 0.66225 roc_auc 0.36000 prc_auc 0.56019[0m
[93maverage test of epoch 17: loss -11.96774 acc 0.67568 roc_auc 0.45333 prc_auc 0.65015[0m
[92maverage training of epoch 18: loss -12.19909 acc 0.66225 roc_auc 0.37412 prc_auc 0.57171[0m
[93maverage test of epoch 18: loss -12.53225 acc 0.67568 roc_auc 0.68333 prc_auc 0.81532[0m
[92maverage training of epoch 19: loss -12.75978 acc 0.66225 roc_auc 0.37333 prc_auc 0.57334[0m
[93maverage test of epoch 19: loss -13.09563 acc 0.67568 roc_auc 0.25500 prc_auc 0.56211[0m
[92maverage training of epoch 20: loss -13.32069 acc 0.66225 roc_auc 0.36549 prc_auc 0.56702[0m
[93maverage test of epoch 20: loss -13.65583 acc 0.67568 roc_auc 0.44500 prc_auc 0.65835[0m
[92maverage training of epoch 21: loss -13.88052 acc 0.66225 roc_auc 0.36618 prc_auc 0.56493[0m
[93maverage test of epoch 21: loss -14.21715 acc 0.67568 roc_auc 0.63333 prc_auc 0.77119[0m
[92maverage training of epoch 22: loss -14.43799 acc 0.66225 roc_auc 0.36843 prc_auc 0.56811[0m
[93maverage test of epoch 22: loss -14.78110 acc 0.67568 roc_auc 0.36167 prc_auc 0.60751[0m
[92maverage training of epoch 23: loss -14.99677 acc 0.66225 roc_auc 0.37000 prc_auc 0.56708[0m
[93maverage test of epoch 23: loss -15.34093 acc 0.67568 roc_auc 0.54333 prc_auc 0.73239[0m
[92maverage training of epoch 24: loss -15.55334 acc 0.66225 roc_auc 0.36745 prc_auc 0.56723[0m
[93maverage test of epoch 24: loss -15.90036 acc 0.67568 roc_auc 0.45167 prc_auc 0.63885[0m
[92maverage training of epoch 25: loss -16.11186 acc 0.66225 roc_auc 0.36657 prc_auc 0.56470[0m
[93maverage test of epoch 25: loss -16.45905 acc 0.67568 roc_auc 0.57667 prc_auc 0.71671[0m
[92maverage training of epoch 26: loss -16.66809 acc 0.66225 roc_auc 0.37255 prc_auc 0.56957[0m
[93maverage test of epoch 26: loss -17.01873 acc 0.67568 roc_auc 0.41833 prc_auc 0.63311[0m
[92maverage training of epoch 27: loss -17.22469 acc 0.66225 roc_auc 0.36931 prc_auc 0.56971[0m
[93maverage test of epoch 27: loss -17.57630 acc 0.67568 roc_auc 0.46667 prc_auc 0.67323[0m
[92maverage training of epoch 28: loss -17.78186 acc 0.66225 roc_auc 0.37059 prc_auc 0.57061[0m
[93maverage test of epoch 28: loss -18.13672 acc 0.67568 roc_auc 0.52667 prc_auc 0.70295[0m
[92maverage training of epoch 29: loss -18.33805 acc 0.66225 roc_auc 0.36922 prc_auc 0.56849[0m
[93maverage test of epoch 29: loss -18.69460 acc 0.67568 roc_auc 0.40500 prc_auc 0.63054[0m
[92maverage training of epoch 30: loss -18.89379 acc 0.66225 roc_auc 0.37020 prc_auc 0.56854[0m
[93maverage test of epoch 30: loss -19.25250 acc 0.67568 roc_auc 0.35167 prc_auc 0.59608[0m
[92maverage training of epoch 31: loss -19.45000 acc 0.66225 roc_auc 0.36843 prc_auc 0.56827[0m
[93maverage test of epoch 31: loss -19.81027 acc 0.67568 roc_auc 0.40500 prc_auc 0.62728[0m
[92maverage training of epoch 32: loss -20.00500 acc 0.66225 roc_auc 0.36912 prc_auc 0.56741[0m
[93maverage test of epoch 32: loss -20.36897 acc 0.67568 roc_auc 0.50333 prc_auc 0.68206[0m
[92maverage training of epoch 33: loss -20.56126 acc 0.66225 roc_auc 0.36794 prc_auc 0.56713[0m
[93maverage test of epoch 33: loss -20.92628 acc 0.67568 roc_auc 0.26167 prc_auc 0.56193[0m
[92maverage training of epoch 34: loss -21.11646 acc 0.66225 roc_auc 0.37186 prc_auc 0.57103[0m
[93maverage test of epoch 34: loss -21.48471 acc 0.67568 roc_auc 0.39000 prc_auc 0.62049[0m
[92maverage training of epoch 35: loss -21.67235 acc 0.66225 roc_auc 0.36941 prc_auc 0.56768[0m
[93maverage test of epoch 35: loss -22.04230 acc 0.67568 roc_auc 0.51000 prc_auc 0.67790[0m
[92maverage training of epoch 36: loss -22.22723 acc 0.66225 roc_auc 0.36873 prc_auc 0.56830[0m
[93maverage test of epoch 36: loss -22.60066 acc 0.67568 roc_auc 0.45333 prc_auc 0.65484[0m
[92maverage training of epoch 37: loss -22.78292 acc 0.66225 roc_auc 0.37029 prc_auc 0.56849[0m
[93maverage test of epoch 37: loss -23.15823 acc 0.67568 roc_auc 0.51333 prc_auc 0.68532[0m
[92maverage training of epoch 38: loss -23.33810 acc 0.66225 roc_auc 0.36971 prc_auc 0.56951[0m
[93maverage test of epoch 38: loss -23.71453 acc 0.67568 roc_auc 0.47000 prc_auc 0.66905[0m
[92maverage training of epoch 39: loss -23.89302 acc 0.66225 roc_auc 0.36843 prc_auc 0.56878[0m
[93maverage test of epoch 39: loss -24.27335 acc 0.67568 roc_auc 0.49500 prc_auc 0.67290[0m
[92maverage training of epoch 40: loss -24.44821 acc 0.66225 roc_auc 0.37010 prc_auc 0.57113[0m
[93maverage test of epoch 40: loss -24.82945 acc 0.67568 roc_auc 0.27833 prc_auc 0.57520[0m
[92maverage training of epoch 41: loss -25.00325 acc 0.66225 roc_auc 0.37108 prc_auc 0.56982[0m
[93maverage test of epoch 41: loss -25.38829 acc 0.67568 roc_auc 0.43833 prc_auc 0.64868[0m
[92maverage training of epoch 42: loss -25.55810 acc 0.66225 roc_auc 0.36804 prc_auc 0.56738[0m
[93maverage test of epoch 42: loss -25.94504 acc 0.67568 roc_auc 0.45000 prc_auc 0.65239[0m
[92maverage training of epoch 43: loss -26.11332 acc 0.66225 roc_auc 0.36971 prc_auc 0.56796[0m
[93maverage test of epoch 43: loss -26.50264 acc 0.67568 roc_auc 0.57000 prc_auc 0.70912[0m
[92maverage training of epoch 44: loss -26.66819 acc 0.66225 roc_auc 0.37078 prc_auc 0.56961[0m
[93maverage test of epoch 44: loss -27.06022 acc 0.67568 roc_auc 0.59500 prc_auc 0.72417[0m
[92maverage training of epoch 45: loss -27.22341 acc 0.66225 roc_auc 0.36941 prc_auc 0.56882[0m
[93maverage test of epoch 45: loss -27.61728 acc 0.67568 roc_auc 0.42667 prc_auc 0.64455[0m
[92maverage training of epoch 46: loss -27.77809 acc 0.66225 roc_auc 0.36961 prc_auc 0.57079[0m
[93maverage test of epoch 46: loss -28.17479 acc 0.67568 roc_auc 0.58500 prc_auc 0.71530[0m
[92maverage training of epoch 47: loss -28.33310 acc 0.66225 roc_auc 0.36922 prc_auc 0.56865[0m
[93maverage test of epoch 47: loss -28.73197 acc 0.67568 roc_auc 0.46000 prc_auc 0.65863[0m
[92maverage training of epoch 48: loss -28.88760 acc 0.66225 roc_auc 0.37069 prc_auc 0.56994[0m
[93maverage test of epoch 48: loss -29.28921 acc 0.67568 roc_auc 0.46000 prc_auc 0.65827[0m
[92maverage training of epoch 49: loss -29.44284 acc 0.66225 roc_auc 0.36814 prc_auc 0.56829[0m
[93maverage test of epoch 49: loss -29.84645 acc 0.67568 roc_auc 0.48000 prc_auc 0.66703[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.69203 ROC_AUC (avg): 0.54367 PRC_AUC (avg): 0.69051 

Average forward propagation time taken(ms): 3.957680322006838
Average backward propagation time taken(ms): 1.5145419287035216

