# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 2)
('lr', 0.0001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-04-49-59/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-04-49-59/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 16,
 'epochs': 100,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 8,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.0001,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 1,
 'num_workers': 8,
 'number_of_mlp_layer': 2,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-18-04-49-59',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 100, 'learning_rate': 0.0001, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=8, bias=True)
    (ReLU1): ReLU()
    (Linear2): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss 0.39610 acc 0.33333 roc_auc 0.65840 prc_auc 0.83053[0m
[93maverage test of epoch 0: loss 0.21118 acc 0.34211 roc_auc 0.84615 prc_auc 0.91257[0m
[92maverage training of epoch 1: loss 0.09252 acc 0.33333 roc_auc 0.73360 prc_auc 0.86851[0m
[93maverage test of epoch 1: loss -0.08041 acc 0.34211 roc_auc 0.86154 prc_auc 0.93076[0m
[92maverage training of epoch 2: loss -0.19220 acc 0.33333 roc_auc 0.78360 prc_auc 0.89558[0m
[93maverage test of epoch 2: loss -0.36135 acc 0.34211 roc_auc 0.86462 prc_auc 0.93409[0m
[92maverage training of epoch 3: loss -0.47253 acc 0.33333 roc_auc 0.81800 prc_auc 0.91356[0m
[93maverage test of epoch 3: loss -0.64122 acc 0.34211 roc_auc 0.86462 prc_auc 0.93409[0m
[92maverage training of epoch 4: loss -0.74615 acc 0.33333 roc_auc 0.84100 prc_auc 0.92498[0m
[93maverage test of epoch 4: loss -0.90950 acc 0.34211 roc_auc 0.86462 prc_auc 0.93409[0m
[92maverage training of epoch 5: loss -1.00469 acc 0.33333 roc_auc 0.86320 prc_auc 0.93331[0m
[93maverage test of epoch 5: loss -1.16050 acc 0.34211 roc_auc 0.86462 prc_auc 0.93409[0m
[92maverage training of epoch 6: loss -1.24491 acc 0.33333 roc_auc 0.87200 prc_auc 0.93673[0m
[93maverage test of epoch 6: loss -1.39013 acc 0.34211 roc_auc 0.86462 prc_auc 0.93409[0m
[92maverage training of epoch 7: loss -1.44029 acc 0.33333 roc_auc 0.87380 prc_auc 0.93749[0m
[93maverage test of epoch 7: loss -1.57602 acc 0.34211 roc_auc 0.86462 prc_auc 0.93409[0m
[92maverage training of epoch 8: loss -1.62952 acc 0.33333 roc_auc 0.87540 prc_auc 0.93773[0m
[93maverage test of epoch 8: loss -1.78015 acc 0.34211 roc_auc 0.86462 prc_auc 0.93409[0m
[92maverage training of epoch 9: loss -1.83885 acc 0.33333 roc_auc 0.87660 prc_auc 0.93810[0m
[93maverage test of epoch 9: loss -2.00640 acc 0.34211 roc_auc 0.87077 prc_auc 0.93634[0m
[92maverage training of epoch 10: loss -2.07370 acc 0.33333 roc_auc 0.87640 prc_auc 0.93828[0m
[93maverage test of epoch 10: loss -2.26017 acc 0.34211 roc_auc 0.87077 prc_auc 0.93634[0m
[92maverage training of epoch 11: loss -2.34185 acc 0.33333 roc_auc 0.87460 prc_auc 0.93816[0m
[93maverage test of epoch 11: loss -2.55270 acc 0.34211 roc_auc 0.87385 prc_auc 0.93759[0m
[92maverage training of epoch 12: loss -2.65211 acc 0.33333 roc_auc 0.87280 prc_auc 0.93815[0m
[93maverage test of epoch 12: loss -2.89174 acc 0.34211 roc_auc 0.87385 prc_auc 0.93759[0m
[92maverage training of epoch 13: loss -3.01360 acc 0.33333 roc_auc 0.86240 prc_auc 0.93465[0m
[93maverage test of epoch 13: loss -3.28566 acc 0.34211 roc_auc 0.86769 prc_auc 0.93559[0m
[92maverage training of epoch 14: loss -3.42235 acc 0.33333 roc_auc 0.84800 prc_auc 0.93161[0m
[93maverage test of epoch 14: loss -3.72325 acc 0.34211 roc_auc 0.86462 prc_auc 0.93834[0m
[92maverage training of epoch 15: loss -3.87560 acc 0.33333 roc_auc 0.83340 prc_auc 0.92742[0m
[93maverage test of epoch 15: loss -4.20838 acc 0.34211 roc_auc 0.87077 prc_auc 0.93977[0m
[92maverage training of epoch 16: loss -4.39223 acc 0.33333 roc_auc 0.75640 prc_auc 0.88835[0m
[93maverage test of epoch 16: loss -4.77497 acc 0.34211 roc_auc 0.86154 prc_auc 0.93632[0m
[92maverage training of epoch 17: loss -4.99125 acc 0.33333 roc_auc 0.70100 prc_auc 0.85636[0m
[93maverage test of epoch 17: loss -5.41373 acc 0.34211 roc_auc 0.86462 prc_auc 0.93606[0m
[92maverage training of epoch 18: loss -5.64891 acc 0.33333 roc_auc 0.67860 prc_auc 0.83916[0m
[93maverage test of epoch 18: loss -6.09812 acc 0.34211 roc_auc 0.87077 prc_auc 0.94037[0m
[92maverage training of epoch 19: loss -6.35103 acc 0.33333 roc_auc 0.65320 prc_auc 0.81514[0m
[93maverage test of epoch 19: loss -6.82799 acc 0.34211 roc_auc 0.87692 prc_auc 0.94369[0m
[92maverage training of epoch 20: loss -7.09902 acc 0.33333 roc_auc 0.62500 prc_auc 0.78917[0m
[93maverage test of epoch 20: loss -7.60409 acc 0.34211 roc_auc 0.88615 prc_auc 0.95009[0m
[92maverage training of epoch 21: loss -7.89338 acc 0.33333 roc_auc 0.60160 prc_auc 0.76155[0m
[93maverage test of epoch 21: loss -8.42618 acc 0.34211 roc_auc 0.88615 prc_auc 0.95059[0m
[92maverage training of epoch 22: loss -8.73344 acc 0.33333 roc_auc 0.58720 prc_auc 0.74159[0m
[93maverage test of epoch 22: loss -9.29392 acc 0.34211 roc_auc 0.88615 prc_auc 0.94995[0m
[92maverage training of epoch 23: loss -9.61939 acc 0.33333 roc_auc 0.57720 prc_auc 0.72617[0m
[93maverage test of epoch 23: loss -10.20821 acc 0.34211 roc_auc 0.88308 prc_auc 0.94772[0m
[92maverage training of epoch 24: loss -10.55125 acc 0.33333 roc_auc 0.56680 prc_auc 0.71498[0m
[93maverage test of epoch 24: loss -11.16762 acc 0.34211 roc_auc 0.89846 prc_auc 0.95397[0m
[92maverage training of epoch 25: loss -11.53872 acc 0.33333 roc_auc 0.56500 prc_auc 0.71687[0m
[93maverage test of epoch 25: loss -12.19866 acc 0.34211 roc_auc 0.88615 prc_auc 0.94995[0m
[92maverage training of epoch 26: loss -12.58840 acc 0.33333 roc_auc 0.56240 prc_auc 0.71132[0m
[93maverage test of epoch 26: loss -13.27941 acc 0.34211 roc_auc 0.89846 prc_auc 0.95762[0m
[92maverage training of epoch 27: loss -13.69312 acc 0.33333 roc_auc 0.56480 prc_auc 0.71484[0m
[93maverage test of epoch 27: loss -14.41939 acc 0.34211 roc_auc 0.91385 prc_auc 0.96126[0m
[92maverage training of epoch 28: loss -14.85902 acc 0.33333 roc_auc 0.56580 prc_auc 0.71572[0m
[93maverage test of epoch 28: loss -15.62345 acc 0.34211 roc_auc 0.91231 prc_auc 0.95955[0m
[92maverage training of epoch 29: loss -16.09155 acc 0.33333 roc_auc 0.56640 prc_auc 0.71660[0m
[93maverage test of epoch 29: loss -16.89721 acc 0.34211 roc_auc 0.91077 prc_auc 0.95838[0m
[92maverage training of epoch 30: loss -17.39643 acc 0.33333 roc_auc 0.56720 prc_auc 0.71693[0m
[93maverage test of epoch 30: loss -18.24632 acc 0.34211 roc_auc 0.90462 prc_auc 0.95665[0m
[92maverage training of epoch 31: loss -18.77743 acc 0.33333 roc_auc 0.56780 prc_auc 0.71753[0m
[93maverage test of epoch 31: loss -19.67181 acc 0.34211 roc_auc 0.89231 prc_auc 0.95080[0m
[92maverage training of epoch 32: loss -20.23485 acc 0.33333 roc_auc 0.57000 prc_auc 0.71879[0m
[93maverage test of epoch 32: loss -21.17595 acc 0.34211 roc_auc 0.89231 prc_auc 0.95053[0m
[92maverage training of epoch 33: loss -21.77411 acc 0.33333 roc_auc 0.57060 prc_auc 0.71927[0m
[93maverage test of epoch 33: loss -22.76549 acc 0.34211 roc_auc 0.89385 prc_auc 0.95064[0m
[92maverage training of epoch 34: loss -23.40176 acc 0.33333 roc_auc 0.57180 prc_auc 0.72027[0m
[93maverage test of epoch 34: loss -24.44680 acc 0.34211 roc_auc 0.88615 prc_auc 0.94805[0m
[92maverage training of epoch 35: loss -25.12375 acc 0.33333 roc_auc 0.57240 prc_auc 0.72055[0m
[93maverage test of epoch 35: loss -26.22521 acc 0.34211 roc_auc 0.88769 prc_auc 0.94946[0m
[92maverage training of epoch 36: loss -26.94442 acc 0.33333 roc_auc 0.57320 prc_auc 0.72168[0m
[93maverage test of epoch 36: loss -28.10433 acc 0.34211 roc_auc 0.87385 prc_auc 0.94312[0m
[92maverage training of epoch 37: loss -28.86356 acc 0.33333 roc_auc 0.57380 prc_auc 0.72199[0m
[93maverage test of epoch 37: loss -30.07900 acc 0.34211 roc_auc 0.86462 prc_auc 0.93927[0m
[92maverage training of epoch 38: loss -30.87726 acc 0.33333 roc_auc 0.57460 prc_auc 0.72234[0m
[93maverage test of epoch 38: loss -32.14801 acc 0.34211 roc_auc 0.87846 prc_auc 0.94351[0m
[92maverage training of epoch 39: loss -32.98580 acc 0.33333 roc_auc 0.57500 prc_auc 0.72255[0m
[93maverage test of epoch 39: loss -34.31487 acc 0.34211 roc_auc 0.87692 prc_auc 0.94256[0m
[92maverage training of epoch 40: loss -35.19630 acc 0.33333 roc_auc 0.57520 prc_auc 0.72270[0m
[93maverage test of epoch 40: loss -36.58479 acc 0.34211 roc_auc 0.83077 prc_auc 0.92017[0m
[92maverage training of epoch 41: loss -37.50481 acc 0.33333 roc_auc 0.57560 prc_auc 0.72302[0m
[93maverage test of epoch 41: loss -38.94868 acc 0.34211 roc_auc 0.86923 prc_auc 0.93504[0m
[92maverage training of epoch 42: loss -39.90624 acc 0.33333 roc_auc 0.57560 prc_auc 0.72275[0m
[93maverage test of epoch 42: loss -41.40993 acc 0.34211 roc_auc 0.87231 prc_auc 0.94194[0m
[92maverage training of epoch 43: loss -42.40747 acc 0.33333 roc_auc 0.57580 prc_auc 0.72294[0m
[93maverage test of epoch 43: loss -43.97055 acc 0.34211 roc_auc 0.83077 prc_auc 0.91529[0m
[92maverage training of epoch 44: loss -45.00828 acc 0.33333 roc_auc 0.57540 prc_auc 0.72221[0m
[93maverage test of epoch 44: loss -46.63250 acc 0.34211 roc_auc 0.81538 prc_auc 0.89884[0m
[92maverage training of epoch 45: loss -47.71215 acc 0.33333 roc_auc 0.57540 prc_auc 0.72221[0m
[93maverage test of epoch 45: loss -49.39590 acc 0.34211 roc_auc 0.73231 prc_auc 0.87685[0m
[92maverage training of epoch 46: loss -50.51849 acc 0.33333 roc_auc 0.57540 prc_auc 0.72220[0m
[93maverage test of epoch 46: loss -52.26152 acc 0.34211 roc_auc 0.79077 prc_auc 0.87587[0m
[92maverage training of epoch 47: loss -53.42330 acc 0.33333 roc_auc 0.57520 prc_auc 0.72182[0m
[93maverage test of epoch 47: loss -55.22737 acc 0.34211 roc_auc 0.78462 prc_auc 0.88512[0m
[92maverage training of epoch 48: loss -56.43450 acc 0.33333 roc_auc 0.57520 prc_auc 0.72181[0m
[93maverage test of epoch 48: loss -58.30048 acc 0.34211 roc_auc 0.72462 prc_auc 0.84081[0m
[92maverage training of epoch 49: loss -59.54629 acc 0.33333 roc_auc 0.57500 prc_auc 0.72141[0m
[93maverage test of epoch 49: loss -61.47333 acc 0.34211 roc_auc 0.83077 prc_auc 0.90078[0m
[92maverage training of epoch 50: loss -62.76274 acc 0.33333 roc_auc 0.57500 prc_auc 0.72141[0m
[93maverage test of epoch 50: loss -64.75373 acc 0.34211 roc_auc 0.72308 prc_auc 0.83402[0m
[92maverage training of epoch 51: loss -66.08881 acc 0.33333 roc_auc 0.57460 prc_auc 0.72073[0m
[93maverage test of epoch 51: loss -68.14719 acc 0.34211 roc_auc 0.64769 prc_auc 0.80269[0m
[92maverage training of epoch 52: loss -69.53088 acc 0.33333 roc_auc 0.57400 prc_auc 0.71980[0m
[93maverage test of epoch 52: loss -71.65869 acc 0.34211 roc_auc 0.60308 prc_auc 0.75238[0m
[92maverage training of epoch 53: loss -73.09298 acc 0.33333 roc_auc 0.57420 prc_auc 0.71998[0m
[93maverage test of epoch 53: loss -75.29251 acc 0.34211 roc_auc 0.64000 prc_auc 0.81002[0m
[92maverage training of epoch 54: loss -76.77949 acc 0.33333 roc_auc 0.57440 prc_auc 0.72022[0m
[93maverage test of epoch 54: loss -79.05323 acc 0.34211 roc_auc 0.78308 prc_auc 0.84974[0m
[92maverage training of epoch 55: loss -80.59546 acc 0.33333 roc_auc 0.57520 prc_auc 0.72114[0m
[93maverage test of epoch 55: loss -82.94657 acc 0.34211 roc_auc 0.64769 prc_auc 0.75965[0m
[92maverage training of epoch 56: loss -84.54718 acc 0.33333 roc_auc 0.57600 prc_auc 0.72208[0m
[93maverage test of epoch 56: loss -86.97933 acc 0.34211 roc_auc 0.58000 prc_auc 0.75825[0m
[92maverage training of epoch 57: loss -88.64139 acc 0.33333 roc_auc 0.57620 prc_auc 0.72217[0m
[93maverage test of epoch 57: loss -91.15819 acc 0.34211 roc_auc 0.81077 prc_auc 0.86608[0m
[92maverage training of epoch 58: loss -92.88447 acc 0.33333 roc_auc 0.57700 prc_auc 0.72301[0m
[93maverage test of epoch 58: loss -95.48939 acc 0.34211 roc_auc 0.44923 prc_auc 0.67185[0m
[92maverage training of epoch 59: loss -97.28243 acc 0.33333 roc_auc 0.57740 prc_auc 0.72344[0m
[93maverage test of epoch 59: loss -99.97863 acc 0.34211 roc_auc 0.55385 prc_auc 0.69835[0m
[92maverage training of epoch 60: loss -101.84022 acc 0.33333 roc_auc 0.57760 prc_auc 0.72381[0m
[93maverage test of epoch 60: loss -104.63033 acc 0.34211 roc_auc 0.78615 prc_auc 0.84625[0m
[92maverage training of epoch 61: loss -106.56140 acc 0.33333 roc_auc 0.57800 prc_auc 0.72447[0m
[93maverage test of epoch 61: loss -109.44721 acc 0.34211 roc_auc 0.36000 prc_auc 0.60863[0m
[92maverage training of epoch 62: loss -111.44857 acc 0.33333 roc_auc 0.57830 prc_auc 0.72456[0m
[93maverage test of epoch 62: loss -114.43183 acc 0.34211 roc_auc 0.47692 prc_auc 0.66843[0m
[92maverage training of epoch 63: loss -116.50318 acc 0.33333 roc_auc 0.57860 prc_auc 0.72523[0m
[93maverage test of epoch 63: loss -119.58366 acc 0.34211 roc_auc 0.73231 prc_auc 0.81865[0m
[92maverage training of epoch 64: loss -121.71855 acc 0.33333 roc_auc 0.57860 prc_auc 0.72523[0m
[93maverage test of epoch 64: loss -124.89114 acc 0.34211 roc_auc 0.48000 prc_auc 0.65448[0m
[92maverage training of epoch 65: loss -127.08756 acc 0.33333 roc_auc 0.57840 prc_auc 0.72490[0m
[93maverage test of epoch 65: loss -130.35311 acc 0.34211 roc_auc 0.56000 prc_auc 0.69895[0m
[92maverage training of epoch 66: loss -132.61144 acc 0.33333 roc_auc 0.57820 prc_auc 0.72464[0m
[93maverage test of epoch 66: loss -135.96932 acc 0.34211 roc_auc 0.52000 prc_auc 0.67158[0m
[92maverage training of epoch 67: loss -138.28899 acc 0.33333 roc_auc 0.57780 prc_auc 0.72411[0m
[93maverage test of epoch 67: loss -141.74004 acc 0.34211 roc_auc 0.61077 prc_auc 0.73942[0m
[92maverage training of epoch 68: loss -144.12331 acc 0.33333 roc_auc 0.57720 prc_auc 0.72338[0m
[93maverage test of epoch 68: loss -147.66931 acc 0.34211 roc_auc 0.48000 prc_auc 0.65485[0m
[92maverage training of epoch 69: loss -150.11774 acc 0.33333 roc_auc 0.57670 prc_auc 0.72248[0m
[93maverage test of epoch 69: loss -153.76004 acc 0.34211 roc_auc 0.56923 prc_auc 0.70105[0m
[92maverage training of epoch 70: loss -156.27414 acc 0.33333 roc_auc 0.57540 prc_auc 0.72059[0m
[93maverage test of epoch 70: loss -160.01255 acc 0.34211 roc_auc 0.60000 prc_auc 0.72632[0m
[92maverage training of epoch 71: loss -162.59295 acc 0.33333 roc_auc 0.57380 prc_auc 0.71917[0m
[93maverage test of epoch 71: loss -166.42883 acc 0.34211 roc_auc 0.52000 prc_auc 0.67158[0m
[92maverage training of epoch 72: loss -169.07727 acc 0.33333 roc_auc 0.57280 prc_auc 0.71849[0m
[93maverage test of epoch 72: loss -173.01149 acc 0.34211 roc_auc 0.52000 prc_auc 0.67158[0m
[92maverage training of epoch 73: loss -175.72968 acc 0.33333 roc_auc 0.57200 prc_auc 0.71761[0m
[93maverage test of epoch 73: loss -179.76425 acc 0.34211 roc_auc 0.48000 prc_auc 0.64902[0m
[92maverage training of epoch 74: loss -182.55358 acc 0.33333 roc_auc 0.57080 prc_auc 0.71641[0m
[93maverage test of epoch 74: loss -186.68969 acc 0.34211 roc_auc 0.56000 prc_auc 0.69895[0m
[92maverage training of epoch 75: loss -189.55199 acc 0.33333 roc_auc 0.56960 prc_auc 0.71494[0m
[93maverage test of epoch 75: loss -193.79080 acc 0.34211 roc_auc 0.52000 prc_auc 0.67158[0m
[92maverage training of epoch 76: loss -196.72722 acc 0.33333 roc_auc 0.56660 prc_auc 0.71219[0m
[93maverage test of epoch 76: loss -201.07001 acc 0.34211 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 77: loss -204.08222 acc 0.33333 roc_auc 0.56600 prc_auc 0.71160[0m
[93maverage test of epoch 77: loss -208.53032 acc 0.34211 roc_auc 0.48000 prc_auc 0.64902[0m
[92maverage training of epoch 78: loss -211.61973 acc 0.33333 roc_auc 0.56260 prc_auc 0.70809[0m
[93maverage test of epoch 78: loss -216.17429 acc 0.34211 roc_auc 0.52000 prc_auc 0.67158[0m
[92maverage training of epoch 79: loss -219.34223 acc 0.33333 roc_auc 0.55940 prc_auc 0.70543[0m
[93maverage test of epoch 79: loss -224.00445 acc 0.34211 roc_auc 0.72000 prc_auc 0.80842[0m
[92maverage training of epoch 80: loss -227.25265 acc 0.33333 roc_auc 0.55780 prc_auc 0.70428[0m
[93maverage test of epoch 80: loss -232.02422 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 81: loss -235.35450 acc 0.33333 roc_auc 0.55420 prc_auc 0.70072[0m
[93maverage test of epoch 81: loss -240.23705 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 82: loss -243.65079 acc 0.33333 roc_auc 0.55230 prc_auc 0.69902[0m
[93maverage test of epoch 82: loss -248.64551 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 83: loss -252.14430 acc 0.33333 roc_auc 0.55000 prc_auc 0.69675[0m
[93maverage test of epoch 83: loss -257.25232 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 84: loss -260.83785 acc 0.33333 roc_auc 0.54760 prc_auc 0.69514[0m
[93maverage test of epoch 84: loss -266.06071 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 85: loss -269.73511 acc 0.33333 roc_auc 0.54560 prc_auc 0.69367[0m
[93maverage test of epoch 85: loss -275.07544 acc 0.34211 roc_auc 0.46000 prc_auc 0.64041[0m
[92maverage training of epoch 86: loss -278.84166 acc 0.33333 roc_auc 0.54260 prc_auc 0.69110[0m
[93maverage test of epoch 86: loss -284.30196 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 87: loss -288.16283 acc 0.33333 roc_auc 0.53940 prc_auc 0.68814[0m
[93maverage test of epoch 87: loss -293.74736 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 88: loss -297.71046 acc 0.33333 roc_auc 0.53200 prc_auc 0.68180[0m
[93maverage test of epoch 88: loss -303.42697 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 89: loss -307.49649 acc 0.33333 roc_auc 0.52730 prc_auc 0.68178[0m
[93maverage test of epoch 89: loss -313.34779 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -317.56360 acc 0.33333 roc_auc 0.52080 prc_auc 0.68006[0m
[93maverage test of epoch 90: loss -323.64877 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 91: loss -328.07849 acc 0.33333 roc_auc 0.51300 prc_auc 0.67714[0m
[93maverage test of epoch 91: loss -334.35247 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 92: loss -338.91214 acc 0.33333 roc_auc 0.53000 prc_auc 0.68037[0m
[93maverage test of epoch 92: loss -345.33725 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 93: loss -350.02536 acc 0.33333 roc_auc 0.49500 prc_auc 0.66445[0m
[93maverage test of epoch 93: loss -356.60186 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 94: loss -361.42187 acc 0.33333 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 94: loss -368.15249 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 95: loss -373.10975 acc 0.33333 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 95: loss -379.99838 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 96: loss -385.09751 acc 0.33333 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 96: loss -392.14714 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 97: loss -397.39240 acc 0.33333 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 97: loss -404.60564 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 98: loss -410.00112 acc 0.33333 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 98: loss -417.38027 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -422.92955 acc 0.33333 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 99: loss -430.47636 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=8, bias=True)
    (ReLU1): ReLU()
    (Linear2): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -1.21531 acc 0.33333 roc_auc 0.46340 prc_auc 0.65561[0m
[93maverage test of epoch 0: loss -1.42790 acc 0.34211 roc_auc 0.66462 prc_auc 0.81743[0m
[92maverage training of epoch 1: loss -1.66745 acc 0.60000 roc_auc 0.47880 prc_auc 0.66462[0m
[93maverage test of epoch 1: loss -1.92652 acc 0.65789 roc_auc 0.77538 prc_auc 0.87365[0m
[92maverage training of epoch 2: loss -2.21669 acc 0.66667 roc_auc 0.47740 prc_auc 0.66372[0m
[93maverage test of epoch 2: loss -2.52843 acc 0.65789 roc_auc 0.73538 prc_auc 0.85282[0m
[92maverage training of epoch 3: loss -2.87605 acc 0.66667 roc_auc 0.45400 prc_auc 0.63589[0m
[93maverage test of epoch 3: loss -3.27431 acc 0.65789 roc_auc 0.62462 prc_auc 0.76750[0m
[92maverage training of epoch 4: loss -3.65904 acc 0.66667 roc_auc 0.42040 prc_auc 0.64040[0m
[93maverage test of epoch 4: loss -4.03893 acc 0.65789 roc_auc 0.66154 prc_auc 0.78076[0m
[92maverage training of epoch 5: loss -4.41633 acc 0.66667 roc_auc 0.42740 prc_auc 0.63443[0m
[93maverage test of epoch 5: loss -4.81243 acc 0.65789 roc_auc 0.54769 prc_auc 0.72445[0m
[92maverage training of epoch 6: loss -5.23182 acc 0.66667 roc_auc 0.36500 prc_auc 0.58691[0m
[93maverage test of epoch 6: loss -5.68085 acc 0.65789 roc_auc 0.21846 prc_auc 0.56989[0m
[92maverage training of epoch 7: loss -6.11648 acc 0.66667 roc_auc 0.36640 prc_auc 0.57434[0m
[93maverage test of epoch 7: loss -6.56492 acc 0.65789 roc_auc 0.15385 prc_auc 0.54669[0m
[92maverage training of epoch 8: loss -6.99165 acc 0.66667 roc_auc 0.38260 prc_auc 0.57693[0m
[93maverage test of epoch 8: loss -7.43394 acc 0.65789 roc_auc 0.14615 prc_auc 0.52015[0m
[92maverage training of epoch 9: loss -7.86679 acc 0.66667 roc_auc 0.39540 prc_auc 0.58912[0m
[93maverage test of epoch 9: loss -8.31573 acc 0.65789 roc_auc 0.14154 prc_auc 0.49959[0m
[92maverage training of epoch 10: loss -8.76410 acc 0.66667 roc_auc 0.40840 prc_auc 0.59745[0m
[93maverage test of epoch 10: loss -9.22699 acc 0.65789 roc_auc 0.13692 prc_auc 0.48935[0m
[92maverage training of epoch 11: loss -9.69593 acc 0.66667 roc_auc 0.41640 prc_auc 0.60474[0m
[93maverage test of epoch 11: loss -10.17633 acc 0.65789 roc_auc 0.14308 prc_auc 0.49357[0m
[92maverage training of epoch 12: loss -10.66886 acc 0.66667 roc_auc 0.42680 prc_auc 0.61159[0m
[93maverage test of epoch 12: loss -11.16885 acc 0.65789 roc_auc 0.14308 prc_auc 0.49959[0m
[92maverage training of epoch 13: loss -11.68767 acc 0.66667 roc_auc 0.43260 prc_auc 0.61761[0m
[93maverage test of epoch 13: loss -12.20993 acc 0.65789 roc_auc 0.15385 prc_auc 0.52443[0m
[92maverage training of epoch 14: loss -12.75728 acc 0.66667 roc_auc 0.43660 prc_auc 0.62080[0m
[93maverage test of epoch 14: loss -13.30329 acc 0.65789 roc_auc 0.17846 prc_auc 0.55223[0m
[92maverage training of epoch 15: loss -13.88166 acc 0.66667 roc_auc 0.44060 prc_auc 0.62406[0m
[93maverage test of epoch 15: loss -14.45366 acc 0.65789 roc_auc 0.23846 prc_auc 0.55796[0m
[92maverage training of epoch 16: loss -15.06545 acc 0.66667 roc_auc 0.44380 prc_auc 0.62613[0m
[93maverage test of epoch 16: loss -15.66523 acc 0.65789 roc_auc 0.36154 prc_auc 0.62419[0m
[92maverage training of epoch 17: loss -16.31235 acc 0.66667 roc_auc 0.45080 prc_auc 0.63248[0m
[93maverage test of epoch 17: loss -16.94095 acc 0.65789 roc_auc 0.41385 prc_auc 0.65913[0m
[92maverage training of epoch 18: loss -17.62416 acc 0.66667 roc_auc 0.45440 prc_auc 0.63600[0m
[93maverage test of epoch 18: loss -18.28226 acc 0.65789 roc_auc 0.40000 prc_auc 0.65386[0m
[92maverage training of epoch 19: loss -19.00369 acc 0.66667 roc_auc 0.45900 prc_auc 0.63972[0m
[93maverage test of epoch 19: loss -19.69304 acc 0.65789 roc_auc 0.40154 prc_auc 0.66622[0m
[92maverage training of epoch 20: loss -20.45523 acc 0.66667 roc_auc 0.46280 prc_auc 0.64262[0m
[93maverage test of epoch 20: loss -21.17784 acc 0.65789 roc_auc 0.38769 prc_auc 0.64502[0m
[92maverage training of epoch 21: loss -21.98344 acc 0.66667 roc_auc 0.46500 prc_auc 0.64422[0m
[93maverage test of epoch 21: loss -22.74149 acc 0.65789 roc_auc 0.41231 prc_auc 0.67143[0m
[92maverage training of epoch 22: loss -23.59375 acc 0.66667 roc_auc 0.46620 prc_auc 0.64553[0m
[93maverage test of epoch 22: loss -24.38995 acc 0.65789 roc_auc 0.33846 prc_auc 0.59835[0m
[92maverage training of epoch 23: loss -25.29256 acc 0.66667 roc_auc 0.46720 prc_auc 0.64625[0m
[93maverage test of epoch 23: loss -26.12971 acc 0.65789 roc_auc 0.37538 prc_auc 0.64143[0m
[92maverage training of epoch 24: loss -27.08709 acc 0.66667 roc_auc 0.46800 prc_auc 0.64755[0m
[93maverage test of epoch 24: loss -27.96998 acc 0.65789 roc_auc 0.26462 prc_auc 0.55143[0m
[92maverage training of epoch 25: loss -28.99357 acc 0.66667 roc_auc 0.46810 prc_auc 0.64818[0m
[93maverage test of epoch 25: loss -29.93635 acc 0.65789 roc_auc 0.30462 prc_auc 0.58090[0m
[92maverage training of epoch 26: loss -31.04682 acc 0.66667 roc_auc 0.46840 prc_auc 0.65531[0m
[93maverage test of epoch 26: loss -32.07007 acc 0.65789 roc_auc 0.21692 prc_auc 0.55656[0m
[92maverage training of epoch 27: loss -33.27575 acc 0.66667 roc_auc 0.46880 prc_auc 0.65571[0m
[93maverage test of epoch 27: loss -34.37334 acc 0.65789 roc_auc 0.42000 prc_auc 0.64717[0m
[92maverage training of epoch 28: loss -35.63412 acc 0.66667 roc_auc 0.47040 prc_auc 0.65632[0m
[93maverage test of epoch 28: loss -36.76357 acc 0.65789 roc_auc 0.74000 prc_auc 0.82211[0m
[92maverage training of epoch 29: loss -38.06166 acc 0.66667 roc_auc 0.47100 prc_auc 0.65694[0m
[93maverage test of epoch 29: loss -39.21773 acc 0.65789 roc_auc 0.75846 prc_auc 0.81158[0m
[92maverage training of epoch 30: loss -40.56693 acc 0.66667 roc_auc 0.47240 prc_auc 0.65229[0m
[93maverage test of epoch 30: loss -41.76023 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 31: loss -43.16803 acc 0.66667 roc_auc 0.47100 prc_auc 0.65180[0m
[93maverage test of epoch 31: loss -44.40457 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -45.87532 acc 0.66667 roc_auc 0.45980 prc_auc 0.64205[0m
[93maverage test of epoch 32: loss -47.15839 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 33: loss -48.69489 acc 0.66667 roc_auc 0.48380 prc_auc 0.65861[0m
[93maverage test of epoch 33: loss -50.02620 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -51.62949 acc 0.66667 roc_auc 0.45500 prc_auc 0.64854[0m
[93maverage test of epoch 34: loss -53.00801 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -54.67690 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -56.10158 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -57.83794 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -59.31004 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -61.11657 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -62.63765 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -64.51682 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -66.08822 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -68.04169 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -69.66336 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -71.69231 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -73.36473 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -75.46994 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -77.19181 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -79.37384 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -81.14556 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -83.40519 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -85.22587 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -87.56424 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -89.43444 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -91.85244 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -93.77207 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -96.27147 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -98.24163 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -100.82434 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -102.84586 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -105.51325 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -107.58654 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -110.34023 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -112.46571 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 50: loss -115.30681 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 50: loss -117.48484 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 51: loss -120.41517 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 51: loss -122.64668 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 52: loss -125.66801 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 52: loss -127.95372 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 53: loss -131.06789 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 53: loss -133.40864 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 54: loss -136.61736 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 54: loss -139.01380 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 55: loss -142.31887 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 55: loss -144.77178 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 56: loss -148.17492 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 56: loss -150.68505 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 57: loss -154.18806 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 57: loss -156.75589 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 58: loss -160.36052 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 58: loss -162.98685 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 59: loss -166.69472 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 59: loss -169.38005 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 60: loss -173.19298 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 60: loss -175.93797 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 61: loss -179.85780 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 61: loss -182.66301 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 62: loss -186.69128 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 62: loss -189.55729 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 63: loss -193.69576 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 63: loss -196.62299 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 64: loss -200.87330 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 64: loss -203.86235 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 65: loss -208.22628 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 65: loss -211.27755 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 66: loss -215.75688 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 66: loss -218.87100 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 67: loss -223.46737 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 67: loss -226.64481 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 68: loss -231.36004 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 68: loss -234.60119 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 69: loss -239.43674 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 69: loss -242.74202 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 70: loss -247.69985 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 70: loss -251.06978 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 71: loss -256.15174 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 71: loss -259.58695 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 72: loss -264.79483 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 72: loss -268.29571 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 73: loss -273.63102 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 73: loss -277.19772 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 74: loss -282.66218 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 74: loss -286.29513 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 75: loss -291.89040 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 75: loss -295.59006 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 76: loss -301.31821 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 76: loss -305.08526 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 77: loss -310.94804 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 77: loss -314.78279 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 78: loss -320.78192 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 78: loss -324.68470 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 79: loss -330.82202 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 79: loss -334.79324 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 80: loss -341.07047 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 80: loss -345.11049 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 81: loss -351.52949 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 81: loss -355.63878 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 82: loss -362.20129 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 82: loss -366.38000 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 83: loss -373.08777 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 83: loss -377.33640 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 84: loss -384.19131 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 84: loss -388.51023 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 85: loss -395.51406 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 85: loss -399.90357 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 86: loss -407.05814 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 86: loss -411.51850 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 87: loss -418.82564 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 87: loss -423.35723 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 88: loss -430.81886 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 88: loss -435.42205 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 89: loss -443.03983 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 89: loss -447.71489 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -455.49074 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 90: loss -460.23794 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 91: loss -468.17351 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 91: loss -472.99304 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 92: loss -481.09038 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 92: loss -485.98269 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 93: loss -494.24361 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 93: loss -499.20876 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 94: loss -507.63504 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 94: loss -512.67347 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 95: loss -521.26701 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 95: loss -526.37901 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 96: loss -535.14821 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 96: loss -540.38072 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 97: loss -549.46403 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 97: loss -554.88873 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 98: loss -564.16824 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 98: loss -569.67883 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -579.13848 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 99: loss -584.72770 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=8, bias=True)
    (ReLU1): ReLU()
    (Linear2): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.09393 acc 0.33333 roc_auc 0.51720 prc_auc 0.71841[0m
[93maverage test of epoch 0: loss -0.18339 acc 0.34211 roc_auc 0.94154 prc_auc 0.97436[0m
[92maverage training of epoch 1: loss -0.24967 acc 0.33333 roc_auc 0.56240 prc_auc 0.74999[0m
[93maverage test of epoch 1: loss -0.34708 acc 0.34211 roc_auc 0.94462 prc_auc 0.97520[0m
[92maverage training of epoch 2: loss -0.41090 acc 0.33333 roc_auc 0.61220 prc_auc 0.79232[0m
[93maverage test of epoch 2: loss -0.50468 acc 0.34211 roc_auc 0.94462 prc_auc 0.97520[0m
[92maverage training of epoch 3: loss -0.57245 acc 0.33333 roc_auc 0.67500 prc_auc 0.82226[0m
[93maverage test of epoch 3: loss -0.66734 acc 0.34211 roc_auc 0.94769 prc_auc 0.97662[0m
[92maverage training of epoch 4: loss -0.74547 acc 0.33333 roc_auc 0.71160 prc_auc 0.84513[0m
[93maverage test of epoch 4: loss -0.85224 acc 0.34211 roc_auc 0.94769 prc_auc 0.97662[0m
[92maverage training of epoch 5: loss -0.94874 acc 0.33333 roc_auc 0.68960 prc_auc 0.83029[0m
[93maverage test of epoch 5: loss -1.07383 acc 0.34211 roc_auc 0.94462 prc_auc 0.97578[0m
[92maverage training of epoch 6: loss -1.18990 acc 0.33333 roc_auc 0.61960 prc_auc 0.77295[0m
[93maverage test of epoch 6: loss -1.33400 acc 0.34211 roc_auc 0.93538 prc_auc 0.97257[0m
[92maverage training of epoch 7: loss -1.47115 acc 0.33333 roc_auc 0.52160 prc_auc 0.70370[0m
[93maverage test of epoch 7: loss -1.63353 acc 0.34211 roc_auc 0.92308 prc_auc 0.96529[0m
[92maverage training of epoch 8: loss -1.79636 acc 0.33333 roc_auc 0.48600 prc_auc 0.68796[0m
[93maverage test of epoch 8: loss -1.98202 acc 0.34211 roc_auc 0.90462 prc_auc 0.95535[0m
[92maverage training of epoch 9: loss -2.17370 acc 0.33333 roc_auc 0.45020 prc_auc 0.67526[0m
[93maverage test of epoch 9: loss -2.39166 acc 0.34211 roc_auc 0.91077 prc_auc 0.96462[0m
[92maverage training of epoch 10: loss -2.61313 acc 0.33333 roc_auc 0.43520 prc_auc 0.64898[0m
[93maverage test of epoch 10: loss -2.86278 acc 0.34211 roc_auc 0.94769 prc_auc 0.97538[0m
[92maverage training of epoch 11: loss -3.11581 acc 0.33333 roc_auc 0.41240 prc_auc 0.62908[0m
[93maverage test of epoch 11: loss -3.39602 acc 0.34211 roc_auc 0.59077 prc_auc 0.82666[0m
[92maverage training of epoch 12: loss -3.68354 acc 0.33333 roc_auc 0.40640 prc_auc 0.61092[0m
[93maverage test of epoch 12: loss -3.99780 acc 0.34211 roc_auc 0.53231 prc_auc 0.80265[0m
[92maverage training of epoch 13: loss -4.32690 acc 0.33333 roc_auc 0.40800 prc_auc 0.61586[0m
[93maverage test of epoch 13: loss -4.68026 acc 0.34211 roc_auc 0.40923 prc_auc 0.72834[0m
[92maverage training of epoch 14: loss -5.04841 acc 0.33333 roc_auc 0.41460 prc_auc 0.62223[0m
[93maverage test of epoch 14: loss -5.43180 acc 0.34211 roc_auc 0.57385 prc_auc 0.81364[0m
[92maverage training of epoch 15: loss -5.81801 acc 0.38000 roc_auc 0.41560 prc_auc 0.62219[0m
[93maverage test of epoch 15: loss -6.20937 acc 0.65789 roc_auc 0.75692 prc_auc 0.90035[0m
[92maverage training of epoch 16: loss -6.60195 acc 0.66667 roc_auc 0.41620 prc_auc 0.62165[0m
[93maverage test of epoch 16: loss -6.99547 acc 0.65789 roc_auc 0.90462 prc_auc 0.96368[0m
[92maverage training of epoch 17: loss -7.39590 acc 0.66667 roc_auc 0.41840 prc_auc 0.62312[0m
[93maverage test of epoch 17: loss -7.79454 acc 0.65789 roc_auc 0.92769 prc_auc 0.97221[0m
[92maverage training of epoch 18: loss -8.20666 acc 0.66667 roc_auc 0.41980 prc_auc 0.62368[0m
[93maverage test of epoch 18: loss -8.61379 acc 0.65789 roc_auc 0.95077 prc_auc 0.97919[0m
[92maverage training of epoch 19: loss -9.04028 acc 0.66667 roc_auc 0.42040 prc_auc 0.62379[0m
[93maverage test of epoch 19: loss -9.45813 acc 0.65789 roc_auc 0.95692 prc_auc 0.98092[0m
[92maverage training of epoch 20: loss -9.90062 acc 0.66667 roc_auc 0.42240 prc_auc 0.62540[0m
[93maverage test of epoch 20: loss -10.33042 acc 0.65789 roc_auc 0.95692 prc_auc 0.98092[0m
[92maverage training of epoch 21: loss -10.78933 acc 0.66667 roc_auc 0.42320 prc_auc 0.62571[0m
[93maverage test of epoch 21: loss -11.23074 acc 0.65789 roc_auc 0.95692 prc_auc 0.98092[0m
[92maverage training of epoch 22: loss -11.70589 acc 0.66667 roc_auc 0.42360 prc_auc 0.62622[0m
[93maverage test of epoch 22: loss -12.15856 acc 0.65789 roc_auc 0.95385 prc_auc 0.97950[0m
[92maverage training of epoch 23: loss -12.64886 acc 0.66667 roc_auc 0.42520 prc_auc 0.62840[0m
[93maverage test of epoch 23: loss -13.11195 acc 0.65789 roc_auc 0.95538 prc_auc 0.97950[0m
[92maverage training of epoch 24: loss -13.61853 acc 0.66667 roc_auc 0.42640 prc_auc 0.62936[0m
[93maverage test of epoch 24: loss -14.09337 acc 0.65789 roc_auc 0.95538 prc_auc 0.97950[0m
[92maverage training of epoch 25: loss -14.61777 acc 0.66667 roc_auc 0.42700 prc_auc 0.63050[0m
[93maverage test of epoch 25: loss -15.10553 acc 0.65789 roc_auc 0.95385 prc_auc 0.97950[0m
[92maverage training of epoch 26: loss -15.64928 acc 0.66667 roc_auc 0.42860 prc_auc 0.63191[0m
[93maverage test of epoch 26: loss -16.15107 acc 0.65789 roc_auc 0.95846 prc_auc 0.98092[0m
[92maverage training of epoch 27: loss -16.71546 acc 0.66667 roc_auc 0.42840 prc_auc 0.63254[0m
[93maverage test of epoch 27: loss -17.23221 acc 0.65789 roc_auc 0.95692 prc_auc 0.97950[0m
[92maverage training of epoch 28: loss -17.81851 acc 0.66667 roc_auc 0.43020 prc_auc 0.63460[0m
[93maverage test of epoch 28: loss -18.35110 acc 0.65789 roc_auc 0.96154 prc_auc 0.97968[0m
[92maverage training of epoch 29: loss -18.96055 acc 0.66667 roc_auc 0.43120 prc_auc 0.63585[0m
[93maverage test of epoch 29: loss -19.50988 acc 0.65789 roc_auc 0.96154 prc_auc 0.97536[0m
[92maverage training of epoch 30: loss -20.14353 acc 0.66667 roc_auc 0.43240 prc_auc 0.63740[0m
[93maverage test of epoch 30: loss -20.71014 acc 0.65789 roc_auc 0.95077 prc_auc 0.95919[0m
[92maverage training of epoch 31: loss -21.36922 acc 0.66667 roc_auc 0.43240 prc_auc 0.63728[0m
[93maverage test of epoch 31: loss -21.95403 acc 0.65789 roc_auc 0.89077 prc_auc 0.91263[0m
[92maverage training of epoch 32: loss -22.63954 acc 0.66667 roc_auc 0.43450 prc_auc 0.63892[0m
[93maverage test of epoch 32: loss -23.24298 acc 0.65789 roc_auc 0.71077 prc_auc 0.76954[0m
[92maverage training of epoch 33: loss -23.95604 acc 0.66667 roc_auc 0.43670 prc_auc 0.64098[0m
[93maverage test of epoch 33: loss -24.57886 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -25.32051 acc 0.66667 roc_auc 0.43870 prc_auc 0.64255[0m
[93maverage test of epoch 34: loss -25.96328 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -26.73453 acc 0.66667 roc_auc 0.44020 prc_auc 0.64047[0m
[93maverage test of epoch 35: loss -27.39777 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -28.19928 acc 0.66667 roc_auc 0.43460 prc_auc 0.63582[0m
[93maverage test of epoch 36: loss -28.88447 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -29.71784 acc 0.66667 roc_auc 0.44220 prc_auc 0.64085[0m
[93maverage test of epoch 37: loss -30.42343 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -31.28921 acc 0.66667 roc_auc 0.44340 prc_auc 0.64135[0m
[93maverage test of epoch 38: loss -32.01662 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -32.91570 acc 0.66667 roc_auc 0.44390 prc_auc 0.64162[0m
[93maverage test of epoch 39: loss -33.66526 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -34.59513 acc 0.66667 roc_auc 0.43500 prc_auc 0.63295[0m
[93maverage test of epoch 40: loss -35.37089 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -36.33868 acc 0.66667 roc_auc 0.43960 prc_auc 0.63299[0m
[93maverage test of epoch 41: loss -37.13246 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -38.13430 acc 0.66667 roc_auc 0.44500 prc_auc 0.64370[0m
[93maverage test of epoch 42: loss -38.94898 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -39.98543 acc 0.66667 roc_auc 0.43790 prc_auc 0.62933[0m
[93maverage test of epoch 43: loss -40.82119 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -41.89289 acc 0.66667 roc_auc 0.43600 prc_auc 0.63480[0m
[93maverage test of epoch 44: loss -42.74971 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -43.85582 acc 0.66667 roc_auc 0.49000 prc_auc 0.66226[0m
[93maverage test of epoch 45: loss -44.73098 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -45.86993 acc 0.66667 roc_auc 0.46500 prc_auc 0.65161[0m
[93maverage test of epoch 46: loss -46.76234 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -47.93488 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -48.84509 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -50.05213 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -50.98066 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -52.22297 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -53.17019 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 50: loss -54.44851 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 50: loss -55.41482 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 51: loss -56.72993 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 51: loss -57.71563 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 52: loss -59.06808 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 52: loss -60.07333 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 53: loss -61.46389 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 53: loss -62.48910 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 54: loss -63.91854 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 54: loss -64.96400 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 55: loss -66.43297 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 55: loss -67.49900 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 56: loss -69.01001 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 56: loss -70.09950 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 57: loss -71.65614 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 57: loss -72.77115 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 58: loss -74.37447 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 58: loss -75.51611 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 59: loss -77.16737 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 59: loss -78.33710 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 60: loss -80.03772 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 60: loss -81.23721 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 61: loss -82.98900 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 61: loss -84.22018 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 62: loss -86.02478 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 62: loss -87.28966 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 63: loss -89.14925 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 63: loss -90.45027 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 64: loss -92.36699 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 64: loss -93.70664 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 65: loss -95.68235 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 65: loss -97.06305 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 66: loss -99.09909 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 66: loss -100.52391 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 67: loss -102.62319 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 67: loss -104.09284 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 68: loss -106.25537 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 68: loss -107.77160 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 69: loss -109.99732 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 69: loss -111.56066 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 70: loss -113.84866 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 70: loss -115.45791 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 71: loss -117.79933 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 71: loss -119.44523 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 72: loss -121.83601 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 72: loss -123.51810 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 73: loss -125.95994 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 73: loss -127.67904 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 74: loss -130.17321 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 74: loss -131.92982 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 75: loss -134.47737 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 75: loss -136.27202 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 76: loss -138.87413 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 76: loss -140.70738 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 77: loss -143.36504 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 77: loss -145.23724 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 78: loss -147.95126 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 78: loss -149.86284 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 79: loss -152.63427 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 79: loss -154.58579 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 80: loss -157.41561 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 80: loss -159.40745 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 81: loss -162.29642 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 81: loss -164.32890 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 82: loss -167.27796 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 82: loss -169.35154 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 83: loss -172.36154 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 83: loss -174.47660 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 84: loss -177.60207 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 84: loss -179.83849 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 85: loss -183.06128 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 85: loss -185.35032 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 86: loss -188.63849 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 86: loss -190.97159 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 87: loss -194.32664 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 87: loss -196.70472 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 88: loss -200.12883 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 88: loss -202.55346 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 89: loss -206.04823 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 89: loss -208.52039 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -212.08717 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 90: loss -214.60756 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 91: loss -218.24734 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 91: loss -220.81636 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 92: loss -224.53036 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 92: loss -227.14885 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 93: loss -230.93830 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 93: loss -233.60685 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 94: loss -237.47282 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 94: loss -240.19190 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 95: loss -244.13548 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 95: loss -246.90562 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 96: loss -250.92775 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 96: loss -253.74931 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 97: loss -257.85108 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 97: loss -260.72454 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 98: loss -264.91181 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 98: loss -267.86971 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -272.22505 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 99: loss -275.30132 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=8, bias=True)
    (ReLU1): ReLU()
    (Linear2): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss 0.72979 acc 0.34437 roc_auc 0.46922 prc_auc 0.65854[0m
[93maverage test of epoch 0: loss 0.54271 acc 0.67568 roc_auc 0.85000 prc_auc 0.90577[0m
[92maverage training of epoch 1: loss 0.34047 acc 0.66225 roc_auc 0.46843 prc_auc 0.65852[0m
[93maverage test of epoch 1: loss 0.11014 acc 0.67568 roc_auc 0.86333 prc_auc 0.91835[0m
[92maverage training of epoch 2: loss 0.00732 acc 0.66225 roc_auc 0.47333 prc_auc 0.68049[0m
[93maverage test of epoch 2: loss -0.05785 acc 0.67568 roc_auc 0.78000 prc_auc 0.88029[0m
[92maverage training of epoch 3: loss -0.09699 acc 0.66225 roc_auc 0.40118 prc_auc 0.63337[0m
[93maverage test of epoch 3: loss -0.15110 acc 0.67568 roc_auc 0.69333 prc_auc 0.81348[0m
[92maverage training of epoch 4: loss -0.19392 acc 0.66225 roc_auc 0.23784 prc_auc 0.51821[0m
[93maverage test of epoch 4: loss -0.25748 acc 0.67568 roc_auc 0.18000 prc_auc 0.54809[0m
[92maverage training of epoch 5: loss -0.31961 acc 0.66225 roc_auc 0.31373 prc_auc 0.55695[0m
[93maverage test of epoch 5: loss -0.40751 acc 0.67568 roc_auc 0.18000 prc_auc 0.54809[0m
[92maverage training of epoch 6: loss -0.50415 acc 0.66225 roc_auc 0.33824 prc_auc 0.56019[0m
[93maverage test of epoch 6: loss -0.62706 acc 0.67568 roc_auc 0.18000 prc_auc 0.54809[0m
[92maverage training of epoch 7: loss -0.75800 acc 0.66225 roc_auc 0.38078 prc_auc 0.58335[0m
[93maverage test of epoch 7: loss -0.91058 acc 0.67568 roc_auc 0.18000 prc_auc 0.54809[0m
[92maverage training of epoch 8: loss -1.05639 acc 0.66225 roc_auc 0.33549 prc_auc 0.56183[0m
[93maverage test of epoch 8: loss -1.21618 acc 0.67568 roc_auc 0.18333 prc_auc 0.55209[0m
[92maverage training of epoch 9: loss -1.38013 acc 0.66225 roc_auc 0.38098 prc_auc 0.58178[0m
[93maverage test of epoch 9: loss -1.55964 acc 0.67568 roc_auc 0.18000 prc_auc 0.55121[0m
[92maverage training of epoch 10: loss -1.75421 acc 0.66225 roc_auc 0.42373 prc_auc 0.61506[0m
[93maverage test of epoch 10: loss -1.96728 acc 0.67568 roc_auc 0.18333 prc_auc 0.55255[0m
[92maverage training of epoch 11: loss -2.20186 acc 0.56954 roc_auc 0.44216 prc_auc 0.61598[0m
[93maverage test of epoch 11: loss -2.44928 acc 0.32432 roc_auc 0.14667 prc_auc 0.51146[0m
[92maverage training of epoch 12: loss -2.70225 acc 0.33775 roc_auc 0.38059 prc_auc 0.58404[0m
[93maverage test of epoch 12: loss -2.95479 acc 0.32432 roc_auc 0.14667 prc_auc 0.51146[0m
[92maverage training of epoch 13: loss -3.20472 acc 0.33775 roc_auc 0.35294 prc_auc 0.57176[0m
[93maverage test of epoch 13: loss -3.45347 acc 0.32432 roc_auc 0.18167 prc_auc 0.55161[0m
[92maverage training of epoch 14: loss -3.70497 acc 0.33775 roc_auc 0.34725 prc_auc 0.58428[0m
[93maverage test of epoch 14: loss -3.95785 acc 0.32432 roc_auc 0.18667 prc_auc 0.55421[0m
[92maverage training of epoch 15: loss -4.21691 acc 0.33775 roc_auc 0.35961 prc_auc 0.59150[0m
[93maverage test of epoch 15: loss -4.47926 acc 0.32432 roc_auc 0.21667 prc_auc 0.58875[0m
[92maverage training of epoch 16: loss -4.74820 acc 0.33775 roc_auc 0.37686 prc_auc 0.59031[0m
[93maverage test of epoch 16: loss -5.02176 acc 0.32432 roc_auc 0.23000 prc_auc 0.59220[0m
[92maverage training of epoch 17: loss -5.30177 acc 0.33775 roc_auc 0.37235 prc_auc 0.58556[0m
[93maverage test of epoch 17: loss -5.58840 acc 0.32432 roc_auc 0.25333 prc_auc 0.62058[0m
[92maverage training of epoch 18: loss -5.88143 acc 0.33775 roc_auc 0.36725 prc_auc 0.58210[0m
[93maverage test of epoch 18: loss -6.17982 acc 0.32432 roc_auc 0.58667 prc_auc 0.82020[0m
[92maverage training of epoch 19: loss -6.47688 acc 0.33775 roc_auc 0.36333 prc_auc 0.58027[0m
[93maverage test of epoch 19: loss -6.78244 acc 0.32432 roc_auc 0.78000 prc_auc 0.88938[0m
[92maverage training of epoch 20: loss -7.08887 acc 0.33775 roc_auc 0.36412 prc_auc 0.57778[0m
[93maverage test of epoch 20: loss -7.40583 acc 0.64865 roc_auc 0.78833 prc_auc 0.89007[0m
[92maverage training of epoch 21: loss -7.72249 acc 0.60265 roc_auc 0.36588 prc_auc 0.57688[0m
[93maverage test of epoch 21: loss -8.05253 acc 0.67568 roc_auc 0.76833 prc_auc 0.89421[0m
[92maverage training of epoch 22: loss -8.38064 acc 0.66225 roc_auc 0.36627 prc_auc 0.57360[0m
[93maverage test of epoch 22: loss -8.72502 acc 0.67568 roc_auc 0.78833 prc_auc 0.90024[0m
[92maverage training of epoch 23: loss -9.06570 acc 0.66225 roc_auc 0.37451 prc_auc 0.57512[0m
[93maverage test of epoch 23: loss -9.42584 acc 0.67568 roc_auc 0.79167 prc_auc 0.90489[0m
[92maverage training of epoch 24: loss -9.77949 acc 0.66225 roc_auc 0.37314 prc_auc 0.56753[0m
[93maverage test of epoch 24: loss -10.15650 acc 0.67568 roc_auc 0.80833 prc_auc 0.90598[0m
[92maverage training of epoch 25: loss -10.52478 acc 0.66225 roc_auc 0.37529 prc_auc 0.57050[0m
[93maverage test of epoch 25: loss -10.92071 acc 0.67568 roc_auc 0.81500 prc_auc 0.91089[0m
[92maverage training of epoch 26: loss -11.30479 acc 0.66225 roc_auc 0.37725 prc_auc 0.57128[0m
[93maverage test of epoch 26: loss -11.72059 acc 0.67568 roc_auc 0.80833 prc_auc 0.90340[0m
[92maverage training of epoch 27: loss -12.12180 acc 0.66225 roc_auc 0.37725 prc_auc 0.57103[0m
[93maverage test of epoch 27: loss -12.55910 acc 0.67568 roc_auc 0.81333 prc_auc 0.90608[0m
[92maverage training of epoch 28: loss -12.97902 acc 0.66225 roc_auc 0.37667 prc_auc 0.57045[0m
[93maverage test of epoch 28: loss -13.43942 acc 0.67568 roc_auc 0.81667 prc_auc 0.90398[0m
[92maverage training of epoch 29: loss -13.87959 acc 0.66225 roc_auc 0.37647 prc_auc 0.57093[0m
[93maverage test of epoch 29: loss -14.36459 acc 0.67568 roc_auc 0.81500 prc_auc 0.90484[0m
[92maverage training of epoch 30: loss -14.82653 acc 0.66225 roc_auc 0.37569 prc_auc 0.56965[0m
[93maverage test of epoch 30: loss -15.33752 acc 0.67568 roc_auc 0.81667 prc_auc 0.90693[0m
[92maverage training of epoch 31: loss -15.82230 acc 0.66225 roc_auc 0.37304 prc_auc 0.56660[0m
[93maverage test of epoch 31: loss -16.36012 acc 0.67568 roc_auc 0.82167 prc_auc 0.90721[0m
[92maverage training of epoch 32: loss -16.86888 acc 0.66225 roc_auc 0.37461 prc_auc 0.56907[0m
[93maverage test of epoch 32: loss -17.43472 acc 0.67568 roc_auc 0.83000 prc_auc 0.90240[0m
[92maverage training of epoch 33: loss -17.96851 acc 0.66225 roc_auc 0.37608 prc_auc 0.57297[0m
[93maverage test of epoch 33: loss -18.56289 acc 0.67568 roc_auc 0.86167 prc_auc 0.91769[0m
[92maverage training of epoch 34: loss -19.12187 acc 0.66225 roc_auc 0.37510 prc_auc 0.57352[0m
[93maverage test of epoch 34: loss -19.74522 acc 0.67568 roc_auc 0.84833 prc_auc 0.90230[0m
[92maverage training of epoch 35: loss -20.33020 acc 0.66225 roc_auc 0.37569 prc_auc 0.57490[0m
[93maverage test of epoch 35: loss -20.98321 acc 0.67568 roc_auc 0.83500 prc_auc 0.90001[0m
[92maverage training of epoch 36: loss -21.59496 acc 0.66225 roc_auc 0.37510 prc_auc 0.57643[0m
[93maverage test of epoch 36: loss -22.27848 acc 0.67568 roc_auc 0.83667 prc_auc 0.89145[0m
[92maverage training of epoch 37: loss -22.91767 acc 0.66225 roc_auc 0.37431 prc_auc 0.57446[0m
[93maverage test of epoch 37: loss -23.63211 acc 0.67568 roc_auc 0.83167 prc_auc 0.89241[0m
[92maverage training of epoch 38: loss -24.29739 acc 0.66225 roc_auc 0.37471 prc_auc 0.57264[0m
[93maverage test of epoch 38: loss -25.04143 acc 0.67568 roc_auc 0.82500 prc_auc 0.89375[0m
[92maverage training of epoch 39: loss -25.73213 acc 0.66225 roc_auc 0.37510 prc_auc 0.57106[0m
[93maverage test of epoch 39: loss -26.50633 acc 0.67568 roc_auc 0.76833 prc_auc 0.84625[0m
[92maverage training of epoch 40: loss -27.22343 acc 0.66225 roc_auc 0.37275 prc_auc 0.56719[0m
[93maverage test of epoch 40: loss -28.02868 acc 0.67568 roc_auc 0.80500 prc_auc 0.85872[0m
[92maverage training of epoch 41: loss -28.77292 acc 0.66225 roc_auc 0.37392 prc_auc 0.56754[0m
[93maverage test of epoch 41: loss -29.61024 acc 0.67568 roc_auc 0.80667 prc_auc 0.90332[0m
[92maverage training of epoch 42: loss -30.38166 acc 0.66225 roc_auc 0.37353 prc_auc 0.56723[0m
[93maverage test of epoch 42: loss -31.25036 acc 0.67568 roc_auc 0.73667 prc_auc 0.81760[0m
[92maverage training of epoch 43: loss -32.04748 acc 0.66225 roc_auc 0.37392 prc_auc 0.56749[0m
[93maverage test of epoch 43: loss -32.94713 acc 0.67568 roc_auc 0.78000 prc_auc 0.85165[0m
[92maverage training of epoch 44: loss -33.77071 acc 0.66225 roc_auc 0.37529 prc_auc 0.56959[0m
[93maverage test of epoch 44: loss -34.70224 acc 0.67568 roc_auc 0.73667 prc_auc 0.81817[0m
[92maverage training of epoch 45: loss -35.55173 acc 0.66225 roc_auc 0.37559 prc_auc 0.57009[0m
[93maverage test of epoch 45: loss -36.51512 acc 0.67568 roc_auc 0.64000 prc_auc 0.76649[0m
[92maverage training of epoch 46: loss -37.39118 acc 0.66225 roc_auc 0.37667 prc_auc 0.57103[0m
[93maverage test of epoch 46: loss -38.38780 acc 0.67568 roc_auc 0.66000 prc_auc 0.75975[0m
[92maverage training of epoch 47: loss -39.29103 acc 0.66225 roc_auc 0.37735 prc_auc 0.57014[0m
[93maverage test of epoch 47: loss -40.32157 acc 0.67568 roc_auc 0.66833 prc_auc 0.77789[0m
[92maverage training of epoch 48: loss -41.25278 acc 0.66225 roc_auc 0.37843 prc_auc 0.57118[0m
[93maverage test of epoch 48: loss -42.31847 acc 0.67568 roc_auc 0.58000 prc_auc 0.72346[0m
[92maverage training of epoch 49: loss -43.27852 acc 0.66225 roc_auc 0.37990 prc_auc 0.57197[0m
[93maverage test of epoch 49: loss -44.38063 acc 0.67568 roc_auc 0.86000 prc_auc 0.89108[0m
[92maverage training of epoch 50: loss -45.36921 acc 0.66225 roc_auc 0.38059 prc_auc 0.57273[0m
[93maverage test of epoch 50: loss -46.50649 acc 0.67568 roc_auc 0.36000 prc_auc 0.68865[0m
[92maverage training of epoch 51: loss -47.52260 acc 0.66225 roc_auc 0.38157 prc_auc 0.57312[0m
[93maverage test of epoch 51: loss -48.69567 acc 0.67568 roc_auc 0.80000 prc_auc 0.85359[0m
[92maverage training of epoch 52: loss -49.74021 acc 0.66225 roc_auc 0.38147 prc_auc 0.57320[0m
[93maverage test of epoch 52: loss -50.95005 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 53: loss -52.02362 acc 0.66225 roc_auc 0.38118 prc_auc 0.57355[0m
[93maverage test of epoch 53: loss -53.27121 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 54: loss -54.37428 acc 0.66225 roc_auc 0.38176 prc_auc 0.57425[0m
[93maverage test of epoch 54: loss -55.66048 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 55: loss -56.79356 acc 0.66225 roc_auc 0.38186 prc_auc 0.57409[0m
[93maverage test of epoch 55: loss -58.11923 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 56: loss -59.28270 acc 0.66225 roc_auc 0.38206 prc_auc 0.57402[0m
[93maverage test of epoch 56: loss -60.64861 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 57: loss -61.84282 acc 0.66225 roc_auc 0.38255 prc_auc 0.57404[0m
[93maverage test of epoch 57: loss -63.24969 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 58: loss -64.47508 acc 0.66225 roc_auc 0.38275 prc_auc 0.57419[0m
[93maverage test of epoch 58: loss -65.92389 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 59: loss -67.18099 acc 0.66225 roc_auc 0.38255 prc_auc 0.57411[0m
[93maverage test of epoch 59: loss -68.67263 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 60: loss -69.96190 acc 0.66225 roc_auc 0.38304 prc_auc 0.57455[0m
[93maverage test of epoch 60: loss -71.49722 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 61: loss -72.81906 acc 0.66225 roc_auc 0.38373 prc_auc 0.57462[0m
[93maverage test of epoch 61: loss -74.39890 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 62: loss -75.75367 acc 0.66225 roc_auc 0.38382 prc_auc 0.57626[0m
[93maverage test of epoch 62: loss -77.37893 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 63: loss -78.76695 acc 0.66225 roc_auc 0.38471 prc_auc 0.57593[0m
[93maverage test of epoch 63: loss -80.43832 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 64: loss -81.86006 acc 0.66225 roc_auc 0.38480 prc_auc 0.57578[0m
[93maverage test of epoch 64: loss -83.57851 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 65: loss -85.03420 acc 0.66225 roc_auc 0.38510 prc_auc 0.57619[0m
[93maverage test of epoch 65: loss -86.80041 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 66: loss -88.29044 acc 0.66225 roc_auc 0.38549 prc_auc 0.57747[0m
[93maverage test of epoch 66: loss -90.10535 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 67: loss -91.63011 acc 0.66225 roc_auc 0.38686 prc_auc 0.57759[0m
[93maverage test of epoch 67: loss -93.49454 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 68: loss -95.05423 acc 0.66225 roc_auc 0.38735 prc_auc 0.58137[0m
[93maverage test of epoch 68: loss -96.96889 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 69: loss -98.56386 acc 0.66225 roc_auc 0.39353 prc_auc 0.58320[0m
[93maverage test of epoch 69: loss -100.52970 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 70: loss -102.16033 acc 0.66225 roc_auc 0.39235 prc_auc 0.58516[0m
[93maverage test of epoch 70: loss -104.17823 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 71: loss -105.84476 acc 0.66225 roc_auc 0.39324 prc_auc 0.59335[0m
[93maverage test of epoch 71: loss -107.91547 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 72: loss -109.61826 acc 0.66225 roc_auc 0.39059 prc_auc 0.59504[0m
[93maverage test of epoch 72: loss -111.74262 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 73: loss -113.48180 acc 0.66225 roc_auc 0.40578 prc_auc 0.61827[0m
[93maverage test of epoch 73: loss -115.66059 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 74: loss -117.43658 acc 0.66225 roc_auc 0.41922 prc_auc 0.62407[0m
[93maverage test of epoch 74: loss -119.67063 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 75: loss -121.48351 acc 0.66225 roc_auc 0.45667 prc_auc 0.64622[0m
[93maverage test of epoch 75: loss -123.77373 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 76: loss -125.62400 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 76: loss -127.97134 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 77: loss -129.85923 acc 0.66225 roc_auc 0.44647 prc_auc 0.63981[0m
[93maverage test of epoch 77: loss -132.26445 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 78: loss -134.19006 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 78: loss -136.65398 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 79: loss -138.61768 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 79: loss -141.14120 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 80: loss -143.14318 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 80: loss -145.72712 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 81: loss -147.76765 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 81: loss -150.41294 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 82: loss -152.49225 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 82: loss -155.19975 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 83: loss -157.31810 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 83: loss -160.08867 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 84: loss -162.24605 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 84: loss -165.08039 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 85: loss -167.27722 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 85: loss -170.17640 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 86: loss -172.41291 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 86: loss -175.37783 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 87: loss -177.65416 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 87: loss -180.68563 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 88: loss -183.00193 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 88: loss -186.10074 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 89: loss -188.45713 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 89: loss -191.62427 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 90: loss -194.02115 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 90: loss -197.25766 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 91: loss -199.69517 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 91: loss -203.00188 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 92: loss -205.48020 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 92: loss -208.85794 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 93: loss -211.37713 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 93: loss -214.82689 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 94: loss -217.38714 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 94: loss -220.90981 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 95: loss -223.51145 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 95: loss -227.10804 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 96: loss -229.75120 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 96: loss -233.42264 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 97: loss -236.11077 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 97: loss -239.88339 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 98: loss -242.69345 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 98: loss -246.60905 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 99: loss -249.46781 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 99: loss -253.46513 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=8, bias=True)
    (ReLU1): ReLU()
    (Linear2): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.06700 acc 0.33775 roc_auc 0.29510 prc_auc 0.56403[0m
[93maverage test of epoch 0: loss -0.10198 acc 0.32432 roc_auc 0.34333 prc_auc 0.70804[0m
[92maverage training of epoch 1: loss -0.12755 acc 0.33775 roc_auc 0.36275 prc_auc 0.58340[0m
[93maverage test of epoch 1: loss -0.16446 acc 0.67568 roc_auc 0.34333 prc_auc 0.70804[0m
[92maverage training of epoch 2: loss -0.19485 acc 0.62252 roc_auc 0.43804 prc_auc 0.66816[0m
[93maverage test of epoch 2: loss -0.24193 acc 0.67568 roc_auc 0.94000 prc_auc 0.97546[0m
[92maverage training of epoch 3: loss -0.27785 acc 0.65563 roc_auc 0.48922 prc_auc 0.70749[0m
[93maverage test of epoch 3: loss -0.33246 acc 0.67568 roc_auc 0.94000 prc_auc 0.97546[0m
[92maverage training of epoch 4: loss -0.37208 acc 0.65563 roc_auc 0.53667 prc_auc 0.73474[0m
[93maverage test of epoch 4: loss -0.42926 acc 0.67568 roc_auc 0.94000 prc_auc 0.97546[0m
[92maverage training of epoch 5: loss -0.46307 acc 0.66225 roc_auc 0.64078 prc_auc 0.81361[0m
[93maverage test of epoch 5: loss -0.51419 acc 0.67568 roc_auc 0.93667 prc_auc 0.97435[0m
[92maverage training of epoch 6: loss -0.54768 acc 0.66225 roc_auc 0.70765 prc_auc 0.85010[0m
[93maverage test of epoch 6: loss -0.60131 acc 0.67568 roc_auc 0.93333 prc_auc 0.97332[0m
[92maverage training of epoch 7: loss -0.64306 acc 0.66225 roc_auc 0.65078 prc_auc 0.82022[0m
[93maverage test of epoch 7: loss -0.70695 acc 0.67568 roc_auc 0.93333 prc_auc 0.97332[0m
[92maverage training of epoch 8: loss -0.76504 acc 0.66225 roc_auc 0.64000 prc_auc 0.80921[0m
[93maverage test of epoch 8: loss -0.85776 acc 0.67568 roc_auc 0.93333 prc_auc 0.97377[0m
[92maverage training of epoch 9: loss -0.94904 acc 0.66225 roc_auc 0.60235 prc_auc 0.77972[0m
[93maverage test of epoch 9: loss -1.07349 acc 0.67568 roc_auc 0.93333 prc_auc 0.97377[0m
[92maverage training of epoch 10: loss -1.18385 acc 0.66225 roc_auc 0.58118 prc_auc 0.76131[0m
[93maverage test of epoch 10: loss -1.33054 acc 0.67568 roc_auc 0.93667 prc_auc 0.97536[0m
[92maverage training of epoch 11: loss -1.45120 acc 0.66225 roc_auc 0.56078 prc_auc 0.74123[0m
[93maverage test of epoch 11: loss -1.61134 acc 0.67568 roc_auc 0.93667 prc_auc 0.97536[0m
[92maverage training of epoch 12: loss -1.73666 acc 0.66225 roc_auc 0.53647 prc_auc 0.71851[0m
[93maverage test of epoch 12: loss -1.90706 acc 0.67568 roc_auc 0.93667 prc_auc 0.97536[0m
[92maverage training of epoch 13: loss -2.03909 acc 0.66225 roc_auc 0.52392 prc_auc 0.70564[0m
[93maverage test of epoch 13: loss -2.22404 acc 0.67568 roc_auc 0.93667 prc_auc 0.97536[0m
[92maverage training of epoch 14: loss -2.36794 acc 0.66225 roc_auc 0.50902 prc_auc 0.69662[0m
[93maverage test of epoch 14: loss -2.57397 acc 0.67568 roc_auc 0.93667 prc_auc 0.97536[0m
[92maverage training of epoch 15: loss -2.73492 acc 0.66225 roc_auc 0.49784 prc_auc 0.68909[0m
[93maverage test of epoch 15: loss -2.96576 acc 0.67568 roc_auc 0.93667 prc_auc 0.97536[0m
[92maverage training of epoch 16: loss -3.14044 acc 0.66225 roc_auc 0.48706 prc_auc 0.68088[0m
[93maverage test of epoch 16: loss -3.38799 acc 0.67568 roc_auc 0.93667 prc_auc 0.97536[0m
[92maverage training of epoch 17: loss -3.57305 acc 0.66225 roc_auc 0.47941 prc_auc 0.67748[0m
[93maverage test of epoch 17: loss -3.83564 acc 0.67568 roc_auc 0.93333 prc_auc 0.97377[0m
[92maverage training of epoch 18: loss -4.03033 acc 0.66225 roc_auc 0.48843 prc_auc 0.69976[0m
[93maverage test of epoch 18: loss -4.30887 acc 0.67568 roc_auc 0.93333 prc_auc 0.97377[0m
[92maverage training of epoch 19: loss -4.51509 acc 0.66225 roc_auc 0.50451 prc_auc 0.71789[0m
[93maverage test of epoch 19: loss -4.81269 acc 0.67568 roc_auc 0.93000 prc_auc 0.97235[0m
[92maverage training of epoch 20: loss -5.03372 acc 0.66225 roc_auc 0.55098 prc_auc 0.75725[0m
[93maverage test of epoch 20: loss -5.35210 acc 0.67568 roc_auc 0.92667 prc_auc 0.97104[0m
[92maverage training of epoch 21: loss -5.59152 acc 0.66225 roc_auc 0.58059 prc_auc 0.78222[0m
[93maverage test of epoch 21: loss -5.93496 acc 0.67568 roc_auc 0.92333 prc_auc 0.96958[0m
[92maverage training of epoch 22: loss -6.20036 acc 0.66225 roc_auc 0.63373 prc_auc 0.81135[0m
[93maverage test of epoch 22: loss -6.57829 acc 0.67568 roc_auc 0.92333 prc_auc 0.96958[0m
[92maverage training of epoch 23: loss -6.88523 acc 0.66225 roc_auc 0.73373 prc_auc 0.86168[0m
[93maverage test of epoch 23: loss -7.31404 acc 0.67568 roc_auc 0.92333 prc_auc 0.96958[0m
[92maverage training of epoch 24: loss -7.66023 acc 0.66225 roc_auc 0.71275 prc_auc 0.85633[0m
[93maverage test of epoch 24: loss -8.13031 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 25: loss -8.50732 acc 0.66225 roc_auc 0.49275 prc_auc 0.68142[0m
[93maverage test of epoch 25: loss -9.00706 acc 0.67568 roc_auc 0.82500 prc_auc 0.92396[0m
[92maverage training of epoch 26: loss -9.39741 acc 0.66225 roc_auc 0.41275 prc_auc 0.62024[0m
[93maverage test of epoch 26: loss -9.91805 acc 0.67568 roc_auc 0.62167 prc_auc 0.82610[0m
[92maverage training of epoch 27: loss -10.33487 acc 0.66225 roc_auc 0.41735 prc_auc 0.61861[0m
[93maverage test of epoch 27: loss -10.89913 acc 0.67568 roc_auc 0.50500 prc_auc 0.74642[0m
[92maverage training of epoch 28: loss -11.34049 acc 0.66225 roc_auc 0.42255 prc_auc 0.62246[0m
[93maverage test of epoch 28: loss -11.94130 acc 0.67568 roc_auc 0.77500 prc_auc 0.87796[0m
[92maverage training of epoch 29: loss -12.40180 acc 0.66225 roc_auc 0.42412 prc_auc 0.62377[0m
[93maverage test of epoch 29: loss -13.03704 acc 0.67568 roc_auc 0.92167 prc_auc 0.96087[0m
[92maverage training of epoch 30: loss -13.51406 acc 0.66225 roc_auc 0.42431 prc_auc 0.62393[0m
[93maverage test of epoch 30: loss -14.18349 acc 0.67568 roc_auc 0.93167 prc_auc 0.95918[0m
[92maverage training of epoch 31: loss -14.67625 acc 0.66225 roc_auc 0.42451 prc_auc 0.62399[0m
[93maverage test of epoch 31: loss -15.37998 acc 0.67568 roc_auc 0.94667 prc_auc 0.96121[0m
[92maverage training of epoch 32: loss -15.88692 acc 0.66225 roc_auc 0.42451 prc_auc 0.62399[0m
[93maverage test of epoch 32: loss -16.62534 acc 0.67568 roc_auc 0.78000 prc_auc 0.85333[0m
[92maverage training of epoch 33: loss -17.14680 acc 0.66225 roc_auc 0.42451 prc_auc 0.62399[0m
[93maverage test of epoch 33: loss -17.92117 acc 0.67568 roc_auc 0.80000 prc_auc 0.87027[0m
[92maverage training of epoch 34: loss -18.45736 acc 0.66225 roc_auc 0.42441 prc_auc 0.62406[0m
[93maverage test of epoch 34: loss -19.26938 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 35: loss -19.82098 acc 0.66225 roc_auc 0.42412 prc_auc 0.62333[0m
[93maverage test of epoch 35: loss -20.67221 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 36: loss -21.23920 acc 0.66225 roc_auc 0.42412 prc_auc 0.62164[0m
[93maverage test of epoch 36: loss -22.13095 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 37: loss -22.71300 acc 0.66225 roc_auc 0.42235 prc_auc 0.62011[0m
[93maverage test of epoch 37: loss -23.64534 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 38: loss -24.24045 acc 0.66225 roc_auc 0.42010 prc_auc 0.61845[0m
[93maverage test of epoch 38: loss -25.21210 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 39: loss -25.81864 acc 0.66225 roc_auc 0.42451 prc_auc 0.62698[0m
[93maverage test of epoch 39: loss -26.82993 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -27.44772 acc 0.66225 roc_auc 0.42010 prc_auc 0.62014[0m
[93maverage test of epoch 40: loss -28.49905 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -29.12782 acc 0.66225 roc_auc 0.42892 prc_auc 0.63166[0m
[93maverage test of epoch 41: loss -30.22023 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -30.86048 acc 0.66225 roc_auc 0.41588 prc_auc 0.62911[0m
[93maverage test of epoch 42: loss -31.99542 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -32.64734 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 43: loss -33.82597 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -34.48757 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 44: loss -35.71043 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -36.38734 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 45: loss -37.65789 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -38.34710 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 46: loss -39.66579 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -40.36917 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 47: loss -41.73795 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -42.45569 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 48: loss -43.86951 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -44.60642 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 49: loss -46.08080 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 50: loss -46.82561 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 50: loss -48.35428 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 51: loss -49.11526 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 51: loss -50.69340 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 52: loss -51.46921 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 52: loss -53.10246 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 53: loss -53.89143 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 53: loss -55.58747 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 54: loss -56.39461 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 54: loss -58.13916 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 55: loss -58.96767 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 55: loss -60.77946 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 56: loss -61.61885 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 56: loss -63.49057 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 57: loss -64.34656 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0mUsing backend: pytorch
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))

[93maverage test of epoch 57: loss -66.28349 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 58: loss -67.15678 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 58: loss -69.15640 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 59: loss -70.04771 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 59: loss -72.11255 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 60: loss -73.02141 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 60: loss -75.14764 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 61: loss -76.09431 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 61: loss -78.32702 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 62: loss -79.32398 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 62: loss -81.62775 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 63: loss -82.63833 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 63: loss -85.00495 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 64: loss -86.03081 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 64: loss -88.46123 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 65: loss -89.50035 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 65: loss -91.99892 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 66: loss -93.05675 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 66: loss -95.61845 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 67: loss -96.69383 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 67: loss -99.32706 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 68: loss -100.41878 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 68: loss -103.12117 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 69: loss -104.23009 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 69: loss -107.00430 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 70: loss -108.13124 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 70: loss -110.97794 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 71: loss -112.12286 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 71: loss -115.04365 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 72: loss -116.20680 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 72: loss -119.20064 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 73: loss -120.38374 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 73: loss -123.45689 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 74: loss -124.65608 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 74: loss -127.80728 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 75: loss -129.02453 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 75: loss -132.25510 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 76: loss -133.49216 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 76: loss -136.80178 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 77: loss -138.05761 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 77: loss -141.44819 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 78: loss -142.72311 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 78: loss -146.19302 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 79: loss -147.48991 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 79: loss -151.04805 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 80: loss -152.36039 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 80: loss -156.00306 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 81: loss -157.33427 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 81: loss -161.06308 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 82: loss -162.41331 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 82: loss -166.22958 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 83: loss -167.59842 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 83: loss -171.50353 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 84: loss -172.89147 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 84: loss -176.88615 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 85: loss -178.29276 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 85: loss -182.37841 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 86: loss -183.80298 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 86: loss -187.98183 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 87: loss -189.42603 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 87: loss -193.69724 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 88: loss -195.16005 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 88: loss -199.52584 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 89: loss -201.00722 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 89: loss -205.46875 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 90: loss -206.96867 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 90: loss -211.52719 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 91: loss -213.04560 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 91: loss -217.70079 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 92: loss -219.23883 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 92: loss -223.99530 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 93: loss -225.55047 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 93: loss -230.40719 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 94: loss -231.98030 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 94: loss -236.93874 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 95: loss -238.53003 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 95: loss -243.59144 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 96: loss -245.20054 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 96: loss -250.36613 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 97: loss -251.99285 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 97: loss -257.26399 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 98: loss -258.90862 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 98: loss -264.28625 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 99: loss -265.94841 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 99: loss -271.43391 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 2)
('lr', 0.0001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.60185 ROC_AUC (avg): 0.5 PRC_AUC (avg): 0.66501 

Average forward propagation time taken(ms): 3.132420820709788
Average backward propagation time taken(ms): 1.004066212759138

