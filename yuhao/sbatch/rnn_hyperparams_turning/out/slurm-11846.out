# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.0003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-18-12-20/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-18-12-20/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 16,
 'epochs': 50,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 4,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.0003,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 1,
 'num_workers': 8,
 'number_of_mlp_layer': 0,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-17-18-12-20',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 50, 'learning_rate': 0.0003, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss 0.03830 acc 0.33333 roc_auc 0.56640 prc_auc 0.72384[0m
[93maverage test of epoch 0: loss -0.14409 acc 0.34211 roc_auc 0.88923 prc_auc 0.94599[0m
[92maverage training of epoch 1: loss -0.29529 acc 0.33333 roc_auc 0.55080 prc_auc 0.73964[0m
[93maverage test of epoch 1: loss -0.48110 acc 0.34211 roc_auc 0.88000 prc_auc 0.94441[0m
[92maverage training of epoch 2: loss -0.68006 acc 0.33333 roc_auc 0.52380 prc_auc 0.72491[0m
[93maverage test of epoch 2: loss -0.92241 acc 0.34211 roc_auc 0.90154 prc_auc 0.95504[0m
[92maverage training of epoch 3: loss -1.11401 acc 0.35333 roc_auc 0.55480 prc_auc 0.75463[0m
[93maverage test of epoch 3: loss -1.37962 acc 0.39474 roc_auc 0.89846 prc_auc 0.95557[0m
[92maverage training of epoch 4: loss -1.50804 acc 0.66000 roc_auc 0.72620 prc_auc 0.85502[0m
[93maverage test of epoch 4: loss -1.72478 acc 0.78947 roc_auc 0.89846 prc_auc 0.95390[0m
[92maverage training of epoch 5: loss -1.88806 acc 0.80667 roc_auc 0.83620 prc_auc 0.89844[0m
[93maverage test of epoch 5: loss -2.11621 acc 0.81579 roc_auc 0.87692 prc_auc 0.95033[0m
[92maverage training of epoch 6: loss -2.32469 acc 0.86000 roc_auc 0.84460 prc_auc 0.88875[0m
[93maverage test of epoch 6: loss -2.44332 acc 0.81579 roc_auc 0.88615 prc_auc 0.95366[0m
[92maverage training of epoch 7: loss -2.66502 acc 0.87333 roc_auc 0.84380 prc_auc 0.88585[0m
[93maverage test of epoch 7: loss -2.70534 acc 0.81579 roc_auc 0.88615 prc_auc 0.95366[0m
[92maverage training of epoch 8: loss -2.93217 acc 0.88000 roc_auc 0.83900 prc_auc 0.88130[0m
[93maverage test of epoch 8: loss -2.97737 acc 0.84211 roc_auc 0.88923 prc_auc 0.95442[0m
[92maverage training of epoch 9: loss -3.16324 acc 0.88000 roc_auc 0.82880 prc_auc 0.87258[0m
[93maverage test of epoch 9: loss -3.14412 acc 0.81579 roc_auc 0.88308 prc_auc 0.95213[0m
[92maverage training of epoch 10: loss -3.38028 acc 0.88000 roc_auc 0.83160 prc_auc 0.86345[0m
[93maverage test of epoch 10: loss -3.39819 acc 0.84211 roc_auc 0.89846 prc_auc 0.95735[0m
[92maverage training of epoch 11: loss -3.48577 acc 0.84000 roc_auc 0.79420 prc_auc 0.84954[0m
[93maverage test of epoch 11: loss -3.59426 acc 0.84211 roc_auc 0.90154 prc_auc 0.95910[0m
[92maverage training of epoch 12: loss -3.59728 acc 0.80667 roc_auc 0.70320 prc_auc 0.78318[0m
[93maverage test of epoch 12: loss -3.78002 acc 0.84211 roc_auc 0.88615 prc_auc 0.95247[0m
[92maverage training of epoch 13: loss -3.97509 acc 0.88667 roc_auc 0.83800 prc_auc 0.87766[0m
[93maverage test of epoch 13: loss -3.89716 acc 0.81579 roc_auc 0.89538 prc_auc 0.95423[0m
[92maverage training of epoch 14: loss -4.18899 acc 0.89333 roc_auc 0.84580 prc_auc 0.88237[0m
[93maverage test of epoch 14: loss -4.07858 acc 0.81579 roc_auc 0.89538 prc_auc 0.95483[0m
[92maverage training of epoch 15: loss -4.35824 acc 0.88667 roc_auc 0.84740 prc_auc 0.88283[0m
[93maverage test of epoch 15: loss -4.32568 acc 0.84211 roc_auc 0.90769 prc_auc 0.96191[0m
[92maverage training of epoch 16: loss -4.52343 acc 0.88000 roc_auc 0.84360 prc_auc 0.88095[0m
[93maverage test of epoch 16: loss -4.49704 acc 0.84211 roc_auc 0.90154 prc_auc 0.95915[0m
[92maverage training of epoch 17: loss -4.70187 acc 0.88000 roc_auc 0.82240 prc_auc 0.85456[0m
[93maverage test of epoch 17: loss -4.67579 acc 0.84211 roc_auc 0.89846 prc_auc 0.95662[0m
[92maverage training of epoch 18: loss -4.85474 acc 0.87333 roc_auc 0.79280 prc_auc 0.83590[0m
[93maverage test of epoch 18: loss -4.77478 acc 0.81579 roc_auc 0.90462 prc_auc 0.95920[0m
[92maverage training of epoch 19: loss -4.99843 acc 0.86667 roc_auc 0.75360 prc_auc 0.78966[0m
[93maverage test of epoch 19: loss -4.93412 acc 0.81579 roc_auc 0.90462 prc_auc 0.96070[0m
[92maverage training of epoch 20: loss -5.11455 acc 0.84667 roc_auc 0.80790 prc_auc 0.85554[0m
[93maverage test of epoch 20: loss -5.17896 acc 0.84211 roc_auc 0.90462 prc_auc 0.95959[0m
[92maverage training of epoch 21: loss -5.44593 acc 0.90000 roc_auc 0.84500 prc_auc 0.87467[0m
[93maverage test of epoch 21: loss -5.26453 acc 0.81579 roc_auc 0.91077 prc_auc 0.96163[0m
[92maverage training of epoch 22: loss -5.38680 acc 0.82667 roc_auc 0.65340 prc_auc 0.71488[0m
[93maverage test of epoch 22: loss -4.93863 acc 0.65789 roc_auc 0.87538 prc_auc 0.94014[0m
[92maverage training of epoch 23: loss -5.05968 acc 0.66667 roc_auc 0.37580 prc_auc 0.59221[0m
[93maverage test of epoch 23: loss -5.11304 acc 0.65789 roc_auc 0.87077 prc_auc 0.93530[0m
[92maverage training of epoch 24: loss -5.23435 acc 0.66667 roc_auc 0.37460 prc_auc 0.59041[0m
[93maverage test of epoch 24: loss -5.28680 acc 0.65789 roc_auc 0.88000 prc_auc 0.93539[0m
[92maverage training of epoch 25: loss -5.40821 acc 0.66667 roc_auc 0.37300 prc_auc 0.58947[0m
[93maverage test of epoch 25: loss -5.45979 acc 0.65789 roc_auc 0.88308 prc_auc 0.93154[0m
[92maverage training of epoch 26: loss -5.58135 acc 0.66667 roc_auc 0.37220 prc_auc 0.58938[0m
[93maverage test of epoch 26: loss -5.63211 acc 0.65789 roc_auc 0.88154 prc_auc 0.93203[0m
[92maverage training of epoch 27: loss -5.75385 acc 0.66667 roc_auc 0.37180 prc_auc 0.58904[0m
[93maverage test of epoch 27: loss -5.80382 acc 0.65789 roc_auc 0.87385 prc_auc 0.91122[0m
[92maverage training of epoch 28: loss -5.92578 acc 0.66667 roc_auc 0.37100 prc_auc 0.58876[0m
[93maverage test of epoch 28: loss -5.97499 acc 0.65789 roc_auc 0.88000 prc_auc 0.90915[0m
[92maverage training of epoch 29: loss -6.09718 acc 0.66667 roc_auc 0.37040 prc_auc 0.58854[0m
[93maverage test of epoch 29: loss -6.14567 acc 0.65789 roc_auc 0.87846 prc_auc 0.90125[0m
[92maverage training of epoch 30: loss -6.26812 acc 0.66667 roc_auc 0.36960 prc_auc 0.58830[0m
[93maverage test of epoch 30: loss -6.31589 acc 0.65789 roc_auc 0.88462 prc_auc 0.90934[0m
[92maverage training of epoch 31: loss -6.43861 acc 0.66667 roc_auc 0.36910 prc_auc 0.58804[0m
[93maverage test of epoch 31: loss -6.48570 acc 0.65789 roc_auc 0.86769 prc_auc 0.89637[0m
[92maverage training of epoch 32: loss -6.60871 acc 0.66667 roc_auc 0.36880 prc_auc 0.58856[0m
[93maverage test of epoch 32: loss -6.65512 acc 0.65789 roc_auc 0.84154 prc_auc 0.87393[0m
[92maverage training of epoch 33: loss -6.77843 acc 0.66667 roc_auc 0.36830 prc_auc 0.58822[0m
[93maverage test of epoch 33: loss -6.82419 acc 0.65789 roc_auc 0.81846 prc_auc 0.85741[0m
[92maverage training of epoch 34: loss -6.94781 acc 0.66667 roc_auc 0.36800 prc_auc 0.58725[0m
[93maverage test of epoch 34: loss -6.99293 acc 0.65789 roc_auc 0.76769 prc_auc 0.81867[0m
[92maverage training of epoch 35: loss -7.11688 acc 0.66667 roc_auc 0.36750 prc_auc 0.58727[0m
[93maverage test of epoch 35: loss -7.16138 acc 0.65789 roc_auc 0.75077 prc_auc 0.82298[0m
[92maverage training of epoch 36: loss -7.28566 acc 0.66667 roc_auc 0.36710 prc_auc 0.58727[0m
[93maverage test of epoch 36: loss -7.32954 acc 0.65789 roc_auc 0.72615 prc_auc 0.79384[0m
[92maverage training of epoch 37: loss -7.45417 acc 0.66667 roc_auc 0.36680 prc_auc 0.58682[0m
[93maverage test of epoch 37: loss -7.49746 acc 0.65789 roc_auc 0.69077 prc_auc 0.77651[0m
[92maverage training of epoch 38: loss -7.62244 acc 0.66667 roc_auc 0.36650 prc_auc 0.58690[0m
[93maverage test of epoch 38: loss -7.66513 acc 0.65789 roc_auc 0.63385 prc_auc 0.74699[0m
[92maverage training of epoch 39: loss -7.79048 acc 0.66667 roc_auc 0.36630 prc_auc 0.58679[0m
[93maverage test of epoch 39: loss -7.83260 acc 0.65789 roc_auc 0.64769 prc_auc 0.76930[0m
[92maverage training of epoch 40: loss -7.95831 acc 0.66667 roc_auc 0.36650 prc_auc 0.58702[0m
[93maverage test of epoch 40: loss -7.99986 acc 0.65789 roc_auc 0.49692 prc_auc 0.65675[0m
[92maverage training of epoch 41: loss -8.12596 acc 0.66667 roc_auc 0.36650 prc_auc 0.58708[0m
[93maverage test of epoch 41: loss -8.16694 acc 0.65789 roc_auc 0.44769 prc_auc 0.63997[0m
[92maverage training of epoch 42: loss -8.29343 acc 0.66667 roc_auc 0.36560 prc_auc 0.58419[0m
[93maverage test of epoch 42: loss -8.33386 acc 0.65789 roc_auc 0.45538 prc_auc 0.63867[0m
[92maverage training of epoch 43: loss -8.46074 acc 0.66667 roc_auc 0.36520 prc_auc 0.58432[0m
[93maverage test of epoch 43: loss -8.50063 acc 0.65789 roc_auc 0.52154 prc_auc 0.66895[0m
[92maverage training of epoch 44: loss -8.62791 acc 0.66667 roc_auc 0.36490 prc_auc 0.58315[0m
[93maverage test of epoch 44: loss -8.66726 acc 0.65789 roc_auc 0.51231 prc_auc 0.66351[0m
[92maverage training of epoch 45: loss -8.79494 acc 0.66667 roc_auc 0.36420 prc_auc 0.58355[0m
[93maverage test of epoch 45: loss -8.83375 acc 0.65789 roc_auc 0.52000 prc_auc 0.67158[0m
[92maverage training of epoch 46: loss -8.96185 acc 0.66667 roc_auc 0.36440 prc_auc 0.58324[0m
[93maverage test of epoch 46: loss -9.00014 acc 0.65789 roc_auc 0.51077 prc_auc 0.66281[0m
[92maverage training of epoch 47: loss -9.12865 acc 0.66667 roc_auc 0.36470 prc_auc 0.58351[0m
[93maverage test of epoch 47: loss -9.16642 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -9.29535 acc 0.66667 roc_auc 0.36450 prc_auc 0.58287[0m
[93maverage test of epoch 48: loss -9.33260 acc 0.65789 roc_auc 0.35846 prc_auc 0.60256[0m
[92maverage training of epoch 49: loss -9.46196 acc 0.66667 roc_auc 0.36430 prc_auc 0.58229[0m
[93maverage test of epoch 49: loss -9.49870 acc 0.65789 roc_auc 0.50154 prc_auc 0.65860[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.31554 acc 0.33333 roc_auc 0.42100 prc_auc 0.62727[0m
[93maverage test of epoch 0: loss -0.71555 acc 0.34211 roc_auc 0.25538 prc_auc 0.59912[0m
[92maverage training of epoch 1: loss -1.05111 acc 0.40000 roc_auc 0.47040 prc_auc 0.66312[0m
[93maverage test of epoch 1: loss -1.51799 acc 0.65789 roc_auc 0.59538 prc_auc 0.82801[0m
[92maverage training of epoch 2: loss -1.98598 acc 0.66667 roc_auc 0.51600 prc_auc 0.70481[0m
[93maverage test of epoch 2: loss -2.43576 acc 0.65789 roc_auc 0.79692 prc_auc 0.89651[0m
[92maverage training of epoch 3: loss -2.70593 acc 0.66667 roc_auc 0.59260 prc_auc 0.76672[0m
[93maverage test of epoch 3: loss -2.92723 acc 0.65789 roc_auc 0.81231 prc_auc 0.90709[0m
[92maverage training of epoch 4: loss -3.10180 acc 0.66667 roc_auc 0.58040 prc_auc 0.75407[0m
[93maverage test of epoch 4: loss -3.25103 acc 0.65789 roc_auc 0.80923 prc_auc 0.90476[0m
[92maverage training of epoch 5: loss -3.39480 acc 0.66667 roc_auc 0.55160 prc_auc 0.73641[0m
[93maverage test of epoch 5: loss -3.51695 acc 0.65789 roc_auc 0.81231 prc_auc 0.90709[0m
[92maverage training of epoch 6: loss -3.64705 acc 0.66667 roc_auc 0.52560 prc_auc 0.71648[0m
[93maverage test of epoch 6: loss -3.75521 acc 0.65789 roc_auc 0.80923 prc_auc 0.90553[0m
[92maverage training of epoch 7: loss -3.87798 acc 0.66667 roc_auc 0.49480 prc_auc 0.68596[0m
[93maverage test of epoch 7: loss -3.97763 acc 0.65789 roc_auc 0.80615 prc_auc 0.90220[0m
[92maverage training of epoch 8: loss -4.09599 acc 0.66667 roc_auc 0.47400 prc_auc 0.66128[0m
[93maverage test of epoch 8: loss -4.18990 acc 0.65789 roc_auc 0.80615 prc_auc 0.90220[0m
[92maverage training of epoch 9: loss -4.30535 acc 0.66667 roc_auc 0.45800 prc_auc 0.64684[0m
[93maverage test of epoch 9: loss -4.39500 acc 0.65789 roc_auc 0.80615 prc_auc 0.90254[0m
[92maverage training of epoch 10: loss -4.50838 acc 0.66667 roc_auc 0.44560 prc_auc 0.63721[0m
[93maverage test of epoch 10: loss -4.59462 acc 0.65789 roc_auc 0.80615 prc_auc 0.90254[0m
[92maverage training of epoch 11: loss -4.70642 acc 0.66667 roc_auc 0.43660 prc_auc 0.62395[0m
[93maverage test of epoch 11: loss -4.78975 acc 0.65789 roc_auc 0.80615 prc_auc 0.90254[0m
[92maverage training of epoch 12: loss -4.90028 acc 0.66667 roc_auc 0.43310 prc_auc 0.61843[0m
[93maverage test of epoch 12: loss -4.98103 acc 0.65789 roc_auc 0.80615 prc_auc 0.90254[0m
[92maverage training of epoch 13: loss -5.09055 acc 0.66667 roc_auc 0.43050 prc_auc 0.61326[0m
[93maverage test of epoch 13: loss -5.16896 acc 0.65789 roc_auc 0.80615 prc_auc 0.90058[0m
[92maverage training of epoch 14: loss -5.27767 acc 0.66667 roc_auc 0.42680 prc_auc 0.60735[0m
[93maverage test of epoch 14: loss -5.35393 acc 0.65789 roc_auc 0.80462 prc_auc 0.90058[0m
[92maverage training of epoch 15: loss -5.46201 acc 0.66667 roc_auc 0.42560 prc_auc 0.60548[0m
[93maverage test of epoch 15: loss -5.53632 acc 0.65789 roc_auc 0.80308 prc_auc 0.89391[0m
[92maverage training of epoch 16: loss -5.64392 acc 0.66667 roc_auc 0.42460 prc_auc 0.60076[0m
[93maverage test of epoch 16: loss -5.71644 acc 0.65789 roc_auc 0.80154 prc_auc 0.89410[0m
[92maverage training of epoch 17: loss -5.82371 acc 0.66667 roc_auc 0.42300 prc_auc 0.59964[0m
[93maverage test of epoch 17: loss -5.89460 acc 0.65789 roc_auc 0.80308 prc_auc 0.89276[0m
[92maverage training of epoch 18: loss -6.00165 acc 0.66667 roc_auc 0.42120 prc_auc 0.59927[0m
[93maverage test of epoch 18: loss -6.07104 acc 0.65789 roc_auc 0.80000 prc_auc 0.89276[0m
[92maverage training of epoch 19: loss -6.17797 acc 0.66667 roc_auc 0.42110 prc_auc 0.60006[0m
[93maverage test of epoch 19: loss -6.24600 acc 0.65789 roc_auc 0.80615 prc_auc 0.89825[0m
[92maverage training of epoch 20: loss -6.35291 acc 0.66667 roc_auc 0.42140 prc_auc 0.60205[0m
[93maverage test of epoch 20: loss -6.41969 acc 0.65789 roc_auc 0.80615 prc_auc 0.89682[0m
[92maverage training of epoch 21: loss -6.52665 acc 0.66667 roc_auc 0.42150 prc_auc 0.60336[0m
[93maverage test of epoch 21: loss -6.59227 acc 0.65789 roc_auc 0.80615 prc_auc 0.89349[0m
[92maverage training of epoch 22: loss -6.69935 acc 0.66667 roc_auc 0.42100 prc_auc 0.60433[0m
[93maverage test of epoch 22: loss -6.76390 acc 0.65789 roc_auc 0.79692 prc_auc 0.88931[0m
[92maverage training of epoch 23: loss -6.87115 acc 0.66667 roc_auc 0.42180 prc_auc 0.60685[0m
[93maverage test of epoch 23: loss -6.93471 acc 0.65789 roc_auc 0.88154 prc_auc 0.92363[0m
[92maverage training of epoch 24: loss -7.04217 acc 0.66667 roc_auc 0.42240 prc_auc 0.60825[0m
[93maverage test of epoch 24: loss -7.10481 acc 0.65789 roc_auc 0.87077 prc_auc 0.91167[0m
[92maverage training of epoch 25: loss -7.21252 acc 0.66667 roc_auc 0.42310 prc_auc 0.61136[0m
[93maverage test of epoch 25: loss -7.27429 acc 0.65789 roc_auc 0.88154 prc_auc 0.92164[0m
[92maverage training of epoch 26: loss -7.38229 acc 0.66667 roc_auc 0.42320 prc_auc 0.61143[0m
[93maverage test of epoch 26: loss -7.44324 acc 0.65789 roc_auc 0.87385 prc_auc 0.90528[0m
[92maverage training of epoch 27: loss -7.55155 acc 0.66667 roc_auc 0.42300 prc_auc 0.61138[0m
[93maverage test of epoch 27: loss -7.61173 acc 0.65789 roc_auc 0.87231 prc_auc 0.90910[0m
[92maverage training of epoch 28: loss -7.72037 acc 0.66667 roc_auc 0.42280 prc_auc 0.61108[0m
[93maverage test of epoch 28: loss -7.77981 acc 0.65789 roc_auc 0.88308 prc_auc 0.91777[0m
[92maverage training of epoch 29: loss -7.88881 acc 0.66667 roc_auc 0.42250 prc_auc 0.61103[0m
[93maverage test of epoch 29: loss -7.94755 acc 0.65789 roc_auc 0.88154 prc_auc 0.91510[0m
[92maverage training of epoch 30: loss -8.05692 acc 0.66667 roc_auc 0.42250 prc_auc 0.61103[0m
[93maverage test of epoch 30: loss -8.11498 acc 0.65789 roc_auc 0.88154 prc_auc 0.91556[0m
[92maverage training of epoch 31: loss -8.22473 acc 0.66667 roc_auc 0.42250 prc_auc 0.61103[0m
[93maverage test of epoch 31: loss -8.28214 acc 0.65789 roc_auc 0.86462 prc_auc 0.89079[0m
[92maverage training of epoch 32: loss -8.39230 acc 0.66667 roc_auc 0.42240 prc_auc 0.61098[0m
[93maverage test of epoch 32: loss -8.44908 acc 0.65789 roc_auc 0.85538 prc_auc 0.88000[0m
[92maverage training of epoch 33: loss -8.55964 acc 0.66667 roc_auc 0.42210 prc_auc 0.60965[0m
[93maverage test of epoch 33: loss -8.61581 acc 0.65789 roc_auc 0.86462 prc_auc 0.89079[0m
[92maverage training of epoch 34: loss -8.72679 acc 0.66667 roc_auc 0.42200 prc_auc 0.60960[0m
[93maverage test of epoch 34: loss -8.78237 acc 0.65789 roc_auc 0.87077 prc_auc 0.89689[0m
[92maverage training of epoch 35: loss -8.89377 acc 0.66667 roc_auc 0.42180 prc_auc 0.60960[0m
[93maverage test of epoch 35: loss -8.94877 acc 0.65789 roc_auc 0.86462 prc_auc 0.89079[0m
[92maverage training of epoch 36: loss -9.06060 acc 0.66667 roc_auc 0.42180 prc_auc 0.60960[0m
[93maverage test of epoch 36: loss -9.11504 acc 0.65789 roc_auc 0.87077 prc_auc 0.89689[0m
[92maverage training of epoch 37: loss -9.22731 acc 0.66667 roc_auc 0.42180 prc_auc 0.60963[0m
[93maverage test of epoch 37: loss -9.28118 acc 0.65789 roc_auc 0.82462 prc_auc 0.84889[0m
[92maverage training of epoch 38: loss -9.39389 acc 0.66667 roc_auc 0.42180 prc_auc 0.60960[0m
[93maverage test of epoch 38: loss -9.44723 acc 0.65789 roc_auc 0.89231 prc_auc 0.90963[0m
[92maverage training of epoch 39: loss -9.56038 acc 0.66667 roc_auc 0.42160 prc_auc 0.60877[0m
[93maverage test of epoch 39: loss -9.61317 acc 0.65789 roc_auc 0.82000 prc_auc 0.84667[0m
[92maverage training of epoch 40: loss -9.72678 acc 0.66667 roc_auc 0.42160 prc_auc 0.60813[0m
[93maverage test of epoch 40: loss -9.77905 acc 0.65789 roc_auc 0.88462 prc_auc 0.90133[0m
[92maverage training of epoch 41: loss -9.89310 acc 0.66667 roc_auc 0.42150 prc_auc 0.60718[0m
[93maverage test of epoch 41: loss -9.94484 acc 0.65789 roc_auc 0.82000 prc_auc 0.84667[0m
[92maverage training of epoch 42: loss -10.05935 acc 0.66667 roc_auc 0.42140 prc_auc 0.60718[0m
[93maverage test of epoch 42: loss -10.11058 acc 0.65789 roc_auc 0.83692 prc_auc 0.85806[0m
[92maverage training of epoch 43: loss -10.22555 acc 0.66667 roc_auc 0.42120 prc_auc 0.60647[0m
[93maverage test of epoch 43: loss -10.27626 acc 0.65789 roc_auc 0.77385 prc_auc 0.81889[0m
[92maverage training of epoch 44: loss -10.39169 acc 0.66667 roc_auc 0.42100 prc_auc 0.60591[0m
[93maverage test of epoch 44: loss -10.44189 acc 0.65789 roc_auc 0.82154 prc_auc 0.84961[0m
[92maverage training of epoch 45: loss -10.55778 acc 0.66667 roc_auc 0.42060 prc_auc 0.60510[0m
[93maverage test of epoch 45: loss -10.60748 acc 0.65789 roc_auc 0.76154 prc_auc 0.82530[0m
[92maverage training of epoch 46: loss -10.72383 acc 0.66667 roc_auc 0.42070 prc_auc 0.60517[0m
[93maverage test of epoch 46: loss -10.77303 acc 0.65789 roc_auc 0.76615 prc_auc 0.81514[0m
[92maverage training of epoch 47: loss -10.88985 acc 0.66667 roc_auc 0.42060 prc_auc 0.60502[0m
[93maverage test of epoch 47: loss -10.93855 acc 0.65789 roc_auc 0.75846 prc_auc 0.81158[0m
[92maverage training of epoch 48: loss -11.05583 acc 0.66667 roc_auc 0.42070 prc_auc 0.60517[0m
[93maverage test of epoch 48: loss -11.10404 acc 0.65789 roc_auc 0.78769 prc_auc 0.82194[0m
[92maverage training of epoch 49: loss -11.22178 acc 0.66667 roc_auc 0.42050 prc_auc 0.60491[0m
[93maverage test of epoch 49: loss -11.26950 acc 0.65789 roc_auc 0.57538 prc_auc 0.70162[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss 0.17349 acc 0.34000 roc_auc 0.39420 prc_auc 0.61630[0m
[93maverage test of epoch 0: loss 0.02484 acc 0.63158 roc_auc 0.53846 prc_auc 0.80401[0m
[92maverage training of epoch 1: loss -0.10909 acc 0.66000 roc_auc 0.42680 prc_auc 0.64033[0m
[93maverage test of epoch 1: loss -0.24028 acc 0.65789 roc_auc 0.78462 prc_auc 0.91657[0m
[92maverage training of epoch 2: loss -0.38437 acc 0.66667 roc_auc 0.45980 prc_auc 0.66777[0m
[93maverage test of epoch 2: loss -0.52612 acc 0.65789 roc_auc 0.94923 prc_auc 0.97679[0m
[92maverage training of epoch 3: loss -0.73433 acc 0.66667 roc_auc 0.47940 prc_auc 0.68102[0m
[93maverage test of epoch 3: loss -0.96111 acc 0.65789 roc_auc 0.95385 prc_auc 0.97950[0m
[92maverage training of epoch 4: loss -1.26023 acc 0.66667 roc_auc 0.49060 prc_auc 0.69547[0m
[93maverage test of epoch 4: loss -1.53197 acc 0.65789 roc_auc 0.95385 prc_auc 0.97950[0m
[92maverage training of epoch 5: loss -1.79985 acc 0.66667 roc_auc 0.49780 prc_auc 0.69444[0m
[93maverage test of epoch 5: loss -2.02070 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 6: loss -2.26622 acc 0.66667 roc_auc 0.47960 prc_auc 0.68504[0m
[93maverage test of epoch 6: loss -2.47321 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 7: loss -2.71188 acc 0.66667 roc_auc 0.48680 prc_auc 0.69082[0m
[93maverage test of epoch 7: loss -2.88548 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 8: loss -3.07384 acc 0.66667 roc_auc 0.51780 prc_auc 0.71358[0m
[93maverage test of epoch 8: loss -3.19255 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 9: loss -3.35295 acc 0.66667 roc_auc 0.51900 prc_auc 0.70928[0m
[93maverage test of epoch 9: loss -3.44652 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 10: loss -3.59558 acc 0.66667 roc_auc 0.51200 prc_auc 0.70161[0m
[93maverage test of epoch 10: loss -3.67679 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 11: loss -3.81934 acc 0.66667 roc_auc 0.50080 prc_auc 0.69190[0m
[93maverage test of epoch 11: loss -3.89267 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 12: loss -4.03087 acc 0.66667 roc_auc 0.48460 prc_auc 0.67827[0m
[93maverage test of epoch 12: loss -4.09856 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 13: loss -4.23366 acc 0.66667 roc_auc 0.46710 prc_auc 0.66447[0m
[93maverage test of epoch 13: loss -4.29707 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 14: loss -4.42988 acc 0.66667 roc_auc 0.45310 prc_auc 0.65531[0m
[93maverage test of epoch 14: loss -4.48991 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 15: loss -4.62101 acc 0.66667 roc_auc 0.44480 prc_auc 0.65039[0m
[93maverage test of epoch 15: loss -4.67828 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 16: loss -4.80808 acc 0.66667 roc_auc 0.44010 prc_auc 0.64704[0m
[93maverage test of epoch 16: loss -4.86306 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 17: loss -4.99188 acc 0.66667 roc_auc 0.43440 prc_auc 0.64391[0m
[93maverage test of epoch 17: loss -5.04491 acc 0.65789 roc_auc 0.95231 prc_auc 0.97791[0m
[92maverage training of epoch 18: loss -5.17299 acc 0.66667 roc_auc 0.42890 prc_auc 0.63961[0m
[93maverage test of epoch 18: loss -5.22433 acc 0.65789 roc_auc 0.95231 prc_auc 0.97791[0m
[92maverage training of epoch 19: loss -5.35187 acc 0.66667 roc_auc 0.42240 prc_auc 0.62959[0m
[93maverage test of epoch 19: loss -5.40173 acc 0.65789 roc_auc 0.95231 prc_auc 0.97791[0m
[92maverage training of epoch 20: loss -5.52890 acc 0.66667 roc_auc 0.41190 prc_auc 0.62052[0m
[93maverage test of epoch 20: loss -5.57744 acc 0.65789 roc_auc 0.95231 prc_auc 0.97791[0m
[92maverage training of epoch 21: loss -5.70435 acc 0.66667 roc_auc 0.40470 prc_auc 0.61520[0m
[93maverage test of epoch 21: loss -5.75172 acc 0.65789 roc_auc 0.95077 prc_auc 0.97663[0m
[92maverage training of epoch 22: loss -5.87849 acc 0.66667 roc_auc 0.40070 prc_auc 0.61119[0m
[93maverage test of epoch 22: loss -5.92479 acc 0.65789 roc_auc 0.95231 prc_auc 0.97791[0m
[92maverage training of epoch 23: loss -6.05149 acc 0.66667 roc_auc 0.39860 prc_auc 0.61093[0m
[93maverage test of epoch 23: loss -6.09681 acc 0.65789 roc_auc 0.95077 prc_auc 0.97663[0m
[92maverage training of epoch 24: loss -6.22354 acc 0.66667 roc_auc 0.39700 prc_auc 0.60971[0m
[93maverage test of epoch 24: loss -6.26795 acc 0.65789 roc_auc 0.95231 prc_auc 0.97791[0m
[92maverage training of epoch 25: loss -6.39476 acc 0.66667 roc_auc 0.39570 prc_auc 0.60873[0m
[93maverage test of epoch 25: loss -6.43833 acc 0.65789 roc_auc 0.95077 prc_auc 0.97663[0m
[92maverage training of epoch 26: loss -6.56527 acc 0.66667 roc_auc 0.39380 prc_auc 0.60777[0m
[93maverage test of epoch 26: loss -6.60805 acc 0.65789 roc_auc 0.95077 prc_auc 0.97663[0m
[92maverage training of epoch 27: loss -6.73517 acc 0.66667 roc_auc 0.39150 prc_auc 0.60667[0m
[93maverage test of epoch 27: loss -6.77720 acc 0.65789 roc_auc 0.95385 prc_auc 0.97808[0m
[92maverage training of epoch 28: loss -6.90454 acc 0.66667 roc_auc 0.39010 prc_auc 0.60563[0m
[93maverage test of epoch 28: loss -6.94587 acc 0.65789 roc_auc 0.95077 prc_auc 0.97663[0m
[92maverage training of epoch 29: loss -7.07345 acc 0.66667 roc_auc 0.38850 prc_auc 0.60349[0m
[93maverage test of epoch 29: loss -7.11410 acc 0.65789 roc_auc 0.95385 prc_auc 0.97663[0m
[92maverage training of epoch 30: loss -7.24197 acc 0.66667 roc_auc 0.38830 prc_auc 0.60238[0m
[93maverage test of epoch 30: loss -7.28197 acc 0.65789 roc_auc 0.94923 prc_auc 0.97524[0m
[92maverage training of epoch 31: loss -7.41013 acc 0.66667 roc_auc 0.38750 prc_auc 0.60144[0m
[93maverage test of epoch 31: loss -7.44951 acc 0.65789 roc_auc 0.94923 prc_auc 0.97264[0m
[92maverage training of epoch 32: loss -7.57800 acc 0.66667 roc_auc 0.38700 prc_auc 0.60132[0m
[93maverage test of epoch 32: loss -7.61678 acc 0.65789 roc_auc 0.95385 prc_auc 0.97298[0m
[92maverage training of epoch 33: loss -7.74561 acc 0.66667 roc_auc 0.38630 prc_auc 0.60051[0m
[93maverage test of epoch 33: loss -7.78380 acc 0.65789 roc_auc 0.96154 prc_auc 0.97536[0m
[92maverage training of epoch 34: loss -7.91299 acc 0.66667 roc_auc 0.38590 prc_auc 0.59989[0m
[93maverage test of epoch 34: loss -7.95060 acc 0.65789 roc_auc 0.95385 prc_auc 0.97298[0m
[92maverage training of epoch 35: loss -8.08017 acc 0.66667 roc_auc 0.38540 prc_auc 0.59965[0m
[93maverage test of epoch 35: loss -8.11722 acc 0.65789 roc_auc 0.93538 prc_auc 0.95520[0m
[92maverage training of epoch 36: loss -8.24717 acc 0.66667 roc_auc 0.38490 prc_auc 0.59652[0m
[93maverage test of epoch 36: loss -8.28368 acc 0.65789 roc_auc 0.84462 prc_auc 0.87016[0m
[92maverage training of epoch 37: loss -8.41403 acc 0.66667 roc_auc 0.38440 prc_auc 0.59678[0m
[93maverage test of epoch 37: loss -8.44999 acc 0.65789 roc_auc 0.92462 prc_auc 0.94060[0m
[92maverage training of epoch 38: loss -8.58074 acc 0.66667 roc_auc 0.38420 prc_auc 0.59673[0m
[93maverage test of epoch 38: loss -8.61617 acc 0.65789 roc_auc 0.84462 prc_auc 0.86648[0m
[92maverage training of epoch 39: loss -8.74734 acc 0.66667 roc_auc 0.38400 prc_auc 0.59711[0m
[93maverage test of epoch 39: loss -8.78225 acc 0.65789 roc_auc 0.84308 prc_auc 0.87222[0m
[92maverage training of epoch 40: loss -8.91383 acc 0.66667 roc_auc 0.38340 prc_auc 0.59213[0m
[93maverage test of epoch 40: loss -8.94823 acc 0.65789 roc_auc 0.88154 prc_auc 0.90708[0m
[92maverage training of epoch 41: loss -9.08024 acc 0.66667 roc_auc 0.38280 prc_auc 0.58949[0m
[93maverage test of epoch 41: loss -9.11412 acc 0.65789 roc_auc 0.86462 prc_auc 0.87965[0m
[92maverage training of epoch 42: loss -9.24656 acc 0.66667 roc_auc 0.38260 prc_auc 0.58940[0m
[93maverage test of epoch 42: loss -9.27993 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -9.41282 acc 0.66667 roc_auc 0.38120 prc_auc 0.58858[0m
[93maverage test of epoch 43: loss -9.44569 acc 0.65789 roc_auc 0.67231 prc_auc 0.74632[0m
[92maverage training of epoch 44: loss -9.57901 acc 0.66667 roc_auc 0.38050 prc_auc 0.58721[0m
[93maverage test of epoch 44: loss -9.61138 acc 0.65789 roc_auc 0.88000 prc_auc 0.91789[0m
[92maverage training of epoch 45: loss -9.74514 acc 0.66667 roc_auc 0.38050 prc_auc 0.58642[0m
[93maverage test of epoch 45: loss -9.77702 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -9.91123 acc 0.66667 roc_auc 0.38060 prc_auc 0.58685[0m
[93maverage test of epoch 46: loss -9.94261 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -10.07728 acc 0.66667 roc_auc 0.38030 prc_auc 0.58224[0m
[93maverage test of epoch 47: loss -10.10817 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -10.24329 acc 0.66667 roc_auc 0.37930 prc_auc 0.57854[0m
[93maverage test of epoch 48: loss -10.27369 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -10.40926 acc 0.66667 roc_auc 0.37910 prc_auc 0.57792[0m
[93maverage test of epoch 49: loss -10.43918 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.03426 acc 0.66225 roc_auc 0.47961 prc_auc 0.63633[0m
[93maverage test of epoch 0: loss -0.10886 acc 0.67568 roc_auc 0.51333 prc_auc 0.78854[0m
[92maverage training of epoch 1: loss -0.18136 acc 0.59603 roc_auc 0.56314 prc_auc 0.70558[0m
[93maverage test of epoch 1: loss -0.26182 acc 0.35135 roc_auc 0.94000 prc_auc 0.97577[0m
[92maverage training of epoch 2: loss -0.34327 acc 0.36424 roc_auc 0.66784 prc_auc 0.80859[0m
[93maverage test of epoch 2: loss -0.41528 acc 0.35135 roc_auc 0.87667 prc_auc 0.93583[0m
[92maverage training of epoch 3: loss -0.50167 acc 0.35099 roc_auc 0.76392 prc_auc 0.88469[0m
[93maverage test of epoch 3: loss -0.57391 acc 0.35135 roc_auc 0.86667 prc_auc 0.92599[0m
[92maverage training of epoch 4: loss -0.68368 acc 0.35099 roc_auc 0.81569 prc_auc 0.91310[0m
[93maverage test of epoch 4: loss -0.77007 acc 0.35135 roc_auc 0.86333 prc_auc 0.92366[0m
[92maverage training of epoch 5: loss -0.88859 acc 0.35099 roc_auc 0.74667 prc_auc 0.88735[0m
[93maverage test of epoch 5: loss -0.98218 acc 0.32432 roc_auc 0.86667 prc_auc 0.93436[0m
[92maverage training of epoch 6: loss -1.10403 acc 0.33775 roc_auc 0.55422 prc_auc 0.77154[0m
[93maverage test of epoch 6: loss -1.19912 acc 0.32432 roc_auc 0.87333 prc_auc 0.93345[0m
[92maverage training of epoch 7: loss -1.31542 acc 0.33775 roc_auc 0.43000 prc_auc 0.65189[0m
[93maverage test of epoch 7: loss -1.40718 acc 0.32432 roc_auc 0.81000 prc_auc 0.88706[0m
[92maverage training of epoch 8: loss -1.52470 acc 0.33775 roc_auc 0.40000 prc_auc 0.62036[0m
[93maverage test of epoch 8: loss -1.62071 acc 0.32432 roc_auc 0.81000 prc_auc 0.88807[0m
[92maverage training of epoch 9: loss -1.74177 acc 0.33775 roc_auc 0.39451 prc_auc 0.60760[0m
[93maverage test of epoch 9: loss -1.84174 acc 0.32432 roc_auc 0.82000 prc_auc 0.89096[0m
[92maverage training of epoch 10: loss -1.96151 acc 0.33775 roc_auc 0.39020 prc_auc 0.60153[0m
[93maverage test of epoch 10: loss -2.06038 acc 0.32432 roc_auc 0.82667 prc_auc 0.89488[0m
[92maverage training of epoch 11: loss -2.17563 acc 0.33775 roc_auc 0.38373 prc_auc 0.59076[0m
[93maverage test of epoch 11: loss -2.27139 acc 0.32432 roc_auc 0.84333 prc_auc 0.89975[0m
[92maverage training of epoch 12: loss -2.38187 acc 0.33775 roc_auc 0.37667 prc_auc 0.56966[0m
[93maverage test of epoch 12: loss -2.47463 acc 0.32432 roc_auc 0.80000 prc_auc 0.87637[0m
[92maverage training of epoch 13: loss -2.58098 acc 0.33775 roc_auc 0.37451 prc_auc 0.56774[0m
[93maverage test of epoch 13: loss -2.67134 acc 0.32432 roc_auc 0.79333 prc_auc 0.86519[0m
[92maverage training of epoch 14: loss -2.77424 acc 0.33775 roc_auc 0.37431 prc_auc 0.56776[0m
[93maverage test of epoch 14: loss -2.86283 acc 0.32432 roc_auc 0.79333 prc_auc 0.86549[0m
[92maverage training of epoch 15: loss -2.96285 acc 0.33775 roc_auc 0.37373 prc_auc 0.56753[0m
[93maverage test of epoch 15: loss -3.05016 acc 0.32432 roc_auc 0.79833 prc_auc 0.87418[0m
[92maverage training of epoch 16: loss -3.14773 acc 0.33775 roc_auc 0.37373 prc_auc 0.56768[0m
[93maverage test of epoch 16: loss -3.23415 acc 0.32432 roc_auc 0.79333 prc_auc 0.86360[0m
[92maverage training of epoch 17: loss -3.32961 acc 0.33775 roc_auc 0.37392 prc_auc 0.56795[0m
[93maverage test of epoch 17: loss -3.41543 acc 0.32432 roc_auc 0.80000 prc_auc 0.86590[0m
[92maverage training of epoch 18: loss -3.50905 acc 0.33775 roc_auc 0.37451 prc_auc 0.56845[0m
[93maverage test of epoch 18: loss -3.59452 acc 0.32432 roc_auc 0.80000 prc_auc 0.86585[0m
[92maverage training of epoch 19: loss -3.68649 acc 0.33775 roc_auc 0.37431 prc_auc 0.56844[0m
[93maverage test of epoch 19: loss -3.77178 acc 0.32432 roc_auc 0.79667 prc_auc 0.86501[0m
[92maverage training of epoch 20: loss -3.86227 acc 0.33775 roc_auc 0.37490 prc_auc 0.56913[0m
[93maverage test of epoch 20: loss -3.94754 acc 0.32432 roc_auc 0.80333 prc_auc 0.86730[0m
[92maverage training of epoch 21: loss -4.03667 acc 0.33775 roc_auc 0.37549 prc_auc 0.56932[0m
[93maverage test of epoch 21: loss -4.12203 acc 0.32432 roc_auc 0.79000 prc_auc 0.86185[0m
[92maverage training of epoch 22: loss -4.20992 acc 0.33775 roc_auc 0.37549 prc_auc 0.56946[0m
[93maverage test of epoch 22: loss -4.29547 acc 0.32432 roc_auc 0.79667 prc_auc 0.86420[0m
[92maverage training of epoch 23: loss -4.38219 acc 0.33775 roc_auc 0.37529 prc_auc 0.56920[0m
[93maverage test of epoch 23: loss -4.46802 acc 0.32432 roc_auc 0.79667 prc_auc 0.86371[0m
[92maverage training of epoch 24: loss -4.55364 acc 0.33775 roc_auc 0.37529 prc_auc 0.56920[0m
[93maverage test of epoch 24: loss -4.63980 acc 0.32432 roc_auc 0.81833 prc_auc 0.88382[0m
[92maverage training of epoch 25: loss -4.72439 acc 0.33775 roc_auc 0.37529 prc_auc 0.56920[0m
[93maverage test of epoch 25: loss -4.81095 acc 0.32432 roc_auc 0.79833 prc_auc 0.84538[0m
[92maverage training of epoch 26: loss -4.89455 acc 0.47682 roc_auc 0.37549 prc_auc 0.56979[0m
[93maverage test of epoch 26: loss -4.98155 acc 0.67568 roc_auc 0.80667 prc_auc 0.85407[0m
[92maverage training of epoch 27: loss -5.06420 acc 0.66225 roc_auc 0.37529 prc_auc 0.56942[0m
[93maverage test of epoch 27: loss -5.15168 acc 0.67568 roc_auc 0.78167 prc_auc 0.83174[0m
[92maverage training of epoch 28: loss -5.23342 acc 0.66225 roc_auc 0.37529 prc_auc 0.56942[0m
[93maverage test of epoch 28: loss -5.32140 acc 0.67568 roc_auc 0.75667 prc_auc 0.82622[0m
[92maverage training of epoch 29: loss -5.40226 acc 0.66225 roc_auc 0.37549 prc_auc 0.56951[0m
[93maverage test of epoch 29: loss -5.49079 acc 0.67568 roc_auc 0.80833 prc_auc 0.86512[0m
[92maverage training of epoch 30: loss -5.57079 acc 0.66225 roc_auc 0.37549 prc_auc 0.56951[0m
[93maverage test of epoch 30: loss -5.65987 acc 0.67568 roc_auc 0.71000 prc_auc 0.78675[0m
[92maverage training of epoch 31: loss -5.73903 acc 0.66225 roc_auc 0.37569 prc_auc 0.56982[0m
[93maverage test of epoch 31: loss -5.82870 acc 0.67568 roc_auc 0.76833 prc_auc 0.83524[0m
[92maverage training of epoch 32: loss -5.90704 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 32: loss -5.99731 acc 0.67568 roc_auc 0.73667 prc_auc 0.81535[0m
[92maverage training of epoch 33: loss -6.07485 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 33: loss -6.16573 acc 0.67568 roc_auc 0.66000 prc_auc 0.76569[0m
[92maverage training of epoch 34: loss -6.24248 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 34: loss -6.33399 acc 0.67568 roc_auc 0.67500 prc_auc 0.77073[0m
[92maverage training of epoch 35: loss -6.40995 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 35: loss -6.50210 acc 0.67568 roc_auc 0.67000 prc_auc 0.76487[0m
[92maverage training of epoch 36: loss -6.57730 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 36: loss -6.67010 acc 0.67568 roc_auc 0.69833 prc_auc 0.81578[0m
[92maverage training of epoch 37: loss -6.74453 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 37: loss -6.83798 acc 0.67568 roc_auc 0.82500 prc_auc 0.89323[0m
[92maverage training of epoch 38: loss -6.91166 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 38: loss -7.00577 acc 0.67568 roc_auc 0.78833 prc_auc 0.85127[0m
[92maverage training of epoch 39: loss -7.07870 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 39: loss -7.17348 acc 0.67568 roc_auc 0.64833 prc_auc 0.76824[0m
[92maverage training of epoch 40: loss -7.24566 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 40: loss -7.34112 acc 0.67568 roc_auc 0.76167 prc_auc 0.83122[0m
[92maverage training of epoch 41: loss -7.41257 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 41: loss -7.50870 acc 0.67568 roc_auc 0.70500 prc_auc 0.81571[0m
[92maverage training of epoch 42: loss -7.57941 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 42: loss -7.67623 acc 0.67568 roc_auc 0.82000 prc_auc 0.88203[0m
[92maverage training of epoch 43: loss -7.74621 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 43: loss -7.84371 acc 0.67568 roc_auc 0.51667 prc_auc 0.70936[0m
[92maverage training of epoch 44: loss -7.91296 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 44: loss -8.01115 acc 0.67568 roc_auc 0.66833 prc_auc 0.77100[0m
[92maverage training of epoch 45: loss -8.07967 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 45: loss -8.17855 acc 0.67568 roc_auc 0.76333 prc_auc 0.85159[0m
[92maverage training of epoch 46: loss -8.24635 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 46: loss -8.34593 acc 0.67568 roc_auc 0.60000 prc_auc 0.73814[0m
[92maverage training of epoch 47: loss -8.41301 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 47: loss -8.51328 acc 0.67568 roc_auc 0.68500 prc_auc 0.84103[0m
[92maverage training of epoch 48: loss -8.57964 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 48: loss -8.68060 acc 0.67568 roc_auc 0.26333 prc_auc 0.61089[0m
[92maverage training of epoch 49: loss -8.74624 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 49: loss -8.84790 acc 0.67568 roc_auc 0.66833 prc_auc 0.77975[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.61953 acc 0.66225 roc_auc 0.42137 prc_auc 0.63177[0m
[93maverage test of epoch 0: loss -0.73787 acc 0.67568 roc_auc 0.92333 prc_auc 0.96958[0m
[92maverage training of epoch 1: loss -0.84207 acc 0.66225 roc_auc 0.43549 prc_auc 0.66114[0m
[93maverage test of epoch 1: loss -0.96082 acc 0.67568 roc_auc 0.92667 prc_auc 0.97089[0m
[92maverage training of epoch 2: loss -1.06204 acc 0.66225 roc_auc 0.44608 prc_auc 0.65865[0m
[93maverage test of epoch 2: loss -1.18263 acc 0.67568 roc_auc 0.92667 prc_auc 0.97089[0m
[92maverage training of epoch 3: loss -1.28160 acc 0.66225 roc_auc 0.46353 prc_auc 0.67190[0m
[93maverage test of epoch 3: loss -1.40494 acc 0.67568 roc_auc 0.92333 prc_auc 0.96958[0m
[92maverage training of epoch 4: loss -1.50149 acc 0.66225 roc_auc 0.48627 prc_auc 0.69258[0m
[93maverage test of epoch 4: loss -1.62746 acc 0.67568 roc_auc 0.92667 prc_auc 0.97104[0m
[92maverage training of epoch 5: loss -1.72055 acc 0.66225 roc_auc 0.49451 prc_auc 0.70130[0m
[93maverage test of epoch 5: loss -1.84804 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 6: loss -1.93753 acc 0.66225 roc_auc 0.48725 prc_auc 0.69015[0m
[93maverage test of epoch 6: loss -2.06634 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 7: loss -2.15281 acc 0.66225 roc_auc 0.47627 prc_auc 0.67876[0mUsing backend: pytorch
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))

[93maverage test of epoch 7: loss -2.28313 acc 0.67568 roc_auc 0.92667 prc_auc 0.97135[0m
[92maverage training of epoch 8: loss -2.36633 acc 0.66225 roc_auc 0.46804 prc_auc 0.67138[0m
[93maverage test of epoch 8: loss -2.49764 acc 0.67568 roc_auc 0.92667 prc_auc 0.97104[0m
[92maverage training of epoch 9: loss -2.57698 acc 0.66225 roc_auc 0.45882 prc_auc 0.66296[0m
[93maverage test of epoch 9: loss -2.70854 acc 0.67568 roc_auc 0.92667 prc_auc 0.97104[0m
[92maverage training of epoch 10: loss -2.78364 acc 0.66225 roc_auc 0.45020 prc_auc 0.65579[0m
[93maverage test of epoch 10: loss -2.91486 acc 0.67568 roc_auc 0.93167 prc_auc 0.97235[0m
[92maverage training of epoch 11: loss -2.98566 acc 0.66225 roc_auc 0.43745 prc_auc 0.64496[0m
[93maverage test of epoch 11: loss -3.11622 acc 0.67568 roc_auc 0.93333 prc_auc 0.97390[0m
[92maverage training of epoch 12: loss -3.18295 acc 0.66225 roc_auc 0.42627 prc_auc 0.63680[0m
[93maverage test of epoch 12: loss -3.31275 acc 0.67568 roc_auc 0.93333 prc_auc 0.97377[0m
[92maverage training of epoch 13: loss -3.37578 acc 0.66225 roc_auc 0.41735 prc_auc 0.63068[0m
[93maverage test of epoch 13: loss -3.50490 acc 0.67568 roc_auc 0.93333 prc_auc 0.97377[0m
[92maverage training of epoch 14: loss -3.56465 acc 0.66225 roc_auc 0.40824 prc_auc 0.62537[0m
[93maverage test of epoch 14: loss -3.69322 acc 0.67568 roc_auc 0.93167 prc_auc 0.97104[0m
[92maverage training of epoch 15: loss -3.75010 acc 0.66225 roc_auc 0.40373 prc_auc 0.62301[0m
[93maverage test of epoch 15: loss -3.87829 acc 0.67568 roc_auc 0.93167 prc_auc 0.97104[0m
[92maverage training of epoch 16: loss -3.93265 acc 0.66225 roc_auc 0.39706 prc_auc 0.61720[0m
[93maverage test of epoch 16: loss -4.06062 acc 0.67568 roc_auc 0.93333 prc_auc 0.97264[0m
[92maverage training of epoch 17: loss -4.11277 acc 0.66225 roc_auc 0.39039 prc_auc 0.60601[0m
[93maverage test of epoch 17: loss -4.24066 acc 0.67568 roc_auc 0.93167 prc_auc 0.97104[0m
[92maverage training of epoch 18: loss -4.29085 acc 0.66225 roc_auc 0.38657 prc_auc 0.59877[0m
[93maverage test of epoch 18: loss -4.41877 acc 0.67568 roc_auc 0.93167 prc_auc 0.97104[0m
[92maverage training of epoch 19: loss -4.46721 acc 0.66225 roc_auc 0.38529 prc_auc 0.59869[0m
[93maverage test of epoch 19: loss -4.59528 acc 0.67568 roc_auc 0.93167 prc_auc 0.97104[0m
[92maverage training of epoch 20: loss -4.64214 acc 0.66225 roc_auc 0.38275 prc_auc 0.59681[0m
[93maverage test of epoch 20: loss -4.77044 acc 0.67568 roc_auc 0.93667 prc_auc 0.97264[0m
[92maverage training of epoch 21: loss -4.81586 acc 0.66225 roc_auc 0.38176 prc_auc 0.59553[0m
[93maverage test of epoch 21: loss -4.94446 acc 0.67568 roc_auc 0.93333 prc_auc 0.96845[0m
[92maverage training of epoch 22: loss -4.98856 acc 0.66225 roc_auc 0.38088 prc_auc 0.59301[0m
[93maverage test of epoch 22: loss -5.11752 acc 0.67568 roc_auc 0.93000 prc_auc 0.96845[0m
[92maverage training of epoch 23: loss -5.16039 acc 0.66225 roc_auc 0.38108 prc_auc 0.59321[0m
[93maverage test of epoch 23: loss -5.28977 acc 0.67568 roc_auc 0.93333 prc_auc 0.96845[0m
[92maverage training of epoch 24: loss -5.33149 acc 0.66225 roc_auc 0.38020 prc_auc 0.59282[0m
[93maverage test of epoch 24: loss -5.46132 acc 0.67568 roc_auc 0.93000 prc_auc 0.96958[0m
[92maverage training of epoch 25: loss -5.50195 acc 0.66225 roc_auc 0.37941 prc_auc 0.59130[0m
[93maverage test of epoch 25: loss -5.63228 acc 0.67568 roc_auc 0.93667 prc_auc 0.97264[0m
[92maverage training of epoch 26: loss -5.67188 acc 0.66225 roc_auc 0.37941 prc_auc 0.59243[0m
[93maverage test of epoch 26: loss -5.80273 acc 0.67568 roc_auc 0.93667 prc_auc 0.97264[0m
[92maverage training of epoch 27: loss -5.84135 acc 0.66225 roc_auc 0.37863 prc_auc 0.59121[0m
[93maverage test of epoch 27: loss -5.97275 acc 0.67568 roc_auc 0.93667 prc_auc 0.97264[0m
[92maverage training of epoch 28: loss -6.01043 acc 0.66225 roc_auc 0.37863 prc_auc 0.59131[0m
[93maverage test of epoch 28: loss -6.14239 acc 0.67568 roc_auc 0.93333 prc_auc 0.96845[0m
[92maverage training of epoch 29: loss -6.17916 acc 0.66225 roc_auc 0.37873 prc_auc 0.59094[0m
[93maverage test of epoch 29: loss -6.31172 acc 0.67568 roc_auc 0.93333 prc_auc 0.96845[0m
[92maverage training of epoch 30: loss -6.34760 acc 0.66225 roc_auc 0.37667 prc_auc 0.58256[0m
[93maverage test of epoch 30: loss -6.48076 acc 0.67568 roc_auc 0.93333 prc_auc 0.96845[0m
[92maverage training of epoch 31: loss -6.51579 acc 0.66225 roc_auc 0.37657 prc_auc 0.58241[0m
[93maverage test of epoch 31: loss -6.64957 acc 0.67568 roc_auc 0.93333 prc_auc 0.96875[0m
[92maverage training of epoch 32: loss -6.68375 acc 0.66225 roc_auc 0.37608 prc_auc 0.57484[0m
[93maverage test of epoch 32: loss -6.81816 acc 0.67568 roc_auc 0.94000 prc_auc 0.96875[0m
[92maverage training of epoch 33: loss -6.85153 acc 0.66225 roc_auc 0.37510 prc_auc 0.57304[0m
[93maverage test of epoch 33: loss -6.98658 acc 0.67568 roc_auc 0.93333 prc_auc 0.96998[0m
[92maverage training of epoch 34: loss -7.01914 acc 0.66225 roc_auc 0.37363 prc_auc 0.57135[0m
[93maverage test of epoch 34: loss -7.15484 acc 0.67568 roc_auc 0.94333 prc_auc 0.96875[0m
[92maverage training of epoch 35: loss -7.18661 acc 0.66225 roc_auc 0.37353 prc_auc 0.57131[0m
[93maverage test of epoch 35: loss -7.32297 acc 0.67568 roc_auc 0.93000 prc_auc 0.95690[0m
[92maverage training of epoch 36: loss -7.35395 acc 0.66225 roc_auc 0.37304 prc_auc 0.57097[0m
[93maverage test of epoch 36: loss -7.49098 acc 0.67568 roc_auc 0.91667 prc_auc 0.94505[0m
[92maverage training of epoch 37: loss -7.52118 acc 0.66225 roc_auc 0.37294 prc_auc 0.57091[0m
[93maverage test of epoch 37: loss -7.65888 acc 0.67568 roc_auc 0.89333 prc_auc 0.93850[0m
[92maverage training of epoch 38: loss -7.68832 acc 0.66225 roc_auc 0.37245 prc_auc 0.57052[0m
[93maverage test of epoch 38: loss -7.82669 acc 0.67568 roc_auc 0.91333 prc_auc 0.93912[0m
[92maverage training of epoch 39: loss -7.85538 acc 0.66225 roc_auc 0.37225 prc_auc 0.57023[0m
[93maverage test of epoch 39: loss -7.99443 acc 0.67568 roc_auc 0.92000 prc_auc 0.95750[0m
[92maverage training of epoch 40: loss -8.02236 acc 0.66225 roc_auc 0.37206 prc_auc 0.56997[0m
[93maverage test of epoch 40: loss -8.16210 acc 0.67568 roc_auc 0.90000 prc_auc 0.93703[0m
[92maverage training of epoch 41: loss -8.18928 acc 0.66225 roc_auc 0.37118 prc_auc 0.56927[0m
[93maverage test of epoch 41: loss -8.32970 acc 0.67568 roc_auc 0.82667 prc_auc 0.89147[0m
[92maverage training of epoch 42: loss -8.35615 acc 0.66225 roc_auc 0.37078 prc_auc 0.56895[0m
[93maverage test of epoch 42: loss -8.49726 acc 0.67568 roc_auc 0.92000 prc_auc 0.94811[0m
[92maverage training of epoch 43: loss -8.52296 acc 0.66225 roc_auc 0.37088 prc_auc 0.56914[0m
[93maverage test of epoch 43: loss -8.66477 acc 0.67568 roc_auc 0.79333 prc_auc 0.83776[0m
[92maverage training of epoch 44: loss -8.68974 acc 0.66225 roc_auc 0.37078 prc_auc 0.56897[0m
[93maverage test of epoch 44: loss -8.83224 acc 0.67568 roc_auc 0.66667 prc_auc 0.75758[0m
[92maverage training of epoch 45: loss -8.85648 acc 0.66225 roc_auc 0.37078 prc_auc 0.56895[0m
[93maverage test of epoch 45: loss -8.99967 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -9.02318 acc 0.66225 roc_auc 0.37069 prc_auc 0.56877[0m
[93maverage test of epoch 46: loss -9.16707 acc 0.67568 roc_auc 0.90000 prc_auc 0.93514[0m
[92maverage training of epoch 47: loss -9.18986 acc 0.66225 roc_auc 0.37039 prc_auc 0.56861[0m
[93maverage test of epoch 47: loss -9.33445 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -9.35651 acc 0.66225 roc_auc 0.37049 prc_auc 0.56861[0m
[93maverage test of epoch 48: loss -9.50180 acc 0.67568 roc_auc 0.54167 prc_auc 0.69444[0m
[92maverage training of epoch 49: loss -9.52314 acc 0.66225 roc_auc 0.37039 prc_auc 0.56849[0m
[93maverage test of epoch 49: loss -9.66913 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.0003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.66501 ROC_AUC (avg): 0.54905 PRC_AUC (avg): 0.69471 

Average forward propagation time taken(ms): 2.462732796145081
Average backward propagation time taken(ms): 0.8684127232453746

