# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 1)
('lr', 0.0003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-06-04-50/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-06-04-50/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 8,
 'epochs': 100,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 4,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.0003,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 2,
 'num_workers': 8,
 'number_of_mlp_layer': 1,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-18-06-04-50',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 100, 'learning_rate': 0.0003, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss 0.09729 acc 0.33333 roc_auc 0.56940 prc_auc 0.72833[0m
[93maverage test of epoch 0: loss -0.01277 acc 0.34211 roc_auc 0.52000 prc_auc 0.69222[0m
[92maverage training of epoch 1: loss -0.03628 acc 0.33333 roc_auc 0.35800 prc_auc 0.58375[0m
[93maverage test of epoch 1: loss -0.07368 acc 0.34211 roc_auc 0.60000 prc_auc 0.71956[0m
[92maverage training of epoch 2: loss -0.08780 acc 0.33333 roc_auc 0.44500 prc_auc 0.63624[0m
[93maverage test of epoch 2: loss -0.11575 acc 0.34211 roc_auc 0.49538 prc_auc 0.63470[0m
[92maverage training of epoch 3: loss -0.12627 acc 0.33333 roc_auc 0.44300 prc_auc 0.60640[0m
[93maverage test of epoch 3: loss -0.14714 acc 0.34211 roc_auc 0.38769 prc_auc 0.60766[0m
[92maverage training of epoch 4: loss -0.16091 acc 0.33333 roc_auc 0.39270 prc_auc 0.57309[0m
[93maverage test of epoch 4: loss -0.18364 acc 0.34211 roc_auc 0.57692 prc_auc 0.69444[0m
[92maverage training of epoch 5: loss -0.19362 acc 0.33333 roc_auc 0.34790 prc_auc 0.56130[0m
[93maverage test of epoch 5: loss -0.21616 acc 0.34211 roc_auc 0.53846 prc_auc 0.67568[0m
[92maverage training of epoch 6: loss -0.22719 acc 0.33333 roc_auc 0.36860 prc_auc 0.56650[0m
[93maverage test of epoch 6: loss -0.24800 acc 0.34211 roc_auc 0.44000 prc_auc 0.63096[0m
[92maverage training of epoch 7: loss -0.26026 acc 0.33333 roc_auc 0.36480 prc_auc 0.56567[0m
[93maverage test of epoch 7: loss -0.28189 acc 0.34211 roc_auc 0.52000 prc_auc 0.66703[0m
[92maverage training of epoch 8: loss -0.29340 acc 0.33333 roc_auc 0.37440 prc_auc 0.56946[0m
[93maverage test of epoch 8: loss -0.31479 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 9: loss -0.32657 acc 0.33333 roc_auc 0.37560 prc_auc 0.57051[0m
[93maverage test of epoch 9: loss -0.34784 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 10: loss -0.35960 acc 0.33333 roc_auc 0.35140 prc_auc 0.56042[0m
[93maverage test of epoch 10: loss -0.38074 acc 0.34211 roc_auc 0.48000 prc_auc 0.64902[0m
[92maverage training of epoch 11: loss -0.39287 acc 0.33333 roc_auc 0.35250 prc_auc 0.56020[0m
[93maverage test of epoch 11: loss -0.41369 acc 0.34211 roc_auc 0.48000 prc_auc 0.64902[0m
[92maverage training of epoch 12: loss -0.42598 acc 0.33333 roc_auc 0.35340 prc_auc 0.56061[0m
[93maverage test of epoch 12: loss -0.44697 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 13: loss -0.45918 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 13: loss -0.48002 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 14: loss -0.49232 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 14: loss -0.51306 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 15: loss -0.52546 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 15: loss -0.54611 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 16: loss -0.55860 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 16: loss -0.57907 acc 0.34211 roc_auc 0.48000 prc_auc 0.64902[0m
[92maverage training of epoch 17: loss -0.59174 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 17: loss -0.61221 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 18: loss -0.62488 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 18: loss -0.64525 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -0.65803 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 19: loss -0.67830 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -0.69117 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 20: loss -0.71135 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -0.72427 acc 0.33333 roc_auc 0.35480 prc_auc 0.56131[0m
[93maverage test of epoch 21: loss -0.74440 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -0.75745 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 22: loss -0.77745 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -0.79060 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 23: loss -0.81050 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -0.82374 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 24: loss -0.84355 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -0.85691 acc 0.33333 roc_auc 0.36460 prc_auc 0.56387[0m
[93maverage test of epoch 25: loss -0.87659 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -0.89003 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 26: loss -0.90964 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -0.92313 acc 0.33333 roc_auc 0.35520 prc_auc 0.56143[0m
[93maverage test of epoch 27: loss -0.94269 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -0.95631 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 28: loss -0.97574 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -0.98946 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 29: loss -1.00879 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -1.02253 acc 0.33333 roc_auc 0.35680 prc_auc 0.56147[0m
[93maverage test of epoch 30: loss -1.04184 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -1.05574 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 31: loss -1.07489 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -1.08889 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 32: loss -1.10793 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -1.12203 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 33: loss -1.14098 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -1.15517 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 34: loss -1.17403 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -1.18831 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 35: loss -1.20708 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -1.22145 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 36: loss -1.24012 acc 0.34211 roc_auc 0.48000 prc_auc 0.64902[0m
[92maverage training of epoch 37: loss -1.25457 acc 0.33333 roc_auc 0.35420 prc_auc 0.56112[0m
[93maverage test of epoch 37: loss -1.27317 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -1.28774 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 38: loss -1.30622 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -1.32088 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 39: loss -1.33927 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -1.35402 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 40: loss -1.37232 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -1.38717 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 41: loss -1.40536 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -1.42031 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 42: loss -1.43841 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -1.45345 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 43: loss -1.47146 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -1.48659 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 44: loss -1.50451 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -1.51973 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 45: loss -1.53755 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -1.55288 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 46: loss -1.57060 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -1.58602 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 47: loss -1.60365 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -1.61916 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 48: loss -1.63670 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -1.65230 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 49: loss -1.66973 acc 0.34211 roc_auc 0.52000 prc_auc 0.67158[0m
[92maverage training of epoch 50: loss -1.68543 acc 0.33333 roc_auc 0.36360 prc_auc 0.57407[0m
[93maverage test of epoch 50: loss -1.70279 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 51: loss -1.71859 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 51: loss -1.73584 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 52: loss -1.75173 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 52: loss -1.76888 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 53: loss -1.78487 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 53: loss -1.80193 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 54: loss -1.81801 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 54: loss -1.83498 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 55: loss -1.85115 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 55: loss -1.86803 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 56: loss -1.88429 acc 0.62000 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 56: loss -1.90107 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 57: loss -1.91743 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 57: loss -1.93412 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 58: loss -1.95058 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 58: loss -1.96717 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 59: loss -1.98372 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 59: loss -2.00021 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 60: loss -2.01686 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 60: loss -2.03326 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 61: loss -2.05000 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 61: loss -2.06631 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 62: loss -2.08312 acc 0.66667 roc_auc 0.35220 prc_auc 0.56011[0m
[93maverage test of epoch 62: loss -2.09936 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 63: loss -2.11629 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 63: loss -2.13240 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 64: loss -2.14943 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 64: loss -2.16545 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 65: loss -2.18257 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 65: loss -2.19850 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 66: loss -2.21571 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 66: loss -2.23154 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 67: loss -2.24885 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 67: loss -2.26459 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 68: loss -2.28199 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 68: loss -2.29764 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 69: loss -2.31514 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 69: loss -2.33069 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 70: loss -2.34827 acc 0.66667 roc_auc 0.35840 prc_auc 0.57063[0m
[93maverage test of epoch 70: loss -2.36373 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 71: loss -2.38142 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 71: loss -2.39678 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 72: loss -2.41456 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 72: loss -2.42983 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 73: loss -2.44770 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 73: loss -2.46287 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 74: loss -2.48084 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 74: loss -2.49592 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 75: loss -2.51398 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 75: loss -2.52897 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 76: loss -2.54713 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 76: loss -2.56201 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 77: loss -2.64557 acc 0.66667 roc_auc 0.41400 prc_auc 0.62199[0m
[93maverage test of epoch 77: loss -2.79882 acc 0.65789 roc_auc 0.67385 prc_auc 0.84689[0m
[92maverage training of epoch 78: loss -3.00170 acc 0.66667 roc_auc 0.39920 prc_auc 0.61279[0m
[93maverage test of epoch 78: loss -3.20130 acc 0.65789 roc_auc 0.56308 prc_auc 0.68513[0m
[92maverage training of epoch 79: loss -3.39627 acc 0.66667 roc_auc 0.40710 prc_auc 0.61199[0m
[93maverage test of epoch 79: loss -3.58935 acc 0.65789 roc_auc 0.62154 prc_auc 0.78377[0m
[92maverage training of epoch 80: loss -3.78471 acc 0.66667 roc_auc 0.39600 prc_auc 0.60295[0m
[93maverage test of epoch 80: loss -3.97711 acc 0.65789 roc_auc 0.45231 prc_auc 0.63468[0m
[92maverage training of epoch 81: loss -4.17674 acc 0.66667 roc_auc 0.38760 prc_auc 0.60307[0m
[93maverage test of epoch 81: loss -4.36990 acc 0.65789 roc_auc 0.51385 prc_auc 0.70183[0m
[92maverage training of epoch 82: loss -4.57671 acc 0.66667 roc_auc 0.40040 prc_auc 0.61297[0m
[93maverage test of epoch 82: loss -4.77446 acc 0.65789 roc_auc 0.51538 prc_auc 0.74914[0m
[92maverage training of epoch 83: loss -4.98520 acc 0.66667 roc_auc 0.39720 prc_auc 0.60660[0m
[93maverage test of epoch 83: loss -5.18553 acc 0.65789 roc_auc 0.65846 prc_auc 0.72346[0m
[92maverage training of epoch 84: loss -5.40545 acc 0.66667 roc_auc 0.40600 prc_auc 0.61026[0m
[93maverage test of epoch 84: loss -5.61246 acc 0.65789 roc_auc 0.60769 prc_auc 0.74199[0m
[92maverage training of epoch 85: loss -5.83782 acc 0.66667 roc_auc 0.39420 prc_auc 0.60047[0m
[93maverage test of epoch 85: loss -6.04827 acc 0.65789 roc_auc 0.43077 prc_auc 0.62899[0m
[92maverage training of epoch 86: loss -6.28242 acc 0.66667 roc_auc 0.38800 prc_auc 0.59589[0m
[93maverage test of epoch 86: loss -6.49830 acc 0.65789 roc_auc 0.64308 prc_auc 0.76277[0m
[92maverage training of epoch 87: loss -6.74051 acc 0.66667 roc_auc 0.39080 prc_auc 0.59726[0m
[93maverage test of epoch 87: loss -6.96131 acc 0.65789 roc_auc 0.41538 prc_auc 0.63565[0m
[92maverage training of epoch 88: loss -7.21109 acc 0.66667 roc_auc 0.39400 prc_auc 0.60043[0m
[93maverage test of epoch 88: loss -7.43637 acc 0.65789 roc_auc 0.41385 prc_auc 0.62054[0m
[92maverage training of epoch 89: loss -7.69654 acc 0.66667 roc_auc 0.40200 prc_auc 0.60644[0m
[93maverage test of epoch 89: loss -7.92949 acc 0.65789 roc_auc 0.38154 prc_auc 0.61810[0m
[92maverage training of epoch 90: loss -8.19449 acc 0.66667 roc_auc 0.40040 prc_auc 0.60626[0m
[93maverage test of epoch 90: loss -8.43410 acc 0.65789 roc_auc 0.48308 prc_auc 0.68232[0m
[92maverage training of epoch 91: loss -8.70799 acc 0.66667 roc_auc 0.38780 prc_auc 0.59625[0m
[93maverage test of epoch 91: loss -8.95304 acc 0.65789 roc_auc 0.42000 prc_auc 0.63115[0m
[92maverage training of epoch 92: loss -9.23560 acc 0.66667 roc_auc 0.39740 prc_auc 0.60215[0m
[93maverage test of epoch 92: loss -9.48619 acc 0.65789 roc_auc 0.52769 prc_auc 0.67746[0m
[92maverage training of epoch 93: loss -9.77722 acc 0.66667 roc_auc 0.39440 prc_auc 0.60081[0m
[93maverage test of epoch 93: loss -10.03256 acc 0.65789 roc_auc 0.39077 prc_auc 0.62804[0m
[92maverage training of epoch 94: loss -10.32906 acc 0.66667 roc_auc 0.39850 prc_auc 0.60340[0m
[93maverage test of epoch 94: loss -10.58657 acc 0.65789 roc_auc 0.42769 prc_auc 0.60830[0m
[92maverage training of epoch 95: loss -10.89085 acc 0.66667 roc_auc 0.39590 prc_auc 0.60557[0m
[93maverage test of epoch 95: loss -11.15235 acc 0.65789 roc_auc 0.38615 prc_auc 0.62485[0m
[92maverage training of epoch 96: loss -11.46305 acc 0.66667 roc_auc 0.38860 prc_auc 0.59500[0m
[93maverage test of epoch 96: loss -11.72851 acc 0.65789 roc_auc 0.33538 prc_auc 0.57883[0m
[92maverage training of epoch 97: loss -12.04651 acc 0.66667 roc_auc 0.39340 prc_auc 0.59949[0m
[93maverage test of epoch 97: loss -12.31673 acc 0.65789 roc_auc 0.67692 prc_auc 0.77586[0m
[92maverage training of epoch 98: loss -12.64272 acc 0.66667 roc_auc 0.39220 prc_auc 0.59893[0m
[93maverage test of epoch 98: loss -12.91687 acc 0.65789 roc_auc 0.38308 prc_auc 0.59725[0m
[92maverage training of epoch 99: loss -13.25114 acc 0.66667 roc_auc 0.39020 prc_auc 0.59779[0m
[93maverage test of epoch 99: loss -13.53117 acc 0.65789 roc_auc 0.36308 prc_auc 0.58521[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.66775 acc 0.33333 roc_auc 0.48920 prc_auc 0.66425[0m
[93maverage test of epoch 0: loss -1.01678 acc 0.34211 roc_auc 0.58462 prc_auc 0.71677[0m
[92maverage training of epoch 1: loss -1.36235 acc 0.33333 roc_auc 0.45660 prc_auc 0.63977[0m
[93maverage test of epoch 1: loss -1.73637 acc 0.34211 roc_auc 0.32308 prc_auc 0.56821[0m
[92maverage training of epoch 2: loss -2.07971 acc 0.33333 roc_auc 0.51740 prc_auc 0.67612[0m
[93maverage test of epoch 2: loss -2.45152 acc 0.34211 roc_auc 0.40615 prc_auc 0.59132[0m
[92maverage training of epoch 3: loss -2.80145 acc 0.33333 roc_auc 0.54780 prc_auc 0.68516[0m
[93maverage test of epoch 3: loss -3.20330 acc 0.34211 roc_auc 0.59692 prc_auc 0.73467[0m
[92maverage training of epoch 4: loss -3.54181 acc 0.33333 roc_auc 0.55120 prc_auc 0.71849[0m
[93maverage test of epoch 4: loss -3.95008 acc 0.34211 roc_auc 0.46462 prc_auc 0.71324[0m
[92maverage training of epoch 5: loss -4.31821 acc 0.33333 roc_auc 0.51180 prc_auc 0.67467[0m
[93maverage test of epoch 5: loss -4.71289 acc 0.34211 roc_auc 0.52615 prc_auc 0.70515[0m
[92maverage training of epoch 6: loss -5.08624 acc 0.33333 roc_auc 0.53160 prc_auc 0.68962[0m
[93maverage test of epoch 6: loss -5.51252 acc 0.34211 roc_auc 0.53231 prc_auc 0.72739[0m
[92maverage training of epoch 7: loss -5.87302 acc 0.33333 roc_auc 0.53640 prc_auc 0.67947[0m
[93maverage test of epoch 7: loss -6.28372 acc 0.34211 roc_auc 0.43692 prc_auc 0.62487[0m
[92maverage training of epoch 8: loss -6.67061 acc 0.33333 roc_auc 0.53500 prc_auc 0.67989[0m
[93maverage test of epoch 8: loss -7.10186 acc 0.34211 roc_auc 0.34154 prc_auc 0.61980[0m
[92maverage training of epoch 9: loss -7.48126 acc 0.33333 roc_auc 0.51300 prc_auc 0.68096[0m
[93maverage test of epoch 9: loss -7.93832 acc 0.34211 roc_auc 0.43385 prc_auc 0.63058[0m
[92maverage training of epoch 10: loss -8.33735 acc 0.33333 roc_auc 0.48740 prc_auc 0.65637[0m
[93maverage test of epoch 10: loss -8.78936 acc 0.34211 roc_auc 0.42154 prc_auc 0.65188[0m
[92maverage training of epoch 11: loss -9.20565 acc 0.33333 roc_auc 0.51180 prc_auc 0.67826[0m
[93maverage test of epoch 11: loss -9.70005 acc 0.34211 roc_auc 0.35385 prc_auc 0.61769[0m
[92maverage training of epoch 12: loss -10.10698 acc 0.33333 roc_auc 0.49740 prc_auc 0.69677[0m
[93maverage test of epoch 12: loss -10.61021 acc 0.34211 roc_auc 0.63385 prc_auc 0.78313[0m
[92maverage training of epoch 13: loss -11.03162 acc 0.33333 roc_auc 0.50280 prc_auc 0.65576[0m
[93maverage test of epoch 13: loss -11.55163 acc 0.34211 roc_auc 0.29538 prc_auc 0.55137[0m
[92maverage training of epoch 14: loss -11.99440 acc 0.33333 roc_auc 0.50740 prc_auc 0.67403[0m
[93maverage test of epoch 14: loss -12.52884 acc 0.34211 roc_auc 0.76923 prc_auc 0.88146[0m
[92maverage training of epoch 15: loss -12.97684 acc 0.33333 roc_auc 0.55460 prc_auc 0.69299[0m
[93maverage test of epoch 15: loss -13.52356 acc 0.34211 roc_auc 0.49846 prc_auc 0.72691[0m
[92maverage training of epoch 16: loss -13.99304 acc 0.33333 roc_auc 0.50460 prc_auc 0.66987[0m
[93maverage test of epoch 16: loss -14.54780 acc 0.34211 roc_auc 0.49538 prc_auc 0.66353[0m
[92maverage training of epoch 17: loss -15.02731 acc 0.33333 roc_auc 0.45140 prc_auc 0.63062[0m
[93maverage test of epoch 17: loss -15.60875 acc 0.34211 roc_auc 0.35385 prc_auc 0.58719[0m
[92maverage training of epoch 18: loss -16.09220 acc 0.33333 roc_auc 0.47100 prc_auc 0.63720[0m
[93maverage test of epoch 18: loss -16.67646 acc 0.34211 roc_auc 0.28923 prc_auc 0.60411[0m
[92maverage training of epoch 19: loss -17.17642 acc 0.33333 roc_auc 0.47640 prc_auc 0.66944[0m
[93maverage test of epoch 19: loss -17.76580 acc 0.34211 roc_auc 0.48308 prc_auc 0.69484[0m
[92maverage training of epoch 20: loss -18.28043 acc 0.33333 roc_auc 0.42880 prc_auc 0.62016[0m
[93maverage test of epoch 20: loss -18.90742 acc 0.34211 roc_auc 0.55077 prc_auc 0.72760[0m
[92maverage training of epoch 21: loss -19.41733 acc 0.33333 roc_auc 0.43160 prc_auc 0.61019[0m
[93maverage test of epoch 21: loss -20.04695 acc 0.34211 roc_auc 0.50769 prc_auc 0.66620[0m
[92maverage training of epoch 22: loss -20.58213 acc 0.33333 roc_auc 0.40640 prc_auc 0.61454[0m
[93maverage test of epoch 22: loss -21.21668 acc 0.34211 roc_auc 0.30462 prc_auc 0.57926[0m
[92maverage training of epoch 23: loss -21.76263 acc 0.33333 roc_auc 0.38740 prc_auc 0.59089[0m
[93maverage test of epoch 23: loss -22.42122 acc 0.34211 roc_auc 0.40154 prc_auc 0.61663[0m
[92maverage training of epoch 24: loss -22.97591 acc 0.33333 roc_auc 0.38940 prc_auc 0.62184[0m
[93maverage test of epoch 24: loss -23.64371 acc 0.34211 roc_auc 0.53385 prc_auc 0.76552[0m
[92maverage training of epoch 25: loss -24.21314 acc 0.33333 roc_auc 0.40120 prc_auc 0.65933[0m
[93maverage test of epoch 25: loss -24.90400 acc 0.34211 roc_auc 0.50462 prc_auc 0.70885[0m
[92maverage training of epoch 26: loss -25.48207 acc 0.33333 roc_auc 0.39760 prc_auc 0.63200[0m
[93maverage test of epoch 26: loss -26.18026 acc 0.34211 roc_auc 0.44308 prc_auc 0.64033[0m
[92maverage training of epoch 27: loss -26.77155 acc 0.33333 roc_auc 0.41180 prc_auc 0.62242[0m
[93maverage test of epoch 27: loss -27.47628 acc 0.34211 roc_auc 0.43077 prc_auc 0.66455[0m
[92maverage training of epoch 28: loss -28.10039 acc 0.33333 roc_auc 0.41680 prc_auc 0.61404[0m
[93maverage test of epoch 28: loss -28.82483 acc 0.34211 roc_auc 0.44462 prc_auc 0.61542[0m
[92maverage training of epoch 29: loss -29.44372 acc 0.33333 roc_auc 0.41080 prc_auc 0.61146[0m
[93maverage test of epoch 29: loss -30.19267 acc 0.34211 roc_auc 0.45846 prc_auc 0.67615[0m
[92maverage training of epoch 30: loss -30.82538 acc 0.33333 roc_auc 0.40980 prc_auc 0.59668[0m
[93maverage test of epoch 30: loss -31.58310 acc 0.34211 roc_auc 0.54615 prc_auc 0.67333[0m
[92maverage training of epoch 31: loss -32.23259 acc 0.33333 roc_auc 0.41300 prc_auc 0.61885[0m
[93maverage test of epoch 31: loss -33.00551 acc 0.34211 roc_auc 0.40154 prc_auc 0.61162[0m
[92maverage training of epoch 32: loss -33.67284 acc 0.33333 roc_auc 0.40560 prc_auc 0.60065[0m
[93maverage test of epoch 32: loss -34.45556 acc 0.34211 roc_auc 0.43692 prc_auc 0.63981[0m
[92maverage training of epoch 33: loss -35.13650 acc 0.33333 roc_auc 0.41180 prc_auc 0.60124[0m
[93maverage test of epoch 33: loss -35.93568 acc 0.34211 roc_auc 0.31538 prc_auc 0.55901[0m
[92maverage training of epoch 34: loss -36.63394 acc 0.33333 roc_auc 0.40920 prc_auc 0.60398[0m
[93maverage test of epoch 34: loss -37.44575 acc 0.34211 roc_auc 0.32769 prc_auc 0.59403[0m
[92maverage training of epoch 35: loss -38.15213 acc 0.33333 roc_auc 0.40900 prc_auc 0.61221[0m
[93maverage test of epoch 35: loss -38.98008 acc 0.34211 roc_auc 0.56615 prc_auc 0.73088[0m
[92maverage training of epoch 36: loss -39.78699 acc 0.33333 roc_auc 0.41720 prc_auc 0.59548[0m
[93maverage test of epoch 36: loss -40.75780 acc 0.34211 roc_auc 0.57846 prc_auc 0.71265[0m
[92maverage training of epoch 37: loss -41.65198 acc 0.33333 roc_auc 0.41500 prc_auc 0.59698[0m
[93maverage test of epoch 37: loss -42.65923 acc 0.34211 roc_auc 0.37077 prc_auc 0.60577[0m
[92maverage training of epoch 38: loss -43.58170 acc 0.33333 roc_auc 0.41780 prc_auc 0.59499[0m
[93maverage test of epoch 38: loss -44.60763 acc 0.34211 roc_auc 0.43077 prc_auc 0.64374[0m
[92maverage training of epoch 39: loss -45.54328 acc 0.33333 roc_auc 0.41820 prc_auc 0.59804[0m
[93maverage test of epoch 39: loss -46.58717 acc 0.34211 roc_auc 0.29231 prc_auc 0.62753[0m
[92maverage training of epoch 40: loss -47.54553 acc 0.33333 roc_auc 0.41870 prc_auc 0.59685[0m
[93maverage test of epoch 40: loss -48.60311 acc 0.34211 roc_auc 0.42000 prc_auc 0.63236[0m
[92maverage training of epoch 41: loss -49.58435 acc 0.33333 roc_auc 0.41580 prc_auc 0.59403[0m
[93maverage test of epoch 41: loss -50.66305 acc 0.34211 roc_auc 0.60769 prc_auc 0.72779[0m
[92maverage training of epoch 42: loss -51.66763 acc 0.33333 roc_auc 0.41700 prc_auc 0.59577[0m
[93maverage test of epoch 42: loss -52.76339 acc 0.34211 roc_auc 0.38923 prc_auc 0.62279[0m
[92maverage training of epoch 43: loss -53.79007 acc 0.33333 roc_auc 0.41820 prc_auc 0.59631[0m
[93maverage test of epoch 43: loss -54.90531 acc 0.34211 roc_auc 0.58308 prc_auc 0.73950[0m
[92maverage training of epoch 44: loss -55.95828 acc 0.33333 roc_auc 0.41760 prc_auc 0.59750[0m
[93maverage test of epoch 44: loss -57.09474 acc 0.34211 roc_auc 0.28154 prc_auc 0.55303[0m
[92maverage training of epoch 45: loss -58.16997 acc 0.33333 roc_auc 0.41800 prc_auc 0.60336[0m
[93maverage test of epoch 45: loss -59.32164 acc 0.34211 roc_auc 0.70000 prc_auc 0.84949[0m
[92maverage training of epoch 46: loss -60.42043 acc 0.33333 roc_auc 0.42080 prc_auc 0.60439[0m
[93maverage test of epoch 46: loss -61.59418 acc 0.34211 roc_auc 0.60615 prc_auc 0.77490[0m
[92maverage training of epoch 47: loss -62.71840 acc 0.33333 roc_auc 0.42020 prc_auc 0.60553[0m
[93maverage test of epoch 47: loss -63.90919 acc 0.34211 roc_auc 0.48308 prc_auc 0.66652[0m
[92maverage training of epoch 48: loss -65.05778 acc 0.33333 roc_auc 0.42080 prc_auc 0.60478[0m
[93maverage test of epoch 48: loss -66.27165 acc 0.34211 roc_auc 0.56615 prc_auc 0.70952[0m
[92maverage training of epoch 49: loss -67.44403 acc 0.33333 roc_auc 0.42370 prc_auc 0.60911[0m
[93maverage test of epoch 49: loss -68.67441 acc 0.34211 roc_auc 0.56769 prc_auc 0.72377[0m
[92maverage training of epoch 50: loss -69.87230 acc 0.33333 roc_auc 0.42400 prc_auc 0.60951[0m
[93maverage test of epoch 50: loss -71.12360 acc 0.34211 roc_auc 0.38615 prc_auc 0.59029[0m
[92maverage training of epoch 51: loss -72.34481 acc 0.33333 roc_auc 0.42520 prc_auc 0.60976[0m
[93maverage test of epoch 51: loss -73.60942 acc 0.34211 roc_auc 0.41692 prc_auc 0.64010[0m
[92maverage training of epoch 52: loss -74.85563 acc 0.33333 roc_auc 0.42580 prc_auc 0.61045[0m
[93maverage test of epoch 52: loss -76.13831 acc 0.34211 roc_auc 0.47385 prc_auc 0.67386[0m
[92maverage training of epoch 53: loss -77.40823 acc 0.61333 roc_auc 0.42640 prc_auc 0.61051[0m
[93maverage test of epoch 53: loss -78.70731 acc 0.65789 roc_auc 0.34462 prc_auc 0.58040[0m
[92maverage training of epoch 54: loss -79.99921 acc 0.66667 roc_auc 0.42700 prc_auc 0.61088[0m
[93maverage test of epoch 54: loss -81.31640 acc 0.65789 roc_auc 0.46308 prc_auc 0.64389[0m
[92maverage training of epoch 55: loss -82.63270 acc 0.66667 roc_auc 0.42780 prc_auc 0.61166[0m
[93maverage test of epoch 55: loss -83.96603 acc 0.65789 roc_auc 0.25846 prc_auc 0.55376[0m
[92maverage training of epoch 56: loss -85.30710 acc 0.66667 roc_auc 0.42860 prc_auc 0.61130[0m
[93maverage test of epoch 56: loss -86.65850 acc 0.65789 roc_auc 0.47846 prc_auc 0.65215[0m
[92maverage training of epoch 57: loss -88.02620 acc 0.66667 roc_auc 0.43040 prc_auc 0.61362[0m
[93maverage test of epoch 57: loss -89.39217 acc 0.65789 roc_auc 0.64615 prc_auc 0.72771[0m
[92maverage training of epoch 58: loss -90.78708 acc 0.66667 roc_auc 0.43020 prc_auc 0.61334[0m
[93maverage test of epoch 58: loss -92.17077 acc 0.65789 roc_auc 0.37538 prc_auc 0.59192[0m
[92maverage training of epoch 59: loss -93.59118 acc 0.66667 roc_auc 0.43140 prc_auc 0.61504[0m
[93maverage test of epoch 59: loss -94.99182 acc 0.65789 roc_auc 0.57385 prc_auc 0.69017[0m
[92maverage training of epoch 60: loss -96.43952 acc 0.66667 roc_auc 0.43230 prc_auc 0.61482[0m
[93maverage test of epoch 60: loss -97.85915 acc 0.65789 roc_auc 0.61846 prc_auc 0.73155[0m
[92maverage training of epoch 61: loss -99.33077 acc 0.66667 roc_auc 0.43220 prc_auc 0.61588[0m
[93maverage test of epoch 61: loss -100.76953 acc 0.65789 roc_auc 0.42923 prc_auc 0.62999[0m
[92maverage training of epoch 62: loss -102.26834 acc 0.66667 roc_auc 0.43220 prc_auc 0.61585[0m
[93maverage test of epoch 62: loss -103.72195 acc 0.65789 roc_auc 0.59077 prc_auc 0.71631[0m
[92maverage training of epoch 63: loss -105.24914 acc 0.66667 roc_auc 0.43220 prc_auc 0.61570[0m
[93maverage test of epoch 63: loss -106.72090 acc 0.65789 roc_auc 0.59538 prc_auc 0.73573[0m
[92maverage training of epoch 64: loss -108.27350 acc 0.66667 roc_auc 0.43200 prc_auc 0.61539[0m
[93maverage test of epoch 64: loss -109.76374 acc 0.65789 roc_auc 0.60308 prc_auc 0.71465[0m
[92maverage training of epoch 65: loss -111.34062 acc 0.66667 roc_auc 0.43270 prc_auc 0.61629[0m
[93maverage test of epoch 65: loss -112.84681 acc 0.65789 roc_auc 0.48923 prc_auc 0.65183[0m
[92maverage training of epoch 66: loss -114.45114 acc 0.66667 roc_auc 0.43350 prc_auc 0.61691[0m
[93maverage test of epoch 66: loss -115.97411 acc 0.65789 roc_auc 0.51077 prc_auc 0.66487[0m
[92maverage training of epoch 67: loss -117.60547 acc 0.66667 roc_auc 0.43340 prc_auc 0.61689[0m
[93maverage test of epoch 67: loss -119.14373 acc 0.65789 roc_auc 0.49692 prc_auc 0.65683[0m
[92maverage training of epoch 68: loss -120.80081 acc 0.66667 roc_auc 0.43390 prc_auc 0.61730[0m
[93maverage test of epoch 68: loss -122.35571 acc 0.65789 roc_auc 0.53692 prc_auc 0.67498[0m
[92maverage training of epoch 69: loss -124.03959 acc 0.66667 roc_auc 0.43500 prc_auc 0.61642[0m
[93maverage test of epoch 69: loss -125.61064 acc 0.65789 roc_auc 0.53846 prc_auc 0.67568[0m
[92maverage training of epoch 70: loss -127.32222 acc 0.66667 roc_auc 0.43570 prc_auc 0.61673[0m
[93maverage test of epoch 70: loss -128.90949 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 71: loss -130.64818 acc 0.66667 roc_auc 0.43450 prc_auc 0.61818[0m
[93maverage test of epoch 71: loss -132.25127 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 72: loss -134.01745 acc 0.66667 roc_auc 0.43850 prc_auc 0.61724[0m
[93maverage test of epoch 72: loss -135.63656 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 73: loss -137.43103 acc 0.66667 roc_auc 0.43860 prc_auc 0.62038[0m
[93maverage test of epoch 73: loss -139.06539 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 74: loss -140.88804 acc 0.66667 roc_auc 0.44320 prc_auc 0.62249[0m
[93maverage test of epoch 74: loss -142.53915 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 75: loss -144.38951 acc 0.66667 roc_auc 0.43680 prc_auc 0.61897[0m
[93maverage test of epoch 75: loss -146.05631 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 76: loss -147.93412 acc 0.66667 roc_auc 0.44470 prc_auc 0.63095[0m
[93maverage test of epoch 76: loss -149.61652 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 77: loss -151.52427 acc 0.66667 roc_auc 0.47110 prc_auc 0.65047[0m
[93maverage test of epoch 77: loss -153.22183 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 78: loss -155.15778 acc 0.66667 roc_auc 0.46820 prc_auc 0.65165[0m
[93maverage test of epoch 78: loss -156.87115 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 79: loss -158.83567 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 79: loss -160.56512 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 80: loss -162.55841 acc 0.66667 roc_auc 0.51000 prc_auc 0.67115[0m
[93maverage test of epoch 80: loss -164.30274 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 81: loss -166.32511 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 81: loss -168.08470 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 82: loss -170.13645 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 82: loss -171.90950 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 83: loss -173.99241 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 83: loss -175.78155 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 84: loss -177.89239 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 84: loss -179.69665 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 85: loss -181.83717 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 85: loss -183.65517 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 86: loss -185.82587 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 86: loss -187.66030 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 87: loss -189.86019 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 87: loss -191.70850 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 88: loss -193.93892 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 88: loss -195.80171 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 89: loss -198.06198 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 89: loss -199.93898 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -202.22947 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 90: loss -204.12078 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 91: loss -206.44206 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 91: loss -208.34769 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 92: loss -210.69873 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 92: loss -212.61844 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 93: loss -215.00073 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 93: loss -216.93364 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 94: loss -219.34718 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 94: loss -221.29388 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 95: loss -223.73816 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 95: loss -225.69859 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 96: loss -228.17363 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 96: loss -230.14767 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 97: loss -232.65382 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 97: loss -234.64145 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 98: loss -237.17937 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 98: loss -239.17974 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -241.74924 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 99: loss -243.76273 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -1.14996 acc 0.33333 roc_auc 0.53880 prc_auc 0.71448[0m
[93maverage test of epoch 0: loss -1.55358 acc 0.34211 roc_auc 0.63385 prc_auc 0.74379[0m
[92maverage training of epoch 1: loss -1.84157 acc 0.33333 roc_auc 0.56420 prc_auc 0.70034[0m
[93maverage test of epoch 1: loss -2.14332 acc 0.34211 roc_auc 0.23385 prc_auc 0.54076[0m
[92maverage training of epoch 2: loss -2.42012 acc 0.33333 roc_auc 0.49160 prc_auc 0.64137[0m
[93maverage test of epoch 2: loss -2.72091 acc 0.34211 roc_auc 0.46154 prc_auc 0.66058[0m
[92maverage training of epoch 3: loss -2.97338 acc 0.33333 roc_auc 0.52820 prc_auc 0.66545[0m
[93maverage test of epoch 3: loss -3.30539 acc 0.34211 roc_auc 0.46462 prc_auc 0.67115[0m
[92maverage training of epoch 4: loss -3.57115 acc 0.33333 roc_auc 0.53940 prc_auc 0.71383[0m
[93maverage test of epoch 4: loss -3.91086 acc 0.34211 roc_auc 0.61538 prc_auc 0.72448[0m
[92maverage training of epoch 5: loss -4.20270 acc 0.33333 roc_auc 0.50140 prc_auc 0.64287[0m
[93maverage test of epoch 5: loss -4.53932 acc 0.34211 roc_auc 0.49846 prc_auc 0.67440[0m
[92maverage training of epoch 6: loss -4.88185 acc 0.33333 roc_auc 0.53240 prc_auc 0.70101[0m
[93maverage test of epoch 6: loss -5.33515 acc 0.34211 roc_auc 0.62769 prc_auc 0.82889[0m
[92maverage training of epoch 7: loss -5.74405 acc 0.33333 roc_auc 0.53640 prc_auc 0.68198[0m
[93maverage test of epoch 7: loss -6.25972 acc 0.34211 roc_auc 0.84923 prc_auc 0.91101[0m
[92maverage training of epoch 8: loss -6.67794 acc 0.33333 roc_auc 0.53140 prc_auc 0.67366[0m
[93maverage test of epoch 8: loss -7.19855 acc 0.34211 roc_auc 0.48000 prc_auc 0.66915[0m
[92maverage training of epoch 9: loss -7.63682 acc 0.33333 roc_auc 0.53000 prc_auc 0.66069[0m
[93maverage test of epoch 9: loss -8.17337 acc 0.34211 roc_auc 0.51692 prc_auc 0.73905[0m
[92maverage training of epoch 10: loss -8.63067 acc 0.33333 roc_auc 0.50260 prc_auc 0.67148[0m
[93maverage test of epoch 10: loss -9.16919 acc 0.34211 roc_auc 0.59385 prc_auc 0.73983[0m
[92maverage training of epoch 11: loss -9.64520 acc 0.33333 roc_auc 0.56740 prc_auc 0.72210[0m
[93maverage test of epoch 11: loss -10.23450 acc 0.34211 roc_auc 0.49846 prc_auc 0.68214[0m
[92maverage training of epoch 12: loss -10.70076 acc 0.33333 roc_auc 0.52760 prc_auc 0.68890[0m
[93maverage test of epoch 12: loss -11.29348 acc 0.34211 roc_auc 0.33538 prc_auc 0.57724[0m
[92maverage training of epoch 13: loss -11.78897 acc 0.33333 roc_auc 0.50000 prc_auc 0.65719[0m
[93maverage test of epoch 13: loss -12.37683 acc 0.34211 roc_auc 0.52308 prc_auc 0.70234[0m
[92maverage training of epoch 14: loss -12.91702 acc 0.33333 roc_auc 0.52780 prc_auc 0.66022[0m
[93maverage test of epoch 14: loss -13.53605 acc 0.34211 roc_auc 0.55077 prc_auc 0.75014[0m
[92maverage training of epoch 15: loss -14.06617 acc 0.33333 roc_auc 0.49360 prc_auc 0.66345[0m
[93maverage test of epoch 15: loss -14.72889 acc 0.34211 roc_auc 0.64000 prc_auc 0.74565[0m
[92maverage training of epoch 16: loss -15.27364 acc 0.33333 roc_auc 0.53160 prc_auc 0.68100[0m
[93maverage test of epoch 16: loss -15.96146 acc 0.34211 roc_auc 0.58769 prc_auc 0.74178[0m
[92maverage training of epoch 17: loss -16.52508 acc 0.33333 roc_auc 0.48580 prc_auc 0.65888[0m
[93maverage test of epoch 17: loss -17.22809 acc 0.34211 roc_auc 0.40000 prc_auc 0.59820[0m
[92maverage training of epoch 18: loss -17.81697 acc 0.33333 roc_auc 0.49500 prc_auc 0.67142[0m
[93maverage test of epoch 18: loss -18.56166 acc 0.34211 roc_auc 0.45385 prc_auc 0.72963[0m
[92maverage training of epoch 19: loss -19.15207 acc 0.33333 roc_auc 0.47360 prc_auc 0.64212[0m
[93maverage test of epoch 19: loss -19.91707 acc 0.34211 roc_auc 0.46769 prc_auc 0.66353[0m
[92maverage training of epoch 20: loss -20.53917 acc 0.33333 roc_auc 0.53340 prc_auc 0.67984[0m
[93maverage test of epoch 20: loss -21.33101 acc 0.34211 roc_auc 0.32923 prc_auc 0.64787[0m
[92maverage training of epoch 21: loss -21.97995 acc 0.33333 roc_auc 0.53480 prc_auc 0.71273[0m
[93maverage test of epoch 21: loss -22.77991 acc 0.34211 roc_auc 0.34154 prc_auc 0.60909[0m
[92maverage training of epoch 22: loss -23.45828 acc 0.33333 roc_auc 0.44980 prc_auc 0.61508[0m
[93maverage test of epoch 22: loss -24.28157 acc 0.34211 roc_auc 0.45231 prc_auc 0.65215[0m
[92maverage training of epoch 23: loss -24.99088 acc 0.33333 roc_auc 0.47500 prc_auc 0.63932[0m
[93maverage test of epoch 23: loss -25.84432 acc 0.34211 roc_auc 0.47231 prc_auc 0.68883[0m
[92maverage training of epoch 24: loss -26.57485 acc 0.33333 roc_auc 0.45520 prc_auc 0.62229[0m
[93maverage test of epoch 24: loss -27.45444 acc 0.34211 roc_auc 0.62000 prc_auc 0.79443[0m
[92maverage training of epoch 25: loss -28.20543 acc 0.33333 roc_auc 0.45320 prc_auc 0.61459[0m
[93maverage test of epoch 25: loss -29.11292 acc 0.34211 roc_auc 0.58462 prc_auc 0.74764[0m
[92maverage training of epoch 26: loss -29.86935 acc 0.33333 roc_auc 0.46780 prc_auc 0.66059[0m
[93maverage test of epoch 26: loss -30.79372 acc 0.34211 roc_auc 0.36769 prc_auc 0.63329[0m
[92maverage training of epoch 27: loss -31.58176 acc 0.33333 roc_auc 0.47080 prc_auc 0.66396[0m
[93maverage test of epoch 27: loss -32.53388 acc 0.34211 roc_auc 0.48923 prc_auc 0.64640[0m
[92maverage training of epoch 28: loss -33.34062 acc 0.33333 roc_auc 0.44510 prc_auc 0.64493[0m
[93maverage test of epoch 28: loss -34.31477 acc 0.34211 roc_auc 0.54462 prc_auc 0.65362[0m
[92maverage training of epoch 29: loss -35.14483 acc 0.33333 roc_auc 0.44320 prc_auc 0.62698[0m
[93maverage test of epoch 29: loss -36.13936 acc 0.34211 roc_auc 0.43538 prc_auc 0.67547[0m
[92maverage training of epoch 30: loss -36.99081 acc 0.33333 roc_auc 0.44000 prc_auc 0.62954[0m
[93maverage test of epoch 30: loss -38.00659 acc 0.34211 roc_auc 0.47846 prc_auc 0.62678[0m
[92maverage training of epoch 31: loss -38.88069 acc 0.33333 roc_auc 0.42240 prc_auc 0.62775[0m
[93maverage test of epoch 31: loss -39.93310 acc 0.34211 roc_auc 0.48615 prc_auc 0.69220[0m
[92maverage training of epoch 32: loss -40.81589 acc 0.33333 roc_auc 0.42940 prc_auc 0.64495[0m
[93maverage test of epoch 32: loss -41.88942 acc 0.34211 roc_auc 0.45846 prc_auc 0.68098[0m
[92maverage training of epoch 33: loss -42.80303 acc 0.33333 roc_auc 0.40820 prc_auc 0.61577[0m
[93maverage test of epoch 33: loss -43.89491 acc 0.34211 roc_auc 0.43077 prc_auc 0.60552[0m
[92maverage training of epoch 34: loss -44.83023 acc 0.33333 roc_auc 0.39320 prc_auc 0.60109[0m
[93maverage test of epoch 34: loss -45.94855 acc 0.34211 roc_auc 0.44462 prc_auc 0.65908[0m
[92maverage training of epoch 35: loss -46.89989 acc 0.33333 roc_auc 0.39000 prc_auc 0.59907[0m
[93maverage test of epoch 35: loss -48.03934 acc 0.34211 roc_auc 0.30000 prc_auc 0.61299[0m
[92maverage training of epoch 36: loss -49.01506 acc 0.33333 roc_auc 0.40160 prc_auc 0.60666[0m
[93maverage test of epoch 36: loss -50.16877 acc 0.34211 roc_auc 0.40615 prc_auc 0.66392[0m
[92maverage training of epoch 37: loss -51.16939 acc 0.33333 roc_auc 0.39340 prc_auc 0.60645[0m
[93maverage test of epoch 37: loss -52.35045 acc 0.34211 roc_auc 0.50923 prc_auc 0.64041[0m
[92maverage training of epoch 38: loss -53.36380 acc 0.33333 roc_auc 0.39080 prc_auc 0.60167[0m
[93maverage test of epoch 38: loss -54.56548 acc 0.34211 roc_auc 0.52462 prc_auc 0.74042[0m
[92maverage training of epoch 39: loss -55.59625 acc 0.33333 roc_auc 0.39720 prc_auc 0.59544[0m
[93maverage test of epoch 39: loss -56.81163 acc 0.34211 roc_auc 0.42615 prc_auc 0.68321[0m
[92maverage training of epoch 40: loss -57.87262 acc 0.33333 roc_auc 0.39300 prc_auc 0.60223[0m
[93maverage test of epoch 40: loss -59.11169 acc 0.34211 roc_auc 0.56615 prc_auc 0.75581[0m
[92maverage training of epoch 41: loss -60.18617 acc 0.33333 roc_auc 0.39500 prc_auc 0.60467[0m
[93maverage test of epoch 41: loss -61.44919 acc 0.34211 roc_auc 0.42000 prc_auc 0.63611[0m
[92maverage training of epoch 42: loss -62.54022 acc 0.33333 roc_auc 0.38620 prc_auc 0.59446[0m
[93maverage test of epoch 42: loss -63.82020 acc 0.34211 roc_auc 0.67846 prc_auc 0.76822[0m
[92maverage training of epoch 43: loss -64.94005 acc 0.33333 roc_auc 0.38160 prc_auc 0.59089[0m
[93maverage test of epoch 43: loss -66.23985 acc 0.34211 roc_auc 0.41231 prc_auc 0.60919[0m
[92maverage training of epoch 44: loss -67.37962 acc 0.33333 roc_auc 0.38000 prc_auc 0.59350[0m
[93maverage test of epoch 44: loss -68.69958 acc 0.34211 roc_auc 0.45692 prc_auc 0.66517[0m
[92maverage training of epoch 45: loss -69.86407 acc 0.33333 roc_auc 0.38200 prc_auc 0.58742[0m
[93maverage test of epoch 45: loss -71.20278 acc 0.34211 roc_auc 0.56308 prc_auc 0.71571[0m
[92maverage training of epoch 46: loss -72.38963 acc 0.33333 roc_auc 0.38080 prc_auc 0.58621[0m
[93maverage test of epoch 46: loss -73.75346 acc 0.34211 roc_auc 0.54308 prc_auc 0.73444[0m
[92maverage training of epoch 47: loss -74.96263 acc 0.33333 roc_auc 0.37760 prc_auc 0.58334[0m
[93maverage test of epoch 47: loss -76.34190 acc 0.34211 roc_auc 0.54000 prc_auc 0.68268[0m
[92maverage training of epoch 48: loss -77.57553 acc 0.33333 roc_auc 0.37860 prc_auc 0.58512[0m
[93maverage test of epoch 48: loss -78.97502 acc 0.34211 roc_auc 0.50923 prc_auc 0.62924[0m
[92maverage training of epoch 49: loss -80.23266 acc 0.33333 roc_auc 0.38080 prc_auc 0.58860[0m
[93maverage test of epoch 49: loss -81.65105 acc 0.34211 roc_auc 0.44000 prc_auc 0.60835[0m
[92maverage training of epoch 50: loss -82.93300 acc 0.33333 roc_auc 0.37700 prc_auc 0.58260[0m
[93maverage test of epoch 50: loss -84.37466 acc 0.34211 roc_auc 0.48615 prc_auc 0.70781[0m
[92maverage training of epoch 51: loss -85.67892 acc 0.33333 roc_auc 0.37660 prc_auc 0.58071[0m
[93maverage test of epoch 51: loss -87.13840 acc 0.34211 roc_auc 0.46769 prc_auc 0.63777[0m
[92maverage training of epoch 52: loss -88.46640 acc 0.33333 roc_auc 0.37940 prc_auc 0.58187[0m
[93maverage test of epoch 52: loss -89.94618 acc 0.34211 roc_auc 0.45692 prc_auc 0.68072[0m
[92maverage training of epoch 53: loss -91.29886 acc 0.33333 roc_auc 0.37940 prc_auc 0.58265[0m
[93maverage test of epoch 53: loss -92.79994 acc 0.34211 roc_auc 0.56769 prc_auc 0.74146[0m
[92maverage training of epoch 54: loss -94.17558 acc 0.33333 roc_auc 0.37920 prc_auc 0.58097[0m
[93maverage test of epoch 54: loss -95.69197 acc 0.34211 roc_auc 0.58000 prc_auc 0.75370[0m
[92maverage training of epoch 55: loss -97.09639 acc 0.33333 roc_auc 0.37840 prc_auc 0.57967[0m
[93maverage test of epoch 55: loss -98.63627 acc 0.34211 roc_auc 0.57385 prc_auc 0.74633[0m
[92maverage training of epoch 56: loss -100.06112 acc 0.33333 roc_auc 0.38020 prc_auc 0.58058[0m
[93maverage test of epoch 56: loss -101.62084 acc 0.34211 roc_auc 0.45231 prc_auc 0.69343[0m
[92maverage training of epoch 57: loss -103.06988 acc 0.33333 roc_auc 0.37990 prc_auc 0.58513[0m
[93maverage test of epoch 57: loss -104.65136 acc 0.34211 roc_auc 0.29077 prc_auc 0.56375[0m
[92maverage training of epoch 58: loss -106.12468 acc 0.33333 roc_auc 0.37940 prc_auc 0.57916[0m
[93maverage test of epoch 58: loss -107.72339 acc 0.34211 roc_auc 0.50154 prc_auc 0.65814[0m
[92maverage training of epoch 59: loss -109.22149 acc 0.33333 roc_auc 0.37760 prc_auc 0.57545[0m
[93maverage test of epoch 59: loss -110.84128 acc 0.34211 roc_auc 0.47077 prc_auc 0.61891[0m
[92maverage training of epoch 60: loss -112.39363 acc 0.33333 roc_auc 0.37360 prc_auc 0.57110[0m
[93maverage test of epoch 60: loss -114.12274 acc 0.34211 roc_auc 0.53077 prc_auc 0.67720[0m
[92maverage training of epoch 61: loss -115.82284 acc 0.33333 roc_auc 0.37560 prc_auc 0.57129[0m
[93maverage test of epoch 61: loss -117.63475 acc 0.34211 roc_auc 0.45692 prc_auc 0.63478[0m
[92maverage training of epoch 62: loss -119.36875 acc 0.33333 roc_auc 0.37600 prc_auc 0.57117[0m
[93maverage test of epoch 62: loss -121.20101 acc 0.34211 roc_auc 0.45231 prc_auc 0.65245[0m
[92maverage training of epoch 63: loss -122.96418 acc 0.33333 roc_auc 0.37540 prc_auc 0.57068[0m
[93maverage test of epoch 63: loss -124.81764 acc 0.34211 roc_auc 0.40308 prc_auc 0.66922[0m
[92maverage training of epoch 64: loss -126.61337 acc 0.33333 roc_auc 0.37680 prc_auc 0.57238[0m
[93maverage test of epoch 64: loss -128.49141 acc 0.34211 roc_auc 0.46154 prc_auc 0.67648[0m
[92maverage training of epoch 65: loss -130.31865 acc 0.33333 roc_auc 0.37620 prc_auc 0.57418[0m
[93maverage test of epoch 65: loss -132.22101 acc 0.34211 roc_auc 0.59692 prc_auc 0.71431[0m
[92maverage training of epoch 66: loss -134.08245 acc 0.33333 roc_auc 0.37740 prc_auc 0.57509[0m
[93maverage test of epoch 66: loss -136.00568 acc 0.34211 roc_auc 0.47692 prc_auc 0.65844[0m
[92maverage training of epoch 67: loss -137.90261 acc 0.49333 roc_auc 0.37820 prc_auc 0.57604[0m
[93maverage test of epoch 67: loss -139.85217 acc 0.65789 roc_auc 0.60308 prc_auc 0.73092[0m
[92maverage training of epoch 68: loss -141.78002 acc 0.66667 roc_auc 0.37840 prc_auc 0.57776[0m
[93maverage test of epoch 68: loss -143.75421 acc 0.65789 roc_auc 0.52462 prc_auc 0.68742[0m
[92maverage training of epoch 69: loss -145.71704 acc 0.66667 roc_auc 0.37910 prc_auc 0.57855[0m
[93maverage test of epoch 69: loss -147.71295 acc 0.65789 roc_auc 0.54615 prc_auc 0.67963[0m
[92maverage training of epoch 70: loss -149.71079 acc 0.66667 roc_auc 0.37870 prc_auc 0.57794[0m
[93maverage test of epoch 70: loss -151.73034 acc 0.65789 roc_auc 0.44923 prc_auc 0.65611[0m
[92maverage training of epoch 71: loss -153.76398 acc 0.66667 roc_auc 0.37840 prc_auc 0.57781[0m
[93maverage test of epoch 71: loss -155.80954 acc 0.65789 roc_auc 0.47692 prc_auc 0.64902[0m
[92maverage training of epoch 72: loss -157.87673 acc 0.66667 roc_auc 0.37900 prc_auc 0.57859[0m
[93maverage test of epoch 72: loss -159.94488 acc 0.65789 roc_auc 0.52308 prc_auc 0.68402[0m
[92maverage training of epoch 73: loss -162.04762 acc 0.66667 roc_auc 0.38080 prc_auc 0.58510[0m
[93maverage test of epoch 73: loss -164.13876 acc 0.65789 roc_auc 0.43077 prc_auc 0.64539[0m
[92maverage training of epoch 74: loss -166.27857 acc 0.66667 roc_auc 0.38220 prc_auc 0.58682[0m
[93maverage test of epoch 74: loss -168.39430 acc 0.65789 roc_auc 0.52308 prc_auc 0.66187[0m
[92maverage training of epoch 75: loss -170.56843 acc 0.66667 roc_auc 0.38220 prc_auc 0.58217[0m
[93maverage test of epoch 75: loss -172.70695 acc 0.65789 roc_auc 0.43385 prc_auc 0.62621[0m
[92maverage training of epoch 76: loss -174.91884 acc 0.66667 roc_auc 0.38370 prc_auc 0.58836[0m
[93maverage test of epoch 76: loss -177.08083 acc 0.65789 roc_auc 0.39385 prc_auc 0.61240[0m
[92maverage training of epoch 77: loss -179.32680 acc 0.66667 roc_auc 0.38440 prc_auc 0.58907[0m
[93maverage test of epoch 77: loss -181.51165 acc 0.65789 roc_auc 0.46308 prc_auc 0.64098[0m
[92maverage training of epoch 78: loss -183.79352 acc 0.66667 roc_auc 0.38450 prc_auc 0.58885[0m
[93maverage test of epoch 78: loss -185.99754 acc 0.65789 roc_auc 0.51692 prc_auc 0.66632[0m
[92maverage training of epoch 79: loss -188.31328 acc 0.66667 roc_auc 0.38450 prc_auc 0.58481[0m
[93maverage test of epoch 79: loss -190.53850 acc 0.65789 roc_auc 0.53846 prc_auc 0.67568[0m
[92maverage training of epoch 80: loss -192.88853 acc 0.66667 roc_auc 0.38550 prc_auc 0.58624[0m
[93maverage test of epoch 80: loss -195.13476 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 81: loss -197.52041 acc 0.66667 roc_auc 0.38550 prc_auc 0.58739[0m
[93maverage test of epoch 81: loss -199.78777 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 82: loss -202.20854 acc 0.66667 roc_auc 0.38630 prc_auc 0.58987[0m
[93maverage test of epoch 82: loss -204.49758 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 83: loss -206.95474 acc 0.66667 roc_auc 0.38390 prc_auc 0.58851[0m
[93maverage test of epoch 83: loss -209.26494 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 84: loss -211.75870 acc 0.66667 roc_auc 0.39000 prc_auc 0.59753[0m
[93maverage test of epoch 84: loss -214.08983 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 85: loss -216.62149 acc 0.66667 roc_auc 0.42200 prc_auc 0.62449[0m
[93maverage test of epoch 85: loss -218.97411 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 86: loss -221.54269 acc 0.66667 roc_auc 0.39210 prc_auc 0.61779[0m
[93maverage test of epoch 86: loss -223.91674 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 87: loss -226.52287 acc 0.66667 roc_auc 0.48000 prc_auc 0.66000[0m
[93maverage test of epoch 87: loss -228.91748 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 88: loss -231.56177 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 88: loss -233.97718 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 89: loss -236.65846 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 89: loss -239.09420 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -241.81198 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 90: loss -244.26774 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 91: loss -247.02327 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 91: loss -249.49862 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 92: loss -252.29227 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 92: loss -254.78739 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 93: loss -257.61889 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 93: loss -260.13353 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 94: loss -263.00365 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 94: loss -265.53839 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 95: loss -268.44706 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 95: loss -271.00120 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 96: loss -273.94853 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 96: loss -276.52092 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 97: loss -279.50910 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 97: loss -282.10210 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 98: loss -285.12841 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 98: loss -287.74058 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -290.80622 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 99: loss -293.43770 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.25486 acc 0.66225 roc_auc 0.53922 prc_auc 0.68335[0m
[93maverage test of epoch 0: loss -0.36248 acc 0.67568 roc_auc 0.49667 prc_auc 0.69126[0m
[92maverage training of epoch 1: loss -0.50871 acc 0.59603 roc_auc 0.51059 prc_auc 0.65092[0m
[93maverage test of epoch 1: loss -0.75001 acc 0.32432 roc_auc 0.59667 prc_auc 0.82250[0m
[92maverage training of epoch 2: loss -1.10458 acc 0.33775 roc_auc 0.54588 prc_auc 0.68253[0m
[93maverage test of epoch 2: loss -1.42777 acc 0.32432 roc_auc 0.42333 prc_auc 0.69692[0m
[92maverage training of epoch 3: loss -1.87785 acc 0.33775 roc_auc 0.56745 prc_auc 0.70803[0m
[93maverage test of epoch 3: loss -2.21575 acc 0.32432 roc_auc 0.41000 prc_auc 0.67627[0m
[92maverage training of epoch 4: loss -2.61574 acc 0.33775 roc_auc 0.49804 prc_auc 0.69699[0m
[93maverage test of epoch 4: loss -2.91969 acc 0.32432 roc_auc 0.38667 prc_auc 0.61337[0m
[92maverage training of epoch 5: loss -3.28870 acc 0.33775 roc_auc 0.55275 prc_auc 0.70968[0m
[93maverage test of epoch 5: loss -3.55686 acc 0.32432 roc_auc 0.39333 prc_auc 0.64444[0m
[92maverage training of epoch 6: loss -3.96610 acc 0.33775 roc_auc 0.50098 prc_auc 0.64660[0m
[93maverage test of epoch 6: loss -4.26311 acc 0.32432 roc_auc 0.35667 prc_auc 0.62668[0m
[92maverage training of epoch 7: loss -4.64580 acc 0.33775 roc_auc 0.58784 prc_auc 0.75339[0m
[93maverage test of epoch 7: loss -4.93829 acc 0.32432 roc_auc 0.40667 prc_auc 0.61264[0m
[92maverage training of epoch 8: loss -5.32800 acc 0.33775 roc_auc 0.52824 prc_auc 0.66853[0m
[93maverage test of epoch 8: loss -5.62649 acc 0.32432 roc_auc 0.53000 prc_auc 0.75204[0m
[92maverage training of epoch 9: loss -6.04035 acc 0.33775 roc_auc 0.55275 prc_auc 0.70314[0m
[93maverage test of epoch 9: loss -6.34533 acc 0.32432 roc_auc 0.57333 prc_auc 0.73927[0m
[92maverage training of epoch 10: loss -6.77641 acc 0.33775 roc_auc 0.53333 prc_auc 0.68632[0m
[93maverage test of epoch 10: loss -7.06836 acc 0.32432 roc_auc 0.45667 prc_auc 0.66776[0m
[92maverage training of epoch 11: loss -7.53666 acc 0.33775 roc_auc 0.52490 prc_auc 0.69841[0m
[93maverage test of epoch 11: loss -7.85502 acc 0.32432 roc_auc 0.42667 prc_auc 0.63019[0m
[92maverage training of epoch 12: loss -8.33454 acc 0.33775 roc_auc 0.51549 prc_auc 0.66767[0m
[93maverage test of epoch 12: loss -8.67858 acc 0.32432 roc_auc 0.63667 prc_auc 0.80772[0m
[92maverage training of epoch 13: loss -9.16443 acc 0.33775 roc_auc 0.56588 prc_auc 0.74048[0m
[93maverage test of epoch 13: loss -9.51206 acc 0.32432 roc_auc 0.28667 prc_auc 0.59025[0m
[92maverage training of epoch 14: loss -10.02674 acc 0.33775 roc_auc 0.53059 prc_auc 0.69043[0m
[93maverage test of epoch 14: loss -10.37914 acc 0.32432 roc_auc 0.46000 prc_auc 0.72516[0m
[92maverage training of epoch 15: loss -10.91900 acc 0.33775 roc_auc 0.53000 prc_auc 0.69264[0m
[93maverage test of epoch 15: loss -11.29633 acc 0.32432 roc_auc 0.52333 prc_auc 0.69393[0m
[92maverage training of epoch 16: loss -11.85496 acc 0.33775 roc_auc 0.52157 prc_auc 0.68684[0m
[93maverage test of epoch 16: loss -12.23828 acc 0.32432 roc_auc 0.62000 prc_auc 0.78917[0m
[92maverage training of epoch 17: loss -12.81780 acc 0.33775 roc_auc 0.50373 prc_auc 0.66083[0m
[93maverage test of epoch 17: loss -13.22729 acc 0.32432 roc_auc 0.51667 prc_auc 0.71142[0m
[92maverage training of epoch 18: loss -13.82294 acc 0.33775 roc_auc 0.51902 prc_auc 0.66374[0m
[93maverage test of epoch 18: loss -14.24179 acc 0.32432 roc_auc 0.53000 prc_auc 0.65691[0m
[92maverage training of epoch 19: loss -14.85919 acc 0.33775 roc_auc 0.46588 prc_auc 0.63161[0m
[93maverage test of epoch 19: loss -15.29030 acc 0.32432 roc_auc 0.28000 prc_auc 0.56576[0m
[92maverage training of epoch 20: loss -15.92900 acc 0.33775 roc_auc 0.46725 prc_auc 0.64244[0m
[93maverage test of epoch 20: loss -16.37982 acc 0.32432 roc_auc 0.43333 prc_auc 0.63759[0m
[92maverage training of epoch 21: loss -17.03525 acc 0.33775 roc_auc 0.47373 prc_auc 0.65582[0m
[93maverage test of epoch 21: loss -17.50414 acc 0.32432 roc_auc 0.51333 prc_auc 0.74991[0m
[92maverage training of epoch 22: loss -18.16697 acc 0.33775 roc_auc 0.49020 prc_auc 0.65367[0m
[93maverage test of epoch 22: loss -18.65376 acc 0.32432 roc_auc 0.50333 prc_auc 0.75542[0m
[92maverage training of epoch 23: loss -19.33513 acc 0.33775 roc_auc 0.47098 prc_auc 0.66595[0m
[93maverage test of epoch 23: loss -19.83678 acc 0.32432 roc_auc 0.54667 prc_auc 0.68575[0m
[92maverage training of epoch 24: loss -20.53117 acc 0.33775 roc_auc 0.46255 prc_auc 0.67203[0m
[93maverage test of epoch 24: loss -21.03430 acc 0.32432 roc_auc 0.42000 prc_auc 0.64919[0m
[92maverage training of epoch 25: loss -21.74977 acc 0.33775 roc_auc 0.44941 prc_auc 0.65333[0m
[93maverage test of epoch 25: loss -22.27686 acc 0.32432 roc_auc 0.49500 prc_auc 0.67533[0m
[92maverage training of epoch 26: loss -22.99306 acc 0.33775 roc_auc 0.43745 prc_auc 0.65191[0m
[93maverage test of epoch 26: loss -23.51460 acc 0.32432 roc_auc 0.46167 prc_auc 0.69782[0m
[92maverage training of epoch 27: loss -24.25468 acc 0.33775 roc_auc 0.40059 prc_auc 0.59432[0m
[93maverage test of epoch 27: loss -24.78981 acc 0.32432 roc_auc 0.65667 prc_auc 0.80421[0m
[92maverage training of epoch 28: loss -25.54092 acc 0.33775 roc_auc 0.40520 prc_auc 0.64288[0m
[93maverage test of epoch 28: loss -26.08617 acc 0.32432 roc_auc 0.43667 prc_auc 0.62698[0m
[92maverage training of epoch 29: loss -26.84936 acc 0.33775 roc_auc 0.39588 prc_auc 0.61383[0m
[93maverage test of epoch 29: loss -27.41365 acc 0.32432 roc_auc 0.59167 prc_auc 0.74678[0m
[92maverage training of epoch 30: loss -28.18311 acc 0.33775 roc_auc 0.38275 prc_auc 0.59597[0m
[93maverage test of epoch 30: loss -28.75738 acc 0.32432 roc_auc 0.47333 prc_auc 0.73808[0m
[92maverage training of epoch 31: loss -29.54805 acc 0.33775 roc_auc 0.36333 prc_auc 0.58857[0m
[93maverage test of epoch 31: loss -30.13663 acc 0.32432 roc_auc 0.46833 prc_auc 0.66535[0m
[92maverage training of epoch 32: loss -30.93584 acc 0.33775 roc_auc 0.37784 prc_auc 0.60253[0m
[93maverage test of epoch 32: loss -31.53651 acc 0.32432 roc_auc 0.53667 prc_auc 0.70940[0m
[92maverage training of epoch 33: loss -32.35285 acc 0.33775 roc_auc 0.38000 prc_auc 0.60185[0m
[93maverage test of epoch 33: loss -32.96667 acc 0.32432 roc_auc 0.49500 prc_auc 0.70604[0m
[92maverage training of epoch 34: loss -33.79267 acc 0.33775 roc_auc 0.38392 prc_auc 0.59300[0m
[93maverage test of epoch 34: loss -34.42019 acc 0.32432 roc_auc 0.59500 prc_auc 0.73091[0m
[92maverage training of epoch 35: loss -35.26314 acc 0.33775 roc_auc 0.38255 prc_auc 0.58809[0mUsing backend: pytorch

[93maverage test of epoch 35: loss -35.90659 acc 0.32432 roc_auc 0.34667 prc_auc 0.60133[0m
[92maverage training of epoch 36: loss -36.76088 acc 0.33775 roc_auc 0.38020 prc_auc 0.59839[0m
[93maverage test of epoch 36: loss -37.41839 acc 0.32432 roc_auc 0.50167 prc_auc 0.68533[0m
[92maverage training of epoch 37: loss -38.28617 acc 0.33775 roc_auc 0.38078 prc_auc 0.59208[0m
[93maverage test of epoch 37: loss -38.95805 acc 0.32432 roc_auc 0.46833 prc_auc 0.70275[0m
[92maverage training of epoch 38: loss -39.84381 acc 0.33775 roc_auc 0.37902 prc_auc 0.58709[0m
[93maverage test of epoch 38: loss -40.52791 acc 0.32432 roc_auc 0.68167 prc_auc 0.85492[0m
[92maverage training of epoch 39: loss -41.42630 acc 0.33775 roc_auc 0.37275 prc_auc 0.58687[0m
[93maverage test of epoch 39: loss -42.13148 acc 0.32432 roc_auc 0.45167 prc_auc 0.71457[0m
[92maverage training of epoch 40: loss -43.03801 acc 0.33775 roc_auc 0.37353 prc_auc 0.58419[0m
[93maverage test of epoch 40: loss -43.75828 acc 0.32432 roc_auc 0.54667 prc_auc 0.78179[0m
[92maverage training of epoch 41: loss -44.67972 acc 0.33775 roc_auc 0.36804 prc_auc 0.58682[0m
[93maverage test of epoch 41: loss -45.41774 acc 0.32432 roc_auc 0.33000 prc_auc 0.57213[0m
[92maverage training of epoch 42: loss -46.35023 acc 0.33775 roc_auc 0.36314 prc_auc 0.58133[0m
[93maverage test of epoch 42: loss -47.10361 acc 0.32432 roc_auc 0.62333 prc_auc 0.77897[0m
[92maverage training of epoch 43: loss -48.05087 acc 0.33775 roc_auc 0.36235 prc_auc 0.57843[0m
[93maverage test of epoch 43: loss -48.82119 acc 0.32432 roc_auc 0.70000 prc_auc 0.82779[0m
[92maverage training of epoch 44: loss -49.78188 acc 0.33775 roc_auc 0.36510 prc_auc 0.58605[0m
[93maverage test of epoch 44: loss -50.56750 acc 0.32432 roc_auc 0.58833 prc_auc 0.78658[0m
[92maverage training of epoch 45: loss -51.54095 acc 0.33775 roc_auc 0.36314 prc_auc 0.57752[0m
[93maverage test of epoch 45: loss -52.34457 acc 0.32432 roc_auc 0.58333 prc_auc 0.81040[0m
[92maverage training of epoch 46: loss -53.32921 acc 0.33775 roc_auc 0.36392 prc_auc 0.58094[0m
[93maverage test of epoch 46: loss -54.14789 acc 0.32432 roc_auc 0.47667 prc_auc 0.64733[0m
[92maverage training of epoch 47: loss -55.14823 acc 0.33775 roc_auc 0.36765 prc_auc 0.58528[0m
[93maverage test of epoch 47: loss -55.98548 acc 0.32432 roc_auc 0.47667 prc_auc 0.72651[0m
[92maverage training of epoch 48: loss -56.99752 acc 0.33775 roc_auc 0.36569 prc_auc 0.57532[0m
[93maverage test of epoch 48: loss -57.85167 acc 0.32432 roc_auc 0.53500 prc_auc 0.73404[0m
[92maverage training of epoch 49: loss -58.87347 acc 0.33775 roc_auc 0.36490 prc_auc 0.57842[0m
[93maverage test of epoch 49: loss -59.74353 acc 0.32432 roc_auc 0.34333 prc_auc 0.61186[0m
[92maverage training of epoch 50: loss -60.78149 acc 0.33775 roc_auc 0.36667 prc_auc 0.57755[0m
[93maverage test of epoch 50: loss -61.67080 acc 0.32432 roc_auc 0.44500 prc_auc 0.67702[0m
[92maverage training of epoch 51: loss -62.71988 acc 0.33775 roc_auc 0.36569 prc_auc 0.57444[0m
[93maverage test of epoch 51: loss -63.62504 acc 0.32432 roc_auc 0.38167 prc_auc 0.64567[0m
[92maverage training of epoch 52: loss -64.68722 acc 0.33775 roc_auc 0.36676 prc_auc 0.57531[0m
[93maverage test of epoch 52: loss -65.61173 acc 0.32432 roc_auc 0.37833 prc_auc 0.64112[0m
[92maverage training of epoch 53: loss -66.68503 acc 0.33775 roc_auc 0.36745 prc_auc 0.57532[0m
[93maverage test of epoch 53: loss -67.62903 acc 0.32432 roc_auc 0.46000 prc_auc 0.69526[0m
[92maverage training of epoch 54: loss -68.71287 acc 0.33775 roc_auc 0.36784 prc_auc 0.57557[0m
[93maverage test of epoch 54: loss -69.67311 acc 0.32432 roc_auc 0.58833 prc_auc 0.77048[0m
[92maverage training of epoch 55: loss -70.76947 acc 0.33775 roc_auc 0.36941 prc_auc 0.57613[0m
[93maverage test of epoch 55: loss -71.74880 acc 0.32432 roc_auc 0.44167 prc_auc 0.65678[0m
[92maverage training of epoch 56: loss -72.85820 acc 0.33775 roc_auc 0.37000 prc_auc 0.57463[0m
[93maverage test of epoch 56: loss -73.85589 acc 0.32432 roc_auc 0.41333 prc_auc 0.63410[0m
[92maverage training of epoch 57: loss -74.97481 acc 0.33775 roc_auc 0.37078 prc_auc 0.57564[0m
[93maverage test of epoch 57: loss -75.99191 acc 0.32432 roc_auc 0.45167 prc_auc 0.62598[0m
[92maverage training of epoch 58: loss -77.12054 acc 0.33775 roc_auc 0.37118 prc_auc 0.57410[0m
[93maverage test of epoch 58: loss -78.15791 acc 0.32432 roc_auc 0.59500 prc_auc 0.76660[0m
[92maverage training of epoch 59: loss -79.30052 acc 0.33775 roc_auc 0.37157 prc_auc 0.57411[0m
[93maverage test of epoch 59: loss -80.35459 acc 0.32432 roc_auc 0.38667 prc_auc 0.60910[0m
[92maverage training of epoch 60: loss -81.50761 acc 0.33775 roc_auc 0.37294 prc_auc 0.57414[0m
[93maverage test of epoch 60: loss -82.58147 acc 0.32432 roc_auc 0.61500 prc_auc 0.74760[0m
[92maverage training of epoch 61: loss -83.74405 acc 0.33775 roc_auc 0.37451 prc_auc 0.57476[0m
[93maverage test of epoch 61: loss -84.83816 acc 0.32432 roc_auc 0.56833 prc_auc 0.73998[0m
[92maverage training of epoch 62: loss -86.01307 acc 0.33775 roc_auc 0.37471 prc_auc 0.57609[0m
[93maverage test of epoch 62: loss -87.12428 acc 0.32432 roc_auc 0.53000 prc_auc 0.69035[0m
[92maverage training of epoch 63: loss -88.31066 acc 0.33775 roc_auc 0.37451 prc_auc 0.57396[0m
[93maverage test of epoch 63: loss -89.44054 acc 0.32432 roc_auc 0.49500 prc_auc 0.65258[0m
[92maverage training of epoch 64: loss -90.63939 acc 0.33775 roc_auc 0.37490 prc_auc 0.57402[0m
[93maverage test of epoch 64: loss -91.78994 acc 0.32432 roc_auc 0.48333 prc_auc 0.63318[0m
[92maverage training of epoch 65: loss -92.99736 acc 0.33775 roc_auc 0.37490 prc_auc 0.57334[0m
[93maverage test of epoch 65: loss -94.16809 acc 0.32432 roc_auc 0.56667 prc_auc 0.71957[0m
[92maverage training of epoch 66: loss -95.38591 acc 0.33775 roc_auc 0.37549 prc_auc 0.57281[0m
[93maverage test of epoch 66: loss -96.57486 acc 0.32432 roc_auc 0.53167 prc_auc 0.75028[0m
[92maverage training of epoch 67: loss -97.81617 acc 0.33775 roc_auc 0.37529 prc_auc 0.57010[0m
[93maverage test of epoch 67: loss -99.08673 acc 0.32432 roc_auc 0.58833 prc_auc 0.79328[0m
[92maverage training of epoch 68: loss -100.47245 acc 0.33775 roc_auc 0.37627 prc_auc 0.57110[0m
[93maverage test of epoch 68: loss -101.86045 acc 0.32432 roc_auc 0.54000 prc_auc 0.72290[0m
[92maverage training of epoch 69: loss -103.26237 acc 0.33775 roc_auc 0.37667 prc_auc 0.57058[0m
[93maverage test of epoch 69: loss -104.67598 acc 0.32432 roc_auc 0.44500 prc_auc 0.65160[0m
[92maverage training of epoch 70: loss -106.08962 acc 0.33775 roc_auc 0.37686 prc_auc 0.57060[0m
[93maverage test of epoch 70: loss -107.52799 acc 0.32432 roc_auc 0.61667 prc_auc 0.79680[0m
[92maverage training of epoch 71: loss -108.95625 acc 0.33775 roc_auc 0.37657 prc_auc 0.57007[0m
[93maverage test of epoch 71: loss -110.42338 acc 0.32432 roc_auc 0.62167 prc_auc 0.79585[0m
[92maverage training of epoch 72: loss -111.86533 acc 0.59603 roc_auc 0.37706 prc_auc 0.56981[0m
[93maverage test of epoch 72: loss -113.36089 acc 0.67568 roc_auc 0.55833 prc_auc 0.70292[0m
[92maverage training of epoch 73: loss -114.81603 acc 0.66225 roc_auc 0.37765 prc_auc 0.57012[0m
[93maverage test of epoch 73: loss -116.34106 acc 0.67568 roc_auc 0.50667 prc_auc 0.71286[0m
[92maverage training of epoch 74: loss -117.81066 acc 0.66225 roc_auc 0.37863 prc_auc 0.57095[0m
[93maverage test of epoch 74: loss -119.37349 acc 0.67568 roc_auc 0.44000 prc_auc 0.65572[0m
[92maverage training of epoch 75: loss -120.97538 acc 0.66225 roc_auc 0.38118 prc_auc 0.57300[0m
[93maverage test of epoch 75: loss -122.70825 acc 0.67568 roc_auc 0.41833 prc_auc 0.65129[0m
[92maverage training of epoch 76: loss -124.35845 acc 0.66225 roc_auc 0.38098 prc_auc 0.57295[0m
[93maverage test of epoch 76: loss -126.13294 acc 0.67568 roc_auc 0.44000 prc_auc 0.65128[0m
[92maverage training of epoch 77: loss -127.79870 acc 0.66225 roc_auc 0.38196 prc_auc 0.57420[0m
[93maverage test of epoch 77: loss -129.60799 acc 0.67568 roc_auc 0.45833 prc_auc 0.68135[0m
[92maverage training of epoch 78: loss -131.29241 acc 0.66225 roc_auc 0.38225 prc_auc 0.57446[0m
[93maverage test of epoch 78: loss -133.13856 acc 0.67568 roc_auc 0.52667 prc_auc 0.68116[0m
[92maverage training of epoch 79: loss -134.84196 acc 0.66225 roc_auc 0.38216 prc_auc 0.57434[0m
[93maverage test of epoch 79: loss -136.72693 acc 0.67568 roc_auc 0.40167 prc_auc 0.64129[0m
[92maverage training of epoch 80: loss -138.44808 acc 0.66225 roc_auc 0.38206 prc_auc 0.57415[0m
[93maverage test of epoch 80: loss -140.37289 acc 0.67568 roc_auc 0.33333 prc_auc 0.60729[0m
[92maverage training of epoch 81: loss -142.11219 acc 0.66225 roc_auc 0.38206 prc_auc 0.57401[0m
[93maverage test of epoch 81: loss -144.07630 acc 0.67568 roc_auc 0.58833 prc_auc 0.71681[0m
[92maverage training of epoch 82: loss -145.83457 acc 0.66225 roc_auc 0.38284 prc_auc 0.57448[0m
[93maverage test of epoch 82: loss -147.83879 acc 0.67568 roc_auc 0.50000 prc_auc 0.67606[0m
[92maverage training of epoch 83: loss -149.61592 acc 0.66225 roc_auc 0.38196 prc_auc 0.57355[0m
[93maverage test of epoch 83: loss -151.66064 acc 0.67568 roc_auc 0.48000 prc_auc 0.66703[0m
[92maverage training of epoch 84: loss -153.45629 acc 0.66225 roc_auc 0.38216 prc_auc 0.57370[0m
[93maverage test of epoch 84: loss -155.54134 acc 0.67568 roc_auc 0.48000 prc_auc 0.66703[0m
[92maverage training of epoch 85: loss -157.35381 acc 0.66225 roc_auc 0.38225 prc_auc 0.57395[0m
[93maverage test of epoch 85: loss -159.47708 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 86: loss -161.30547 acc 0.66225 roc_auc 0.38265 prc_auc 0.57456[0m
[93maverage test of epoch 86: loss -163.46854 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 87: loss -165.31250 acc 0.66225 roc_auc 0.38245 prc_auc 0.57642[0m
[93maverage test of epoch 87: loss -167.51452 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 88: loss -169.37607 acc 0.66225 roc_auc 0.38206 prc_auc 0.57560[0m
[93maverage test of epoch 88: loss -171.62030 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 89: loss -173.49746 acc 0.66225 roc_auc 0.38010 prc_auc 0.58026[0m
[93maverage test of epoch 89: loss -175.78286 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 90: loss -177.67633 acc 0.66225 roc_auc 0.39265 prc_auc 0.59497[0m
[93maverage test of epoch 90: loss -180.00387 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 91: loss -181.91415 acc 0.66225 roc_auc 0.40461 prc_auc 0.61110[0m
[93maverage test of epoch 91: loss -184.28400 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 92: loss -186.20897 acc 0.66225 roc_auc 0.40255 prc_auc 0.61644[0m
[93maverage test of epoch 92: loss -188.61915 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 93: loss -190.55830 acc 0.66225 roc_auc 0.47098 prc_auc 0.65354[0m
[93maverage test of epoch 93: loss -193.00937 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 94: loss -194.96253 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 94: loss -197.45524 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 95: loss -199.42250 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 95: loss -201.95688 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 96: loss -203.93759 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 96: loss -206.51377 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 97: loss -208.50830 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 97: loss -211.12716 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 98: loss -213.13541 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 98: loss -215.79706 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 99: loss -217.81946 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 99: loss -220.52466 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.09370 acc 0.37748 roc_auc 0.42922 prc_auc 0.63091[0m
[93maverage test of epoch 0: loss -0.86323 acc 0.67568 roc_auc 0.52333 prc_auc 0.74773[0m
[92maverage training of epoch 1: loss -2.04301 acc 0.66225 roc_auc 0.42922 prc_auc 0.62363[0m
[93maverage test of epoch 1: loss -2.97473 acc 0.67568 roc_auc 0.40000 prc_auc 0.67575[0m
[92maverage training of epoch 2: loss -3.49100 acc 0.66225 roc_auc 0.39902 prc_auc 0.60874[0m
[93maverage test of epoch 2: loss -4.03264 acc 0.67568 roc_auc 0.70000 prc_auc 0.78199[0m
[92maverage training of epoch 3: loss -4.42796 acc 0.66225 roc_auc 0.42451 prc_auc 0.63327[0m
[93maverage test of epoch 3: loss -4.95441 acc 0.67568 roc_auc 0.60667 prc_auc 0.71285[0m
[92maverage training of epoch 4: loss -5.35286 acc 0.66225 roc_auc 0.41863 prc_auc 0.60626[0m
[93maverage test of epoch 4: loss -5.87611 acc 0.67568 roc_auc 0.59000 prc_auc 0.77802[0m
[92maverage training of epoch 5: loss -6.29497 acc 0.66225 roc_auc 0.41451 prc_auc 0.61750[0m
[93maverage test of epoch 5: loss -6.84574 acc 0.67568 roc_auc 0.56000 prc_auc 0.71627[0m
[92maverage training of epoch 6: loss -7.26636 acc 0.66225 roc_auc 0.41706 prc_auc 0.61514[0m
[93maverage test of epoch 6: loss -7.84528 acc 0.67568 roc_auc 0.55333 prc_auc 0.77837[0m
[92maverage training of epoch 7: loss -8.27427 acc 0.66225 roc_auc 0.41843 prc_auc 0.63197[0m
[93maverage test of epoch 7: loss -8.86169 acc 0.67568 roc_auc 0.37667 prc_auc 0.64017[0m
[92maverage training of epoch 8: loss -9.33333 acc 0.66225 roc_auc 0.38147 prc_auc 0.58591[0m
[93maverage test of epoch 8: loss -9.97085 acc 0.67568 roc_auc 0.60833 prc_auc 0.80323[0m
[92maverage training of epoch 9: loss -10.44123 acc 0.66225 roc_auc 0.41725 prc_auc 0.61015[0m
[93maverage test of epoch 9: loss -11.10351 acc 0.67568 roc_auc 0.51667 prc_auc 0.73394[0m
[92maverage training of epoch 10: loss -11.58686 acc 0.66225 roc_auc 0.40765 prc_auc 0.61883[0m
[93maverage test of epoch 10: loss -12.28827 acc 0.67568 roc_auc 0.50667 prc_auc 0.74054[0m
[92maverage training of epoch 11: loss -12.79682 acc 0.66225 roc_auc 0.41245 prc_auc 0.60268[0m
[93maverage test of epoch 11: loss -13.52524 acc 0.67568 roc_auc 0.40500 prc_auc 0.67080[0m
[92maverage training of epoch 12: loss -14.04255 acc 0.66225 roc_auc 0.40324 prc_auc 0.59800[0m
[93maverage test of epoch 12: loss -14.80807 acc 0.67568 roc_auc 0.44833 prc_auc 0.67909[0m
[92maverage training of epoch 13: loss -15.33437 acc 0.66225 roc_auc 0.41078 prc_auc 0.61729[0m
[93maverage test of epoch 13: loss -16.14445 acc 0.67568 roc_auc 0.80333 prc_auc 0.89672[0m
[92maverage training of epoch 14: loss -16.68047 acc 0.66225 roc_auc 0.41853 prc_auc 0.62524[0m
[93maverage test of epoch 14: loss -17.52035 acc 0.67568 roc_auc 0.50167 prc_auc 0.67093[0m
[92maverage training of epoch 15: loss -18.08077 acc 0.66225 roc_auc 0.38775 prc_auc 0.59504[0m
[93maverage test of epoch 15: loss -18.93853 acc 0.67568 roc_auc 0.56000 prc_auc 0.70146[0m
[92maverage training of epoch 16: loss -19.52599 acc 0.66225 roc_auc 0.40010 prc_auc 0.60059[0m
[93maverage test of epoch 16: loss -20.43178 acc 0.67568 roc_auc 0.44333 prc_auc 0.64399[0m
[92maverage training of epoch 17: loss -21.02663 acc 0.66225 roc_auc 0.40461 prc_auc 0.60094[0m
[93maverage test of epoch 17: loss -21.97020 acc 0.67568 roc_auc 0.56333 prc_auc 0.70347[0m
[92maverage training of epoch 18: loss -22.57235 acc 0.66225 roc_auc 0.40059 prc_auc 0.59661[0m
[93maverage test of epoch 18: loss -23.53871 acc 0.67568 roc_auc 0.63333 prc_auc 0.74494[0m
[92maverage training of epoch 19: loss -24.17284 acc 0.66225 roc_auc 0.39324 prc_auc 0.59359[0m
[93maverage test of epoch 19: loss -25.17233 acc 0.67568 roc_auc 0.57500 prc_auc 0.71032[0m
[92maverage training of epoch 20: loss -25.81071 acc 0.66225 roc_auc 0.40735 prc_auc 0.60798[0m
[93maverage test of epoch 20: loss -26.82443 acc 0.67568 roc_auc 0.46333 prc_auc 0.66009[0m
[92maverage training of epoch 21: loss -27.48076 acc 0.66225 roc_auc 0.40343 prc_auc 0.60616[0m
[93maverage test of epoch 21: loss -28.54883 acc 0.67568 roc_auc 0.58333 prc_auc 0.71429[0m
[92maverage training of epoch 22: loss -29.20391 acc 0.66225 roc_auc 0.43922 prc_auc 0.63114[0m
[93maverage test of epoch 22: loss -30.28828 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 23: loss -30.96476 acc 0.66225 roc_auc 0.39608 prc_auc 0.62519[0m
[93maverage test of epoch 23: loss -32.09457 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 24: loss -32.76336 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 24: loss -33.92036 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 25: loss -34.61134 acc 0.66225 roc_auc 0.47382 prc_auc 0.65079[0m
[93maverage test of epoch 25: loss -35.79597 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 26: loss -36.50029 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 26: loss -37.72277 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 27: loss -38.42517 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 27: loss -39.67708 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 28: loss -40.39353 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 28: loss -41.68137 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 29: loss -42.40493 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 29: loss -43.72722 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 30: loss -44.45883 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 30: loss -45.81086 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 31: loss -46.55504 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 31: loss -47.93735 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 32: loss -48.69039 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 32: loss -50.11183 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 33: loss -50.87525 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 33: loss -52.32934 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 34: loss -53.10204 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 34: loss -54.58581 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 35: loss -55.37359 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 35: loss -56.89686 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 36: loss -57.68948 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 36: loss -59.24807 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 37: loss -60.05019 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 37: loss -61.64785 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 38: loss -62.45464 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 38: loss -64.08715 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 39: loss -64.90724 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 39: loss -66.57621 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -67.40386 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 40: loss -69.10611 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -69.94492 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 41: loss -71.68010 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -72.52924 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 42: loss -74.30167 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -75.15783 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 43: loss -76.96798 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -77.82919 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 44: loss -79.67450 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -80.54126 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 45: loss -82.42374 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -83.29760 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 46: loss -85.21916 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -86.09996 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 47: loss -88.05627 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -88.94335 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 48: loss -90.93970 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -91.83366 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 49: loss -93.86683 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 50: loss -94.76669 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 50: loss -96.83750 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 51: loss -97.74642 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 51: loss -99.85253 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 52: loss -100.76899 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 52: loss -102.90929 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 53: loss -103.83583 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 53: loss -106.01746 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 54: loss -106.94676 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 54: loss -109.17063 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 55: loss -110.10290 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 55: loss -112.36084 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 56: loss -113.30453 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 56: loss -115.60517 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 57: loss -116.55058 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 57: loss -118.89059 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 58: loss -119.84139 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 58: loss -122.22210 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 59: loss -123.17848 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 59: loss -125.59741 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 60: loss -126.55884 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 60: loss -129.01751 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 61: loss -129.98413 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 61: loss -132.48522 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 62: loss -133.45665 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 62: loss -135.99573 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 63: loss -136.97251 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 63: loss -139.55186 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 64: loss -140.53373 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 64: loss -143.15353 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 65: loss -144.13930 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 65: loss -146.80160 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 66: loss -147.78976 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 66: loss -150.49330 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 67: loss -151.48620 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 67: loss -154.23081 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 68: loss -155.22749 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 68: loss -158.01395 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 69: loss -159.01499 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 69: loss -161.84190 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 70: loss -162.84619 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 70: loss -165.71607 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 71: loss -166.72318 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 71: loss -169.63457 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 72: loss -170.64545 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 72: loss -173.59914 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 73: loss -174.64564 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 73: loss -177.74157 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 74: loss -178.91129 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 74: loss -182.11020 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 75: loss -183.28209 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 75: loss -186.52931 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 76: loss -187.70576 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 76: loss -191.00230 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 77: loss -192.18443 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 77: loss -195.53054 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 78: loss -196.71973 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 78: loss -200.11779 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 79: loss -201.31250 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 79: loss -204.76236 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 80: loss -205.96389 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 80: loss -209.46548 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 81: loss -210.67409 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 81: loss -214.22857 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 82: loss -215.44245 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 82: loss -219.04986 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 83: loss -220.27037 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 83: loss -223.93207 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 84: loss -225.15830 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 84: loss -228.87316 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 85: loss -230.10533 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 85: loss -233.87478 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 86: loss -235.11253 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 86: loss -238.93640 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 87: loss -240.18001 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 87: loss -244.05814 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 88: loss -245.30712 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 88: loss -249.24067 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 89: loss -250.49450 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 89: loss -254.48355 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 90: loss -255.74213 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 90: loss -259.78587 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 91: loss -261.04625 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 91: loss -265.14174 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 92: loss -266.40510 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 92: loss -270.55595 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 93: loss -271.82055 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 93: loss -276.02504 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 94: loss -277.29291 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 94: loss -281.55430 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 95: loss -282.82351 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 95: loss -287.13998 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 96: loss -288.41208 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 96: loss -292.78547 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 97: loss -294.05949 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 97: loss -298.49001 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 98: loss -299.76624 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 98: loss -304.25363 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 99: loss -305.53219 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 99: loss -310.07732 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 1)
('lr', 0.0003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.66501 ROC_AUC (avg): 0.47262 PRC_AUC (avg): 0.65047 

Average forward propagation time taken(ms): 4.273195522824019
Average backward propagation time taken(ms): 1.5721755543854439

