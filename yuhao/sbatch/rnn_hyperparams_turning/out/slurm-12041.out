# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.0003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-11-16-40/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-11-16-40/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 16,
 'epochs': 100,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 8,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.0003,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 2,
 'num_workers': 8,
 'number_of_mlp_layer': 0,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-18-11-16-40',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 100, 'learning_rate': 0.0003, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.97409 acc 0.64000 roc_auc 0.44720 prc_auc 0.66707[0m
[93maverage test of epoch 0: loss -1.29280 acc 0.65789 roc_auc 0.63385 prc_auc 0.79511[0m
[92maverage training of epoch 1: loss -1.56708 acc 0.66667 roc_auc 0.55940 prc_auc 0.76638[0m
[93maverage test of epoch 1: loss -1.89190 acc 0.65789 roc_auc 0.78154 prc_auc 0.89351[0m
[92maverage training of epoch 2: loss -2.15401 acc 0.66667 roc_auc 0.63680 prc_auc 0.78026[0m
[93maverage test of epoch 2: loss -2.41906 acc 0.65789 roc_auc 0.84615 prc_auc 0.92579[0m
[92maverage training of epoch 3: loss -2.63657 acc 0.66667 roc_auc 0.75300 prc_auc 0.86129[0m
[93maverage test of epoch 3: loss -2.90024 acc 0.65789 roc_auc 0.89846 prc_auc 0.93860[0m
[92maverage training of epoch 4: loss -3.08817 acc 0.72000 roc_auc 0.82960 prc_auc 0.89404[0m
[93maverage test of epoch 4: loss -3.30672 acc 0.71053 roc_auc 0.87692 prc_auc 0.93611[0m
[92maverage training of epoch 5: loss -3.51639 acc 0.81333 roc_auc 0.85620 prc_auc 0.89944[0m
[93maverage test of epoch 5: loss -3.70995 acc 0.78947 roc_auc 0.85538 prc_auc 0.92466[0m
[92maverage training of epoch 6: loss -3.90643 acc 0.83333 roc_auc 0.85860 prc_auc 0.90245[0m
[93maverage test of epoch 6: loss -4.08221 acc 0.81579 roc_auc 0.87385 prc_auc 0.93624[0m
[92maverage training of epoch 7: loss -4.25172 acc 0.83333 roc_auc 0.86580 prc_auc 0.92758[0m
[93maverage test of epoch 7: loss -4.45194 acc 0.81579 roc_auc 0.88000 prc_auc 0.94575[0m
[92maverage training of epoch 8: loss -4.60170 acc 0.86000 roc_auc 0.85260 prc_auc 0.89339[0m
[93maverage test of epoch 8: loss -4.67377 acc 0.78947 roc_auc 0.82154 prc_auc 0.87615[0m
[92maverage training of epoch 9: loss -4.91517 acc 0.86000 roc_auc 0.83280 prc_auc 0.86085[0m
[93maverage test of epoch 9: loss -4.98002 acc 0.81579 roc_auc 0.87077 prc_auc 0.94136[0m
[92maverage training of epoch 10: loss -5.12349 acc 0.80000 roc_auc 0.82800 prc_auc 0.89819[0m
[93maverage test of epoch 10: loss -5.30026 acc 0.81579 roc_auc 0.80615 prc_auc 0.87557[0m
[92maverage training of epoch 11: loss -5.40200 acc 0.79333 roc_auc 0.82380 prc_auc 0.89976[0m
[93maverage test of epoch 11: loss -5.69692 acc 0.84211 roc_auc 0.88308 prc_auc 0.92080[0m
[92maverage training of epoch 12: loss -5.82819 acc 0.86667 roc_auc 0.85640 prc_auc 0.89446[0m
[93maverage test of epoch 12: loss -5.84207 acc 0.81579 roc_auc 0.82462 prc_auc 0.87725[0m
[92maverage training of epoch 13: loss -6.05388 acc 0.83333 roc_auc 0.80940 prc_auc 0.89007[0m
[93maverage test of epoch 13: loss -6.20529 acc 0.81579 roc_auc 0.90462 prc_auc 0.94909[0m
[92maverage training of epoch 14: loss -6.35719 acc 0.84000 roc_auc 0.77640 prc_auc 0.80837[0m
[93maverage test of epoch 14: loss -6.57528 acc 0.84211 roc_auc 0.84923 prc_auc 0.87459[0m
[92maverage training of epoch 15: loss -6.65949 acc 0.83333 roc_auc 0.80480 prc_auc 0.86505[0m
[93maverage test of epoch 15: loss -6.87727 acc 0.84211 roc_auc 0.90462 prc_auc 0.95374[0m
[92maverage training of epoch 16: loss -6.93132 acc 0.82000 roc_auc 0.77640 prc_auc 0.82250[0m
[93maverage test of epoch 16: loss -7.18164 acc 0.84211 roc_auc 0.88000 prc_auc 0.94929[0m
[92maverage training of epoch 17: loss -7.25322 acc 0.83333 roc_auc 0.82060 prc_auc 0.88299[0m
[93maverage test of epoch 17: loss -7.45836 acc 0.84211 roc_auc 0.81538 prc_auc 0.87638[0m
[92maverage training of epoch 18: loss -7.54164 acc 0.83333 roc_auc 0.81160 prc_auc 0.87528[0m
[93maverage test of epoch 18: loss -7.69996 acc 0.84211 roc_auc 0.83692 prc_auc 0.92180[0m
[92maverage training of epoch 19: loss -7.78624 acc 0.84667 roc_auc 0.77520 prc_auc 0.82239[0m
[93maverage test of epoch 19: loss -7.82778 acc 0.81579 roc_auc 0.78154 prc_auc 0.87942[0m
[92maverage training of epoch 20: loss -8.12760 acc 0.83333 roc_auc 0.81660 prc_auc 0.84455[0m
[93maverage test of epoch 20: loss -8.16382 acc 0.78947 roc_auc 0.87692 prc_auc 0.94285[0m
[92maverage training of epoch 21: loss -8.42046 acc 0.83333 roc_auc 0.85000 prc_auc 0.87452[0m
[93maverage test of epoch 21: loss -8.46301 acc 0.84211 roc_auc 0.80615 prc_auc 0.90672[0m
[92maverage training of epoch 22: loss -8.71368 acc 0.84667 roc_auc 0.83200 prc_auc 0.87001[0m
[93maverage test of epoch 22: loss -8.74332 acc 0.84211 roc_auc 0.86769 prc_auc 0.93652[0m
[92maverage training of epoch 23: loss -8.91569 acc 0.84667 roc_auc 0.77130 prc_auc 0.81357[0m
[93maverage test of epoch 23: loss -8.85695 acc 0.81579 roc_auc 0.68923 prc_auc 0.74590[0m
[92maverage training of epoch 24: loss -9.16164 acc 0.82000 roc_auc 0.82460 prc_auc 0.86497[0m
[93maverage test of epoch 24: loss -9.41013 acc 0.84211 roc_auc 0.85692 prc_auc 0.92323[0m
[92maverage training of epoch 25: loss -9.51640 acc 0.82667 roc_auc 0.84190 prc_auc 0.88769[0m
[93maverage test of epoch 25: loss -9.53913 acc 0.84211 roc_auc 0.87385 prc_auc 0.94702[0m
[92maverage training of epoch 26: loss -9.81273 acc 0.84000 roc_auc 0.82640 prc_auc 0.84660[0m
[93maverage test of epoch 26: loss -9.79334 acc 0.81579 roc_auc 0.88308 prc_auc 0.92899[0m
[92maverage training of epoch 27: loss -10.03310 acc 0.83333 roc_auc 0.79430 prc_auc 0.82668[0m
[93maverage test of epoch 27: loss -10.22875 acc 0.84211 roc_auc 0.84615 prc_auc 0.93399[0m
[92maverage training of epoch 28: loss -10.34887 acc 0.84000 roc_auc 0.82770 prc_auc 0.89116[0m
[93maverage test of epoch 28: loss -10.29906 acc 0.78947 roc_auc 0.84000 prc_auc 0.92384[0m
[92maverage training of epoch 29: loss -10.67250 acc 0.85333 roc_auc 0.81860 prc_auc 0.83121[0m
[93maverage test of epoch 29: loss -10.61673 acc 0.81579 roc_auc 0.74308 prc_auc 0.77435[0m
[92maverage training of epoch 30: loss -10.81666 acc 0.84000 roc_auc 0.77090 prc_auc 0.81573[0m
[93maverage test of epoch 30: loss -11.02648 acc 0.84211 roc_auc 0.79077 prc_auc 0.84007[0m
[92maverage training of epoch 31: loss -11.14484 acc 0.84000 roc_auc 0.81720 prc_auc 0.84334[0m
[93maverage test of epoch 31: loss -11.24170 acc 0.84211 roc_auc 0.82462 prc_auc 0.90736[0m
[92maverage training of epoch 32: loss -11.40200 acc 0.82667 roc_auc 0.80380 prc_auc 0.85626[0m
[93maverage test of epoch 32: loss -11.50051 acc 0.84211 roc_auc 0.88000 prc_auc 0.93949[0m
[92maverage training of epoch 33: loss -11.55119 acc 0.82000 roc_auc 0.79470 prc_auc 0.83484[0m
[93maverage test of epoch 33: loss -11.64690 acc 0.81579 roc_auc 0.89538 prc_auc 0.95302[0m
[92maverage training of epoch 34: loss -11.97107 acc 0.84667 roc_auc 0.81720 prc_auc 0.82254[0m
[93maverage test of epoch 34: loss -11.76230 acc 0.81579 roc_auc 0.76769 prc_auc 0.80344[0m
[92maverage training of epoch 35: loss -12.13926 acc 0.81333 roc_auc 0.80800 prc_auc 0.85170[0m
[93maverage test of epoch 35: loss -12.29251 acc 0.84211 roc_auc 0.84000 prc_auc 0.92966[0m
[92maverage training of epoch 36: loss -12.51498 acc 0.84000 roc_auc 0.82840 prc_auc 0.87052[0m
[93maverage test of epoch 36: loss -12.61833 acc 0.84211 roc_auc 0.88308 prc_auc 0.94953[0m
[92maverage training of epoch 37: loss -12.80879 acc 0.85333 roc_auc 0.82740 prc_auc 0.85590[0m
[93maverage test of epoch 37: loss -12.68809 acc 0.78947 roc_auc 0.88000 prc_auc 0.92020[0m
[92maverage training of epoch 38: loss -13.09129 acc 0.84667 roc_auc 0.83090 prc_auc 0.85445[0m
[93maverage test of epoch 38: loss -13.03729 acc 0.81579 roc_auc 0.87077 prc_auc 0.93824[0m
[92maverage training of epoch 39: loss -13.38841 acc 0.85333 roc_auc 0.80990 prc_auc 0.83663[0m
[93maverage test of epoch 39: loss -13.33949 acc 0.84211 roc_auc 0.83538 prc_auc 0.89882[0m
[92maverage training of epoch 40: loss -13.58612 acc 0.86000 roc_auc 0.80220 prc_auc 0.81230[0m
[93maverage test of epoch 40: loss -13.61830 acc 0.78947 roc_auc 0.85538 prc_auc 0.92602[0m
[92maverage training of epoch 41: loss -13.90010 acc 0.84000 roc_auc 0.81580 prc_auc 0.86007[0m
[93maverage test of epoch 41: loss -13.83900 acc 0.81579 roc_auc 0.85077 prc_auc 0.91089[0m
[92maverage training of epoch 42: loss -14.12873 acc 0.84000 roc_auc 0.81350 prc_auc 0.84575[0m
[93maverage test of epoch 42: loss -14.13234 acc 0.84211 roc_auc 0.87077 prc_auc 0.94683[0m
[92maverage training of epoch 43: loss -14.36457 acc 0.84000 roc_auc 0.83130 prc_auc 0.86803[0m
[93maverage test of epoch 43: loss -14.38618 acc 0.81579 roc_auc 0.90769 prc_auc 0.95239[0m
[92maverage training of epoch 44: loss -14.71822 acc 0.84667 roc_auc 0.81130 prc_auc 0.84193[0m
[93maverage test of epoch 44: loss -14.64359 acc 0.81579 roc_auc 0.89846 prc_auc 0.95119[0m
[92maverage training of epoch 45: loss -14.89521 acc 0.84667 roc_auc 0.83880 prc_auc 0.85548[0m
[93maverage test of epoch 45: loss -14.90955 acc 0.84211 roc_auc 0.85538 prc_auc 0.93203[0m
[92maverage training of epoch 46: loss -15.24369 acc 0.84667 roc_auc 0.83220 prc_auc 0.85556[0m
[93maverage test of epoch 46: loss -15.18936 acc 0.84211 roc_auc 0.84000 prc_auc 0.90377[0m
[92maverage training of epoch 47: loss -15.43766 acc 0.83333 roc_auc 0.81880 prc_auc 0.83648[0m
[93maverage test of epoch 47: loss -15.57812 acc 0.84211 roc_auc 0.84154 prc_auc 0.91025[0m
[92maverage training of epoch 48: loss -15.80152 acc 0.86000 roc_auc 0.80400 prc_auc 0.82699[0m
[93maverage test of epoch 48: loss -15.56802 acc 0.81579 roc_auc 0.85385 prc_auc 0.89487[0m
[92maverage training of epoch 49: loss -16.01923 acc 0.84667 roc_auc 0.82180 prc_auc 0.85159[0m
[93maverage test of epoch 49: loss -15.94491 acc 0.81579 roc_auc 0.85846 prc_auc 0.89912[0m
[92maverage training of epoch 50: loss -16.39709 acc 0.86000 roc_auc 0.83690 prc_auc 0.85590[0m
[93maverage test of epoch 50: loss -16.20761 acc 0.81579 roc_auc 0.87385 prc_auc 0.90164[0m
[92maverage training of epoch 51: loss -16.55384 acc 0.85333 roc_auc 0.81450 prc_auc 0.84527[0m
[93maverage test of epoch 51: loss -16.47023 acc 0.81579 roc_auc 0.86923 prc_auc 0.91863[0m
[92maverage training of epoch 52: loss -16.87093 acc 0.86000 roc_auc 0.82390 prc_auc 0.85923[0m
[93maverage test of epoch 52: loss -16.61920 acc 0.81579 roc_auc 0.84923 prc_auc 0.90762[0m
[92maverage training of epoch 53: loss -17.16682 acc 0.86000 roc_auc 0.81320 prc_auc 0.84389[0m
[93maverage test of epoch 53: loss -16.83118 acc 0.78947 roc_auc 0.89385 prc_auc 0.91458[0m
[92maverage training of epoch 54: loss -17.39121 acc 0.85333 roc_auc 0.81670 prc_auc 0.84830[0m
[93maverage test of epoch 54: loss -17.25112 acc 0.81579 roc_auc 0.86615 prc_auc 0.90827[0m
[92maverage training of epoch 55: loss -17.71618 acc 0.86000 roc_auc 0.82380 prc_auc 0.85175[0m
[93maverage test of epoch 55: loss -17.51418 acc 0.81579 roc_auc 0.78769 prc_auc 0.88026[0m
[92maverage training of epoch 56: loss -17.88587 acc 0.86667 roc_auc 0.82570 prc_auc 0.84288[0m
[93maverage test of epoch 56: loss -17.74925 acc 0.81579 roc_auc 0.81385 prc_auc 0.85370[0m
[92maverage training of epoch 57: loss -18.24460 acc 0.86000 roc_auc 0.81970 prc_auc 0.85584[0m
[93maverage test of epoch 57: loss -17.89791 acc 0.81579 roc_auc 0.81846 prc_auc 0.90380[0m
[92maverage training of epoch 58: loss -18.56424 acc 0.86667 roc_auc 0.84720 prc_auc 0.88725[0m
[93maverage test of epoch 58: loss -18.10779 acc 0.78947 roc_auc 0.88308 prc_auc 0.92365[0m
[92maverage training of epoch 59: loss -18.78657 acc 0.86000 roc_auc 0.82140 prc_auc 0.86651[0m
[93maverage test of epoch 59: loss -18.55608 acc 0.81579 roc_auc 0.84154 prc_auc 0.90770[0m
[92maverage training of epoch 60: loss -19.03346 acc 0.85333 roc_auc 0.82700 prc_auc 0.87064[0m
[93maverage test of epoch 60: loss -18.64639 acc 0.78947 roc_auc 0.82154 prc_auc 0.89233[0m
[92maverage training of epoch 61: loss -19.29452 acc 0.85333 roc_auc 0.83040 prc_auc 0.87254[0m
[93maverage test of epoch 61: loss -19.08160 acc 0.81579 roc_auc 0.84462 prc_auc 0.91068[0m
[92maverage training of epoch 62: loss -19.63691 acc 0.86667 roc_auc 0.82640 prc_auc 0.87239[0m
[93maverage test of epoch 62: loss -19.34054 acc 0.81579 roc_auc 0.85231 prc_auc 0.91401[0m
[92maverage training of epoch 63: loss -19.90343 acc 0.86667 roc_auc 0.84260 prc_auc 0.88230[0m
[93maverage test of epoch 63: loss -19.60088 acc 0.81579 roc_auc 0.85077 prc_auc 0.91209[0m
[92maverage training of epoch 64: loss -20.03531 acc 0.84667 roc_auc 0.84160 prc_auc 0.89217[0m
[93maverage test of epoch 64: loss -19.86152 acc 0.81579 roc_auc 0.83846 prc_auc 0.90035[0m
[92maverage training of epoch 65: loss -20.23535 acc 0.84000 roc_auc 0.81920 prc_auc 0.87606[0m
[93maverage test of epoch 65: loss -20.13953 acc 0.81579 roc_auc 0.86923 prc_auc 0.92130[0m
[92maverage training of epoch 66: loss -20.61033 acc 0.86000 roc_auc 0.83980 prc_auc 0.89059[0m
[93maverage test of epoch 66: loss -20.38614 acc 0.81579 roc_auc 0.82923 prc_auc 0.90577[0m
[92maverage training of epoch 67: loss -20.91250 acc 0.86000 roc_auc 0.83520 prc_auc 0.89210[0m
[93maverage test of epoch 67: loss -20.52018 acc 0.81579 roc_auc 0.88615 prc_auc 0.92490[0m
[92maverage training of epoch 68: loss -21.19182 acc 0.86000 roc_auc 0.84560 prc_auc 0.89516[0m
[93maverage test of epoch 68: loss -20.90423 acc 0.81579 roc_auc 0.88154 prc_auc 0.92418[0m
[92maverage training of epoch 69: loss -21.48466 acc 0.86667 roc_auc 0.83500 prc_auc 0.88785[0m
[93maverage test of epoch 69: loss -21.16434 acc 0.81579 roc_auc 0.90308 prc_auc 0.93096[0m
[92maverage training of epoch 70: loss -21.75985 acc 0.86667 roc_auc 0.86080 prc_auc 0.90942[0m
[93maverage test of epoch 70: loss -21.42354 acc 0.81579 roc_auc 0.86769 prc_auc 0.90861[0m
[92maverage training of epoch 71: loss -22.24793 acc 0.89333 roc_auc 0.88230 prc_auc 0.90354[0m
[93maverage test of epoch 71: loss -21.46505 acc 0.78947 roc_auc 0.81231 prc_auc 0.85460[0m
[92maverage training of epoch 72: loss -22.01855 acc 0.83333 roc_auc 0.84680 prc_auc 0.89259[0m
[93maverage test of epoch 72: loss -21.95294 acc 0.81579 roc_auc 0.87538 prc_auc 0.92332[0m
[92maverage training of epoch 73: loss -22.39823 acc 0.84667 roc_auc 0.82800 prc_auc 0.87382[0m
[93maverage test of epoch 73: loss -22.20256 acc 0.81579 roc_auc 0.84154 prc_auc 0.90852[0m
[92maverage training of epoch 74: loss -22.84190 acc 0.86667 roc_auc 0.85580 prc_auc 0.90882[0m
[93maverage test of epoch 74: loss -22.46704 acc 0.81579 roc_auc 0.86923 prc_auc 0.91865[0m
[92maverage training of epoch 75: loss -23.11056 acc 0.86667 roc_auc 0.85880 prc_auc 0.90941[0m
[93maverage test of epoch 75: loss -22.48269 acc 0.78947 roc_auc 0.84615 prc_auc 0.90819[0m
[92maverage training of epoch 76: loss -23.06847 acc 0.83333 roc_auc 0.80020 prc_auc 0.84538[0m
[93maverage test of epoch 76: loss -23.22147 acc 0.84211 roc_auc 0.84923 prc_auc 0.91387[0m
[92maverage training of epoch 77: loss -23.54343 acc 0.85333 roc_auc 0.85160 prc_auc 0.90170[0m
[93maverage test of epoch 77: loss -23.24614 acc 0.81579 roc_auc 0.89385 prc_auc 0.92591[0m
[92maverage training of epoch 78: loss -23.78537 acc 0.85333 roc_auc 0.85640 prc_auc 0.90765[0m
[93maverage test of epoch 78: loss -23.50551 acc 0.81579 roc_auc 0.89385 prc_auc 0.92730[0m
[92maverage training of epoch 79: loss -24.17439 acc 0.86667 roc_auc 0.86150 prc_auc 0.90987[0m
[93maverage test of epoch 79: loss -23.51886 acc 0.78947 roc_auc 0.84000 prc_auc 0.90941[0m
[92maverage training of epoch 80: loss -24.43908 acc 0.86667 roc_auc 0.86200 prc_auc 0.91077[0m
[93maverage test of epoch 80: loss -24.02594 acc 0.81579 roc_auc 0.78615 prc_auc 0.89099[0m
[92maverage training of epoch 81: loss -24.71294 acc 0.86667 roc_auc 0.87620 prc_auc 0.91609[0m
[93maverage test of epoch 81: loss -24.28571 acc 0.81579 roc_auc 0.82000 prc_auc 0.89969[0m
[92maverage training of epoch 82: loss -24.97850 acc 0.86667 roc_auc 0.82820 prc_auc 0.87964[0m
[93maverage test of epoch 82: loss -24.34136 acc 0.81579 roc_auc 0.84615 prc_auc 0.90642[0m
[92maverage training of epoch 83: loss -25.18316 acc 0.86000 roc_auc 0.85320 prc_auc 0.90725[0m
[93maverage test of epoch 83: loss -24.80862 acc 0.81579 roc_auc 0.86615 prc_auc 0.91541[0m
[92maverage training of epoch 84: loss -25.51194 acc 0.86667 roc_auc 0.85300 prc_auc 0.90769[0m
[93maverage test of epoch 84: loss -25.07267 acc 0.81579 roc_auc 0.90923 prc_auc 0.93365[0m
[92maverage training of epoch 85: loss -25.71822 acc 0.86000 roc_auc 0.84840 prc_auc 0.90046[0m
[93maverage test of epoch 85: loss -25.33068 acc 0.81579 roc_auc 0.85077 prc_auc 0.90900[0m
[92maverage training of epoch 86: loss -26.04996 acc 0.86667 roc_auc 0.85720 prc_auc 0.90899[0m
[93maverage test of epoch 86: loss -25.32532 acc 0.78947 roc_auc 0.80615 prc_auc 0.89535[0m
[92maverage training of epoch 87: loss -26.12047 acc 0.84667 roc_auc 0.84600 prc_auc 0.89855[0m
[93maverage test of epoch 87: loss -26.11937 acc 0.84211 roc_auc 0.82154 prc_auc 0.90551[0m
[92maverage training of epoch 88: loss -26.44234 acc 0.85333 roc_auc 0.83820 prc_auc 0.89090[0m
[93maverage test of epoch 88: loss -26.38534 acc 0.84211 roc_auc 0.87385 prc_auc 0.92109[0m
[92maverage training of epoch 89: loss -26.66188 acc 0.84667 roc_auc 0.84440 prc_auc 0.87921[0m
[93maverage test of epoch 89: loss -26.14426 acc 0.78947 roc_auc 0.76000 prc_auc 0.83896[0m
[92maverage training of epoch 90: loss -27.04529 acc 0.86000 roc_auc 0.84540 prc_auc 0.89921[0m
[93maverage test of epoch 90: loss -26.34990 acc 0.78947 roc_auc 0.84615 prc_auc 0.90798[0m
[92maverage training of epoch 91: loss -27.31107 acc 0.86000 roc_auc 0.86480 prc_auc 0.91158[0m
[93maverage test of epoch 91: loss -26.89181 acc 0.81579 roc_auc 0.86000 prc_auc 0.91699[0m
[92maverage training of epoch 92: loss -27.64810 acc 0.86667 roc_auc 0.85440 prc_auc 0.90787[0m
[93maverage test of epoch 92: loss -27.15246 acc 0.81579 roc_auc 0.87538 prc_auc 0.91924[0m
[92maverage training of epoch 93: loss -27.91724 acc 0.86667 roc_auc 0.85700 prc_auc 0.90925[0m
[93maverage test of epoch 93: loss -27.13240 acc 0.78947 roc_auc 0.87077 prc_auc 0.91666[0m
[92maverage training of epoch 94: loss -28.42347 acc 0.88667 roc_auc 0.86080 prc_auc 0.89758[0m
[93maverage test of epoch 94: loss -27.71652 acc 0.81579 roc_auc 0.82615 prc_auc 0.86390[0m
[92maverage training of epoch 95: loss -28.31247 acc 0.85333 roc_auc 0.85080 prc_auc 0.89560[0m
[93maverage test of epoch 95: loss -27.94642 acc 0.81579 roc_auc 0.86308 prc_auc 0.91818[0m
[92maverage training of epoch 96: loss -28.64474 acc 0.86000 roc_auc 0.85240 prc_auc 0.90695[0m
[93maverage test of epoch 96: loss -27.62296 acc 0.76316 roc_auc 0.85385 prc_auc 0.90966[0m
[92maverage training of epoch 97: loss -28.83633 acc 0.85333 roc_auc 0.85100 prc_auc 0.90604[0m
[93maverage test of epoch 97: loss -28.45571 acc 0.81579 roc_auc 0.83846 prc_auc 0.90902[0m
[92maverage training of epoch 98: loss -29.18821 acc 0.86000 roc_auc 0.84460 prc_auc 0.89398[0m
[93maverage test of epoch 98: loss -28.74759 acc 0.81579 roc_auc 0.82923 prc_auc 0.90445[0m
[92maverage training of epoch 99: loss -29.44372 acc 0.86000 roc_auc 0.85140 prc_auc 0.90635[0m
[93maverage test of epoch 99: loss -28.67064 acc 0.78947 roc_auc 0.86154 prc_auc 0.91346[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -1.31461 acc 0.66667 roc_auc 0.44820 prc_auc 0.64017[0m
[93maverage test of epoch 0: loss -1.93379 acc 0.65789 roc_auc 0.36923 prc_auc 0.62028[0m
[92maverage training of epoch 1: loss -2.85048 acc 0.66667 roc_auc 0.44800 prc_auc 0.61735[0m
[93maverage test of epoch 1: loss -3.65774 acc 0.65789 roc_auc 0.34154 prc_auc 0.60881[0m
[92maverage training of epoch 2: loss -4.20502 acc 0.66667 roc_auc 0.46340 prc_auc 0.65744[0m
[93maverage test of epoch 2: loss -4.65197 acc 0.65789 roc_auc 0.30769 prc_auc 0.59190[0m
[92maverage training of epoch 3: loss -5.01423 acc 0.66667 roc_auc 0.46600 prc_auc 0.67120[0m
[93maverage test of epoch 3: loss -5.30034 acc 0.65789 roc_auc 0.51077 prc_auc 0.72720[0m
[92maverage training of epoch 4: loss -5.57950 acc 0.66667 roc_auc 0.48940 prc_auc 0.66568[0m
[93maverage test of epoch 4: loss -5.81214 acc 0.65789 roc_auc 0.58154 prc_auc 0.71918[0m
[92maverage training of epoch 5: loss -6.04190 acc 0.66667 roc_auc 0.44440 prc_auc 0.63126[0m
[93maverage test of epoch 5: loss -6.23203 acc 0.65789 roc_auc 0.53231 prc_auc 0.68892[0m
[92maverage training of epoch 6: loss -6.43321 acc 0.66667 roc_auc 0.45260 prc_auc 0.62665[0m
[93maverage test of epoch 6: loss -6.60174 acc 0.65789 roc_auc 0.54769 prc_auc 0.72728[0m
[92maverage training of epoch 7: loss -6.81631 acc 0.66667 roc_auc 0.48680 prc_auc 0.65271[0m
[93maverage test of epoch 7: loss -6.95860 acc 0.65789 roc_auc 0.48615 prc_auc 0.70117[0m
[92maverage training of epoch 8: loss -7.16419 acc 0.66667 roc_auc 0.46420 prc_auc 0.66867[0m
[93maverage test of epoch 8: loss -7.29901 acc 0.65789 roc_auc 0.29538 prc_auc 0.56045[0m
[92maverage training of epoch 9: loss -7.50743 acc 0.66667 roc_auc 0.44120 prc_auc 0.63672[0m
[93maverage test of epoch 9: loss -7.63714 acc 0.65789 roc_auc 0.40615 prc_auc 0.61524[0m
[92maverage training of epoch 10: loss -7.84191 acc 0.66667 roc_auc 0.45770 prc_auc 0.63179[0m
[93maverage test of epoch 10: loss -7.97581 acc 0.65789 roc_auc 0.51385 prc_auc 0.64802[0m
[92maverage training of epoch 11: loss -8.16361 acc 0.66667 roc_auc 0.42220 prc_auc 0.61064[0m
[93maverage test of epoch 11: loss -8.29266 acc 0.65789 roc_auc 0.55077 prc_auc 0.76694[0m
[92maverage training of epoch 12: loss -8.49009 acc 0.66667 roc_auc 0.44200 prc_auc 0.61831[0m
[93maverage test of epoch 12: loss -8.60890 acc 0.65789 roc_auc 0.53231 prc_auc 0.71390[0m
[92maverage training of epoch 13: loss -8.80544 acc 0.66667 roc_auc 0.45840 prc_auc 0.63180[0m
[93maverage test of epoch 13: loss -8.93393 acc 0.65789 roc_auc 0.51538 prc_auc 0.71735[0m
[92maverage training of epoch 14: loss -9.12116 acc 0.66667 roc_auc 0.44800 prc_auc 0.62009[0m
[93maverage test of epoch 14: loss -9.24497 acc 0.65789 roc_auc 0.41846 prc_auc 0.63268[0m
[92maverage training of epoch 15: loss -9.43191 acc 0.66667 roc_auc 0.43900 prc_auc 0.61301[0m
[93maverage test of epoch 15: loss -9.54564 acc 0.65789 roc_auc 0.44000 prc_auc 0.62526[0m
[92maverage training of epoch 16: loss -9.73821 acc 0.66667 roc_auc 0.44060 prc_auc 0.62854[0m
[93maverage test of epoch 16: loss -9.86206 acc 0.65789 roc_auc 0.45385 prc_auc 0.63977[0m
[92maverage training of epoch 17: loss -10.05149 acc 0.66667 roc_auc 0.44380 prc_auc 0.61539[0m
[93maverage test of epoch 17: loss -10.16766 acc 0.65789 roc_auc 0.35231 prc_auc 0.66390[0m
[92maverage training of epoch 18: loss -10.35700 acc 0.66667 roc_auc 0.44580 prc_auc 0.63498[0m
[93maverage test of epoch 18: loss -10.47573 acc 0.65789 roc_auc 0.65231 prc_auc 0.77419[0m
[92maverage training of epoch 19: loss -10.66172 acc 0.66667 roc_auc 0.44210 prc_auc 0.60652[0m
[93maverage test of epoch 19: loss -10.77231 acc 0.65789 roc_auc 0.30923 prc_auc 0.61660[0m
[92maverage training of epoch 20: loss -10.96518 acc 0.66667 roc_auc 0.41240 prc_auc 0.59300[0m
[93maverage test of epoch 20: loss -11.08324 acc 0.65789 roc_auc 0.63846 prc_auc 0.81354[0m
[92maverage training of epoch 21: loss -11.26906 acc 0.66667 roc_auc 0.40480 prc_auc 0.59747[0m
[93maverage test of epoch 21: loss -11.38112 acc 0.65789 roc_auc 0.54308 prc_auc 0.68691[0m
[92maverage training of epoch 22: loss -11.57186 acc 0.66667 roc_auc 0.42010 prc_auc 0.59628[0m
[93maverage test of epoch 22: loss -11.68235 acc 0.65789 roc_auc 0.42154 prc_auc 0.62155[0m
[92maverage training of epoch 23: loss -11.87561 acc 0.66667 roc_auc 0.42310 prc_auc 0.60160[0m
[93maverage test of epoch 23: loss -11.98803 acc 0.65789 roc_auc 0.57538 prc_auc 0.78595[0m
[92maverage training of epoch 24: loss -12.17795 acc 0.66667 roc_auc 0.42620 prc_auc 0.61979[0m
[93maverage test of epoch 24: loss -12.29012 acc 0.65789 roc_auc 0.65538 prc_auc 0.75501[0m
[92maverage training of epoch 25: loss -12.48023 acc 0.66667 roc_auc 0.42670 prc_auc 0.61155[0m
[93maverage test of epoch 25: loss -12.58788 acc 0.65789 roc_auc 0.35692 prc_auc 0.61803[0m
[92maverage training of epoch 26: loss -12.77993 acc 0.66667 roc_auc 0.43010 prc_auc 0.60939[0m
[93maverage test of epoch 26: loss -12.88845 acc 0.65789 roc_auc 0.43846 prc_auc 0.67949[0m
[92maverage training of epoch 27: loss -13.08185 acc 0.66667 roc_auc 0.43400 prc_auc 0.62282[0m
[93maverage test of epoch 27: loss -13.18758 acc 0.65789 roc_auc 0.45077 prc_auc 0.62932[0m
[92maverage training of epoch 28: loss -13.38283 acc 0.66667 roc_auc 0.43390 prc_auc 0.64230[0m
[93maverage test of epoch 28: loss -13.48696 acc 0.65789 roc_auc 0.53077 prc_auc 0.69898[0m
[92maverage training of epoch 29: loss -13.68288 acc 0.66667 roc_auc 0.44020 prc_auc 0.62006[0m
[93maverage test of epoch 29: loss -13.78654 acc 0.65789 roc_auc 0.50000 prc_auc 0.72541[0m
[92maverage training of epoch 30: loss -13.98256 acc 0.66667 roc_auc 0.42090 prc_auc 0.60291[0m
[93maverage test of epoch 30: loss -14.08662 acc 0.65789 roc_auc 0.65231 prc_auc 0.77390[0m
[92maverage training of epoch 31: loss -14.28318 acc 0.66667 roc_auc 0.42900 prc_auc 0.60922[0m
[93maverage test of epoch 31: loss -14.38631 acc 0.65789 roc_auc 0.65846 prc_auc 0.77079[0m
[92maverage training of epoch 32: loss -14.58291 acc 0.66667 roc_auc 0.41900 prc_auc 0.59403[0m
[93maverage test of epoch 32: loss -14.68538 acc 0.65789 roc_auc 0.59692 prc_auc 0.70452[0m
[92maverage training of epoch 33: loss -14.88147 acc 0.66667 roc_auc 0.42050 prc_auc 0.60153[0m
[93maverage test of epoch 33: loss -14.98411 acc 0.65789 roc_auc 0.54000 prc_auc 0.70283[0m
[92maverage training of epoch 34: loss -15.18130 acc 0.66667 roc_auc 0.41160 prc_auc 0.60244[0m
[93maverage test of epoch 34: loss -15.28169 acc 0.65789 roc_auc 0.57385 prc_auc 0.74674[0m
[92maverage training of epoch 35: loss -15.48105 acc 0.66667 roc_auc 0.43080 prc_auc 0.62801[0m
[93maverage test of epoch 35: loss -15.57960 acc 0.65789 roc_auc 0.48923 prc_auc 0.67478[0m
[92maverage training of epoch 36: loss -15.78049 acc 0.66667 roc_auc 0.42720 prc_auc 0.60907[0m
[93maverage test of epoch 36: loss -15.87784 acc 0.65789 roc_auc 0.44615 prc_auc 0.61785[0m
[92maverage training of epoch 37: loss -16.07981 acc 0.66667 roc_auc 0.42230 prc_auc 0.60623[0m
[93maverage test of epoch 37: loss -16.17748 acc 0.65789 roc_auc 0.64615 prc_auc 0.78137[0m
[92maverage training of epoch 38: loss -16.37849 acc 0.66667 roc_auc 0.42490 prc_auc 0.60316[0m
[93maverage test of epoch 38: loss -16.47508 acc 0.65789 roc_auc 0.62923 prc_auc 0.74509[0m
[92maverage training of epoch 39: loss -16.67735 acc 0.66667 roc_auc 0.42060 prc_auc 0.60207[0m
[93maverage test of epoch 39: loss -16.77395 acc 0.65789 roc_auc 0.80154 prc_auc 0.88980[0m
[92maverage training of epoch 40: loss -16.97631 acc 0.66667 roc_auc 0.41930 prc_auc 0.60904[0m
[93maverage test of epoch 40: loss -17.06951 acc 0.65789 roc_auc 0.52000 prc_auc 0.66231[0m
[92maverage training of epoch 41: loss -17.27476 acc 0.66667 roc_auc 0.42110 prc_auc 0.59839[0m
[93maverage test of epoch 41: loss -17.36995 acc 0.65789 roc_auc 0.65077 prc_auc 0.78049[0m
[92maverage training of epoch 42: loss -17.57437 acc 0.66667 roc_auc 0.42380 prc_auc 0.61032[0m
[93maverage test of epoch 42: loss -17.66665 acc 0.65789 roc_auc 0.60769 prc_auc 0.74885[0m
[92maverage training of epoch 43: loss -17.87280 acc 0.66667 roc_auc 0.42640 prc_auc 0.61862[0m
[93maverage test of epoch 43: loss -17.96396 acc 0.65789 roc_auc 0.54000 prc_auc 0.69856[0m
[92maverage training of epoch 44: loss -18.17209 acc 0.66667 roc_auc 0.42880 prc_auc 0.61060[0m
[93maverage test of epoch 44: loss -18.26247 acc 0.65789 roc_auc 0.49692 prc_auc 0.71738[0m
[92maverage training of epoch 45: loss -18.47045 acc 0.66667 roc_auc 0.41840 prc_auc 0.60529[0m
[93maverage test of epoch 45: loss -18.56073 acc 0.65789 roc_auc 0.49231 prc_auc 0.64417[0m
[92maverage training of epoch 46: loss -18.76871 acc 0.66667 roc_auc 0.41910 prc_auc 0.59890[0m
[93maverage test of epoch 46: loss -18.85839 acc 0.65789 roc_auc 0.41846 prc_auc 0.59928[0m
[92maverage training of epoch 47: loss -19.06728 acc 0.66667 roc_auc 0.42070 prc_auc 0.60063[0m
[93maverage test of epoch 47: loss -19.15642 acc 0.65789 roc_auc 0.52000 prc_auc 0.66139[0m
[92maverage training of epoch 48: loss -19.36631 acc 0.66667 roc_auc 0.42020 prc_auc 0.59985[0m
[93maverage test of epoch 48: loss -19.45405 acc 0.65789 roc_auc 0.60615 prc_auc 0.75954[0m
[92maverage training of epoch 49: loss -19.66478 acc 0.66667 roc_auc 0.42090 prc_auc 0.60428[0m
[93maverage test of epoch 49: loss -19.75185 acc 0.65789 roc_auc 0.55231 prc_auc 0.71610[0m
[92maverage training of epoch 50: loss -19.96328 acc 0.66667 roc_auc 0.41870 prc_auc 0.60153[0m
[93maverage test of epoch 50: loss -20.04907 acc 0.65789 roc_auc 0.50615 prc_auc 0.67706[0m
[92maverage training of epoch 51: loss -20.26169 acc 0.66667 roc_auc 0.42890 prc_auc 0.60837[0m
[93maverage test of epoch 51: loss -20.34699 acc 0.65789 roc_auc 0.51692 prc_auc 0.67896[0m
[92maverage training of epoch 52: loss -20.56060 acc 0.66667 roc_auc 0.42300 prc_auc 0.60726[0m
[93maverage test of epoch 52: loss -20.64448 acc 0.65789 roc_auc 0.62000 prc_auc 0.74752[0m
[92maverage training of epoch 53: loss -20.85879 acc 0.66667 roc_auc 0.42100 prc_auc 0.60549[0m
[93maverage test of epoch 53: loss -20.94251 acc 0.65789 roc_auc 0.59077 prc_auc 0.71045[0m
[92maverage training of epoch 54: loss -21.15711 acc 0.66667 roc_auc 0.42030 prc_auc 0.60443[0m
[93maverage test of epoch 54: loss -21.23985 acc 0.65789 roc_auc 0.48462 prc_auc 0.65590[0m
[92maverage training of epoch 55: loss -21.45572 acc 0.66667 roc_auc 0.42250 prc_auc 0.60454[0m
[93maverage test of epoch 55: loss -21.53772 acc 0.65789 roc_auc 0.46615 prc_auc 0.64271[0m
[92maverage training of epoch 56: loss -21.75413 acc 0.66667 roc_auc 0.42080 prc_auc 0.60435[0m
[93maverage test of epoch 56: loss -21.83512 acc 0.65789 roc_auc 0.45231 prc_auc 0.63149[0m
[92maverage training of epoch 57: loss -22.05267 acc 0.66667 roc_auc 0.42010 prc_auc 0.59999[0m
[93maverage test of epoch 57: loss -22.13236 acc 0.65789 roc_auc 0.60154 prc_auc 0.72152[0m
[92maverage training of epoch 58: loss -22.35106 acc 0.66667 roc_auc 0.42110 prc_auc 0.60191[0m
[93maverage test of epoch 58: loss -22.43042 acc 0.65789 roc_auc 0.42615 prc_auc 0.62537[0m
[92maverage training of epoch 59: loss -22.64931 acc 0.66667 roc_auc 0.41970 prc_auc 0.60042[0m
[93maverage test of epoch 59: loss -22.72757 acc 0.65789 roc_auc 0.50154 prc_auc 0.65798[0m
[92maverage training of epoch 60: loss -22.94789 acc 0.66667 roc_auc 0.41980 prc_auc 0.60715[0m
[93maverage test of epoch 60: loss -23.02495 acc 0.65789 roc_auc 0.55846 prc_auc 0.68742[0m
[92maverage training of epoch 61: loss -23.24609 acc 0.66667 roc_auc 0.42040 prc_auc 0.60693[0m
[93maverage test of epoch 61: loss -23.32296 acc 0.65789 roc_auc 0.57077 prc_auc 0.69232[0m
[92maverage training of epoch 62: loss -23.54433 acc 0.66667 roc_auc 0.42250 prc_auc 0.60401[0m
[93maverage test of epoch 62: loss -23.62045 acc 0.65789 roc_auc 0.52923 prc_auc 0.67135[0m
[92maverage training of epoch 63: loss -23.84285 acc 0.66667 roc_auc 0.41920 prc_auc 0.60234[0m
[93maverage test of epoch 63: loss -23.91781 acc 0.65789 roc_auc 0.42000 prc_auc 0.62409[0m
[92maverage training of epoch 64: loss -24.14137 acc 0.66667 roc_auc 0.41840 prc_auc 0.60382[0m
[93maverage test of epoch 64: loss -24.21547 acc 0.65789 roc_auc 0.45846 prc_auc 0.63981[0m
[92maverage training of epoch 65: loss -24.43942 acc 0.66667 roc_auc 0.42160 prc_auc 0.60220[0m
[93maverage test of epoch 65: loss -24.51308 acc 0.65789 roc_auc 0.54308 prc_auc 0.67788[0m
[92maverage training of epoch 66: loss -24.73793 acc 0.66667 roc_auc 0.41990 prc_auc 0.60006[0m
[93maverage test of epoch 66: loss -24.81036 acc 0.65789 roc_auc 0.46154 prc_auc 0.64132[0m
[92maverage training of epoch 67: loss -25.03641 acc 0.66667 roc_auc 0.41950 prc_auc 0.60212[0m
[93maverage test of epoch 67: loss -25.10798 acc 0.65789 roc_auc 0.38000 prc_auc 0.60914[0m
[92maverage training of epoch 68: loss -25.33456 acc 0.66667 roc_auc 0.41960 prc_auc 0.59957[0m
[93maverage test of epoch 68: loss -25.40559 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 69: loss -25.63314 acc 0.66667 roc_auc 0.42210 prc_auc 0.60601[0m
[93maverage test of epoch 69: loss -25.70292 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 70: loss -25.93130 acc 0.66667 roc_auc 0.41770 prc_auc 0.59759[0m
[93maverage test of epoch 70: loss -26.00037 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 71: loss -26.22972 acc 0.66667 roc_auc 0.42010 prc_auc 0.60084[0m
[93maverage test of epoch 71: loss -26.29769 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 72: loss -26.52806 acc 0.66667 roc_auc 0.41770 prc_auc 0.60135[0m
[93maverage test of epoch 72: loss -26.59523 acc 0.65789 roc_auc 0.45231 prc_auc 0.63769[0m
[92maverage training of epoch 73: loss -26.82629 acc 0.66667 roc_auc 0.41630 prc_auc 0.59780[0m
[93maverage test of epoch 73: loss -26.89255 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 74: loss -27.12469 acc 0.66667 roc_auc 0.41870 prc_auc 0.59884[0m
[93maverage test of epoch 74: loss -27.18982 acc 0.65789 roc_auc 0.51846 prc_auc 0.66632[0m
[92maverage training of epoch 75: loss -27.42304 acc 0.66667 roc_auc 0.42470 prc_auc 0.61014[0m
[93maverage test of epoch 75: loss -27.48766 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 76: loss -27.72115 acc 0.66667 roc_auc 0.42180 prc_auc 0.60259[0m
[93maverage test of epoch 76: loss -27.78516 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 77: loss -28.01962 acc 0.66667 roc_auc 0.41930 prc_auc 0.60403[0m
[93maverage test of epoch 77: loss -28.08259 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 78: loss -28.31791 acc 0.66667 roc_auc 0.42320 prc_auc 0.60613[0m
[93maverage test of epoch 78: loss -28.38004 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 79: loss -28.61616 acc 0.66667 roc_auc 0.42350 prc_auc 0.61033[0m
[93maverage test of epoch 79: loss -28.67742 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 80: loss -28.91450 acc 0.66667 roc_auc 0.42210 prc_auc 0.60355[0m
[93maverage test of epoch 80: loss -28.97505 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 81: loss -29.21282 acc 0.66667 roc_auc 0.42760 prc_auc 0.61173[0m
[93maverage test of epoch 81: loss -29.27237 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 82: loss -29.51103 acc 0.66667 roc_auc 0.42410 prc_auc 0.60539[0m
[93maverage test of epoch 82: loss -29.56982 acc 0.65789 roc_auc 0.42308 prc_auc 0.65789[0m
[92maverage training of epoch 83: loss -29.80947 acc 0.66667 roc_auc 0.42490 prc_auc 0.61405[0m
[93maverage test of epoch 83: loss -29.86735 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 84: loss -30.10775 acc 0.66667 roc_auc 0.42340 prc_auc 0.60776[0m
[93maverage test of epoch 84: loss -30.16451 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 85: loss -30.40600 acc 0.66667 roc_auc 0.42550 prc_auc 0.60730[0m
[93maverage test of epoch 85: loss -30.46222 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 86: loss -30.70430 acc 0.66667 roc_auc 0.42590 prc_auc 0.60948[0m
[93maverage test of epoch 86: loss -30.75957 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 87: loss -31.00260 acc 0.66667 roc_auc 0.42260 prc_auc 0.60633[0m
[93maverage test of epoch 87: loss -31.05697 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 88: loss -31.30088 acc 0.66667 roc_auc 0.43030 prc_auc 0.62015[0m
[93maverage test of epoch 88: loss -31.35454 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 89: loss -31.59921 acc 0.66667 roc_auc 0.42840 prc_auc 0.61343[0m
[93maverage test of epoch 89: loss -31.65197 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -31.89749 acc 0.66667 roc_auc 0.42650 prc_auc 0.61267[0m
[93maverage test of epoch 90: loss -31.94945 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 91: loss -32.19576 acc 0.66667 roc_auc 0.43150 prc_auc 0.61809[0m
[93maverage test of epoch 91: loss -32.24688 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 92: loss -32.49409 acc 0.66667 roc_auc 0.42600 prc_auc 0.61624[0m
[93maverage test of epoch 92: loss -32.54429 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 93: loss -32.79230 acc 0.66667 roc_auc 0.43020 prc_auc 0.61813[0m
[93maverage test of epoch 93: loss -32.84185 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 94: loss -33.09064 acc 0.66667 roc_auc 0.43430 prc_auc 0.62094[0m
[93maverage test of epoch 94: loss -33.13920 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 95: loss -33.38892 acc 0.66667 roc_auc 0.44190 prc_auc 0.62943[0m
[93maverage test of epoch 95: loss -33.43668 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 96: loss -33.68726 acc 0.66667 roc_auc 0.42320 prc_auc 0.61758[0m
[93maverage test of epoch 96: loss -33.73413 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 97: loss -33.98551 acc 0.66667 roc_auc 0.45480 prc_auc 0.63626[0m
[93maverage test of epoch 97: loss -34.03150 acc 0.65789 roc_auc 0.44000 prc_auc 0.63209[0m
[92maverage training of epoch 98: loss -34.28386 acc 0.66667 roc_auc 0.43810 prc_auc 0.62905[0m
[93maverage test of epoch 98: loss -34.32899 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -34.58214 acc 0.66667 roc_auc 0.45140 prc_auc 0.63751[0m
[93maverage test of epoch 99: loss -34.62642 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.07750 acc 0.46000 roc_auc 0.39440 prc_auc 0.61556[0m
[93maverage test of epoch 0: loss -0.35274 acc 0.68421 roc_auc 0.67077 prc_auc 0.78984[0m
[92maverage training of epoch 1: loss -0.56851 acc 0.66000 roc_auc 0.47680 prc_auc 0.66753[0m
[93maverage test of epoch 1: loss -0.79604 acc 0.65789 roc_auc 0.60000 prc_auc 0.76812[0m
[92maverage training of epoch 2: loss -1.01591 acc 0.66667 roc_auc 0.44280 prc_auc 0.65474[0m
[93maverage test of epoch 2: loss -1.27418 acc 0.65789 roc_auc 0.61846 prc_auc 0.70640[0m
[92maverage training of epoch 3: loss -1.60610 acc 0.66667 roc_auc 0.49760 prc_auc 0.68676[0m
[93maverage test of epoch 3: loss -1.93160 acc 0.65789 roc_auc 0.50769 prc_auc 0.66977[0m
[92maverage training of epoch 4: loss -2.17353 acc 0.66667 roc_auc 0.38280 prc_auc 0.59211[0m
[93maverage test of epoch 4: loss -2.38953 acc 0.65789 roc_auc 0.51692 prc_auc 0.69834[0m
[92maverage training of epoch 5: loss -2.57203 acc 0.66667 roc_auc 0.39480 prc_auc 0.63472[0m
[93maverage test of epoch 5: loss -2.75821 acc 0.65789 roc_auc 0.68000 prc_auc 0.83310[0m
[92maverage training of epoch 6: loss -2.92488 acc 0.66667 roc_auc 0.45500 prc_auc 0.64567[0m
[93maverage test of epoch 6: loss -3.08981 acc 0.65789 roc_auc 0.72923 prc_auc 0.85421[0m
[92maverage training of epoch 7: loss -3.24906 acc 0.66667 roc_auc 0.33680 prc_auc 0.58576[0m
[93maverage test of epoch 7: loss -3.40622 acc 0.65789 roc_auc 0.50154 prc_auc 0.68887[0m
[92maverage training of epoch 8: loss -3.57230 acc 0.66667 roc_auc 0.48560 prc_auc 0.67129[0m
[93maverage test of epoch 8: loss -3.71283 acc 0.65789 roc_auc 0.46154 prc_auc 0.65064[0m
[92maverage training of epoch 9: loss -3.88344 acc 0.66667 roc_auc 0.40660 prc_auc 0.59919[0m
[93maverage test of epoch 9: loss -4.01717 acc 0.65789 roc_auc 0.46154 prc_auc 0.68900[0m
[92maverage training of epoch 10: loss -4.18823 acc 0.66667 roc_auc 0.40860 prc_auc 0.60285[0m
[93maverage test of epoch 10: loss -4.33328 acc 0.65789 roc_auc 0.47077 prc_auc 0.64361[0m
[92maverage training of epoch 11: loss -4.51252 acc 0.66667 roc_auc 0.40800 prc_auc 0.60556[0m
[93maverage test of epoch 11: loss -4.67727 acc 0.65789 roc_auc 0.54462 prc_auc 0.70780[0m
[92maverage training of epoch 12: loss -4.88344 acc 0.66667 roc_auc 0.41180 prc_auc 0.60349[0m
[93maverage test of epoch 12: loss -5.07807 acc 0.65789 roc_auc 0.60615 prc_auc 0.72282[0m
[92maverage training of epoch 13: loss -5.29536 acc 0.66667 roc_auc 0.44160 prc_auc 0.64978[0m
[93maverage test of epoch 13: loss -5.46707 acc 0.65789 roc_auc 0.47077 prc_auc 0.68013[0m
[92maverage training of epoch 14: loss -5.67047 acc 0.66667 roc_auc 0.40100 prc_auc 0.60112[0m
[93maverage test of epoch 14: loss -5.82456 acc 0.65789 roc_auc 0.69538 prc_auc 0.82279[0m
[92maverage training of epoch 15: loss -6.02245 acc 0.66667 roc_auc 0.41640 prc_auc 0.60481[0m
[93maverage test of epoch 15: loss -6.16455 acc 0.65789 roc_auc 0.51692 prc_auc 0.71873[0m
[92maverage training of epoch 16: loss -6.35994 acc 0.66667 roc_auc 0.40080 prc_auc 0.60531[0m
[93maverage test of epoch 16: loss -6.49544 acc 0.65789 roc_auc 0.50462 prc_auc 0.70511[0m
[92maverage training of epoch 17: loss -6.68934 acc 0.66667 roc_auc 0.39710 prc_auc 0.60086[0m
[93maverage test of epoch 17: loss -6.82327 acc 0.65789 roc_auc 0.44923 prc_auc 0.67271[0m
[92maverage training of epoch 18: loss -7.01186 acc 0.66667 roc_auc 0.37180 prc_auc 0.57324[0m
[93maverage test of epoch 18: loss -7.13872 acc 0.65789 roc_auc 0.46154 prc_auc 0.64088[0m
[92maverage training of epoch 19: loss -7.33020 acc 0.66667 roc_auc 0.37410 prc_auc 0.57618[0m
[93maverage test of epoch 19: loss -7.45579 acc 0.65789 roc_auc 0.52308 prc_auc 0.68549[0m
[92maverage training of epoch 20: loss -7.64726 acc 0.66667 roc_auc 0.37760 prc_auc 0.57538[0m
[93maverage test of epoch 20: loss -7.76934 acc 0.65789 roc_auc 0.46154 prc_auc 0.71287[0m
[92maverage training of epoch 21: loss -7.95916 acc 0.66667 roc_auc 0.38560 prc_auc 0.59713[0m
[93maverage test of epoch 21: loss -8.07866 acc 0.65789 roc_auc 0.48615 prc_auc 0.71607[0m
[92maverage training of epoch 22: loss -8.26920 acc 0.66667 roc_auc 0.38930 prc_auc 0.59697[0m
[93maverage test of epoch 22: loss -8.38946 acc 0.65789 roc_auc 0.60000 prc_auc 0.70280[0m
[92maverage training of epoch 23: loss -8.57802 acc 0.66667 roc_auc 0.39740 prc_auc 0.58605[0m
[93maverage test of epoch 23: loss -8.69571 acc 0.65789 roc_auc 0.43385 prc_auc 0.67205[0m
[92maverage training of epoch 24: loss -8.88407 acc 0.66667 roc_auc 0.39000 prc_auc 0.57762[0m
[93maverage test of epoch 24: loss -9.00010 acc 0.65789 roc_auc 0.56923 prc_auc 0.72641[0m
[92maverage training of epoch 25: loss -9.19050 acc 0.66667 roc_auc 0.38530 prc_auc 0.58603[0m
[93maverage test of epoch 25: loss -9.30529 acc 0.65789 roc_auc 0.45846 prc_auc 0.62550[0m
[92maverage training of epoch 26: loss -9.49555 acc 0.66667 roc_auc 0.37880 prc_auc 0.58102[0m
[93maverage test of epoch 26: loss -9.60873 acc 0.65789 roc_auc 0.61538 prc_auc 0.76839[0m
[92maverage training of epoch 27: loss -9.79935 acc 0.66667 roc_auc 0.39450 prc_auc 0.58720[0m
[93maverage test of epoch 27: loss -9.91354 acc 0.65789 roc_auc 0.46769 prc_auc 0.64849[0m
[92maverage training of epoch 28: loss -10.10275 acc 0.66667 roc_auc 0.37450 prc_auc 0.58194[0m
[93maverage test of epoch 28: loss -10.21525 acc 0.65789 roc_auc 0.44308 prc_auc 0.64087[0m
[92maverage training of epoch 29: loss -10.40431 acc 0.66667 roc_auc 0.37420 prc_auc 0.57993[0m
[93maverage test of epoch 29: loss -10.51529 acc 0.65789 roc_auc 0.68462 prc_auc 0.81850[0m
[92maverage training of epoch 30: loss -10.70707 acc 0.66667 roc_auc 0.38110 prc_auc 0.58684[0m
[93maverage test of epoch 30: loss -10.81588 acc 0.65789 roc_auc 0.36462 prc_auc 0.62672[0m
[92maverage training of epoch 31: loss -11.00822 acc 0.66667 roc_auc 0.39250 prc_auc 0.58430[0m
[93maverage test of epoch 31: loss -11.11685 acc 0.65789 roc_auc 0.49231 prc_auc 0.65931[0m
[92maverage training of epoch 32: loss -11.31067 acc 0.66667 roc_auc 0.38660 prc_auc 0.59413[0m
[93maverage test of epoch 32: loss -11.41724 acc 0.65789 roc_auc 0.45538 prc_auc 0.64793[0m
[92maverage training of epoch 33: loss -11.61043 acc 0.66667 roc_auc 0.38010 prc_auc 0.57939[0m
[93maverage test of epoch 33: loss -11.71520 acc 0.65789 roc_auc 0.50000 prc_auc 0.65235[0m
[92maverage training of epoch 34: loss -11.91128 acc 0.66667 roc_auc 0.38230 prc_auc 0.59181[0m
[93maverage test of epoch 34: loss -12.01644 acc 0.65789 roc_auc 0.63385 prc_auc 0.80773[0m
[92maverage training of epoch 35: loss -12.21142 acc 0.66667 roc_auc 0.38470 prc_auc 0.58890[0m
[93maverage test of epoch 35: loss -12.31389 acc 0.65789 roc_auc 0.43231 prc_auc 0.60166[0m
[92maverage training of epoch 36: loss -12.51097 acc 0.66667 roc_auc 0.38220 prc_auc 0.58002[0m
[93maverage test of epoch 36: loss -12.61438 acc 0.65789 roc_auc 0.47846 prc_auc 0.63215[0m
[92maverage training of epoch 37: loss -12.81125 acc 0.66667 roc_auc 0.38080 prc_auc 0.57947[0m
[93maverage test of epoch 37: loss -12.91344 acc 0.65789 roc_auc 0.42000 prc_auc 0.61822[0m
[92maverage training of epoch 38: loss -13.11081 acc 0.66667 roc_auc 0.38240 prc_auc 0.57815[0m
[93maverage test of epoch 38: loss -13.21143 acc 0.65789 roc_auc 0.40923 prc_auc 0.63835[0m
[92maverage training of epoch 39: loss -13.41015 acc 0.66667 roc_auc 0.38270 prc_auc 0.58060[0m
[93maverage test of epoch 39: loss -13.51018 acc 0.65789 roc_auc 0.56154 prc_auc 0.74888[0m
[92maverage training of epoch 40: loss -13.70981 acc 0.66667 roc_auc 0.37660 prc_auc 0.57899[0m
[93maverage test of epoch 40: loss -13.80964 acc 0.65789 roc_auc 0.60308 prc_auc 0.71440[0m
[92maverage training of epoch 41: loss -14.00909 acc 0.66667 roc_auc 0.37930 prc_auc 0.57675[0m
[93maverage test of epoch 41: loss -14.10658 acc 0.65789 roc_auc 0.42462 prc_auc 0.64487[0m
[92maverage training of epoch 42: loss -14.30798 acc 0.66667 roc_auc 0.37380 prc_auc 0.57152[0m
[93maverage test of epoch 42: loss -14.40492 acc 0.65789 roc_auc 0.56615 prc_auc 0.77206[0m
[92maverage training of epoch 43: loss -14.60667 acc 0.66667 roc_auc 0.38370 prc_auc 0.58864[0m
[93maverage test of epoch 43: loss -14.70268 acc 0.65789 roc_auc 0.57846 prc_auc 0.74917[0m
[92maverage training of epoch 44: loss -14.90568 acc 0.66667 roc_auc 0.38280 prc_auc 0.57975[0m
[93maverage test of epoch 44: loss -15.00116 acc 0.65789 roc_auc 0.55077 prc_auc 0.69212[0m
[92maverage training of epoch 45: loss -15.20369 acc 0.66667 roc_auc 0.38000 prc_auc 0.58355[0m
[93maverage test of epoch 45: loss -15.29907 acc 0.65789 roc_auc 0.48154 prc_auc 0.69222[0m
[92maverage training of epoch 46: loss -15.50358 acc 0.66667 roc_auc 0.38150 prc_auc 0.57849[0m
[93maverage test of epoch 46: loss -15.59734 acc 0.65789 roc_auc 0.42154 prc_auc 0.60484[0m
[92maverage training of epoch 47: loss -15.80207 acc 0.66667 roc_auc 0.37690 prc_auc 0.58318[0m
[93maverage test of epoch 47: loss -15.89521 acc 0.65789 roc_auc 0.55538 prc_auc 0.70104[0m
[92maverage training of epoch 48: loss -16.10090 acc 0.66667 roc_auc 0.38530 prc_auc 0.58775[0m
[93maverage test of epoch 48: loss -16.19254 acc 0.65789 roc_auc 0.63385 prc_auc 0.75232[0m
[92maverage training of epoch 49: loss -16.39952 acc 0.66667 roc_auc 0.38310 prc_auc 0.58141[0m
[93maverage test of epoch 49: loss -16.49084 acc 0.65789 roc_auc 0.40769 prc_auc 0.62445[0m
[92maverage training of epoch 50: loss -16.69808 acc 0.66667 roc_auc 0.38100 prc_auc 0.58154[0m
[93maverage test of epoch 50: loss -16.78774 acc 0.65789 roc_auc 0.36462 prc_auc 0.58646[0m
[92maverage training of epoch 51: loss -16.99690 acc 0.66667 roc_auc 0.37850 prc_auc 0.58244[0m
[93maverage test of epoch 51: loss -17.08533 acc 0.65789 roc_auc 0.65385 prc_auc 0.77924[0m
[92maverage training of epoch 52: loss -17.29539 acc 0.66667 roc_auc 0.38580 prc_auc 0.58299[0m
[93maverage test of epoch 52: loss -17.38316 acc 0.65789 roc_auc 0.41692 prc_auc 0.61734[0m
[92maverage training of epoch 53: loss -17.59359 acc 0.66667 roc_auc 0.37620 prc_auc 0.57356[0m
[93maverage test of epoch 53: loss -17.68114 acc 0.65789 roc_auc 0.48769 prc_auc 0.64804[0m
[92maverage training of epoch 54: loss -17.89216 acc 0.66667 roc_auc 0.37940 prc_auc 0.57760[0m
[93maverage test of epoch 54: loss -17.97855 acc 0.65789 roc_auc 0.40769 prc_auc 0.64104[0m
[92maverage training of epoch 55: loss -18.19067 acc 0.66667 roc_auc 0.37960 prc_auc 0.58341[0m
[93maverage test of epoch 55: loss -18.27666 acc 0.65789 roc_auc 0.32000 prc_auc 0.57925[0m
[92maverage training of epoch 56: loss -18.48929 acc 0.66667 roc_auc 0.38040 prc_auc 0.58496[0m
[93maverage test of epoch 56: loss -18.57422 acc 0.65789 roc_auc 0.54154 prc_auc 0.67543[0m
[92maverage training of epoch 57: loss -18.78758 acc 0.66667 roc_auc 0.37840 prc_auc 0.57659[0m
[93maverage test of epoch 57: loss -18.87164 acc 0.65789 roc_auc 0.64154 prc_auc 0.73946[0m
[92maverage training of epoch 58: loss -19.08604 acc 0.66667 roc_auc 0.37810 prc_auc 0.57724[0m
[93maverage test of epoch 58: loss -19.16857 acc 0.65789 roc_auc 0.43538 prc_auc 0.62715[0m
[92maverage training of epoch 59: loss -19.38392 acc 0.66667 roc_auc 0.37860 prc_auc 0.57296[0m
[93maverage test of epoch 59: loss -19.46684 acc 0.65789 roc_auc 0.54769 prc_auc 0.68424[0m
[92maverage training of epoch 60: loss -19.68275 acc 0.66667 roc_auc 0.37540 prc_auc 0.57959[0m
[93maverage test of epoch 60: loss -19.76414 acc 0.65789 roc_auc 0.40000 prc_auc 0.61296[0m
[92maverage training of epoch 61: loss -19.98117 acc 0.66667 roc_auc 0.37580 prc_auc 0.57979[0m
[93maverage test of epoch 61: loss -20.06171 acc 0.65789 roc_auc 0.44923 prc_auc 0.63227[0m
[92maverage training of epoch 62: loss -20.27938 acc 0.66667 roc_auc 0.37830 prc_auc 0.57668[0m
[93maverage test of epoch 62: loss -20.35936 acc 0.65789 roc_auc 0.48615 prc_auc 0.65202[0m
[92maverage training of epoch 63: loss -20.57785 acc 0.66667 roc_auc 0.37860 prc_auc 0.57740[0m
[93maverage test of epoch 63: loss -20.65673 acc 0.65789 roc_auc 0.60615 prc_auc 0.71075[0m
[92maverage training of epoch 64: loss -20.87616 acc 0.66667 roc_auc 0.37860 prc_auc 0.58351[0m
[93maverage test of epoch 64: loss -20.95406 acc 0.65789 roc_auc 0.42000 prc_auc 0.63071[0m
[92maverage training of epoch 65: loss -21.17446 acc 0.66667 roc_auc 0.37770 prc_auc 0.57927[0m
[93maverage test of epoch 65: loss -21.25175 acc 0.65789 roc_auc 0.45692 prc_auc 0.63870[0m
[92maverage training of epoch 66: loss -21.47282 acc 0.66667 roc_auc 0.37780 prc_auc 0.58023[0m
[93maverage test of epoch 66: loss -21.54903 acc 0.65789 roc_auc 0.55538 prc_auc 0.68465[0m
[92maverage training of epoch 67: loss -21.77120 acc 0.66667 roc_auc 0.37800 prc_auc 0.57548[0m
[93maverage test of epoch 67: loss -21.84655 acc 0.65789 roc_auc 0.51231 prc_auc 0.66432[0m
[92maverage training of epoch 68: loss -22.06943 acc 0.66667 roc_auc 0.37530 prc_auc 0.57808[0m
[93maverage test of epoch 68: loss -22.14416 acc 0.65789 roc_auc 0.44923 prc_auc 0.63574[0m
[92maverage training of epoch 69: loss -22.36795 acc 0.66667 roc_auc 0.37720 prc_auc 0.57740[0m
[93maverage test of epoch 69: loss -22.44158 acc 0.65789 roc_auc 0.44923 prc_auc 0.63666[0m
[92maverage training of epoch 70: loss -22.66622 acc 0.66667 roc_auc 0.37820 prc_auc 0.57696[0m
[93maverage test of epoch 70: loss -22.73910 acc 0.65789 roc_auc 0.39231 prc_auc 0.61696[0m
[92maverage training of epoch 71: loss -22.96450 acc 0.66667 roc_auc 0.37700 prc_auc 0.58457[0m
[93maverage test of epoch 71: loss -23.03645 acc 0.65789 roc_auc 0.58769 prc_auc 0.70272[0m
[92maverage training of epoch 72: loss -23.26272 acc 0.66667 roc_auc 0.38010 prc_auc 0.58199[0m
[93maverage test of epoch 72: loss -23.33393 acc 0.65789 roc_auc 0.48000 prc_auc 0.64902[0m
[92maverage training of epoch 73: loss -23.56102 acc 0.66667 roc_auc 0.37840 prc_auc 0.57851[0m
[93maverage test of epoch 73: loss -23.63142 acc 0.65789 roc_auc 0.48000 prc_auc 0.64902[0m
[92maverage training of epoch 74: loss -23.85936 acc 0.66667 roc_auc 0.37980 prc_auc 0.58380[0m
[93maverage test of epoch 74: loss -23.92857 acc 0.65789 roc_auc 0.53692 prc_auc 0.67536[0m
[92maverage training of epoch 75: loss -24.15756 acc 0.66667 roc_auc 0.37910 prc_auc 0.58118[0m
[93maverage test of epoch 75: loss -24.22621 acc 0.65789 roc_auc 0.37692 prc_auc 0.60931[0m
[92maverage training of epoch 76: loss -24.45583 acc 0.66667 roc_auc 0.37700 prc_auc 0.57934[0m
[93maverage test of epoch 76: loss -24.52349 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 77: loss -24.75418 acc 0.66667 roc_auc 0.37770 prc_auc 0.58377[0m
[93maverage test of epoch 77: loss -24.82100 acc 0.65789 roc_auc 0.51692 prc_auc 0.66561[0m
[92maverage training of epoch 78: loss -25.05245 acc 0.66667 roc_auc 0.38010 prc_auc 0.58083[0m
[93maverage test of epoch 78: loss -25.11858 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 79: loss -25.35069 acc 0.66667 roc_auc 0.38260 prc_auc 0.58300[0m
[93maverage test of epoch 79: loss -25.41579 acc 0.65789 roc_auc 0.46000 prc_auc 0.64041[0m
[92maverage training of epoch 80: loss -25.64897 acc 0.66667 roc_auc 0.37500 prc_auc 0.57991[0m
[93maverage test of epoch 80: loss -25.71344 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 81: loss -25.94728 acc 0.66667 roc_auc 0.38310 prc_auc 0.58618[0m
[93maverage test of epoch 81: loss -26.01080 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 82: loss -26.24551 acc 0.66667 roc_auc 0.38200 prc_auc 0.58603[0m
[93maverage test of epoch 82: loss -26.30819 acc 0.65789 roc_auc 0.46000 prc_auc 0.64041[0m
[92maverage training of epoch 83: loss -26.54382 acc 0.66667 roc_auc 0.37600 prc_auc 0.58368[0m
[93maverage test of epoch 83: loss -26.60568 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 84: loss -26.84206 acc 0.66667 roc_auc 0.38860 prc_auc 0.59449[0m
[93maverage test of epoch 84: loss -26.90306 acc 0.65789 roc_auc 0.55385 prc_auc 0.68330[0m
[92maverage training of epoch 85: loss -27.14038 acc 0.66667 roc_auc 0.38710 prc_auc 0.59351[0m
[93maverage test of epoch 85: loss -27.20048 acc 0.65789 roc_auc 0.63231 prc_auc 0.72428[0m
[92maverage training of epoch 86: loss -27.43859 acc 0.66667 roc_auc 0.38280 prc_auc 0.58894[0m
[93maverage test of epoch 86: loss -27.49795 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 87: loss -27.73695 acc 0.66667 roc_auc 0.37580 prc_auc 0.58646[0m
[93maverage test of epoch 87: loss -27.79526 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 88: loss -28.03520 acc 0.66667 roc_auc 0.38300 prc_auc 0.58944[0m
[93maverage test of epoch 88: loss -28.09276 acc 0.65789 roc_auc 0.52000 prc_auc 0.67158[0m
[92maverage training of epoch 89: loss -28.33340 acc 0.66667 roc_auc 0.38500 prc_auc 0.58783[0m
[93maverage test of epoch 89: loss -28.39010 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -28.63169 acc 0.66667 roc_auc 0.38010 prc_auc 0.58791[0m
[93maverage test of epoch 90: loss -28.68759 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 91: loss -28.92992 acc 0.66667 roc_auc 0.37610 prc_auc 0.58782[0m
[93maverage test of epoch 91: loss -28.98492 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 92: loss -29.22822 acc 0.66667 roc_auc 0.38750 prc_auc 0.59532[0m
[93maverage test of epoch 92: loss -29.28221 acc 0.65789 roc_auc 0.50462 prc_auc 0.66000[0m
[92maverage training of epoch 93: loss -29.52647 acc 0.66667 roc_auc 0.38260 prc_auc 0.59207[0m
[93maverage test of epoch 93: loss -29.57975 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 94: loss -29.82472 acc 0.66667 roc_auc 0.38620 prc_auc 0.59653[0m
[93maverage test of epoch 94: loss -29.87710 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 95: loss -30.12294 acc 0.66667 roc_auc 0.39660 prc_auc 0.60117[0m
[93maverage test of epoch 95: loss -30.17447 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 96: loss -30.42123 acc 0.66667 roc_auc 0.38700 prc_auc 0.60014[0m
[93maverage test of epoch 96: loss -30.47204 acc 0.65789 roc_auc 0.53846 prc_auc 0.67568[0m
[92maverage training of epoch 97: loss -30.71950 acc 0.66667 roc_auc 0.39280 prc_auc 0.60201[0m
[93maverage test of epoch 97: loss -30.76926 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 98: loss -31.01768 acc 0.66667 roc_auc 0.39240 prc_auc 0.60466[0m
[93maverage test of epoch 98: loss -31.06678 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -31.31596 acc 0.66667 roc_auc 0.37940 prc_auc 0.59635[0m
[93maverage test of epoch 99: loss -31.36423 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss 0.09586 acc 0.33775 roc_auc 0.45412 prc_auc 0.64767[0m
[93maverage test of epoch 0: loss -0.50334 acc 0.32432 roc_auc 0.60333 prc_auc 0.78835[0m
[92maverage training of epoch 1: loss -0.85577 acc 0.56291 roc_auc 0.59196 prc_auc 0.77551[0m
[93maverage test of epoch 1: loss -1.18128 acc 0.64865 roc_auc 0.74000 prc_auc 0.87308[0m
[92maverage training of epoch 2: loss -1.54758 acc 0.68874 roc_auc 0.76451 prc_auc 0.85513[0m
[93maverage test of epoch 2: loss -1.95145 acc 0.67568 roc_auc 0.86667 prc_auc 0.93481[0m
[92maverage training of epoch 3: loss -2.36170 acc 0.70199 roc_auc 0.83157 prc_auc 0.89839[0m
[93maverage test of epoch 3: loss -2.74027 acc 0.67568 roc_auc 0.86000 prc_auc 0.93110[0m
[92maverage training of epoch 4: loss -3.04427 acc 0.76159 roc_auc 0.85275 prc_auc 0.90523[0m
[93maverage test of epoch 4: loss -3.23326 acc 0.75676 roc_auc 0.81000 prc_auc 0.86113[0m
[92maverage training of epoch 5: loss -3.54236 acc 0.80132 roc_auc 0.85686 prc_auc 0.90121[0m
[93maverage test of epoch 5: loss -3.60624 acc 0.75676 roc_auc 0.86000 prc_auc 0.92497[0m
[92maverage training of epoch 6: loss -4.00148 acc 0.82119 roc_auc 0.85471 prc_auc 0.89551[0m
[93maverage test of epoch 6: loss -3.97278 acc 0.75676 roc_auc 0.87000 prc_auc 0.93811[0m
[92maverage training of epoch 7: loss -4.37665 acc 0.84106 roc_auc 0.85324 prc_auc 0.89779[0m
[93maverage test of epoch 7: loss -4.32703 acc 0.75676 roc_auc 0.79000 prc_auc 0.86757[0m
[92maverage training of epoch 8: loss -4.71579 acc 0.83444 roc_auc 0.84216 prc_auc 0.85797[0m
[93maverage test of epoch 8: loss -4.55369 acc 0.75676 roc_auc 0.74000 prc_auc 0.83306[0m
[92maverage training of epoch 9: loss -5.04281 acc 0.84768 roc_auc 0.82961 prc_auc 0.85550[0m
[93maverage test of epoch 9: loss -4.96410 acc 0.78378 roc_auc 0.77667 prc_auc 0.87033[0m
[92maverage training of epoch 10: loss -5.30203 acc 0.83444 roc_auc 0.84529 prc_auc 0.87148[0m
[93maverage test of epoch 10: loss -5.27402 acc 0.78378 roc_auc 0.82667 prc_auc 0.91018[0m
[92maverage training of epoch 11: loss -5.64615 acc 0.84106 roc_auc 0.83324 prc_auc 0.86774[0m
[93maverage test of epoch 11: loss -5.55034 acc 0.78378 roc_auc 0.82667 prc_auc 0.88232[0m
[92maverage training of epoch 12: loss -5.93049 acc 0.84768 roc_auc 0.82157 prc_auc 0.86902[0m
[93maverage test of epoch 12: loss -5.84335 acc 0.78378 roc_auc 0.78333 prc_auc 0.86663[0m
[92maverage training of epoch 13: loss -6.25755 acc 0.85430 roc_auc 0.81176 prc_auc 0.85991[0m
[93maverage test of epoch 13: loss -6.13686 acc 0.78378 roc_auc 0.83333 prc_auc 0.92098[0m
[92maverage training of epoch 14: loss -6.53773 acc 0.85430 roc_auc 0.84696 prc_auc 0.89011[0m
[93maverage test of epoch 14: loss -6.41641 acc 0.81081 roc_auc 0.80000 prc_auc 0.89681[0m
[92maverage training of epoch 15: loss -6.83702 acc 0.85430 roc_auc 0.83108 prc_auc 0.84464[0m
[93maverage test of epoch 15: loss -6.63870 acc 0.81081 roc_auc 0.78833 prc_auc 0.87258[0m
[92maverage training of epoch 16: loss -7.09693 acc 0.85430 roc_auc 0.85510 prc_auc 0.88623[0m
[93maverage test of epoch 16: loss -6.86947 acc 0.78378 roc_auc 0.79667 prc_auc 0.83917[0m
[92maverage training of epoch 17: loss -7.17334 acc 0.82781 roc_auc 0.82745 prc_auc 0.84756[0m
[93maverage test of epoch 17: loss -7.06506 acc 0.78378 roc_auc 0.75167 prc_auc 0.85348[0m
[92maverage training of epoch 18: loss -7.59620 acc 0.85430 roc_auc 0.83088 prc_auc 0.87073[0m
[93maverage test of epoch 18: loss -7.45227 acc 0.81081 roc_auc 0.78667 prc_auc 0.85842[0m
[92maverage training of epoch 19: loss -7.78726 acc 0.83444 roc_auc 0.80794 prc_auc 0.83411[0m
[93maverage test of epoch 19: loss -7.69264 acc 0.81081 roc_auc 0.70000 prc_auc 0.80465[0m
[92maverage training of epoch 20: loss -7.90923 acc 0.83444 roc_auc 0.83441 prc_auc 0.89496[0m
[93maverage test of epoch 20: loss -7.84402 acc 0.78378 roc_auc 0.81333 prc_auc 0.89600[0m
[92maverage training of epoch 21: loss -8.30800 acc 0.85430 roc_auc 0.82108 prc_auc 0.86352[0m
[93maverage test of epoch 21: loss -8.18207 acc 0.81081 roc_auc 0.81333 prc_auc 0.90811[0m
[92maverage training of epoch 22: loss -8.51090 acc 0.84768 roc_auc 0.82569 prc_auc 0.84766[0m
[93maverage test of epoch 22: loss -8.36121 acc 0.81081 roc_auc 0.76167 prc_auc 0.81281[0m
[92maverage training of epoch 23: loss -8.94944 acc 0.85430 roc_auc 0.83108 prc_auc 0.86725[0m
[93maverage test of epoch 23: loss -8.49859 acc 0.78378 roc_auc 0.73667 prc_auc 0.82741[0m
[92maverage training of epoch 24: loss -8.80076 acc 0.82781 roc_auc 0.82441 prc_auc 0.86769[0m
[93maverage test of epoch 24: loss -8.94889 acc 0.81081 roc_auc 0.74167 prc_auc 0.80793[0m
[92maverage training of epoch 25: loss -9.22236 acc 0.84106 roc_auc 0.83784 prc_auc 0.89453[0m
[93maverage test of epoch 25: loss -9.17081 acc 0.81081 roc_auc 0.85333 prc_auc 0.90410[0m
[92maverage training of epoch 26: loss -9.52405 acc 0.84106 roc_auc 0.80549 prc_auc 0.84903[0m
[93maverage test of epoch 26: loss -9.48079 acc 0.81081 roc_auc 0.74000 prc_auc 0.81169[0m
[92maverage training of epoch 27: loss -9.90766 acc 0.85430 roc_auc 0.83147 prc_auc 0.85831[0m
[93maverage test of epoch 27: loss -9.64057 acc 0.81081 roc_auc 0.77333 prc_auc 0.84100[0m
[92maverage training of epoch 28: loss -10.14119 acc 0.86093 roc_auc 0.83431 prc_auc 0.87671[0m
[93maverage test of epoch 28: loss -9.93485 acc 0.81081 roc_auc 0.75500 prc_auc 0.83207[0m
[92maverage training of epoch 29: loss -10.29935 acc 0.84106 roc_auc 0.80696 prc_auc 0.85438[0m
[93maverage test of epoch 29: loss -10.01006 acc 0.78378 roc_auc 0.76833 prc_auc 0.84555[0m
[92maverage training of epoch 30: loss -10.57937 acc 0.84768 roc_auc 0.83245 prc_auc 0.86673[0m
[93maverage test of epoch 30: loss -10.20976 acc 0.78378 roc_auc 0.85833 prc_auc 0.90433[0m
[92maverage training of epoch 31: loss -10.97476 acc 0.86755 roc_auc 0.84196 prc_auc 0.87885[0m
[93maverage test of epoch 31: loss -10.39429 acc 0.78378 roc_auc 0.78167 prc_auc 0.83835[0m
[92maverage training of epoch 32: loss -11.01223 acc 0.84768 roc_auc 0.83353 prc_auc 0.86210[0m
[93maverage test of epoch 32: loss -10.64909 acc 0.78378 roc_auc 0.79833 prc_auc 0.86664[0m
[92maverage training of epoch 33: loss -11.46888 acc 0.86755 roc_auc 0.82549 prc_auc 0.86131[0m
[93maverage test of epoch 33: loss -10.85307 acc 0.78378 roc_auc 0.72000 prc_auc 0.79429[0m
[92maverage training of epoch 34: loss -11.76680 acc 0.87417 roc_auc 0.83392 prc_auc 0.86649[0m
[93maverage test of epoch 34: loss -11.08961 acc 0.78378 roc_auc 0.73000 prc_auc 0.80563[0m
[92maverage training of epoch 35: loss -11.97880 acc 0.86093 roc_auc 0.84765 prc_auc 0.87245[0m
[93maverage test of epoch 35: loss -11.32602 acc 0.78378 roc_auc 0.77667 prc_auc 0.83588[0m
[92maverage training of epoch 36: loss -12.14440 acc 0.85430 roc_auc 0.81176 prc_auc 0.84730[0m
[93maverage test of epoch 36: loss -11.61192 acc 0.78378 roc_auc 0.76000 prc_auc 0.81425[0mUsing backend: pytorch

[92maverage training of epoch 37: loss -12.40632 acc 0.85430 roc_auc 0.80843 prc_auc 0.84769[0m
[93maverage test of epoch 37: loss -11.86178 acc 0.78378 roc_auc 0.74167 prc_auc 0.81621[0m
[92maverage training of epoch 38: loss -12.13648 acc 0.83444 roc_auc 0.82843 prc_auc 0.88202[0m
[93maverage test of epoch 38: loss -12.26138 acc 0.81081 roc_auc 0.81000 prc_auc 0.86515[0m
[92maverage training of epoch 39: loss -12.79931 acc 0.86093 roc_auc 0.86216 prc_auc 0.89808[0m
[93maverage test of epoch 39: loss -12.38909 acc 0.78378 roc_auc 0.73333 prc_auc 0.80670[0m
[92maverage training of epoch 40: loss -12.57302 acc 0.83444 roc_auc 0.82324 prc_auc 0.88989[0m
[93maverage test of epoch 40: loss -12.44887 acc 0.81081 roc_auc 0.80667 prc_auc 0.88016[0m
[92maverage training of epoch 41: loss -13.64870 acc 0.89404 roc_auc 0.88000 prc_auc 0.91177[0m
[93maverage test of epoch 41: loss -12.97552 acc 0.81081 roc_auc 0.77667 prc_auc 0.83604[0m
[92maverage training of epoch 42: loss -13.40862 acc 0.84768 roc_auc 0.82706 prc_auc 0.87040[0m
[93maverage test of epoch 42: loss -12.94493 acc 0.78378 roc_auc 0.73333 prc_auc 0.80645[0m
[92maverage training of epoch 43: loss -13.79928 acc 0.84768 roc_auc 0.82255 prc_auc 0.85712[0m
[93maverage test of epoch 43: loss -13.20987 acc 0.78378 roc_auc 0.73667 prc_auc 0.80756[0m
[92maverage training of epoch 44: loss -14.30480 acc 0.88079 roc_auc 0.86500 prc_auc 0.89573[0m
[93maverage test of epoch 44: loss -13.41006 acc 0.78378 roc_auc 0.73667 prc_auc 0.80702[0m
[92maverage training of epoch 45: loss -14.50041 acc 0.87417 roc_auc 0.86529 prc_auc 0.89625[0m
[93maverage test of epoch 45: loss -13.94578 acc 0.81081 roc_auc 0.80667 prc_auc 0.86357[0m
[92maverage training of epoch 46: loss -14.74752 acc 0.86093 roc_auc 0.81716 prc_auc 0.85367[0m
[93maverage test of epoch 46: loss -13.89118 acc 0.78378 roc_auc 0.74667 prc_auc 0.81047[0m
[92maverage training of epoch 47: loss -14.88130 acc 0.86755 roc_auc 0.84608 prc_auc 0.88000[0m
[93maverage test of epoch 47: loss -14.12118 acc 0.78378 roc_auc 0.73667 prc_auc 0.80726[0m
[92maverage training of epoch 48: loss -14.96469 acc 0.85430 roc_auc 0.84010 prc_auc 0.88181[0m
[93maverage test of epoch 48: loss -14.35116 acc 0.78378 roc_auc 0.73667 prc_auc 0.80789[0m
[92maverage training of epoch 49: loss -15.30397 acc 0.86093 roc_auc 0.84922 prc_auc 0.89030[0m
[93maverage test of epoch 49: loss -14.58124 acc 0.78378 roc_auc 0.74000 prc_auc 0.80830[0m
[92maverage training of epoch 50: loss -15.55719 acc 0.85430 roc_auc 0.83686 prc_auc 0.87232[0m
[93maverage test of epoch 50: loss -14.81652 acc 0.78378 roc_auc 0.72667 prc_auc 0.80438[0m
[92maverage training of epoch 51: loss -15.69742 acc 0.84768 roc_auc 0.81922 prc_auc 0.86120[0m
[93maverage test of epoch 51: loss -15.30960 acc 0.81081 roc_auc 0.77333 prc_auc 0.83482[0m
[92maverage training of epoch 52: loss -16.24954 acc 0.86093 roc_auc 0.82167 prc_auc 0.85633[0m
[93maverage test of epoch 52: loss -15.28436 acc 0.78378 roc_auc 0.72333 prc_auc 0.80372[0m
[92maverage training of epoch 53: loss -16.08995 acc 0.84768 roc_auc 0.81216 prc_auc 0.85408[0m
[93maverage test of epoch 53: loss -15.61215 acc 0.78378 roc_auc 0.78667 prc_auc 0.83874[0m
[92maverage training of epoch 54: loss -16.48714 acc 0.84768 roc_auc 0.83539 prc_auc 0.86681[0m
[93maverage test of epoch 54: loss -15.75902 acc 0.78378 roc_auc 0.75000 prc_auc 0.81116[0m
[92maverage training of epoch 55: loss -16.85067 acc 0.86755 roc_auc 0.85706 prc_auc 0.89361[0m
[93maverage test of epoch 55: loss -16.34566 acc 0.81081 roc_auc 0.74000 prc_auc 0.80892[0m
[92maverage training of epoch 56: loss -16.72961 acc 0.84768 roc_auc 0.85304 prc_auc 0.89014[0m
[93maverage test of epoch 56: loss -16.26714 acc 0.78378 roc_auc 0.76000 prc_auc 0.81425[0m
[92maverage training of epoch 57: loss -17.12070 acc 0.86093 roc_auc 0.86804 prc_auc 0.89549[0m
[93maverage test of epoch 57: loss -16.44619 acc 0.78378 roc_auc 0.73000 prc_auc 0.80601[0m
[92maverage training of epoch 58: loss -16.98694 acc 0.83444 roc_auc 0.82814 prc_auc 0.88145[0m
[93maverage test of epoch 58: loss -17.29912 acc 0.83784 roc_auc 0.79667 prc_auc 0.86095[0m
[92maverage training of epoch 59: loss -17.61739 acc 0.84768 roc_auc 0.82284 prc_auc 0.86318[0m
[93maverage test of epoch 59: loss -16.90576 acc 0.78378 roc_auc 0.74000 prc_auc 0.80864[0m
[92maverage training of epoch 60: loss -17.99353 acc 0.86755 roc_auc 0.83941 prc_auc 0.88256[0m
[93maverage test of epoch 60: loss -17.13593 acc 0.78378 roc_auc 0.75000 prc_auc 0.81157[0m
[92maverage training of epoch 61: loss -18.12548 acc 0.86093 roc_auc 0.84961 prc_auc 0.88999[0m
[93maverage test of epoch 61: loss -17.36403 acc 0.78378 roc_auc 0.72667 prc_auc 0.80516[0m
[92maverage training of epoch 62: loss -18.19505 acc 0.85430 roc_auc 0.84539 prc_auc 0.88804[0m
[93maverage test of epoch 62: loss -17.59370 acc 0.78378 roc_auc 0.72333 prc_auc 0.80435[0m
[92maverage training of epoch 63: loss -18.57703 acc 0.85430 roc_auc 0.85294 prc_auc 0.88652[0m
[93maverage test of epoch 63: loss -17.82310 acc 0.78378 roc_auc 0.72333 prc_auc 0.80435[0m
[92maverage training of epoch 64: loss -18.94867 acc 0.86755 roc_auc 0.85598 prc_auc 0.89259[0m
[93maverage test of epoch 64: loss -18.05726 acc 0.78378 roc_auc 0.75667 prc_auc 0.81330[0m
[92maverage training of epoch 65: loss -19.27950 acc 0.87417 roc_auc 0.84765 prc_auc 0.88500[0m
[93maverage test of epoch 65: loss -18.28791 acc 0.78378 roc_auc 0.72333 prc_auc 0.80435[0m
[92maverage training of epoch 66: loss -19.59211 acc 0.87417 roc_auc 0.85392 prc_auc 0.88806[0m
[93maverage test of epoch 66: loss -18.51533 acc 0.78378 roc_auc 0.71000 prc_auc 0.80012[0m
[92maverage training of epoch 67: loss -19.57462 acc 0.86093 roc_auc 0.84902 prc_auc 0.88504[0m
[93maverage test of epoch 67: loss -18.75197 acc 0.78378 roc_auc 0.72000 prc_auc 0.80359[0m
[92maverage training of epoch 68: loss -19.92756 acc 0.86093 roc_auc 0.85353 prc_auc 0.88723[0m
[93maverage test of epoch 68: loss -18.98318 acc 0.78378 roc_auc 0.75000 prc_auc 0.81157[0m
[92maverage training of epoch 69: loss -20.04475 acc 0.86093 roc_auc 0.82706 prc_auc 0.87826[0m
[93maverage test of epoch 69: loss -19.92445 acc 0.83784 roc_auc 0.82000 prc_auc 0.86754[0m
[92maverage training of epoch 70: loss -20.22708 acc 0.85430 roc_auc 0.83382 prc_auc 0.87529[0m
[93maverage test of epoch 70: loss -19.44852 acc 0.78378 roc_auc 0.75000 prc_auc 0.81157[0m
[92maverage training of epoch 71: loss -20.93568 acc 0.88079 roc_auc 0.85588 prc_auc 0.88859[0m
[93maverage test of epoch 71: loss -19.67736 acc 0.78378 roc_auc 0.72000 prc_auc 0.80359[0m
[92maverage training of epoch 72: loss -20.94154 acc 0.86755 roc_auc 0.85137 prc_auc 0.88675[0m
[93maverage test of epoch 72: loss -19.91075 acc 0.78378 roc_auc 0.73000 prc_auc 0.80591[0m
[92maverage training of epoch 73: loss -21.45693 acc 0.87417 roc_auc 0.85745 prc_auc 0.88980[0m
[93maverage test of epoch 73: loss -20.14251 acc 0.78378 roc_auc 0.73667 prc_auc 0.80726[0m
[92maverage training of epoch 74: loss -21.23871 acc 0.86093 roc_auc 0.83471 prc_auc 0.87987[0m
[93maverage test of epoch 74: loss -21.11833 acc 0.83784 roc_auc 0.81000 prc_auc 0.86525[0m
[92maverage training of epoch 75: loss -21.33100 acc 0.85430 roc_auc 0.83431 prc_auc 0.87999[0m
[93maverage test of epoch 75: loss -21.34238 acc 0.83784 roc_auc 0.80333 prc_auc 0.86327[0m
[92maverage training of epoch 76: loss -21.73628 acc 0.86093 roc_auc 0.83216 prc_auc 0.87946[0m
[93maverage test of epoch 76: loss -21.59079 acc 0.83784 roc_auc 0.81000 prc_auc 0.86487[0m
[92maverage training of epoch 77: loss -22.14382 acc 0.86755 roc_auc 0.85118 prc_auc 0.88669[0m
[93maverage test of epoch 77: loss -21.06533 acc 0.78378 roc_auc 0.75667 prc_auc 0.81302[0m
[92maverage training of epoch 78: loss -22.21230 acc 0.86093 roc_auc 0.83627 prc_auc 0.88100[0m
[93maverage test of epoch 78: loss -22.06558 acc 0.83784 roc_auc 0.80000 prc_auc 0.86246[0m
[92maverage training of epoch 79: loss -22.80277 acc 0.87417 roc_auc 0.85314 prc_auc 0.88820[0m
[93maverage test of epoch 79: loss -21.53027 acc 0.78378 roc_auc 0.74000 prc_auc 0.80808[0m
[92maverage training of epoch 80: loss -22.87835 acc 0.86755 roc_auc 0.84922 prc_auc 0.88612[0m
[93maverage test of epoch 80: loss -21.76004 acc 0.78378 roc_auc 0.72000 prc_auc 0.80359[0m
[92maverage training of epoch 81: loss -22.92620 acc 0.86093 roc_auc 0.83490 prc_auc 0.88069[0m
[93maverage test of epoch 81: loss -22.78328 acc 0.83784 roc_auc 0.84333 prc_auc 0.87502[0m
[92maverage training of epoch 82: loss -23.44554 acc 0.86093 roc_auc 0.83078 prc_auc 0.86172[0m
[93maverage test of epoch 82: loss -21.34592 acc 0.70270 roc_auc 0.58833 prc_auc 0.71812[0m
[92maverage training of epoch 83: loss -23.31475 acc 0.83444 roc_auc 0.78745 prc_auc 0.83094[0m
[93maverage test of epoch 83: loss -22.45566 acc 0.78378 roc_auc 0.69667 prc_auc 0.79702[0m
[92maverage training of epoch 84: loss -24.10079 acc 0.87417 roc_auc 0.85235 prc_auc 0.88320[0m
[93maverage test of epoch 84: loss -22.69240 acc 0.78378 roc_auc 0.74000 prc_auc 0.80864[0m
[92maverage training of epoch 85: loss -24.25210 acc 0.87417 roc_auc 0.85510 prc_auc 0.88861[0m
[93maverage test of epoch 85: loss -22.97072 acc 0.78378 roc_auc 0.76000 prc_auc 0.81415[0m
[92maverage training of epoch 86: loss -24.14694 acc 0.86093 roc_auc 0.83294 prc_auc 0.88014[0m
[93maverage test of epoch 86: loss -23.97818 acc 0.83784 roc_auc 0.79667 prc_auc 0.86118[0m
[92maverage training of epoch 87: loss -24.79128 acc 0.86755 roc_auc 0.84657 prc_auc 0.87219[0m
[93maverage test of epoch 87: loss -23.27365 acc 0.75676 roc_auc 0.67167 prc_auc 0.76390[0m
[92maverage training of epoch 88: loss -24.70810 acc 0.86755 roc_auc 0.84422 prc_auc 0.88854[0m
[93maverage test of epoch 88: loss -24.45502 acc 0.83784 roc_auc 0.81000 prc_auc 0.86580[0m
[92maverage training of epoch 89: loss -25.64840 acc 0.88742 roc_auc 0.84725 prc_auc 0.87804[0m
[93maverage test of epoch 89: loss -23.86064 acc 0.78378 roc_auc 0.73667 prc_auc 0.80756[0m
[92maverage training of epoch 90: loss -25.21891 acc 0.86755 roc_auc 0.84539 prc_auc 0.88932[0m
[93maverage test of epoch 90: loss -25.00844 acc 0.83784 roc_auc 0.81000 prc_auc 0.86580[0m
[92maverage training of epoch 91: loss -25.20634 acc 0.86093 roc_auc 0.84471 prc_auc 0.89330[0m
[93maverage test of epoch 91: loss -25.17140 acc 0.83784 roc_auc 0.81000 prc_auc 0.86534[0m
[92maverage training of epoch 92: loss -26.32734 acc 0.88742 roc_auc 0.86196 prc_auc 0.89212[0m
[93maverage test of epoch 92: loss -24.98250 acc 0.81081 roc_auc 0.78667 prc_auc 0.83874[0m
[92maverage training of epoch 93: loss -26.17299 acc 0.86755 roc_auc 0.85098 prc_auc 0.88726[0m
[93maverage test of epoch 93: loss -25.21404 acc 0.81081 roc_auc 0.77333 prc_auc 0.83525[0m
[92maverage training of epoch 94: loss -26.70373 acc 0.87417 roc_auc 0.84569 prc_auc 0.87256[0m
[93maverage test of epoch 94: loss -24.46219 acc 0.72973 roc_auc 0.62667 prc_auc 0.73945[0m
[92maverage training of epoch 95: loss -26.21865 acc 0.85430 roc_auc 0.83255 prc_auc 0.87959[0m
[93maverage test of epoch 95: loss -26.13178 acc 0.83784 roc_auc 0.81333 prc_auc 0.86537[0m
[92maverage training of epoch 96: loss -27.20404 acc 0.87417 roc_auc 0.84824 prc_auc 0.87345[0m
[93maverage test of epoch 96: loss -24.91954 acc 0.72973 roc_auc 0.61667 prc_auc 0.73704[0m
[92maverage training of epoch 97: loss -27.29370 acc 0.86755 roc_auc 0.83814 prc_auc 0.86968[0m
[93maverage test of epoch 97: loss -25.72256 acc 0.78378 roc_auc 0.74333 prc_auc 0.81002[0m
[92maverage training of epoch 98: loss -27.24539 acc 0.86755 roc_auc 0.84255 prc_auc 0.88354[0m
[93maverage test of epoch 98: loss -26.81656 acc 0.83784 roc_auc 0.83667 prc_auc 0.87273[0m
[92maverage training of epoch 99: loss -28.27199 acc 0.89404 roc_auc 0.85686 prc_auc 0.88619[0m
[93maverage test of epoch 99: loss -26.19337 acc 0.78378 roc_auc 0.74333 prc_auc 0.80967[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.59569 acc 0.48344 roc_auc 0.42647 prc_auc 0.62370[0m
[93maverage test of epoch 0: loss -1.08053 acc 0.67568 roc_auc 0.64000 prc_auc 0.72966[0m
[92maverage training of epoch 1: loss -1.46670 acc 0.65563 roc_auc 0.43353 prc_auc 0.62222[0m
[93maverage test of epoch 1: loss -1.88176 acc 0.67568 roc_auc 0.54667 prc_auc 0.76054[0m
[92maverage training of epoch 2: loss -2.49007 acc 0.66225 roc_auc 0.42333 prc_auc 0.61013[0m
[93maverage test of epoch 2: loss -3.28381 acc 0.67568 roc_auc 0.76667 prc_auc 0.82763[0m
[92maverage training of epoch 3: loss -3.93534 acc 0.66225 roc_auc 0.45118 prc_auc 0.64939[0m
[93maverage test of epoch 3: loss -4.45707 acc 0.67568 roc_auc 0.52667 prc_auc 0.72506[0m
[92maverage training of epoch 4: loss -4.75336 acc 0.66225 roc_auc 0.46431 prc_auc 0.65684[0m
[93maverage test of epoch 4: loss -5.07985 acc 0.67568 roc_auc 0.45333 prc_auc 0.66410[0m
[92maverage training of epoch 5: loss -5.28191 acc 0.66225 roc_auc 0.39745 prc_auc 0.60088[0m
[93maverage test of epoch 5: loss -5.52436 acc 0.67568 roc_auc 0.51000 prc_auc 0.73575[0m
[92maverage training of epoch 6: loss -5.71389 acc 0.66225 roc_auc 0.40941 prc_auc 0.59338[0m
[93maverage test of epoch 6: loss -5.93633 acc 0.67568 roc_auc 0.56333 prc_auc 0.75983[0m
[92maverage training of epoch 7: loss -6.10695 acc 0.66225 roc_auc 0.40471 prc_auc 0.59862[0m
[93maverage test of epoch 7: loss -6.32507 acc 0.67568 roc_auc 0.52000 prc_auc 0.73124[0m
[92maverage training of epoch 8: loss -6.47140 acc 0.66225 roc_auc 0.37706 prc_auc 0.57206[0m
[93maverage test of epoch 8: loss -6.67974 acc 0.67568 roc_auc 0.53167 prc_auc 0.66489[0m
[92maverage training of epoch 9: loss -6.81991 acc 0.66225 roc_auc 0.38980 prc_auc 0.58275[0m
[93maverage test of epoch 9: loss -7.02748 acc 0.67568 roc_auc 0.54000 prc_auc 0.71527[0m
[92maverage training of epoch 10: loss -7.15715 acc 0.66225 roc_auc 0.35745 prc_auc 0.56574[0m
[93maverage test of epoch 10: loss -7.35048 acc 0.67568 roc_auc 0.56333 prc_auc 0.77113[0m
[92maverage training of epoch 11: loss -7.48749 acc 0.66225 roc_auc 0.36824 prc_auc 0.56157[0m
[93maverage test of epoch 11: loss -7.68654 acc 0.67568 roc_auc 0.43333 prc_auc 0.63180[0m
[92maverage training of epoch 12: loss -7.81750 acc 0.66225 roc_auc 0.37608 prc_auc 0.57886[0m
[93maverage test of epoch 12: loss -8.01141 acc 0.67568 roc_auc 0.44000 prc_auc 0.68286[0m
[92maverage training of epoch 13: loss -8.13881 acc 0.66225 roc_auc 0.37882 prc_auc 0.57548[0m
[93maverage test of epoch 13: loss -8.33315 acc 0.67568 roc_auc 0.37667 prc_auc 0.66045[0m
[92maverage training of epoch 14: loss -8.45688 acc 0.66225 roc_auc 0.37275 prc_auc 0.58069[0m
[93maverage test of epoch 14: loss -8.65191 acc 0.67568 roc_auc 0.56000 prc_auc 0.76601[0m
[92maverage training of epoch 15: loss -8.77201 acc 0.66225 roc_auc 0.36569 prc_auc 0.56958[0m
[93maverage test of epoch 15: loss -8.96451 acc 0.67568 roc_auc 0.40333 prc_auc 0.63428[0m
[92maverage training of epoch 16: loss -9.08291 acc 0.66225 roc_auc 0.36725 prc_auc 0.56914[0m
[93maverage test of epoch 16: loss -9.26896 acc 0.67568 roc_auc 0.42000 prc_auc 0.62719[0m
[92maverage training of epoch 17: loss -9.39459 acc 0.66225 roc_auc 0.37216 prc_auc 0.56938[0m
[93maverage test of epoch 17: loss -9.58473 acc 0.67568 roc_auc 0.47000 prc_auc 0.68258[0m
[92maverage training of epoch 18: loss -9.70384 acc 0.66225 roc_auc 0.37255 prc_auc 0.58606[0m
[93maverage test of epoch 18: loss -9.89740 acc 0.67568 roc_auc 0.33333 prc_auc 0.63742[0m
[92maverage training of epoch 19: loss -10.00913 acc 0.66225 roc_auc 0.37725 prc_auc 0.58136[0m
[93maverage test of epoch 19: loss -10.20501 acc 0.67568 roc_auc 0.40333 prc_auc 0.61431[0m
[92maverage training of epoch 20: loss -10.31770 acc 0.66225 roc_auc 0.36078 prc_auc 0.56345[0m
[93maverage test of epoch 20: loss -10.51287 acc 0.67568 roc_auc 0.51667 prc_auc 0.73632[0m
[92maverage training of epoch 21: loss -10.62385 acc 0.66225 roc_auc 0.37373 prc_auc 0.56903[0m
[93maverage test of epoch 21: loss -10.82192 acc 0.67568 roc_auc 0.52000 prc_auc 0.79071[0m
[92maverage training of epoch 22: loss -10.92796 acc 0.66225 roc_auc 0.37961 prc_auc 0.59378[0m
[93maverage test of epoch 22: loss -11.12494 acc 0.67568 roc_auc 0.46833 prc_auc 0.65414[0m
[92maverage training of epoch 23: loss -11.23139 acc 0.66225 roc_auc 0.37137 prc_auc 0.58021[0m
[93maverage test of epoch 23: loss -11.43137 acc 0.67568 roc_auc 0.54667 prc_auc 0.71523[0m
[92maverage training of epoch 24: loss -11.53550 acc 0.66225 roc_auc 0.37843 prc_auc 0.59125[0m
[93maverage test of epoch 24: loss -11.73387 acc 0.67568 roc_auc 0.53833 prc_auc 0.67789[0m
[92maverage training of epoch 25: loss -11.83916 acc 0.66225 roc_auc 0.37667 prc_auc 0.58482[0m
[93maverage test of epoch 25: loss -12.04319 acc 0.67568 roc_auc 0.75833 prc_auc 0.87514[0m
[92maverage training of epoch 26: loss -12.14033 acc 0.66225 roc_auc 0.36510 prc_auc 0.56627[0m
[93maverage test of epoch 26: loss -12.34360 acc 0.67568 roc_auc 0.50500 prc_auc 0.64353[0m
[92maverage training of epoch 27: loss -12.44484 acc 0.66225 roc_auc 0.36745 prc_auc 0.56967[0m
[93maverage test of epoch 27: loss -12.64701 acc 0.67568 roc_auc 0.40500 prc_auc 0.64678[0m
[92maverage training of epoch 28: loss -12.74692 acc 0.66225 roc_auc 0.36549 prc_auc 0.56770[0m
[93maverage test of epoch 28: loss -12.95063 acc 0.67568 roc_auc 0.54667 prc_auc 0.67141[0m
[92maverage training of epoch 29: loss -13.04800 acc 0.66225 roc_auc 0.37373 prc_auc 0.58122[0m
[93maverage test of epoch 29: loss -13.25307 acc 0.67568 roc_auc 0.40167 prc_auc 0.64216[0m
[92maverage training of epoch 30: loss -13.35022 acc 0.66225 roc_auc 0.37392 prc_auc 0.57276[0m
[93maverage test of epoch 30: loss -13.55669 acc 0.67568 roc_auc 0.60000 prc_auc 0.74309[0m
[92maverage training of epoch 31: loss -13.65073 acc 0.66225 roc_auc 0.36745 prc_auc 0.56817[0m
[93maverage test of epoch 31: loss -13.85934 acc 0.67568 roc_auc 0.47667 prc_auc 0.66814[0m
[92maverage training of epoch 32: loss -13.95196 acc 0.66225 roc_auc 0.37980 prc_auc 0.57654[0m
[93maverage test of epoch 32: loss -14.16167 acc 0.67568 roc_auc 0.52667 prc_auc 0.70909[0m
[92maverage training of epoch 33: loss -14.25326 acc 0.66225 roc_auc 0.37235 prc_auc 0.57229[0m
[93maverage test of epoch 33: loss -14.46236 acc 0.67568 roc_auc 0.44167 prc_auc 0.65430[0m
[92maverage training of epoch 34: loss -14.55400 acc 0.66225 roc_auc 0.36196 prc_auc 0.56511[0m
[93maverage test of epoch 34: loss -14.76617 acc 0.67568 roc_auc 0.38500 prc_auc 0.60499[0m
[92maverage training of epoch 35: loss -14.85479 acc 0.66225 roc_auc 0.36902 prc_auc 0.57152[0m
[93maverage test of epoch 35: loss -15.06815 acc 0.67568 roc_auc 0.63000 prc_auc 0.78227[0m
[92maverage training of epoch 36: loss -15.15553 acc 0.66225 roc_auc 0.36804 prc_auc 0.56563[0m
[93maverage test of epoch 36: loss -15.36901 acc 0.67568 roc_auc 0.48000 prc_auc 0.67472[0m
[92maverage training of epoch 37: loss -15.45594 acc 0.66225 roc_auc 0.36618 prc_auc 0.56549[0m
[93maverage test of epoch 37: loss -15.67112 acc 0.67568 roc_auc 0.60000 prc_auc 0.73126[0m
[92maverage training of epoch 38: loss -15.75655 acc 0.66225 roc_auc 0.37588 prc_auc 0.57522[0m
[93maverage test of epoch 38: loss -15.97210 acc 0.67568 roc_auc 0.64333 prc_auc 0.73755[0m
[92maverage training of epoch 39: loss -16.05632 acc 0.66225 roc_auc 0.36608 prc_auc 0.56716[0m
[93maverage test of epoch 39: loss -16.27456 acc 0.67568 roc_auc 0.51000 prc_auc 0.69230[0m
[92maverage training of epoch 40: loss -16.35576 acc 0.66225 roc_auc 0.36696 prc_auc 0.56617[0m
[93maverage test of epoch 40: loss -16.57492 acc 0.67568 roc_auc 0.51000 prc_auc 0.67898[0m
[92maverage training of epoch 41: loss -16.65630 acc 0.66225 roc_auc 0.37039 prc_auc 0.57073[0m
[93maverage test of epoch 41: loss -16.87646 acc 0.67568 roc_auc 0.35167 prc_auc 0.63062[0m
[92maverage training of epoch 42: loss -16.95695 acc 0.66225 roc_auc 0.36863 prc_auc 0.56893[0m
[93maverage test of epoch 42: loss -17.17888 acc 0.67568 roc_auc 0.54500 prc_auc 0.70643[0m
[92maverage training of epoch 43: loss -17.25749 acc 0.66225 roc_auc 0.36941 prc_auc 0.56901[0m
[93maverage test of epoch 43: loss -17.48009 acc 0.67568 roc_auc 0.41833 prc_auc 0.63164[0m
[92maverage training of epoch 44: loss -17.55697 acc 0.66225 roc_auc 0.36941 prc_auc 0.56959[0m
[93maverage test of epoch 44: loss -17.78091 acc 0.67568 roc_auc 0.71333 prc_auc 0.82046[0m
[92maverage training of epoch 45: loss -17.85673 acc 0.66225 roc_auc 0.36696 prc_auc 0.57083[0m
[93maverage test of epoch 45: loss -18.08215 acc 0.67568 roc_auc 0.43333 prc_auc 0.68031[0m
[92maverage training of epoch 46: loss -18.15682 acc 0.66225 roc_auc 0.36735 prc_auc 0.56771[0m
[93maverage test of epoch 46: loss -18.38330 acc 0.67568 roc_auc 0.37000 prc_auc 0.60934[0m
[92maverage training of epoch 47: loss -18.45712 acc 0.66225 roc_auc 0.36902 prc_auc 0.57056[0m
[93maverage test of epoch 47: loss -18.68492 acc 0.67568 roc_auc 0.38167 prc_auc 0.61472[0m
[92maverage training of epoch 48: loss -18.75697 acc 0.66225 roc_auc 0.37078 prc_auc 0.56943[0m
[93maverage test of epoch 48: loss -18.98487 acc 0.67568 roc_auc 0.46833 prc_auc 0.65441[0m
[92maverage training of epoch 49: loss -19.05642 acc 0.66225 roc_auc 0.36902 prc_auc 0.57160[0m
[93maverage test of epoch 49: loss -19.28719 acc 0.67568 roc_auc 0.43500 prc_auc 0.64245[0m
[92maverage training of epoch 50: loss -19.35673 acc 0.66225 roc_auc 0.36990 prc_auc 0.56772[0m
[93maverage test of epoch 50: loss -19.58764 acc 0.67568 roc_auc 0.58000 prc_auc 0.73000[0m
[92maverage training of epoch 51: loss -19.65644 acc 0.66225 roc_auc 0.36618 prc_auc 0.56641[0m
[93maverage test of epoch 51: loss -19.88900 acc 0.67568 roc_auc 0.43833 prc_auc 0.66543[0m
[92maverage training of epoch 52: loss -19.95637 acc 0.66225 roc_auc 0.37294 prc_auc 0.57072[0m
[93maverage test of epoch 52: loss -20.18989 acc 0.67568 roc_auc 0.43833 prc_auc 0.64606[0m
[92maverage training of epoch 53: loss -20.25546 acc 0.66225 roc_auc 0.36892 prc_auc 0.56978[0m
[93maverage test of epoch 53: loss -20.49117 acc 0.67568 roc_auc 0.64500 prc_auc 0.79801[0m
[92maverage training of epoch 54: loss -20.55570 acc 0.66225 roc_auc 0.36990 prc_auc 0.56982[0m
[93maverage test of epoch 54: loss -20.79203 acc 0.67568 roc_auc 0.48333 prc_auc 0.68006[0m
[92maverage training of epoch 55: loss -20.85543 acc 0.66225 roc_auc 0.36912 prc_auc 0.56707[0m
[93maverage test of epoch 55: loss -21.09324 acc 0.67568 roc_auc 0.44333 prc_auc 0.66598[0m
[92maverage training of epoch 56: loss -21.15531 acc 0.66225 roc_auc 0.37137 prc_auc 0.56961[0m
[93maverage test of epoch 56: loss -21.39410 acc 0.67568 roc_auc 0.52000 prc_auc 0.71813[0m
[92maverage training of epoch 57: loss -21.45485 acc 0.66225 roc_auc 0.36765 prc_auc 0.56816[0m
[93maverage test of epoch 57: loss -21.69538 acc 0.67568 roc_auc 0.60333 prc_auc 0.73028[0m
[92maverage training of epoch 58: loss -21.75473 acc 0.66225 roc_auc 0.37147 prc_auc 0.57102[0m
[93maverage test of epoch 58: loss -21.99621 acc 0.67568 roc_auc 0.40667 prc_auc 0.62934[0m
[92maverage training of epoch 59: loss -22.05430 acc 0.66225 roc_auc 0.37029 prc_auc 0.57017[0m
[93maverage test of epoch 59: loss -22.29734 acc 0.67568 roc_auc 0.56333 prc_auc 0.70860[0m
[92maverage training of epoch 60: loss -22.35410 acc 0.66225 roc_auc 0.36912 prc_auc 0.56923[0m
[93maverage test of epoch 60: loss -22.59781 acc 0.67568 roc_auc 0.47167 prc_auc 0.66641[0m
[92maverage training of epoch 61: loss -22.65363 acc 0.66225 roc_auc 0.36833 prc_auc 0.57220[0m
[93maverage test of epoch 61: loss -22.89861 acc 0.67568 roc_auc 0.42833 prc_auc 0.63554[0m
[92maverage training of epoch 62: loss -22.95325 acc 0.66225 roc_auc 0.37176 prc_auc 0.56841[0m
[93maverage test of epoch 62: loss -23.20012 acc 0.67568 roc_auc 0.41667 prc_auc 0.63697[0m
[92maverage training of epoch 63: loss -23.25310 acc 0.66225 roc_auc 0.36931 prc_auc 0.56785[0m
[93maverage test of epoch 63: loss -23.50094 acc 0.67568 roc_auc 0.71333 prc_auc 0.78601[0m
[92maverage training of epoch 64: loss -23.55270 acc 0.66225 roc_auc 0.36873 prc_auc 0.56874[0m
[93maverage test of epoch 64: loss -23.80185 acc 0.67568 roc_auc 0.57333 prc_auc 0.72444[0m
[92maverage training of epoch 65: loss -23.85241 acc 0.66225 roc_auc 0.36990 prc_auc 0.56806[0m
[93maverage test of epoch 65: loss -24.10292 acc 0.67568 roc_auc 0.55667 prc_auc 0.70888[0m
[92maverage training of epoch 66: loss -24.15220 acc 0.66225 roc_auc 0.36971 prc_auc 0.57011[0m
[93maverage test of epoch 66: loss -24.40362 acc 0.67568 roc_auc 0.44333 prc_auc 0.65615[0m
[92maverage training of epoch 67: loss -24.45184 acc 0.66225 roc_auc 0.36912 prc_auc 0.56851[0m
[93maverage test of epoch 67: loss -24.70494 acc 0.67568 roc_auc 0.66333 prc_auc 0.77853[0m
[92maverage training of epoch 68: loss -24.75147 acc 0.66225 roc_auc 0.36882 prc_auc 0.56828[0m
[93maverage test of epoch 68: loss -25.00568 acc 0.67568 roc_auc 0.51833 prc_auc 0.69159[0m
[92maverage training of epoch 69: loss -25.05100 acc 0.66225 roc_auc 0.36892 prc_auc 0.56894[0m
[93maverage test of epoch 69: loss -25.30665 acc 0.67568 roc_auc 0.57167 prc_auc 0.73369[0m
[92maverage training of epoch 70: loss -25.35073 acc 0.66225 roc_auc 0.37039 prc_auc 0.57044[0m
[93maverage test of epoch 70: loss -25.60755 acc 0.67568 roc_auc 0.45000 prc_auc 0.65362[0m
[92maverage training of epoch 71: loss -25.65036 acc 0.66225 roc_auc 0.36990 prc_auc 0.56856[0m
[93maverage test of epoch 71: loss -25.90847 acc 0.67568 roc_auc 0.34667 prc_auc 0.61317[0m
[92maverage training of epoch 72: loss -25.95008 acc 0.66225 roc_auc 0.36971 prc_auc 0.57151[0m
[93maverage test of epoch 72: loss -26.20933 acc 0.67568 roc_auc 0.51000 prc_auc 0.68014[0m
[92maverage training of epoch 73: loss -26.24969 acc 0.66225 roc_auc 0.36931 prc_auc 0.56994[0m
[93maverage test of epoch 73: loss -26.51041 acc 0.67568 roc_auc 0.42000 prc_auc 0.64265[0m
[92maverage training of epoch 74: loss -26.54922 acc 0.66225 roc_auc 0.36990 prc_auc 0.57029[0m
[93maverage test of epoch 74: loss -26.81123 acc 0.67568 roc_auc 0.48667 prc_auc 0.67000[0m
[92maverage training of epoch 75: loss -26.84896 acc 0.66225 roc_auc 0.37010 prc_auc 0.57143[0m
[93maverage test of epoch 75: loss -27.11216 acc 0.67568 roc_auc 0.50000 prc_auc 0.67606[0m
[92maverage training of epoch 76: loss -27.14858 acc 0.66225 roc_auc 0.36833 prc_auc 0.56969[0m
[93maverage test of epoch 76: loss -27.41300 acc 0.67568 roc_auc 0.54167 prc_auc 0.69444[0m
[92maverage training of epoch 77: loss -27.44811 acc 0.66225 roc_auc 0.36892 prc_auc 0.57025[0m
[93maverage test of epoch 77: loss -27.71389 acc 0.67568 roc_auc 0.61333 prc_auc 0.73285[0m
[92maverage training of epoch 78: loss -27.74781 acc 0.66225 roc_auc 0.36990 prc_auc 0.57056[0m
[93maverage test of epoch 78: loss -28.01483 acc 0.67568 roc_auc 0.50167 prc_auc 0.67641[0m
[92maverage training of epoch 79: loss -28.04741 acc 0.66225 roc_auc 0.36873 prc_auc 0.56874[0m
[93maverage test of epoch 79: loss -28.31566 acc 0.67568 roc_auc 0.54333 prc_auc 0.69527[0m
[92maverage training of epoch 80: loss -28.34708 acc 0.66225 roc_auc 0.36882 prc_auc 0.57091[0m
[93maverage test of epoch 80: loss -28.61643 acc 0.67568 roc_auc 0.52167 prc_auc 0.68531[0m
[92maverage training of epoch 81: loss -28.64670 acc 0.66225 roc_auc 0.36892 prc_auc 0.57035[0m
[93maverage test of epoch 81: loss -28.91741 acc 0.67568 roc_auc 0.48167 prc_auc 0.66775[0m
[92maverage training of epoch 82: loss -28.94627 acc 0.66225 roc_auc 0.36843 prc_auc 0.57168[0m
[93maverage test of epoch 82: loss -29.21844 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 83: loss -29.24593 acc 0.66225 roc_auc 0.36755 prc_auc 0.56853[0m
[93maverage test of epoch 83: loss -29.51922 acc 0.67568 roc_auc 0.44167 prc_auc 0.65126[0m
[92maverage training of epoch 84: loss -29.54550 acc 0.66225 roc_auc 0.36706 prc_auc 0.56915[0m
[93maverage test of epoch 84: loss -29.82028 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 85: loss -29.84520 acc 0.66225 roc_auc 0.36902 prc_auc 0.57030[0m
[93maverage test of epoch 85: loss -30.12110 acc 0.67568 roc_auc 0.48167 prc_auc 0.66775[0m
[92maverage training of epoch 86: loss -30.14474 acc 0.66225 roc_auc 0.36824 prc_auc 0.56948[0m
[93maverage test of epoch 86: loss -30.42180 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 87: loss -30.44442 acc 0.66225 roc_auc 0.36922 prc_auc 0.56985[0m
[93maverage test of epoch 87: loss -30.72285 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 88: loss -30.74398 acc 0.66225 roc_auc 0.36716 prc_auc 0.56725[0m
[93maverage test of epoch 88: loss -31.02379 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 89: loss -31.04361 acc 0.66225 roc_auc 0.36725 prc_auc 0.56698[0m
[93maverage test of epoch 89: loss -31.32459 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 90: loss -31.34318 acc 0.66225 roc_auc 0.36863 prc_auc 0.56991[0m
[93maverage test of epoch 90: loss -31.62553 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 91: loss -31.64284 acc 0.66225 roc_auc 0.36657 prc_auc 0.56823[0m
[93maverage test of epoch 91: loss -31.92638 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 92: loss -31.94247 acc 0.66225 roc_auc 0.37029 prc_auc 0.57406[0m
[93maverage test of epoch 92: loss -32.22723 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 93: loss -32.24206 acc 0.66225 roc_auc 0.36451 prc_auc 0.56755[0m
[93maverage test of epoch 93: loss -32.52803 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 94: loss -32.54163 acc 0.66225 roc_auc 0.36627 prc_auc 0.57094[0m
[93maverage test of epoch 94: loss -32.82900 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 95: loss -32.84128 acc 0.66225 roc_auc 0.37039 prc_auc 0.57550[0m
[93maverage test of epoch 95: loss -33.12991 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 96: loss -33.14086 acc 0.66225 roc_auc 0.36814 prc_auc 0.57435[0m
[93maverage test of epoch 96: loss -33.43087 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 97: loss -33.44048 acc 0.66225 roc_auc 0.36676 prc_auc 0.57526[0m
[93maverage test of epoch 97: loss -33.73172 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 98: loss -33.74014 acc 0.66225 roc_auc 0.37343 prc_auc 0.58252[0m
[93maverage test of epoch 98: loss -34.03253 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 99: loss -34.03968 acc 0.66225 roc_auc 0.37049 prc_auc 0.57639[0m
[93maverage test of epoch 99: loss -34.33345 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.0003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.71294 ROC_AUC (avg): 0.62097 PRC_AUC (avg): 0.74292 

Average forward propagation time taken(ms): 3.9547985626034707
Average backward propagation time taken(ms): 1.5148791208605457

