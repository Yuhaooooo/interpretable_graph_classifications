# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.0001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-02-29-19/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-02-29-19/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 16,
 'epochs': 100,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 4,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.0001,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 1,
 'num_workers': 8,
 'number_of_mlp_layer': 0,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-18-02-29-19',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 100, 'learning_rate': 0.0001, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss 0.16021 acc 0.33333 roc_auc 0.57460 prc_auc 0.73511[0m
[93maverage test of epoch 0: loss 0.08654 acc 0.34211 roc_auc 0.78462 prc_auc 0.91142[0m
[92maverage training of epoch 1: loss 0.03426 acc 0.33333 roc_auc 0.59040 prc_auc 0.75334[0m
[93maverage test of epoch 1: loss -0.03221 acc 0.34211 roc_auc 0.90308 prc_auc 0.95318[0m
[92maverage training of epoch 2: loss -0.07920 acc 0.33333 roc_auc 0.61900 prc_auc 0.79814[0m
[93maverage test of epoch 2: loss -0.14237 acc 0.34211 roc_auc 0.90154 prc_auc 0.95307[0m
[92maverage training of epoch 3: loss -0.18722 acc 0.33333 roc_auc 0.62840 prc_auc 0.80583[0m
[93maverage test of epoch 3: loss -0.25040 acc 0.34211 roc_auc 0.90154 prc_auc 0.95307[0m
[92maverage training of epoch 4: loss -0.29693 acc 0.33333 roc_auc 0.64860 prc_auc 0.81682[0m
[93maverage test of epoch 4: loss -0.36440 acc 0.34211 roc_auc 0.89231 prc_auc 0.95017[0m
[92maverage training of epoch 5: loss -0.41692 acc 0.33333 roc_auc 0.64020 prc_auc 0.81222[0m
[93maverage test of epoch 5: loss -0.49276 acc 0.34211 roc_auc 0.89231 prc_auc 0.95136[0m
[92maverage training of epoch 6: loss -0.55281 acc 0.33333 roc_auc 0.64760 prc_auc 0.81192[0m
[93maverage test of epoch 6: loss -0.63728 acc 0.34211 roc_auc 0.89846 prc_auc 0.95332[0m
[92maverage training of epoch 7: loss -0.70096 acc 0.33333 roc_auc 0.64010 prc_auc 0.81143[0m
[93maverage test of epoch 7: loss -0.78951 acc 0.34211 roc_auc 0.90769 prc_auc 0.95765[0m
[92maverage training of epoch 8: loss -0.85001 acc 0.33333 roc_auc 0.64380 prc_auc 0.81811[0m
[93maverage test of epoch 8: loss -0.93791 acc 0.34211 roc_auc 0.89846 prc_auc 0.95270[0m
[92maverage training of epoch 9: loss -0.99105 acc 0.34667 roc_auc 0.65900 prc_auc 0.82290[0m
[93maverage test of epoch 9: loss -1.07882 acc 0.36842 roc_auc 0.90154 prc_auc 0.95565[0m
[92maverage training of epoch 10: loss -1.12566 acc 0.34667 roc_auc 0.68160 prc_auc 0.83541[0m
[93maverage test of epoch 10: loss -1.22244 acc 0.36842 roc_auc 0.90462 prc_auc 0.95752[0m
[92maverage training of epoch 11: loss -1.26686 acc 0.39333 roc_auc 0.72280 prc_auc 0.85549[0m
[93maverage test of epoch 11: loss -1.37700 acc 0.55263 roc_auc 0.91077 prc_auc 0.96171[0m
[92maverage training of epoch 12: loss -1.40707 acc 0.62667 roc_auc 0.80160 prc_auc 0.89002[0m
[93maverage test of epoch 12: loss -1.50392 acc 0.71053 roc_auc 0.91692 prc_auc 0.96456[0m
[92maverage training of epoch 13: loss -1.52797 acc 0.74000 roc_auc 0.86400 prc_auc 0.91825[0m
[93maverage test of epoch 13: loss -1.61815 acc 0.76316 roc_auc 0.91692 prc_auc 0.96486[0m
[92maverage training of epoch 14: loss -1.65663 acc 0.82000 roc_auc 0.87620 prc_auc 0.92294[0m
[93maverage test of epoch 14: loss -1.74866 acc 0.84211 roc_auc 0.91077 prc_auc 0.96220[0m
[92maverage training of epoch 15: loss -1.80717 acc 0.86000 roc_auc 0.87220 prc_auc 0.91897[0m
[93maverage test of epoch 15: loss -1.89555 acc 0.84211 roc_auc 0.89538 prc_auc 0.95718[0m
[92maverage training of epoch 16: loss -1.96312 acc 0.85333 roc_auc 0.87140 prc_auc 0.91653[0m
[93maverage test of epoch 16: loss -2.02915 acc 0.84211 roc_auc 0.88923 prc_auc 0.95452[0m
[92maverage training of epoch 17: loss -2.10864 acc 0.86667 roc_auc 0.86980 prc_auc 0.91147[0m
[93maverage test of epoch 17: loss -2.14642 acc 0.81579 roc_auc 0.88923 prc_auc 0.95501[0m
[92maverage training of epoch 18: loss -2.23945 acc 0.87333 roc_auc 0.86820 prc_auc 0.90611[0m
[93maverage test of epoch 18: loss -2.25241 acc 0.81579 roc_auc 0.89231 prc_auc 0.95513[0m
[92maverage training of epoch 19: loss -2.35509 acc 0.87333 roc_auc 0.86780 prc_auc 0.90158[0m
[93maverage test of epoch 19: loss -2.35019 acc 0.81579 roc_auc 0.89231 prc_auc 0.95513[0m
[92maverage training of epoch 20: loss -2.45914 acc 0.88000 roc_auc 0.86760 prc_auc 0.89960[0m
[93maverage test of epoch 20: loss -2.43944 acc 0.81579 roc_auc 0.89231 prc_auc 0.95513[0m
[92maverage training of epoch 21: loss -2.55349 acc 0.88000 roc_auc 0.86700 prc_auc 0.89992[0m
[93maverage test of epoch 21: loss -2.52000 acc 0.81579 roc_auc 0.89231 prc_auc 0.95513[0m
[92maverage training of epoch 22: loss -2.63810 acc 0.88000 roc_auc 0.86740 prc_auc 0.90059[0m
[93maverage test of epoch 22: loss -2.60051 acc 0.81579 roc_auc 0.89538 prc_auc 0.95713[0m
[92maverage training of epoch 23: loss -2.71740 acc 0.88000 roc_auc 0.86720 prc_auc 0.90148[0m
[93maverage test of epoch 23: loss -2.69049 acc 0.84211 roc_auc 0.89538 prc_auc 0.95713[0m
[92maverage training of epoch 24: loss -2.79403 acc 0.88000 roc_auc 0.86560 prc_auc 0.89946[0m
[93maverage test of epoch 24: loss -2.77403 acc 0.84211 roc_auc 0.89846 prc_auc 0.95860[0m
[92maverage training of epoch 25: loss -2.86771 acc 0.88000 roc_auc 0.86500 prc_auc 0.89787[0m
[93maverage test of epoch 25: loss -2.84838 acc 0.84211 roc_auc 0.89846 prc_auc 0.95860[0m
[92maverage training of epoch 26: loss -2.93282 acc 0.87333 roc_auc 0.86540 prc_auc 0.90024[0m
[93maverage test of epoch 26: loss -2.93397 acc 0.84211 roc_auc 0.90154 prc_auc 0.96026[0m
[92maverage training of epoch 27: loss -2.98680 acc 0.86667 roc_auc 0.86420 prc_auc 0.89950[0m
[93maverage test of epoch 27: loss -3.03412 acc 0.86842 roc_auc 0.89846 prc_auc 0.95912[0m
[92maverage training of epoch 28: loss -3.07973 acc 0.88000 roc_auc 0.85620 prc_auc 0.89384[0m
[93maverage test of epoch 28: loss -3.10228 acc 0.86842 roc_auc 0.89846 prc_auc 0.95997[0m
[92maverage training of epoch 29: loss -3.14684 acc 0.88000 roc_auc 0.85860 prc_auc 0.89349[0m
[93maverage test of epoch 29: loss -3.16572 acc 0.86842 roc_auc 0.90154 prc_auc 0.96072[0m
[92maverage training of epoch 30: loss -3.21365 acc 0.88000 roc_auc 0.85300 prc_auc 0.89101[0m
[93maverage test of epoch 30: loss -3.23377 acc 0.86842 roc_auc 0.90154 prc_auc 0.96072[0m
[92maverage training of epoch 31: loss -3.27983 acc 0.88000 roc_auc 0.85340 prc_auc 0.89076[0m
[93maverage test of epoch 31: loss -3.29814 acc 0.86842 roc_auc 0.90462 prc_auc 0.96178[0m
[92maverage training of epoch 32: loss -3.34588 acc 0.88000 roc_auc 0.85320 prc_auc 0.88922[0m
[93maverage test of epoch 32: loss -3.36163 acc 0.86842 roc_auc 0.90462 prc_auc 0.96178[0m
[92maverage training of epoch 33: loss -3.42407 acc 0.88667 roc_auc 0.85280 prc_auc 0.88915[0m
[93maverage test of epoch 33: loss -3.42485 acc 0.86842 roc_auc 0.90462 prc_auc 0.96178[0m
[92maverage training of epoch 34: loss -3.48873 acc 0.88667 roc_auc 0.85240 prc_auc 0.88811[0m
[93maverage test of epoch 34: loss -3.48774 acc 0.86842 roc_auc 0.90462 prc_auc 0.96178[0m
[92maverage training of epoch 35: loss -3.55245 acc 0.88667 roc_auc 0.85060 prc_auc 0.88563[0m
[93maverage test of epoch 35: loss -3.55023 acc 0.86842 roc_auc 0.90462 prc_auc 0.96178[0m
[92maverage training of epoch 36: loss -3.61544 acc 0.88667 roc_auc 0.84720 prc_auc 0.88016[0m
[93maverage test of epoch 36: loss -3.61213 acc 0.86842 roc_auc 0.90769 prc_auc 0.96259[0m
[92maverage training of epoch 37: loss -3.65567 acc 0.88000 roc_auc 0.85100 prc_auc 0.88939[0m
[93maverage test of epoch 37: loss -3.67268 acc 0.86842 roc_auc 0.90462 prc_auc 0.96178[0m
[92maverage training of epoch 38: loss -3.74034 acc 0.88667 roc_auc 0.86260 prc_auc 0.89515[0m
[93maverage test of epoch 38: loss -3.72163 acc 0.86842 roc_auc 0.89846 prc_auc 0.95882[0m
[92maverage training of epoch 39: loss -3.80388 acc 0.88667 roc_auc 0.86060 prc_auc 0.89555[0m
[93maverage test of epoch 39: loss -3.78885 acc 0.86842 roc_auc 0.90154 prc_auc 0.96072[0m
[92maverage training of epoch 40: loss -3.84737 acc 0.88000 roc_auc 0.84700 prc_auc 0.88135[0m
[93maverage test of epoch 40: loss -3.85450 acc 0.86842 roc_auc 0.90154 prc_auc 0.96072[0m
[92maverage training of epoch 41: loss -3.89259 acc 0.87333 roc_auc 0.85080 prc_auc 0.88448[0m
[93maverage test of epoch 41: loss -3.91373 acc 0.86842 roc_auc 0.90462 prc_auc 0.96178[0m
[92maverage training of epoch 42: loss -3.98467 acc 0.88667 roc_auc 0.84640 prc_auc 0.87985[0m
[93maverage test of epoch 42: loss -3.97373 acc 0.86842 roc_auc 0.90154 prc_auc 0.96072[0m
[92maverage training of epoch 43: loss -4.03095 acc 0.88000 roc_auc 0.86120 prc_auc 0.89443[0m
[93maverage test of epoch 43: loss -4.02887 acc 0.86842 roc_auc 0.90154 prc_auc 0.96072[0m
[92maverage training of epoch 44: loss -4.08984 acc 0.88000 roc_auc 0.84360 prc_auc 0.87548[0m
[93maverage test of epoch 44: loss -4.02084 acc 0.84211 roc_auc 0.90462 prc_auc 0.96139[0m
[92maverage training of epoch 45: loss -4.12648 acc 0.87333 roc_auc 0.81580 prc_auc 0.85413[0m
[93maverage test of epoch 45: loss -4.07122 acc 0.84211 roc_auc 0.91077 prc_auc 0.96260[0m
[92maverage training of epoch 46: loss -4.16684 acc 0.86667 roc_auc 0.81640 prc_auc 0.85494[0m
[93maverage test of epoch 46: loss -4.19885 acc 0.86842 roc_auc 0.90769 prc_auc 0.96163[0m
[92maverage training of epoch 47: loss -4.24370 acc 0.87333 roc_auc 0.81680 prc_auc 0.85563[0m
[93maverage test of epoch 47: loss -4.21370 acc 0.84211 roc_auc 0.90769 prc_auc 0.96163[0m
[92maverage training of epoch 48: loss -4.30200 acc 0.87333 roc_auc 0.81600 prc_auc 0.85472[0m
[93maverage test of epoch 48: loss -4.31205 acc 0.86842 roc_auc 0.90769 prc_auc 0.96163[0m
[92maverage training of epoch 49: loss -4.36023 acc 0.87333 roc_auc 0.81480 prc_auc 0.85225[0m
[93maverage test of epoch 49: loss -4.29978 acc 0.84211 roc_auc 0.90462 prc_auc 0.96017[0m
[92maverage training of epoch 50: loss -4.40065 acc 0.86667 roc_auc 0.81660 prc_auc 0.85472[0m
[93maverage test of epoch 50: loss -4.35591 acc 0.84211 roc_auc 0.90769 prc_auc 0.96163[0m
[92maverage training of epoch 51: loss -4.47414 acc 0.87333 roc_auc 0.81600 prc_auc 0.85432[0m
[93maverage test of epoch 51: loss -4.41090 acc 0.84211 roc_auc 0.90462 prc_auc 0.96017[0m
[92maverage training of epoch 52: loss -4.56881 acc 0.88667 roc_auc 0.84480 prc_auc 0.87485[0m
[93maverage test of epoch 52: loss -4.47847 acc 0.84211 roc_auc 0.91385 prc_auc 0.96382[0m
[92maverage training of epoch 53: loss -4.60678 acc 0.88000 roc_auc 0.84600 prc_auc 0.88440[0m
[93maverage test of epoch 53: loss -4.52743 acc 0.84211 roc_auc 0.90769 prc_auc 0.96163[0m
[92maverage training of epoch 54: loss -4.62589 acc 0.86667 roc_auc 0.84580 prc_auc 0.87451[0m
[93maverage test of epoch 54: loss -4.57661 acc 0.84211 roc_auc 0.90462 prc_auc 0.96017[0m
[92maverage training of epoch 55: loss -4.69857 acc 0.87333 roc_auc 0.84320 prc_auc 0.87298[0m
[93maverage test of epoch 55: loss -4.63083 acc 0.84211 roc_auc 0.90769 prc_auc 0.96122[0m
[92maverage training of epoch 56: loss -4.73822 acc 0.86667 roc_auc 0.83460 prc_auc 0.86933[0m
[93maverage test of epoch 56: loss -4.68471 acc 0.84211 roc_auc 0.91385 prc_auc 0.96382[0m
[92maverage training of epoch 57: loss -4.81588 acc 0.87333 roc_auc 0.84380 prc_auc 0.87262[0m
[93maverage test of epoch 57: loss -4.73876 acc 0.84211 roc_auc 0.91385 prc_auc 0.96286[0m
[92maverage training of epoch 58: loss -4.84337 acc 0.86667 roc_auc 0.83630 prc_auc 0.86828[0m
[93maverage test of epoch 58: loss -4.79638 acc 0.84211 roc_auc 0.91692 prc_auc 0.96432[0m
[92maverage training of epoch 59: loss -4.83280 acc 0.84667 roc_auc 0.75590 prc_auc 0.80291[0m
[93maverage test of epoch 59: loss -4.60319 acc 0.76316 roc_auc 0.90154 prc_auc 0.95693[0m
[92maverage training of epoch 60: loss -4.96944 acc 0.87333 roc_auc 0.83440 prc_auc 0.86711[0m
[93maverage test of epoch 60: loss -4.90743 acc 0.84211 roc_auc 0.92308 prc_auc 0.96712[0m
[92maverage training of epoch 61: loss -4.87534 acc 0.82667 roc_auc 0.66970 prc_auc 0.74217[0m
[93maverage test of epoch 61: loss -4.78338 acc 0.78947 roc_auc 0.91077 prc_auc 0.95950[0m
[92maverage training of epoch 62: loss -5.05334 acc 0.86667 roc_auc 0.82000 prc_auc 0.86530[0m
[93maverage test of epoch 62: loss -4.94991 acc 0.81579 roc_auc 0.91077 prc_auc 0.96095[0m
[92maverage training of epoch 63: loss -5.13058 acc 0.87333 roc_auc 0.83880 prc_auc 0.87655[0m
[93maverage test of epoch 63: loss -5.05486 acc 0.84211 roc_auc 0.91385 prc_auc 0.96211[0m
[92maverage training of epoch 64: loss -5.16402 acc 0.86667 roc_auc 0.84250 prc_auc 0.87224[0m
[93maverage test of epoch 64: loss -5.11636 acc 0.84211 roc_auc 0.92308 prc_auc 0.96688[0m
[92maverage training of epoch 65: loss -5.19606 acc 0.86000 roc_auc 0.84200 prc_auc 0.88086[0m
[93maverage test of epoch 65: loss -5.09304 acc 0.81579 roc_auc 0.92308 prc_auc 0.96601[0m
[92maverage training of epoch 66: loss -5.26988 acc 0.86667 roc_auc 0.84240 prc_auc 0.87008[0m
[93maverage test of epoch 66: loss -5.21992 acc 0.84211 roc_auc 0.92308 prc_auc 0.96712[0m
[92maverage training of epoch 67: loss -5.36223 acc 0.88000 roc_auc 0.85320 prc_auc 0.89009[0m
[93maverage test of epoch 67: loss -5.27484 acc 0.84211 roc_auc 0.91692 prc_auc 0.96411[0m
[92maverage training of epoch 68: loss -5.35458 acc 0.86000 roc_auc 0.85040 prc_auc 0.88370[0m
[93maverage test of epoch 68: loss -5.08574 acc 0.76316 roc_auc 0.91231 prc_auc 0.96084[0m
[92maverage training of epoch 69: loss -5.44908 acc 0.87333 roc_auc 0.87350 prc_auc 0.90128[0m
[93maverage test of epoch 69: loss -5.37809 acc 0.84211 roc_auc 0.91077 prc_auc 0.96200[0m
[92maverage training of epoch 70: loss -5.39199 acc 0.84000 roc_auc 0.76100 prc_auc 0.80991[0m
[93maverage test of epoch 70: loss -5.41915 acc 0.84211 roc_auc 0.91692 prc_auc 0.96383[0m
[92maverage training of epoch 71: loss -5.61536 acc 0.89333 roc_auc 0.87080 prc_auc 0.90110[0m
[93maverage test of epoch 71: loss -5.39904 acc 0.81579 roc_auc 0.91385 prc_auc 0.96284[0m
[92maverage training of epoch 72: loss -5.64759 acc 0.88667 roc_auc 0.87160 prc_auc 0.90168[0m
[93maverage test of epoch 72: loss -5.45030 acc 0.81579 roc_auc 0.91231 prc_auc 0.96200[0m
[92maverage training of epoch 73: loss -5.66686 acc 0.87333 roc_auc 0.85450 prc_auc 0.88665[0m
[93maverage test of epoch 73: loss -5.58194 acc 0.84211 roc_auc 0.90769 prc_auc 0.96120[0m
[92maverage training of epoch 74: loss -5.74133 acc 0.88667 roc_auc 0.86160 prc_auc 0.89340[0m
[93maverage test of epoch 74: loss -5.63467 acc 0.84211 roc_auc 0.91077 prc_auc 0.96200[0m
[92maverage training of epoch 75: loss -5.78394 acc 0.88000 roc_auc 0.86420 prc_auc 0.89553[0m
[93maverage test of epoch 75: loss -5.68561 acc 0.84211 roc_auc 0.90769 prc_auc 0.96120[0m
[92maverage training of epoch 76: loss -5.87910 acc 0.89333 roc_auc 0.86860 prc_auc 0.89784[0m
[93maverage test of epoch 76: loss -5.73774 acc 0.84211 roc_auc 0.90769 prc_auc 0.96120[0m
[92maverage training of epoch 77: loss -5.91045 acc 0.88667 roc_auc 0.86680 prc_auc 0.89743[0m
[93maverage test of epoch 77: loss -5.78914 acc 0.84211 roc_auc 0.90769 prc_auc 0.96120[0m
[92maverage training of epoch 78: loss -5.96280 acc 0.88667 roc_auc 0.86740 prc_auc 0.89711[0m
[93maverage test of epoch 78: loss -5.84052 acc 0.84211 roc_auc 0.90462 prc_auc 0.95954[0m
[92maverage training of epoch 79: loss -6.01523 acc 0.88667 roc_auc 0.86920 prc_auc 0.89845[0m
[93maverage test of epoch 79: loss -5.89192 acc 0.84211 roc_auc 0.90462 prc_auc 0.95954[0m
[92maverage training of epoch 80: loss -6.04463 acc 0.88000 roc_auc 0.85320 prc_auc 0.87596[0m
[93maverage test of epoch 80: loss -6.02505 acc 0.86842 roc_auc 0.91692 prc_auc 0.96479[0m
[92maverage training of epoch 81: loss -6.16404 acc 0.90000 roc_auc 0.86820 prc_auc 0.89693[0m
[93maverage test of epoch 81: loss -5.99470 acc 0.84211 roc_auc 0.91385 prc_auc 0.96289[0m
[92maverage training of epoch 82: loss -6.17273 acc 0.88667 roc_auc 0.86630 prc_auc 0.89536[0m
[93maverage test of epoch 82: loss -6.04611 acc 0.84211 roc_auc 0.91385 prc_auc 0.96289[0m
[92maverage training of epoch 83: loss -6.22514 acc 0.88667 roc_auc 0.86220 prc_auc 0.89350[0m
[93maverage test of epoch 83: loss -6.09744 acc 0.84211 roc_auc 0.90769 prc_auc 0.96120[0m
[92maverage training of epoch 84: loss -6.27702 acc 0.88667 roc_auc 0.87120 prc_auc 0.89905[0m
[93maverage test of epoch 84: loss -6.23694 acc 0.86842 roc_auc 0.92000 prc_auc 0.96601[0m
[92maverage training of epoch 85: loss -6.19294 acc 0.84667 roc_auc 0.80070 prc_auc 0.82950[0m
[93maverage test of epoch 85: loss -5.94458 acc 0.76316 roc_auc 0.91385 prc_auc 0.96284[0m
[92maverage training of epoch 86: loss -6.30943 acc 0.86667 roc_auc 0.84580 prc_auc 0.88223[0m
[93maverage test of epoch 86: loss -6.33725 acc 0.86842 roc_auc 0.92000 prc_auc 0.96739[0m
[92maverage training of epoch 87: loss -6.39276 acc 0.87333 roc_auc 0.87440 prc_auc 0.90110[0m
[93maverage test of epoch 87: loss -6.38532 acc 0.86842 roc_auc 0.91692 prc_auc 0.96457[0m
[92maverage training of epoch 88: loss -6.48262 acc 0.88667 roc_auc 0.87070 prc_auc 0.90005[0m
[93maverage test of epoch 88: loss -6.43663 acc 0.86842 roc_auc 0.92000 prc_auc 0.96670[0m
[92maverage training of epoch 89: loss -6.51186 acc 0.88000 roc_auc 0.86920 prc_auc 0.89761[0m
[93maverage test of epoch 89: loss -6.48788 acc 0.86842 roc_auc 0.92000 prc_auc 0.96670[0m
[92maverage training of epoch 90: loss -6.23574 acc 0.78667 roc_auc 0.62840 prc_auc 0.71489[0m
[93maverage test of epoch 90: loss -6.44665 acc 0.84211 roc_auc 0.91385 prc_auc 0.96494[0m
[92maverage training of epoch 91: loss -6.58982 acc 0.87333 roc_auc 0.84960 prc_auc 0.88096[0m
[93maverage test of epoch 91: loss -6.58925 acc 0.86842 roc_auc 0.92000 prc_auc 0.96670[0m
[92maverage training of epoch 92: loss -6.66539 acc 0.88000 roc_auc 0.87040 prc_auc 0.89938[0m
[93maverage test of epoch 92: loss -6.64048 acc 0.86842 roc_auc 0.92000 prc_auc 0.96670[0m
[92maverage training of epoch 93: loss -6.71627 acc 0.88000 roc_auc 0.85730 prc_auc 0.88996[0m
[93maverage test of epoch 93: loss -6.59974 acc 0.84211 roc_auc 0.91385 prc_auc 0.96261[0m
[92maverage training of epoch 94: loss -6.81460 acc 0.89333 roc_auc 0.87450 prc_auc 0.90095[0m
[93maverage test of epoch 94: loss -6.74306 acc 0.86842 roc_auc 0.92615 prc_auc 0.96833[0m
[92maverage training of epoch 95: loss -6.82010 acc 0.88000 roc_auc 0.86870 prc_auc 0.89677[0m
[93maverage test of epoch 95: loss -6.79418 acc 0.86842 roc_auc 0.92615 prc_auc 0.96833[0m
[92maverage training of epoch 96: loss -6.53825 acc 0.78667 roc_auc 0.61920 prc_auc 0.70361[0m
[93maverage test of epoch 96: loss -6.75118 acc 0.84211 roc_auc 0.92000 prc_auc 0.96670[0m
[92maverage training of epoch 97: loss -6.87455 acc 0.86667 roc_auc 0.85150 prc_auc 0.88725[0m
[93maverage test of epoch 97: loss -6.70581 acc 0.81579 roc_auc 0.92000 prc_auc 0.96464[0m
[92maverage training of epoch 98: loss -6.92631 acc 0.86667 roc_auc 0.85260 prc_auc 0.87696[0m
[93maverage test of epoch 98: loss -6.94611 acc 0.86842 roc_auc 0.92000 prc_auc 0.96670[0m
[92maverage training of epoch 99: loss -7.04793 acc 0.88667 roc_auc 0.85740 prc_auc 0.88985[0m
[93maverage test of epoch 99: loss -6.89996 acc 0.84211 roc_auc 0.92000 prc_auc 0.96464[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.08802 acc 0.33333 roc_auc 0.35440 prc_auc 0.59088[0m
[93maverage test of epoch 0: loss -0.25946 acc 0.34211 roc_auc 0.21846 prc_auc 0.56661[0m
[92maverage training of epoch 1: loss -0.32147 acc 0.33333 roc_auc 0.36120 prc_auc 0.59521[0m
[93maverage test of epoch 1: loss -0.49290 acc 0.34211 roc_auc 0.21538 prc_auc 0.56583[0m
[92maverage training of epoch 2: loss -0.56260 acc 0.33333 roc_auc 0.39100 prc_auc 0.60745[0m
[93maverage test of epoch 2: loss -0.72835 acc 0.34211 roc_auc 0.25538 prc_auc 0.59912[0m
[92maverage training of epoch 3: loss -0.80769 acc 0.34000 roc_auc 0.43840 prc_auc 0.63157[0m
[93maverage test of epoch 3: loss -0.97409 acc 0.39474 roc_auc 0.32923 prc_auc 0.63884[0m
[92maverage training of epoch 4: loss -1.07407 acc 0.34000 roc_auc 0.48920 prc_auc 0.67569[0m
[93maverage test of epoch 4: loss -1.25444 acc 0.42105 roc_auc 0.51385 prc_auc 0.77146[0m
[92maverage training of epoch 5: loss -1.38424 acc 0.54000 roc_auc 0.53140 prc_auc 0.72843[0m
[93maverage test of epoch 5: loss -1.58151 acc 0.65789 roc_auc 0.74462 prc_auc 0.88869[0m
[92maverage training of epoch 6: loss -1.72999 acc 0.66667 roc_auc 0.56780 prc_auc 0.75990[0m
[93maverage test of epoch 6: loss -1.92222 acc 0.65789 roc_auc 0.87692 prc_auc 0.92959[0m
[92maverage training of epoch 7: loss -2.06217 acc 0.66667 roc_auc 0.60740 prc_auc 0.79153[0m
[93maverage test of epoch 7: loss -2.21984 acc 0.65789 roc_auc 0.79692 prc_auc 0.89472[0m
[92maverage training of epoch 8: loss -2.33492 acc 0.66667 roc_auc 0.65800 prc_auc 0.82561[0m
[93maverage test of epoch 8: loss -2.45186 acc 0.65789 roc_auc 0.80000 prc_auc 0.89847[0m
[92maverage training of epoch 9: loss -2.54485 acc 0.66667 roc_auc 0.70740 prc_auc 0.85347[0m
[93maverage test of epoch 9: loss -2.63239 acc 0.65789 roc_auc 0.80615 prc_auc 0.90328[0m
[92maverage training of epoch 10: loss -2.71060 acc 0.66667 roc_auc 0.74280 prc_auc 0.87130[0m
[93maverage test of epoch 10: loss -2.77963 acc 0.65789 roc_auc 0.81538 prc_auc 0.90905[0m
[92maverage training of epoch 11: loss -2.84833 acc 0.66667 roc_auc 0.76160 prc_auc 0.87961[0m
[93maverage test of epoch 11: loss -2.90550 acc 0.65789 roc_auc 0.81231 prc_auc 0.90709[0m
[92maverage training of epoch 12: loss -2.96794 acc 0.66667 roc_auc 0.76520 prc_auc 0.87837[0m
[93maverage test of epoch 12: loss -3.01711 acc 0.65789 roc_auc 0.81231 prc_auc 0.90709[0m
[92maverage training of epoch 13: loss -3.07530 acc 0.66667 roc_auc 0.76780 prc_auc 0.87652[0m
[93maverage test of epoch 13: loss -3.11879 acc 0.65789 roc_auc 0.81231 prc_auc 0.90709[0m
[92maverage training of epoch 14: loss -3.17403 acc 0.66667 roc_auc 0.76300 prc_auc 0.86987[0m
[93maverage test of epoch 14: loss -3.21329 acc 0.65789 roc_auc 0.81231 prc_auc 0.90709[0m
[92maverage training of epoch 15: loss -3.26642 acc 0.66667 roc_auc 0.74860 prc_auc 0.86078[0m
[93maverage test of epoch 15: loss -3.30240 acc 0.65789 roc_auc 0.81231 prc_auc 0.90709[0m
[92maverage training of epoch 16: loss -3.35399 acc 0.66667 roc_auc 0.72860 prc_auc 0.84756[0m
[93maverage test of epoch 16: loss -3.38735 acc 0.65789 roc_auc 0.81231 prc_auc 0.90709[0m
[92maverage training of epoch 17: loss -3.43779 acc 0.66667 roc_auc 0.70280 prc_auc 0.83258[0m
[93maverage test of epoch 17: loss -3.46899 acc 0.65789 roc_auc 0.81231 prc_auc 0.90709[0m
[92maverage training of epoch 18: loss -3.51857 acc 0.66667 roc_auc 0.68340 prc_auc 0.82184[0m
[93maverage test of epoch 18: loss -3.54797 acc 0.65789 roc_auc 0.80923 prc_auc 0.90376[0m
[92maverage training of epoch 19: loss -3.59689 acc 0.66667 roc_auc 0.66280 prc_auc 0.80897[0m
[93maverage test of epoch 19: loss -3.62474 acc 0.65789 roc_auc 0.81231 prc_auc 0.90572[0m
[92maverage training of epoch 20: loss -3.67316 acc 0.66667 roc_auc 0.64140 prc_auc 0.79637[0m
[93maverage test of epoch 20: loss -3.69967 acc 0.65789 roc_auc 0.81077 prc_auc 0.90416[0m
[92maverage training of epoch 21: loss -3.74771 acc 0.66667 roc_auc 0.62460 prc_auc 0.78598[0m
[93maverage test of epoch 21: loss -3.77305 acc 0.65789 roc_auc 0.80923 prc_auc 0.90416[0m
[92maverage training of epoch 22: loss -3.82080 acc 0.66667 roc_auc 0.60860 prc_auc 0.77629[0m
[93maverage test of epoch 22: loss -3.84509 acc 0.65789 roc_auc 0.80923 prc_auc 0.90416[0m
[92maverage training of epoch 23: loss -3.89263 acc 0.66667 roc_auc 0.58900 prc_auc 0.76112[0m
[93maverage test of epoch 23: loss -3.91598 acc 0.65789 roc_auc 0.80923 prc_auc 0.90416[0m
[92maverage training of epoch 24: loss -3.96336 acc 0.66667 roc_auc 0.56990 prc_auc 0.74801[0m
[93maverage test of epoch 24: loss -3.98586 acc 0.65789 roc_auc 0.81231 prc_auc 0.90603[0m
[92maverage training of epoch 25: loss -4.03311 acc 0.66667 roc_auc 0.54940 prc_auc 0.73139[0m
[93maverage test of epoch 25: loss -4.05484 acc 0.65789 roc_auc 0.81231 prc_auc 0.90603[0m
[92maverage training of epoch 26: loss -4.10199 acc 0.66667 roc_auc 0.53500 prc_auc 0.71949[0m
[93maverage test of epoch 26: loss -4.12300 acc 0.65789 roc_auc 0.81231 prc_auc 0.90603[0m
[92maverage training of epoch 27: loss -4.17008 acc 0.66667 roc_auc 0.51990 prc_auc 0.70806[0m
[93maverage test of epoch 27: loss -4.19041 acc 0.65789 roc_auc 0.81231 prc_auc 0.90603[0m
[92maverage training of epoch 28: loss -4.23745 acc 0.66667 roc_auc 0.50340 prc_auc 0.69445[0m
[93maverage test of epoch 28: loss -4.25714 acc 0.65789 roc_auc 0.81231 prc_auc 0.90603[0m
[92maverage training of epoch 29: loss -4.30414 acc 0.66667 roc_auc 0.49220 prc_auc 0.68427[0m
[93maverage test of epoch 29: loss -4.32323 acc 0.65789 roc_auc 0.81231 prc_auc 0.90603[0m
[92maverage training of epoch 30: loss -4.37020 acc 0.66667 roc_auc 0.48260 prc_auc 0.67028[0m
[93maverage test of epoch 30: loss -4.38871 acc 0.65789 roc_auc 0.81077 prc_auc 0.90441[0m
[92maverage training of epoch 31: loss -4.43566 acc 0.66667 roc_auc 0.47280 prc_auc 0.66091[0m
[93maverage test of epoch 31: loss -4.45361 acc 0.65789 roc_auc 0.80923 prc_auc 0.90441[0m
[92maverage training of epoch 32: loss -4.50056 acc 0.66667 roc_auc 0.46260 prc_auc 0.65073[0m
[93maverage test of epoch 32: loss -4.51796 acc 0.65789 roc_auc 0.80769 prc_auc 0.90254[0m
[92maverage training of epoch 33: loss -4.56490 acc 0.66667 roc_auc 0.45680 prc_auc 0.64682[0m
[93maverage test of epoch 33: loss -4.58178 acc 0.65789 roc_auc 0.80923 prc_auc 0.90254[0m
[92maverage training of epoch 34: loss -4.62873 acc 0.66667 roc_auc 0.45060 prc_auc 0.64183[0m
[93maverage test of epoch 34: loss -4.64509 acc 0.65789 roc_auc 0.80769 prc_auc 0.90254[0m
[92maverage training of epoch 35: loss -4.69205 acc 0.66667 roc_auc 0.44520 prc_auc 0.63376[0m
[93maverage test of epoch 35: loss -4.70791 acc 0.65789 roc_auc 0.80615 prc_auc 0.90254[0m
[92maverage training of epoch 36: loss -4.75489 acc 0.66667 roc_auc 0.44020 prc_auc 0.62790[0m
[93maverage test of epoch 36: loss -4.77027 acc 0.65789 roc_auc 0.80769 prc_auc 0.90254[0m
[92maverage training of epoch 37: loss -4.81727 acc 0.66667 roc_auc 0.43680 prc_auc 0.62491[0m
[93maverage test of epoch 37: loss -4.83217 acc 0.65789 roc_auc 0.80615 prc_auc 0.90273[0m
[92maverage training of epoch 38: loss -4.87920 acc 0.66667 roc_auc 0.43460 prc_auc 0.62168[0m
[93maverage test of epoch 38: loss -4.89363 acc 0.65789 roc_auc 0.80769 prc_auc 0.90273[0m
[92maverage training of epoch 39: loss -4.94070 acc 0.66667 roc_auc 0.43180 prc_auc 0.61840[0m
[93maverage test of epoch 39: loss -4.95469 acc 0.65789 roc_auc 0.80308 prc_auc 0.89546[0m
[92maverage training of epoch 40: loss -5.00180 acc 0.66667 roc_auc 0.42910 prc_auc 0.61537[0m
[93maverage test of epoch 40: loss -5.01534 acc 0.65789 roc_auc 0.80462 prc_auc 0.89713[0m
[92maverage training of epoch 41: loss -5.06251 acc 0.66667 roc_auc 0.42670 prc_auc 0.61233[0m
[93maverage test of epoch 41: loss -5.07562 acc 0.65789 roc_auc 0.80769 prc_auc 0.90077[0m
[92maverage training of epoch 42: loss -5.12284 acc 0.66667 roc_auc 0.42450 prc_auc 0.60694[0m
[93maverage test of epoch 42: loss -5.13555 acc 0.65789 roc_auc 0.80769 prc_auc 0.90077[0m
[92maverage training of epoch 43: loss -5.18283 acc 0.66667 roc_auc 0.42340 prc_auc 0.60625[0m
[93maverage test of epoch 43: loss -5.19513 acc 0.65789 roc_auc 0.80000 prc_auc 0.89257[0m
[92maverage training of epoch 44: loss -5.24249 acc 0.66667 roc_auc 0.42220 prc_auc 0.60529[0m
[93maverage test of epoch 44: loss -5.25439 acc 0.65789 roc_auc 0.80615 prc_auc 0.89410[0m
[92maverage training of epoch 45: loss -5.30183 acc 0.66667 roc_auc 0.42100 prc_auc 0.60139[0m
[93maverage test of epoch 45: loss -5.31335 acc 0.65789 roc_auc 0.80462 prc_auc 0.89616[0m
[92maverage training of epoch 46: loss -5.36087 acc 0.66667 roc_auc 0.42010 prc_auc 0.60001[0m
[93maverage test of epoch 46: loss -5.37203 acc 0.65789 roc_auc 0.79846 prc_auc 0.89037[0m
[92maverage training of epoch 47: loss -5.41964 acc 0.66667 roc_auc 0.41960 prc_auc 0.59878[0m
[93maverage test of epoch 47: loss -5.43045 acc 0.65789 roc_auc 0.80308 prc_auc 0.89147[0m
[92maverage training of epoch 48: loss -5.47815 acc 0.66667 roc_auc 0.41880 prc_auc 0.59744[0m
[93maverage test of epoch 48: loss -5.48861 acc 0.65789 roc_auc 0.80154 prc_auc 0.88972[0m
[92maverage training of epoch 49: loss -5.53642 acc 0.66667 roc_auc 0.41910 prc_auc 0.59740[0m
[93maverage test of epoch 49: loss -5.54654 acc 0.65789 roc_auc 0.80308 prc_auc 0.88804[0m
[92maverage training of epoch 50: loss -5.59446 acc 0.66667 roc_auc 0.41840 prc_auc 0.59744[0m
[93maverage test of epoch 50: loss -5.60425 acc 0.65789 roc_auc 0.79692 prc_auc 0.88372[0m
[92maverage training of epoch 51: loss -5.65228 acc 0.66667 roc_auc 0.41840 prc_auc 0.59748[0m
[93maverage test of epoch 51: loss -5.66177 acc 0.65789 roc_auc 0.80308 prc_auc 0.89106[0m
[92maverage training of epoch 52: loss -5.70991 acc 0.66667 roc_auc 0.41790 prc_auc 0.59651[0m
[93maverage test of epoch 52: loss -5.71909 acc 0.65789 roc_auc 0.79538 prc_auc 0.88476[0m
[92maverage training of epoch 53: loss -5.76735 acc 0.66667 roc_auc 0.41760 prc_auc 0.59649[0m
[93maverage test of epoch 53: loss -5.77624 acc 0.65789 roc_auc 0.79692 prc_auc 0.88335[0m
[92maverage training of epoch 54: loss -5.82463 acc 0.66667 roc_auc 0.41770 prc_auc 0.59647[0m
[93maverage test of epoch 54: loss -5.83323 acc 0.65789 roc_auc 0.78308 prc_auc 0.85809[0m
[92maverage training of epoch 55: loss -5.88174 acc 0.66667 roc_auc 0.41730 prc_auc 0.59647[0m
[93maverage test of epoch 55: loss -5.89007 acc 0.65789 roc_auc 0.80000 prc_auc 0.87854[0m
[92maverage training of epoch 56: loss -5.93871 acc 0.66667 roc_auc 0.41680 prc_auc 0.59758[0m
[93maverage test of epoch 56: loss -5.94677 acc 0.65789 roc_auc 0.78923 prc_auc 0.85486[0m
[92maverage training of epoch 57: loss -5.99555 acc 0.66667 roc_auc 0.41610 prc_auc 0.59704[0m
[93maverage test of epoch 57: loss -6.00334 acc 0.65789 roc_auc 0.79385 prc_auc 0.86018[0m
[92maverage training of epoch 58: loss -6.05225 acc 0.66667 roc_auc 0.41640 prc_auc 0.59730[0m
[93maverage test of epoch 58: loss -6.05979 acc 0.65789 roc_auc 0.79846 prc_auc 0.87943[0m
[92maverage training of epoch 59: loss -6.10884 acc 0.66667 roc_auc 0.41630 prc_auc 0.59756[0m
[93maverage test of epoch 59: loss -6.11613 acc 0.65789 roc_auc 0.78615 prc_auc 0.85685[0m
[92maverage training of epoch 60: loss -6.16533 acc 0.66667 roc_auc 0.41570 prc_auc 0.59717[0m
[93maverage test of epoch 60: loss -6.17238 acc 0.65789 roc_auc 0.78923 prc_auc 0.85577[0m
[92maverage training of epoch 61: loss -6.22171 acc 0.66667 roc_auc 0.41580 prc_auc 0.59826[0m
[93maverage test of epoch 61: loss -6.22852 acc 0.65789 roc_auc 0.79077 prc_auc 0.87041[0m
[92maverage training of epoch 62: loss -6.27800 acc 0.66667 roc_auc 0.41640 prc_auc 0.60069[0m
[93maverage test of epoch 62: loss -6.28459 acc 0.65789 roc_auc 0.78923 prc_auc 0.85540[0m
[92maverage training of epoch 63: loss -6.33421 acc 0.66667 roc_auc 0.41700 prc_auc 0.60111[0m
[93maverage test of epoch 63: loss -6.34057 acc 0.65789 roc_auc 0.78769 prc_auc 0.85915[0m
[92maverage training of epoch 64: loss -6.39034 acc 0.66667 roc_auc 0.41770 prc_auc 0.60157[0m
[93maverage test of epoch 64: loss -6.39648 acc 0.65789 roc_auc 0.80154 prc_auc 0.87976[0m
[92maverage training of epoch 65: loss -6.44640 acc 0.66667 roc_auc 0.41780 prc_auc 0.60161[0m
[93maverage test of epoch 65: loss -6.45233 acc 0.65789 roc_auc 0.78462 prc_auc 0.85067[0m
[92maverage training of epoch 66: loss -6.50240 acc 0.66667 roc_auc 0.41820 prc_auc 0.60181[0m
[93maverage test of epoch 66: loss -6.50811 acc 0.65789 roc_auc 0.78462 prc_auc 0.85157[0m
[92maverage training of epoch 67: loss -6.55833 acc 0.66667 roc_auc 0.41850 prc_auc 0.60217[0m
[93maverage test of epoch 67: loss -6.56384 acc 0.65789 roc_auc 0.77538 prc_auc 0.84005[0m
[92maverage training of epoch 68: loss -6.61421 acc 0.66667 roc_auc 0.41890 prc_auc 0.60233[0m
[93maverage test of epoch 68: loss -6.61951 acc 0.65789 roc_auc 0.74462 prc_auc 0.80824[0m
[92maverage training of epoch 69: loss -6.67004 acc 0.66667 roc_auc 0.41900 prc_auc 0.60303[0m
[93maverage test of epoch 69: loss -6.67514 acc 0.65789 roc_auc 0.77846 prc_auc 0.84076[0m
[92maverage training of epoch 70: loss -6.72582 acc 0.66667 roc_auc 0.41940 prc_auc 0.60380[0m
[93maverage test of epoch 70: loss -6.73072 acc 0.65789 roc_auc 0.75846 prc_auc 0.81958[0m
[92maverage training of epoch 71: loss -6.78155 acc 0.66667 roc_auc 0.41950 prc_auc 0.60434[0m
[93maverage test of epoch 71: loss -6.78627 acc 0.65789 roc_auc 0.74000 prc_auc 0.80601[0m
[92maverage training of epoch 72: loss -6.83725 acc 0.66667 roc_auc 0.41970 prc_auc 0.60441[0m
[93maverage test of epoch 72: loss -6.84177 acc 0.65789 roc_auc 0.74462 prc_auc 0.80824[0m
[92maverage training of epoch 73: loss -6.89291 acc 0.66667 roc_auc 0.42000 prc_auc 0.60482[0m
[93maverage test of epoch 73: loss -6.89724 acc 0.65789 roc_auc 0.78462 prc_auc 0.84355[0m
[92maverage training of epoch 74: loss -6.94853 acc 0.66667 roc_auc 0.42020 prc_auc 0.60463[0m
[93maverage test of epoch 74: loss -6.95268 acc 0.65789 roc_auc 0.79538 prc_auc 0.87146[0m
[92maverage training of epoch 75: loss -7.00413 acc 0.66667 roc_auc 0.42060 prc_auc 0.60529[0m
[93maverage test of epoch 75: loss -7.00809 acc 0.65789 roc_auc 0.79846 prc_auc 0.85768[0m
[92maverage training of epoch 76: loss -7.05969 acc 0.66667 roc_auc 0.42060 prc_auc 0.60564[0m
[93maverage test of epoch 76: loss -7.06348 acc 0.65789 roc_auc 0.79231 prc_auc 0.85330[0m
[92maverage training of epoch 77: loss -7.11523 acc 0.66667 roc_auc 0.42060 prc_auc 0.60526[0m
[93maverage test of epoch 77: loss -7.11883 acc 0.65789 roc_auc 0.74000 prc_auc 0.80601[0m
[92maverage training of epoch 78: loss -7.17075 acc 0.66667 roc_auc 0.42060 prc_auc 0.60526[0m
[93maverage test of epoch 78: loss -7.17417 acc 0.65789 roc_auc 0.76769 prc_auc 0.83698[0m
[92maverage training of epoch 79: loss -7.22624 acc 0.66667 roc_auc 0.42060 prc_auc 0.60526[0m
[93maverage test of epoch 79: loss -7.22949 acc 0.65789 roc_auc 0.78923 prc_auc 0.82706[0m
[92maverage training of epoch 80: loss -7.28171 acc 0.66667 roc_auc 0.42050 prc_auc 0.60495[0m
[93maverage test of epoch 80: loss -7.28478 acc 0.65789 roc_auc 0.80462 prc_auc 0.83697[0m
[92maverage training of epoch 81: loss -7.33716 acc 0.66667 roc_auc 0.42030 prc_auc 0.60466[0m
[93maverage test of epoch 81: loss -7.34006 acc 0.65789 roc_auc 0.85846 prc_auc 0.87310[0m
[92maverage training of epoch 82: loss -7.39260 acc 0.66667 roc_auc 0.42020 prc_auc 0.60455[0m
[93maverage test of epoch 82: loss -7.39533 acc 0.65789 roc_auc 0.83538 prc_auc 0.85692[0m
[92maverage training of epoch 83: loss -7.44802 acc 0.66667 roc_auc 0.42020 prc_auc 0.60455[0m
[93maverage test of epoch 83: loss -7.45058 acc 0.65789 roc_auc 0.76308 prc_auc 0.82121[0m
[92maverage training of epoch 84: loss -7.50343 acc 0.66667 roc_auc 0.42050 prc_auc 0.60495[0m
[93maverage test of epoch 84: loss -7.50581 acc 0.65789 roc_auc 0.82308 prc_auc 0.84667[0m
[92maverage training of epoch 85: loss -7.55882 acc 0.66667 roc_auc 0.42040 prc_auc 0.60495[0m
[93maverage test of epoch 85: loss -7.56104 acc 0.65789 roc_auc 0.82769 prc_auc 0.86424[0m
[92maverage training of epoch 86: loss -7.61420 acc 0.66667 roc_auc 0.42020 prc_auc 0.60458[0m
[93maverage test of epoch 86: loss -7.61625 acc 0.65789 roc_auc 0.86000 prc_auc 0.88625[0m
[92maverage training of epoch 87: loss -7.66957 acc 0.66667 roc_auc 0.42020 prc_auc 0.60458[0m
[93maverage test of epoch 87: loss -7.67145 acc 0.65789 roc_auc 0.82308 prc_auc 0.84667[0m
[92maverage training of epoch 88: loss -7.72493 acc 0.66667 roc_auc 0.42040 prc_auc 0.60495[0m
[93maverage test of epoch 88: loss -7.72665 acc 0.65789 roc_auc 0.74769 prc_auc 0.79884[0m
[92maverage training of epoch 89: loss -7.78028 acc 0.66667 roc_auc 0.42020 prc_auc 0.60466[0m
[93maverage test of epoch 89: loss -7.78183 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 90: loss -7.83562 acc 0.66667 roc_auc 0.42020 prc_auc 0.60458[0m
[93maverage test of epoch 90: loss -7.83700 acc 0.65789 roc_auc 0.82308 prc_auc 0.84667[0m
[92maverage training of epoch 91: loss -7.89095 acc 0.66667 roc_auc 0.42020 prc_auc 0.60458[0m
[93maverage test of epoch 91: loss -7.89217 acc 0.65789 roc_auc 0.81846 prc_auc 0.84819[0m
[92maverage training of epoch 92: loss -7.94628 acc 0.66667 roc_auc 0.42020 prc_auc 0.60458[0m
[93maverage test of epoch 92: loss -7.94733 acc 0.65789 roc_auc 0.67846 prc_auc 0.76484[0m
[92maverage training of epoch 93: loss -8.00160 acc 0.66667 roc_auc 0.42040 prc_auc 0.60495[0m
[93maverage test of epoch 93: loss -8.00249 acc 0.65789 roc_auc 0.57846 prc_auc 0.71242[0m
[92maverage training of epoch 94: loss -8.05691 acc 0.66667 roc_auc 0.42030 prc_auc 0.60466[0m
[93maverage test of epoch 94: loss -8.05763 acc 0.65789 roc_auc 0.72462 prc_auc 0.80436[0m
[92maverage training of epoch 95: loss -8.11221 acc 0.66667 roc_auc 0.42020 prc_auc 0.60458[0m
[93maverage test of epoch 95: loss -8.11278 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 96: loss -8.16752 acc 0.66667 roc_auc 0.42040 prc_auc 0.60466[0m
[93maverage test of epoch 96: loss -8.16792 acc 0.65789 roc_auc 0.75846 prc_auc 0.81158[0m
[92maverage training of epoch 97: loss -8.22281 acc 0.66667 roc_auc 0.42020 prc_auc 0.60466[0m
[93maverage test of epoch 97: loss -8.22305 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 98: loss -8.27810 acc 0.66667 roc_auc 0.42020 prc_auc 0.60458[0m
[93maverage test of epoch 98: loss -8.27818 acc 0.65789 roc_auc 0.75846 prc_auc 0.81158[0m
[92maverage training of epoch 99: loss -8.33339 acc 0.66667 roc_auc 0.42030 prc_auc 0.60466[0m
[93maverage test of epoch 99: loss -8.33331 acc 0.65789 roc_auc 0.68000 prc_auc 0.78105[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss 0.26668 acc 0.33333 roc_auc 0.36460 prc_auc 0.60265[0m
[93maverage test of epoch 0: loss 0.21086 acc 0.34211 roc_auc 0.31538 prc_auc 0.66912[0m
[92maverage training of epoch 1: loss 0.16490 acc 0.34667 roc_auc 0.38760 prc_auc 0.62140[0m
[93maverage test of epoch 1: loss 0.11395 acc 0.34211 roc_auc 0.43385 prc_auc 0.73884[0m
[92maverage training of epoch 2: loss 0.06750 acc 0.46667 roc_auc 0.41400 prc_auc 0.63869[0m
[93maverage test of epoch 2: loss 0.02059 acc 0.63158 roc_auc 0.56923 prc_auc 0.82126[0m
[92maverage training of epoch 3: loss -0.02669 acc 0.66000 roc_auc 0.43840 prc_auc 0.66107[0m
[93maverage test of epoch 3: loss -0.07017 acc 0.65789 roc_auc 0.65231 prc_auc 0.85938[0m
[92maverage training of epoch 4: loss -0.11873 acc 0.66000 roc_auc 0.47100 prc_auc 0.68596[0m
[93maverage test of epoch 4: loss -0.15945 acc 0.65789 roc_auc 0.74154 prc_auc 0.89821[0m
[92maverage training of epoch 5: loss -0.20985 acc 0.66667 roc_auc 0.50080 prc_auc 0.71674[0m
[93maverage test of epoch 5: loss -0.24861 acc 0.65789 roc_auc 0.78769 prc_auc 0.91737[0m
[92maverage training of epoch 6: loss -0.30161 acc 0.66667 roc_auc 0.52140 prc_auc 0.73257[0m
[93maverage test of epoch 6: loss -0.33959 acc 0.65789 roc_auc 0.82615 prc_auc 0.93279[0m
[92maverage training of epoch 7: loss -0.39664 acc 0.66667 roc_auc 0.54320 prc_auc 0.75209[0m
[93maverage test of epoch 7: loss -0.43606 acc 0.65789 roc_auc 0.92308 prc_auc 0.96774[0m
[92maverage training of epoch 8: loss -0.50011 acc 0.66667 roc_auc 0.55300 prc_auc 0.75890[0m
[93maverage test of epoch 8: loss -0.54489 acc 0.65789 roc_auc 0.95385 prc_auc 0.98035[0m
[92maverage training of epoch 9: loss -0.62036 acc 0.66667 roc_auc 0.55620 prc_auc 0.76092[0m
[93maverage test of epoch 9: loss -0.67541 acc 0.65789 roc_auc 0.95538 prc_auc 0.98035[0m
[92maverage training of epoch 10: loss -0.76582 acc 0.66667 roc_auc 0.55740 prc_auc 0.76256[0m
[93maverage test of epoch 10: loss -0.83389 acc 0.65789 roc_auc 0.95385 prc_auc 0.97950[0m
[92maverage training of epoch 11: loss -0.93752 acc 0.66667 roc_auc 0.56240 prc_auc 0.76677[0m
[93maverage test of epoch 11: loss -1.01492 acc 0.65789 roc_auc 0.95385 prc_auc 0.97950[0m
[92maverage training of epoch 12: loss -1.12415 acc 0.66667 roc_auc 0.57260 prc_auc 0.77339[0m
[93maverage test of epoch 12: loss -1.20287 acc 0.65789 roc_auc 0.95385 prc_auc 0.97950[0m
[92maverage training of epoch 13: loss -1.31151 acc 0.66667 roc_auc 0.58780 prc_auc 0.78429[0m
[93maverage test of epoch 13: loss -1.38647 acc 0.65789 roc_auc 0.95385 prc_auc 0.97950[0m
[92maverage training of epoch 14: loss -1.49147 acc 0.66667 roc_auc 0.60180 prc_auc 0.79452[0m
[93maverage test of epoch 14: loss -1.55959 acc 0.65789 roc_auc 0.95385 prc_auc 0.97950[0m
[92maverage training of epoch 15: loss -1.65916 acc 0.66667 roc_auc 0.61120 prc_auc 0.79780[0m
[93maverage test of epoch 15: loss -1.71917 acc 0.65789 roc_auc 0.95385 prc_auc 0.97950[0m
[92maverage training of epoch 16: loss -1.81518 acc 0.66667 roc_auc 0.59540 prc_auc 0.77713[0m
[93maverage test of epoch 16: loss -1.86943 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 17: loss -1.96478 acc 0.66667 roc_auc 0.55840 prc_auc 0.74430[0m
[93maverage test of epoch 17: loss -2.01589 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 18: loss -2.11215 acc 0.66667 roc_auc 0.53760 prc_auc 0.72698[0m
[93maverage test of epoch 18: loss -2.16155 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 19: loss -2.25897 acc 0.66667 roc_auc 0.53620 prc_auc 0.72588[0m
[93maverage test of epoch 19: loss -2.30662 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 20: loss -2.40366 acc 0.66667 roc_auc 0.54280 prc_auc 0.73330[0m
[93maverage test of epoch 20: loss -2.44785 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 21: loss -2.54197 acc 0.66667 roc_auc 0.55500 prc_auc 0.74666[0m
[93maverage test of epoch 21: loss -2.58048 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 22: loss -2.66972 acc 0.66667 roc_auc 0.57960 prc_auc 0.76549[0m
[93maverage test of epoch 22: loss -2.70128 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 23: loss -2.78508 acc 0.66667 roc_auc 0.60650 prc_auc 0.79037[0m
[93maverage test of epoch 23: loss -2.80972 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 24: loss -2.88860 acc 0.66667 roc_auc 0.62480 prc_auc 0.80493[0m
[93maverage test of epoch 24: loss -2.90716 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 25: loss -2.98228 acc 0.66667 roc_auc 0.63900 prc_auc 0.81307[0m
[93maverage test of epoch 25: loss -2.99603 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 26: loss -3.06864 acc 0.66667 roc_auc 0.64680 prc_auc 0.81493[0m
[93maverage test of epoch 26: loss -3.07880 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 27: loss -3.14981 acc 0.66667 roc_auc 0.64780 prc_auc 0.81254[0m
[93maverage test of epoch 27: loss -3.15727 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 28: loss -3.22725 acc 0.66667 roc_auc 0.64800 prc_auc 0.81109[0m
[93maverage test of epoch 28: loss -3.23262 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 29: loss -3.30190 acc 0.66667 roc_auc 0.64370 prc_auc 0.80373[0m
[93maverage test of epoch 29: loss -3.30558 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 30: loss -3.37438 acc 0.66667 roc_auc 0.63760 prc_auc 0.79859[0m
[93maverage test of epoch 30: loss -3.37667 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 31: loss -3.44511 acc 0.66667 roc_auc 0.62540 prc_auc 0.78820[0m
[93maverage test of epoch 31: loss -3.44622 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 32: loss -3.51437 acc 0.66667 roc_auc 0.61340 prc_auc 0.77721[0m
[93maverage test of epoch 32: loss -3.51446 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 33: loss -3.58239 acc 0.66667 roc_auc 0.60720 prc_auc 0.77301[0m
[93maverage test of epoch 33: loss -3.58159 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 34: loss -3.64934 acc 0.66667 roc_auc 0.59960 prc_auc 0.76691[0m
[93maverage test of epoch 34: loss -3.64773 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 35: loss -3.71534 acc 0.66667 roc_auc 0.58920 prc_auc 0.75974[0m
[93maverage test of epoch 35: loss -3.71302 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 36: loss -3.78050 acc 0.66667 roc_auc 0.58060 prc_auc 0.75372[0m
[93maverage test of epoch 36: loss -3.77752 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 37: loss -3.84490 acc 0.66667 roc_auc 0.57290 prc_auc 0.74727[0m
[93maverage test of epoch 37: loss -3.84134 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 38: loss -3.90863 acc 0.66667 roc_auc 0.56390 prc_auc 0.74131[0m
[93maverage test of epoch 38: loss -3.90452 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 39: loss -3.97174 acc 0.66667 roc_auc 0.55100 prc_auc 0.73154[0m
[93maverage test of epoch 39: loss -3.96713 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 40: loss -4.03428 acc 0.66667 roc_auc 0.54040 prc_auc 0.72337[0m
[93maverage test of epoch 40: loss -4.02921 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 41: loss -4.09632 acc 0.66667 roc_auc 0.53070 prc_auc 0.71582[0m
[93maverage test of epoch 41: loss -4.09081 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 42: loss -4.15788 acc 0.66667 roc_auc 0.52340 prc_auc 0.71126[0m
[93maverage test of epoch 42: loss -4.15196 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 43: loss -4.21900 acc 0.66667 roc_auc 0.51740 prc_auc 0.70701[0m
[93maverage test of epoch 43: loss -4.21270 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 44: loss -4.27972 acc 0.66667 roc_auc 0.51240 prc_auc 0.70222[0m
[93maverage test of epoch 44: loss -4.27305 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 45: loss -4.34006 acc 0.66667 roc_auc 0.50350 prc_auc 0.69472[0m
[93maverage test of epoch 45: loss -4.33305 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 46: loss -4.40006 acc 0.66667 roc_auc 0.49140 prc_auc 0.68315[0m
[93maverage test of epoch 46: loss -4.39272 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 47: loss -4.45973 acc 0.66667 roc_auc 0.47940 prc_auc 0.67317[0m
[93maverage test of epoch 47: loss -4.45208 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 48: loss -4.51910 acc 0.66667 roc_auc 0.47030 prc_auc 0.66730[0m
[93maverage test of epoch 48: loss -4.51115 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 49: loss -4.57819 acc 0.66667 roc_auc 0.46320 prc_auc 0.66107[0m
[93maverage test of epoch 49: loss -4.56995 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 50: loss -4.63702 acc 0.66667 roc_auc 0.45620 prc_auc 0.65587[0m
[93maverage test of epoch 50: loss -4.62850 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 51: loss -4.69561 acc 0.66667 roc_auc 0.45110 prc_auc 0.65385[0m
[93maverage test of epoch 51: loss -4.68682 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 52: loss -4.75397 acc 0.66667 roc_auc 0.44730 prc_auc 0.65119[0m
[93maverage test of epoch 52: loss -4.74492 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 53: loss -4.81211 acc 0.66667 roc_auc 0.44410 prc_auc 0.65057[0m
[93maverage test of epoch 53: loss -4.80282 acc 0.65789 roc_auc 0.95231 prc_auc 0.97791[0m
[92maverage training of epoch 54: loss -4.87006 acc 0.66667 roc_auc 0.44110 prc_auc 0.64816[0m
[93maverage test of epoch 54: loss -4.86052 acc 0.65789 roc_auc 0.95385 prc_auc 0.97946[0m
[92maverage training of epoch 55: loss -4.92782 acc 0.66667 roc_auc 0.43770 prc_auc 0.64641[0m
[93maverage test of epoch 55: loss -4.91804 acc 0.65789 roc_auc 0.95231 prc_auc 0.97791[0m
[92maverage training of epoch 56: loss -4.98540 acc 0.66667 roc_auc 0.43350 prc_auc 0.64355[0m
[93maverage test of epoch 56: loss -4.97540 acc 0.65789 roc_auc 0.95385 prc_auc 0.97946[0m
[92maverage training of epoch 57: loss -5.04283 acc 0.66667 roc_auc 0.43040 prc_auc 0.64100[0m
[93maverage test of epoch 57: loss -5.03260 acc 0.65789 roc_auc 0.95385 prc_auc 0.97946[0m
[92maverage training of epoch 58: loss -5.10010 acc 0.66667 roc_auc 0.42770 prc_auc 0.63842[0m
[93maverage test of epoch 58: loss -5.08966 acc 0.65789 roc_auc 0.95231 prc_auc 0.97791[0m
[92maverage training of epoch 59: loss -5.15724 acc 0.66667 roc_auc 0.42510 prc_auc 0.63753[0m
[93maverage test of epoch 59: loss -5.14658 acc 0.65789 roc_auc 0.95077 prc_auc 0.97663[0m
[92maverage training of epoch 60: loss -5.21424 acc 0.66667 roc_auc 0.42080 prc_auc 0.63421[0m
[93maverage test of epoch 60: loss -5.20337 acc 0.65789 roc_auc 0.95231 prc_auc 0.97791[0m
[92maverage training of epoch 61: loss -5.27111 acc 0.66667 roc_auc 0.41590 prc_auc 0.62917[0m
[93maverage test of epoch 61: loss -5.26004 acc 0.65789 roc_auc 0.95077 prc_auc 0.97663[0m
[92maverage training of epoch 62: loss -5.32788 acc 0.66667 roc_auc 0.41300 prc_auc 0.62670[0m
[93maverage test of epoch 62: loss -5.31660 acc 0.65789 roc_auc 0.95077 prc_auc 0.97663[0m
[92maverage training of epoch 63: loss -5.38453 acc 0.66667 roc_auc 0.41000 prc_auc 0.62482[0m
[93maverage test of epoch 63: loss -5.37305 acc 0.65789 roc_auc 0.95077 prc_auc 0.97663[0m
[92maverage training of epoch 64: loss -5.44109 acc 0.66667 roc_auc 0.40780 prc_auc 0.62185[0m
[93maverage test of epoch 64: loss -5.42941 acc 0.65789 roc_auc 0.95077 prc_auc 0.97663[0m
[92maverage training of epoch 65: loss -5.49755 acc 0.66667 roc_auc 0.40630 prc_auc 0.62089[0m
[93maverage test of epoch 65: loss -5.48568 acc 0.65789 roc_auc 0.95077 prc_auc 0.97663[0m
[92maverage training of epoch 66: loss -5.55392 acc 0.66667 roc_auc 0.40450 prc_auc 0.62037[0m
[93maverage test of epoch 66: loss -5.54186 acc 0.65789 roc_auc 0.95077 prc_auc 0.97663[0m
[92maverage training of epoch 67: loss -5.61021 acc 0.66667 roc_auc 0.40380 prc_auc 0.61933[0m
[93maverage test of epoch 67: loss -5.59797 acc 0.65789 roc_auc 0.95077 prc_auc 0.97663[0m
[92maverage training of epoch 68: loss -5.66643 acc 0.66667 roc_auc 0.40260 prc_auc 0.61862[0m
[93maverage test of epoch 68: loss -5.65400 acc 0.65789 roc_auc 0.94308 prc_auc 0.97264[0m
[92maverage training of epoch 69: loss -5.72258 acc 0.66667 roc_auc 0.40150 prc_auc 0.61444[0m
[93maverage test of epoch 69: loss -5.70997 acc 0.65789 roc_auc 0.94308 prc_auc 0.97264[0m
[92maverage training of epoch 70: loss -5.77866 acc 0.66667 roc_auc 0.39760 prc_auc 0.60885[0m
[93maverage test of epoch 70: loss -5.76587 acc 0.65789 roc_auc 0.94615 prc_auc 0.97264[0m
[92maverage training of epoch 71: loss -5.83468 acc 0.66667 roc_auc 0.39620 prc_auc 0.60827[0m
[93maverage test of epoch 71: loss -5.82171 acc 0.65789 roc_auc 0.94615 prc_auc 0.97264[0m
[92maverage training of epoch 72: loss -5.89064 acc 0.66667 roc_auc 0.39330 prc_auc 0.60642[0m
[93maverage test of epoch 72: loss -5.87749 acc 0.65789 roc_auc 0.94923 prc_auc 0.96936[0m
[92maverage training of epoch 73: loss -5.94655 acc 0.66667 roc_auc 0.39160 prc_auc 0.60581[0m
[93maverage test of epoch 73: loss -5.93322 acc 0.65789 roc_auc 0.94923 prc_auc 0.97001[0m
[92maverage training of epoch 74: loss -6.00242 acc 0.66667 roc_auc 0.39120 prc_auc 0.60598[0m
[93maverage test of epoch 74: loss -5.98891 acc 0.65789 roc_auc 0.96000 prc_auc 0.97663[0m
[92maverage training of epoch 75: loss -6.05823 acc 0.66667 roc_auc 0.39060 prc_auc 0.60521[0m
[93maverage test of epoch 75: loss -6.04455 acc 0.65789 roc_auc 0.94923 prc_auc 0.97264[0m
[92maverage training of epoch 76: loss -6.11400 acc 0.66667 roc_auc 0.38930 prc_auc 0.60474[0m
[93maverage test of epoch 76: loss -6.10015 acc 0.65789 roc_auc 0.93077 prc_auc 0.95418[0m
[92maverage training of epoch 77: loss -6.16974 acc 0.66667 roc_auc 0.38870 prc_auc 0.60445[0m
[93maverage test of epoch 77: loss -6.15572 acc 0.65789 roc_auc 0.93231 prc_auc 0.95907[0m
[92maverage training of epoch 78: loss -6.22543 acc 0.66667 roc_auc 0.38850 prc_auc 0.60320[0m
[93maverage test of epoch 78: loss -6.21124 acc 0.65789 roc_auc 0.94769 prc_auc 0.95697[0m
[92maverage training of epoch 79: loss -6.28110 acc 0.66667 roc_auc 0.38770 prc_auc 0.60186[0m
[93maverage test of epoch 79: loss -6.26674 acc 0.65789 roc_auc 0.92615 prc_auc 0.94959[0m
[92maverage training of epoch 80: loss -6.33673 acc 0.66667 roc_auc 0.38710 prc_auc 0.60168[0m
[93maverage test of epoch 80: loss -6.32220 acc 0.65789 roc_auc 0.94923 prc_auc 0.96346[0m
[92maverage training of epoch 81: loss -6.39233 acc 0.66667 roc_auc 0.38710 prc_auc 0.60112[0m
[93maverage test of epoch 81: loss -6.37763 acc 0.65789 roc_auc 0.92000 prc_auc 0.93298[0m
[92maverage training of epoch 82: loss -6.44791 acc 0.66667 roc_auc 0.38670 prc_auc 0.60104[0m
[93maverage test of epoch 82: loss -6.43304 acc 0.65789 roc_auc 0.93077 prc_auc 0.95632[0m
[92maverage training of epoch 83: loss -6.50345 acc 0.66667 roc_auc 0.38620 prc_auc 0.59771[0m
[93maverage test of epoch 83: loss -6.48842 acc 0.65789 roc_auc 0.86462 prc_auc 0.87965[0m
[92maverage training of epoch 84: loss -6.55898 acc 0.66667 roc_auc 0.38640 prc_auc 0.59813[0m
[93maverage test of epoch 84: loss -6.54378 acc 0.65789 roc_auc 0.86462 prc_auc 0.87965[0m
[92maverage training of epoch 85: loss -6.61448 acc 0.66667 roc_auc 0.38620 prc_auc 0.59971[0m
[93maverage test of epoch 85: loss -6.59912 acc 0.65789 roc_auc 0.88000 prc_auc 0.91789[0m
[92maverage training of epoch 86: loss -6.66997 acc 0.66667 roc_auc 0.38610 prc_auc 0.59826[0m
[93maverage test of epoch 86: loss -6.65444 acc 0.65789 roc_auc 0.86462 prc_auc 0.87965[0m
[92maverage training of epoch 87: loss -6.72544 acc 0.66667 roc_auc 0.38570 prc_auc 0.59711[0m
[93maverage test of epoch 87: loss -6.70975 acc 0.65789 roc_auc 0.82615 prc_auc 0.84917[0m
[92maverage training of epoch 88: loss -6.78089 acc 0.66667 roc_auc 0.38530 prc_auc 0.59756[0m
[93maverage test of epoch 88: loss -6.76503 acc 0.65789 roc_auc 0.67231 prc_auc 0.74632[0m
[92maverage training of epoch 89: loss -6.83632 acc 0.66667 roc_auc 0.38480 prc_auc 0.59753[0m
[93maverage test of epoch 89: loss -6.82030 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -6.89173 acc 0.66667 roc_auc 0.38490 prc_auc 0.59745[0m
[93maverage test of epoch 90: loss -6.87555 acc 0.65789 roc_auc 0.80000 prc_auc 0.86316[0m
[92maverage training of epoch 91: loss -6.94714 acc 0.66667 roc_auc 0.38480 prc_auc 0.59708[0m
[93maverage test of epoch 91: loss -6.93079 acc 0.65789 roc_auc 0.90000 prc_auc 0.93158[0m
[92maverage training of epoch 92: loss -7.00253 acc 0.66667 roc_auc 0.38430 prc_auc 0.59719[0m
[93maverage test of epoch 92: loss -6.98602 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 93: loss -7.05791 acc 0.66667 roc_auc 0.38410 prc_auc 0.59733[0m
[93maverage test of epoch 93: loss -7.04124 acc 0.65789 roc_auc 0.80000 prc_auc 0.86316[0m
[92maverage training of epoch 94: loss -7.11328 acc 0.66667 roc_auc 0.38400 prc_auc 0.59730[0m
[93maverage test of epoch 94: loss -7.09645 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 95: loss -7.16863 acc 0.66667 roc_auc 0.38390 prc_auc 0.59668[0m
[93maverage test of epoch 95: loss -7.15165 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 96: loss -7.22398 acc 0.66667 roc_auc 0.38360 prc_auc 0.59692[0m
[93maverage test of epoch 96: loss -7.20684 acc 0.65789 roc_auc 0.86462 prc_auc 0.87965[0m
[92maverage training of epoch 97: loss -7.27932 acc 0.66667 roc_auc 0.38380 prc_auc 0.59704[0m
[93maverage test of epoch 97: loss -7.26202 acc 0.65789 roc_auc 0.84000 prc_auc 0.89053[0m
[92maverage training of epoch 98: loss -7.33466 acc 0.66667 roc_auc 0.38370 prc_auc 0.59696[0m
[93maverage test of epoch 98: loss -7.31719 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -7.38998 acc 0.66667 roc_auc 0.38390 prc_auc 0.59709[0m
[93maverage test of epoch 99: loss -7.37235 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss 0.00833 acc 0.66225 roc_auc 0.39294 prc_auc 0.59731[0m
[93maverage test of epoch 0: loss -0.02080 acc 0.67568 roc_auc 0.38000 prc_auc 0.70842[0m
[92maverage training of epoch 1: loss -0.03642 acc 0.66225 roc_auc 0.43392 prc_auc 0.62702[0m
[93maverage test of epoch 1: loss -0.06532 acc 0.67568 roc_auc 0.45667 prc_auc 0.75656[0m
[92maverage training of epoch 2: loss -0.08350 acc 0.66225 roc_auc 0.48078 prc_auc 0.65977[0m
[93maverage test of epoch 2: loss -0.11234 acc 0.67568 roc_auc 0.51667 prc_auc 0.78994[0m
[92maverage training of epoch 3: loss -0.13353 acc 0.66225 roc_auc 0.54157 prc_auc 0.70460[0m
[93maverage test of epoch 3: loss -0.16216 acc 0.67568 roc_auc 0.77333 prc_auc 0.90983[0m
[92maverage training of epoch 4: loss -0.18635 acc 0.66225 roc_auc 0.60784 prc_auc 0.76280[0m
[93maverage test of epoch 4: loss -0.21415 acc 0.67568 roc_auc 0.94000 prc_auc 0.97546[0m
[92maverage training of epoch 5: loss -0.24083 acc 0.63576 roc_auc 0.67431 prc_auc 0.82786[0m
[93maverage test of epoch 5: loss -0.26684 acc 0.35135 roc_auc 0.93667 prc_auc 0.97474[0m
[92maverage training of epoch 6: loss -0.29520 acc 0.37086 roc_auc 0.71922 prc_auc 0.86167[0m
[93maverage test of epoch 6: loss -0.31843 acc 0.35135 roc_auc 0.91333 prc_auc 0.95998[0m
[92maverage training of epoch 7: loss -0.34786 acc 0.35762 roc_auc 0.76725 prc_auc 0.88833[0m
[93maverage test of epoch 7: loss -0.36797 acc 0.35135 roc_auc 0.90000 prc_auc 0.95106[0m
[92maverage training of epoch 8: loss -0.39866 acc 0.35099 roc_auc 0.82431 prc_auc 0.91763[0m
[93maverage test of epoch 8: loss -0.41627 acc 0.35135 roc_auc 0.88000 prc_auc 0.93792[0m
[92maverage training of epoch 9: loss -0.44929 acc 0.35099 roc_auc 0.85922 prc_auc 0.93455[0m
[93maverage test of epoch 9: loss -0.46565 acc 0.35135 roc_auc 0.87333 prc_auc 0.93363[0m
[92maverage training of epoch 10: loss -0.50237 acc 0.35099 roc_auc 0.87098 prc_auc 0.94003[0m
[93maverage test of epoch 10: loss -0.51879 acc 0.35135 roc_auc 0.87333 prc_auc 0.93363[0m
[92maverage training of epoch 11: loss -0.56017 acc 0.35099 roc_auc 0.87216 prc_auc 0.94041[0m
[93maverage test of epoch 11: loss -0.57749 acc 0.35135 roc_auc 0.87000 prc_auc 0.92999[0m
[92maverage training of epoch 12: loss -0.62316 acc 0.35099 roc_auc 0.87176 prc_auc 0.94016[0m
[93maverage test of epoch 12: loss -0.64143 acc 0.35135 roc_auc 0.86667 prc_auc 0.92766[0m
[92maverage training of epoch 13: loss -0.68951 acc 0.35099 roc_auc 0.87216 prc_auc 0.94093[0m
[93maverage test of epoch 13: loss -0.70846 acc 0.35135 roc_auc 0.87000 prc_auc 0.93129[0m
[92maverage training of epoch 14: loss -0.75679 acc 0.35099 roc_auc 0.86902 prc_auc 0.94009[0m
[93maverage test of epoch 14: loss -0.77686 acc 0.35135 roc_auc 0.88000 prc_auc 0.93687[0m
[92maverage training of epoch 15: loss -0.82383 acc 0.35099 roc_auc 0.86294 prc_auc 0.93862[0m
[93maverage test of epoch 15: loss -0.84502 acc 0.35135 roc_auc 0.88333 prc_auc 0.93896[0m
[92maverage training of epoch 16: loss -0.89172 acc 0.35099 roc_auc 0.82255 prc_auc 0.91978[0m
[93maverage test of epoch 16: loss -0.91422 acc 0.35135 roc_auc 0.87333 prc_auc 0.93612[0m
[92maverage training of epoch 17: loss -0.96222 acc 0.34437 roc_auc 0.73137 prc_auc 0.87464[0m
[93maverage test of epoch 17: loss -0.98479 acc 0.32432 roc_auc 0.87333 prc_auc 0.93612[0m
[92maverage training of epoch 18: loss -1.03245 acc 0.33775 roc_auc 0.65667 prc_auc 0.83469[0m
[93maverage test of epoch 18: loss -1.05378 acc 0.32432 roc_auc 0.86667 prc_auc 0.93424[0m
[92maverage training of epoch 19: loss -1.10088 acc 0.33775 roc_auc 0.59451 prc_auc 0.79211[0m
[93maverage test of epoch 19: loss -1.12143 acc 0.32432 roc_auc 0.86000 prc_auc 0.92548[0m
[92maverage training of epoch 20: loss -1.16831 acc 0.33775 roc_auc 0.54373 prc_auc 0.75504[0m
[93maverage test of epoch 20: loss -1.18864 acc 0.32432 roc_auc 0.86333 prc_auc 0.92515[0m
[92maverage training of epoch 21: loss -1.23557 acc 0.33775 roc_auc 0.50824 prc_auc 0.72679[0m
[93maverage test of epoch 21: loss -1.25607 acc 0.32432 roc_auc 0.85667 prc_auc 0.91456[0m
[92maverage training of epoch 22: loss -1.30320 acc 0.33775 roc_auc 0.48725 prc_auc 0.70606[0m
[93maverage test of epoch 22: loss -1.32408 acc 0.32432 roc_auc 0.84000 prc_auc 0.89913[0m
[92maverage training of epoch 23: loss -1.37137 acc 0.33775 roc_auc 0.47569 prc_auc 0.69508[0m
[93maverage test of epoch 23: loss -1.39263 acc 0.32432 roc_auc 0.83000 prc_auc 0.89540[0m
[92maverage training of epoch 24: loss -1.43994 acc 0.33775 roc_auc 0.46373 prc_auc 0.68521[0m
[93maverage test of epoch 24: loss -1.46146 acc 0.32432 roc_auc 0.83000 prc_auc 0.89445[0m
[92maverage training of epoch 25: loss -1.50857 acc 0.33775 roc_auc 0.45078 prc_auc 0.67116[0m
[93maverage test of epoch 25: loss -1.53018 acc 0.32432 roc_auc 0.83000 prc_auc 0.89406[0m
[92maverage training of epoch 26: loss -1.57692 acc 0.33775 roc_auc 0.44137 prc_auc 0.65668[0m
[93maverage test of epoch 26: loss -1.59849 acc 0.32432 roc_auc 0.83333 prc_auc 0.89528[0m
[92maverage training of epoch 27: loss -1.64472 acc 0.33775 roc_auc 0.43255 prc_auc 0.64749[0m
[93maverage test of epoch 27: loss -1.66618 acc 0.32432 roc_auc 0.83333 prc_auc 0.89528[0m
[92maverage training of epoch 28: loss -1.71184 acc 0.33775 roc_auc 0.42686 prc_auc 0.64398[0m
[93maverage test of epoch 28: loss -1.73313 acc 0.32432 roc_auc 0.83500 prc_auc 0.89528[0m
[92maverage training of epoch 29: loss -1.77819 acc 0.33775 roc_auc 0.41794 prc_auc 0.63099[0m
[93maverage test of epoch 29: loss -1.79933 acc 0.32432 roc_auc 0.83667 prc_auc 0.89631[0m
[92maverage training of epoch 30: loss -1.84378 acc 0.33775 roc_auc 0.40627 prc_auc 0.62030[0m
[93maverage test of epoch 30: loss -1.86476 acc 0.32432 roc_auc 0.83500 prc_auc 0.89528[0m
[92maverage training of epoch 31: loss -1.90860 acc 0.33775 roc_auc 0.40294 prc_auc 0.61692[0m
[93maverage test of epoch 31: loss -1.92945 acc 0.32432 roc_auc 0.83000 prc_auc 0.89431[0m
[92maverage training of epoch 32: loss -1.97271 acc 0.33775 roc_auc 0.39961 prc_auc 0.61424[0m
[93maverage test of epoch 32: loss -1.99343 acc 0.32432 roc_auc 0.83000 prc_auc 0.89431[0m
[92maverage training of epoch 33: loss -2.03614 acc 0.33775 roc_auc 0.39549 prc_auc 0.60898[0m
[93maverage test of epoch 33: loss -2.05676 acc 0.32432 roc_auc 0.82333 prc_auc 0.89254[0m
[92maverage training of epoch 34: loss -2.09893 acc 0.33775 roc_auc 0.39176 prc_auc 0.60496[0m
[93maverage test of epoch 34: loss -2.11947 acc 0.32432 roc_auc 0.82000 prc_auc 0.89096[0m
[92maverage training of epoch 35: loss -2.16112 acc 0.33775 roc_auc 0.38941 prc_auc 0.60276[0m
[93maverage test of epoch 35: loss -2.18160 acc 0.32432 roc_auc 0.82000 prc_auc 0.89096[0m
[92maverage training of epoch 36: loss -2.22276 acc 0.33775 roc_auc 0.38784 prc_auc 0.59785[0m
[93maverage test of epoch 36: loss -2.24321 acc 0.32432 roc_auc 0.82000 prc_auc 0.89096[0m
[92maverage training of epoch 37: loss -2.28389 acc 0.33775 roc_auc 0.38314 prc_auc 0.58024[0m
[93maverage test of epoch 37: loss -2.30433 acc 0.32432 roc_auc 0.81667 prc_auc 0.88161[0m
[92maverage training of epoch 38: loss -2.34456 acc 0.33775 roc_auc 0.38098 prc_auc 0.57777[0m
[93maverage test of epoch 38: loss -2.36499 acc 0.32432 roc_auc 0.77833 prc_auc 0.86663[0m
[92maverage training of epoch 39: loss -2.40479 acc 0.33775 roc_auc 0.37882 prc_auc 0.57520[0m
[93maverage test of epoch 39: loss -2.42524 acc 0.32432 roc_auc 0.78000 prc_auc 0.86840[0mUsing backend: pytorch
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))

[92maverage training of epoch 40: loss -2.46463 acc 0.33775 roc_auc 0.37765 prc_auc 0.57467[0m
[93maverage test of epoch 40: loss -2.48511 acc 0.32432 roc_auc 0.78000 prc_auc 0.87577[0m
[92maverage training of epoch 41: loss -2.52410 acc 0.33775 roc_auc 0.37627 prc_auc 0.57279[0m
[93maverage test of epoch 41: loss -2.54463 acc 0.32432 roc_auc 0.78333 prc_auc 0.87701[0m
[92maverage training of epoch 42: loss -2.58324 acc 0.33775 roc_auc 0.37431 prc_auc 0.57018[0m
[93maverage test of epoch 42: loss -2.60384 acc 0.32432 roc_auc 0.79333 prc_auc 0.87936[0m
[92maverage training of epoch 43: loss -2.64207 acc 0.33775 roc_auc 0.37373 prc_auc 0.56920[0m
[93maverage test of epoch 43: loss -2.66274 acc 0.32432 roc_auc 0.79333 prc_auc 0.88003[0m
[92maverage training of epoch 44: loss -2.70062 acc 0.33775 roc_auc 0.37275 prc_auc 0.56719[0m
[93maverage test of epoch 44: loss -2.72138 acc 0.32432 roc_auc 0.79000 prc_auc 0.87005[0m
[92maverage training of epoch 45: loss -2.75891 acc 0.33775 roc_auc 0.37216 prc_auc 0.56709[0m
[93maverage test of epoch 45: loss -2.77977 acc 0.32432 roc_auc 0.79333 prc_auc 0.87263[0m
[92maverage training of epoch 46: loss -2.81696 acc 0.33775 roc_auc 0.37176 prc_auc 0.56671[0m
[93maverage test of epoch 46: loss -2.83794 acc 0.32432 roc_auc 0.79500 prc_auc 0.87494[0m
[92maverage training of epoch 47: loss -2.87480 acc 0.33775 roc_auc 0.37196 prc_auc 0.56641[0m
[93maverage test of epoch 47: loss -2.89590 acc 0.32432 roc_auc 0.79833 prc_auc 0.87567[0m
[92maverage training of epoch 48: loss -2.93244 acc 0.33775 roc_auc 0.37196 prc_auc 0.56624[0m
[93maverage test of epoch 48: loss -2.95367 acc 0.32432 roc_auc 0.78667 prc_auc 0.86151[0m
[92maverage training of epoch 49: loss -2.98989 acc 0.33775 roc_auc 0.37196 prc_auc 0.56633[0m
[93maverage test of epoch 49: loss -3.01126 acc 0.32432 roc_auc 0.80167 prc_auc 0.87481[0m
[92maverage training of epoch 50: loss -3.04718 acc 0.33775 roc_auc 0.37216 prc_auc 0.56677[0m
[93maverage test of epoch 50: loss -3.06870 acc 0.32432 roc_auc 0.80000 prc_auc 0.86525[0m
[92maverage training of epoch 51: loss -3.10432 acc 0.33775 roc_auc 0.37235 prc_auc 0.56703[0m
[93maverage test of epoch 51: loss -3.12599 acc 0.32432 roc_auc 0.81333 prc_auc 0.87688[0m
[92maverage training of epoch 52: loss -3.16132 acc 0.33775 roc_auc 0.37196 prc_auc 0.56668[0m
[93maverage test of epoch 52: loss -3.18315 acc 0.32432 roc_auc 0.82500 prc_auc 0.88530[0m
[92maverage training of epoch 53: loss -3.21819 acc 0.33775 roc_auc 0.37235 prc_auc 0.56708[0m
[93maverage test of epoch 53: loss -3.24018 acc 0.32432 roc_auc 0.80500 prc_auc 0.86997[0m
[92maverage training of epoch 54: loss -3.27494 acc 0.33775 roc_auc 0.37255 prc_auc 0.56736[0m
[93maverage test of epoch 54: loss -3.29711 acc 0.32432 roc_auc 0.81500 prc_auc 0.87322[0m
[92maverage training of epoch 55: loss -3.33158 acc 0.33775 roc_auc 0.37294 prc_auc 0.56753[0m
[93maverage test of epoch 55: loss -3.35393 acc 0.32432 roc_auc 0.81500 prc_auc 0.86494[0m
[92maverage training of epoch 56: loss -3.38813 acc 0.33775 roc_auc 0.37294 prc_auc 0.56753[0m
[93maverage test of epoch 56: loss -3.41066 acc 0.32432 roc_auc 0.81167 prc_auc 0.87612[0m
[92maverage training of epoch 57: loss -3.44459 acc 0.33775 roc_auc 0.37353 prc_auc 0.56776[0m
[93maverage test of epoch 57: loss -3.46730 acc 0.32432 roc_auc 0.80000 prc_auc 0.87457[0m
[92maverage training of epoch 58: loss -3.50096 acc 0.33775 roc_auc 0.37353 prc_auc 0.56760[0m
[93maverage test of epoch 58: loss -3.52386 acc 0.32432 roc_auc 0.83167 prc_auc 0.88886[0m
[92maverage training of epoch 59: loss -3.55726 acc 0.33775 roc_auc 0.37353 prc_auc 0.56760[0m
[93maverage test of epoch 59: loss -3.58036 acc 0.32432 roc_auc 0.82667 prc_auc 0.89615[0m
[92maverage training of epoch 60: loss -3.61349 acc 0.33775 roc_auc 0.37382 prc_auc 0.56793[0m
[93maverage test of epoch 60: loss -3.63678 acc 0.32432 roc_auc 0.80333 prc_auc 0.88012[0m
[92maverage training of epoch 61: loss -3.66965 acc 0.33775 roc_auc 0.37402 prc_auc 0.56843[0m
[93maverage test of epoch 61: loss -3.69315 acc 0.32432 roc_auc 0.83833 prc_auc 0.89877[0m
[92maverage training of epoch 62: loss -3.72576 acc 0.33775 roc_auc 0.37490 prc_auc 0.56935[0m
[93maverage test of epoch 62: loss -3.74946 acc 0.32432 roc_auc 0.77000 prc_auc 0.84352[0m
[92maverage training of epoch 63: loss -3.78182 acc 0.33775 roc_auc 0.37529 prc_auc 0.56961[0m
[93maverage test of epoch 63: loss -3.80572 acc 0.32432 roc_auc 0.77667 prc_auc 0.84053[0m
[92maverage training of epoch 64: loss -3.83782 acc 0.33775 roc_auc 0.37529 prc_auc 0.56956[0m
[93maverage test of epoch 64: loss -3.86194 acc 0.32432 roc_auc 0.72167 prc_auc 0.80879[0m
[92maverage training of epoch 65: loss -3.89378 acc 0.33775 roc_auc 0.37529 prc_auc 0.56941[0m
[93maverage test of epoch 65: loss -3.91811 acc 0.32432 roc_auc 0.81667 prc_auc 0.87655[0m
[92maverage training of epoch 66: loss -3.94971 acc 0.33775 roc_auc 0.37529 prc_auc 0.56935[0m
[93maverage test of epoch 66: loss -3.97424 acc 0.32432 roc_auc 0.79000 prc_auc 0.85483[0m
[92maverage training of epoch 67: loss -4.00559 acc 0.33775 roc_auc 0.37529 prc_auc 0.56935[0m
[93maverage test of epoch 67: loss -4.03034 acc 0.32432 roc_auc 0.73667 prc_auc 0.84036[0m
[92maverage training of epoch 68: loss -4.06144 acc 0.33775 roc_auc 0.37490 prc_auc 0.56899[0m
[93maverage test of epoch 68: loss -4.08641 acc 0.32432 roc_auc 0.70667 prc_auc 0.81103[0m
[92maverage training of epoch 69: loss -4.11726 acc 0.33775 roc_auc 0.37490 prc_auc 0.56899[0m
[93maverage test of epoch 69: loss -4.14245 acc 0.32432 roc_auc 0.71833 prc_auc 0.80387[0m
[92maverage training of epoch 70: loss -4.17305 acc 0.33775 roc_auc 0.37510 prc_auc 0.56910[0m
[93maverage test of epoch 70: loss -4.19846 acc 0.32432 roc_auc 0.64833 prc_auc 0.76372[0m
[92maverage training of epoch 71: loss -4.22881 acc 0.33775 roc_auc 0.37510 prc_auc 0.56910[0m
[93maverage test of epoch 71: loss -4.25444 acc 0.32432 roc_auc 0.72000 prc_auc 0.80925[0m
[92maverage training of epoch 72: loss -4.28455 acc 0.33775 roc_auc 0.37510 prc_auc 0.56910[0m
[93maverage test of epoch 72: loss -4.31041 acc 0.32432 roc_auc 0.69667 prc_auc 0.79153[0m
[92maverage training of epoch 73: loss -4.34027 acc 0.33775 roc_auc 0.37510 prc_auc 0.56932[0m
[93maverage test of epoch 73: loss -4.36635 acc 0.32432 roc_auc 0.55000 prc_auc 0.70336[0m
[92maverage training of epoch 74: loss -4.39597 acc 0.33775 roc_auc 0.37529 prc_auc 0.56942[0m
[93maverage test of epoch 74: loss -4.42227 acc 0.32432 roc_auc 0.66333 prc_auc 0.78173[0m
[92maverage training of epoch 75: loss -4.45165 acc 0.33775 roc_auc 0.37529 prc_auc 0.56942[0m
[93maverage test of epoch 75: loss -4.47818 acc 0.32432 roc_auc 0.75333 prc_auc 0.83132[0m
[92maverage training of epoch 76: loss -4.50732 acc 0.33775 roc_auc 0.37529 prc_auc 0.56942[0m
[93maverage test of epoch 76: loss -4.53407 acc 0.32432 roc_auc 0.50500 prc_auc 0.69456[0m
[92maverage training of epoch 77: loss -4.56297 acc 0.33775 roc_auc 0.37529 prc_auc 0.56942[0m
[93maverage test of epoch 77: loss -4.58994 acc 0.32432 roc_auc 0.81500 prc_auc 0.86916[0m
[92maverage training of epoch 78: loss -4.61860 acc 0.33775 roc_auc 0.37529 prc_auc 0.56942[0m
[93maverage test of epoch 78: loss -4.64581 acc 0.32432 roc_auc 0.68667 prc_auc 0.78596[0m
[92maverage training of epoch 79: loss -4.67422 acc 0.33775 roc_auc 0.37549 prc_auc 0.56951[0m
[93maverage test of epoch 79: loss -4.70166 acc 0.32432 roc_auc 0.60000 prc_auc 0.72798[0m
[92maverage training of epoch 80: loss -4.72983 acc 0.33775 roc_auc 0.37549 prc_auc 0.56971[0m
[93maverage test of epoch 80: loss -4.75750 acc 0.32432 roc_auc 0.72500 prc_auc 0.80502[0m
[92maverage training of epoch 81: loss -4.78543 acc 0.33775 roc_auc 0.37549 prc_auc 0.56951[0m
[93maverage test of epoch 81: loss -4.81333 acc 0.32432 roc_auc 0.46000 prc_auc 0.68810[0m
[92maverage training of epoch 82: loss -4.84102 acc 0.33775 roc_auc 0.37549 prc_auc 0.56951[0m
[93maverage test of epoch 82: loss -4.86915 acc 0.32432 roc_auc 0.61167 prc_auc 0.74817[0m
[92maverage training of epoch 83: loss -4.89661 acc 0.33775 roc_auc 0.37549 prc_auc 0.56951[0m
[93maverage test of epoch 83: loss -4.92496 acc 0.32432 roc_auc 0.70000 prc_auc 0.80457[0m
[92maverage training of epoch 84: loss -4.95218 acc 0.59603 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 84: loss -4.98077 acc 0.67568 roc_auc 0.54000 prc_auc 0.70703[0m
[92maverage training of epoch 85: loss -5.00774 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 85: loss -5.03656 acc 0.67568 roc_auc 0.36000 prc_auc 0.62258[0m
[92maverage training of epoch 86: loss -5.06330 acc 0.66225 roc_auc 0.37569 prc_auc 0.57045[0m
[93maverage test of epoch 86: loss -5.09235 acc 0.67568 roc_auc 0.55000 prc_auc 0.70336[0m
[92maverage training of epoch 87: loss -5.11886 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 87: loss -5.14814 acc 0.67568 roc_auc 0.81333 prc_auc 0.87641[0m
[92maverage training of epoch 88: loss -5.17440 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 88: loss -5.20392 acc 0.67568 roc_auc 0.56667 prc_auc 0.70636[0m
[92maverage training of epoch 89: loss -5.22994 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 89: loss -5.25969 acc 0.67568 roc_auc 0.44000 prc_auc 0.65036[0m
[92maverage training of epoch 90: loss -5.28548 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 90: loss -5.31546 acc 0.67568 roc_auc 0.54000 prc_auc 0.73869[0m
[92maverage training of epoch 91: loss -5.34101 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 91: loss -5.37123 acc 0.67568 roc_auc 0.59000 prc_auc 0.73163[0m
[92maverage training of epoch 92: loss -5.39654 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 92: loss -5.42699 acc 0.67568 roc_auc 0.55500 prc_auc 0.72012[0m
[92maverage training of epoch 93: loss -5.45206 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 93: loss -5.48275 acc 0.67568 roc_auc 0.47333 prc_auc 0.67556[0m
[92maverage training of epoch 94: loss -5.50758 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 94: loss -5.53850 acc 0.67568 roc_auc 0.73333 prc_auc 0.81200[0m
[92maverage training of epoch 95: loss -5.56310 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 95: loss -5.59425 acc 0.67568 roc_auc 0.60500 prc_auc 0.76491[0m
[92maverage training of epoch 96: loss -5.61862 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 96: loss -5.65000 acc 0.67568 roc_auc 0.28000 prc_auc 0.59068[0m
[92maverage training of epoch 97: loss -5.67413 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 97: loss -5.70575 acc 0.67568 roc_auc 0.82000 prc_auc 0.88278[0m
[92maverage training of epoch 98: loss -5.72964 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 98: loss -5.76150 acc 0.67568 roc_auc 0.66333 prc_auc 0.76268[0m
[92maverage training of epoch 99: loss -5.78515 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 99: loss -5.81724 acc 0.67568 roc_auc 0.46167 prc_auc 0.67645[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.54660 acc 0.66225 roc_auc 0.45608 prc_auc 0.67351[0m
[93maverage test of epoch 0: loss -0.58690 acc 0.67568 roc_auc 0.92333 prc_auc 0.96958[0m
[92maverage training of epoch 1: loss -0.62151 acc 0.66225 roc_auc 0.47686 prc_auc 0.69390[0m
[93maverage test of epoch 1: loss -0.66217 acc 0.67568 roc_auc 0.92333 prc_auc 0.96958[0m
[92maverage training of epoch 2: loss -0.69621 acc 0.66225 roc_auc 0.50020 prc_auc 0.71474[0m
[93maverage test of epoch 2: loss -0.73730 acc 0.67568 roc_auc 0.92333 prc_auc 0.96958[0m
[92maverage training of epoch 3: loss -0.77061 acc 0.66225 roc_auc 0.51863 prc_auc 0.73395[0m
[93maverage test of epoch 3: loss -0.81210 acc 0.67568 roc_auc 0.92333 prc_auc 0.96958[0m
[92maverage training of epoch 4: loss -0.84460 acc 0.66225 roc_auc 0.53118 prc_auc 0.74217[0m
[93maverage test of epoch 4: loss -0.88650 acc 0.67568 roc_auc 0.92667 prc_auc 0.97089[0m
[92maverage training of epoch 5: loss -0.91815 acc 0.66225 roc_auc 0.54118 prc_auc 0.74985[0m
[93maverage test of epoch 5: loss -0.96051 acc 0.67568 roc_auc 0.92667 prc_auc 0.97089[0m
[92maverage training of epoch 6: loss -0.99131 acc 0.66225 roc_auc 0.54490 prc_auc 0.75329[0m
[93maverage test of epoch 6: loss -1.03418 acc 0.67568 roc_auc 0.92667 prc_auc 0.97089[0m
[92maverage training of epoch 7: loss -1.06413 acc 0.66225 roc_auc 0.54686 prc_auc 0.75428[0m
[93maverage test of epoch 7: loss -1.10758 acc 0.67568 roc_auc 0.92667 prc_auc 0.97089[0m
[92maverage training of epoch 8: loss -1.13665 acc 0.66225 roc_auc 0.55275 prc_auc 0.76000[0m
[93maverage test of epoch 8: loss -1.18075 acc 0.67568 roc_auc 0.92667 prc_auc 0.97089[0m
[92maverage training of epoch 9: loss -1.20892 acc 0.66225 roc_auc 0.55804 prc_auc 0.76321[0m
[93maverage test of epoch 9: loss -1.25372 acc 0.67568 roc_auc 0.92667 prc_auc 0.97089[0m
[92maverage training of epoch 10: loss -1.28098 acc 0.66225 roc_auc 0.56608 prc_auc 0.76882[0m
[93maverage test of epoch 10: loss -1.32654 acc 0.67568 roc_auc 0.92333 prc_auc 0.96958[0m
[92maverage training of epoch 11: loss -1.35283 acc 0.66225 roc_auc 0.57431 prc_auc 0.77609[0m
[93maverage test of epoch 11: loss -1.39919 acc 0.67568 roc_auc 0.92333 prc_auc 0.96958[0m
[92maverage training of epoch 12: loss -1.42447 acc 0.66225 roc_auc 0.58529 prc_auc 0.78610[0m
[93maverage test of epoch 12: loss -1.47168 acc 0.67568 roc_auc 0.92333 prc_auc 0.96958[0m
[92maverage training of epoch 13: loss -1.49588 acc 0.66225 roc_auc 0.59490 prc_auc 0.79416[0m
[93maverage test of epoch 13: loss -1.54396 acc 0.67568 roc_auc 0.92667 prc_auc 0.97104[0m
[92maverage training of epoch 14: loss -1.56702 acc 0.66225 roc_auc 0.60392 prc_auc 0.79928[0m
[93maverage test of epoch 14: loss -1.61593 acc 0.67568 roc_auc 0.92667 prc_auc 0.97104[0m
[92maverage training of epoch 15: loss -1.63783 acc 0.66225 roc_auc 0.61706 prc_auc 0.80693[0m
[93maverage test of epoch 15: loss -1.68752 acc 0.67568 roc_auc 0.92667 prc_auc 0.97104[0m
[92maverage training of epoch 16: loss -1.70828 acc 0.66225 roc_auc 0.62000 prc_auc 0.80618[0m
[93maverage test of epoch 16: loss -1.75869 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 17: loss -1.77835 acc 0.66225 roc_auc 0.62275 prc_auc 0.80585[0m
[93maverage test of epoch 17: loss -1.82944 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 18: loss -1.84808 acc 0.66225 roc_auc 0.61922 prc_auc 0.80148[0m
[93maverage test of epoch 18: loss -1.89984 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 19: loss -1.91752 acc 0.66225 roc_auc 0.61137 prc_auc 0.79326[0m
[93maverage test of epoch 19: loss -1.96995 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 20: loss -1.98672 acc 0.66225 roc_auc 0.60529 prc_auc 0.78602[0m
[93maverage test of epoch 20: loss -2.03983 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 21: loss -2.05569 acc 0.66225 roc_auc 0.59353 prc_auc 0.77698[0m
[93maverage test of epoch 21: loss -2.10949 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 22: loss -2.12446 acc 0.66225 roc_auc 0.58020 prc_auc 0.76648[0m
[93maverage test of epoch 22: loss -2.17893 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 23: loss -2.19298 acc 0.66225 roc_auc 0.57000 prc_auc 0.75637[0m
[93maverage test of epoch 23: loss -2.24813 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 24: loss -2.26125 acc 0.66225 roc_auc 0.55627 prc_auc 0.74606[0m
[93maverage test of epoch 24: loss -2.31705 acc 0.67568 roc_auc 0.92667 prc_auc 0.97104[0m
[92maverage training of epoch 25: loss -2.32922 acc 0.66225 roc_auc 0.55000 prc_auc 0.74006[0m
[93maverage test of epoch 25: loss -2.38564 acc 0.67568 roc_auc 0.92667 prc_auc 0.97104[0m
[92maverage training of epoch 26: loss -2.39685 acc 0.66225 roc_auc 0.54255 prc_auc 0.73502[0m
[93maverage test of epoch 26: loss -2.45387 acc 0.67568 roc_auc 0.92667 prc_auc 0.97104[0m
[92maverage training of epoch 27: loss -2.46411 acc 0.66225 roc_auc 0.53490 prc_auc 0.73004[0m
[93maverage test of epoch 27: loss -2.52170 acc 0.67568 roc_auc 0.92667 prc_auc 0.97104[0m
[92maverage training of epoch 28: loss -2.53096 acc 0.66225 roc_auc 0.52706 prc_auc 0.72328[0m
[93maverage test of epoch 28: loss -2.58910 acc 0.67568 roc_auc 0.92667 prc_auc 0.97104[0m
[92maverage training of epoch 29: loss -2.59737 acc 0.66225 roc_auc 0.51941 prc_auc 0.71774[0m
[93maverage test of epoch 29: loss -2.65602 acc 0.67568 roc_auc 0.92667 prc_auc 0.97104[0m
[92maverage training of epoch 30: loss -2.66333 acc 0.66225 roc_auc 0.51333 prc_auc 0.71214[0m
[93maverage test of epoch 30: loss -2.72246 acc 0.67568 roc_auc 0.92833 prc_auc 0.97104[0m
[92maverage training of epoch 31: loss -2.72880 acc 0.66225 roc_auc 0.50490 prc_auc 0.70582[0m
[93maverage test of epoch 31: loss -2.78839 acc 0.67568 roc_auc 0.93000 prc_auc 0.97235[0m
[92maverage training of epoch 32: loss -2.79378 acc 0.66225 roc_auc 0.49627 prc_auc 0.69745[0m
[93maverage test of epoch 32: loss -2.85380 acc 0.67568 roc_auc 0.93167 prc_auc 0.97235[0m
[92maverage training of epoch 33: loss -2.85827 acc 0.66225 roc_auc 0.48882 prc_auc 0.69110[0m
[93maverage test of epoch 33: loss -2.91870 acc 0.67568 roc_auc 0.93333 prc_auc 0.97377[0m
[92maverage training of epoch 34: loss -2.92227 acc 0.66225 roc_auc 0.48490 prc_auc 0.68557[0m
[93maverage test of epoch 34: loss -2.98308 acc 0.67568 roc_auc 0.93333 prc_auc 0.97390[0m
[92maverage training of epoch 35: loss -2.98577 acc 0.66225 roc_auc 0.48020 prc_auc 0.68244[0m
[93maverage test of epoch 35: loss -3.04695 acc 0.67568 roc_auc 0.93333 prc_auc 0.97377[0m
[92maverage training of epoch 36: loss -3.04879 acc 0.66225 roc_auc 0.47314 prc_auc 0.67633[0m
[93maverage test of epoch 36: loss -3.11032 acc 0.67568 roc_auc 0.93333 prc_auc 0.97390[0m
[92maverage training of epoch 37: loss -3.11134 acc 0.66225 roc_auc 0.46863 prc_auc 0.67292[0m
[93maverage test of epoch 37: loss -3.17320 acc 0.67568 roc_auc 0.93333 prc_auc 0.97377[0m
[92maverage training of epoch 38: loss -3.17344 acc 0.66225 roc_auc 0.46275 prc_auc 0.66719[0m
[93maverage test of epoch 38: loss -3.23562 acc 0.67568 roc_auc 0.93333 prc_auc 0.97377[0m
[92maverage training of epoch 39: loss -3.23510 acc 0.66225 roc_auc 0.45333 prc_auc 0.65822[0m
[93maverage test of epoch 39: loss -3.29758 acc 0.67568 roc_auc 0.93167 prc_auc 0.97235[0m
[92maverage training of epoch 40: loss -3.29634 acc 0.66225 roc_auc 0.44676 prc_auc 0.65216[0m
[93maverage test of epoch 40: loss -3.35912 acc 0.67568 roc_auc 0.93000 prc_auc 0.97104[0m
[92maverage training of epoch 41: loss -3.35718 acc 0.66225 roc_auc 0.44157 prc_auc 0.64862[0m
[93maverage test of epoch 41: loss -3.42025 acc 0.67568 roc_auc 0.93333 prc_auc 0.97377[0m
[92maverage training of epoch 42: loss -3.41765 acc 0.66225 roc_auc 0.43706 prc_auc 0.64451[0m
[93maverage test of epoch 42: loss -3.48100 acc 0.67568 roc_auc 0.93500 prc_auc 0.97377[0m
[92maverage training of epoch 43: loss -3.47776 acc 0.66225 roc_auc 0.43069 prc_auc 0.64058[0m
[93maverage test of epoch 43: loss -3.54138 acc 0.67568 roc_auc 0.93167 prc_auc 0.97104[0m
[92maverage training of epoch 44: loss -3.53753 acc 0.66225 roc_auc 0.42824 prc_auc 0.63994[0m
[93maverage test of epoch 44: loss -3.60141 acc 0.67568 roc_auc 0.93333 prc_auc 0.97264[0m
[92maverage training of epoch 45: loss -3.59698 acc 0.66225 roc_auc 0.42353 prc_auc 0.63781[0m
[93maverage test of epoch 45: loss -3.66113 acc 0.67568 roc_auc 0.93167 prc_auc 0.97104[0m
[92maverage training of epoch 46: loss -3.65613 acc 0.66225 roc_auc 0.42118 prc_auc 0.63855[0m
[93maverage test of epoch 46: loss -3.72054 acc 0.67568 roc_auc 0.93333 prc_auc 0.97264[0m
[92maverage training of epoch 47: loss -3.71501 acc 0.66225 roc_auc 0.41745 prc_auc 0.63600[0m
[93maverage test of epoch 47: loss -3.77968 acc 0.67568 roc_auc 0.93333 prc_auc 0.97264[0m
[92maverage training of epoch 48: loss -3.77364 acc 0.66225 roc_auc 0.41373 prc_auc 0.63427[0m
[93maverage test of epoch 48: loss -3.83855 acc 0.67568 roc_auc 0.93167 prc_auc 0.97104[0m
[92maverage training of epoch 49: loss -3.83202 acc 0.66225 roc_auc 0.41147 prc_auc 0.63389[0m
[93maverage test of epoch 49: loss -3.89718 acc 0.67568 roc_auc 0.93500 prc_auc 0.97264[0m
[92maverage training of epoch 50: loss -3.89017 acc 0.66225 roc_auc 0.40784 prc_auc 0.63033[0m
[93maverage test of epoch 50: loss -3.95558 acc 0.67568 roc_auc 0.93167 prc_auc 0.97104[0m
[92maverage training of epoch 51: loss -3.94812 acc 0.66225 roc_auc 0.40559 prc_auc 0.62986[0m
[93maverage test of epoch 51: loss -4.01377 acc 0.67568 roc_auc 0.93500 prc_auc 0.97264[0m
[92maverage training of epoch 52: loss -4.00587 acc 0.66225 roc_auc 0.40255 prc_auc 0.62485[0m
[93maverage test of epoch 52: loss -4.07177 acc 0.67568 roc_auc 0.93667 prc_auc 0.97264[0m
[92maverage training of epoch 53: loss -4.06345 acc 0.66225 roc_auc 0.40020 prc_auc 0.62119[0m
[93maverage test of epoch 53: loss -4.12958 acc 0.67568 roc_auc 0.93000 prc_auc 0.96845[0m
[92maverage training of epoch 54: loss -4.12086 acc 0.66225 roc_auc 0.39716 prc_auc 0.61420[0m
[93maverage test of epoch 54: loss -4.18723 acc 0.67568 roc_auc 0.92833 prc_auc 0.96958[0m
[92maverage training of epoch 55: loss -4.17811 acc 0.66225 roc_auc 0.39510 prc_auc 0.61237[0m
[93maverage test of epoch 55: loss -4.24473 acc 0.67568 roc_auc 0.93667 prc_auc 0.97264[0m
[92maverage training of epoch 56: loss -4.23523 acc 0.66225 roc_auc 0.39324 prc_auc 0.61099[0m
[93maverage test of epoch 56: loss -4.30208 acc 0.67568 roc_auc 0.93667 prc_auc 0.97264[0m
[92maverage training of epoch 57: loss -4.29222 acc 0.66225 roc_auc 0.39216 prc_auc 0.60991[0m
[93maverage test of epoch 57: loss -4.35931 acc 0.67568 roc_auc 0.93333 prc_auc 0.97104[0m
[92maverage training of epoch 58: loss -4.34908 acc 0.66225 roc_auc 0.39196 prc_auc 0.60961[0m
[93maverage test of epoch 58: loss -4.41641 acc 0.67568 roc_auc 0.93667 prc_auc 0.97264[0m
[92maverage training of epoch 59: loss -4.40583 acc 0.66225 roc_auc 0.39098 prc_auc 0.60914[0m
[93maverage test of epoch 59: loss -4.47340 acc 0.67568 roc_auc 0.93667 prc_auc 0.97264[0m
[92maverage training of epoch 60: loss -4.46249 acc 0.66225 roc_auc 0.38608 prc_auc 0.59847[0m
[93maverage test of epoch 60: loss -4.53029 acc 0.67568 roc_auc 0.93667 prc_auc 0.97264[0m
[92maverage training of epoch 61: loss -4.51904 acc 0.66225 roc_auc 0.38402 prc_auc 0.59591[0m
[93maverage test of epoch 61: loss -4.58708 acc 0.67568 roc_auc 0.92667 prc_auc 0.96822[0m
[92maverage training of epoch 62: loss -4.57551 acc 0.66225 roc_auc 0.38314 prc_auc 0.59606[0m
[93maverage test of epoch 62: loss -4.64379 acc 0.67568 roc_auc 0.93333 prc_auc 0.96845[0m
[92maverage training of epoch 63: loss -4.63190 acc 0.66225 roc_auc 0.38245 prc_auc 0.59321[0m
[93maverage test of epoch 63: loss -4.70042 acc 0.67568 roc_auc 0.93333 prc_auc 0.96845[0m
[92maverage training of epoch 64: loss -4.68822 acc 0.66225 roc_auc 0.38216 prc_auc 0.59334[0m
[93maverage test of epoch 64: loss -4.75697 acc 0.67568 roc_auc 0.93333 prc_auc 0.96875[0m
[92maverage training of epoch 65: loss -4.74447 acc 0.66225 roc_auc 0.38186 prc_auc 0.59309[0m
[93maverage test of epoch 65: loss -4.81346 acc 0.67568 roc_auc 0.93333 prc_auc 0.96845[0m
[92maverage training of epoch 66: loss -4.80066 acc 0.66225 roc_auc 0.38118 prc_auc 0.59216[0m
[93maverage test of epoch 66: loss -4.86988 acc 0.67568 roc_auc 0.93333 prc_auc 0.96845[0m
[92maverage training of epoch 67: loss -4.85679 acc 0.66225 roc_auc 0.38029 prc_auc 0.59193[0m
[93maverage test of epoch 67: loss -4.92625 acc 0.67568 roc_auc 0.93333 prc_auc 0.96875[0m
[92maverage training of epoch 68: loss -4.91287 acc 0.66225 roc_auc 0.38010 prc_auc 0.59179[0m
[93maverage test of epoch 68: loss -4.98256 acc 0.67568 roc_auc 0.92667 prc_auc 0.96822[0m
[92maverage training of epoch 69: loss -4.96890 acc 0.66225 roc_auc 0.38020 prc_auc 0.59297[0m
[93maverage test of epoch 69: loss -5.03882 acc 0.67568 roc_auc 0.93333 prc_auc 0.97104[0m
[92maverage training of epoch 70: loss -5.02489 acc 0.66225 roc_auc 0.38020 prc_auc 0.59218[0m
[93maverage test of epoch 70: loss -5.09505 acc 0.67568 roc_auc 0.93333 prc_auc 0.96875[0m
[92maverage training of epoch 71: loss -5.08083 acc 0.66225 roc_auc 0.37990 prc_auc 0.59176[0m
[93maverage test of epoch 71: loss -5.15123 acc 0.67568 roc_auc 0.93667 prc_auc 0.96845[0m
[92maverage training of epoch 72: loss -5.13674 acc 0.66225 roc_auc 0.37990 prc_auc 0.59167[0m
[93maverage test of epoch 72: loss -5.20737 acc 0.67568 roc_auc 0.93333 prc_auc 0.96875[0m
[92maverage training of epoch 73: loss -5.19261 acc 0.66225 roc_auc 0.37971 prc_auc 0.59150[0m
[93maverage test of epoch 73: loss -5.26348 acc 0.67568 roc_auc 0.93333 prc_auc 0.96875[0m
[92maverage training of epoch 74: loss -5.24846 acc 0.66225 roc_auc 0.37941 prc_auc 0.59134[0m
[93maverage test of epoch 74: loss -5.31956 acc 0.67568 roc_auc 0.94333 prc_auc 0.97135[0m
[92maverage training of epoch 75: loss -5.30427 acc 0.66225 roc_auc 0.37951 prc_auc 0.59134[0m
[93maverage test of epoch 75: loss -5.37560 acc 0.67568 roc_auc 0.93000 prc_auc 0.96632[0m
[92maverage training of epoch 76: loss -5.36006 acc 0.66225 roc_auc 0.37912 prc_auc 0.59094[0m
[93maverage test of epoch 76: loss -5.43163 acc 0.67568 roc_auc 0.93333 prc_auc 0.96875[0m
[92maverage training of epoch 77: loss -5.41582 acc 0.66225 roc_auc 0.37892 prc_auc 0.59165[0m
[93maverage test of epoch 77: loss -5.48762 acc 0.67568 roc_auc 0.93167 prc_auc 0.96253[0m
[92maverage training of epoch 78: loss -5.47156 acc 0.66225 roc_auc 0.37873 prc_auc 0.59087[0m
[93maverage test of epoch 78: loss -5.54360 acc 0.67568 roc_auc 0.94333 prc_auc 0.96875[0m
[92maverage training of epoch 79: loss -5.52728 acc 0.66225 roc_auc 0.37814 prc_auc 0.59050[0m
[93maverage test of epoch 79: loss -5.59955 acc 0.67568 roc_auc 0.94000 prc_auc 0.96632[0m
[92maverage training of epoch 80: loss -5.58298 acc 0.66225 roc_auc 0.37814 prc_auc 0.59050[0m
[93maverage test of epoch 80: loss -5.65549 acc 0.67568 roc_auc 0.92667 prc_auc 0.96454[0m
[92maverage training of epoch 81: loss -5.63866 acc 0.66225 roc_auc 0.37804 prc_auc 0.59087[0m
[93maverage test of epoch 81: loss -5.71141 acc 0.67568 roc_auc 0.94000 prc_auc 0.96632[0m
[92maverage training of epoch 82: loss -5.69433 acc 0.66225 roc_auc 0.37804 prc_auc 0.59044[0m
[93maverage test of epoch 82: loss -5.76731 acc 0.67568 roc_auc 0.94000 prc_auc 0.96632[0m
[92maverage training of epoch 83: loss -5.74998 acc 0.66225 roc_auc 0.37735 prc_auc 0.58421[0m
[93maverage test of epoch 83: loss -5.82320 acc 0.67568 roc_auc 0.92333 prc_auc 0.95203[0m
[92maverage training of epoch 84: loss -5.80562 acc 0.66225 roc_auc 0.37667 prc_auc 0.58232[0m
[93maverage test of epoch 84: loss -5.87908 acc 0.67568 roc_auc 0.90667 prc_auc 0.95341[0m
[92maverage training of epoch 85: loss -5.86125 acc 0.66225 roc_auc 0.37657 prc_auc 0.58243[0m
[93maverage test of epoch 85: loss -5.93494 acc 0.67568 roc_auc 0.90167 prc_auc 0.94605[0m
[92maverage training of epoch 86: loss -5.91686 acc 0.66225 roc_auc 0.37627 prc_auc 0.58215[0m
[93maverage test of epoch 86: loss -5.99079 acc 0.67568 roc_auc 0.89667 prc_auc 0.93270[0m
[92maverage training of epoch 87: loss -5.97247 acc 0.66225 roc_auc 0.37608 prc_auc 0.57548[0m
[93maverage test of epoch 87: loss -6.04663 acc 0.67568 roc_auc 0.94667 prc_auc 0.96121[0m
[92maverage training of epoch 88: loss -6.02806 acc 0.66225 roc_auc 0.37520 prc_auc 0.57408[0m
[93maverage test of epoch 88: loss -6.10246 acc 0.67568 roc_auc 0.89333 prc_auc 0.92242[0m
[92maverage training of epoch 89: loss -6.08365 acc 0.66225 roc_auc 0.37461 prc_auc 0.57277[0m
[93maverage test of epoch 89: loss -6.15828 acc 0.67568 roc_auc 0.83500 prc_auc 0.88120[0m
[92maverage training of epoch 90: loss -6.13923 acc 0.66225 roc_auc 0.37412 prc_auc 0.57179[0m
[93maverage test of epoch 90: loss -6.21410 acc 0.67568 roc_auc 0.89000 prc_auc 0.92667[0m
[92maverage training of epoch 91: loss -6.19480 acc 0.66225 roc_auc 0.37343 prc_auc 0.57120[0m
[93maverage test of epoch 91: loss -6.26991 acc 0.67568 roc_auc 0.81000 prc_auc 0.85977[0m
[92maverage training of epoch 92: loss -6.25037 acc 0.66225 roc_auc 0.37353 prc_auc 0.57120[0m
[93maverage test of epoch 92: loss -6.32571 acc 0.67568 roc_auc 0.85667 prc_auc 0.88775[0m
[92maverage training of epoch 93: loss -6.30593 acc 0.66225 roc_auc 0.37304 prc_auc 0.57130[0m
[93maverage test of epoch 93: loss -6.38150 acc 0.67568 roc_auc 0.74667 prc_auc 0.81576[0m
[92maverage training of epoch 94: loss -6.36148 acc 0.66225 roc_auc 0.37304 prc_auc 0.57080[0m
[93maverage test of epoch 94: loss -6.43729 acc 0.67568 roc_auc 0.76000 prc_auc 0.82545[0m
[92maverage training of epoch 95: loss -6.41703 acc 0.66225 roc_auc 0.37275 prc_auc 0.57068[0m
[93maverage test of epoch 95: loss -6.49307 acc 0.67568 roc_auc 0.79333 prc_auc 0.83776[0m
[92maverage training of epoch 96: loss -6.47257 acc 0.66225 roc_auc 0.37265 prc_auc 0.57055[0m
[93maverage test of epoch 96: loss -6.54885 acc 0.67568 roc_auc 0.80000 prc_auc 0.87027[0m
[92maverage training of epoch 97: loss -6.52811 acc 0.66225 roc_auc 0.37255 prc_auc 0.57072[0m
[93maverage test of epoch 97: loss -6.60463 acc 0.67568 roc_auc 0.88000 prc_auc 0.92216[0m
[92maverage training of epoch 98: loss -6.58364 acc 0.66225 roc_auc 0.37235 prc_auc 0.57026[0m
[93maverage test of epoch 98: loss -6.66040 acc 0.67568 roc_auc 0.84000 prc_auc 0.89622[0m
[92maverage training of epoch 99: loss -6.63917 acc 0.66225 roc_auc 0.37225 prc_auc 0.57034[0m
[93maverage test of epoch 99: loss -6.71616 acc 0.67568 roc_auc 0.66667 prc_auc 0.75758[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.0001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.70185 ROC_AUC (avg): 0.64567 PRC_AUC (avg): 0.76752 

Average forward propagation time taken(ms): 2.4718778908722716
Average backward propagation time taken(ms): 0.8692816485659066

