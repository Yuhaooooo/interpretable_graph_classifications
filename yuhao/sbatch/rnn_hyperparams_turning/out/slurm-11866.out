# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 1)
('lr', 0.0003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-19-10-47/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-19-10-47/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 16,
 'epochs': 50,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 8,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.0003,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 1,
 'num_workers': 8,
 'number_of_mlp_layer': 1,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-17-19-10-47',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 50, 'learning_rate': 0.0003, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss 0.16767 acc 0.33333 roc_auc 0.38760 prc_auc 0.59239[0m
[93maverage test of epoch 0: loss 0.05106 acc 0.34211 roc_auc 0.75692 prc_auc 0.89719[0m
[92maverage training of epoch 1: loss 0.02973 acc 0.33333 roc_auc 0.35600 prc_auc 0.57493[0m
[93maverage test of epoch 1: loss 0.00576 acc 0.34211 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 2: loss -0.00634 acc 0.33333 roc_auc 0.36930 prc_auc 0.58751[0m
[93maverage test of epoch 2: loss -0.02732 acc 0.34211 roc_auc 0.52000 prc_auc 0.67158[0m
[92maverage training of epoch 3: loss -0.03954 acc 0.33333 roc_auc 0.36800 prc_auc 0.58663[0m
[93maverage test of epoch 3: loss -0.06036 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 4: loss -0.07275 acc 0.33333 roc_auc 0.36080 prc_auc 0.56473[0m
[93maverage test of epoch 4: loss -0.09338 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 5: loss -0.10590 acc 0.33333 roc_auc 0.35830 prc_auc 0.56335[0m
[93maverage test of epoch 5: loss -0.12642 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 6: loss -0.13903 acc 0.33333 roc_auc 0.35780 prc_auc 0.56257[0m
[93maverage test of epoch 6: loss -0.15945 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 7: loss -0.17216 acc 0.33333 roc_auc 0.35760 prc_auc 0.56233[0m
[93maverage test of epoch 7: loss -0.19249 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 8: loss -0.20529 acc 0.33333 roc_auc 0.35760 prc_auc 0.56226[0m
[93maverage test of epoch 8: loss -0.22553 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 9: loss -0.23843 acc 0.33333 roc_auc 0.35760 prc_auc 0.56226[0m
[93maverage test of epoch 9: loss -0.25858 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 10: loss -0.27157 acc 0.33333 roc_auc 0.35740 prc_auc 0.56208[0m
[93maverage test of epoch 10: loss -0.29162 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 11: loss -0.30471 acc 0.33333 roc_auc 0.35740 prc_auc 0.56208[0m
[93maverage test of epoch 11: loss -0.32467 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 12: loss -0.33785 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 12: loss -0.35771 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 13: loss -0.37099 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 13: loss -0.39076 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 14: loss -0.40413 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 14: loss -0.42381 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 15: loss -0.43727 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 15: loss -0.45685 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 16: loss -0.47041 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 16: loss -0.48990 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 17: loss -0.50355 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 17: loss -0.52295 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 18: loss -0.53669 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 18: loss -0.55600 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -0.56984 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 19: loss -0.58905 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -0.60298 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 20: loss -0.62209 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -0.63612 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 21: loss -0.65514 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -0.66927 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 22: loss -0.68819 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -0.70241 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 23: loss -0.72124 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -0.73555 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 24: loss -0.75429 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -0.76870 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 25: loss -0.78734 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -0.80184 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 26: loss -0.82039 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -0.83498 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 27: loss -0.85344 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -0.86813 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 28: loss -0.88648 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -0.90127 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 29: loss -0.91953 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -0.93441 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 30: loss -0.95258 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -0.96756 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 31: loss -0.98563 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -1.00064 acc 0.33333 roc_auc 0.35260 prc_auc 0.55995[0m
[93maverage test of epoch 32: loss -1.01868 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -1.03384 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 33: loss -1.05173 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -1.06698 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 34: loss -1.08478 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -1.10013 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 35: loss -1.11782 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -1.13327 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 36: loss -1.15087 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -1.16641 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 37: loss -1.18392 acc 0.34211 roc_auc 0.52000 prc_auc 0.67158[0m
[92maverage training of epoch 38: loss -1.19955 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 38: loss -1.21697 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -1.23270 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 39: loss -1.25002 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -1.26584 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 40: loss -1.28306 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -1.29898 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 41: loss -1.31611 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -1.33212 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 42: loss -1.34916 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -1.36527 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 43: loss -1.38221 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -1.39841 acc 0.43333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 44: loss -1.41525 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -1.43155 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 45: loss -1.44830 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -1.46469 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 46: loss -1.48135 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -1.49783 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 47: loss -1.51440 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -1.53098 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 48: loss -1.54744 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -1.56412 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 49: loss -1.58049 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -1.26645 acc 0.66667 roc_auc 0.46060 prc_auc 0.64270[0m
[93maverage test of epoch 0: loss -1.64276 acc 0.65789 roc_auc 0.25385 prc_auc 0.58929[0m
[92maverage training of epoch 1: loss -2.24559 acc 0.66667 roc_auc 0.46740 prc_auc 0.64694[0m
[93maverage test of epoch 1: loss -3.05584 acc 0.65789 roc_auc 0.54769 prc_auc 0.79440[0m
[92maverage training of epoch 2: loss -3.94479 acc 0.66667 roc_auc 0.46840 prc_auc 0.64783[0m
[93maverage test of epoch 2: loss -4.84906 acc 0.65789 roc_auc 0.84462 prc_auc 0.91766[0m
[92maverage training of epoch 3: loss -5.87288 acc 0.66667 roc_auc 0.46920 prc_auc 0.64802[0m
[93maverage test of epoch 3: loss -6.92477 acc 0.65789 roc_auc 0.84000 prc_auc 0.90747[0m
[92maverage training of epoch 4: loss -8.04421 acc 0.66667 roc_auc 0.46920 prc_auc 0.64802[0m
[93maverage test of epoch 4: loss -9.08833 acc 0.65789 roc_auc 0.82615 prc_auc 0.90552[0m
[92maverage training of epoch 5: loss -10.14134 acc 0.66667 roc_auc 0.46940 prc_auc 0.64947[0m
[93maverage test of epoch 5: loss -11.12653 acc 0.65789 roc_auc 0.88615 prc_auc 0.93130[0m
[92maverage training of epoch 6: loss -12.18385 acc 0.66667 roc_auc 0.46880 prc_auc 0.64902[0m
[93maverage test of epoch 6: loss -13.17543 acc 0.65789 roc_auc 0.88308 prc_auc 0.92686[0m
[92maverage training of epoch 7: loss -14.27020 acc 0.66667 roc_auc 0.46880 prc_auc 0.65015[0m
[93maverage test of epoch 7: loss -15.29066 acc 0.65789 roc_auc 0.88000 prc_auc 0.90544[0m
[92maverage training of epoch 8: loss -16.43211 acc 0.66667 roc_auc 0.46880 prc_auc 0.65015[0m
[93maverage test of epoch 8: loss -17.48707 acc 0.65789 roc_auc 0.79385 prc_auc 0.83767[0m
[92maverage training of epoch 9: loss -18.68094 acc 0.66667 roc_auc 0.46800 prc_auc 0.64806[0m
[93maverage test of epoch 9: loss -19.77587 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 10: loss -21.02666 acc 0.66667 roc_auc 0.46800 prc_auc 0.64799[0m
[93maverage test of epoch 10: loss -22.16433 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 11: loss -23.47091 acc 0.66667 roc_auc 0.46780 prc_auc 0.64579[0m
[93maverage test of epoch 11: loss -24.64884 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 12: loss -26.01209 acc 0.66667 roc_auc 0.46570 prc_auc 0.64185[0m
[93maverage test of epoch 12: loss -27.23190 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 13: loss -28.65422 acc 0.66667 roc_auc 0.46400 prc_auc 0.63912[0m
[93maverage test of epoch 13: loss -29.91745 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 14: loss -31.40065 acc 0.66667 roc_auc 0.46460 prc_auc 0.63944[0m
[93maverage test of epoch 14: loss -32.70834 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 15: loss -34.25385 acc 0.66667 roc_auc 0.44690 prc_auc 0.62920[0m
[93maverage test of epoch 15: loss -35.60667 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 16: loss -37.21566 acc 0.66667 roc_auc 0.47420 prc_auc 0.65471[0m
[93maverage test of epoch 16: loss -38.61406 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 17: loss -40.28753 acc 0.66667 roc_auc 0.48500 prc_auc 0.66030[0m
[93maverage test of epoch 17: loss -41.73178 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 18: loss -43.47060 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 18: loss -44.96084 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -46.76576 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 19: loss -48.30203 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -50.17372 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 20: loss -51.75599 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -53.69508 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 21: loss -55.32324 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -57.33028 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 22: loss -59.00419 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -61.07970 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 23: loss -62.79915 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -64.94353 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 24: loss -66.70789 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -68.91894 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 25: loss -70.72354 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -72.99764 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 26: loss -74.84048 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -77.17901 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 27: loss -79.06077 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -81.46486 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 28: loss -83.38592 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -85.85656 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 29: loss -87.81717 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -90.35517 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 30: loss -92.35546 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -94.96153 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 31: loss -97.00151 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -99.67628 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 32: loss -101.75589 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -104.49990 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 33: loss -106.61900 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -109.43277 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -111.59121 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -114.47518 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -116.67272 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -119.62707 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -121.86240 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -124.88507 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -127.15579 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -130.24696 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -132.55314 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -135.71354 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -138.05528 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -141.28546 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -143.66268 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -146.96318 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -149.37578 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -152.74695 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -155.19478 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -158.63719 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -161.12016 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -164.63404 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -167.15111 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -170.73448 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -173.28313 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -176.93610 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -179.51642 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -183.23960 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -185.85166 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -189.64572 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -192.28961 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -196.15514 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -198.83080 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.59220 acc 0.58000 roc_auc 0.40120 prc_auc 0.61557[0m
[93maverage test of epoch 0: loss -1.42326 acc 0.65789 roc_auc 0.18462 prc_auc 0.59969[0m
[92maverage training of epoch 1: loss -2.04195 acc 0.66667 roc_auc 0.41080 prc_auc 0.62045[0m
[93maverage test of epoch 1: loss -2.72852 acc 0.65789 roc_auc 0.49846 prc_auc 0.75913[0m
[92maverage training of epoch 2: loss -3.78604 acc 0.66667 roc_auc 0.44480 prc_auc 0.64475[0m
[93maverage test of epoch 2: loss -5.12109 acc 0.65789 roc_auc 0.18000 prc_auc 0.57639[0m
[92maverage training of epoch 3: loss -6.33806 acc 0.66667 roc_auc 0.44200 prc_auc 0.63971[0m
[93maverage test of epoch 3: loss -7.42456 acc 0.65789 roc_auc 0.97385 prc_auc 0.98722[0m
[92maverage training of epoch 4: loss -8.51397 acc 0.66667 roc_auc 0.43180 prc_auc 0.63154[0m
[93maverage test of epoch 4: loss -9.58566 acc 0.65789 roc_auc 0.96923 prc_auc 0.98569[0m
[92maverage training of epoch 5: loss -10.70047 acc 0.66667 roc_auc 0.42760 prc_auc 0.62687[0m
[93maverage test of epoch 5: loss -11.78351 acc 0.65789 roc_auc 0.96769 prc_auc 0.98461[0m
[92maverage training of epoch 6: loss -12.94154 acc 0.66667 roc_auc 0.42600 prc_auc 0.62556[0m
[93maverage test of epoch 6: loss -14.06133 acc 0.65789 roc_auc 0.96154 prc_auc 0.97337[0m
[92maverage training of epoch 7: loss -15.27998 acc 0.66667 roc_auc 0.42520 prc_auc 0.62471[0m
[93maverage test of epoch 7: loss -16.45141 acc 0.65789 roc_auc 0.92615 prc_auc 0.94494[0m
[92maverage training of epoch 8: loss -17.73969 acc 0.66667 roc_auc 0.42380 prc_auc 0.62324[0m
[93maverage test of epoch 8: loss -18.97039 acc 0.65789 roc_auc 0.94000 prc_auc 0.95895[0m
[92maverage training of epoch 9: loss -20.33299 acc 0.66667 roc_auc 0.42230 prc_auc 0.62199[0m
[93maverage test of epoch 9: loss -21.62541 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 10: loss -23.06132 acc 0.66667 roc_auc 0.42150 prc_auc 0.62161[0m
[93maverage test of epoch 10: loss -24.41451 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 11: loss -25.92605 acc 0.66667 roc_auc 0.42090 prc_auc 0.62025[0m
[93maverage test of epoch 11: loss -27.34230 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 12: loss -28.93177 acc 0.66667 roc_auc 0.42040 prc_auc 0.61981[0m
[93maverage test of epoch 12: loss -30.41252 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 13: loss -32.08153 acc 0.66667 roc_auc 0.42010 prc_auc 0.61316[0m
[93maverage test of epoch 13: loss -33.62755 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 14: loss -35.37728 acc 0.66667 roc_auc 0.42420 prc_auc 0.61535[0m
[93maverage test of epoch 14: loss -36.98891 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 15: loss -38.82028 acc 0.66667 roc_auc 0.42170 prc_auc 0.61525[0m
[93maverage test of epoch 15: loss -40.49758 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 16: loss -42.41122 acc 0.66667 roc_auc 0.41610 prc_auc 0.61586[0m
[93maverage test of epoch 16: loss -44.15361 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 17: loss -46.14880 acc 0.66667 roc_auc 0.45170 prc_auc 0.64386[0m
[93maverage test of epoch 17: loss -47.95467 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 18: loss -50.03199 acc 0.66667 roc_auc 0.40000 prc_auc 0.62886[0m
[93maverage test of epoch 18: loss -51.90131 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -54.06154 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 19: loss -55.99419 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -58.23799 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 20: loss -60.23371 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -62.56161 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 21: loss -64.62007 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -67.03240 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 22: loss -69.15250 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -71.64759 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 23: loss -73.82594 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -76.40008 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 24: loss -78.63244 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -81.28529 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 25: loss -83.57112 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -86.30009 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 26: loss -88.63596 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -91.44087 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 27: loss -93.82584 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -96.70376 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 28: loss -99.13503 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -102.08646 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 29: loss -104.56363 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -107.58931 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 30: loss -110.11280 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -113.21445 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 31: loss -115.78514 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -118.96421 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 32: loss -121.58270 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -124.84043 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 33: loss -127.50712 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -130.84460 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -133.55974 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -136.97794 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -139.74169 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -143.24006 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -146.04943 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -149.62569 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -152.47856 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -156.13364 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -159.03048 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -162.76547 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -165.70664 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -169.52254 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -172.50825 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -176.40597 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -179.43647 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -183.41674 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -186.49202 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -190.55578 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -193.67602 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -197.82387 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -200.98883 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -205.22137 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -208.43108 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -212.74919 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -216.00363 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -220.40787 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -223.70698 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -228.19761 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -231.54083 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -236.11850 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -239.50582 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.21702 acc 0.58278 roc_auc 0.42039 prc_auc 0.61598[0m
[93maverage test of epoch 0: loss -0.51200 acc 0.64865 roc_auc 0.75667 prc_auc 0.88694[0m
[92maverage training of epoch 1: loss -1.11619 acc 0.66225 roc_auc 0.48941 prc_auc 0.70219[0m
[93maverage test of epoch 1: loss -1.86158 acc 0.67568 roc_auc 0.85000 prc_auc 0.91747[0m
[92maverage training of epoch 2: loss -2.73923 acc 0.66225 roc_auc 0.48804 prc_auc 0.71708[0m
[93maverage test of epoch 2: loss -3.67718 acc 0.67568 roc_auc 0.83333 prc_auc 0.91833[0m
[92maverage training of epoch 3: loss -4.59247 acc 0.66225 roc_auc 0.47314 prc_auc 0.68107[0m
[93maverage test of epoch 3: loss -5.56825 acc 0.67568 roc_auc 0.83000 prc_auc 0.91600[0m
[92maverage training of epoch 4: loss -6.48355 acc 0.66225 roc_auc 0.49314 prc_auc 0.68836[0m
[93maverage test of epoch 4: loss -7.47391 acc 0.67568 roc_auc 0.82667 prc_auc 0.91352[0m
[92maverage training of epoch 5: loss -8.38335 acc 0.66225 roc_auc 0.51275 prc_auc 0.68825[0m
[93maverage test of epoch 5: loss -9.39077 acc 0.67568 roc_auc 0.82667 prc_auc 0.91352[0m
[92maverage training of epoch 6: loss -10.30441 acc 0.66225 roc_auc 0.52804 prc_auc 0.69900[0m
[93maverage test of epoch 6: loss -11.33794 acc 0.67568 roc_auc 0.84667 prc_auc 0.91893[0m
[92maverage training of epoch 7: loss -12.25890 acc 0.66225 roc_auc 0.56196 prc_auc 0.72239[0m
[93maverage test of epoch 7: loss -13.32391 acc 0.67568 roc_auc 0.86000 prc_auc 0.92396[0m
[92maverage training of epoch 8: loss -14.26097 acc 0.66225 roc_auc 0.61157 prc_auc 0.75242[0m
[93maverage test of epoch 8: loss -15.36649 acc 0.67568 roc_auc 0.86000 prc_auc 0.92396[0m
[92maverage training of epoch 9: loss -16.32512 acc 0.66225 roc_auc 0.71784 prc_auc 0.79615[0m
[93maverage test of epoch 9: loss -17.47553 acc 0.67568 roc_auc 0.86333 prc_auc 0.92643[0m
[92maverage training of epoch 10: loss -18.46148 acc 0.66225 roc_auc 0.80020 prc_auc 0.84268[0m
[93maverage test of epoch 10: loss -19.66364 acc 0.67568 roc_auc 0.86667 prc_auc 0.92754[0m
[92maverage training of epoch 11: loss -20.67927 acc 0.66225 roc_auc 0.83216 prc_auc 0.86048[0m
[93maverage test of epoch 11: loss -21.92243 acc 0.67568 roc_auc 0.86000 prc_auc 0.92106[0m
[92maverage training of epoch 12: loss -22.97171 acc 0.66225 roc_auc 0.84098 prc_auc 0.86191[0m
[93maverage test of epoch 12: loss -24.23545 acc 0.67568 roc_auc 0.84500 prc_auc 0.89349[0m
[92maverage training of epoch 13: loss -25.32695 acc 0.66225 roc_auc 0.84471 prc_auc 0.86106[0m
[93maverage test of epoch 13: loss -26.63232 acc 0.67568 roc_auc 0.83667 prc_auc 0.86980[0m
[92maverage training of epoch 14: loss -27.75478 acc 0.66225 roc_auc 0.84510 prc_auc 0.85697[0m
[93maverage test of epoch 14: loss -29.10758 acc 0.67568 roc_auc 0.83000 prc_auc 0.86863[0m
[92maverage training of epoch 15: loss -30.26404 acc 0.66225 roc_auc 0.84490 prc_auc 0.85433[0m
[93maverage test of epoch 15: loss -31.66737 acc 0.67568 roc_auc 0.83000 prc_auc 0.87209[0m
[92maverage training of epoch 16: loss -32.86094 acc 0.66225 roc_auc 0.84461 prc_auc 0.85366[0m
[93maverage test of epoch 16: loss -34.31808 acc 0.67568 roc_auc 0.83833 prc_auc 0.88043[0m
[92maverage training of epoch 17: loss -35.54916 acc 0.66225 roc_auc 0.84363 prc_auc 0.85282[0m
[93maverage test of epoch 17: loss -37.06287 acc 0.67568 roc_auc 0.82333 prc_auc 0.86770[0m
[92maverage training of epoch 18: loss -38.33490 acc 0.66225 roc_auc 0.84363 prc_auc 0.85635[0m
[93maverage test of epoch 18: loss -39.90687 acc 0.67568 roc_auc 0.85667 prc_auc 0.89656[0m
[92maverage training of epoch 19: loss -41.22115 acc 0.66225 roc_auc 0.84373 prc_auc 0.85422[0m
[93maverage test of epoch 19: loss -42.85344 acc 0.67568 roc_auc 0.86333 prc_auc 0.90262[0m
[92maverage training of epoch 20: loss -44.21120 acc 0.66225 roc_auc 0.84647 prc_auc 0.86332[0m
[93maverage test of epoch 20: loss -45.90566 acc 0.67568 roc_auc 0.86500 prc_auc 0.90262[0m
[92maverage training of epoch 21: loss -47.30756 acc 0.66225 roc_auc 0.84755 prc_auc 0.87299[0m
[93maverage test of epoch 21: loss -49.06617 acc 0.67568 roc_auc 0.86500 prc_auc 0.90262[0m
[92maverage training of epoch 22: loss -50.51071 acc 0.66225 roc_auc 0.88745 prc_auc 0.91456[0m
[93maverage test of epoch 22: loss -52.33507 acc 0.67568 roc_auc 0.86000 prc_auc 0.89830[0m
[92maverage training of epoch 23: loss -53.82310 acc 0.66225 roc_auc 0.88716 prc_auc 0.91370[0m
[93maverage test of epoch 23: loss -55.71525 acc 0.67568 roc_auc 0.83167 prc_auc 0.87442[0m
[92maverage training of epoch 24: loss -57.24493 acc 0.66225 roc_auc 0.82745 prc_auc 0.86089[0m
[93maverage test of epoch 24: loss -59.20638 acc 0.67568 roc_auc 0.83167 prc_auc 0.87442[0m
[92maverage training of epoch 25: loss -60.77701 acc 0.66225 roc_auc 0.81833 prc_auc 0.85340[0m
[93maverage test of epoch 25: loss -62.81012 acc 0.67568 roc_auc 0.83167 prc_auc 0.87442[0m
[92maverage training of epoch 26: loss -64.42085 acc 0.66225 roc_auc 0.80961 prc_auc 0.84615[0m
[93maverage test of epoch 26: loss -66.52854 acc 0.67568 roc_auc 0.83500 prc_auc 0.87552[0m
[92maverage training of epoch 27: loss -68.17776 acc 0.66225 roc_auc 0.81078 prc_auc 0.84645[0m
[93maverage test of epoch 27: loss -70.36304 acc 0.67568 roc_auc 0.75833 prc_auc 0.81739[0m
[92maverage training of epoch 28: loss -72.04877 acc 0.66225 roc_auc 0.80167 prc_auc 0.83920[0m
[93maverage test of epoch 28: loss -74.31537 acc 0.67568 roc_auc 0.75833 prc_auc 0.81739[0m
[92maverage training of epoch 29: loss -76.03561 acc 0.66225 roc_auc 0.80147 prc_auc 0.83912[0m
[93maverage test of epoch 29: loss -78.38882 acc 0.67568 roc_auc 0.75833 prc_auc 0.81739[0m
[92maverage training of epoch 30: loss -80.14273 acc 0.66225 roc_auc 0.80088 prc_auc 0.83887[0m
[93maverage test of epoch 30: loss -82.58747 acc 0.67568 roc_auc 0.68667 prc_auc 0.77180[0m
[92maverage training of epoch 31: loss -84.37690 acc 0.66225 roc_auc 0.77343 prc_auc 0.81784[0m
[93maverage test of epoch 31: loss -86.92355 acc 0.67568 roc_auc 0.64667 prc_auc 0.74857[0m
[92maverage training of epoch 32: loss -88.76313 acc 0.66225 roc_auc 0.67794 prc_auc 0.75330[0m
[93maverage test of epoch 32: loss -91.42532 acc 0.67568 roc_auc 0.60667 prc_auc 0.72675[0m
[92maverage training of epoch 33: loss -93.39356 acc 0.66225 roc_auc 0.65931 prc_auc 0.74226[0m
[93maverage test of epoch 33: loss -96.17917 acc 0.67568 roc_auc 0.58333 prc_auc 0.71429[0m
[92maverage training of epoch 34: loss -98.31780 acc 0.66225 roc_auc 0.60784 prc_auc 0.71429[0m
[93maverage test of epoch 34: loss -101.22416 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 35: loss -103.31667 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 35: loss -106.29077 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 36: loss -108.38895 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 36: loss -111.43641 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 37: loss -113.58220 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 37: loss -116.70980 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 38: loss -118.90815 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 38: loss -122.12182 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 39: loss -124.37668 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 39: loss -127.67896 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -129.98829 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 40: loss -133.37729 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -135.74099 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 41: loss -139.21589 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -141.63702 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 42: loss -145.20182 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -147.67867 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 43: loss -151.33141 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -153.86296 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 44: loss -157.60187 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -160.18731 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 45: loss -164.01283 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -166.65260 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 46: loss -170.56551 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -173.25971 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 47: loss -177.26058 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -180.00918 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 48: loss -184.09855 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -186.90129 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 49: loss -191.07955 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.30848 acc 0.35099 roc_auc 0.46294 prc_auc 0.66833[0m
[93maverage test of epoch 0: loss -0.47358 acc 0.40541 roc_auc 0.94667 prc_auc 0.97960[0m
[92maverage training of epoch 1: loss -0.67778 acc 0.60927 roc_auc 0.45961 prc_auc 0.66403[0m
[93maverage test of epoch 1: loss -0.93547 acc 0.67568 roc_auc 0.94667 prc_auc 0.97890[0m
[92maverage training of epoch 2: loss -1.22583 acc 0.66225 roc_auc 0.46216 prc_auc 0.66362[0m
[93maverage test of epoch 2: loss -1.59970 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 3: loss -1.90306 acc 0.66225 roc_auc 0.46275 prc_auc 0.66022[0mUsing backend: pytorch
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))

[93maverage test of epoch 3: loss -2.29608 acc 0.67568 roc_auc 0.92667 prc_auc 0.97104[0m
[92maverage training of epoch 4: loss -2.61133 acc 0.66225 roc_auc 0.44510 prc_auc 0.64701[0m
[93maverage test of epoch 4: loss -3.01280 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 5: loss -3.28451 acc 0.66225 roc_auc 0.43824 prc_auc 0.63898[0m
[93maverage test of epoch 5: loss -3.68024 acc 0.67568 roc_auc 0.92667 prc_auc 0.97104[0m
[92maverage training of epoch 6: loss -3.96502 acc 0.66225 roc_auc 0.42863 prc_auc 0.63653[0m
[93maverage test of epoch 6: loss -4.39408 acc 0.67568 roc_auc 0.92667 prc_auc 0.97104[0m
[92maverage training of epoch 7: loss -4.70578 acc 0.66225 roc_auc 0.42353 prc_auc 0.64304[0m
[93maverage test of epoch 7: loss -5.17537 acc 0.67568 roc_auc 0.92667 prc_auc 0.97104[0m
[92maverage training of epoch 8: loss -5.51839 acc 0.66225 roc_auc 0.41647 prc_auc 0.64251[0m
[93maverage test of epoch 8: loss -6.03030 acc 0.67568 roc_auc 0.92667 prc_auc 0.97104[0m
[92maverage training of epoch 9: loss -6.40517 acc 0.66225 roc_auc 0.40912 prc_auc 0.63106[0m
[93maverage test of epoch 9: loss -6.95943 acc 0.67568 roc_auc 0.92500 prc_auc 0.96958[0m
[92maverage training of epoch 10: loss -7.36645 acc 0.66225 roc_auc 0.39941 prc_auc 0.61625[0m
[93maverage test of epoch 10: loss -7.96294 acc 0.67568 roc_auc 0.92667 prc_auc 0.96958[0m
[92maverage training of epoch 11: loss -8.40964 acc 0.66225 roc_auc 0.39706 prc_auc 0.60244[0m
[93maverage test of epoch 11: loss -9.10266 acc 0.67568 roc_auc 0.93000 prc_auc 0.96988[0m
[92maverage training of epoch 12: loss -9.78339 acc 0.66225 roc_auc 0.39294 prc_auc 0.59604[0m
[93maverage test of epoch 12: loss -10.69327 acc 0.67568 roc_auc 0.93333 prc_auc 0.96845[0m
[92maverage training of epoch 13: loss -11.44041 acc 0.66225 roc_auc 0.38216 prc_auc 0.58796[0m
[93maverage test of epoch 13: loss -12.40875 acc 0.67568 roc_auc 0.93333 prc_auc 0.96875[0m
[92maverage training of epoch 14: loss -13.20178 acc 0.66225 roc_auc 0.37735 prc_auc 0.57580[0m
[93maverage test of epoch 14: loss -14.22669 acc 0.67568 roc_auc 0.93333 prc_auc 0.96875[0m
[92maverage training of epoch 15: loss -15.06679 acc 0.66225 roc_auc 0.37578 prc_auc 0.57412[0m
[93maverage test of epoch 15: loss -16.15009 acc 0.67568 roc_auc 0.94000 prc_auc 0.96632[0m
[92maverage training of epoch 16: loss -17.03823 acc 0.66225 roc_auc 0.37549 prc_auc 0.57401[0m
[93maverage test of epoch 16: loss -18.18143 acc 0.67568 roc_auc 0.81833 prc_auc 0.86691[0m
[92maverage training of epoch 17: loss -19.11843 acc 0.66225 roc_auc 0.37500 prc_auc 0.57382[0m
[93maverage test of epoch 17: loss -20.32292 acc 0.67568 roc_auc 0.66667 prc_auc 0.75758[0m
[92maverage training of epoch 18: loss -21.30957 acc 0.66225 roc_auc 0.37373 prc_auc 0.57215[0m
[93maverage test of epoch 18: loss -22.57666 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 19: loss -23.61368 acc 0.66225 roc_auc 0.37176 prc_auc 0.57121[0m
[93maverage test of epoch 19: loss -24.94463 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 20: loss -26.03265 acc 0.66225 roc_auc 0.37137 prc_auc 0.56929[0m
[93maverage test of epoch 20: loss -27.42865 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 21: loss -28.56824 acc 0.66225 roc_auc 0.37029 prc_auc 0.57068[0m
[93maverage test of epoch 21: loss -30.03042 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 22: loss -31.22202 acc 0.66225 roc_auc 0.36794 prc_auc 0.56862[0m
[93maverage test of epoch 22: loss -32.75143 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 23: loss -33.99538 acc 0.66225 roc_auc 0.36961 prc_auc 0.57083[0m
[93maverage test of epoch 23: loss -35.59300 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 24: loss -36.91112 acc 0.66225 roc_auc 0.37784 prc_auc 0.57875[0m
[93maverage test of epoch 24: loss -38.66711 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 25: loss -40.24125 acc 0.66225 roc_auc 0.37186 prc_auc 0.57567[0m
[93maverage test of epoch 25: loss -42.21857 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 26: loss -43.87464 acc 0.66225 roc_auc 0.36108 prc_auc 0.57445[0m
[93maverage test of epoch 26: loss -45.94142 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 27: loss -47.66336 acc 0.66225 roc_auc 0.36912 prc_auc 0.58212[0m
[93maverage test of epoch 27: loss -49.81550 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 28: loss -51.60180 acc 0.66225 roc_auc 0.38118 prc_auc 0.59704[0m
[93maverage test of epoch 28: loss -53.83966 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 29: loss -55.68916 acc 0.66225 roc_auc 0.38990 prc_auc 0.61239[0m
[93maverage test of epoch 29: loss -58.01174 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 30: loss -59.91791 acc 0.66225 roc_auc 0.44647 prc_auc 0.63981[0m
[93maverage test of epoch 30: loss -62.31945 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 31: loss -64.27807 acc 0.66225 roc_auc 0.36549 prc_auc 0.61682[0m
[93maverage test of epoch 31: loss -66.75846 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 32: loss -68.77060 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 32: loss -71.33181 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 33: loss -73.39672 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 33: loss -76.03808 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 34: loss -78.15413 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 34: loss -80.87578 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 35: loss -83.04334 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 35: loss -85.84700 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 36: loss -88.06639 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 36: loss -90.95358 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 37: loss -93.22489 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 37: loss -96.19689 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 38: loss -98.52008 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 38: loss -101.57808 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 39: loss -103.95290 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 39: loss -107.09791 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -109.52407 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 40: loss -112.75703 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -115.23416 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 41: loss -118.55595 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -121.08309 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 42: loss -124.49246 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -127.06034 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 43: loss -130.54959 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -133.15535 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 44: loss -136.72599 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -139.37075 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 45: loss -143.02515 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -145.70962 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 46: loss -149.44973 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -152.17437 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 47: loss -156.00184 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -158.76589 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 48: loss -162.68037 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -165.48302 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 49: loss -169.48553 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 1)
('lr', 0.0003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.66501 ROC_AUC (avg): 0.5 PRC_AUC (avg): 0.66501 

Average forward propagation time taken(ms): 2.8204417882278303
Average backward propagation time taken(ms): 0.9434667472376861

