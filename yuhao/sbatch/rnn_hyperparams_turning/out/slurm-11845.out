# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.0001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-18-09-36/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-18-09-36/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 16,
 'epochs': 50,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 4,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.0001,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 1,
 'num_workers': 8,
 'number_of_mlp_layer': 0,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-17-18-09-36',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 50, 'learning_rate': 0.0001, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss 0.16021 acc 0.33333 roc_auc 0.57460 prc_auc 0.73511[0m
[93maverage test of epoch 0: loss 0.08654 acc 0.34211 roc_auc 0.78462 prc_auc 0.91142[0m
[92maverage training of epoch 1: loss 0.03426 acc 0.33333 roc_auc 0.59040 prc_auc 0.75334[0m
[93maverage test of epoch 1: loss -0.03221 acc 0.34211 roc_auc 0.90308 prc_auc 0.95318[0m
[92maverage training of epoch 2: loss -0.07920 acc 0.33333 roc_auc 0.61900 prc_auc 0.79814[0m
[93maverage test of epoch 2: loss -0.14237 acc 0.34211 roc_auc 0.90154 prc_auc 0.95307[0m
[92maverage training of epoch 3: loss -0.18722 acc 0.33333 roc_auc 0.62840 prc_auc 0.80583[0m
[93maverage test of epoch 3: loss -0.25040 acc 0.34211 roc_auc 0.90154 prc_auc 0.95307[0m
[92maverage training of epoch 4: loss -0.29693 acc 0.33333 roc_auc 0.64860 prc_auc 0.81682[0m
[93maverage test of epoch 4: loss -0.36440 acc 0.34211 roc_auc 0.89231 prc_auc 0.95017[0m
[92maverage training of epoch 5: loss -0.41692 acc 0.33333 roc_auc 0.64020 prc_auc 0.81222[0m
[93maverage test of epoch 5: loss -0.49276 acc 0.34211 roc_auc 0.89231 prc_auc 0.95136[0m
[92maverage training of epoch 6: loss -0.55281 acc 0.33333 roc_auc 0.64760 prc_auc 0.81192[0m
[93maverage test of epoch 6: loss -0.63728 acc 0.34211 roc_auc 0.89846 prc_auc 0.95332[0m
[92maverage training of epoch 7: loss -0.70096 acc 0.33333 roc_auc 0.64010 prc_auc 0.81143[0m
[93maverage test of epoch 7: loss -0.78951 acc 0.34211 roc_auc 0.90769 prc_auc 0.95765[0m
[92maverage training of epoch 8: loss -0.85001 acc 0.33333 roc_auc 0.64380 prc_auc 0.81811[0m
[93maverage test of epoch 8: loss -0.93791 acc 0.34211 roc_auc 0.89846 prc_auc 0.95270[0m
[92maverage training of epoch 9: loss -0.99105 acc 0.34667 roc_auc 0.65900 prc_auc 0.82290[0m
[93maverage test of epoch 9: loss -1.07882 acc 0.36842 roc_auc 0.90154 prc_auc 0.95565[0m
[92maverage training of epoch 10: loss -1.12566 acc 0.34667 roc_auc 0.68160 prc_auc 0.83541[0m
[93maverage test of epoch 10: loss -1.22244 acc 0.36842 roc_auc 0.90462 prc_auc 0.95752[0m
[92maverage training of epoch 11: loss -1.26686 acc 0.39333 roc_auc 0.72280 prc_auc 0.85549[0m
[93maverage test of epoch 11: loss -1.37700 acc 0.55263 roc_auc 0.91077 prc_auc 0.96171[0m
[92maverage training of epoch 12: loss -1.40707 acc 0.62667 roc_auc 0.80160 prc_auc 0.89002[0m
[93maverage test of epoch 12: loss -1.50392 acc 0.71053 roc_auc 0.91692 prc_auc 0.96456[0m
[92maverage training of epoch 13: loss -1.52797 acc 0.74000 roc_auc 0.86400 prc_auc 0.91825[0m
[93maverage test of epoch 13: loss -1.61815 acc 0.76316 roc_auc 0.91692 prc_auc 0.96486[0m
[92maverage training of epoch 14: loss -1.65663 acc 0.82000 roc_auc 0.87620 prc_auc 0.92294[0m
[93maverage test of epoch 14: loss -1.74866 acc 0.84211 roc_auc 0.91077 prc_auc 0.96220[0m
[92maverage training of epoch 15: loss -1.80717 acc 0.86000 roc_auc 0.87220 prc_auc 0.91897[0m
[93maverage test of epoch 15: loss -1.89555 acc 0.84211 roc_auc 0.89538 prc_auc 0.95718[0m
[92maverage training of epoch 16: loss -1.96312 acc 0.85333 roc_auc 0.87140 prc_auc 0.91653[0m
[93maverage test of epoch 16: loss -2.02915 acc 0.84211 roc_auc 0.88923 prc_auc 0.95452[0m
[92maverage training of epoch 17: loss -2.10864 acc 0.86667 roc_auc 0.86980 prc_auc 0.91147[0m
[93maverage test of epoch 17: loss -2.14642 acc 0.81579 roc_auc 0.88923 prc_auc 0.95501[0m
[92maverage training of epoch 18: loss -2.23945 acc 0.87333 roc_auc 0.86820 prc_auc 0.90611[0m
[93maverage test of epoch 18: loss -2.25241 acc 0.81579 roc_auc 0.89231 prc_auc 0.95513[0m
[92maverage training of epoch 19: loss -2.35509 acc 0.87333 roc_auc 0.86780 prc_auc 0.90158[0m
[93maverage test of epoch 19: loss -2.35019 acc 0.81579 roc_auc 0.89231 prc_auc 0.95513[0m
[92maverage training of epoch 20: loss -2.45914 acc 0.88000 roc_auc 0.86760 prc_auc 0.89960[0m
[93maverage test of epoch 20: loss -2.43944 acc 0.81579 roc_auc 0.89231 prc_auc 0.95513[0m
[92maverage training of epoch 21: loss -2.55349 acc 0.88000 roc_auc 0.86700 prc_auc 0.89992[0m
[93maverage test of epoch 21: loss -2.52000 acc 0.81579 roc_auc 0.89231 prc_auc 0.95513[0m
[92maverage training of epoch 22: loss -2.63810 acc 0.88000 roc_auc 0.86740 prc_auc 0.90059[0m
[93maverage test of epoch 22: loss -2.60051 acc 0.81579 roc_auc 0.89538 prc_auc 0.95713[0m
[92maverage training of epoch 23: loss -2.71740 acc 0.88000 roc_auc 0.86720 prc_auc 0.90148[0m
[93maverage test of epoch 23: loss -2.69049 acc 0.84211 roc_auc 0.89538 prc_auc 0.95713[0m
[92maverage training of epoch 24: loss -2.79403 acc 0.88000 roc_auc 0.86560 prc_auc 0.89946[0m
[93maverage test of epoch 24: loss -2.77403 acc 0.84211 roc_auc 0.89846 prc_auc 0.95860[0m
[92maverage training of epoch 25: loss -2.86771 acc 0.88000 roc_auc 0.86500 prc_auc 0.89787[0m
[93maverage test of epoch 25: loss -2.84838 acc 0.84211 roc_auc 0.89846 prc_auc 0.95860[0m
[92maverage training of epoch 26: loss -2.93282 acc 0.87333 roc_auc 0.86540 prc_auc 0.90024[0m
[93maverage test of epoch 26: loss -2.93397 acc 0.84211 roc_auc 0.90154 prc_auc 0.96026[0m
[92maverage training of epoch 27: loss -2.98680 acc 0.86667 roc_auc 0.86420 prc_auc 0.89950[0m
[93maverage test of epoch 27: loss -3.03412 acc 0.86842 roc_auc 0.89846 prc_auc 0.95912[0m
[92maverage training of epoch 28: loss -3.07973 acc 0.88000 roc_auc 0.85620 prc_auc 0.89384[0m
[93maverage test of epoch 28: loss -3.10228 acc 0.86842 roc_auc 0.89846 prc_auc 0.95997[0m
[92maverage training of epoch 29: loss -3.14684 acc 0.88000 roc_auc 0.85860 prc_auc 0.89349[0m
[93maverage test of epoch 29: loss -3.16572 acc 0.86842 roc_auc 0.90154 prc_auc 0.96072[0m
[92maverage training of epoch 30: loss -3.21365 acc 0.88000 roc_auc 0.85300 prc_auc 0.89101[0m
[93maverage test of epoch 30: loss -3.23377 acc 0.86842 roc_auc 0.90154 prc_auc 0.96072[0m
[92maverage training of epoch 31: loss -3.27983 acc 0.88000 roc_auc 0.85340 prc_auc 0.89076[0m
[93maverage test of epoch 31: loss -3.29814 acc 0.86842 roc_auc 0.90462 prc_auc 0.96178[0m
[92maverage training of epoch 32: loss -3.34588 acc 0.88000 roc_auc 0.85320 prc_auc 0.88922[0m
[93maverage test of epoch 32: loss -3.36163 acc 0.86842 roc_auc 0.90462 prc_auc 0.96178[0m
[92maverage training of epoch 33: loss -3.42407 acc 0.88667 roc_auc 0.85280 prc_auc 0.88915[0m
[93maverage test of epoch 33: loss -3.42485 acc 0.86842 roc_auc 0.90462 prc_auc 0.96178[0m
[92maverage training of epoch 34: loss -3.48873 acc 0.88667 roc_auc 0.85240 prc_auc 0.88811[0m
[93maverage test of epoch 34: loss -3.48774 acc 0.86842 roc_auc 0.90462 prc_auc 0.96178[0m
[92maverage training of epoch 35: loss -3.55245 acc 0.88667 roc_auc 0.85060 prc_auc 0.88563[0m
[93maverage test of epoch 35: loss -3.55023 acc 0.86842 roc_auc 0.90462 prc_auc 0.96178[0m
[92maverage training of epoch 36: loss -3.61544 acc 0.88667 roc_auc 0.84720 prc_auc 0.88016[0m
[93maverage test of epoch 36: loss -3.61213 acc 0.86842 roc_auc 0.90769 prc_auc 0.96259[0m
[92maverage training of epoch 37: loss -3.65567 acc 0.88000 roc_auc 0.85100 prc_auc 0.88939[0m
[93maverage test of epoch 37: loss -3.67268 acc 0.86842 roc_auc 0.90462 prc_auc 0.96178[0m
[92maverage training of epoch 38: loss -3.74034 acc 0.88667 roc_auc 0.86260 prc_auc 0.89515[0m
[93maverage test of epoch 38: loss -3.72163 acc 0.86842 roc_auc 0.89846 prc_auc 0.95882[0m
[92maverage training of epoch 39: loss -3.80388 acc 0.88667 roc_auc 0.86060 prc_auc 0.89555[0m
[93maverage test of epoch 39: loss -3.78885 acc 0.86842 roc_auc 0.90154 prc_auc 0.96072[0m
[92maverage training of epoch 40: loss -3.84737 acc 0.88000 roc_auc 0.84700 prc_auc 0.88135[0m
[93maverage test of epoch 40: loss -3.85450 acc 0.86842 roc_auc 0.90154 prc_auc 0.96072[0m
[92maverage training of epoch 41: loss -3.89259 acc 0.87333 roc_auc 0.85080 prc_auc 0.88448[0m
[93maverage test of epoch 41: loss -3.91373 acc 0.86842 roc_auc 0.90462 prc_auc 0.96178[0m
[92maverage training of epoch 42: loss -3.98467 acc 0.88667 roc_auc 0.84640 prc_auc 0.87985[0m
[93maverage test of epoch 42: loss -3.97373 acc 0.86842 roc_auc 0.90154 prc_auc 0.96072[0m
[92maverage training of epoch 43: loss -4.03095 acc 0.88000 roc_auc 0.86120 prc_auc 0.89443[0m
[93maverage test of epoch 43: loss -4.02887 acc 0.86842 roc_auc 0.90154 prc_auc 0.96072[0m
[92maverage training of epoch 44: loss -4.08984 acc 0.88000 roc_auc 0.84360 prc_auc 0.87548[0m
[93maverage test of epoch 44: loss -4.02084 acc 0.84211 roc_auc 0.90462 prc_auc 0.96139[0m
[92maverage training of epoch 45: loss -4.12648 acc 0.87333 roc_auc 0.81580 prc_auc 0.85413[0m
[93maverage test of epoch 45: loss -4.07122 acc 0.84211 roc_auc 0.91077 prc_auc 0.96260[0m
[92maverage training of epoch 46: loss -4.16684 acc 0.86667 roc_auc 0.81640 prc_auc 0.85494[0m
[93maverage test of epoch 46: loss -4.19885 acc 0.86842 roc_auc 0.90769 prc_auc 0.96163[0m
[92maverage training of epoch 47: loss -4.24370 acc 0.87333 roc_auc 0.81680 prc_auc 0.85563[0m
[93maverage test of epoch 47: loss -4.21370 acc 0.84211 roc_auc 0.90769 prc_auc 0.96163[0m
[92maverage training of epoch 48: loss -4.30200 acc 0.87333 roc_auc 0.81600 prc_auc 0.85472[0m
[93maverage test of epoch 48: loss -4.31205 acc 0.86842 roc_auc 0.90769 prc_auc 0.96163[0m
[92maverage training of epoch 49: loss -4.36023 acc 0.87333 roc_auc 0.81480 prc_auc 0.85225[0m
[93maverage test of epoch 49: loss -4.29978 acc 0.84211 roc_auc 0.90462 prc_auc 0.96017[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.08802 acc 0.33333 roc_auc 0.35440 prc_auc 0.59088[0m
[93maverage test of epoch 0: loss -0.25946 acc 0.34211 roc_auc 0.21846 prc_auc 0.56661[0m
[92maverage training of epoch 1: loss -0.32147 acc 0.33333 roc_auc 0.36120 prc_auc 0.59521[0m
[93maverage test of epoch 1: loss -0.49290 acc 0.34211 roc_auc 0.21538 prc_auc 0.56583[0m
[92maverage training of epoch 2: loss -0.56260 acc 0.33333 roc_auc 0.39100 prc_auc 0.60745[0m
[93maverage test of epoch 2: loss -0.72835 acc 0.34211 roc_auc 0.25538 prc_auc 0.59912[0m
[92maverage training of epoch 3: loss -0.80769 acc 0.34000 roc_auc 0.43840 prc_auc 0.63157[0m
[93maverage test of epoch 3: loss -0.97409 acc 0.39474 roc_auc 0.32923 prc_auc 0.63884[0m
[92maverage training of epoch 4: loss -1.07407 acc 0.34000 roc_auc 0.48920 prc_auc 0.67569[0m
[93maverage test of epoch 4: loss -1.25444 acc 0.42105 roc_auc 0.51385 prc_auc 0.77146[0m
[92maverage training of epoch 5: loss -1.38424 acc 0.54000 roc_auc 0.53140 prc_auc 0.72843[0m
[93maverage test of epoch 5: loss -1.58151 acc 0.65789 roc_auc 0.74462 prc_auc 0.88869[0m
[92maverage training of epoch 6: loss -1.72999 acc 0.66667 roc_auc 0.56780 prc_auc 0.75990[0m
[93maverage test of epoch 6: loss -1.92222 acc 0.65789 roc_auc 0.87692 prc_auc 0.92959[0m
[92maverage training of epoch 7: loss -2.06217 acc 0.66667 roc_auc 0.60740 prc_auc 0.79153[0m
[93maverage test of epoch 7: loss -2.21984 acc 0.65789 roc_auc 0.79692 prc_auc 0.89472[0m
[92maverage training of epoch 8: loss -2.33492 acc 0.66667 roc_auc 0.65800 prc_auc 0.82561[0m
[93maverage test of epoch 8: loss -2.45186 acc 0.65789 roc_auc 0.80000 prc_auc 0.89847[0m
[92maverage training of epoch 9: loss -2.54485 acc 0.66667 roc_auc 0.70740 prc_auc 0.85347[0m
[93maverage test of epoch 9: loss -2.63239 acc 0.65789 roc_auc 0.80615 prc_auc 0.90328[0m
[92maverage training of epoch 10: loss -2.71060 acc 0.66667 roc_auc 0.74280 prc_auc 0.87130[0m
[93maverage test of epoch 10: loss -2.77963 acc 0.65789 roc_auc 0.81538 prc_auc 0.90905[0m
[92maverage training of epoch 11: loss -2.84833 acc 0.66667 roc_auc 0.76160 prc_auc 0.87961[0m
[93maverage test of epoch 11: loss -2.90550 acc 0.65789 roc_auc 0.81231 prc_auc 0.90709[0m
[92maverage training of epoch 12: loss -2.96794 acc 0.66667 roc_auc 0.76520 prc_auc 0.87837[0m
[93maverage test of epoch 12: loss -3.01711 acc 0.65789 roc_auc 0.81231 prc_auc 0.90709[0m
[92maverage training of epoch 13: loss -3.07530 acc 0.66667 roc_auc 0.76780 prc_auc 0.87652[0m
[93maverage test of epoch 13: loss -3.11879 acc 0.65789 roc_auc 0.81231 prc_auc 0.90709[0m
[92maverage training of epoch 14: loss -3.17403 acc 0.66667 roc_auc 0.76300 prc_auc 0.86987[0m
[93maverage test of epoch 14: loss -3.21329 acc 0.65789 roc_auc 0.81231 prc_auc 0.90709[0m
[92maverage training of epoch 15: loss -3.26642 acc 0.66667 roc_auc 0.74860 prc_auc 0.86078[0m
[93maverage test of epoch 15: loss -3.30240 acc 0.65789 roc_auc 0.81231 prc_auc 0.90709[0m
[92maverage training of epoch 16: loss -3.35399 acc 0.66667 roc_auc 0.72860 prc_auc 0.84756[0m
[93maverage test of epoch 16: loss -3.38735 acc 0.65789 roc_auc 0.81231 prc_auc 0.90709[0m
[92maverage training of epoch 17: loss -3.43779 acc 0.66667 roc_auc 0.70280 prc_auc 0.83258[0m
[93maverage test of epoch 17: loss -3.46899 acc 0.65789 roc_auc 0.81231 prc_auc 0.90709[0m
[92maverage training of epoch 18: loss -3.51857 acc 0.66667 roc_auc 0.68340 prc_auc 0.82184[0m
[93maverage test of epoch 18: loss -3.54797 acc 0.65789 roc_auc 0.80923 prc_auc 0.90376[0m
[92maverage training of epoch 19: loss -3.59689 acc 0.66667 roc_auc 0.66280 prc_auc 0.80897[0m
[93maverage test of epoch 19: loss -3.62474 acc 0.65789 roc_auc 0.81231 prc_auc 0.90572[0m
[92maverage training of epoch 20: loss -3.67316 acc 0.66667 roc_auc 0.64140 prc_auc 0.79637[0m
[93maverage test of epoch 20: loss -3.69967 acc 0.65789 roc_auc 0.81077 prc_auc 0.90416[0m
[92maverage training of epoch 21: loss -3.74771 acc 0.66667 roc_auc 0.62460 prc_auc 0.78598[0m
[93maverage test of epoch 21: loss -3.77305 acc 0.65789 roc_auc 0.80923 prc_auc 0.90416[0m
[92maverage training of epoch 22: loss -3.82080 acc 0.66667 roc_auc 0.60860 prc_auc 0.77629[0m
[93maverage test of epoch 22: loss -3.84509 acc 0.65789 roc_auc 0.80923 prc_auc 0.90416[0m
[92maverage training of epoch 23: loss -3.89263 acc 0.66667 roc_auc 0.58900 prc_auc 0.76112[0m
[93maverage test of epoch 23: loss -3.91598 acc 0.65789 roc_auc 0.80923 prc_auc 0.90416[0m
[92maverage training of epoch 24: loss -3.96336 acc 0.66667 roc_auc 0.56990 prc_auc 0.74801[0m
[93maverage test of epoch 24: loss -3.98586 acc 0.65789 roc_auc 0.81231 prc_auc 0.90603[0m
[92maverage training of epoch 25: loss -4.03311 acc 0.66667 roc_auc 0.54940 prc_auc 0.73139[0m
[93maverage test of epoch 25: loss -4.05484 acc 0.65789 roc_auc 0.81231 prc_auc 0.90603[0m
[92maverage training of epoch 26: loss -4.10199 acc 0.66667 roc_auc 0.53500 prc_auc 0.71949[0m
[93maverage test of epoch 26: loss -4.12300 acc 0.65789 roc_auc 0.81231 prc_auc 0.90603[0m
[92maverage training of epoch 27: loss -4.17008 acc 0.66667 roc_auc 0.51990 prc_auc 0.70806[0m
[93maverage test of epoch 27: loss -4.19041 acc 0.65789 roc_auc 0.81231 prc_auc 0.90603[0m
[92maverage training of epoch 28: loss -4.23745 acc 0.66667 roc_auc 0.50340 prc_auc 0.69445[0m
[93maverage test of epoch 28: loss -4.25714 acc 0.65789 roc_auc 0.81231 prc_auc 0.90603[0m
[92maverage training of epoch 29: loss -4.30414 acc 0.66667 roc_auc 0.49220 prc_auc 0.68427[0m
[93maverage test of epoch 29: loss -4.32323 acc 0.65789 roc_auc 0.81231 prc_auc 0.90603[0m
[92maverage training of epoch 30: loss -4.37020 acc 0.66667 roc_auc 0.48260 prc_auc 0.67028[0m
[93maverage test of epoch 30: loss -4.38871 acc 0.65789 roc_auc 0.81077 prc_auc 0.90441[0m
[92maverage training of epoch 31: loss -4.43566 acc 0.66667 roc_auc 0.47280 prc_auc 0.66091[0m
[93maverage test of epoch 31: loss -4.45361 acc 0.65789 roc_auc 0.80923 prc_auc 0.90441[0m
[92maverage training of epoch 32: loss -4.50056 acc 0.66667 roc_auc 0.46260 prc_auc 0.65073[0m
[93maverage test of epoch 32: loss -4.51796 acc 0.65789 roc_auc 0.80769 prc_auc 0.90254[0m
[92maverage training of epoch 33: loss -4.56490 acc 0.66667 roc_auc 0.45680 prc_auc 0.64682[0m
[93maverage test of epoch 33: loss -4.58178 acc 0.65789 roc_auc 0.80923 prc_auc 0.90254[0m
[92maverage training of epoch 34: loss -4.62873 acc 0.66667 roc_auc 0.45060 prc_auc 0.64183[0m
[93maverage test of epoch 34: loss -4.64509 acc 0.65789 roc_auc 0.80769 prc_auc 0.90254[0m
[92maverage training of epoch 35: loss -4.69205 acc 0.66667 roc_auc 0.44520 prc_auc 0.63376[0m
[93maverage test of epoch 35: loss -4.70791 acc 0.65789 roc_auc 0.80615 prc_auc 0.90254[0m
[92maverage training of epoch 36: loss -4.75489 acc 0.66667 roc_auc 0.44020 prc_auc 0.62790[0m
[93maverage test of epoch 36: loss -4.77027 acc 0.65789 roc_auc 0.80769 prc_auc 0.90254[0m
[92maverage training of epoch 37: loss -4.81727 acc 0.66667 roc_auc 0.43680 prc_auc 0.62491[0m
[93maverage test of epoch 37: loss -4.83217 acc 0.65789 roc_auc 0.80615 prc_auc 0.90273[0m
[92maverage training of epoch 38: loss -4.87920 acc 0.66667 roc_auc 0.43460 prc_auc 0.62168[0m
[93maverage test of epoch 38: loss -4.89363 acc 0.65789 roc_auc 0.80769 prc_auc 0.90273[0m
[92maverage training of epoch 39: loss -4.94070 acc 0.66667 roc_auc 0.43180 prc_auc 0.61840[0m
[93maverage test of epoch 39: loss -4.95469 acc 0.65789 roc_auc 0.80308 prc_auc 0.89546[0m
[92maverage training of epoch 40: loss -5.00180 acc 0.66667 roc_auc 0.42910 prc_auc 0.61537[0m
[93maverage test of epoch 40: loss -5.01534 acc 0.65789 roc_auc 0.80462 prc_auc 0.89713[0m
[92maverage training of epoch 41: loss -5.06251 acc 0.66667 roc_auc 0.42670 prc_auc 0.61233[0m
[93maverage test of epoch 41: loss -5.07562 acc 0.65789 roc_auc 0.80769 prc_auc 0.90077[0m
[92maverage training of epoch 42: loss -5.12284 acc 0.66667 roc_auc 0.42450 prc_auc 0.60694[0m
[93maverage test of epoch 42: loss -5.13555 acc 0.65789 roc_auc 0.80769 prc_auc 0.90077[0m
[92maverage training of epoch 43: loss -5.18283 acc 0.66667 roc_auc 0.42340 prc_auc 0.60625[0m
[93maverage test of epoch 43: loss -5.19513 acc 0.65789 roc_auc 0.80000 prc_auc 0.89257[0m
[92maverage training of epoch 44: loss -5.24249 acc 0.66667 roc_auc 0.42220 prc_auc 0.60529[0m
[93maverage test of epoch 44: loss -5.25439 acc 0.65789 roc_auc 0.80615 prc_auc 0.89410[0m
[92maverage training of epoch 45: loss -5.30183 acc 0.66667 roc_auc 0.42100 prc_auc 0.60139[0m
[93maverage test of epoch 45: loss -5.31335 acc 0.65789 roc_auc 0.80462 prc_auc 0.89616[0m
[92maverage training of epoch 46: loss -5.36087 acc 0.66667 roc_auc 0.42010 prc_auc 0.60001[0m
[93maverage test of epoch 46: loss -5.37203 acc 0.65789 roc_auc 0.79846 prc_auc 0.89037[0m
[92maverage training of epoch 47: loss -5.41964 acc 0.66667 roc_auc 0.41960 prc_auc 0.59878[0m
[93maverage test of epoch 47: loss -5.43045 acc 0.65789 roc_auc 0.80308 prc_auc 0.89147[0m
[92maverage training of epoch 48: loss -5.47815 acc 0.66667 roc_auc 0.41880 prc_auc 0.59744[0m
[93maverage test of epoch 48: loss -5.48861 acc 0.65789 roc_auc 0.80154 prc_auc 0.88972[0m
[92maverage training of epoch 49: loss -5.53642 acc 0.66667 roc_auc 0.41910 prc_auc 0.59740[0m
[93maverage test of epoch 49: loss -5.54654 acc 0.65789 roc_auc 0.80308 prc_auc 0.88804[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss 0.26668 acc 0.33333 roc_auc 0.36460 prc_auc 0.60265[0m
[93maverage test of epoch 0: loss 0.21086 acc 0.34211 roc_auc 0.31538 prc_auc 0.66912[0m
[92maverage training of epoch 1: loss 0.16490 acc 0.34667 roc_auc 0.38760 prc_auc 0.62140[0m
[93maverage test of epoch 1: loss 0.11395 acc 0.34211 roc_auc 0.43385 prc_auc 0.73884[0m
[92maverage training of epoch 2: loss 0.06750 acc 0.46667 roc_auc 0.41400 prc_auc 0.63869[0m
[93maverage test of epoch 2: loss 0.02059 acc 0.63158 roc_auc 0.56923 prc_auc 0.82126[0m
[92maverage training of epoch 3: loss -0.02669 acc 0.66000 roc_auc 0.43840 prc_auc 0.66107[0m
[93maverage test of epoch 3: loss -0.07017 acc 0.65789 roc_auc 0.65231 prc_auc 0.85938[0m
[92maverage training of epoch 4: loss -0.11873 acc 0.66000 roc_auc 0.47100 prc_auc 0.68596[0m
[93maverage test of epoch 4: loss -0.15945 acc 0.65789 roc_auc 0.74154 prc_auc 0.89821[0m
[92maverage training of epoch 5: loss -0.20985 acc 0.66667 roc_auc 0.50080 prc_auc 0.71674[0m
[93maverage test of epoch 5: loss -0.24861 acc 0.65789 roc_auc 0.78769 prc_auc 0.91737[0m
[92maverage training of epoch 6: loss -0.30161 acc 0.66667 roc_auc 0.52140 prc_auc 0.73257[0m
[93maverage test of epoch 6: loss -0.33959 acc 0.65789 roc_auc 0.82615 prc_auc 0.93279[0m
[92maverage training of epoch 7: loss -0.39664 acc 0.66667 roc_auc 0.54320 prc_auc 0.75209[0m
[93maverage test of epoch 7: loss -0.43606 acc 0.65789 roc_auc 0.92308 prc_auc 0.96774[0m
[92maverage training of epoch 8: loss -0.50011 acc 0.66667 roc_auc 0.55300 prc_auc 0.75890[0m
[93maverage test of epoch 8: loss -0.54489 acc 0.65789 roc_auc 0.95385 prc_auc 0.98035[0m
[92maverage training of epoch 9: loss -0.62036 acc 0.66667 roc_auc 0.55620 prc_auc 0.76092[0m
[93maverage test of epoch 9: loss -0.67541 acc 0.65789 roc_auc 0.95538 prc_auc 0.98035[0m
[92maverage training of epoch 10: loss -0.76582 acc 0.66667 roc_auc 0.55740 prc_auc 0.76256[0m
[93maverage test of epoch 10: loss -0.83389 acc 0.65789 roc_auc 0.95385 prc_auc 0.97950[0m
[92maverage training of epoch 11: loss -0.93752 acc 0.66667 roc_auc 0.56240 prc_auc 0.76677[0m
[93maverage test of epoch 11: loss -1.01492 acc 0.65789 roc_auc 0.95385 prc_auc 0.97950[0m
[92maverage training of epoch 12: loss -1.12415 acc 0.66667 roc_auc 0.57260 prc_auc 0.77339[0m
[93maverage test of epoch 12: loss -1.20287 acc 0.65789 roc_auc 0.95385 prc_auc 0.97950[0m
[92maverage training of epoch 13: loss -1.31151 acc 0.66667 roc_auc 0.58780 prc_auc 0.78429[0m
[93maverage test of epoch 13: loss -1.38647 acc 0.65789 roc_auc 0.95385 prc_auc 0.97950[0m
[92maverage training of epoch 14: loss -1.49147 acc 0.66667 roc_auc 0.60180 prc_auc 0.79452[0m
[93maverage test of epoch 14: loss -1.55959 acc 0.65789 roc_auc 0.95385 prc_auc 0.97950[0m
[92maverage training of epoch 15: loss -1.65916 acc 0.66667 roc_auc 0.61120 prc_auc 0.79780[0m
[93maverage test of epoch 15: loss -1.71917 acc 0.65789 roc_auc 0.95385 prc_auc 0.97950[0m
[92maverage training of epoch 16: loss -1.81518 acc 0.66667 roc_auc 0.59540 prc_auc 0.77713[0m
[93maverage test of epoch 16: loss -1.86943 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 17: loss -1.96478 acc 0.66667 roc_auc 0.55840 prc_auc 0.74430[0m
[93maverage test of epoch 17: loss -2.01589 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 18: loss -2.11215 acc 0.66667 roc_auc 0.53760 prc_auc 0.72698[0m
[93maverage test of epoch 18: loss -2.16155 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 19: loss -2.25897 acc 0.66667 roc_auc 0.53620 prc_auc 0.72588[0m
[93maverage test of epoch 19: loss -2.30662 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 20: loss -2.40366 acc 0.66667 roc_auc 0.54280 prc_auc 0.73330[0m
[93maverage test of epoch 20: loss -2.44785 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 21: loss -2.54197 acc 0.66667 roc_auc 0.55500 prc_auc 0.74666[0m
[93maverage test of epoch 21: loss -2.58048 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 22: loss -2.66972 acc 0.66667 roc_auc 0.57960 prc_auc 0.76549[0m
[93maverage test of epoch 22: loss -2.70128 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 23: loss -2.78508 acc 0.66667 roc_auc 0.60650 prc_auc 0.79037[0m
[93maverage test of epoch 23: loss -2.80972 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 24: loss -2.88860 acc 0.66667 roc_auc 0.62480 prc_auc 0.80493[0m
[93maverage test of epoch 24: loss -2.90716 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 25: loss -2.98228 acc 0.66667 roc_auc 0.63900 prc_auc 0.81307[0m
[93maverage test of epoch 25: loss -2.99603 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 26: loss -3.06864 acc 0.66667 roc_auc 0.64680 prc_auc 0.81493[0m
[93maverage test of epoch 26: loss -3.07880 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 27: loss -3.14981 acc 0.66667 roc_auc 0.64780 prc_auc 0.81254[0m
[93maverage test of epoch 27: loss -3.15727 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 28: loss -3.22725 acc 0.66667 roc_auc 0.64800 prc_auc 0.81109[0m
[93maverage test of epoch 28: loss -3.23262 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 29: loss -3.30190 acc 0.66667 roc_auc 0.64370 prc_auc 0.80373[0m
[93maverage test of epoch 29: loss -3.30558 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 30: loss -3.37438 acc 0.66667 roc_auc 0.63760 prc_auc 0.79859[0m
[93maverage test of epoch 30: loss -3.37667 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 31: loss -3.44511 acc 0.66667 roc_auc 0.62540 prc_auc 0.78820[0m
[93maverage test of epoch 31: loss -3.44622 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 32: loss -3.51437 acc 0.66667 roc_auc 0.61340 prc_auc 0.77721[0m
[93maverage test of epoch 32: loss -3.51446 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 33: loss -3.58239 acc 0.66667 roc_auc 0.60720 prc_auc 0.77301[0m
[93maverage test of epoch 33: loss -3.58159 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 34: loss -3.64934 acc 0.66667 roc_auc 0.59960 prc_auc 0.76691[0m
[93maverage test of epoch 34: loss -3.64773 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 35: loss -3.71534 acc 0.66667 roc_auc 0.58920 prc_auc 0.75974[0m
[93maverage test of epoch 35: loss -3.71302 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 36: loss -3.78050 acc 0.66667 roc_auc 0.58060 prc_auc 0.75372[0m
[93maverage test of epoch 36: loss -3.77752 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 37: loss -3.84490 acc 0.66667 roc_auc 0.57290 prc_auc 0.74727[0m
[93maverage test of epoch 37: loss -3.84134 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 38: loss -3.90863 acc 0.66667 roc_auc 0.56390 prc_auc 0.74131[0m
[93maverage test of epoch 38: loss -3.90452 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 39: loss -3.97174 acc 0.66667 roc_auc 0.55100 prc_auc 0.73154[0m
[93maverage test of epoch 39: loss -3.96713 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 40: loss -4.03428 acc 0.66667 roc_auc 0.54040 prc_auc 0.72337[0m
[93maverage test of epoch 40: loss -4.02921 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 41: loss -4.09632 acc 0.66667 roc_auc 0.53070 prc_auc 0.71582[0m
[93maverage test of epoch 41: loss -4.09081 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 42: loss -4.15788 acc 0.66667 roc_auc 0.52340 prc_auc 0.71126[0m
[93maverage test of epoch 42: loss -4.15196 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 43: loss -4.21900 acc 0.66667 roc_auc 0.51740 prc_auc 0.70701[0m
[93maverage test of epoch 43: loss -4.21270 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 44: loss -4.27972 acc 0.66667 roc_auc 0.51240 prc_auc 0.70222[0m
[93maverage test of epoch 44: loss -4.27305 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 45: loss -4.34006 acc 0.66667 roc_auc 0.50350 prc_auc 0.69472[0m
[93maverage test of epoch 45: loss -4.33305 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 46: loss -4.40006 acc 0.66667 roc_auc 0.49140 prc_auc 0.68315[0m
[93maverage test of epoch 46: loss -4.39272 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 47: loss -4.45973 acc 0.66667 roc_auc 0.47940 prc_auc 0.67317[0m
[93maverage test of epoch 47: loss -4.45208 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 48: loss -4.51910 acc 0.66667 roc_auc 0.47030 prc_auc 0.66730[0m
[93maverage test of epoch 48: loss -4.51115 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 49: loss -4.57819 acc 0.66667 roc_auc 0.46320 prc_auc 0.66107[0m
[93maverage test of epoch 49: loss -4.56995 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss 0.00833 acc 0.66225 roc_auc 0.39294 prc_auc 0.59731[0m
[93maverage test of epoch 0: loss -0.02080 acc 0.67568 roc_auc 0.38000 prc_auc 0.70842[0m
[92maverage training of epoch 1: loss -0.03642 acc 0.66225 roc_auc 0.43392 prc_auc 0.62702[0m
[93maverage test of epoch 1: loss -0.06532 acc 0.67568 roc_auc 0.45667 prc_auc 0.75656[0m
[92maverage training of epoch 2: loss -0.08350 acc 0.66225 roc_auc 0.48078 prc_auc 0.65977[0m
[93maverage test of epoch 2: loss -0.11234 acc 0.67568 roc_auc 0.51667 prc_auc 0.78994[0m
[92maverage training of epoch 3: loss -0.13353 acc 0.66225 roc_auc 0.54157 prc_auc 0.70460[0m
[93maverage test of epoch 3: loss -0.16216 acc 0.67568 roc_auc 0.77333 prc_auc 0.90983[0m
[92maverage training of epoch 4: loss -0.18635 acc 0.66225 roc_auc 0.60784 prc_auc 0.76280[0m
[93maverage test of epoch 4: loss -0.21415 acc 0.67568 roc_auc 0.94000 prc_auc 0.97546[0m
[92maverage training of epoch 5: loss -0.24083 acc 0.63576 roc_auc 0.67431 prc_auc 0.82786[0m
[93maverage test of epoch 5: loss -0.26684 acc 0.35135 roc_auc 0.93667 prc_auc 0.97474[0m
[92maverage training of epoch 6: loss -0.29520 acc 0.37086 roc_auc 0.71922 prc_auc 0.86167[0m
[93maverage test of epoch 6: loss -0.31843 acc 0.35135 roc_auc 0.91333 prc_auc 0.95998[0m
[92maverage training of epoch 7: loss -0.34786 acc 0.35762 roc_auc 0.76725 prc_auc 0.88833[0m
[93maverage test of epoch 7: loss -0.36797 acc 0.35135 roc_auc 0.90000 prc_auc 0.95106[0m
[92maverage training of epoch 8: loss -0.39866 acc 0.35099 roc_auc 0.82431 prc_auc 0.91763[0m
[93maverage test of epoch 8: loss -0.41627 acc 0.35135 roc_auc 0.88000 prc_auc 0.93792[0m
[92maverage training of epoch 9: loss -0.44929 acc 0.35099 roc_auc 0.85922 prc_auc 0.93455[0m
[93maverage test of epoch 9: loss -0.46565 acc 0.35135 roc_auc 0.87333 prc_auc 0.93363[0m
[92maverage training of epoch 10: loss -0.50237 acc 0.35099 roc_auc 0.87098 prc_auc 0.94003[0m
[93maverage test of epoch 10: loss -0.51879 acc 0.35135 roc_auc 0.87333 prc_auc 0.93363[0m
[92maverage training of epoch 11: loss -0.56017 acc 0.35099 roc_auc 0.87216 prc_auc 0.94041[0m
[93maverage test of epoch 11: loss -0.57749 acc 0.35135 roc_auc 0.87000 prc_auc 0.92999[0m
[92maverage training of epoch 12: loss -0.62316 acc 0.35099 roc_auc 0.87176 prc_auc 0.94016[0m
[93maverage test of epoch 12: loss -0.64143 acc 0.35135 roc_auc 0.86667 prc_auc 0.92766[0m
[92maverage training of epoch 13: loss -0.68951 acc 0.35099 roc_auc 0.87216 prc_auc 0.94093[0m
[93maverage test of epoch 13: loss -0.70846 acc 0.35135 roc_auc 0.87000 prc_auc 0.93129[0m
[92maverage training of epoch 14: loss -0.75679 acc 0.35099 roc_auc 0.86902 prc_auc 0.94009[0m
[93maverage test of epoch 14: loss -0.77686 acc 0.35135 roc_auc 0.88000 prc_auc 0.93687[0m
[92maverage training of epoch 15: loss -0.82383 acc 0.35099 roc_auc 0.86294 prc_auc 0.93862[0m
[93maverage test of epoch 15: loss -0.84502 acc 0.35135 roc_auc 0.88333 prc_auc 0.93896[0m
[92maverage training of epoch 16: loss -0.89172 acc 0.35099 roc_auc 0.82255 prc_auc 0.91978[0m
[93maverage test of epoch 16: loss -0.91422 acc 0.35135 roc_auc 0.87333 prc_auc 0.93612[0m
[92maverage training of epoch 17: loss -0.96222 acc 0.34437 roc_auc 0.73137 prc_auc 0.87464[0m
[93maverage test of epoch 17: loss -0.98479 acc 0.32432 roc_auc 0.87333 prc_auc 0.93612[0m
[92maverage training of epoch 18: loss -1.03245 acc 0.33775 roc_auc 0.65667 prc_auc 0.83469[0m
[93maverage test of epoch 18: loss -1.05378 acc 0.32432 roc_auc 0.86667 prc_auc 0.93424[0m
[92maverage training of epoch 19: loss -1.10088 acc 0.33775 roc_auc 0.59451 prc_auc 0.79211[0m
[93maverage test of epoch 19: loss -1.12143 acc 0.32432 roc_auc 0.86000 prc_auc 0.92548[0m
[92maverage training of epoch 20: loss -1.16831 acc 0.33775 roc_auc 0.54373 prc_auc 0.75504[0m
[93maverage test of epoch 20: loss -1.18864 acc 0.32432 roc_auc 0.86333 prc_auc 0.92515[0m
[92maverage training of epoch 21: loss -1.23557 acc 0.33775 roc_auc 0.50824 prc_auc 0.72679[0m
[93maverage test of epoch 21: loss -1.25607 acc 0.32432 roc_auc 0.85667 prc_auc 0.91456[0m
[92maverage training of epoch 22: loss -1.30320 acc 0.33775 roc_auc 0.48725 prc_auc 0.70606[0m
[93maverage test of epoch 22: loss -1.32408 acc 0.32432 roc_auc 0.84000 prc_auc 0.89913[0m
[92maverage training of epoch 23: loss -1.37137 acc 0.33775 roc_auc 0.47569 prc_auc 0.69508[0m
[93maverage test of epoch 23: loss -1.39263 acc 0.32432 roc_auc 0.83000 prc_auc 0.89540[0m
[92maverage training of epoch 24: loss -1.43994 acc 0.33775 roc_auc 0.46373 prc_auc 0.68521[0m
[93maverage test of epoch 24: loss -1.46146 acc 0.32432 roc_auc 0.83000 prc_auc 0.89445[0m
[92maverage training of epoch 25: loss -1.50857 acc 0.33775 roc_auc 0.45078 prc_auc 0.67116[0m
[93maverage test of epoch 25: loss -1.53018 acc 0.32432 roc_auc 0.83000 prc_auc 0.89406[0m
[92maverage training of epoch 26: loss -1.57692 acc 0.33775 roc_auc 0.44137 prc_auc 0.65668[0m
[93maverage test of epoch 26: loss -1.59849 acc 0.32432 roc_auc 0.83333 prc_auc 0.89528[0m
[92maverage training of epoch 27: loss -1.64472 acc 0.33775 roc_auc 0.43255 prc_auc 0.64749[0m
[93maverage test of epoch 27: loss -1.66618 acc 0.32432 roc_auc 0.83333 prc_auc 0.89528[0m
[92maverage training of epoch 28: loss -1.71184 acc 0.33775 roc_auc 0.42686 prc_auc 0.64398[0m
[93maverage test of epoch 28: loss -1.73313 acc 0.32432 roc_auc 0.83500 prc_auc 0.89528[0m
[92maverage training of epoch 29: loss -1.77819 acc 0.33775 roc_auc 0.41794 prc_auc 0.63099[0m
[93maverage test of epoch 29: loss -1.79933 acc 0.32432 roc_auc 0.83667 prc_auc 0.89631[0m
[92maverage training of epoch 30: loss -1.84378 acc 0.33775 roc_auc 0.40627 prc_auc 0.62030[0m
[93maverage test of epoch 30: loss -1.86476 acc 0.32432 roc_auc 0.83500 prc_auc 0.89528[0m
[92maverage training of epoch 31: loss -1.90860 acc 0.33775 roc_auc 0.40294 prc_auc 0.61692[0m
[93maverage test of epoch 31: loss -1.92945 acc 0.32432 roc_auc 0.83000 prc_auc 0.89431[0m
[92maverage training of epoch 32: loss -1.97271 acc 0.33775 roc_auc 0.39961 prc_auc 0.61424[0m
[93maverage test of epoch 32: loss -1.99343 acc 0.32432 roc_auc 0.83000 prc_auc 0.89431[0m
[92maverage training of epoch 33: loss -2.03614 acc 0.33775 roc_auc 0.39549 prc_auc 0.60898[0m
[93maverage test of epoch 33: loss -2.05676 acc 0.32432 roc_auc 0.82333 prc_auc 0.89254[0m
[92maverage training of epoch 34: loss -2.09893 acc 0.33775 roc_auc 0.39176 prc_auc 0.60496[0m
[93maverage test of epoch 34: loss -2.11947 acc 0.32432 roc_auc 0.82000 prc_auc 0.89096[0m
[92maverage training of epoch 35: loss -2.16112 acc 0.33775 roc_auc 0.38941 prc_auc 0.60276[0m
[93maverage test of epoch 35: loss -2.18160 acc 0.32432 roc_auc 0.82000 prc_auc 0.89096[0m
[92maverage training of epoch 36: loss -2.22276 acc 0.33775 roc_auc 0.38784 prc_auc 0.59785[0m
[93maverage test of epoch 36: loss -2.24321 acc 0.32432 roc_auc 0.82000 prc_auc 0.89096[0m
[92maverage training of epoch 37: loss -2.28389 acc 0.33775 roc_auc 0.38314 prc_auc 0.58024[0m
[93maverage test of epoch 37: loss -2.30433 acc 0.32432 roc_auc 0.81667 prc_auc 0.88161[0m
[92maverage training of epoch 38: loss -2.34456 acc 0.33775 roc_auc 0.38098 prc_auc 0.57777[0m
[93maverage test of epoch 38: loss -2.36499 acc 0.32432 roc_auc 0.77833 prc_auc 0.86663[0m
[92maverage training of epoch 39: loss -2.40479 acc 0.33775 roc_auc 0.37882 prc_auc 0.57520[0m
[93maverage test of epoch 39: loss -2.42524 acc 0.32432 roc_auc 0.78000 prc_auc 0.86840[0m
[92maverage training of epoch 40: loss -2.46463 acc 0.33775 roc_auc 0.37765 prc_auc 0.57467[0m
[93maverage test of epoch 40: loss -2.48511 acc 0.32432 roc_auc 0.78000 prc_auc 0.87577[0m
[92maverage training of epoch 41: loss -2.52410 acc 0.33775 roc_auc 0.37627 prc_auc 0.57279[0m
[93maverage test of epoch 41: loss -2.54463 acc 0.32432 roc_auc 0.78333 prc_auc 0.87701[0m
[92maverage training of epoch 42: loss -2.58324 acc 0.33775 roc_auc 0.37431 prc_auc 0.57018[0m
[93maverage test of epoch 42: loss -2.60384 acc 0.32432 roc_auc 0.79333 prc_auc 0.87936[0m
[92maverage training of epoch 43: loss -2.64207 acc 0.33775 roc_auc 0.37373 prc_auc 0.56920[0m
[93maverage test of epoch 43: loss -2.66274 acc 0.32432 roc_auc 0.79333 prc_auc 0.88003[0m
[92maverage training of epoch 44: loss -2.70062 acc 0.33775 roc_auc 0.37275 prc_auc 0.56719[0m
[93maverage test of epoch 44: loss -2.72138 acc 0.32432 roc_auc 0.79000 prc_auc 0.87005[0m
[92maverage training of epoch 45: loss -2.75891 acc 0.33775 roc_auc 0.37216 prc_auc 0.56709[0m
[93maverage test of epoch 45: loss -2.77977 acc 0.32432 roc_auc 0.79333 prc_auc 0.87263[0m
[92maverage training of epoch 46: loss -2.81696 acc 0.33775 roc_auc 0.37176 prc_auc 0.56671[0m
[93maverage test of epoch 46: loss -2.83794 acc 0.32432 roc_auc 0.79500 prc_auc 0.87494[0m
[92maverage training of epoch 47: loss -2.87480 acc 0.33775 roc_auc 0.37196 prc_auc 0.56641[0m
[93maverage test of epoch 47: loss -2.89590 acc 0.32432 roc_auc 0.79833 prc_auc 0.87567[0m
[92maverage training of epoch 48: loss -2.93244 acc 0.33775 roc_auc 0.37196 prc_auc 0.56624[0m
[93maverage test of epoch 48: loss -2.95367 acc 0.32432 roc_auc 0.78667 prc_auc 0.86151[0m
[92maverage training of epoch 49: loss -2.98989 acc 0.33775 roc_auc 0.37196 prc_auc 0.56633[0m
[93maverage test of epoch 49: loss -3.01126 acc 0.32432 roc_auc 0.80167 prc_auc 0.87481[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.54660 acc 0.66225 roc_auc 0.45608 prc_auc 0.67351[0m
[93maverage test of epoch 0: loss -0.58690 acc 0.67568 roc_auc 0.92333 prc_auc 0.96958[0m
[92maverage training of epoch 1: loss -0.62151 acc 0.66225 roc_auc 0.47686 prc_auc 0.69390[0m
[93maverage test of epoch 1: loss -0.66217 acc 0.67568 roc_auc 0.92333 prc_auc 0.96958[0m
[92maverage training of epoch 2: loss -0.69621 acc 0.66225 roc_auc 0.50020 prc_auc 0.71474[0m
[93maverage test of epoch 2: loss -0.73730 acc 0.67568 roc_auc 0.92333 prc_auc 0.96958[0m
[92maverage training of epoch 3: loss -0.77061 acc 0.66225 roc_auc 0.51863 prc_auc 0.73395[0m
[93maverage test of epoch 3: loss -0.81210 acc 0.67568 roc_auc 0.92333 prc_auc 0.96958[0m
[92maverage training of epoch 4: loss -0.84460 acc 0.66225 roc_auc 0.53118 prc_auc 0.74217[0m
[93maverage test of epoch 4: loss -0.88650 acc 0.67568 roc_auc 0.92667 prc_auc 0.97089[0m
[92maverage training of epoch 5: loss -0.91815 acc 0.66225 roc_auc 0.54118 prc_auc 0.74985[0m
[93maverage test of epoch 5: loss -0.96051 acc 0.67568 roc_auc 0.92667 prc_auc 0.97089[0m
[92maverage training of epoch 6: loss -0.99131 acc 0.66225 roc_auc 0.54490 prc_auc 0.75329[0m
[93maverage test of epoch 6: loss -1.03418 acc 0.67568 roc_auc 0.92667 prc_auc 0.97089[0m
[92maverage training of epoch 7: loss -1.06413 acc 0.66225 roc_auc 0.54686 prc_auc 0.75428[0mUsing backend: pytorch
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))

[93maverage test of epoch 7: loss -1.10758 acc 0.67568 roc_auc 0.92667 prc_auc 0.97089[0m
[92maverage training of epoch 8: loss -1.13665 acc 0.66225 roc_auc 0.55275 prc_auc 0.76000[0m
[93maverage test of epoch 8: loss -1.18075 acc 0.67568 roc_auc 0.92667 prc_auc 0.97089[0m
[92maverage training of epoch 9: loss -1.20892 acc 0.66225 roc_auc 0.55804 prc_auc 0.76321[0m
[93maverage test of epoch 9: loss -1.25372 acc 0.67568 roc_auc 0.92667 prc_auc 0.97089[0m
[92maverage training of epoch 10: loss -1.28098 acc 0.66225 roc_auc 0.56608 prc_auc 0.76882[0m
[93maverage test of epoch 10: loss -1.32654 acc 0.67568 roc_auc 0.92333 prc_auc 0.96958[0m
[92maverage training of epoch 11: loss -1.35283 acc 0.66225 roc_auc 0.57431 prc_auc 0.77609[0m
[93maverage test of epoch 11: loss -1.39919 acc 0.67568 roc_auc 0.92333 prc_auc 0.96958[0m
[92maverage training of epoch 12: loss -1.42447 acc 0.66225 roc_auc 0.58529 prc_auc 0.78610[0m
[93maverage test of epoch 12: loss -1.47168 acc 0.67568 roc_auc 0.92333 prc_auc 0.96958[0m
[92maverage training of epoch 13: loss -1.49588 acc 0.66225 roc_auc 0.59490 prc_auc 0.79416[0m
[93maverage test of epoch 13: loss -1.54396 acc 0.67568 roc_auc 0.92667 prc_auc 0.97104[0m
[92maverage training of epoch 14: loss -1.56702 acc 0.66225 roc_auc 0.60392 prc_auc 0.79928[0m
[93maverage test of epoch 14: loss -1.61593 acc 0.67568 roc_auc 0.92667 prc_auc 0.97104[0m
[92maverage training of epoch 15: loss -1.63783 acc 0.66225 roc_auc 0.61706 prc_auc 0.80693[0m
[93maverage test of epoch 15: loss -1.68752 acc 0.67568 roc_auc 0.92667 prc_auc 0.97104[0m
[92maverage training of epoch 16: loss -1.70828 acc 0.66225 roc_auc 0.62000 prc_auc 0.80618[0m
[93maverage test of epoch 16: loss -1.75869 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 17: loss -1.77835 acc 0.66225 roc_auc 0.62275 prc_auc 0.80585[0m
[93maverage test of epoch 17: loss -1.82944 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 18: loss -1.84808 acc 0.66225 roc_auc 0.61922 prc_auc 0.80148[0m
[93maverage test of epoch 18: loss -1.89984 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 19: loss -1.91752 acc 0.66225 roc_auc 0.61137 prc_auc 0.79326[0m
[93maverage test of epoch 19: loss -1.96995 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 20: loss -1.98672 acc 0.66225 roc_auc 0.60529 prc_auc 0.78602[0m
[93maverage test of epoch 20: loss -2.03983 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 21: loss -2.05569 acc 0.66225 roc_auc 0.59353 prc_auc 0.77698[0m
[93maverage test of epoch 21: loss -2.10949 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 22: loss -2.12446 acc 0.66225 roc_auc 0.58020 prc_auc 0.76648[0m
[93maverage test of epoch 22: loss -2.17893 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 23: loss -2.19298 acc 0.66225 roc_auc 0.57000 prc_auc 0.75637[0m
[93maverage test of epoch 23: loss -2.24813 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 24: loss -2.26125 acc 0.66225 roc_auc 0.55627 prc_auc 0.74606[0m
[93maverage test of epoch 24: loss -2.31705 acc 0.67568 roc_auc 0.92667 prc_auc 0.97104[0m
[92maverage training of epoch 25: loss -2.32922 acc 0.66225 roc_auc 0.55000 prc_auc 0.74006[0m
[93maverage test of epoch 25: loss -2.38564 acc 0.67568 roc_auc 0.92667 prc_auc 0.97104[0m
[92maverage training of epoch 26: loss -2.39685 acc 0.66225 roc_auc 0.54255 prc_auc 0.73502[0m
[93maverage test of epoch 26: loss -2.45387 acc 0.67568 roc_auc 0.92667 prc_auc 0.97104[0m
[92maverage training of epoch 27: loss -2.46411 acc 0.66225 roc_auc 0.53490 prc_auc 0.73004[0m
[93maverage test of epoch 27: loss -2.52170 acc 0.67568 roc_auc 0.92667 prc_auc 0.97104[0m
[92maverage training of epoch 28: loss -2.53096 acc 0.66225 roc_auc 0.52706 prc_auc 0.72328[0m
[93maverage test of epoch 28: loss -2.58910 acc 0.67568 roc_auc 0.92667 prc_auc 0.97104[0m
[92maverage training of epoch 29: loss -2.59737 acc 0.66225 roc_auc 0.51941 prc_auc 0.71774[0m
[93maverage test of epoch 29: loss -2.65602 acc 0.67568 roc_auc 0.92667 prc_auc 0.97104[0m
[92maverage training of epoch 30: loss -2.66333 acc 0.66225 roc_auc 0.51333 prc_auc 0.71214[0m
[93maverage test of epoch 30: loss -2.72246 acc 0.67568 roc_auc 0.92833 prc_auc 0.97104[0m
[92maverage training of epoch 31: loss -2.72880 acc 0.66225 roc_auc 0.50490 prc_auc 0.70582[0m
[93maverage test of epoch 31: loss -2.78839 acc 0.67568 roc_auc 0.93000 prc_auc 0.97235[0m
[92maverage training of epoch 32: loss -2.79378 acc 0.66225 roc_auc 0.49627 prc_auc 0.69745[0m
[93maverage test of epoch 32: loss -2.85380 acc 0.67568 roc_auc 0.93167 prc_auc 0.97235[0m
[92maverage training of epoch 33: loss -2.85827 acc 0.66225 roc_auc 0.48882 prc_auc 0.69110[0m
[93maverage test of epoch 33: loss -2.91870 acc 0.67568 roc_auc 0.93333 prc_auc 0.97377[0m
[92maverage training of epoch 34: loss -2.92227 acc 0.66225 roc_auc 0.48490 prc_auc 0.68557[0m
[93maverage test of epoch 34: loss -2.98308 acc 0.67568 roc_auc 0.93333 prc_auc 0.97390[0m
[92maverage training of epoch 35: loss -2.98577 acc 0.66225 roc_auc 0.48020 prc_auc 0.68244[0m
[93maverage test of epoch 35: loss -3.04695 acc 0.67568 roc_auc 0.93333 prc_auc 0.97377[0m
[92maverage training of epoch 36: loss -3.04879 acc 0.66225 roc_auc 0.47314 prc_auc 0.67633[0m
[93maverage test of epoch 36: loss -3.11032 acc 0.67568 roc_auc 0.93333 prc_auc 0.97390[0m
[92maverage training of epoch 37: loss -3.11134 acc 0.66225 roc_auc 0.46863 prc_auc 0.67292[0m
[93maverage test of epoch 37: loss -3.17320 acc 0.67568 roc_auc 0.93333 prc_auc 0.97377[0m
[92maverage training of epoch 38: loss -3.17344 acc 0.66225 roc_auc 0.46275 prc_auc 0.66719[0m
[93maverage test of epoch 38: loss -3.23562 acc 0.67568 roc_auc 0.93333 prc_auc 0.97377[0m
[92maverage training of epoch 39: loss -3.23510 acc 0.66225 roc_auc 0.45333 prc_auc 0.65822[0m
[93maverage test of epoch 39: loss -3.29758 acc 0.67568 roc_auc 0.93167 prc_auc 0.97235[0m
[92maverage training of epoch 40: loss -3.29634 acc 0.66225 roc_auc 0.44676 prc_auc 0.65216[0m
[93maverage test of epoch 40: loss -3.35912 acc 0.67568 roc_auc 0.93000 prc_auc 0.97104[0m
[92maverage training of epoch 41: loss -3.35718 acc 0.66225 roc_auc 0.44157 prc_auc 0.64862[0m
[93maverage test of epoch 41: loss -3.42025 acc 0.67568 roc_auc 0.93333 prc_auc 0.97377[0m
[92maverage training of epoch 42: loss -3.41765 acc 0.66225 roc_auc 0.43706 prc_auc 0.64451[0m
[93maverage test of epoch 42: loss -3.48100 acc 0.67568 roc_auc 0.93500 prc_auc 0.97377[0m
[92maverage training of epoch 43: loss -3.47776 acc 0.66225 roc_auc 0.43069 prc_auc 0.64058[0m
[93maverage test of epoch 43: loss -3.54138 acc 0.67568 roc_auc 0.93167 prc_auc 0.97104[0m
[92maverage training of epoch 44: loss -3.53753 acc 0.66225 roc_auc 0.42824 prc_auc 0.63994[0m
[93maverage test of epoch 44: loss -3.60141 acc 0.67568 roc_auc 0.93333 prc_auc 0.97264[0m
[92maverage training of epoch 45: loss -3.59698 acc 0.66225 roc_auc 0.42353 prc_auc 0.63781[0m
[93maverage test of epoch 45: loss -3.66113 acc 0.67568 roc_auc 0.93167 prc_auc 0.97104[0m
[92maverage training of epoch 46: loss -3.65613 acc 0.66225 roc_auc 0.42118 prc_auc 0.63855[0m
[93maverage test of epoch 46: loss -3.72054 acc 0.67568 roc_auc 0.93333 prc_auc 0.97264[0m
[92maverage training of epoch 47: loss -3.71501 acc 0.66225 roc_auc 0.41745 prc_auc 0.63600[0m
[93maverage test of epoch 47: loss -3.77968 acc 0.67568 roc_auc 0.93333 prc_auc 0.97264[0m
[92maverage training of epoch 48: loss -3.77364 acc 0.66225 roc_auc 0.41373 prc_auc 0.63427[0m
[93maverage test of epoch 48: loss -3.83855 acc 0.67568 roc_auc 0.93167 prc_auc 0.97104[0m
[92maverage training of epoch 49: loss -3.83202 acc 0.66225 roc_auc 0.41147 prc_auc 0.63389[0m
[93maverage test of epoch 49: loss -3.89718 acc 0.67568 roc_auc 0.93500 prc_auc 0.97264[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.0001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.63158 ROC_AUC (avg): 0.87964 PRC_AUC (avg): 0.935 

Average forward propagation time taken(ms): 2.4668410886903076
Average backward propagation time taken(ms): 0.8696804758863603

