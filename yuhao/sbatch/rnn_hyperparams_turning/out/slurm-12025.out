# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.0001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-09-11-46/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-09-11-46/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 16,
 'epochs': 100,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 4,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.0001,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 2,
 'num_workers': 8,
 'number_of_mlp_layer': 0,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-18-09-11-46',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 100, 'learning_rate': 0.0001, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss 0.59812 acc 0.66667 roc_auc 0.43800 prc_auc 0.64402[0m
[93maverage test of epoch 0: loss 0.52005 acc 0.65789 roc_auc 0.62154 prc_auc 0.77261[0m
[92maverage training of epoch 1: loss 0.43190 acc 0.66667 roc_auc 0.48640 prc_auc 0.68572[0m
[93maverage test of epoch 1: loss 0.35553 acc 0.65789 roc_auc 0.66462 prc_auc 0.79829[0m
[92maverage training of epoch 2: loss 0.27202 acc 0.66667 roc_auc 0.45760 prc_auc 0.68884[0m
[93maverage test of epoch 2: loss 0.19358 acc 0.65789 roc_auc 0.67385 prc_auc 0.82352[0m
[92maverage training of epoch 3: loss 0.12922 acc 0.66667 roc_auc 0.52640 prc_auc 0.71953[0m
[93maverage test of epoch 3: loss 0.06923 acc 0.65789 roc_auc 0.71692 prc_auc 0.87345[0m
[92maverage training of epoch 4: loss -0.01045 acc 0.66667 roc_auc 0.53000 prc_auc 0.72297[0m
[93maverage test of epoch 4: loss -0.06605 acc 0.65789 roc_auc 0.62769 prc_auc 0.81440[0m
[92maverage training of epoch 5: loss -0.14412 acc 0.66667 roc_auc 0.52600 prc_auc 0.73402[0m
[93maverage test of epoch 5: loss -0.19567 acc 0.65789 roc_auc 0.53231 prc_auc 0.75327[0m
[92maverage training of epoch 6: loss -0.27123 acc 0.66667 roc_auc 0.52740 prc_auc 0.69574[0m
[93maverage test of epoch 6: loss -0.33900 acc 0.65789 roc_auc 0.60923 prc_auc 0.79653[0m
[92maverage training of epoch 7: loss -0.42223 acc 0.66667 roc_auc 0.47880 prc_auc 0.67925[0m
[93maverage test of epoch 7: loss -0.51354 acc 0.65789 roc_auc 0.50769 prc_auc 0.71870[0m
[92maverage training of epoch 8: loss -0.60677 acc 0.66667 roc_auc 0.52220 prc_auc 0.71440[0m
[93maverage test of epoch 8: loss -0.70116 acc 0.65789 roc_auc 0.64923 prc_auc 0.79333[0m
[92maverage training of epoch 9: loss -0.78905 acc 0.66667 roc_auc 0.50580 prc_auc 0.67985[0m
[93maverage test of epoch 9: loss -0.88062 acc 0.65789 roc_auc 0.57538 prc_auc 0.74395[0m
[92maverage training of epoch 10: loss -0.97016 acc 0.66667 roc_auc 0.51140 prc_auc 0.67992[0m
[93maverage test of epoch 10: loss -1.05027 acc 0.65789 roc_auc 0.72308 prc_auc 0.86304[0m
[92maverage training of epoch 11: loss -1.12184 acc 0.66667 roc_auc 0.45080 prc_auc 0.65594[0m
[93maverage test of epoch 11: loss -1.24633 acc 0.65789 roc_auc 0.68615 prc_auc 0.80958[0m
[92maverage training of epoch 12: loss -1.28245 acc 0.66667 roc_auc 0.51620 prc_auc 0.71370[0m
[93maverage test of epoch 12: loss -1.35444 acc 0.65789 roc_auc 0.55385 prc_auc 0.73434[0m
[92maverage training of epoch 13: loss -1.43692 acc 0.66667 roc_auc 0.43380 prc_auc 0.61919[0m
[93maverage test of epoch 13: loss -1.53072 acc 0.65789 roc_auc 0.53538 prc_auc 0.75152[0m
[92maverage training of epoch 14: loss -1.59748 acc 0.66667 roc_auc 0.56380 prc_auc 0.70535[0m
[93maverage test of epoch 14: loss -1.62068 acc 0.65789 roc_auc 0.38462 prc_auc 0.59435[0m
[92maverage training of epoch 15: loss -1.74297 acc 0.66667 roc_auc 0.51940 prc_auc 0.65868[0m
[93maverage test of epoch 15: loss -1.80322 acc 0.65789 roc_auc 0.35692 prc_auc 0.59339[0m
[92maverage training of epoch 16: loss -1.87676 acc 0.66667 roc_auc 0.51200 prc_auc 0.69717[0m
[93maverage test of epoch 16: loss -1.91591 acc 0.65789 roc_auc 0.69538 prc_auc 0.84704[0m
[92maverage training of epoch 17: loss -2.00689 acc 0.66667 roc_auc 0.51940 prc_auc 0.69636[0m
[93maverage test of epoch 17: loss -2.02186 acc 0.65789 roc_auc 0.56308 prc_auc 0.69589[0m
[92maverage training of epoch 18: loss -2.10925 acc 0.66667 roc_auc 0.45720 prc_auc 0.64085[0m
[93maverage test of epoch 18: loss -2.13470 acc 0.65789 roc_auc 0.54154 prc_auc 0.71414[0m
[92maverage training of epoch 19: loss -2.19100 acc 0.66667 roc_auc 0.43560 prc_auc 0.63022[0m
[93maverage test of epoch 19: loss -2.23611 acc 0.65789 roc_auc 0.56308 prc_auc 0.74233[0m
[92maverage training of epoch 20: loss -2.31480 acc 0.66667 roc_auc 0.57940 prc_auc 0.74675[0m
[93maverage test of epoch 20: loss -2.32992 acc 0.65789 roc_auc 0.50154 prc_auc 0.73341[0m
[92maverage training of epoch 21: loss -2.38500 acc 0.66667 roc_auc 0.42100 prc_auc 0.65486[0m
[93maverage test of epoch 21: loss -2.40940 acc 0.65789 roc_auc 0.52000 prc_auc 0.70948[0m
[92maverage training of epoch 22: loss -2.45845 acc 0.66667 roc_auc 0.46870 prc_auc 0.64389[0m
[93maverage test of epoch 22: loss -2.47980 acc 0.65789 roc_auc 0.49231 prc_auc 0.69555[0m
[92maverage training of epoch 23: loss -2.54454 acc 0.66667 roc_auc 0.50740 prc_auc 0.68404[0m
[93maverage test of epoch 23: loss -2.54869 acc 0.65789 roc_auc 0.39692 prc_auc 0.64151[0m
[92maverage training of epoch 24: loss -2.61152 acc 0.66667 roc_auc 0.47580 prc_auc 0.63088[0m
[93maverage test of epoch 24: loss -2.62795 acc 0.65789 roc_auc 0.50769 prc_auc 0.65928[0m
[92maverage training of epoch 25: loss -2.68641 acc 0.66667 roc_auc 0.50540 prc_auc 0.65281[0m
[93maverage test of epoch 25: loss -2.68022 acc 0.65789 roc_auc 0.52615 prc_auc 0.73082[0m
[92maverage training of epoch 26: loss -2.73834 acc 0.66667 roc_auc 0.43160 prc_auc 0.61216[0m
[93maverage test of epoch 26: loss -2.75217 acc 0.65789 roc_auc 0.45231 prc_auc 0.63693[0m
[92maverage training of epoch 27: loss -2.81991 acc 0.66667 roc_auc 0.47820 prc_auc 0.64310[0m
[93maverage test of epoch 27: loss -2.81810 acc 0.65789 roc_auc 0.47385 prc_auc 0.65849[0m
[92maverage training of epoch 28: loss -2.88598 acc 0.66667 roc_auc 0.51840 prc_auc 0.64341[0m
[93maverage test of epoch 28: loss -2.88096 acc 0.65789 roc_auc 0.36308 prc_auc 0.58109[0m
[92maverage training of epoch 29: loss -2.94665 acc 0.66667 roc_auc 0.51640 prc_auc 0.69356[0m
[93maverage test of epoch 29: loss -2.94670 acc 0.65789 roc_auc 0.43077 prc_auc 0.67722[0m
[92maverage training of epoch 30: loss -3.00530 acc 0.66667 roc_auc 0.51020 prc_auc 0.67670[0m
[93maverage test of epoch 30: loss -3.03648 acc 0.65789 roc_auc 0.71385 prc_auc 0.79590[0m
[92maverage training of epoch 31: loss -3.06341 acc 0.66667 roc_auc 0.44820 prc_auc 0.65459[0m
[93maverage test of epoch 31: loss -3.07921 acc 0.65789 roc_auc 0.56615 prc_auc 0.70082[0m
[92maverage training of epoch 32: loss -3.13599 acc 0.66667 roc_auc 0.53640 prc_auc 0.71024[0m
[93maverage test of epoch 32: loss -3.13200 acc 0.65789 roc_auc 0.50462 prc_auc 0.70479[0m
[92maverage training of epoch 33: loss -3.19703 acc 0.66667 roc_auc 0.52940 prc_auc 0.67267[0m
[93maverage test of epoch 33: loss -3.18508 acc 0.65789 roc_auc 0.54154 prc_auc 0.69496[0m
[92maverage training of epoch 34: loss -3.25279 acc 0.66667 roc_auc 0.47080 prc_auc 0.65571[0m
[93maverage test of epoch 34: loss -3.26332 acc 0.65789 roc_auc 0.45846 prc_auc 0.62162[0m
[92maverage training of epoch 35: loss -3.30766 acc 0.66667 roc_auc 0.45140 prc_auc 0.64945[0m
[93maverage test of epoch 35: loss -3.30427 acc 0.65789 roc_auc 0.32615 prc_auc 0.59598[0m
[92maverage training of epoch 36: loss -3.37986 acc 0.66667 roc_auc 0.51640 prc_auc 0.65975[0m
[93maverage test of epoch 36: loss -3.36549 acc 0.65789 roc_auc 0.55385 prc_auc 0.74186[0m
[92maverage training of epoch 37: loss -3.43702 acc 0.66667 roc_auc 0.53520 prc_auc 0.68609[0m
[93maverage test of epoch 37: loss -3.44577 acc 0.65789 roc_auc 0.65231 prc_auc 0.81701[0m
[92maverage training of epoch 38: loss -3.49895 acc 0.66667 roc_auc 0.42720 prc_auc 0.61138[0m
[93maverage test of epoch 38: loss -3.47860 acc 0.65789 roc_auc 0.39385 prc_auc 0.65141[0m
[92maverage training of epoch 39: loss -3.56127 acc 0.66667 roc_auc 0.51950 prc_auc 0.65708[0m
[93maverage test of epoch 39: loss -3.54432 acc 0.65789 roc_auc 0.39385 prc_auc 0.64303[0m
[92maverage training of epoch 40: loss -3.61781 acc 0.66667 roc_auc 0.54740 prc_auc 0.69278[0m
[93maverage test of epoch 40: loss -3.61604 acc 0.65789 roc_auc 0.58154 prc_auc 0.74794[0m
[92maverage training of epoch 41: loss -3.68040 acc 0.66667 roc_auc 0.50990 prc_auc 0.66081[0m
[93maverage test of epoch 41: loss -3.66828 acc 0.65789 roc_auc 0.63077 prc_auc 0.81057[0m
[92maverage training of epoch 42: loss -3.73592 acc 0.66667 roc_auc 0.43070 prc_auc 0.64053[0m
[93maverage test of epoch 42: loss -3.73633 acc 0.65789 roc_auc 0.52615 prc_auc 0.71330[0m
[92maverage training of epoch 43: loss -3.79442 acc 0.66667 roc_auc 0.46510 prc_auc 0.63913[0m
[93maverage test of epoch 43: loss -3.80319 acc 0.65789 roc_auc 0.68308 prc_auc 0.79195[0m
[92maverage training of epoch 44: loss -3.85605 acc 0.66667 roc_auc 0.42320 prc_auc 0.59551[0m
[93maverage test of epoch 44: loss -3.85595 acc 0.65789 roc_auc 0.49846 prc_auc 0.70598[0m
[92maverage training of epoch 45: loss -3.91712 acc 0.66667 roc_auc 0.46020 prc_auc 0.63800[0m
[93maverage test of epoch 45: loss -3.90755 acc 0.65789 roc_auc 0.38462 prc_auc 0.57433[0m
[92maverage training of epoch 46: loss -3.97484 acc 0.66667 roc_auc 0.48980 prc_auc 0.63695[0m
[93maverage test of epoch 46: loss -3.96228 acc 0.65789 roc_auc 0.45846 prc_auc 0.63966[0m
[92maverage training of epoch 47: loss -4.02944 acc 0.66667 roc_auc 0.58980 prc_auc 0.70408[0m
[93maverage test of epoch 47: loss -4.02352 acc 0.65789 roc_auc 0.28000 prc_auc 0.57228[0m
[92maverage training of epoch 48: loss -4.09037 acc 0.66667 roc_auc 0.40300 prc_auc 0.61369[0m
[93maverage test of epoch 48: loss -4.08195 acc 0.65789 roc_auc 0.37538 prc_auc 0.64957[0m
[92maverage training of epoch 49: loss -4.14574 acc 0.66667 roc_auc 0.44290 prc_auc 0.62303[0m
[93maverage test of epoch 49: loss -4.14786 acc 0.65789 roc_auc 0.51077 prc_auc 0.73225[0m
[92maverage training of epoch 50: loss -4.21156 acc 0.66667 roc_auc 0.53720 prc_auc 0.65873[0m
[93maverage test of epoch 50: loss -4.21226 acc 0.65789 roc_auc 0.58462 prc_auc 0.69199[0m
[92maverage training of epoch 51: loss -4.26519 acc 0.66667 roc_auc 0.39900 prc_auc 0.58898[0m
[93maverage test of epoch 51: loss -4.25982 acc 0.65789 roc_auc 0.60308 prc_auc 0.74536[0m
[92maverage training of epoch 52: loss -4.32428 acc 0.66667 roc_auc 0.44960 prc_auc 0.60486[0m
[93maverage test of epoch 52: loss -4.32304 acc 0.65789 roc_auc 0.46769 prc_auc 0.70216[0m
[92maverage training of epoch 53: loss -4.38214 acc 0.66667 roc_auc 0.36570 prc_auc 0.59657[0m
[93maverage test of epoch 53: loss -4.38076 acc 0.65789 roc_auc 0.47077 prc_auc 0.63206[0m
[92maverage training of epoch 54: loss -4.44493 acc 0.66667 roc_auc 0.53580 prc_auc 0.67087[0m
[93maverage test of epoch 54: loss -4.43801 acc 0.65789 roc_auc 0.37077 prc_auc 0.60625[0m
[92maverage training of epoch 55: loss -4.50230 acc 0.66667 roc_auc 0.55550 prc_auc 0.69527[0m
[93maverage test of epoch 55: loss -4.49079 acc 0.65789 roc_auc 0.55077 prc_auc 0.70154[0m
[92maverage training of epoch 56: loss -4.56080 acc 0.66667 roc_auc 0.56370 prc_auc 0.70112[0m
[93maverage test of epoch 56: loss -4.55563 acc 0.65789 roc_auc 0.62154 prc_auc 0.72445[0m
[92maverage training of epoch 57: loss -4.61652 acc 0.66667 roc_auc 0.44960 prc_auc 0.60693[0m
[93maverage test of epoch 57: loss -4.61140 acc 0.65789 roc_auc 0.75077 prc_auc 0.85478[0m
[92maverage training of epoch 58: loss -4.67182 acc 0.66667 roc_auc 0.48320 prc_auc 0.65825[0m
[93maverage test of epoch 58: loss -4.67035 acc 0.65789 roc_auc 0.58615 prc_auc 0.79067[0m
[92maverage training of epoch 59: loss -4.72795 acc 0.66667 roc_auc 0.39740 prc_auc 0.60841[0m
[93maverage test of epoch 59: loss -4.72399 acc 0.65789 roc_auc 0.53385 prc_auc 0.68836[0m
[92maverage training of epoch 60: loss -4.78901 acc 0.66667 roc_auc 0.47770 prc_auc 0.66300[0m
[93maverage test of epoch 60: loss -4.78070 acc 0.65789 roc_auc 0.56000 prc_auc 0.68937[0m
[92maverage training of epoch 61: loss -4.84807 acc 0.66667 roc_auc 0.55890 prc_auc 0.67520[0m
[93maverage test of epoch 61: loss -4.84058 acc 0.65789 roc_auc 0.59538 prc_auc 0.73026[0m
[92maverage training of epoch 62: loss -4.90229 acc 0.66667 roc_auc 0.40790 prc_auc 0.60091[0m
[93maverage test of epoch 62: loss -4.89702 acc 0.65789 roc_auc 0.61538 prc_auc 0.76199[0m
[92maverage training of epoch 63: loss -4.96033 acc 0.66667 roc_auc 0.42230 prc_auc 0.61809[0m
[93maverage test of epoch 63: loss -4.94899 acc 0.65789 roc_auc 0.35231 prc_auc 0.60003[0m
[92maverage training of epoch 64: loss -5.01741 acc 0.66667 roc_auc 0.48170 prc_auc 0.63621[0m
[93maverage test of epoch 64: loss -5.01012 acc 0.65789 roc_auc 0.48308 prc_auc 0.62964[0m
[92maverage training of epoch 65: loss -5.07321 acc 0.66667 roc_auc 0.46120 prc_auc 0.61914[0m
[93maverage test of epoch 65: loss -5.06653 acc 0.65789 roc_auc 0.41846 prc_auc 0.65007[0m
[92maverage training of epoch 66: loss -5.13339 acc 0.66667 roc_auc 0.44080 prc_auc 0.63521[0m
[93maverage test of epoch 66: loss -5.12364 acc 0.65789 roc_auc 0.52154 prc_auc 0.67905[0m
[92maverage training of epoch 67: loss -5.18721 acc 0.66667 roc_auc 0.49550 prc_auc 0.65220[0m
[93maverage test of epoch 67: loss -5.17227 acc 0.65789 roc_auc 0.57846 prc_auc 0.76958[0m
[92maverage training of epoch 68: loss -5.24649 acc 0.66667 roc_auc 0.48040 prc_auc 0.62139[0m
[93maverage test of epoch 68: loss -5.24057 acc 0.65789 roc_auc 0.53385 prc_auc 0.69258[0m
[92maverage training of epoch 69: loss -5.30258 acc 0.66667 roc_auc 0.43130 prc_auc 0.60164[0m
[93maverage test of epoch 69: loss -5.29345 acc 0.65789 roc_auc 0.52769 prc_auc 0.69398[0m
[92maverage training of epoch 70: loss -5.35955 acc 0.66667 roc_auc 0.38260 prc_auc 0.59234[0m
[93maverage test of epoch 70: loss -5.34748 acc 0.65789 roc_auc 0.52769 prc_auc 0.67512[0m
[92maverage training of epoch 71: loss -5.41475 acc 0.66667 roc_auc 0.50430 prc_auc 0.66098[0m
[93maverage test of epoch 71: loss -5.40299 acc 0.65789 roc_auc 0.36462 prc_auc 0.57244[0m
[92maverage training of epoch 72: loss -5.47259 acc 0.66667 roc_auc 0.49600 prc_auc 0.66484[0m
[93maverage test of epoch 72: loss -5.46449 acc 0.65789 roc_auc 0.60923 prc_auc 0.72728[0m
[92maverage training of epoch 73: loss -5.52878 acc 0.66667 roc_auc 0.43680 prc_auc 0.60911[0m
[93maverage test of epoch 73: loss -5.51978 acc 0.65789 roc_auc 0.61385 prc_auc 0.75907[0m
[92maverage training of epoch 74: loss -5.58282 acc 0.66667 roc_auc 0.43160 prc_auc 0.61047[0m
[93maverage test of epoch 74: loss -5.57700 acc 0.65789 roc_auc 0.48462 prc_auc 0.67524[0m
[92maverage training of epoch 75: loss -5.64183 acc 0.66667 roc_auc 0.43070 prc_auc 0.60045[0m
[93maverage test of epoch 75: loss -5.63131 acc 0.65789 roc_auc 0.49538 prc_auc 0.66242[0m
[92maverage training of epoch 76: loss -5.69604 acc 0.66667 roc_auc 0.39930 prc_auc 0.59663[0m
[93maverage test of epoch 76: loss -5.68648 acc 0.65789 roc_auc 0.42154 prc_auc 0.64598[0m
[92maverage training of epoch 77: loss -5.75234 acc 0.66667 roc_auc 0.44530 prc_auc 0.64760[0m
[93maverage test of epoch 77: loss -5.73820 acc 0.65789 roc_auc 0.48308 prc_auc 0.68873[0m
[92maverage training of epoch 78: loss -5.80867 acc 0.66667 roc_auc 0.45380 prc_auc 0.61171[0m
[93maverage test of epoch 78: loss -5.79876 acc 0.65789 roc_auc 0.53538 prc_auc 0.70427[0m
[92maverage training of epoch 79: loss -5.86517 acc 0.66667 roc_auc 0.45970 prc_auc 0.62968[0m
[93maverage test of epoch 79: loss -5.85497 acc 0.65789 roc_auc 0.54000 prc_auc 0.69972[0m
[92maverage training of epoch 80: loss -5.92248 acc 0.66667 roc_auc 0.45830 prc_auc 0.62478[0m
[93maverage test of epoch 80: loss -5.91263 acc 0.65789 roc_auc 0.49846 prc_auc 0.66059[0m
[92maverage training of epoch 81: loss -5.97736 acc 0.66667 roc_auc 0.46650 prc_auc 0.64200[0m
[93maverage test of epoch 81: loss -5.96632 acc 0.65789 roc_auc 0.33538 prc_auc 0.57142[0m
[92maverage training of epoch 82: loss -6.03328 acc 0.66667 roc_auc 0.42990 prc_auc 0.61034[0m
[93maverage test of epoch 82: loss -6.02063 acc 0.65789 roc_auc 0.45846 prc_auc 0.61513[0m
[92maverage training of epoch 83: loss -6.09036 acc 0.66667 roc_auc 0.37130 prc_auc 0.57730[0m
[93maverage test of epoch 83: loss -6.07920 acc 0.65789 roc_auc 0.53538 prc_auc 0.68212[0m
[92maverage training of epoch 84: loss -6.14598 acc 0.66667 roc_auc 0.48010 prc_auc 0.63697[0m
[93maverage test of epoch 84: loss -6.13331 acc 0.65789 roc_auc 0.51077 prc_auc 0.73742[0m
[92maverage training of epoch 85: loss -6.20111 acc 0.66667 roc_auc 0.42900 prc_auc 0.60859[0m
[93maverage test of epoch 85: loss -6.19023 acc 0.65789 roc_auc 0.42462 prc_auc 0.61225[0m
[92maverage training of epoch 86: loss -6.25704 acc 0.66667 roc_auc 0.39170 prc_auc 0.58864[0m
[93maverage test of epoch 86: loss -6.24694 acc 0.65789 roc_auc 0.50154 prc_auc 0.68051[0m
[92maverage training of epoch 87: loss -6.31278 acc 0.66667 roc_auc 0.46200 prc_auc 0.63091[0m
[93maverage test of epoch 87: loss -6.30212 acc 0.65789 roc_auc 0.44769 prc_auc 0.65647[0m
[92maverage training of epoch 88: loss -6.36812 acc 0.66667 roc_auc 0.37360 prc_auc 0.56885[0m
[93maverage test of epoch 88: loss -6.35731 acc 0.65789 roc_auc 0.44923 prc_auc 0.69662[0m
[92maverage training of epoch 89: loss -6.42478 acc 0.66667 roc_auc 0.38320 prc_auc 0.58318[0m
[93maverage test of epoch 89: loss -6.41299 acc 0.65789 roc_auc 0.49538 prc_auc 0.68199[0m
[92maverage training of epoch 90: loss -6.48053 acc 0.66667 roc_auc 0.32280 prc_auc 0.55433[0m
[93maverage test of epoch 90: loss -6.46732 acc 0.65789 roc_auc 0.61385 prc_auc 0.76023[0m
[92maverage training of epoch 91: loss -6.53559 acc 0.66667 roc_auc 0.39670 prc_auc 0.59699[0m
[93maverage test of epoch 91: loss -6.52315 acc 0.65789 roc_auc 0.36923 prc_auc 0.58047[0m
[92maverage training of epoch 92: loss -6.59255 acc 0.66667 roc_auc 0.41080 prc_auc 0.59403[0m
[93maverage test of epoch 92: loss -6.58030 acc 0.65789 roc_auc 0.46769 prc_auc 0.67913[0m
[92maverage training of epoch 93: loss -6.64683 acc 0.66667 roc_auc 0.40920 prc_auc 0.59523[0m
[93maverage test of epoch 93: loss -6.63399 acc 0.65789 roc_auc 0.32308 prc_auc 0.57922[0m
[92maverage training of epoch 94: loss -6.70202 acc 0.66667 roc_auc 0.37320 prc_auc 0.57581[0m
[93maverage test of epoch 94: loss -6.68800 acc 0.65789 roc_auc 0.60000 prc_auc 0.70773[0m
[92maverage training of epoch 95: loss -6.75813 acc 0.66667 roc_auc 0.44630 prc_auc 0.62362[0m
[93maverage test of epoch 95: loss -6.74295 acc 0.65789 roc_auc 0.31846 prc_auc 0.55181[0m
[92maverage training of epoch 96: loss -6.81346 acc 0.66667 roc_auc 0.36020 prc_auc 0.58054[0m
[93maverage test of epoch 96: loss -6.80048 acc 0.65789 roc_auc 0.50154 prc_auc 0.69390[0m
[92maverage training of epoch 97: loss -6.86917 acc 0.66667 roc_auc 0.42790 prc_auc 0.61088[0m
[93maverage test of epoch 97: loss -6.85623 acc 0.65789 roc_auc 0.37846 prc_auc 0.63360[0m
[92maverage training of epoch 98: loss -6.92540 acc 0.66667 roc_auc 0.39000 prc_auc 0.58252[0m
[93maverage test of epoch 98: loss -6.91115 acc 0.65789 roc_auc 0.45846 prc_auc 0.69899[0m
[92maverage training of epoch 99: loss -6.98065 acc 0.66667 roc_auc 0.42030 prc_auc 0.61627[0m
[93maverage test of epoch 99: loss -6.96645 acc 0.65789 roc_auc 0.56154 prc_auc 0.73533[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss 1.11712 acc 0.33333 roc_auc 0.49780 prc_auc 0.69508[0m
[93maverage test of epoch 0: loss 1.00989 acc 0.34211 roc_auc 0.50462 prc_auc 0.70789[0m
[92maverage training of epoch 1: loss 0.90977 acc 0.33333 roc_auc 0.60440 prc_auc 0.76475[0m
[93maverage test of epoch 1: loss 0.78605 acc 0.34211 roc_auc 0.58154 prc_auc 0.78525[0m
[92maverage training of epoch 2: loss 0.70966 acc 0.33333 roc_auc 0.57380 prc_auc 0.75346[0m
[93maverage test of epoch 2: loss 0.55809 acc 0.34211 roc_auc 0.65846 prc_auc 0.82835[0m
[92maverage training of epoch 3: loss 0.48734 acc 0.33333 roc_auc 0.49160 prc_auc 0.67970[0m
[93maverage test of epoch 3: loss 0.34592 acc 0.34211 roc_auc 0.63077 prc_auc 0.81662[0m
[92maverage training of epoch 4: loss 0.23388 acc 0.33333 roc_auc 0.55500 prc_auc 0.70449[0m
[93maverage test of epoch 4: loss 0.08435 acc 0.34211 roc_auc 0.64308 prc_auc 0.78544[0m
[92maverage training of epoch 5: loss -0.01024 acc 0.33333 roc_auc 0.49600 prc_auc 0.70408[0m
[93maverage test of epoch 5: loss -0.18466 acc 0.34211 roc_auc 0.61846 prc_auc 0.79832[0m
[92maverage training of epoch 6: loss -0.30669 acc 0.33333 roc_auc 0.40840 prc_auc 0.63111[0m
[93maverage test of epoch 6: loss -0.50443 acc 0.34211 roc_auc 0.55077 prc_auc 0.76612[0m
[92maverage training of epoch 7: loss -0.72105 acc 0.33333 roc_auc 0.51660 prc_auc 0.69524[0m
[93maverage test of epoch 7: loss -0.96483 acc 0.34211 roc_auc 0.54462 prc_auc 0.69473[0m
[92maverage training of epoch 8: loss -1.18821 acc 0.38000 roc_auc 0.57080 prc_auc 0.74316[0m
[93maverage test of epoch 8: loss -1.35839 acc 0.47368 roc_auc 0.53846 prc_auc 0.71189[0m
[92maverage training of epoch 9: loss -1.47398 acc 0.63333 roc_auc 0.54140 prc_auc 0.69419[0m
[93maverage test of epoch 9: loss -1.57721 acc 0.60526 roc_auc 0.41231 prc_auc 0.65999[0m
[92maverage training of epoch 10: loss -1.67944 acc 0.67333 roc_auc 0.51060 prc_auc 0.67906[0m
[93maverage test of epoch 10: loss -1.75429 acc 0.65789 roc_auc 0.44615 prc_auc 0.63338[0m
[92maverage training of epoch 11: loss -1.82300 acc 0.66667 roc_auc 0.46740 prc_auc 0.69208[0m
[93maverage test of epoch 11: loss -1.89605 acc 0.65789 roc_auc 0.41231 prc_auc 0.68886[0m
[92maverage training of epoch 12: loss -1.96309 acc 0.66667 roc_auc 0.44780 prc_auc 0.62033[0m
[93maverage test of epoch 12: loss -2.03758 acc 0.65789 roc_auc 0.44000 prc_auc 0.67998[0m
[92maverage training of epoch 13: loss -2.09345 acc 0.66667 roc_auc 0.46720 prc_auc 0.63833[0m
[93maverage test of epoch 13: loss -2.14379 acc 0.65789 roc_auc 0.40000 prc_auc 0.64510[0m
[92maverage training of epoch 14: loss -2.20362 acc 0.66667 roc_auc 0.43520 prc_auc 0.64851[0m
[93maverage test of epoch 14: loss -2.25290 acc 0.65789 roc_auc 0.54462 prc_auc 0.67394[0m
[92maverage training of epoch 15: loss -2.30379 acc 0.66667 roc_auc 0.42680 prc_auc 0.62859[0m
[93maverage test of epoch 15: loss -2.34480 acc 0.65789 roc_auc 0.26154 prc_auc 0.54589[0m
[92maverage training of epoch 16: loss -2.39689 acc 0.66667 roc_auc 0.47700 prc_auc 0.68821[0m
[93maverage test of epoch 16: loss -2.43492 acc 0.65789 roc_auc 0.29538 prc_auc 0.60015[0m
[92maverage training of epoch 17: loss -2.49734 acc 0.66667 roc_auc 0.49080 prc_auc 0.68468[0m
[93maverage test of epoch 17: loss -2.52383 acc 0.65789 roc_auc 0.41231 prc_auc 0.65493[0m
[92maverage training of epoch 18: loss -2.56383 acc 0.66667 roc_auc 0.46980 prc_auc 0.67764[0m
[93maverage test of epoch 18: loss -2.62430 acc 0.65789 roc_auc 0.40923 prc_auc 0.60369[0m
[92maverage training of epoch 19: loss -2.64963 acc 0.66667 roc_auc 0.42460 prc_auc 0.63779[0m
[93maverage test of epoch 19: loss -2.68888 acc 0.65789 roc_auc 0.55692 prc_auc 0.75925[0m
[92maverage training of epoch 20: loss -2.73439 acc 0.66667 roc_auc 0.51480 prc_auc 0.69119[0m
[93maverage test of epoch 20: loss -2.76894 acc 0.65789 roc_auc 0.57846 prc_auc 0.71949[0m
[92maverage training of epoch 21: loss -2.79961 acc 0.66667 roc_auc 0.42460 prc_auc 0.63170[0m
[93maverage test of epoch 21: loss -2.83562 acc 0.65789 roc_auc 0.57846 prc_auc 0.70753[0m
[92maverage training of epoch 22: loss -2.88725 acc 0.66667 roc_auc 0.47380 prc_auc 0.64797[0m
[93maverage test of epoch 22: loss -2.89968 acc 0.65789 roc_auc 0.52308 prc_auc 0.66910[0m
[92maverage training of epoch 23: loss -2.95055 acc 0.66667 roc_auc 0.53760 prc_auc 0.66598[0m
[93maverage test of epoch 23: loss -2.97579 acc 0.65789 roc_auc 0.44923 prc_auc 0.67802[0m
[92maverage training of epoch 24: loss -3.01354 acc 0.66667 roc_auc 0.51040 prc_auc 0.70609[0m
[93maverage test of epoch 24: loss -3.04470 acc 0.65789 roc_auc 0.49846 prc_auc 0.69001[0m
[92maverage training of epoch 25: loss -3.08339 acc 0.66667 roc_auc 0.47980 prc_auc 0.64607[0m
[93maverage test of epoch 25: loss -3.10971 acc 0.65789 roc_auc 0.56615 prc_auc 0.69978[0m
[92maverage training of epoch 26: loss -3.14224 acc 0.66667 roc_auc 0.52020 prc_auc 0.68678[0m
[93maverage test of epoch 26: loss -3.15996 acc 0.65789 roc_auc 0.56615 prc_auc 0.76677[0m
[92maverage training of epoch 27: loss -3.20716 acc 0.66667 roc_auc 0.54640 prc_auc 0.72489[0m
[93maverage test of epoch 27: loss -3.22271 acc 0.65789 roc_auc 0.53538 prc_auc 0.67385[0m
[92maverage training of epoch 28: loss -3.26652 acc 0.66667 roc_auc 0.48180 prc_auc 0.65120[0m
[93maverage test of epoch 28: loss -3.28224 acc 0.65789 roc_auc 0.40000 prc_auc 0.61952[0m
[92maverage training of epoch 29: loss -3.32898 acc 0.66667 roc_auc 0.53400 prc_auc 0.69377[0m
[93maverage test of epoch 29: loss -3.33622 acc 0.65789 roc_auc 0.50462 prc_auc 0.71224[0m
[92maverage training of epoch 30: loss -3.38672 acc 0.66667 roc_auc 0.51260 prc_auc 0.66373[0m
[93maverage test of epoch 30: loss -3.41539 acc 0.65789 roc_auc 0.51385 prc_auc 0.63923[0m
[92maverage training of epoch 31: loss -3.44050 acc 0.66667 roc_auc 0.43240 prc_auc 0.62366[0m
[93maverage test of epoch 31: loss -3.45885 acc 0.65789 roc_auc 0.41538 prc_auc 0.60630[0m
[92maverage training of epoch 32: loss -3.50868 acc 0.66667 roc_auc 0.41660 prc_auc 0.61395[0m
[93maverage test of epoch 32: loss -3.50878 acc 0.65789 roc_auc 0.53538 prc_auc 0.73612[0m
[92maverage training of epoch 33: loss -3.56119 acc 0.66667 roc_auc 0.52760 prc_auc 0.70143[0m
[93maverage test of epoch 33: loss -3.58164 acc 0.65789 roc_auc 0.40308 prc_auc 0.65573[0m
[92maverage training of epoch 34: loss -3.62036 acc 0.66667 roc_auc 0.47760 prc_auc 0.63651[0m
[93maverage test of epoch 34: loss -3.63456 acc 0.65789 roc_auc 0.49538 prc_auc 0.70650[0m
[92maverage training of epoch 35: loss -3.67724 acc 0.66667 roc_auc 0.53540 prc_auc 0.69189[0m
[93maverage test of epoch 35: loss -3.69665 acc 0.65789 roc_auc 0.41231 prc_auc 0.67370[0m
[92maverage training of epoch 36: loss -3.73242 acc 0.66667 roc_auc 0.48400 prc_auc 0.64473[0m
[93maverage test of epoch 36: loss -3.73627 acc 0.65789 roc_auc 0.44308 prc_auc 0.62577[0m
[92maverage training of epoch 37: loss -3.78643 acc 0.66667 roc_auc 0.48140 prc_auc 0.66155[0m
[93maverage test of epoch 37: loss -3.80734 acc 0.65789 roc_auc 0.51077 prc_auc 0.72931[0m
[92maverage training of epoch 38: loss -3.85435 acc 0.66667 roc_auc 0.45740 prc_auc 0.62596[0m
[93maverage test of epoch 38: loss -3.87302 acc 0.65789 roc_auc 0.50462 prc_auc 0.67823[0m
[92maverage training of epoch 39: loss -3.91105 acc 0.66667 roc_auc 0.47060 prc_auc 0.65970[0m
[93maverage test of epoch 39: loss -3.92858 acc 0.65789 roc_auc 0.49538 prc_auc 0.73306[0m
[92maverage training of epoch 40: loss -3.97765 acc 0.66667 roc_auc 0.44440 prc_auc 0.66182[0m
[93maverage test of epoch 40: loss -3.99208 acc 0.65789 roc_auc 0.39077 prc_auc 0.59096[0m
[92maverage training of epoch 41: loss -4.04904 acc 0.66667 roc_auc 0.50240 prc_auc 0.68900[0m
[93maverage test of epoch 41: loss -4.08286 acc 0.65789 roc_auc 0.64615 prc_auc 0.80800[0m
[92maverage training of epoch 42: loss -4.12752 acc 0.66667 roc_auc 0.52320 prc_auc 0.69360[0m
[93maverage test of epoch 42: loss -4.14190 acc 0.65789 roc_auc 0.28923 prc_auc 0.53562[0m
[92maverage training of epoch 43: loss -4.21294 acc 0.66667 roc_auc 0.47660 prc_auc 0.67822[0m
[93maverage test of epoch 43: loss -4.24852 acc 0.65789 roc_auc 0.60923 prc_auc 0.80752[0m
[92maverage training of epoch 44: loss -4.30805 acc 0.66667 roc_auc 0.52960 prc_auc 0.66313[0m
[93maverage test of epoch 44: loss -4.34409 acc 0.65789 roc_auc 0.59077 prc_auc 0.69959[0m
[92maverage training of epoch 45: loss -4.39777 acc 0.66667 roc_auc 0.39240 prc_auc 0.59373[0m
[93maverage test of epoch 45: loss -4.42011 acc 0.65789 roc_auc 0.33846 prc_auc 0.62848[0m
[92maverage training of epoch 46: loss -4.49201 acc 0.66667 roc_auc 0.49260 prc_auc 0.66780[0m
[93maverage test of epoch 46: loss -4.51790 acc 0.65789 roc_auc 0.55385 prc_auc 0.70482[0m
[92maverage training of epoch 47: loss -4.58665 acc 0.66667 roc_auc 0.45560 prc_auc 0.62787[0m
[93maverage test of epoch 47: loss -4.60455 acc 0.65789 roc_auc 0.52308 prc_auc 0.66750[0m
[92maverage training of epoch 48: loss -4.67651 acc 0.66667 roc_auc 0.50160 prc_auc 0.65403[0m
[93maverage test of epoch 48: loss -4.71175 acc 0.65789 roc_auc 0.47077 prc_auc 0.69565[0m
[92maverage training of epoch 49: loss -4.77049 acc 0.66667 roc_auc 0.50800 prc_auc 0.66657[0m
[93maverage test of epoch 49: loss -4.78726 acc 0.65789 roc_auc 0.45538 prc_auc 0.66446[0m
[92maverage training of epoch 50: loss -4.85736 acc 0.66667 roc_auc 0.46460 prc_auc 0.63325[0m
[93maverage test of epoch 50: loss -4.87620 acc 0.65789 roc_auc 0.54769 prc_auc 0.71088[0m
[92maverage training of epoch 51: loss -4.93972 acc 0.66667 roc_auc 0.52500 prc_auc 0.66975[0m
[93maverage test of epoch 51: loss -4.94041 acc 0.65789 roc_auc 0.53846 prc_auc 0.75826[0m
[92maverage training of epoch 52: loss -5.00980 acc 0.66667 roc_auc 0.45240 prc_auc 0.63607[0m
[93maverage test of epoch 52: loss -5.00853 acc 0.65789 roc_auc 0.51385 prc_auc 0.69650[0m
[92maverage training of epoch 53: loss -5.07737 acc 0.66667 roc_auc 0.47480 prc_auc 0.66612[0m
[93maverage test of epoch 53: loss -5.09337 acc 0.65789 roc_auc 0.34462 prc_auc 0.59924[0m
[92maverage training of epoch 54: loss -5.15582 acc 0.66667 roc_auc 0.51320 prc_auc 0.66882[0m
[93maverage test of epoch 54: loss -5.16349 acc 0.65789 roc_auc 0.62462 prc_auc 0.77662[0m
[92maverage training of epoch 55: loss -5.21328 acc 0.66667 roc_auc 0.35840 prc_auc 0.58612[0m
[93maverage test of epoch 55: loss -5.23716 acc 0.65789 roc_auc 0.48923 prc_auc 0.72646[0m
[92maverage training of epoch 56: loss -5.28804 acc 0.66667 roc_auc 0.49920 prc_auc 0.66792[0m
[93maverage test of epoch 56: loss -5.28431 acc 0.65789 roc_auc 0.12923 prc_auc 0.49486[0m
[92maverage training of epoch 57: loss -5.35869 acc 0.66667 roc_auc 0.59680 prc_auc 0.73183[0m
[93maverage test of epoch 57: loss -5.36140 acc 0.65789 roc_auc 0.55692 prc_auc 0.74537[0m
[92maverage training of epoch 58: loss -5.42433 acc 0.66667 roc_auc 0.48920 prc_auc 0.63756[0m
[93maverage test of epoch 58: loss -5.41737 acc 0.65789 roc_auc 0.42154 prc_auc 0.70924[0m
[92maverage training of epoch 59: loss -5.48637 acc 0.66667 roc_auc 0.51340 prc_auc 0.68812[0m
[93maverage test of epoch 59: loss -5.47546 acc 0.65789 roc_auc 0.32615 prc_auc 0.59667[0m
[92maverage training of epoch 60: loss -5.54371 acc 0.66667 roc_auc 0.45400 prc_auc 0.60547[0m
[93maverage test of epoch 60: loss -5.55679 acc 0.65789 roc_auc 0.48923 prc_auc 0.65476[0m
[92maverage training of epoch 61: loss -5.59609 acc 0.66667 roc_auc 0.41320 prc_auc 0.63623[0m
[93maverage test of epoch 61: loss -5.60848 acc 0.65789 roc_auc 0.60000 prc_auc 0.81275[0m
[92maverage training of epoch 62: loss -5.67671 acc 0.66667 roc_auc 0.58120 prc_auc 0.68033[0m
[93maverage test of epoch 62: loss -5.68135 acc 0.65789 roc_auc 0.60000 prc_auc 0.81474[0m
[92maverage training of epoch 63: loss -5.72940 acc 0.66667 roc_auc 0.44160 prc_auc 0.63068[0m
[93maverage test of epoch 63: loss -5.73293 acc 0.65789 roc_auc 0.49385 prc_auc 0.68144[0m
[92maverage training of epoch 64: loss -5.79104 acc 0.66667 roc_auc 0.40660 prc_auc 0.60057[0m
[93maverage test of epoch 64: loss -5.79408 acc 0.65789 roc_auc 0.48000 prc_auc 0.66129[0m
[92maverage training of epoch 65: loss -5.85072 acc 0.66667 roc_auc 0.43600 prc_auc 0.62030[0m
[93maverage test of epoch 65: loss -5.84601 acc 0.65789 roc_auc 0.56923 prc_auc 0.77707[0m
[92maverage training of epoch 66: loss -5.91037 acc 0.66667 roc_auc 0.47610 prc_auc 0.65781[0m
[93maverage test of epoch 66: loss -5.91349 acc 0.65789 roc_auc 0.61538 prc_auc 0.77481[0m
[92maverage training of epoch 67: loss -5.97005 acc 0.66667 roc_auc 0.43820 prc_auc 0.62422[0m
[93maverage test of epoch 67: loss -5.97133 acc 0.65789 roc_auc 0.50769 prc_auc 0.73291[0m
[92maverage training of epoch 68: loss -6.03178 acc 0.66667 roc_auc 0.49800 prc_auc 0.67814[0m
[93maverage test of epoch 68: loss -6.02544 acc 0.65789 roc_auc 0.39077 prc_auc 0.65060[0m
[92maverage training of epoch 69: loss -6.08538 acc 0.66667 roc_auc 0.46440 prc_auc 0.63463[0m
[93maverage test of epoch 69: loss -6.08170 acc 0.65789 roc_auc 0.44000 prc_auc 0.61469[0m
[92maverage training of epoch 70: loss -6.15034 acc 0.66667 roc_auc 0.53520 prc_auc 0.69332[0m
[93maverage test of epoch 70: loss -6.14391 acc 0.65789 roc_auc 0.41077 prc_auc 0.63671[0m
[92maverage training of epoch 71: loss -6.20300 acc 0.66667 roc_auc 0.44020 prc_auc 0.61298[0m
[93maverage test of epoch 71: loss -6.20089 acc 0.65789 roc_auc 0.42923 prc_auc 0.65452[0m
[92maverage training of epoch 72: loss -6.26629 acc 0.66667 roc_auc 0.46030 prc_auc 0.65845[0m
[93maverage test of epoch 72: loss -6.26756 acc 0.65789 roc_auc 0.58154 prc_auc 0.76003[0m
[92maverage training of epoch 73: loss -6.32185 acc 0.66667 roc_auc 0.43080 prc_auc 0.63223[0m
[93maverage test of epoch 73: loss -6.32343 acc 0.65789 roc_auc 0.49231 prc_auc 0.67358[0m
[92maverage training of epoch 74: loss -6.38293 acc 0.66667 roc_auc 0.49400 prc_auc 0.66947[0m
[93maverage test of epoch 74: loss -6.36649 acc 0.65789 roc_auc 0.36308 prc_auc 0.56953[0m
[92maverage training of epoch 75: loss -6.43242 acc 0.66667 roc_auc 0.36250 prc_auc 0.57265[0m
[93maverage test of epoch 75: loss -6.43386 acc 0.65789 roc_auc 0.48000 prc_auc 0.64913[0m
[92maverage training of epoch 76: loss -6.49203 acc 0.66667 roc_auc 0.47000 prc_auc 0.63013[0m
[93maverage test of epoch 76: loss -6.49506 acc 0.65789 roc_auc 0.52000 prc_auc 0.64709[0m
[92maverage training of epoch 77: loss -6.55605 acc 0.66667 roc_auc 0.52320 prc_auc 0.66312[0m
[93maverage test of epoch 77: loss -6.54749 acc 0.65789 roc_auc 0.48000 prc_auc 0.65307[0m
[92maverage training of epoch 78: loss -6.61089 acc 0.66667 roc_auc 0.48200 prc_auc 0.64825[0m
[93maverage test of epoch 78: loss -6.60267 acc 0.65789 roc_auc 0.55077 prc_auc 0.78359[0m
[92maverage training of epoch 79: loss -6.66654 acc 0.66667 roc_auc 0.45240 prc_auc 0.63785[0m
[93maverage test of epoch 79: loss -6.66230 acc 0.65789 roc_auc 0.39692 prc_auc 0.64925[0m
[92maverage training of epoch 80: loss -6.72214 acc 0.66667 roc_auc 0.52460 prc_auc 0.66063[0m
[93maverage test of epoch 80: loss -6.72087 acc 0.65789 roc_auc 0.53077 prc_auc 0.74802[0m
[92maverage training of epoch 81: loss -6.77737 acc 0.66667 roc_auc 0.47240 prc_auc 0.66421[0m
[93maverage test of epoch 81: loss -6.77816 acc 0.65789 roc_auc 0.52154 prc_auc 0.67091[0m
[92maverage training of epoch 82: loss -6.83724 acc 0.66667 roc_auc 0.46860 prc_auc 0.63879[0m
[93maverage test of epoch 82: loss -6.83197 acc 0.65789 roc_auc 0.50769 prc_auc 0.71068[0m
[92maverage training of epoch 83: loss -6.89348 acc 0.66667 roc_auc 0.39840 prc_auc 0.59358[0m
[93maverage test of epoch 83: loss -6.88922 acc 0.65789 roc_auc 0.40923 prc_auc 0.63122[0m
[92maverage training of epoch 84: loss -6.95159 acc 0.66667 roc_auc 0.47250 prc_auc 0.64327[0m
[93maverage test of epoch 84: loss -6.94315 acc 0.65789 roc_auc 0.49538 prc_auc 0.71309[0m
[92maverage training of epoch 85: loss -7.00630 acc 0.66667 roc_auc 0.48830 prc_auc 0.63769[0m
[93maverage test of epoch 85: loss -7.00068 acc 0.65789 roc_auc 0.40615 prc_auc 0.59506[0m
[92maverage training of epoch 86: loss -7.06362 acc 0.66667 roc_auc 0.45570 prc_auc 0.62385[0m
[93maverage test of epoch 86: loss -7.05166 acc 0.65789 roc_auc 0.40154 prc_auc 0.65358[0m
[92maverage training of epoch 87: loss -7.11848 acc 0.66667 roc_auc 0.54520 prc_auc 0.67225[0m
[93maverage test of epoch 87: loss -7.11415 acc 0.65789 roc_auc 0.59692 prc_auc 0.74156[0m
[92maverage training of epoch 88: loss -7.17212 acc 0.66667 roc_auc 0.45230 prc_auc 0.61909[0m
[93maverage test of epoch 88: loss -7.16893 acc 0.65789 roc_auc 0.59846 prc_auc 0.76274[0m
[92maverage training of epoch 89: loss -7.23196 acc 0.66667 roc_auc 0.53200 prc_auc 0.65475[0m
[93maverage test of epoch 89: loss -7.22454 acc 0.65789 roc_auc 0.38154 prc_auc 0.62052[0m
[92maverage training of epoch 90: loss -7.28683 acc 0.66667 roc_auc 0.42510 prc_auc 0.59805[0m
[93maverage test of epoch 90: loss -7.28533 acc 0.65789 roc_auc 0.62154 prc_auc 0.77227[0m
[92maverage training of epoch 91: loss -7.34524 acc 0.66667 roc_auc 0.48220 prc_auc 0.64796[0m
[93maverage test of epoch 91: loss -7.33879 acc 0.65789 roc_auc 0.68154 prc_auc 0.76880[0m
[92maverage training of epoch 92: loss -7.39871 acc 0.66667 roc_auc 0.40740 prc_auc 0.59768[0m
[93maverage test of epoch 92: loss -7.39369 acc 0.65789 roc_auc 0.68154 prc_auc 0.80729[0m
[92maverage training of epoch 93: loss -7.45713 acc 0.66667 roc_auc 0.45040 prc_auc 0.61854[0m
[93maverage test of epoch 93: loss -7.44851 acc 0.65789 roc_auc 0.62615 prc_auc 0.77601[0m
[92maverage training of epoch 94: loss -7.51219 acc 0.66667 roc_auc 0.43260 prc_auc 0.64928[0m
[93maverage test of epoch 94: loss -7.50766 acc 0.65789 roc_auc 0.71692 prc_auc 0.86188[0m
[92maverage training of epoch 95: loss -7.57066 acc 0.66667 roc_auc 0.54010 prc_auc 0.66086[0m
[93maverage test of epoch 95: loss -7.56180 acc 0.65789 roc_auc 0.34769 prc_auc 0.57148[0m
[92maverage training of epoch 96: loss -7.62378 acc 0.66667 roc_auc 0.42670 prc_auc 0.60962[0m
[93maverage test of epoch 96: loss -7.61359 acc 0.65789 roc_auc 0.54308 prc_auc 0.74412[0m
[92maverage training of epoch 97: loss -7.67983 acc 0.66667 roc_auc 0.38410 prc_auc 0.61100[0m
[93maverage test of epoch 97: loss -7.67457 acc 0.65789 roc_auc 0.55231 prc_auc 0.70781[0m
[92maverage training of epoch 98: loss -7.73584 acc 0.66667 roc_auc 0.50620 prc_auc 0.65572[0m
[93maverage test of epoch 98: loss -7.72898 acc 0.65789 roc_auc 0.47077 prc_auc 0.63285[0m
[92maverage training of epoch 99: loss -7.79114 acc 0.66667 roc_auc 0.44240 prc_auc 0.62024[0m
[93maverage test of epoch 99: loss -7.78515 acc 0.65789 roc_auc 0.41231 prc_auc 0.63283[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.35647 acc 0.52000 roc_auc 0.52520 prc_auc 0.67887[0m
[93maverage test of epoch 0: loss -0.48493 acc 0.63158 roc_auc 0.50462 prc_auc 0.65480[0m
[92maverage training of epoch 1: loss -0.58898 acc 0.66667 roc_auc 0.41780 prc_auc 0.63392[0m
[93maverage test of epoch 1: loss -0.68069 acc 0.65789 roc_auc 0.52615 prc_auc 0.73809[0m
[92maverage training of epoch 2: loss -0.79704 acc 0.66667 roc_auc 0.47660 prc_auc 0.65296[0m
[93maverage test of epoch 2: loss -0.90461 acc 0.65789 roc_auc 0.58769 prc_auc 0.74819[0m
[92maverage training of epoch 3: loss -1.00335 acc 0.66667 roc_auc 0.58860 prc_auc 0.74161[0m
[93maverage test of epoch 3: loss -1.09644 acc 0.65789 roc_auc 0.52308 prc_auc 0.66370[0m
[92maverage training of epoch 4: loss -1.18330 acc 0.66667 roc_auc 0.53820 prc_auc 0.71473[0m
[93maverage test of epoch 4: loss -1.24248 acc 0.65789 roc_auc 0.44923 prc_auc 0.68126[0m
[92maverage training of epoch 5: loss -1.38267 acc 0.66667 roc_auc 0.44880 prc_auc 0.61589[0m
[93maverage test of epoch 5: loss -1.47092 acc 0.65789 roc_auc 0.57846 prc_auc 0.75751[0m
[92maverage training of epoch 6: loss -1.60546 acc 0.66667 roc_auc 0.48080 prc_auc 0.69313[0m
[93maverage test of epoch 6: loss -1.70938 acc 0.65789 roc_auc 0.51077 prc_auc 0.67658[0m
[92maverage training of epoch 7: loss -1.81632 acc 0.66667 roc_auc 0.51520 prc_auc 0.69266[0m
[93maverage test of epoch 7: loss -1.91578 acc 0.65789 roc_auc 0.51385 prc_auc 0.64381[0m
[92maverage training of epoch 8: loss -2.02810 acc 0.66667 roc_auc 0.45600 prc_auc 0.64976[0m
[93maverage test of epoch 8: loss -2.08917 acc 0.65789 roc_auc 0.37231 prc_auc 0.61194[0m
[92maverage training of epoch 9: loss -2.23598 acc 0.66667 roc_auc 0.42380 prc_auc 0.65156[0m
[93maverage test of epoch 9: loss -2.34709 acc 0.65789 roc_auc 0.62769 prc_auc 0.79013[0m
[92maverage training of epoch 10: loss -2.50833 acc 0.66667 roc_auc 0.55100 prc_auc 0.67864[0m
[93maverage test of epoch 10: loss -2.60895 acc 0.65789 roc_auc 0.42154 prc_auc 0.67371[0m
[92maverage training of epoch 11: loss -2.73497 acc 0.66667 roc_auc 0.45280 prc_auc 0.65429[0m
[93maverage test of epoch 11: loss -2.85200 acc 0.65789 roc_auc 0.60000 prc_auc 0.70255[0m
[92maverage training of epoch 12: loss -2.95427 acc 0.66667 roc_auc 0.41660 prc_auc 0.61575[0m
[93maverage test of epoch 12: loss -3.03154 acc 0.65789 roc_auc 0.52308 prc_auc 0.70208[0m
[92maverage training of epoch 13: loss -3.13228 acc 0.66667 roc_auc 0.50100 prc_auc 0.68322[0m
[93maverage test of epoch 13: loss -3.19187 acc 0.65789 roc_auc 0.48615 prc_auc 0.66104[0m
[92maverage training of epoch 14: loss -3.26440 acc 0.66667 roc_auc 0.42160 prc_auc 0.61042[0m
[93maverage test of epoch 14: loss -3.30378 acc 0.65789 roc_auc 0.48615 prc_auc 0.71821[0m
[92maverage training of epoch 15: loss -3.38490 acc 0.66667 roc_auc 0.40460 prc_auc 0.63117[0m
[93maverage test of epoch 15: loss -3.42516 acc 0.65789 roc_auc 0.55538 prc_auc 0.77104[0m
[92maverage training of epoch 16: loss -3.50551 acc 0.66667 roc_auc 0.53140 prc_auc 0.70375[0m
[93maverage test of epoch 16: loss -3.54198 acc 0.65789 roc_auc 0.46769 prc_auc 0.66836[0m
[92maverage training of epoch 17: loss -3.60979 acc 0.66667 roc_auc 0.52950 prc_auc 0.66896[0m
[93maverage test of epoch 17: loss -3.61984 acc 0.65789 roc_auc 0.35385 prc_auc 0.60389[0m
[92maverage training of epoch 18: loss -3.70738 acc 0.66667 roc_auc 0.60380 prc_auc 0.72922[0m
[93maverage test of epoch 18: loss -3.72048 acc 0.65789 roc_auc 0.54769 prc_auc 0.72119[0m
[92maverage training of epoch 19: loss -3.80362 acc 0.66667 roc_auc 0.41940 prc_auc 0.61444[0m
[93maverage test of epoch 19: loss -3.83307 acc 0.65789 roc_auc 0.63692 prc_auc 0.73951[0m
[92maverage training of epoch 20: loss -3.89486 acc 0.66667 roc_auc 0.43830 prc_auc 0.64121[0m
[93maverage test of epoch 20: loss -3.89789 acc 0.65789 roc_auc 0.72923 prc_auc 0.85316[0m
[92maverage training of epoch 21: loss -3.97877 acc 0.66667 roc_auc 0.42820 prc_auc 0.62990[0m
[93maverage test of epoch 21: loss -3.98359 acc 0.65789 roc_auc 0.52308 prc_auc 0.73502[0m
[92maverage training of epoch 22: loss -4.06458 acc 0.66667 roc_auc 0.45220 prc_auc 0.62933[0m
[93maverage test of epoch 22: loss -4.08672 acc 0.65789 roc_auc 0.56308 prc_auc 0.74508[0m
[92maverage training of epoch 23: loss -4.14139 acc 0.66667 roc_auc 0.47200 prc_auc 0.65545[0m
[93maverage test of epoch 23: loss -4.16383 acc 0.65789 roc_auc 0.70462 prc_auc 0.85003[0m
[92maverage training of epoch 24: loss -4.21835 acc 0.66667 roc_auc 0.47420 prc_auc 0.64608[0m
[93maverage test of epoch 24: loss -4.24408 acc 0.65789 roc_auc 0.52154 prc_auc 0.77427[0m
[92maverage training of epoch 25: loss -4.30795 acc 0.66667 roc_auc 0.48640 prc_auc 0.65620[0m
[93maverage test of epoch 25: loss -4.30667 acc 0.65789 roc_auc 0.36000 prc_auc 0.59219[0m
[92maverage training of epoch 26: loss -4.37483 acc 0.66667 roc_auc 0.44480 prc_auc 0.64813[0m
[93maverage test of epoch 26: loss -4.38512 acc 0.65789 roc_auc 0.45538 prc_auc 0.69361[0m
[92maverage training of epoch 27: loss -4.44811 acc 0.66667 roc_auc 0.45900 prc_auc 0.62205[0m
[93maverage test of epoch 27: loss -4.43777 acc 0.65789 roc_auc 0.46462 prc_auc 0.69534[0m
[92maverage training of epoch 28: loss -4.52555 acc 0.66667 roc_auc 0.41780 prc_auc 0.62372[0m
[93maverage test of epoch 28: loss -4.53140 acc 0.65789 roc_auc 0.33846 prc_auc 0.57924[0m
[92maverage training of epoch 29: loss -4.59575 acc 0.66667 roc_auc 0.37610 prc_auc 0.58253[0m
[93maverage test of epoch 29: loss -4.59047 acc 0.65789 roc_auc 0.44769 prc_auc 0.69080[0m
[92maverage training of epoch 30: loss -4.65930 acc 0.66667 roc_auc 0.43360 prc_auc 0.64372[0m
[93maverage test of epoch 30: loss -4.65292 acc 0.65789 roc_auc 0.34308 prc_auc 0.56583[0m
[92maverage training of epoch 31: loss -4.73953 acc 0.66667 roc_auc 0.45820 prc_auc 0.63694[0m
[93maverage test of epoch 31: loss -4.72544 acc 0.65789 roc_auc 0.46462 prc_auc 0.69547[0m
[92maverage training of epoch 32: loss -4.79622 acc 0.66667 roc_auc 0.45640 prc_auc 0.64316[0m
[93maverage test of epoch 32: loss -4.79592 acc 0.65789 roc_auc 0.54308 prc_auc 0.71756[0m
[92maverage training of epoch 33: loss -4.86690 acc 0.66667 roc_auc 0.43690 prc_auc 0.61256[0m
[93maverage test of epoch 33: loss -4.86163 acc 0.65789 roc_auc 0.44000 prc_auc 0.67406[0m
[92maverage training of epoch 34: loss -4.93366 acc 0.66667 roc_auc 0.45140 prc_auc 0.61582[0m
[93maverage test of epoch 34: loss -4.91771 acc 0.65789 roc_auc 0.51385 prc_auc 0.68431[0m
[92maverage training of epoch 35: loss -4.99583 acc 0.66667 roc_auc 0.44770 prc_auc 0.62560[0m
[93maverage test of epoch 35: loss -4.98975 acc 0.65789 roc_auc 0.52308 prc_auc 0.75465[0m
[92maverage training of epoch 36: loss -5.06373 acc 0.66667 roc_auc 0.47510 prc_auc 0.64313[0m
[93maverage test of epoch 36: loss -5.05336 acc 0.65789 roc_auc 0.37846 prc_auc 0.67572[0m
[92maverage training of epoch 37: loss -5.13008 acc 0.66667 roc_auc 0.49110 prc_auc 0.64034[0m
[93maverage test of epoch 37: loss -5.12227 acc 0.65789 roc_auc 0.52000 prc_auc 0.72701[0m
[92maverage training of epoch 38: loss -5.19192 acc 0.66667 roc_auc 0.58410 prc_auc 0.71479[0m
[93maverage test of epoch 38: loss -5.18198 acc 0.65789 roc_auc 0.45538 prc_auc 0.66559[0m
[92maverage training of epoch 39: loss -5.24403 acc 0.66667 roc_auc 0.39670 prc_auc 0.58249[0m
[93maverage test of epoch 39: loss -5.25010 acc 0.65789 roc_auc 0.55231 prc_auc 0.71870[0m
[92maverage training of epoch 40: loss -5.31426 acc 0.66667 roc_auc 0.46180 prc_auc 0.64377[0m
[93maverage test of epoch 40: loss -5.29722 acc 0.65789 roc_auc 0.55692 prc_auc 0.73863[0m
[92maverage training of epoch 41: loss -5.37585 acc 0.66667 roc_auc 0.51420 prc_auc 0.66210[0m
[93maverage test of epoch 41: loss -5.37977 acc 0.65789 roc_auc 0.59846 prc_auc 0.77097[0m
[92maverage training of epoch 42: loss -5.43420 acc 0.66667 roc_auc 0.52890 prc_auc 0.66202[0m
[93maverage test of epoch 42: loss -5.42627 acc 0.65789 roc_auc 0.64615 prc_auc 0.78886[0m
[92maverage training of epoch 43: loss -5.49904 acc 0.66667 roc_auc 0.49770 prc_auc 0.66226[0m
[93maverage test of epoch 43: loss -5.48706 acc 0.65789 roc_auc 0.43385 prc_auc 0.69070[0m
[92maverage training of epoch 44: loss -5.55810 acc 0.66667 roc_auc 0.41880 prc_auc 0.61718[0m
[93maverage test of epoch 44: loss -5.54874 acc 0.65789 roc_auc 0.40462 prc_auc 0.63687[0m
[92maverage training of epoch 45: loss -5.61906 acc 0.66667 roc_auc 0.47540 prc_auc 0.66584[0m
[93maverage test of epoch 45: loss -5.60995 acc 0.65789 roc_auc 0.63538 prc_auc 0.78806[0m
[92maverage training of epoch 46: loss -5.67388 acc 0.66667 roc_auc 0.41180 prc_auc 0.61083[0m
[93maverage test of epoch 46: loss -5.67678 acc 0.65789 roc_auc 0.67231 prc_auc 0.79355[0m
[92maverage training of epoch 47: loss -5.73359 acc 0.66667 roc_auc 0.50390 prc_auc 0.69776[0m
[93maverage test of epoch 47: loss -5.73353 acc 0.65789 roc_auc 0.52769 prc_auc 0.70121[0m
[92maverage training of epoch 48: loss -5.78948 acc 0.66667 roc_auc 0.53410 prc_auc 0.69021[0m
[93maverage test of epoch 48: loss -5.78973 acc 0.65789 roc_auc 0.54769 prc_auc 0.76596[0m
[92maverage training of epoch 49: loss -5.85592 acc 0.66667 roc_auc 0.46000 prc_auc 0.64813[0m
[93maverage test of epoch 49: loss -5.84742 acc 0.65789 roc_auc 0.49538 prc_auc 0.66862[0m
[92maverage training of epoch 50: loss -5.90814 acc 0.66667 roc_auc 0.37170 prc_auc 0.58300[0m
[93maverage test of epoch 50: loss -5.89470 acc 0.65789 roc_auc 0.38154 prc_auc 0.62896[0m
[92maverage training of epoch 51: loss -5.96860 acc 0.66667 roc_auc 0.53510 prc_auc 0.67630[0m
[93maverage test of epoch 51: loss -5.95666 acc 0.65789 roc_auc 0.44308 prc_auc 0.71685[0m
[92maverage training of epoch 52: loss -6.02777 acc 0.66667 roc_auc 0.44390 prc_auc 0.62684[0m
[93maverage test of epoch 52: loss -6.01966 acc 0.65789 roc_auc 0.49538 prc_auc 0.73686[0m
[92maverage training of epoch 53: loss -6.08522 acc 0.66667 roc_auc 0.44970 prc_auc 0.64426[0m
[93maverage test of epoch 53: loss -6.06814 acc 0.65789 roc_auc 0.57846 prc_auc 0.77956[0m
[92maverage training of epoch 54: loss -6.14164 acc 0.66667 roc_auc 0.41760 prc_auc 0.60354[0m
[93maverage test of epoch 54: loss -6.12968 acc 0.65789 roc_auc 0.60154 prc_auc 0.76448[0m
[92maverage training of epoch 55: loss -6.20322 acc 0.66667 roc_auc 0.49880 prc_auc 0.65893[0m
[93maverage test of epoch 55: loss -6.17915 acc 0.65789 roc_auc 0.52615 prc_auc 0.74324[0m
[92maverage training of epoch 56: loss -6.25806 acc 0.66667 roc_auc 0.46530 prc_auc 0.63833[0m
[93maverage test of epoch 56: loss -6.24721 acc 0.65789 roc_auc 0.57231 prc_auc 0.72084[0m
[92maverage training of epoch 57: loss -6.31771 acc 0.66667 roc_auc 0.41250 prc_auc 0.58578[0m
[93maverage test of epoch 57: loss -6.30232 acc 0.65789 roc_auc 0.50615 prc_auc 0.68795[0m
[92maverage training of epoch 58: loss -6.37041 acc 0.66667 roc_auc 0.44950 prc_auc 0.64252[0m
[93maverage test of epoch 58: loss -6.35341 acc 0.65789 roc_auc 0.28308 prc_auc 0.57073[0m
[92maverage training of epoch 59: loss -6.43160 acc 0.66667 roc_auc 0.50360 prc_auc 0.64819[0m
[93maverage test of epoch 59: loss -6.41635 acc 0.65789 roc_auc 0.24462 prc_auc 0.54019[0m
[92maverage training of epoch 60: loss -6.48606 acc 0.66667 roc_auc 0.52470 prc_auc 0.65637[0m
[93maverage test of epoch 60: loss -6.47062 acc 0.65789 roc_auc 0.59231 prc_auc 0.75364[0m
[92maverage training of epoch 61: loss -6.54605 acc 0.66667 roc_auc 0.48370 prc_auc 0.64410[0m
[93maverage test of epoch 61: loss -6.53478 acc 0.65789 roc_auc 0.56154 prc_auc 0.70521[0m
[92maverage training of epoch 62: loss -6.59994 acc 0.66667 roc_auc 0.45630 prc_auc 0.63232[0m
[93maverage test of epoch 62: loss -6.58694 acc 0.65789 roc_auc 0.60308 prc_auc 0.77013[0m
[92maverage training of epoch 63: loss -6.65954 acc 0.66667 roc_auc 0.45490 prc_auc 0.61555[0m
[93maverage test of epoch 63: loss -6.64123 acc 0.65789 roc_auc 0.54154 prc_auc 0.73144[0m
[92maverage training of epoch 64: loss -6.71263 acc 0.66667 roc_auc 0.42160 prc_auc 0.60493[0m
[93maverage test of epoch 64: loss -6.69963 acc 0.65789 roc_auc 0.44000 prc_auc 0.64752[0m
[92maverage training of epoch 65: loss -6.77077 acc 0.66667 roc_auc 0.45310 prc_auc 0.62535[0m
[93maverage test of epoch 65: loss -6.75822 acc 0.65789 roc_auc 0.47692 prc_auc 0.71066[0m
[92maverage training of epoch 66: loss -6.82827 acc 0.66667 roc_auc 0.48760 prc_auc 0.62980[0m
[93maverage test of epoch 66: loss -6.81227 acc 0.65789 roc_auc 0.58000 prc_auc 0.71128[0m
[92maverage training of epoch 67: loss -6.88528 acc 0.66667 roc_auc 0.45740 prc_auc 0.62018[0m
[93maverage test of epoch 67: loss -6.87165 acc 0.65789 roc_auc 0.51077 prc_auc 0.71117[0m
[92maverage training of epoch 68: loss -6.93900 acc 0.66667 roc_auc 0.43070 prc_auc 0.60077[0m
[93maverage test of epoch 68: loss -6.92189 acc 0.65789 roc_auc 0.68462 prc_auc 0.82871[0m
[92maverage training of epoch 69: loss -6.99770 acc 0.66667 roc_auc 0.44650 prc_auc 0.63003[0m
[93maverage test of epoch 69: loss -6.98100 acc 0.65789 roc_auc 0.38000 prc_auc 0.60222[0m
[92maverage training of epoch 70: loss -7.05089 acc 0.66667 roc_auc 0.37050 prc_auc 0.57895[0m
[93maverage test of epoch 70: loss -7.03690 acc 0.65789 roc_auc 0.48308 prc_auc 0.64738[0m
[92maverage training of epoch 71: loss -7.10700 acc 0.66667 roc_auc 0.47220 prc_auc 0.64136[0m
[93maverage test of epoch 71: loss -7.09061 acc 0.65789 roc_auc 0.28462 prc_auc 0.57487[0m
[92maverage training of epoch 72: loss -7.16376 acc 0.66667 roc_auc 0.42660 prc_auc 0.61141[0m
[93maverage test of epoch 72: loss -7.14888 acc 0.65789 roc_auc 0.54154 prc_auc 0.71593[0m
[92maverage training of epoch 73: loss -7.22104 acc 0.66667 roc_auc 0.50260 prc_auc 0.65027[0m
[93maverage test of epoch 73: loss -7.20617 acc 0.65789 roc_auc 0.54615 prc_auc 0.66952[0m
[92maverage training of epoch 74: loss -7.27530 acc 0.66667 roc_auc 0.46670 prc_auc 0.64162[0m
[93maverage test of epoch 74: loss -7.25941 acc 0.65789 roc_auc 0.39846 prc_auc 0.59354[0m
[92maverage training of epoch 75: loss -7.33303 acc 0.66667 roc_auc 0.44400 prc_auc 0.61749[0m
[93maverage test of epoch 75: loss -7.31820 acc 0.65789 roc_auc 0.43231 prc_auc 0.60408[0m
[92maverage training of epoch 76: loss -7.38765 acc 0.66667 roc_auc 0.39690 prc_auc 0.59705[0m
[93maverage test of epoch 76: loss -7.36945 acc 0.65789 roc_auc 0.37538 prc_auc 0.61105[0m
[92maverage training of epoch 77: loss -7.44448 acc 0.66667 roc_auc 0.45750 prc_auc 0.63472[0m
[93maverage test of epoch 77: loss -7.42701 acc 0.65789 roc_auc 0.61538 prc_auc 0.76317[0m
[92maverage training of epoch 78: loss -7.49865 acc 0.66667 roc_auc 0.43030 prc_auc 0.60824[0m
[93maverage test of epoch 78: loss -7.48406 acc 0.65789 roc_auc 0.58923 prc_auc 0.72885[0m
[92maverage training of epoch 79: loss -7.55748 acc 0.66667 roc_auc 0.44260 prc_auc 0.60505[0m
[93maverage test of epoch 79: loss -7.53876 acc 0.65789 roc_auc 0.50923 prc_auc 0.65224[0m
[92maverage training of epoch 80: loss -7.61134 acc 0.66667 roc_auc 0.42010 prc_auc 0.60013[0m
[93maverage test of epoch 80: loss -7.59440 acc 0.65789 roc_auc 0.52769 prc_auc 0.67316[0m
[92maverage training of epoch 81: loss -7.66822 acc 0.66667 roc_auc 0.44470 prc_auc 0.61506[0m
[93maverage test of epoch 81: loss -7.64789 acc 0.65789 roc_auc 0.48462 prc_auc 0.65566[0m
[92maverage training of epoch 82: loss -7.72272 acc 0.66667 roc_auc 0.43060 prc_auc 0.61236[0m
[93maverage test of epoch 82: loss -7.70572 acc 0.65789 roc_auc 0.51692 prc_auc 0.68812[0m
[92maverage training of epoch 83: loss -7.77774 acc 0.66667 roc_auc 0.41370 prc_auc 0.61287[0m
[93maverage test of epoch 83: loss -7.76240 acc 0.65789 roc_auc 0.52462 prc_auc 0.68909[0m
[92maverage training of epoch 84: loss -7.83252 acc 0.66667 roc_auc 0.38080 prc_auc 0.58150[0m
[93maverage test of epoch 84: loss -7.81898 acc 0.65789 roc_auc 0.58308 prc_auc 0.70556[0m
[92maverage training of epoch 85: loss -7.88989 acc 0.66667 roc_auc 0.43400 prc_auc 0.63099[0m
[93maverage test of epoch 85: loss -7.87298 acc 0.65789 roc_auc 0.58154 prc_auc 0.70163[0m
[92maverage training of epoch 86: loss -7.94530 acc 0.66667 roc_auc 0.44380 prc_auc 0.61480[0m
[93maverage test of epoch 86: loss -7.92676 acc 0.65789 roc_auc 0.67692 prc_auc 0.78324[0m
[92maverage training of epoch 87: loss -8.00074 acc 0.66667 roc_auc 0.43340 prc_auc 0.63645[0m
[93maverage test of epoch 87: loss -7.98358 acc 0.65789 roc_auc 0.49692 prc_auc 0.66063[0m
[92maverage training of epoch 88: loss -8.05785 acc 0.66667 roc_auc 0.41460 prc_auc 0.59129[0m
[93maverage test of epoch 88: loss -8.03888 acc 0.65789 roc_auc 0.47077 prc_auc 0.63494[0m
[92maverage training of epoch 89: loss -8.11324 acc 0.66667 roc_auc 0.40430 prc_auc 0.59001[0m
[93maverage test of epoch 89: loss -8.09459 acc 0.65789 roc_auc 0.58154 prc_auc 0.71907[0m
[92maverage training of epoch 90: loss -8.16878 acc 0.66667 roc_auc 0.40170 prc_auc 0.58404[0m
[93maverage test of epoch 90: loss -8.14936 acc 0.65789 roc_auc 0.38615 prc_auc 0.59706[0m
[92maverage training of epoch 91: loss -8.22324 acc 0.66667 roc_auc 0.39140 prc_auc 0.59166[0m
[93maverage test of epoch 91: loss -8.20625 acc 0.65789 roc_auc 0.70462 prc_auc 0.75857[0m
[92maverage training of epoch 92: loss -8.27951 acc 0.66667 roc_auc 0.37070 prc_auc 0.58241[0m
[93maverage test of epoch 92: loss -8.26165 acc 0.65789 roc_auc 0.60308 prc_auc 0.71281[0m
[92maverage training of epoch 93: loss -8.33617 acc 0.66667 roc_auc 0.40390 prc_auc 0.58538[0m
[93maverage test of epoch 93: loss -8.31541 acc 0.65789 roc_auc 0.51846 prc_auc 0.69025[0m
[92maverage training of epoch 94: loss -8.39056 acc 0.66667 roc_auc 0.33970 prc_auc 0.55464[0m
[93maverage test of epoch 94: loss -8.37060 acc 0.65789 roc_auc 0.60308 prc_auc 0.77964[0m
[92maverage training of epoch 95: loss -8.44574 acc 0.66667 roc_auc 0.38590 prc_auc 0.59217[0m
[93maverage test of epoch 95: loss -8.42595 acc 0.65789 roc_auc 0.54154 prc_auc 0.69334[0m
[92maverage training of epoch 96: loss -8.50204 acc 0.66667 roc_auc 0.40360 prc_auc 0.59488[0m
[93maverage test of epoch 96: loss -8.48073 acc 0.65789 roc_auc 0.41077 prc_auc 0.61602[0m
[92maverage training of epoch 97: loss -8.55718 acc 0.66667 roc_auc 0.38320 prc_auc 0.57720[0m
[93maverage test of epoch 97: loss -8.53664 acc 0.65789 roc_auc 0.60769 prc_auc 0.75244[0m
[92maverage training of epoch 98: loss -8.61251 acc 0.66667 roc_auc 0.37050 prc_auc 0.58554[0m
[93maverage test of epoch 98: loss -8.59341 acc 0.65789 roc_auc 0.52154 prc_auc 0.67952[0m
[92maverage training of epoch 99: loss -8.66821 acc 0.66667 roc_auc 0.41300 prc_auc 0.59425[0m
[93maverage test of epoch 99: loss -8.64716 acc 0.65789 roc_auc 0.49077 prc_auc 0.65542[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.58639 acc 0.33775 roc_auc 0.57980 prc_auc 0.74145[0m
[93maverage test of epoch 0: loss -0.61900 acc 0.32432 roc_auc 0.53667 prc_auc 0.72253[0m
[92maverage training of epoch 1: loss -0.67813 acc 0.33775 roc_auc 0.52882 prc_auc 0.68229[0m
[93maverage test of epoch 1: loss -0.72316 acc 0.32432 roc_auc 0.54000 prc_auc 0.77651[0m
[92maverage training of epoch 2: loss -0.78348 acc 0.33775 roc_auc 0.57902 prc_auc 0.74352[0m
[93maverage test of epoch 2: loss -0.81457 acc 0.32432 roc_auc 0.59333 prc_auc 0.74898[0m
[92maverage training of epoch 3: loss -0.88075 acc 0.35099 roc_auc 0.63765 prc_auc 0.79725[0m
[93maverage test of epoch 3: loss -0.90612 acc 0.35135 roc_auc 0.59000 prc_auc 0.75837[0m
[92maverage training of epoch 4: loss -0.95835 acc 0.35099 roc_auc 0.57882 prc_auc 0.73054[0m
[93maverage test of epoch 4: loss -0.99261 acc 0.35135 roc_auc 0.54000 prc_auc 0.74150[0m
[92maverage training of epoch 5: loss -1.04983 acc 0.35762 roc_auc 0.64059 prc_auc 0.77822[0m
[93maverage test of epoch 5: loss -1.07919 acc 0.37838 roc_auc 0.55667 prc_auc 0.73858[0m
[92maverage training of epoch 6: loss -1.14913 acc 0.39073 roc_auc 0.67922 prc_auc 0.83378[0m
[93maverage test of epoch 6: loss -1.17059 acc 0.37838 roc_auc 0.62000 prc_auc 0.76127[0m
[92maverage training of epoch 7: loss -1.23709 acc 0.43709 roc_auc 0.67373 prc_auc 0.82268[0m
[93maverage test of epoch 7: loss -1.26977 acc 0.45946 roc_auc 0.71667 prc_auc 0.85371[0m
[92maverage training of epoch 8: loss -1.34579 acc 0.59603 roc_auc 0.72843 prc_auc 0.86478[0m
[93maverage test of epoch 8: loss -1.34424 acc 0.48649 roc_auc 0.56667 prc_auc 0.80335[0m
[92maverage training of epoch 9: loss -1.47015 acc 0.67550 roc_auc 0.79373 prc_auc 0.89105[0m
[93maverage test of epoch 9: loss -1.48327 acc 0.62162 roc_auc 0.71667 prc_auc 0.86778[0m
[92maverage training of epoch 10: loss -1.60878 acc 0.72848 roc_auc 0.81804 prc_auc 0.90975[0m
[93maverage test of epoch 10: loss -1.65129 acc 0.83784 roc_auc 0.89000 prc_auc 0.93697[0m
[92maverage training of epoch 11: loss -1.76117 acc 0.79470 roc_auc 0.87627 prc_auc 0.92955[0m
[93maverage test of epoch 11: loss -1.81128 acc 0.81081 roc_auc 0.91000 prc_auc 0.95046[0m
[92maverage training of epoch 12: loss -1.90873 acc 0.74834 roc_auc 0.88980 prc_auc 0.92527[0m
[93maverage test of epoch 12: loss -1.93749 acc 0.78378 roc_auc 0.88000 prc_auc 0.92653[0m
[92maverage training of epoch 13: loss -2.02576 acc 0.73510 roc_auc 0.86863 prc_auc 0.92430[0m
[93maverage test of epoch 13: loss -2.04991 acc 0.67568 roc_auc 0.84333 prc_auc 0.91758[0m
[92maverage training of epoch 14: loss -2.15365 acc 0.78146 roc_auc 0.88000 prc_auc 0.92049[0m
[93maverage test of epoch 14: loss -2.17764 acc 0.72973 roc_auc 0.83667 prc_auc 0.91632[0m
[92maverage training of epoch 15: loss -2.27193 acc 0.78808 roc_auc 0.89843 prc_auc 0.93774[0m
[93maverage test of epoch 15: loss -2.28883 acc 0.78378 roc_auc 0.86000 prc_auc 0.92279[0m
[92maverage training of epoch 16: loss -2.34823 acc 0.77483 roc_auc 0.87549 prc_auc 0.92206[0m
[93maverage test of epoch 16: loss -2.39577 acc 0.81081 roc_auc 0.88000 prc_auc 0.92867[0m
[92maverage training of epoch 17: loss -2.47251 acc 0.84768 roc_auc 0.89471 prc_auc 0.91467[0m
[93maverage test of epoch 17: loss -2.47141 acc 0.78378 roc_auc 0.85667 prc_auc 0.91974[0m
[92maverage training of epoch 18: loss -2.55824 acc 0.80795 roc_auc 0.89686 prc_auc 0.92485[0m
[93maverage test of epoch 18: loss -2.55145 acc 0.83784 roc_auc 0.83333 prc_auc 0.90595[0m
[92maverage training of epoch 19: loss -2.64499 acc 0.81457 roc_auc 0.88745 prc_auc 0.92881[0m
[93maverage test of epoch 19: loss -2.65330 acc 0.83784 roc_auc 0.88000 prc_auc 0.94083[0m
[92maverage training of epoch 20: loss -2.71189 acc 0.83444 roc_auc 0.87235 prc_auc 0.90739[0m
[93maverage test of epoch 20: loss -2.70856 acc 0.81081 roc_auc 0.84667 prc_auc 0.92254[0m
[92maverage training of epoch 21: loss -2.80600 acc 0.82781 roc_auc 0.88529 prc_auc 0.92126[0m
[93maverage test of epoch 21: loss -2.79362 acc 0.78378 roc_auc 0.85333 prc_auc 0.91832[0m
[92maverage training of epoch 22: loss -2.88512 acc 0.84106 roc_auc 0.88961 prc_auc 0.92666[0m
[93maverage test of epoch 22: loss -2.86794 acc 0.83784 roc_auc 0.82667 prc_auc 0.89357[0m
[92maverage training of epoch 23: loss -2.97726 acc 0.84106 roc_auc 0.88510 prc_auc 0.92137[0m
[93maverage test of epoch 23: loss -2.96781 acc 0.86486 roc_auc 0.87333 prc_auc 0.92683[0m
[92maverage training of epoch 24: loss -3.03620 acc 0.83444 roc_auc 0.88471 prc_auc 0.92555[0m
[93maverage test of epoch 24: loss -3.05004 acc 0.86486 roc_auc 0.86667 prc_auc 0.91309[0m
[92maverage training of epoch 25: loss -3.12469 acc 0.84768 roc_auc 0.89078 prc_auc 0.92525[0m
[93maverage test of epoch 25: loss -3.09339 acc 0.83784 roc_auc 0.84667 prc_auc 0.91873[0m
[92maverage training of epoch 26: loss -3.20105 acc 0.85430 roc_auc 0.90157 prc_auc 0.93619[0m
[93maverage test of epoch 26: loss -3.19216 acc 0.83784 roc_auc 0.88667 prc_auc 0.94430[0m
[92maverage training of epoch 27: loss -3.27038 acc 0.85430 roc_auc 0.89392 prc_auc 0.93667[0m
[93maverage test of epoch 27: loss -3.27723 acc 0.86486 roc_auc 0.86333 prc_auc 0.92928[0m
[92maverage training of epoch 28: loss -3.33102 acc 0.85430 roc_auc 0.87353 prc_auc 0.92062[0m
[93maverage test of epoch 28: loss -3.30905 acc 0.86486 roc_auc 0.85000 prc_auc 0.91378[0m
[92maverage training of epoch 29: loss -3.41892 acc 0.85430 roc_auc 0.88961 prc_auc 0.92395[0m
[93maverage test of epoch 29: loss -3.37169 acc 0.86486 roc_auc 0.84333 prc_auc 0.92229[0m
[92maverage training of epoch 30: loss -3.48822 acc 0.86093 roc_auc 0.89255 prc_auc 0.93415[0m
[93maverage test of epoch 30: loss -3.43266 acc 0.86486 roc_auc 0.85000 prc_auc 0.92648[0m
[92maverage training of epoch 31: loss -3.57635 acc 0.86755 roc_auc 0.90255 prc_auc 0.93188[0m
[93maverage test of epoch 31: loss -3.50493 acc 0.83784 roc_auc 0.84667 prc_auc 0.90767[0m
[92maverage training of epoch 32: loss -3.62097 acc 0.86755 roc_auc 0.88588 prc_auc 0.93040[0m
[93maverage test of epoch 32: loss -3.57368 acc 0.86486 roc_auc 0.83000 prc_auc 0.88351[0m
[92maverage training of epoch 33: loss -3.68917 acc 0.85430 roc_auc 0.89235 prc_auc 0.92926[0m
[93maverage test of epoch 33: loss -3.60261 acc 0.83784 roc_auc 0.84333 prc_auc 0.90657[0m
[92maverage training of epoch 34: loss -3.76001 acc 0.85430 roc_auc 0.89873 prc_auc 0.93756[0m
[93maverage test of epoch 34: loss -3.73858 acc 0.86486 roc_auc 0.86667 prc_auc 0.92725[0m
[92maverage training of epoch 35: loss -3.77993 acc 0.84106 roc_auc 0.88118 prc_auc 0.92678[0m
[93maverage test of epoch 35: loss -3.80879 acc 0.86486 roc_auc 0.85333 prc_auc 0.92106[0m
[92maverage training of epoch 36: loss -3.85972 acc 0.86093 roc_auc 0.88078 prc_auc 0.91690[0m
[93maverage test of epoch 36: loss -3.88841 acc 0.86486 roc_auc 0.86667 prc_auc 0.92495[0m
[92maverage training of epoch 37: loss -3.93988 acc 0.84768 roc_auc 0.88588 prc_auc 0.91827[0m
[93maverage test of epoch 37: loss -3.91615 acc 0.83784 roc_auc 0.87667 prc_auc 0.93198[0m
[92maverage training of epoch 38: loss -4.01306 acc 0.84768 roc_auc 0.89863 prc_auc 0.94583[0m
[93maverage test of epoch 38: loss -3.96759 acc 0.83784 roc_auc 0.88000 prc_auc 0.93813[0m
[92maverage training of epoch 39: loss -4.04282 acc 0.85430 roc_auc 0.87412 prc_auc 0.90027[0m
[93maverage test of epoch 39: loss -3.97198 acc 0.83784 roc_auc 0.82333 prc_auc 0.89219[0mUsing backend: pytorch

[92maverage training of epoch 40: loss -4.10589 acc 0.85430 roc_auc 0.89451 prc_auc 0.92802[0m
[93maverage test of epoch 40: loss -4.08498 acc 0.86486 roc_auc 0.81000 prc_auc 0.86709[0m
[92maverage training of epoch 41: loss -4.15957 acc 0.84768 roc_auc 0.86431 prc_auc 0.87994[0m
[93maverage test of epoch 41: loss -4.19765 acc 0.86486 roc_auc 0.82000 prc_auc 0.87435[0m
[92maverage training of epoch 42: loss -4.24283 acc 0.85430 roc_auc 0.89294 prc_auc 0.92447[0m
[93maverage test of epoch 42: loss -4.20128 acc 0.83784 roc_auc 0.82333 prc_auc 0.89155[0m
[92maverage training of epoch 43: loss -4.31964 acc 0.84106 roc_auc 0.89765 prc_auc 0.92941[0m
[93maverage test of epoch 43: loss -4.30943 acc 0.86486 roc_auc 0.83667 prc_auc 0.91276[0m
[92maverage training of epoch 44: loss -4.33796 acc 0.84768 roc_auc 0.89176 prc_auc 0.90802[0m
[93maverage test of epoch 44: loss -4.35769 acc 0.86486 roc_auc 0.86667 prc_auc 0.91800[0m
[92maverage training of epoch 45: loss -4.42867 acc 0.86093 roc_auc 0.89118 prc_auc 0.90668[0m
[93maverage test of epoch 45: loss -4.36788 acc 0.83784 roc_auc 0.83000 prc_auc 0.87707[0m
[92maverage training of epoch 46: loss -4.49409 acc 0.86093 roc_auc 0.89059 prc_auc 0.93219[0m
[93maverage test of epoch 46: loss -4.46765 acc 0.86486 roc_auc 0.84333 prc_auc 0.90278[0m
[92maverage training of epoch 47: loss -4.56297 acc 0.86093 roc_auc 0.88353 prc_auc 0.89690[0m
[93maverage test of epoch 47: loss -4.49935 acc 0.83784 roc_auc 0.83333 prc_auc 0.86742[0m
[92maverage training of epoch 48: loss -4.60012 acc 0.85430 roc_auc 0.90843 prc_auc 0.94238[0m
[93maverage test of epoch 48: loss -4.61194 acc 0.86486 roc_auc 0.86667 prc_auc 0.92939[0m
[92maverage training of epoch 49: loss -4.65146 acc 0.85430 roc_auc 0.87588 prc_auc 0.89621[0m
[93maverage test of epoch 49: loss -4.66009 acc 0.86486 roc_auc 0.87000 prc_auc 0.93775[0m
[92maverage training of epoch 50: loss -4.67037 acc 0.83444 roc_auc 0.88510 prc_auc 0.92589[0m
[93maverage test of epoch 50: loss -4.72482 acc 0.86486 roc_auc 0.82333 prc_auc 0.88518[0m
[92maverage training of epoch 51: loss -4.75608 acc 0.86093 roc_auc 0.90588 prc_auc 0.93180[0m
[93maverage test of epoch 51: loss -4.73197 acc 0.86486 roc_auc 0.82333 prc_auc 0.90283[0m
[92maverage training of epoch 52: loss -4.81555 acc 0.86093 roc_auc 0.87353 prc_auc 0.90417[0m
[93maverage test of epoch 52: loss -4.77664 acc 0.86486 roc_auc 0.80667 prc_auc 0.87410[0m
[92maverage training of epoch 53: loss -4.85538 acc 0.86093 roc_auc 0.86608 prc_auc 0.87333[0m
[93maverage test of epoch 53: loss -4.88332 acc 0.83784 roc_auc 0.81667 prc_auc 0.87034[0m
[92maverage training of epoch 54: loss -4.94802 acc 0.86093 roc_auc 0.90235 prc_auc 0.91947[0m
[93maverage test of epoch 54: loss -4.88487 acc 0.86486 roc_auc 0.89000 prc_auc 0.95166[0m
[92maverage training of epoch 55: loss -4.98811 acc 0.85430 roc_auc 0.89843 prc_auc 0.92337[0m
[93maverage test of epoch 55: loss -4.90924 acc 0.86486 roc_auc 0.80333 prc_auc 0.87876[0m
[92maverage training of epoch 56: loss -5.04906 acc 0.86755 roc_auc 0.87980 prc_auc 0.89757[0m
[93maverage test of epoch 56: loss -4.98538 acc 0.86486 roc_auc 0.80667 prc_auc 0.88265[0m
[92maverage training of epoch 57: loss -5.09481 acc 0.86755 roc_auc 0.89412 prc_auc 0.91995[0m
[93maverage test of epoch 57: loss -5.04227 acc 0.86486 roc_auc 0.84000 prc_auc 0.92032[0m
[92maverage training of epoch 58: loss -5.14322 acc 0.86093 roc_auc 0.87333 prc_auc 0.87653[0m
[93maverage test of epoch 58: loss -5.09986 acc 0.86486 roc_auc 0.91333 prc_auc 0.95467[0m
[92maverage training of epoch 59: loss -5.20458 acc 0.86755 roc_auc 0.88147 prc_auc 0.91023[0m
[93maverage test of epoch 59: loss -5.18756 acc 0.86486 roc_auc 0.82333 prc_auc 0.88722[0m
[92maverage training of epoch 60: loss -5.23647 acc 0.86093 roc_auc 0.87382 prc_auc 0.90374[0m
[93maverage test of epoch 60: loss -5.26396 acc 0.86486 roc_auc 0.83000 prc_auc 0.90147[0m
[92maverage training of epoch 61: loss -5.35284 acc 0.88742 roc_auc 0.89529 prc_auc 0.93015[0m
[93maverage test of epoch 61: loss -5.29709 acc 0.86486 roc_auc 0.84333 prc_auc 0.90184[0m
[92maverage training of epoch 62: loss -5.35147 acc 0.86755 roc_auc 0.87157 prc_auc 0.89775[0m
[93maverage test of epoch 62: loss -5.33037 acc 0.86486 roc_auc 0.83667 prc_auc 0.89374[0m
[92maverage training of epoch 63: loss -5.39622 acc 0.85430 roc_auc 0.88647 prc_auc 0.91073[0m
[93maverage test of epoch 63: loss -5.33996 acc 0.86486 roc_auc 0.83333 prc_auc 0.88212[0m
[92maverage training of epoch 64: loss -5.48051 acc 0.86755 roc_auc 0.88314 prc_auc 0.91314[0m
[93maverage test of epoch 64: loss -5.40873 acc 0.86486 roc_auc 0.86000 prc_auc 0.93498[0m
[92maverage training of epoch 65: loss -5.52222 acc 0.87417 roc_auc 0.90686 prc_auc 0.93464[0m
[93maverage test of epoch 65: loss -5.48874 acc 0.86486 roc_auc 0.92333 prc_auc 0.96572[0m
[92maverage training of epoch 66: loss -5.59782 acc 0.88079 roc_auc 0.90363 prc_auc 0.94328[0m
[93maverage test of epoch 66: loss -5.43216 acc 0.81081 roc_auc 0.83333 prc_auc 0.88735[0m
[92maverage training of epoch 67: loss -5.61689 acc 0.88079 roc_auc 0.88863 prc_auc 0.92795[0m
[93maverage test of epoch 67: loss -5.52666 acc 0.86486 roc_auc 0.85000 prc_auc 0.91805[0m
[92maverage training of epoch 68: loss -5.70609 acc 0.88742 roc_auc 0.89451 prc_auc 0.93458[0m
[93maverage test of epoch 68: loss -5.60794 acc 0.86486 roc_auc 0.80333 prc_auc 0.88260[0m
[92maverage training of epoch 69: loss -5.77601 acc 0.88079 roc_auc 0.89471 prc_auc 0.92586[0m
[93maverage test of epoch 69: loss -5.72614 acc 0.86486 roc_auc 0.81667 prc_auc 0.86936[0m
[92maverage training of epoch 70: loss -5.79138 acc 0.87417 roc_auc 0.89078 prc_auc 0.91547[0m
[93maverage test of epoch 70: loss -5.73550 acc 0.86486 roc_auc 0.83333 prc_auc 0.88721[0m
[92maverage training of epoch 71: loss -5.83852 acc 0.86755 roc_auc 0.89098 prc_auc 0.91438[0m
[93maverage test of epoch 71: loss -5.74383 acc 0.86486 roc_auc 0.87333 prc_auc 0.93662[0m
[92maverage training of epoch 72: loss -5.87330 acc 0.87417 roc_auc 0.90784 prc_auc 0.94298[0m
[93maverage test of epoch 72: loss -5.80504 acc 0.86486 roc_auc 0.82667 prc_auc 0.89458[0m
[92maverage training of epoch 73: loss -5.96363 acc 0.88079 roc_auc 0.90039 prc_auc 0.93480[0m
[93maverage test of epoch 73: loss -5.89673 acc 0.86486 roc_auc 0.87667 prc_auc 0.91310[0m
[92maverage training of epoch 74: loss -5.97046 acc 0.87417 roc_auc 0.90647 prc_auc 0.93691[0m
[93maverage test of epoch 74: loss -5.91070 acc 0.86486 roc_auc 0.81000 prc_auc 0.86762[0m
[92maverage training of epoch 75: loss -6.06860 acc 0.86755 roc_auc 0.91843 prc_auc 0.95985[0m
[93maverage test of epoch 75: loss -5.99971 acc 0.86486 roc_auc 0.84333 prc_auc 0.89132[0m
[92maverage training of epoch 76: loss -6.11846 acc 0.88079 roc_auc 0.92078 prc_auc 0.94988[0m
[93maverage test of epoch 76: loss -6.00515 acc 0.86486 roc_auc 0.88667 prc_auc 0.94675[0m
[92maverage training of epoch 77: loss -6.13099 acc 0.86755 roc_auc 0.91490 prc_auc 0.94609[0m
[93maverage test of epoch 77: loss -6.00573 acc 0.86486 roc_auc 0.86000 prc_auc 0.91453[0m
[92maverage training of epoch 78: loss -6.18466 acc 0.87417 roc_auc 0.90353 prc_auc 0.92468[0m
[93maverage test of epoch 78: loss -6.12575 acc 0.86486 roc_auc 0.86333 prc_auc 0.92359[0m
[92maverage training of epoch 79: loss -6.19902 acc 0.87417 roc_auc 0.91569 prc_auc 0.94905[0m
[93maverage test of epoch 79: loss -6.18170 acc 0.86486 roc_auc 0.89000 prc_auc 0.95604[0m
[92maverage training of epoch 80: loss -6.28076 acc 0.85430 roc_auc 0.91990 prc_auc 0.94562[0m
[93maverage test of epoch 80: loss -6.17198 acc 0.86486 roc_auc 0.81333 prc_auc 0.85697[0m
[92maverage training of epoch 81: loss -6.33146 acc 0.86755 roc_auc 0.92667 prc_auc 0.96132[0m
[93maverage test of epoch 81: loss -6.28273 acc 0.86486 roc_auc 0.86333 prc_auc 0.90993[0m
[92maverage training of epoch 82: loss -6.36604 acc 0.88079 roc_auc 0.91294 prc_auc 0.93983[0m
[93maverage test of epoch 82: loss -6.27207 acc 0.86486 roc_auc 0.87000 prc_auc 0.92780[0m
[92maverage training of epoch 83: loss -6.45153 acc 0.87417 roc_auc 0.90765 prc_auc 0.93143[0m
[93maverage test of epoch 83: loss -6.35972 acc 0.86486 roc_auc 0.87500 prc_auc 0.93287[0m
[92maverage training of epoch 84: loss -6.49553 acc 0.87417 roc_auc 0.91451 prc_auc 0.94170[0m
[93maverage test of epoch 84: loss -6.39355 acc 0.83784 roc_auc 0.87167 prc_auc 0.92924[0m
[92maverage training of epoch 85: loss -6.54778 acc 0.87417 roc_auc 0.91706 prc_auc 0.95369[0m
[93maverage test of epoch 85: loss -6.47044 acc 0.86486 roc_auc 0.83000 prc_auc 0.85199[0m
[92maverage training of epoch 86: loss -6.50946 acc 0.86093 roc_auc 0.90980 prc_auc 0.94030[0m
[93maverage test of epoch 86: loss -6.49527 acc 0.86486 roc_auc 0.84333 prc_auc 0.91973[0m
[92maverage training of epoch 87: loss -6.63227 acc 0.86755 roc_auc 0.93471 prc_auc 0.96968[0m
[93maverage test of epoch 87: loss -6.45789 acc 0.86486 roc_auc 0.86667 prc_auc 0.93668[0m
[92maverage training of epoch 88: loss -6.69620 acc 0.87417 roc_auc 0.91431 prc_auc 0.95110[0m
[93maverage test of epoch 88: loss -6.62142 acc 0.86486 roc_auc 0.83333 prc_auc 0.90027[0m
[92maverage training of epoch 89: loss -6.77303 acc 0.88742 roc_auc 0.92735 prc_auc 0.96703[0m
[93maverage test of epoch 89: loss -6.61809 acc 0.86486 roc_auc 0.81333 prc_auc 0.87562[0m
[92maverage training of epoch 90: loss -6.74537 acc 0.86093 roc_auc 0.89971 prc_auc 0.94792[0m
[93maverage test of epoch 90: loss -6.71561 acc 0.86486 roc_auc 0.85833 prc_auc 0.91287[0m
[92maverage training of epoch 91: loss -6.79774 acc 0.86093 roc_auc 0.91392 prc_auc 0.94943[0m
[93maverage test of epoch 91: loss -6.72027 acc 0.86486 roc_auc 0.83333 prc_auc 0.91483[0m
[92maverage training of epoch 92: loss -6.84332 acc 0.87417 roc_auc 0.90098 prc_auc 0.93636[0m
[93maverage test of epoch 92: loss -6.72287 acc 0.83784 roc_auc 0.79333 prc_auc 0.83687[0m
[92maverage training of epoch 93: loss -6.80739 acc 0.84768 roc_auc 0.89706 prc_auc 0.94597[0m
[93maverage test of epoch 93: loss -6.77556 acc 0.86486 roc_auc 0.85333 prc_auc 0.92207[0m
[92maverage training of epoch 94: loss -6.93225 acc 0.86755 roc_auc 0.91235 prc_auc 0.94864[0m
[93maverage test of epoch 94: loss -6.91364 acc 0.86486 roc_auc 0.87500 prc_auc 0.92049[0m
[92maverage training of epoch 95: loss -6.98303 acc 0.87417 roc_auc 0.88235 prc_auc 0.93036[0m
[93maverage test of epoch 95: loss -6.85991 acc 0.83784 roc_auc 0.80000 prc_auc 0.87191[0m
[92maverage training of epoch 96: loss -7.01289 acc 0.87417 roc_auc 0.90647 prc_auc 0.95095[0m
[93maverage test of epoch 96: loss -6.99395 acc 0.86486 roc_auc 0.88167 prc_auc 0.94685[0m
[92maverage training of epoch 97: loss -7.10369 acc 0.86755 roc_auc 0.90431 prc_auc 0.94898[0m
[93maverage test of epoch 97: loss -6.98440 acc 0.86486 roc_auc 0.83667 prc_auc 0.90085[0m
[92maverage training of epoch 98: loss -7.11523 acc 0.87417 roc_auc 0.89667 prc_auc 0.93342[0m
[93maverage test of epoch 98: loss -7.05243 acc 0.86486 roc_auc 0.88167 prc_auc 0.94452[0m
[92maverage training of epoch 99: loss -7.18830 acc 0.88079 roc_auc 0.91127 prc_auc 0.94338[0m
[93maverage test of epoch 99: loss -7.11266 acc 0.86486 roc_auc 0.82667 prc_auc 0.90940[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.64325 acc 0.33113 roc_auc 0.42431 prc_auc 0.61628[0m
[93maverage test of epoch 0: loss -0.70717 acc 0.29730 roc_auc 0.59333 prc_auc 0.74285[0m
[92maverage training of epoch 1: loss -0.75212 acc 0.40397 roc_auc 0.47882 prc_auc 0.66743[0m
[93maverage test of epoch 1: loss -0.80454 acc 0.35135 roc_auc 0.51333 prc_auc 0.71323[0m
[92maverage training of epoch 2: loss -0.86577 acc 0.37748 roc_auc 0.61784 prc_auc 0.76952[0m
[93maverage test of epoch 2: loss -0.91302 acc 0.32432 roc_auc 0.37667 prc_auc 0.59402[0m
[92maverage training of epoch 3: loss -0.96164 acc 0.34437 roc_auc 0.51294 prc_auc 0.66443[0m
[93maverage test of epoch 3: loss -1.01003 acc 0.35135 roc_auc 0.50333 prc_auc 0.68526[0m
[92maverage training of epoch 4: loss -1.05057 acc 0.35762 roc_auc 0.51667 prc_auc 0.69531[0m
[93maverage test of epoch 4: loss -1.10439 acc 0.32432 roc_auc 0.52333 prc_auc 0.67849[0m
[92maverage training of epoch 5: loss -1.13260 acc 0.37086 roc_auc 0.52980 prc_auc 0.71069[0m
[93maverage test of epoch 5: loss -1.18380 acc 0.32432 roc_auc 0.66333 prc_auc 0.78237[0m
[92maverage training of epoch 6: loss -1.21736 acc 0.38411 roc_auc 0.58373 prc_auc 0.76340[0m
[93maverage test of epoch 6: loss -1.24570 acc 0.32432 roc_auc 0.45667 prc_auc 0.66638[0m
[92maverage training of epoch 7: loss -1.29261 acc 0.40397 roc_auc 0.59157 prc_auc 0.75924[0m
[93maverage test of epoch 7: loss -1.32695 acc 0.32432 roc_auc 0.56333 prc_auc 0.77924[0m
[92maverage training of epoch 8: loss -1.36727 acc 0.40397 roc_auc 0.57157 prc_auc 0.73987[0m
[93maverage test of epoch 8: loss -1.40108 acc 0.40541 roc_auc 0.54000 prc_auc 0.74339[0m
[92maverage training of epoch 9: loss -1.43333 acc 0.43046 roc_auc 0.51804 prc_auc 0.71750[0m
[93maverage test of epoch 9: loss -1.47039 acc 0.37838 roc_auc 0.55000 prc_auc 0.73178[0m
[92maverage training of epoch 10: loss -1.51401 acc 0.49007 roc_auc 0.56667 prc_auc 0.76537[0m
[93maverage test of epoch 10: loss -1.54108 acc 0.45946 roc_auc 0.47000 prc_auc 0.72678[0m
[92maverage training of epoch 11: loss -1.58010 acc 0.48344 roc_auc 0.53039 prc_auc 0.72143[0m
[93maverage test of epoch 11: loss -1.60390 acc 0.43243 roc_auc 0.46667 prc_auc 0.71278[0m
[92maverage training of epoch 12: loss -1.65306 acc 0.49669 roc_auc 0.52980 prc_auc 0.72240[0m
[93maverage test of epoch 12: loss -1.68677 acc 0.56757 roc_auc 0.60000 prc_auc 0.75668[0m
[92maverage training of epoch 13: loss -1.72657 acc 0.58940 roc_auc 0.58176 prc_auc 0.73809[0m
[93maverage test of epoch 13: loss -1.76085 acc 0.56757 roc_auc 0.68333 prc_auc 0.81262[0m
[92maverage training of epoch 14: loss -1.79669 acc 0.57616 roc_auc 0.57392 prc_auc 0.75263[0m
[93maverage test of epoch 14: loss -1.81706 acc 0.48649 roc_auc 0.51333 prc_auc 0.74034[0m
[92maverage training of epoch 15: loss -1.87310 acc 0.67550 roc_auc 0.67078 prc_auc 0.80433[0m
[93maverage test of epoch 15: loss -1.89525 acc 0.56757 roc_auc 0.48000 prc_auc 0.72081[0m
[92maverage training of epoch 16: loss -1.93439 acc 0.57616 roc_auc 0.54098 prc_auc 0.73910[0m
[93maverage test of epoch 16: loss -1.98182 acc 0.70270 roc_auc 0.59333 prc_auc 0.80556[0m
[92maverage training of epoch 17: loss -2.00842 acc 0.62252 roc_auc 0.60745 prc_auc 0.76460[0m
[93maverage test of epoch 17: loss -2.03992 acc 0.67568 roc_auc 0.54667 prc_auc 0.77502[0m
[92maverage training of epoch 18: loss -2.07899 acc 0.62252 roc_auc 0.56902 prc_auc 0.77054[0m
[93maverage test of epoch 18: loss -2.11404 acc 0.62162 roc_auc 0.54333 prc_auc 0.77218[0m
[92maverage training of epoch 19: loss -2.15262 acc 0.68212 roc_auc 0.64059 prc_auc 0.80619[0m
[93maverage test of epoch 19: loss -2.17405 acc 0.62162 roc_auc 0.51333 prc_auc 0.74423[0m
[92maverage training of epoch 20: loss -2.21631 acc 0.66887 roc_auc 0.60451 prc_auc 0.77611[0m
[93maverage test of epoch 20: loss -2.24926 acc 0.64865 roc_auc 0.70000 prc_auc 0.87167[0m
[92maverage training of epoch 21: loss -2.28704 acc 0.66225 roc_auc 0.59294 prc_auc 0.76210[0m
[93maverage test of epoch 21: loss -2.32797 acc 0.67568 roc_auc 0.74667 prc_auc 0.87937[0m
[92maverage training of epoch 22: loss -2.35386 acc 0.66225 roc_auc 0.65098 prc_auc 0.81184[0m
[93maverage test of epoch 22: loss -2.39861 acc 0.67568 roc_auc 0.70333 prc_auc 0.85727[0m
[92maverage training of epoch 23: loss -2.42008 acc 0.66225 roc_auc 0.59059 prc_auc 0.78420[0m
[93maverage test of epoch 23: loss -2.45235 acc 0.67568 roc_auc 0.54000 prc_auc 0.72390[0m
[92maverage training of epoch 24: loss -2.48877 acc 0.66225 roc_auc 0.58373 prc_auc 0.75309[0m
[93maverage test of epoch 24: loss -2.52775 acc 0.67568 roc_auc 0.60000 prc_auc 0.81249[0m
[92maverage training of epoch 25: loss -2.56093 acc 0.66225 roc_auc 0.65667 prc_auc 0.80826[0m
[93maverage test of epoch 25: loss -2.59983 acc 0.67568 roc_auc 0.68667 prc_auc 0.85570[0m
[92maverage training of epoch 26: loss -2.62083 acc 0.66225 roc_auc 0.57392 prc_auc 0.74332[0m
[93maverage test of epoch 26: loss -2.66224 acc 0.67568 roc_auc 0.64667 prc_auc 0.77275[0m
[92maverage training of epoch 27: loss -2.68680 acc 0.66225 roc_auc 0.64353 prc_auc 0.80461[0m
[93maverage test of epoch 27: loss -2.72825 acc 0.67568 roc_auc 0.65000 prc_auc 0.82465[0m
[92maverage training of epoch 28: loss -2.74918 acc 0.66225 roc_auc 0.58098 prc_auc 0.75629[0m
[93maverage test of epoch 28: loss -2.78464 acc 0.67568 roc_auc 0.48000 prc_auc 0.73850[0m
[92maverage training of epoch 29: loss -2.82293 acc 0.66225 roc_auc 0.66098 prc_auc 0.80405[0m
[93maverage test of epoch 29: loss -2.85385 acc 0.67568 roc_auc 0.64000 prc_auc 0.74831[0m
[92maverage training of epoch 30: loss -2.88168 acc 0.66225 roc_auc 0.59941 prc_auc 0.78972[0m
[93maverage test of epoch 30: loss -2.92257 acc 0.67568 roc_auc 0.70667 prc_auc 0.86489[0m
[92maverage training of epoch 31: loss -2.94888 acc 0.66225 roc_auc 0.63098 prc_auc 0.81217[0m
[93maverage test of epoch 31: loss -2.98548 acc 0.67568 roc_auc 0.60333 prc_auc 0.80484[0m
[92maverage training of epoch 32: loss -3.01352 acc 0.66225 roc_auc 0.62196 prc_auc 0.77177[0m
[93maverage test of epoch 32: loss -3.05912 acc 0.67568 roc_auc 0.66000 prc_auc 0.85635[0m
[92maverage training of epoch 33: loss -3.07930 acc 0.66225 roc_auc 0.67686 prc_auc 0.81034[0m
[93maverage test of epoch 33: loss -3.11802 acc 0.67568 roc_auc 0.66667 prc_auc 0.83634[0m
[92maverage training of epoch 34: loss -3.14257 acc 0.66225 roc_auc 0.62863 prc_auc 0.79177[0m
[93maverage test of epoch 34: loss -3.17383 acc 0.67568 roc_auc 0.59667 prc_auc 0.77376[0m
[92maverage training of epoch 35: loss -3.20629 acc 0.66225 roc_auc 0.63392 prc_auc 0.76499[0m
[93maverage test of epoch 35: loss -3.23105 acc 0.67568 roc_auc 0.44667 prc_auc 0.71147[0m
[92maverage training of epoch 36: loss -3.26920 acc 0.66225 roc_auc 0.69941 prc_auc 0.81728[0m
[93maverage test of epoch 36: loss -3.30423 acc 0.67568 roc_auc 0.66333 prc_auc 0.80936[0m
[92maverage training of epoch 37: loss -3.32516 acc 0.66225 roc_auc 0.56804 prc_auc 0.73531[0m
[93maverage test of epoch 37: loss -3.36289 acc 0.67568 roc_auc 0.52667 prc_auc 0.75391[0m
[92maverage training of epoch 38: loss -3.39809 acc 0.66225 roc_auc 0.66431 prc_auc 0.80520[0m
[93maverage test of epoch 38: loss -3.44087 acc 0.67568 roc_auc 0.78333 prc_auc 0.86656[0m
[92maverage training of epoch 39: loss -3.45967 acc 0.66225 roc_auc 0.67059 prc_auc 0.80255[0m
[93maverage test of epoch 39: loss -3.49902 acc 0.67568 roc_auc 0.70000 prc_auc 0.83364[0m
[92maverage training of epoch 40: loss -3.51905 acc 0.66225 roc_auc 0.61431 prc_auc 0.73524[0m
[93maverage test of epoch 40: loss -3.55675 acc 0.67568 roc_auc 0.72667 prc_auc 0.83465[0m
[92maverage training of epoch 41: loss -3.58019 acc 0.66225 roc_auc 0.59118 prc_auc 0.72671[0m
[93maverage test of epoch 41: loss -3.62493 acc 0.67568 roc_auc 0.72667 prc_auc 0.84566[0m
[92maverage training of epoch 42: loss -3.64036 acc 0.66225 roc_auc 0.58294 prc_auc 0.75384[0m
[93maverage test of epoch 42: loss -3.68670 acc 0.67568 roc_auc 0.74333 prc_auc 0.85221[0m
[92maverage training of epoch 43: loss -3.70278 acc 0.66225 roc_auc 0.53490 prc_auc 0.71973[0m
[93maverage test of epoch 43: loss -3.75721 acc 0.67568 roc_auc 0.89333 prc_auc 0.95434[0m
[92maverage training of epoch 44: loss -3.76649 acc 0.66225 roc_auc 0.60843 prc_auc 0.75272[0m
[93maverage test of epoch 44: loss -3.79526 acc 0.67568 roc_auc 0.48000 prc_auc 0.69815[0m
[92maverage training of epoch 45: loss -3.83084 acc 0.66225 roc_auc 0.64451 prc_auc 0.78711[0m
[93maverage test of epoch 45: loss -3.86891 acc 0.67568 roc_auc 0.69333 prc_auc 0.82304[0m
[92maverage training of epoch 46: loss -3.88562 acc 0.66225 roc_auc 0.55765 prc_auc 0.73898[0m
[93maverage test of epoch 46: loss -3.92895 acc 0.67568 roc_auc 0.59000 prc_auc 0.73373[0m
[92maverage training of epoch 47: loss -3.94942 acc 0.66225 roc_auc 0.52216 prc_auc 0.69439[0m
[93maverage test of epoch 47: loss -3.98770 acc 0.67568 roc_auc 0.67667 prc_auc 0.85734[0m
[92maverage training of epoch 48: loss -4.01071 acc 0.66225 roc_auc 0.54549 prc_auc 0.69503[0m
[93maverage test of epoch 48: loss -4.05323 acc 0.67568 roc_auc 0.62333 prc_auc 0.81613[0m
[92maverage training of epoch 49: loss -4.07290 acc 0.66225 roc_auc 0.51980 prc_auc 0.68229[0m
[93maverage test of epoch 49: loss -4.10685 acc 0.67568 roc_auc 0.53667 prc_auc 0.77733[0m
[92maverage training of epoch 50: loss -4.13332 acc 0.66225 roc_auc 0.54157 prc_auc 0.70865[0m
[93maverage test of epoch 50: loss -4.17613 acc 0.67568 roc_auc 0.71000 prc_auc 0.80938[0m
[92maverage training of epoch 51: loss -4.19055 acc 0.66225 roc_auc 0.52000 prc_auc 0.73850[0m
[93maverage test of epoch 51: loss -4.23607 acc 0.67568 roc_auc 0.71000 prc_auc 0.88605[0m
[92maverage training of epoch 52: loss -4.25008 acc 0.66225 roc_auc 0.52804 prc_auc 0.71009[0m
[93maverage test of epoch 52: loss -4.29787 acc 0.67568 roc_auc 0.68000 prc_auc 0.81757[0m
[92maverage training of epoch 53: loss -4.31287 acc 0.66225 roc_auc 0.54863 prc_auc 0.74000[0m
[93maverage test of epoch 53: loss -4.35035 acc 0.67568 roc_auc 0.60000 prc_auc 0.82067[0m
[92maverage training of epoch 54: loss -4.36904 acc 0.66225 roc_auc 0.50294 prc_auc 0.67363[0m
[93maverage test of epoch 54: loss -4.41081 acc 0.67568 roc_auc 0.58333 prc_auc 0.76678[0m
[92maverage training of epoch 55: loss -4.43142 acc 0.66225 roc_auc 0.46431 prc_auc 0.62427[0m
[93maverage test of epoch 55: loss -4.47208 acc 0.67568 roc_auc 0.68000 prc_auc 0.87660[0m
[92maverage training of epoch 56: loss -4.49165 acc 0.66225 roc_auc 0.52039 prc_auc 0.67033[0m
[93maverage test of epoch 56: loss -4.53501 acc 0.67568 roc_auc 0.65333 prc_auc 0.81483[0m
[92maverage training of epoch 57: loss -4.55183 acc 0.66225 roc_auc 0.56255 prc_auc 0.69643[0m
[93maverage test of epoch 57: loss -4.59196 acc 0.67568 roc_auc 0.60333 prc_auc 0.76387[0m
[92maverage training of epoch 58: loss -4.61308 acc 0.66225 roc_auc 0.56627 prc_auc 0.69695[0m
[93maverage test of epoch 58: loss -4.65574 acc 0.67568 roc_auc 0.72333 prc_auc 0.88822[0m
[92maverage training of epoch 59: loss -4.66891 acc 0.66225 roc_auc 0.53980 prc_auc 0.72541[0m
[93maverage test of epoch 59: loss -4.70446 acc 0.67568 roc_auc 0.33667 prc_auc 0.61198[0m
[92maverage training of epoch 60: loss -4.72569 acc 0.66225 roc_auc 0.49627 prc_auc 0.65751[0m
[93maverage test of epoch 60: loss -4.76986 acc 0.67568 roc_auc 0.56000 prc_auc 0.77052[0m
[92maverage training of epoch 61: loss -4.78269 acc 0.66225 roc_auc 0.43373 prc_auc 0.60242[0m
[93maverage test of epoch 61: loss -4.82763 acc 0.67568 roc_auc 0.61000 prc_auc 0.84614[0m
[92maverage training of epoch 62: loss -4.84027 acc 0.66225 roc_auc 0.36882 prc_auc 0.59451[0m
[93maverage test of epoch 62: loss -4.88465 acc 0.67568 roc_auc 0.61333 prc_auc 0.77355[0m
[92maverage training of epoch 63: loss -4.89954 acc 0.66225 roc_auc 0.40294 prc_auc 0.59218[0m
[93maverage test of epoch 63: loss -4.93683 acc 0.67568 roc_auc 0.44333 prc_auc 0.71461[0m
[92maverage training of epoch 64: loss -4.95584 acc 0.66225 roc_auc 0.50078 prc_auc 0.65180[0m
[93maverage test of epoch 64: loss -5.00107 acc 0.67568 roc_auc 0.51333 prc_auc 0.76051[0m
[92maverage training of epoch 65: loss -5.01486 acc 0.66225 roc_auc 0.44235 prc_auc 0.63248[0m
[93maverage test of epoch 65: loss -5.05848 acc 0.67568 roc_auc 0.47667 prc_auc 0.68251[0m
[92maverage training of epoch 66: loss -5.07275 acc 0.66225 roc_auc 0.49824 prc_auc 0.66620[0m
[93maverage test of epoch 66: loss -5.11429 acc 0.67568 roc_auc 0.53333 prc_auc 0.73594[0m
[92maverage training of epoch 67: loss -5.12975 acc 0.66225 roc_auc 0.56902 prc_auc 0.70920[0m
[93maverage test of epoch 67: loss -5.17691 acc 0.67568 roc_auc 0.62333 prc_auc 0.81009[0m
[92maverage training of epoch 68: loss -5.18726 acc 0.66225 roc_auc 0.46039 prc_auc 0.67420[0m
[93maverage test of epoch 68: loss -5.23666 acc 0.67568 roc_auc 0.54667 prc_auc 0.76497[0m
[92maverage training of epoch 69: loss -5.24350 acc 0.66225 roc_auc 0.43510 prc_auc 0.59922[0m
[93maverage test of epoch 69: loss -5.28916 acc 0.67568 roc_auc 0.56333 prc_auc 0.71572[0m
[92maverage training of epoch 70: loss -5.29914 acc 0.66225 roc_auc 0.43353 prc_auc 0.62890[0m
[93maverage test of epoch 70: loss -5.34708 acc 0.67568 roc_auc 0.52000 prc_auc 0.73378[0m
[92maverage training of epoch 71: loss -5.35918 acc 0.66225 roc_auc 0.46275 prc_auc 0.62114[0m
[93maverage test of epoch 71: loss -5.40542 acc 0.67568 roc_auc 0.46333 prc_auc 0.67442[0m
[92maverage training of epoch 72: loss -5.41544 acc 0.66225 roc_auc 0.37765 prc_auc 0.58535[0m
[93maverage test of epoch 72: loss -5.46562 acc 0.67568 roc_auc 0.78333 prc_auc 0.91123[0m
[92maverage training of epoch 73: loss -5.47370 acc 0.66225 roc_auc 0.43176 prc_auc 0.62421[0m
[93maverage test of epoch 73: loss -5.52444 acc 0.67568 roc_auc 0.70000 prc_auc 0.87868[0m
[92maverage training of epoch 74: loss -5.53081 acc 0.66225 roc_auc 0.47431 prc_auc 0.69603[0m
[93maverage test of epoch 74: loss -5.57787 acc 0.67568 roc_auc 0.57333 prc_auc 0.78978[0m
[92maverage training of epoch 75: loss -5.58903 acc 0.66225 roc_auc 0.46314 prc_auc 0.62586[0m
[93maverage test of epoch 75: loss -5.63034 acc 0.67568 roc_auc 0.37333 prc_auc 0.59772[0m
[92maverage training of epoch 76: loss -5.64530 acc 0.66225 roc_auc 0.47176 prc_auc 0.65361[0m
[93maverage test of epoch 76: loss -5.69056 acc 0.67568 roc_auc 0.59333 prc_auc 0.77253[0m
[92maverage training of epoch 77: loss -5.70111 acc 0.66225 roc_auc 0.44882 prc_auc 0.61566[0m
[93maverage test of epoch 77: loss -5.74680 acc 0.67568 roc_auc 0.34667 prc_auc 0.66887[0m
[92maverage training of epoch 78: loss -5.75769 acc 0.66225 roc_auc 0.39941 prc_auc 0.59100[0m
[93maverage test of epoch 78: loss -5.80480 acc 0.67568 roc_auc 0.57333 prc_auc 0.76292[0m
[92maverage training of epoch 79: loss -5.81533 acc 0.66225 roc_auc 0.47020 prc_auc 0.66898[0m
[93maverage test of epoch 79: loss -5.85778 acc 0.67568 roc_auc 0.33667 prc_auc 0.65192[0m
[92maverage training of epoch 80: loss -5.86942 acc 0.66225 roc_auc 0.37412 prc_auc 0.58222[0m
[93maverage test of epoch 80: loss -5.91921 acc 0.67568 roc_auc 0.43333 prc_auc 0.70294[0m
[92maverage training of epoch 81: loss -5.92615 acc 0.66225 roc_auc 0.40765 prc_auc 0.58591[0m
[93maverage test of epoch 81: loss -5.97228 acc 0.67568 roc_auc 0.39833 prc_auc 0.65528[0m
[92maverage training of epoch 82: loss -5.98600 acc 0.66225 roc_auc 0.52216 prc_auc 0.64510[0m
[93maverage test of epoch 82: loss -6.03334 acc 0.67568 roc_auc 0.53167 prc_auc 0.74053[0m
[92maverage training of epoch 83: loss -6.03980 acc 0.66225 roc_auc 0.44608 prc_auc 0.61777[0m
[93maverage test of epoch 83: loss -6.08590 acc 0.67568 roc_auc 0.58000 prc_auc 0.78523[0m
[92maverage training of epoch 84: loss -6.09649 acc 0.66225 roc_auc 0.45667 prc_auc 0.63507[0m
[93maverage test of epoch 84: loss -6.14450 acc 0.67568 roc_auc 0.55667 prc_auc 0.75628[0m
[92maverage training of epoch 85: loss -6.15019 acc 0.66225 roc_auc 0.47176 prc_auc 0.63344[0m
[93maverage test of epoch 85: loss -6.20160 acc 0.67568 roc_auc 0.53833 prc_auc 0.76071[0m
[92maverage training of epoch 86: loss -6.20940 acc 0.66225 roc_auc 0.37716 prc_auc 0.57108[0m
[93maverage test of epoch 86: loss -6.26152 acc 0.67568 roc_auc 0.80833 prc_auc 0.92546[0m
[92maverage training of epoch 87: loss -6.26517 acc 0.66225 roc_auc 0.42373 prc_auc 0.58550[0m
[93maverage test of epoch 87: loss -6.31818 acc 0.67568 roc_auc 0.70667 prc_auc 0.83928[0m
[92maverage training of epoch 88: loss -6.32157 acc 0.66225 roc_auc 0.42333 prc_auc 0.62766[0m
[93maverage test of epoch 88: loss -6.37153 acc 0.67568 roc_auc 0.57667 prc_auc 0.78841[0m
[92maverage training of epoch 89: loss -6.37931 acc 0.66225 roc_auc 0.41176 prc_auc 0.60897[0m
[93maverage test of epoch 89: loss -6.42952 acc 0.67568 roc_auc 0.72167 prc_auc 0.84952[0m
[92maverage training of epoch 90: loss -6.43328 acc 0.66225 roc_auc 0.43539 prc_auc 0.60644[0m
[93maverage test of epoch 90: loss -6.48448 acc 0.67568 roc_auc 0.57333 prc_auc 0.78882[0m
[92maverage training of epoch 91: loss -6.48863 acc 0.66225 roc_auc 0.40451 prc_auc 0.61086[0m
[93maverage test of epoch 91: loss -6.54185 acc 0.67568 roc_auc 0.74333 prc_auc 0.87925[0m
[92maverage training of epoch 92: loss -6.54636 acc 0.66225 roc_auc 0.43765 prc_auc 0.61849[0m
[93maverage test of epoch 92: loss -6.59528 acc 0.67568 roc_auc 0.69833 prc_auc 0.85361[0m
[92maverage training of epoch 93: loss -6.60098 acc 0.66225 roc_auc 0.39588 prc_auc 0.58562[0m
[93maverage test of epoch 93: loss -6.65502 acc 0.67568 roc_auc 0.53667 prc_auc 0.69921[0m
[92maverage training of epoch 94: loss -6.65789 acc 0.66225 roc_auc 0.40157 prc_auc 0.58349[0m
[93maverage test of epoch 94: loss -6.70939 acc 0.67568 roc_auc 0.50333 prc_auc 0.72574[0m
[92maverage training of epoch 95: loss -6.71408 acc 0.66225 roc_auc 0.43490 prc_auc 0.62222[0m
[93maverage test of epoch 95: loss -6.76613 acc 0.67568 roc_auc 0.67333 prc_auc 0.80755[0m
[92maverage training of epoch 96: loss -6.77008 acc 0.66225 roc_auc 0.40245 prc_auc 0.59864[0m
[93maverage test of epoch 96: loss -6.82302 acc 0.67568 roc_auc 0.59333 prc_auc 0.74169[0m
[92maverage training of epoch 97: loss -6.82603 acc 0.66225 roc_auc 0.36569 prc_auc 0.57112[0m
[93maverage test of epoch 97: loss -6.87828 acc 0.67568 roc_auc 0.63667 prc_auc 0.80648[0m
[92maverage training of epoch 98: loss -6.88112 acc 0.66225 roc_auc 0.38863 prc_auc 0.57812[0m
[93maverage test of epoch 98: loss -6.93319 acc 0.67568 roc_auc 0.58833 prc_auc 0.81766[0m
[92maverage training of epoch 99: loss -6.93739 acc 0.66225 roc_auc 0.36647 prc_auc 0.56758[0m
[93maverage test of epoch 99: loss -6.99069 acc 0.67568 roc_auc 0.71333 prc_auc 0.88312[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.0001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.70284 ROC_AUC (avg): 0.60092 PRC_AUC (avg): 0.76322 

Average forward propagation time taken(ms): 3.9468617191798896
Average backward propagation time taken(ms): 1.5133408636207923

