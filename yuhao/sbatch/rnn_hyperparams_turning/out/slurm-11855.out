# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 2)
('lr', 0.0001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-18-38-09/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-18-38-09/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 16,
 'epochs': 50,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 4,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.0001,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 1,
 'num_workers': 8,
 'number_of_mlp_layer': 2,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-17-18-38-09',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 50, 'learning_rate': 0.0001, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=4, bias=True)
    (ReLU1): ReLU()
    (Linear2): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.08068 acc 0.33333 roc_auc 0.36460 prc_auc 0.59698[0m
[93maverage test of epoch 0: loss -0.18369 acc 0.34211 roc_auc 0.29538 prc_auc 0.63862[0m
[92maverage training of epoch 1: loss -0.26995 acc 0.33333 roc_auc 0.39140 prc_auc 0.59264[0m
[93maverage test of epoch 1: loss -0.37357 acc 0.34211 roc_auc 0.26462 prc_auc 0.60933[0m
[92maverage training of epoch 2: loss -0.43582 acc 0.33333 roc_auc 0.52880 prc_auc 0.69662[0m
[93maverage test of epoch 2: loss -0.52477 acc 0.34211 roc_auc 0.26462 prc_auc 0.60931[0m
[92maverage training of epoch 3: loss -0.60092 acc 0.33333 roc_auc 0.53800 prc_auc 0.70254[0m
[93maverage test of epoch 3: loss -0.70744 acc 0.34211 roc_auc 0.28923 prc_auc 0.63378[0m
[92maverage training of epoch 4: loss -0.79847 acc 0.33333 roc_auc 0.54180 prc_auc 0.70587[0m
[93maverage test of epoch 4: loss -0.92307 acc 0.34211 roc_auc 0.27385 prc_auc 0.63004[0m
[92maverage training of epoch 5: loss -1.02981 acc 0.33333 roc_auc 0.53760 prc_auc 0.70331[0m
[93maverage test of epoch 5: loss -1.17389 acc 0.34211 roc_auc 0.26462 prc_auc 0.62040[0m
[92maverage training of epoch 6: loss -1.29721 acc 0.33333 roc_auc 0.52240 prc_auc 0.69310[0m
[93maverage test of epoch 6: loss -1.46201 acc 0.34211 roc_auc 0.16923 prc_auc 0.53651[0m
[92maverage training of epoch 7: loss -1.60351 acc 0.33333 roc_auc 0.49000 prc_auc 0.67514[0m
[93maverage test of epoch 7: loss -1.79111 acc 0.34211 roc_auc 0.12615 prc_auc 0.48627[0m
[92maverage training of epoch 8: loss -1.94636 acc 0.33333 roc_auc 0.43240 prc_auc 0.63872[0m
[93maverage test of epoch 8: loss -2.14633 acc 0.34211 roc_auc 0.12923 prc_auc 0.48907[0m
[92maverage training of epoch 9: loss -2.29589 acc 0.33333 roc_auc 0.35200 prc_auc 0.58336[0m
[93maverage test of epoch 9: loss -2.48750 acc 0.34211 roc_auc 0.12923 prc_auc 0.48907[0m
[92maverage training of epoch 10: loss -2.62528 acc 0.33333 roc_auc 0.26520 prc_auc 0.52966[0m
[93maverage test of epoch 10: loss -2.80843 acc 0.34211 roc_auc 0.13231 prc_auc 0.49041[0m
[92maverage training of epoch 11: loss -2.94141 acc 0.33333 roc_auc 0.18700 prc_auc 0.49944[0m
[93maverage test of epoch 11: loss -3.12267 acc 0.34211 roc_auc 0.13231 prc_auc 0.49041[0m
[92maverage training of epoch 12: loss -3.24990 acc 0.33333 roc_auc 0.18200 prc_auc 0.49715[0m
[93maverage test of epoch 12: loss -3.42407 acc 0.34211 roc_auc 0.13538 prc_auc 0.49118[0m
[92maverage training of epoch 13: loss -3.55182 acc 0.33333 roc_auc 0.17260 prc_auc 0.49510[0m
[93maverage test of epoch 13: loss -3.73019 acc 0.34211 roc_auc 0.13538 prc_auc 0.49118[0m
[92maverage training of epoch 14: loss -3.86486 acc 0.33333 roc_auc 0.18900 prc_auc 0.50167[0m
[93maverage test of epoch 14: loss -4.05170 acc 0.34211 roc_auc 0.13538 prc_auc 0.49118[0m
[92maverage training of epoch 15: loss -4.19949 acc 0.33333 roc_auc 0.24060 prc_auc 0.51875[0m
[93maverage test of epoch 15: loss -4.40221 acc 0.34211 roc_auc 0.14154 prc_auc 0.49269[0m
[92maverage training of epoch 16: loss -4.57119 acc 0.33333 roc_auc 0.29300 prc_auc 0.53564[0m
[93maverage test of epoch 16: loss -4.79632 acc 0.34211 roc_auc 0.13846 prc_auc 0.49190[0m
[92maverage training of epoch 17: loss -4.98167 acc 0.33333 roc_auc 0.23360 prc_auc 0.51411[0m
[93maverage test of epoch 17: loss -5.22191 acc 0.34211 roc_auc 0.13538 prc_auc 0.49114[0m
[92maverage training of epoch 18: loss -5.42048 acc 0.33333 roc_auc 0.31920 prc_auc 0.55064[0m
[93maverage test of epoch 18: loss -5.66822 acc 0.34211 roc_auc 0.13846 prc_auc 0.49475[0m
[92maverage training of epoch 19: loss -5.86386 acc 0.33333 roc_auc 0.33900 prc_auc 0.56530[0m
[93maverage test of epoch 19: loss -6.10695 acc 0.34211 roc_auc 0.14154 prc_auc 0.49523[0m
[92maverage training of epoch 20: loss -6.30206 acc 0.33333 roc_auc 0.36040 prc_auc 0.57888[0m
[93maverage test of epoch 20: loss -6.54275 acc 0.34211 roc_auc 0.13846 prc_auc 0.49235[0m
[92maverage training of epoch 21: loss -6.73962 acc 0.33333 roc_auc 0.37800 prc_auc 0.58924[0m
[93maverage test of epoch 21: loss -6.97975 acc 0.34211 roc_auc 0.13846 prc_auc 0.49446[0m
[92maverage training of epoch 22: loss -7.17971 acc 0.33333 roc_auc 0.38900 prc_auc 0.59888[0m
[93maverage test of epoch 22: loss -7.42000 acc 0.34211 roc_auc 0.13846 prc_auc 0.49446[0m
[92maverage training of epoch 23: loss -7.62307 acc 0.33333 roc_auc 0.39820 prc_auc 0.60713[0m
[93maverage test of epoch 23: loss -7.86320 acc 0.34211 roc_auc 0.13385 prc_auc 0.49084[0m
[92maverage training of epoch 24: loss -8.06970 acc 0.33333 roc_auc 0.40790 prc_auc 0.61555[0m
[93maverage test of epoch 24: loss -8.31022 acc 0.34211 roc_auc 0.13231 prc_auc 0.49858[0m
[92maverage training of epoch 25: loss -8.52057 acc 0.33333 roc_auc 0.41120 prc_auc 0.61855[0m
[93maverage test of epoch 25: loss -8.76152 acc 0.34211 roc_auc 0.13846 prc_auc 0.50634[0m
[92maverage training of epoch 26: loss -8.97620 acc 0.33333 roc_auc 0.41380 prc_auc 0.62046[0m
[93maverage test of epoch 26: loss -9.21804 acc 0.34211 roc_auc 0.16462 prc_auc 0.50545[0m
[92maverage training of epoch 27: loss -9.43784 acc 0.33333 roc_auc 0.41520 prc_auc 0.62144[0m
[93maverage test of epoch 27: loss -9.68116 acc 0.34211 roc_auc 0.16615 prc_auc 0.51301[0m
[92maverage training of epoch 28: loss -9.90666 acc 0.33333 roc_auc 0.41700 prc_auc 0.62269[0m
[93maverage test of epoch 28: loss -10.15199 acc 0.34211 roc_auc 0.17538 prc_auc 0.50711[0m
[92maverage training of epoch 29: loss -10.38369 acc 0.33333 roc_auc 0.41820 prc_auc 0.62380[0m
[93maverage test of epoch 29: loss -10.63130 acc 0.34211 roc_auc 0.70769 prc_auc 0.86611[0m
[92maverage training of epoch 30: loss -10.86956 acc 0.45333 roc_auc 0.41940 prc_auc 0.62513[0m
[93maverage test of epoch 30: loss -11.11949 acc 0.65789 roc_auc 0.85846 prc_auc 0.93318[0m
[92maverage training of epoch 31: loss -11.36469 acc 0.66667 roc_auc 0.41940 prc_auc 0.62513[0m
[93maverage test of epoch 31: loss -11.61687 acc 0.65789 roc_auc 0.86615 prc_auc 0.93301[0m
[92maverage training of epoch 32: loss -11.86935 acc 0.66667 roc_auc 0.41980 prc_auc 0.62604[0m
[93maverage test of epoch 32: loss -12.12432 acc 0.65789 roc_auc 0.86154 prc_auc 0.93301[0m
[92maverage training of epoch 33: loss -12.38402 acc 0.66667 roc_auc 0.42000 prc_auc 0.62613[0m
[93maverage test of epoch 33: loss -12.64135 acc 0.65789 roc_auc 0.86308 prc_auc 0.93352[0m
[92maverage training of epoch 34: loss -12.90835 acc 0.66667 roc_auc 0.42020 prc_auc 0.62629[0m
[93maverage test of epoch 34: loss -13.16774 acc 0.65789 roc_auc 0.86000 prc_auc 0.93114[0m
[92maverage training of epoch 35: loss -13.44212 acc 0.66667 roc_auc 0.42020 prc_auc 0.62629[0m
[93maverage test of epoch 35: loss -13.70411 acc 0.65789 roc_auc 0.85846 prc_auc 0.93146[0m
[92maverage training of epoch 36: loss -13.98650 acc 0.66667 roc_auc 0.42060 prc_auc 0.62654[0m
[93maverage test of epoch 36: loss -14.25102 acc 0.65789 roc_auc 0.86000 prc_auc 0.93164[0m
[92maverage training of epoch 37: loss -14.54125 acc 0.66667 roc_auc 0.42060 prc_auc 0.62654[0m
[93maverage test of epoch 37: loss -14.80822 acc 0.65789 roc_auc 0.85692 prc_auc 0.93120[0m
[92maverage training of epoch 38: loss -15.10660 acc 0.66667 roc_auc 0.42100 prc_auc 0.62689[0m
[93maverage test of epoch 38: loss -15.37573 acc 0.65789 roc_auc 0.86154 prc_auc 0.93462[0m
[92maverage training of epoch 39: loss -15.68230 acc 0.66667 roc_auc 0.42100 prc_auc 0.62689[0m
[93maverage test of epoch 39: loss -15.95365 acc 0.65789 roc_auc 0.86308 prc_auc 0.90692[0m
[92maverage training of epoch 40: loss -16.26856 acc 0.66667 roc_auc 0.42100 prc_auc 0.62689[0m
[93maverage test of epoch 40: loss -16.54249 acc 0.65789 roc_auc 0.85077 prc_auc 0.90783[0m
[92maverage training of epoch 41: loss -16.86646 acc 0.66667 roc_auc 0.42100 prc_auc 0.62689[0m
[93maverage test of epoch 41: loss -17.14302 acc 0.65789 roc_auc 0.88462 prc_auc 0.93679[0m
[92maverage training of epoch 42: loss -17.47610 acc 0.66667 roc_auc 0.42100 prc_auc 0.62689[0m
[93maverage test of epoch 42: loss -17.75518 acc 0.65789 roc_auc 0.90154 prc_auc 0.93165[0m
[92maverage training of epoch 43: loss -18.09700 acc 0.66667 roc_auc 0.42080 prc_auc 0.62680[0m
[93maverage test of epoch 43: loss -18.37834 acc 0.65789 roc_auc 0.82615 prc_auc 0.86936[0m
[92maverage training of epoch 44: loss -18.72973 acc 0.66667 roc_auc 0.42090 prc_auc 0.62680[0m
[93maverage test of epoch 44: loss -19.01417 acc 0.65789 roc_auc 0.72000 prc_auc 0.80842[0m
[92maverage training of epoch 45: loss -19.37491 acc 0.66667 roc_auc 0.42100 prc_auc 0.62697[0m
[93maverage test of epoch 45: loss -19.66179 acc 0.65789 roc_auc 0.80462 prc_auc 0.84026[0m
[92maverage training of epoch 46: loss -20.03245 acc 0.66667 roc_auc 0.42100 prc_auc 0.62697[0m
[93maverage test of epoch 46: loss -20.32215 acc 0.65789 roc_auc 0.80462 prc_auc 0.84026[0m
[92maverage training of epoch 47: loss -20.70274 acc 0.66667 roc_auc 0.42100 prc_auc 0.62697[0m
[93maverage test of epoch 47: loss -20.99513 acc 0.65789 roc_auc 0.78154 prc_auc 0.83920[0m
[92maverage training of epoch 48: loss -21.38591 acc 0.66667 roc_auc 0.42110 prc_auc 0.62697[0m
[93maverage test of epoch 48: loss -21.68099 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -22.08214 acc 0.66667 roc_auc 0.42100 prc_auc 0.62697[0m
[93maverage test of epoch 49: loss -22.37978 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=4, bias=True)
    (ReLU1): ReLU()
    (Linear2): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.01522 acc 0.38667 roc_auc 0.46940 prc_auc 0.65566[0m
[93maverage test of epoch 0: loss -0.14286 acc 0.65789 roc_auc 0.59692 prc_auc 0.80720[0m
[92maverage training of epoch 1: loss -0.18582 acc 0.66667 roc_auc 0.47620 prc_auc 0.65786[0m
[93maverage test of epoch 1: loss -0.32393 acc 0.65789 roc_auc 0.54462 prc_auc 0.79781[0m
[92maverage training of epoch 2: loss -0.39266 acc 0.66667 roc_auc 0.47460 prc_auc 0.65548[0m
[93maverage test of epoch 2: loss -0.55366 acc 0.65789 roc_auc 0.56308 prc_auc 0.81597[0m
[92maverage training of epoch 3: loss -0.65512 acc 0.66667 roc_auc 0.47400 prc_auc 0.66016[0m
[93maverage test of epoch 3: loss -0.83620 acc 0.65789 roc_auc 0.63692 prc_auc 0.84004[0m
[92maverage training of epoch 4: loss -0.96022 acc 0.66667 roc_auc 0.47560 prc_auc 0.66471[0m
[93maverage test of epoch 4: loss -1.14731 acc 0.65789 roc_auc 0.70462 prc_auc 0.87175[0m
[92maverage training of epoch 5: loss -1.28354 acc 0.66667 roc_auc 0.48020 prc_auc 0.66631[0m
[93maverage test of epoch 5: loss -1.46865 acc 0.65789 roc_auc 0.68308 prc_auc 0.86501[0m
[92maverage training of epoch 6: loss -1.61169 acc 0.66667 roc_auc 0.48800 prc_auc 0.67192[0m
[93maverage test of epoch 6: loss -1.79126 acc 0.65789 roc_auc 0.76154 prc_auc 0.88627[0m
[92maverage training of epoch 7: loss -1.94182 acc 0.66667 roc_auc 0.49300 prc_auc 0.67444[0m
[93maverage test of epoch 7: loss -2.11480 acc 0.65789 roc_auc 0.86769 prc_auc 0.92382[0m
[92maverage training of epoch 8: loss -2.27485 acc 0.66667 roc_auc 0.49400 prc_auc 0.67691[0m
[93maverage test of epoch 8: loss -2.44280 acc 0.65789 roc_auc 0.86615 prc_auc 0.92241[0m
[92maverage training of epoch 9: loss -2.61303 acc 0.66667 roc_auc 0.49240 prc_auc 0.67500[0m
[93maverage test of epoch 9: loss -2.77850 acc 0.65789 roc_auc 0.86462 prc_auc 0.92428[0m
[92maverage training of epoch 10: loss -2.96149 acc 0.66667 roc_auc 0.49080 prc_auc 0.67406[0m
[93maverage test of epoch 10: loss -3.12838 acc 0.65789 roc_auc 0.86769 prc_auc 0.92607[0m
[92maverage training of epoch 11: loss -3.32948 acc 0.66667 roc_auc 0.49010 prc_auc 0.67164[0m
[93maverage test of epoch 11: loss -3.50358 acc 0.65789 roc_auc 0.86615 prc_auc 0.92355[0m
[92maverage training of epoch 12: loss -3.73059 acc 0.66667 roc_auc 0.49060 prc_auc 0.67189[0m
[93maverage test of epoch 12: loss -3.91904 acc 0.65789 roc_auc 0.86000 prc_auc 0.91782[0m
[92maverage training of epoch 13: loss -4.18068 acc 0.66667 roc_auc 0.49580 prc_auc 0.67761[0m
[93maverage test of epoch 13: loss -4.39012 acc 0.65789 roc_auc 0.85846 prc_auc 0.91915[0m
[92maverage training of epoch 14: loss -4.69264 acc 0.66667 roc_auc 0.51780 prc_auc 0.69910[0m
[93maverage test of epoch 14: loss -4.92904 acc 0.65789 roc_auc 0.85846 prc_auc 0.91976[0m
[92maverage training of epoch 15: loss -5.27224 acc 0.66667 roc_auc 0.56700 prc_auc 0.74984[0m
[93maverage test of epoch 15: loss -5.52622 acc 0.65789 roc_auc 0.86308 prc_auc 0.91770[0m
[92maverage training of epoch 16: loss -5.87692 acc 0.66667 roc_auc 0.61870 prc_auc 0.78413[0m
[93maverage test of epoch 16: loss -6.08864 acc 0.65789 roc_auc 0.88154 prc_auc 0.92833[0m
[92maverage training of epoch 17: loss -6.42435 acc 0.66667 roc_auc 0.64470 prc_auc 0.78483[0m
[93maverage test of epoch 17: loss -6.58629 acc 0.65789 roc_auc 0.86615 prc_auc 0.90675[0m
[92maverage training of epoch 18: loss -6.92231 acc 0.66667 roc_auc 0.62620 prc_auc 0.75736[0m
[93maverage test of epoch 18: loss -7.06213 acc 0.65789 roc_auc 0.80769 prc_auc 0.83333[0m
[92maverage training of epoch 19: loss -7.40630 acc 0.66667 roc_auc 0.58020 prc_auc 0.72079[0m
[93maverage test of epoch 19: loss -7.53638 acc 0.65789 roc_auc 0.80769 prc_auc 0.83333[0m
[92maverage training of epoch 20: loss -7.89099 acc 0.66667 roc_auc 0.56230 prc_auc 0.69584[0m
[93maverage test of epoch 20: loss -8.01627 acc 0.65789 roc_auc 0.74615 prc_auc 0.79825[0m
[92maverage training of epoch 21: loss -8.38198 acc 0.66667 roc_auc 0.56500 prc_auc 0.69691[0m
[93maverage test of epoch 21: loss -8.50419 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -8.88100 acc 0.66667 roc_auc 0.50500 prc_auc 0.66890[0m
[93maverage test of epoch 22: loss -9.00071 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -9.38861 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 23: loss -9.50608 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -9.90506 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 24: loss -10.02042 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -10.43082 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 25: loss -10.54442 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -10.96664 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 26: loss -11.07872 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -11.51314 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 27: loss -11.62392 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -12.07092 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 28: loss -12.18062 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -12.64063 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 29: loss -12.74946 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -13.22297 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 30: loss -13.33123 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -13.81830 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 31: loss -13.92364 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -14.41999 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 32: loss -14.52172 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -15.03162 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 33: loss -15.13225 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -15.65628 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -15.75614 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -16.29481 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -16.39417 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -16.94799 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -17.04706 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -17.61652 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -17.71551 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -18.30108 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -18.40016 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -19.00231 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -19.10167 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -19.72087 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -19.82066 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -20.45738 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -20.55776 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -21.21247 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -21.31358 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -21.98676 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -22.08876 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -22.78088 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -22.88389 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -23.59543 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -23.69959 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -24.43102 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -24.53645 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -25.28827 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -25.39508 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -26.16777 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -26.27606 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -27.07010 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -27.17997 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=4, bias=True)
    (ReLU1): ReLU()
    (Linear2): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -1.01326 acc 0.33333 roc_auc 0.31380 prc_auc 0.55185[0m
[93maverage test of epoch 0: loss -1.19369 acc 0.34211 roc_auc 0.06154 prc_auc 0.46892[0m
[92maverage training of epoch 1: loss -1.32963 acc 0.33333 roc_auc 0.30660 prc_auc 0.54241[0m
[93maverage test of epoch 1: loss -1.50568 acc 0.34211 roc_auc 0.07077 prc_auc 0.47025[0m
[92maverage training of epoch 2: loss -1.64787 acc 0.33333 roc_auc 0.29800 prc_auc 0.54107[0m
[93maverage test of epoch 2: loss -1.83290 acc 0.34211 roc_auc 0.06462 prc_auc 0.46814[0m
[92maverage training of epoch 3: loss -1.99362 acc 0.33333 roc_auc 0.29620 prc_auc 0.54680[0m
[93maverage test of epoch 3: loss -2.20082 acc 0.34211 roc_auc 0.06769 prc_auc 0.47081[0m
[92maverage training of epoch 4: loss -2.39185 acc 0.33333 roc_auc 0.31240 prc_auc 0.55589[0m
[93maverage test of epoch 4: loss -2.63034 acc 0.34211 roc_auc 0.07692 prc_auc 0.47492[0m
[92maverage training of epoch 5: loss -2.85270 acc 0.33333 roc_auc 0.32560 prc_auc 0.55923[0m
[93maverage test of epoch 5: loss -3.11843 acc 0.34211 roc_auc 0.37385 prc_auc 0.71460[0m
[92maverage training of epoch 6: loss -3.35790 acc 0.33333 roc_auc 0.37380 prc_auc 0.59521[0m
[93maverage test of epoch 6: loss -3.63295 acc 0.34211 roc_auc 0.55385 prc_auc 0.80663[0m
[92maverage training of epoch 7: loss -3.87398 acc 0.33333 roc_auc 0.38440 prc_auc 0.60226[0m
[93maverage test of epoch 7: loss -4.13997 acc 0.34211 roc_auc 0.23077 prc_auc 0.57699[0m
[92maverage training of epoch 8: loss -4.36071 acc 0.33333 roc_auc 0.37860 prc_auc 0.59661[0m
[93maverage test of epoch 8: loss -4.60503 acc 0.34211 roc_auc 0.08000 prc_auc 0.50100[0m
[92maverage training of epoch 9: loss -4.81619 acc 0.33333 roc_auc 0.38250 prc_auc 0.59636[0m
[93maverage test of epoch 9: loss -5.05092 acc 0.34211 roc_auc 0.12308 prc_auc 0.53888[0m
[92maverage training of epoch 10: loss -5.25828 acc 0.33333 roc_auc 0.38380 prc_auc 0.59239[0m
[93maverage test of epoch 10: loss -5.48858 acc 0.34211 roc_auc 0.09385 prc_auc 0.48045[0m
[92maverage training of epoch 11: loss -5.69613 acc 0.33333 roc_auc 0.38360 prc_auc 0.59212[0m
[93maverage test of epoch 11: loss -5.92461 acc 0.34211 roc_auc 0.47077 prc_auc 0.75540[0m
[92maverage training of epoch 12: loss -6.13416 acc 0.33333 roc_auc 0.38600 prc_auc 0.59485[0m
[93maverage test of epoch 12: loss -6.36244 acc 0.34211 roc_auc 0.60769 prc_auc 0.82404[0m
[92maverage training of epoch 13: loss -6.57490 acc 0.33333 roc_auc 0.38720 prc_auc 0.59540[0m
[93maverage test of epoch 13: loss -6.80392 acc 0.34211 roc_auc 0.59692 prc_auc 0.81555[0m
[92maverage training of epoch 14: loss -7.02003 acc 0.33333 roc_auc 0.38940 prc_auc 0.59133[0m
[93maverage test of epoch 14: loss -7.25033 acc 0.34211 roc_auc 0.16923 prc_auc 0.52242[0m
[92maverage training of epoch 15: loss -7.47071 acc 0.33333 roc_auc 0.38940 prc_auc 0.59684[0m
[93maverage test of epoch 15: loss -7.70313 acc 0.34211 roc_auc 0.72923 prc_auc 0.88097[0m
[92maverage training of epoch 16: loss -7.92785 acc 0.33333 roc_auc 0.38980 prc_auc 0.59760[0m
[93maverage test of epoch 16: loss -8.16271 acc 0.34211 roc_auc 0.52615 prc_auc 0.77629[0m
[92maverage training of epoch 17: loss -8.39233 acc 0.33333 roc_auc 0.39140 prc_auc 0.59897[0m
[93maverage test of epoch 17: loss -8.62998 acc 0.34211 roc_auc 0.61538 prc_auc 0.82806[0m
[92maverage training of epoch 18: loss -8.86462 acc 0.58000 roc_auc 0.39200 prc_auc 0.59926[0m
[93maverage test of epoch 18: loss -9.10539 acc 0.65789 roc_auc 0.52923 prc_auc 0.78766[0m
[92maverage training of epoch 19: loss -9.34539 acc 0.66667 roc_auc 0.39280 prc_auc 0.60047[0m
[93maverage test of epoch 19: loss -9.58972 acc 0.65789 roc_auc 0.68462 prc_auc 0.85732[0m
[92maverage training of epoch 20: loss -9.83536 acc 0.66667 roc_auc 0.39280 prc_auc 0.60058[0m
[93maverage test of epoch 20: loss -10.08342 acc 0.65789 roc_auc 0.61692 prc_auc 0.81846[0m
[92maverage training of epoch 21: loss -10.33488 acc 0.66667 roc_auc 0.39300 prc_auc 0.60055[0m
[93maverage test of epoch 21: loss -10.58702 acc 0.65789 roc_auc 0.52000 prc_auc 0.76828[0m
[92maverage training of epoch 22: loss -10.84464 acc 0.66667 roc_auc 0.39340 prc_auc 0.60101[0m
[93maverage test of epoch 22: loss -11.10112 acc 0.65789 roc_auc 0.85846 prc_auc 0.93074[0m
[92maverage training of epoch 23: loss -11.36508 acc 0.66667 roc_auc 0.39500 prc_auc 0.60359[0m
[93maverage test of epoch 23: loss -11.62626 acc 0.65789 roc_auc 0.90769 prc_auc 0.95576[0m
[92maverage training of epoch 24: loss -11.89686 acc 0.66667 roc_auc 0.39520 prc_auc 0.60288[0m
[93maverage test of epoch 24: loss -12.16299 acc 0.65789 roc_auc 0.81846 prc_auc 0.91253[0m
[92maverage training of epoch 25: loss -12.44051 acc 0.66667 roc_auc 0.39600 prc_auc 0.60346[0m
[93maverage test of epoch 25: loss -12.71174 acc 0.65789 roc_auc 0.88923 prc_auc 0.93189[0m
[92maverage training of epoch 26: loss -12.99654 acc 0.66667 roc_auc 0.39720 prc_auc 0.60403[0m
[93maverage test of epoch 26: loss -13.27326 acc 0.65789 roc_auc 0.52154 prc_auc 0.75222[0m
[92maverage training of epoch 27: loss -13.56551 acc 0.66667 roc_auc 0.39760 prc_auc 0.60440[0m
[93maverage test of epoch 27: loss -13.84788 acc 0.65789 roc_auc 0.49692 prc_auc 0.70840[0m
[92maverage training of epoch 28: loss -14.14792 acc 0.66667 roc_auc 0.39780 prc_auc 0.60492[0m
[93maverage test of epoch 28: loss -14.43631 acc 0.65789 roc_auc 0.86615 prc_auc 0.90976[0m
[92maverage training of epoch 29: loss -14.74456 acc 0.66667 roc_auc 0.39900 prc_auc 0.60620[0m
[93maverage test of epoch 29: loss -15.03917 acc 0.65789 roc_auc 0.70769 prc_auc 0.79859[0m
[92maverage training of epoch 30: loss -15.35577 acc 0.66667 roc_auc 0.39940 prc_auc 0.60701[0m
[93maverage test of epoch 30: loss -15.65695 acc 0.65789 roc_auc 0.77538 prc_auc 0.84748[0m
[92maverage training of epoch 31: loss -15.98235 acc 0.66667 roc_auc 0.40140 prc_auc 0.60829[0m
[93maverage test of epoch 31: loss -16.29036 acc 0.65789 roc_auc 0.51538 prc_auc 0.66589[0m
[92maverage training of epoch 32: loss -16.62497 acc 0.66667 roc_auc 0.40220 prc_auc 0.60880[0m
[93maverage test of epoch 32: loss -16.94012 acc 0.65789 roc_auc 0.44000 prc_auc 0.66155[0m
[92maverage training of epoch 33: loss -17.28450 acc 0.66667 roc_auc 0.40320 prc_auc 0.61018[0m
[93maverage test of epoch 33: loss -17.60750 acc 0.65789 roc_auc 0.22769 prc_auc 0.56568[0m
[92maverage training of epoch 34: loss -17.96257 acc 0.66667 roc_auc 0.40420 prc_auc 0.60940[0m
[93maverage test of epoch 34: loss -18.29459 acc 0.65789 roc_auc 0.38462 prc_auc 0.61224[0m
[92maverage training of epoch 35: loss -18.66188 acc 0.66667 roc_auc 0.40760 prc_auc 0.61191[0m
[93maverage test of epoch 35: loss -19.00444 acc 0.65789 roc_auc 0.40154 prc_auc 0.63140[0m
[92maverage training of epoch 36: loss -19.38564 acc 0.66667 roc_auc 0.41000 prc_auc 0.61381[0m
[93maverage test of epoch 36: loss -19.74031 acc 0.65789 roc_auc 0.24000 prc_auc 0.55793[0m
[92maverage training of epoch 37: loss -20.13676 acc 0.66667 roc_auc 0.41290 prc_auc 0.61589[0m
[93maverage test of epoch 37: loss -20.50424 acc 0.65789 roc_auc 0.24000 prc_auc 0.55311[0m
[92maverage training of epoch 38: loss -20.91554 acc 0.66667 roc_auc 0.41740 prc_auc 0.61817[0m
[93maverage test of epoch 38: loss -21.29500 acc 0.65789 roc_auc 0.20154 prc_auc 0.58073[0m
[92maverage training of epoch 39: loss -21.72023 acc 0.66667 roc_auc 0.42000 prc_auc 0.62152[0m
[93maverage test of epoch 39: loss -22.11029 acc 0.65789 roc_auc 0.15538 prc_auc 0.57186[0m
[92maverage training of epoch 40: loss -22.54815 acc 0.66667 roc_auc 0.42160 prc_auc 0.62323[0m
[93maverage test of epoch 40: loss -22.94746 acc 0.65789 roc_auc 0.14923 prc_auc 0.56716[0m
[92maverage training of epoch 41: loss -23.39720 acc 0.66667 roc_auc 0.42420 prc_auc 0.62530[0m
[93maverage test of epoch 41: loss -23.80506 acc 0.65789 roc_auc 0.44000 prc_auc 0.72500[0m
[92maverage training of epoch 42: loss -24.26645 acc 0.66667 roc_auc 0.42580 prc_auc 0.62680[0m
[93maverage test of epoch 42: loss -24.68270 acc 0.65789 roc_auc 0.71231 prc_auc 0.86056[0m
[92maverage training of epoch 43: loss -25.15590 acc 0.66667 roc_auc 0.42720 prc_auc 0.62832[0m
[93maverage test of epoch 43: loss -25.58061 acc 0.65789 roc_auc 0.78462 prc_auc 0.86918[0m
[92maverage training of epoch 44: loss -26.06588 acc 0.66667 roc_auc 0.42820 prc_auc 0.62949[0m
[93maverage test of epoch 44: loss -26.49916 acc 0.65789 roc_auc 0.84000 prc_auc 0.89053[0m
[92maverage training of epoch 45: loss -26.99675 acc 0.66667 roc_auc 0.42900 prc_auc 0.62907[0m
[93maverage test of epoch 45: loss -27.43878 acc 0.65789 roc_auc 0.87077 prc_auc 0.90919[0m
[92maverage training of epoch 46: loss -27.94903 acc 0.66667 roc_auc 0.43020 prc_auc 0.63057[0m
[93maverage test of epoch 46: loss -28.39995 acc 0.65789 roc_auc 0.86000 prc_auc 0.90421[0m
[92maverage training of epoch 47: loss -28.92316 acc 0.66667 roc_auc 0.43100 prc_auc 0.63182[0m
[93maverage test of epoch 47: loss -29.38313 acc 0.65789 roc_auc 0.86000 prc_auc 0.90421[0m
[92maverage training of epoch 48: loss -29.91958 acc 0.66667 roc_auc 0.43100 prc_auc 0.63172[0m
[93maverage test of epoch 48: loss -30.38872 acc 0.65789 roc_auc 0.78000 prc_auc 0.84947[0m
[92maverage training of epoch 49: loss -30.93870 acc 0.66667 roc_auc 0.43150 prc_auc 0.63201[0m
[93maverage test of epoch 49: loss -31.41711 acc 0.65789 roc_auc 0.68615 prc_auc 0.77946[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=4, bias=True)
    (ReLU1): ReLU()
    (Linear2): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.60806 acc 0.66225 roc_auc 0.39373 prc_auc 0.57764[0m
[93maverage test of epoch 0: loss -0.66078 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 1: loss -0.67567 acc 0.66225 roc_auc 0.38510 prc_auc 0.57569[0m
[93maverage test of epoch 1: loss -0.72693 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 2: loss -0.74207 acc 0.66225 roc_auc 0.38529 prc_auc 0.57613[0m
[93maverage test of epoch 2: loss -0.79401 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 3: loss -0.80942 acc 0.66225 roc_auc 0.38490 prc_auc 0.57636[0m
[93maverage test of epoch 3: loss -0.86205 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 4: loss -0.87771 acc 0.66225 roc_auc 0.38549 prc_auc 0.57722[0m
[93maverage test of epoch 4: loss -0.93104 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 5: loss -0.94696 acc 0.66225 roc_auc 0.38569 prc_auc 0.57724[0m
[93maverage test of epoch 5: loss -1.00101 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 6: loss -1.01719 acc 0.66225 roc_auc 0.38520 prc_auc 0.57694[0m
[93maverage test of epoch 6: loss -1.07196 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 7: loss -1.08840 acc 0.66225 roc_auc 0.38647 prc_auc 0.57807[0m
[93maverage test of epoch 7: loss -1.14391 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 8: loss -1.16061 acc 0.66225 roc_auc 0.38755 prc_auc 0.57904[0m
[93maverage test of epoch 8: loss -1.21687 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 9: loss -1.23382 acc 0.66225 roc_auc 0.38843 prc_auc 0.57998[0m
[93maverage test of epoch 9: loss -1.29084 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 10: loss -1.30804 acc 0.66225 roc_auc 0.38912 prc_auc 0.58063[0m
[93maverage test of epoch 10: loss -1.36582 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 11: loss -1.38327 acc 0.66225 roc_auc 0.38922 prc_auc 0.58088[0m
[93maverage test of epoch 11: loss -1.44182 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 12: loss -1.45952 acc 0.66225 roc_auc 0.39000 prc_auc 0.58146[0m
[93maverage test of epoch 12: loss -1.51884 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 13: loss -1.53678 acc 0.66225 roc_auc 0.39039 prc_auc 0.58236[0m
[93maverage test of epoch 13: loss -1.59688 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 14: loss -1.61506 acc 0.66225 roc_auc 0.39108 prc_auc 0.58239[0m
[93maverage test of epoch 14: loss -1.67595 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 15: loss -1.69435 acc 0.66225 roc_auc 0.39176 prc_auc 0.58313[0m
[93maverage test of epoch 15: loss -1.75604 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 16: loss -1.77468 acc 0.66225 roc_auc 0.39235 prc_auc 0.58375[0m
[93maverage test of epoch 16: loss -1.83717 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 17: loss -1.85603 acc 0.66225 roc_auc 0.39373 prc_auc 0.58467[0m
[93maverage test of epoch 17: loss -1.91933 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 18: loss -1.93841 acc 0.66225 roc_auc 0.39431 prc_auc 0.58467[0m
[93maverage test of epoch 18: loss -2.00253 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 19: loss -2.02183 acc 0.66225 roc_auc 0.39480 prc_auc 0.58514[0m
[93maverage test of epoch 19: loss -2.08679 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 20: loss -2.10631 acc 0.66225 roc_auc 0.39549 prc_auc 0.58583[0m
[93maverage test of epoch 20: loss -2.17210 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 21: loss -2.19185 acc 0.66225 roc_auc 0.39618 prc_auc 0.58615[0m
[93maverage test of epoch 21: loss -2.25850 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 22: loss -2.27848 acc 0.66225 roc_auc 0.39657 prc_auc 0.58604[0m
[93maverage test of epoch 22: loss -2.34600 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 23: loss -2.37151 acc 0.66225 roc_auc 0.40333 prc_auc 0.59341[0m
[93maverage test of epoch 23: loss -2.58713 acc 0.67568 roc_auc 0.86333 prc_auc 0.92515[0m
[92maverage training of epoch 24: loss -3.25281 acc 0.66225 roc_auc 0.44961 prc_auc 0.63073[0m
[93maverage test of epoch 24: loss -3.78598 acc 0.67568 roc_auc 0.86333 prc_auc 0.92301[0m
[92maverage training of epoch 25: loss -4.13847 acc 0.66225 roc_auc 0.45784 prc_auc 0.64291[0m
[93maverage test of epoch 25: loss -4.54852 acc 0.67568 roc_auc 0.85833 prc_auc 0.92140[0m
[92maverage training of epoch 26: loss -4.93519 acc 0.66225 roc_auc 0.45951 prc_auc 0.64332[0m
[93maverage test of epoch 26: loss -5.43752 acc 0.67568 roc_auc 0.86000 prc_auc 0.92243[0m
[92maverage training of epoch 27: loss -5.87487 acc 0.66225 roc_auc 0.45765 prc_auc 0.63799[0m
[93maverage test of epoch 27: loss -6.39547 acc 0.67568 roc_auc 0.86000 prc_auc 0.92261[0m
[92maverage training of epoch 28: loss -6.81189 acc 0.66225 roc_auc 0.45196 prc_auc 0.63043[0m
[93maverage test of epoch 28: loss -7.33576 acc 0.67568 roc_auc 0.86000 prc_auc 0.92286[0m
[92maverage training of epoch 29: loss -7.75338 acc 0.66225 roc_auc 0.44882 prc_auc 0.62935[0m
[93maverage test of epoch 29: loss -8.30220 acc 0.67568 roc_auc 0.85667 prc_auc 0.91696[0m
[92maverage training of epoch 30: loss -8.75084 acc 0.66225 roc_auc 0.44627 prc_auc 0.62737[0m
[93maverage test of epoch 30: loss -9.34346 acc 0.67568 roc_auc 0.81333 prc_auc 0.90157[0m
[92maverage training of epoch 31: loss -9.79253 acc 0.66225 roc_auc 0.44490 prc_auc 0.62682[0m
[93maverage test of epoch 31: loss -10.38490 acc 0.67568 roc_auc 0.81000 prc_auc 0.89162[0m
[92maverage training of epoch 32: loss -10.81388 acc 0.66225 roc_auc 0.44529 prc_auc 0.62693[0m
[93maverage test of epoch 32: loss -11.39997 acc 0.67568 roc_auc 0.81333 prc_auc 0.89198[0m
[92maverage training of epoch 33: loss -11.81510 acc 0.66225 roc_auc 0.44588 prc_auc 0.62751[0m
[93maverage test of epoch 33: loss -12.40000 acc 0.67568 roc_auc 0.85167 prc_auc 0.91049[0m
[92maverage training of epoch 34: loss -12.80543 acc 0.66225 roc_auc 0.44588 prc_auc 0.62751[0m
[93maverage test of epoch 34: loss -13.39245 acc 0.67568 roc_auc 0.86000 prc_auc 0.91827[0m
[92maverage training of epoch 35: loss -13.79136 acc 0.66225 roc_auc 0.44549 prc_auc 0.62699[0m
[93maverage test of epoch 35: loss -14.38351 acc 0.67568 roc_auc 0.85500 prc_auc 0.91098[0m
[92maverage training of epoch 36: loss -14.77874 acc 0.66225 roc_auc 0.44529 prc_auc 0.62693[0m
[93maverage test of epoch 36: loss -15.37854 acc 0.67568 roc_auc 0.88000 prc_auc 0.92024[0m
[92maverage training of epoch 37: loss -15.77219 acc 0.66225 roc_auc 0.44529 prc_auc 0.62693[0m
[93maverage test of epoch 37: loss -16.38178 acc 0.67568 roc_auc 0.87000 prc_auc 0.90108[0m
[92maverage training of epoch 38: loss -16.77585 acc 0.66225 roc_auc 0.44510 prc_auc 0.62687[0m
[93maverage test of epoch 38: loss -17.39727 acc 0.67568 roc_auc 0.84000 prc_auc 0.87252[0m
[92maverage training of epoch 39: loss -17.79339 acc 0.66225 roc_auc 0.44490 prc_auc 0.62681[0m
[93maverage test of epoch 39: loss -18.42839 acc 0.67568 roc_auc 0.58000 prc_auc 0.71644[0m
[92maverage training of epoch 40: loss -18.82788 acc 0.66225 roc_auc 0.44451 prc_auc 0.62623[0m
[93maverage test of epoch 40: loss -19.47790 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 41: loss -19.88160 acc 0.66225 roc_auc 0.44441 prc_auc 0.62599[0m
[93maverage test of epoch 41: loss -20.54761 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 42: loss -20.95633 acc 0.66225 roc_auc 0.44412 prc_auc 0.62586[0m
[93maverage test of epoch 42: loss -21.63948 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 43: loss -22.05398 acc 0.66225 roc_auc 0.44353 prc_auc 0.62507[0m
[93maverage test of epoch 43: loss -22.75528 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 44: loss -23.17622 acc 0.66225 roc_auc 0.44235 prc_auc 0.62400[0m
[93maverage test of epoch 44: loss -23.89661 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 45: loss -24.32452 acc 0.66225 roc_auc 0.44196 prc_auc 0.62548[0m
[93maverage test of epoch 45: loss -25.06482 acc 0.67568 roc_auc 0.84000 prc_auc 0.87854[0m
[92maverage training of epoch 46: loss -25.50016 acc 0.66225 roc_auc 0.44147 prc_auc 0.62331[0m
[93maverage test of epoch 46: loss -26.26116 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 47: loss -26.70435 acc 0.66225 roc_auc 0.44176 prc_auc 0.62693[0m
[93maverage test of epoch 47: loss -27.48676 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 48: loss -27.93812 acc 0.66225 roc_auc 0.44000 prc_auc 0.62761[0m
[93maverage test of epoch 48: loss -28.74262 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 49: loss -29.20247 acc 0.66225 roc_auc 0.44059 prc_auc 0.62880[0m
[93maverage test of epoch 49: loss -30.02972 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=4, bias=True)
    (ReLU1): ReLU()
    (Linear2): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss 0.51117 acc 0.33775 roc_auc 0.40314 prc_auc 0.60173[0m
[93maverage test of epoch 0: loss 0.44366 acc 0.32432 roc_auc 0.06667 prc_auc 0.48798[0m
[92maverage training of epoch 1: loss 0.37042 acc 0.33775 roc_auc 0.41353 prc_auc 0.62170[0m
[93maverage test of epoch 1: loss 0.31360 acc 0.32432 roc_auc 0.49000 prc_auc 0.78593[0m
[92maverage training of epoch 2: loss 0.24638 acc 0.33775 roc_auc 0.42686 prc_auc 0.62792[0mUsing backend: pytorch
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))

[93maverage test of epoch 2: loss 0.19641 acc 0.32432 roc_auc 0.60000 prc_auc 0.83100[0m
[92maverage training of epoch 3: loss 0.13997 acc 0.33775 roc_auc 0.43235 prc_auc 0.63376[0m
[93maverage test of epoch 3: loss 0.09409 acc 0.32432 roc_auc 0.66667 prc_auc 0.86812[0m
[92maverage training of epoch 4: loss 0.04494 acc 0.33775 roc_auc 0.43588 prc_auc 0.64033[0m
[93maverage test of epoch 4: loss 0.00101 acc 0.32432 roc_auc 0.64333 prc_auc 0.86044[0m
[92maverage training of epoch 5: loss -0.04081 acc 0.33775 roc_auc 0.42176 prc_auc 0.62449[0m
[93maverage test of epoch 5: loss -0.07392 acc 0.48649 roc_auc 0.69333 prc_auc 0.88157[0m
[92maverage training of epoch 6: loss -0.08747 acc 0.62914 roc_auc 0.43000 prc_auc 0.63007[0m
[93maverage test of epoch 6: loss -0.10514 acc 0.67568 roc_auc 0.68000 prc_auc 0.87315[0m
[92maverage training of epoch 7: loss -0.11775 acc 0.66225 roc_auc 0.42784 prc_auc 0.63320[0m
[93maverage test of epoch 7: loss -0.13606 acc 0.67568 roc_auc 0.68000 prc_auc 0.87654[0m
[92maverage training of epoch 8: loss -0.14777 acc 0.66225 roc_auc 0.43235 prc_auc 0.63701[0m
[93maverage test of epoch 8: loss -0.16657 acc 0.67568 roc_auc 0.65333 prc_auc 0.86448[0m
[92maverage training of epoch 9: loss -0.17729 acc 0.66225 roc_auc 0.42686 prc_auc 0.63864[0m
[93maverage test of epoch 9: loss -0.19693 acc 0.67568 roc_auc 0.66833 prc_auc 0.86989[0m
[92maverage training of epoch 10: loss -0.20663 acc 0.66225 roc_auc 0.43176 prc_auc 0.64255[0m
[93maverage test of epoch 10: loss -0.22698 acc 0.67568 roc_auc 0.68167 prc_auc 0.87315[0m
[92maverage training of epoch 11: loss -0.23585 acc 0.66225 roc_auc 0.43510 prc_auc 0.64284[0m
[93maverage test of epoch 11: loss -0.25757 acc 0.67568 roc_auc 0.70667 prc_auc 0.88957[0m
[92maverage training of epoch 12: loss -0.26525 acc 0.66225 roc_auc 0.43902 prc_auc 0.64654[0m
[93maverage test of epoch 12: loss -0.28853 acc 0.67568 roc_auc 0.78833 prc_auc 0.92120[0m
[92maverage training of epoch 13: loss -0.29548 acc 0.66225 roc_auc 0.44490 prc_auc 0.65124[0m
[93maverage test of epoch 13: loss -0.32046 acc 0.67568 roc_auc 0.82333 prc_auc 0.93244[0m
[92maverage training of epoch 14: loss -0.32825 acc 0.66225 roc_auc 0.44235 prc_auc 0.64584[0m
[93maverage test of epoch 14: loss -0.36148 acc 0.67568 roc_auc 0.84000 prc_auc 0.94076[0m
[92maverage training of epoch 15: loss -0.36867 acc 0.66225 roc_auc 0.38137 prc_auc 0.56939[0m
[93maverage test of epoch 15: loss -0.39335 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 16: loss -0.38690 acc 0.66225 roc_auc 0.36961 prc_auc 0.56815[0m
[93maverage test of epoch 16: loss -0.40450 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 17: loss -0.39800 acc 0.66225 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 17: loss -0.41564 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 18: loss -0.40910 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 18: loss -0.42679 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 19: loss -0.42020 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 19: loss -0.43793 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 20: loss -0.43130 acc 0.66225 roc_auc 0.36980 prc_auc 0.56827[0m
[93maverage test of epoch 20: loss -0.44908 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 21: loss -0.44240 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 21: loss -0.46022 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 22: loss -0.45349 acc 0.66225 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 22: loss -0.47137 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 23: loss -0.46459 acc 0.66225 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 23: loss -0.48251 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 24: loss -0.47569 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 24: loss -0.49366 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 25: loss -0.48679 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 25: loss -0.50480 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 26: loss -0.49788 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 26: loss -0.51595 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 27: loss -0.50898 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 27: loss -0.52709 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 28: loss -0.52008 acc 0.66225 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 28: loss -0.53824 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 29: loss -0.53118 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 29: loss -0.54938 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 30: loss -0.54228 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 30: loss -0.56053 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 31: loss -0.55337 acc 0.66225 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 31: loss -0.57167 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 32: loss -0.56447 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 32: loss -0.58282 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 33: loss -0.57557 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 33: loss -0.59396 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 34: loss -0.58667 acc 0.66225 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 34: loss -0.60511 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 35: loss -0.59777 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 35: loss -0.61625 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 36: loss -0.60886 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 36: loss -0.62740 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 37: loss -0.61996 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 37: loss -0.63854 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 38: loss -0.63106 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 38: loss -0.64969 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 39: loss -0.64216 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 39: loss -0.66084 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -0.65326 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 40: loss -0.67198 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -0.66435 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 41: loss -0.68313 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -0.67545 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 42: loss -0.69427 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -0.68655 acc 0.66225 roc_auc 0.36971 prc_auc 0.56810[0m
[93maverage test of epoch 43: loss -0.70542 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -0.69765 acc 0.66225 roc_auc 0.36971 prc_auc 0.56810[0m
[93maverage test of epoch 44: loss -0.71656 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -0.70875 acc 0.66225 roc_auc 0.36971 prc_auc 0.56810[0m
[93maverage test of epoch 45: loss -0.72771 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -0.71984 acc 0.66225 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 46: loss -0.73885 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -0.73094 acc 0.66225 roc_auc 0.36971 prc_auc 0.56810[0m
[93maverage test of epoch 47: loss -0.75000 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -0.74204 acc 0.66225 roc_auc 0.36971 prc_auc 0.56810[0m
[93maverage test of epoch 48: loss -0.76114 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -0.75314 acc 0.66225 roc_auc 0.36971 prc_auc 0.56810[0m
[93maverage test of epoch 49: loss -0.77229 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 2)
('lr', 0.0001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.66501 ROC_AUC (avg): 0.54123 PRC_AUC (avg): 0.69191 

Average forward propagation time taken(ms): 3.1176908150046376
Average backward propagation time taken(ms): 0.9991554477240964

