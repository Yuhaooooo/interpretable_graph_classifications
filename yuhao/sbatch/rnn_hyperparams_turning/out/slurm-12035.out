# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 2)
('lr', 0.0001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-10-28-03/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-10-28-03/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 16,
 'epochs': 100,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 4,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.0001,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 2,
 'num_workers': 8,
 'number_of_mlp_layer': 2,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-18-10-28-03',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 100, 'learning_rate': 0.0001, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=4, bias=True)
    (ReLU1): ReLU()
    (Linear2): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.57718 acc 0.66667 roc_auc 0.51650 prc_auc 0.67103[0m
[93maverage test of epoch 0: loss -0.59318 acc 0.65789 roc_auc 0.61231 prc_auc 0.78816[0m
[92maverage training of epoch 1: loss -0.62515 acc 0.66667 roc_auc 0.47160 prc_auc 0.64324[0m
[93maverage test of epoch 1: loss -0.61809 acc 0.65789 roc_auc 0.48615 prc_auc 0.72765[0m
[92maverage training of epoch 2: loss -0.65235 acc 0.66667 roc_auc 0.47180 prc_auc 0.66334[0m
[93maverage test of epoch 2: loss -0.65000 acc 0.65789 roc_auc 0.68308 prc_auc 0.82458[0m
[92maverage training of epoch 3: loss -0.68293 acc 0.66667 roc_auc 0.54700 prc_auc 0.70917[0m
[93maverage test of epoch 3: loss -0.67644 acc 0.65789 roc_auc 0.54769 prc_auc 0.73923[0m
[92maverage training of epoch 4: loss -0.71220 acc 0.66667 roc_auc 0.51960 prc_auc 0.70794[0m
[93maverage test of epoch 4: loss -0.70706 acc 0.65789 roc_auc 0.58462 prc_auc 0.77865[0m
[92maverage training of epoch 5: loss -0.74176 acc 0.66667 roc_auc 0.48070 prc_auc 0.69128[0m
[93maverage test of epoch 5: loss -0.73791 acc 0.65789 roc_auc 0.60308 prc_auc 0.78055[0m
[92maverage training of epoch 6: loss -0.77673 acc 0.66667 roc_auc 0.59400 prc_auc 0.76362[0m
[93maverage test of epoch 6: loss -0.77121 acc 0.65789 roc_auc 0.72615 prc_auc 0.84714[0m
[92maverage training of epoch 7: loss -0.80805 acc 0.66667 roc_auc 0.54700 prc_auc 0.74132[0m
[93maverage test of epoch 7: loss -0.80353 acc 0.65789 roc_auc 0.65538 prc_auc 0.82290[0m
[92maverage training of epoch 8: loss -0.84331 acc 0.66667 roc_auc 0.57880 prc_auc 0.76711[0m
[93maverage test of epoch 8: loss -0.83579 acc 0.65789 roc_auc 0.61231 prc_auc 0.82674[0m
[92maverage training of epoch 9: loss -0.87702 acc 0.66667 roc_auc 0.51140 prc_auc 0.72556[0m
[93maverage test of epoch 9: loss -0.87170 acc 0.65789 roc_auc 0.65231 prc_auc 0.84555[0m
[92maverage training of epoch 10: loss -0.91589 acc 0.66667 roc_auc 0.62260 prc_auc 0.79202[0m
[93maverage test of epoch 10: loss -0.91047 acc 0.65789 roc_auc 0.72000 prc_auc 0.84090[0m
[92maverage training of epoch 11: loss -0.95211 acc 0.66667 roc_auc 0.56180 prc_auc 0.74949[0m
[93maverage test of epoch 11: loss -0.94853 acc 0.65789 roc_auc 0.74462 prc_auc 0.88745[0m
[92maverage training of epoch 12: loss -0.99280 acc 0.66667 roc_auc 0.61580 prc_auc 0.77741[0m
[93maverage test of epoch 12: loss -0.98869 acc 0.65789 roc_auc 0.75077 prc_auc 0.88776[0m
[92maverage training of epoch 13: loss -1.03316 acc 0.66667 roc_auc 0.61650 prc_auc 0.79183[0m
[93maverage test of epoch 13: loss -1.02834 acc 0.65789 roc_auc 0.74154 prc_auc 0.88018[0m
[92maverage training of epoch 14: loss -1.07480 acc 0.66667 roc_auc 0.62390 prc_auc 0.78674[0m
[93maverage test of epoch 14: loss -1.06919 acc 0.65789 roc_auc 0.74769 prc_auc 0.87555[0m
[92maverage training of epoch 15: loss -1.11527 acc 0.66667 roc_auc 0.58640 prc_auc 0.76528[0m
[93maverage test of epoch 15: loss -1.11691 acc 0.65789 roc_auc 0.83692 prc_auc 0.91655[0m
[92maverage training of epoch 16: loss -1.16056 acc 0.66667 roc_auc 0.62040 prc_auc 0.79862[0m
[93maverage test of epoch 16: loss -1.15368 acc 0.65789 roc_auc 0.70769 prc_auc 0.85295[0m
[92maverage training of epoch 17: loss -1.20665 acc 0.66667 roc_auc 0.65900 prc_auc 0.81665[0m
[93maverage test of epoch 17: loss -1.20318 acc 0.65789 roc_auc 0.80615 prc_auc 0.91386[0m
[92maverage training of epoch 18: loss -1.24927 acc 0.66667 roc_auc 0.60100 prc_auc 0.76159[0m
[93maverage test of epoch 18: loss -1.24394 acc 0.65789 roc_auc 0.71692 prc_auc 0.85376[0m
[92maverage training of epoch 19: loss -1.29799 acc 0.66667 roc_auc 0.63940 prc_auc 0.81047[0m
[93maverage test of epoch 19: loss -1.29667 acc 0.65789 roc_auc 0.84308 prc_auc 0.93656[0m
[92maverage training of epoch 20: loss -1.34996 acc 0.66667 roc_auc 0.69720 prc_auc 0.83493[0m
[93maverage test of epoch 20: loss -1.33689 acc 0.65789 roc_auc 0.65538 prc_auc 0.82550[0m
[92maverage training of epoch 21: loss -1.40032 acc 0.66667 roc_auc 0.70860 prc_auc 0.83598[0m
[93maverage test of epoch 21: loss -1.39088 acc 0.65789 roc_auc 0.80308 prc_auc 0.90488[0m
[92maverage training of epoch 22: loss -1.44739 acc 0.66667 roc_auc 0.66380 prc_auc 0.79846[0m
[93maverage test of epoch 22: loss -1.44531 acc 0.65789 roc_auc 0.83077 prc_auc 0.93241[0m
[92maverage training of epoch 23: loss -1.50160 acc 0.66667 roc_auc 0.68820 prc_auc 0.78876[0m
[93maverage test of epoch 23: loss -1.49787 acc 0.65789 roc_auc 0.79692 prc_auc 0.87959[0m
[92maverage training of epoch 24: loss -1.55679 acc 0.66667 roc_auc 0.70360 prc_auc 0.81270[0m
[93maverage test of epoch 24: loss -1.54589 acc 0.65789 roc_auc 0.72308 prc_auc 0.84978[0m
[92maverage training of epoch 25: loss -1.61489 acc 0.66667 roc_auc 0.73920 prc_auc 0.83395[0m
[93maverage test of epoch 25: loss -1.60264 acc 0.65789 roc_auc 0.77846 prc_auc 0.90264[0m
[92maverage training of epoch 26: loss -1.66636 acc 0.66667 roc_auc 0.66340 prc_auc 0.79243[0m
[93maverage test of epoch 26: loss -1.66165 acc 0.65789 roc_auc 0.84615 prc_auc 0.92092[0m
[92maverage training of epoch 27: loss -1.72828 acc 0.66667 roc_auc 0.73040 prc_auc 0.84033[0m
[93maverage test of epoch 27: loss -1.71750 acc 0.65789 roc_auc 0.81231 prc_auc 0.85993[0m
[92maverage training of epoch 28: loss -1.78840 acc 0.66667 roc_auc 0.75650 prc_auc 0.84453[0m
[93maverage test of epoch 28: loss -1.77473 acc 0.65789 roc_auc 0.76923 prc_auc 0.86263[0m
[92maverage training of epoch 29: loss -1.84986 acc 0.66667 roc_auc 0.75360 prc_auc 0.84001[0m
[93maverage test of epoch 29: loss -1.84060 acc 0.65789 roc_auc 0.75077 prc_auc 0.85634[0m
[92maverage training of epoch 30: loss -1.92130 acc 0.66667 roc_auc 0.83750 prc_auc 0.89223[0m
[93maverage test of epoch 30: loss -1.89805 acc 0.65789 roc_auc 0.82769 prc_auc 0.89347[0m
[92maverage training of epoch 31: loss -1.98507 acc 0.66667 roc_auc 0.83120 prc_auc 0.86048[0m
[93maverage test of epoch 31: loss -1.97755 acc 0.65789 roc_auc 0.87077 prc_auc 0.89525[0m
[92maverage training of epoch 32: loss -2.05385 acc 0.66667 roc_auc 0.84560 prc_auc 0.88665[0m
[93maverage test of epoch 32: loss -2.03159 acc 0.65789 roc_auc 0.81846 prc_auc 0.89199[0m
[92maverage training of epoch 33: loss -2.12793 acc 0.66667 roc_auc 0.84120 prc_auc 0.86884[0m
[93maverage test of epoch 33: loss -2.10958 acc 0.65789 roc_auc 0.85538 prc_auc 0.93479[0m
[92maverage training of epoch 34: loss -2.21477 acc 0.66667 roc_auc 0.86460 prc_auc 0.90226[0m
[93maverage test of epoch 34: loss -2.20951 acc 0.65789 roc_auc 0.87385 prc_auc 0.92632[0m
[92maverage training of epoch 35: loss -2.30668 acc 0.66667 roc_auc 0.89580 prc_auc 0.91979[0m
[93maverage test of epoch 35: loss -2.28293 acc 0.65789 roc_auc 0.88000 prc_auc 0.93074[0m
[92maverage training of epoch 36: loss -2.40139 acc 0.66667 roc_auc 0.89420 prc_auc 0.91648[0m
[93maverage test of epoch 36: loss -2.36158 acc 0.65789 roc_auc 0.88000 prc_auc 0.94906[0m
[92maverage training of epoch 37: loss -2.48488 acc 0.66667 roc_auc 0.87800 prc_auc 0.91439[0m
[93maverage test of epoch 37: loss -2.45368 acc 0.65789 roc_auc 0.88000 prc_auc 0.89733[0m
[92maverage training of epoch 38: loss -2.58352 acc 0.66667 roc_auc 0.88640 prc_auc 0.90807[0m
[93maverage test of epoch 38: loss -2.55983 acc 0.65789 roc_auc 0.91385 prc_auc 0.96067[0m
[92maverage training of epoch 39: loss -2.68282 acc 0.66667 roc_auc 0.88620 prc_auc 0.89740[0m
[93maverage test of epoch 39: loss -2.59987 acc 0.65789 roc_auc 0.84000 prc_auc 0.90611[0m
[92maverage training of epoch 40: loss -2.76250 acc 0.66667 roc_auc 0.87280 prc_auc 0.87766[0m
[93maverage test of epoch 40: loss -2.67063 acc 0.65789 roc_auc 0.80000 prc_auc 0.85915[0m
[92maverage training of epoch 41: loss -2.87980 acc 0.66667 roc_auc 0.87840 prc_auc 0.90528[0m
[93maverage test of epoch 41: loss -2.80084 acc 0.65789 roc_auc 0.89538 prc_auc 0.95626[0m
[92maverage training of epoch 42: loss -2.97127 acc 0.66667 roc_auc 0.88040 prc_auc 0.89248[0m
[93maverage test of epoch 42: loss -2.87928 acc 0.65789 roc_auc 0.87077 prc_auc 0.94347[0m
[92maverage training of epoch 43: loss -3.08297 acc 0.66667 roc_auc 0.88060 prc_auc 0.91498[0m
[93maverage test of epoch 43: loss -3.00265 acc 0.65789 roc_auc 0.86769 prc_auc 0.90243[0m
[92maverage training of epoch 44: loss -3.17517 acc 0.66667 roc_auc 0.86260 prc_auc 0.89187[0m
[93maverage test of epoch 44: loss -3.04267 acc 0.65789 roc_auc 0.84000 prc_auc 0.89305[0m
[92maverage training of epoch 45: loss -3.29048 acc 0.66667 roc_auc 0.88740 prc_auc 0.92291[0m
[93maverage test of epoch 45: loss -3.16093 acc 0.65789 roc_auc 0.86154 prc_auc 0.92805[0m
[92maverage training of epoch 46: loss -3.38837 acc 0.66667 roc_auc 0.85520 prc_auc 0.87970[0m
[93maverage test of epoch 46: loss -3.29614 acc 0.65789 roc_auc 0.87385 prc_auc 0.92278[0m
[92maverage training of epoch 47: loss -3.50709 acc 0.66667 roc_auc 0.88860 prc_auc 0.91455[0m
[93maverage test of epoch 47: loss -3.40259 acc 0.65789 roc_auc 0.89231 prc_auc 0.94846[0m
[92maverage training of epoch 48: loss -3.62862 acc 0.66667 roc_auc 0.88250 prc_auc 0.91404[0m
[93maverage test of epoch 48: loss -3.46113 acc 0.65789 roc_auc 0.86154 prc_auc 0.93101[0m
[92maverage training of epoch 49: loss -3.74558 acc 0.66667 roc_auc 0.88290 prc_auc 0.91622[0m
[93maverage test of epoch 49: loss -3.58687 acc 0.65789 roc_auc 0.84000 prc_auc 0.85373[0m
[92maverage training of epoch 50: loss -3.84942 acc 0.66667 roc_auc 0.86340 prc_auc 0.88274[0m
[93maverage test of epoch 50: loss -3.67459 acc 0.65789 roc_auc 0.84308 prc_auc 0.90681[0m
[92maverage training of epoch 51: loss -3.98152 acc 0.66667 roc_auc 0.87220 prc_auc 0.89433[0m
[93maverage test of epoch 51: loss -3.79496 acc 0.65789 roc_auc 0.84308 prc_auc 0.91230[0m
[92maverage training of epoch 52: loss -4.10014 acc 0.66667 roc_auc 0.86010 prc_auc 0.87497[0m
[93maverage test of epoch 52: loss -3.88138 acc 0.65789 roc_auc 0.86462 prc_auc 0.92608[0m
[92maverage training of epoch 53: loss -4.20923 acc 0.66667 roc_auc 0.85530 prc_auc 0.86517[0m
[93maverage test of epoch 53: loss -3.99807 acc 0.65789 roc_auc 0.86462 prc_auc 0.94333[0m
[92maverage training of epoch 54: loss -4.33904 acc 0.66667 roc_auc 0.86660 prc_auc 0.88218[0m
[93maverage test of epoch 54: loss -4.14919 acc 0.65789 roc_auc 0.86000 prc_auc 0.93168[0m
[92maverage training of epoch 55: loss -4.47233 acc 0.66667 roc_auc 0.86310 prc_auc 0.87915[0m
[93maverage test of epoch 55: loss -4.27098 acc 0.65789 roc_auc 0.83077 prc_auc 0.85326[0m
[92maverage training of epoch 56: loss -4.62121 acc 0.66667 roc_auc 0.87920 prc_auc 0.90852[0m
[93maverage test of epoch 56: loss -4.37116 acc 0.65789 roc_auc 0.87231 prc_auc 0.93404[0m
[92maverage training of epoch 57: loss -4.72254 acc 0.66667 roc_auc 0.84750 prc_auc 0.85884[0m
[93maverage test of epoch 57: loss -4.44498 acc 0.65789 roc_auc 0.83692 prc_auc 0.91112[0m
[92maverage training of epoch 58: loss -4.87031 acc 0.66667 roc_auc 0.85170 prc_auc 0.87692[0m
[93maverage test of epoch 58: loss -4.56466 acc 0.65789 roc_auc 0.80462 prc_auc 0.84485[0m
[92maverage training of epoch 59: loss -5.00547 acc 0.66667 roc_auc 0.87220 prc_auc 0.90888[0m
[93maverage test of epoch 59: loss -4.71165 acc 0.65789 roc_auc 0.83077 prc_auc 0.87338[0m
[92maverage training of epoch 60: loss -5.14308 acc 0.66667 roc_auc 0.87750 prc_auc 0.90027[0m
[93maverage test of epoch 60: loss -4.96789 acc 0.65789 roc_auc 0.92615 prc_auc 0.95645[0m
[92maverage training of epoch 61: loss -5.28053 acc 0.66667 roc_auc 0.85690 prc_auc 0.89414[0m
[93maverage test of epoch 61: loss -4.93458 acc 0.65789 roc_auc 0.83846 prc_auc 0.90707[0m
[92maverage training of epoch 62: loss -5.46530 acc 0.66667 roc_auc 0.85770 prc_auc 0.87508[0m
[93maverage test of epoch 62: loss -5.10301 acc 0.65789 roc_auc 0.88769 prc_auc 0.94551[0m
[92maverage training of epoch 63: loss -5.59749 acc 0.66667 roc_auc 0.86280 prc_auc 0.87642[0m
[93maverage test of epoch 63: loss -5.26435 acc 0.65789 roc_auc 0.86154 prc_auc 0.87102[0m
[92maverage training of epoch 64: loss -5.74245 acc 0.66667 roc_auc 0.86760 prc_auc 0.89847[0m
[93maverage test of epoch 64: loss -5.32961 acc 0.65789 roc_auc 0.82308 prc_auc 0.87075[0m
[92maverage training of epoch 65: loss -5.87928 acc 0.66667 roc_auc 0.86870 prc_auc 0.90575[0m
[93maverage test of epoch 65: loss -5.44182 acc 0.65789 roc_auc 0.83538 prc_auc 0.92326[0m
[92maverage training of epoch 66: loss -6.04639 acc 0.66667 roc_auc 0.84420 prc_auc 0.86383[0m
[93maverage test of epoch 66: loss -5.65338 acc 0.65789 roc_auc 0.85846 prc_auc 0.88875[0m
[92maverage training of epoch 67: loss -6.20688 acc 0.66667 roc_auc 0.84310 prc_auc 0.86965[0m
[93maverage test of epoch 67: loss -5.78483 acc 0.65789 roc_auc 0.86154 prc_auc 0.93091[0m
[92maverage training of epoch 68: loss -6.39212 acc 0.66667 roc_auc 0.85950 prc_auc 0.89152[0m
[93maverage test of epoch 68: loss -5.88682 acc 0.65789 roc_auc 0.84462 prc_auc 0.88780[0m
[92maverage training of epoch 69: loss -6.50552 acc 0.66667 roc_auc 0.83540 prc_auc 0.85838[0m
[93maverage test of epoch 69: loss -6.06941 acc 0.65789 roc_auc 0.84615 prc_auc 0.89630[0m
[92maverage training of epoch 70: loss -6.69788 acc 0.66667 roc_auc 0.84880 prc_auc 0.86867[0m
[93maverage test of epoch 70: loss -6.29069 acc 0.65789 roc_auc 0.87077 prc_auc 0.90265[0m
[92maverage training of epoch 71: loss -6.86698 acc 0.66667 roc_auc 0.86050 prc_auc 0.88529[0m
[93maverage test of epoch 71: loss -6.46845 acc 0.65789 roc_auc 0.86769 prc_auc 0.90226[0m
[92maverage training of epoch 72: loss -7.05166 acc 0.66667 roc_auc 0.85020 prc_auc 0.88153[0m
[93maverage test of epoch 72: loss -6.57439 acc 0.65789 roc_auc 0.89538 prc_auc 0.91819[0m
[92maverage training of epoch 73: loss -7.23369 acc 0.66667 roc_auc 0.84850 prc_auc 0.87516[0m
[93maverage test of epoch 73: loss -6.68489 acc 0.65789 roc_auc 0.85077 prc_auc 0.91157[0m
[92maverage training of epoch 74: loss -7.40923 acc 0.66667 roc_auc 0.85640 prc_auc 0.87707[0m
[93maverage test of epoch 74: loss -6.84788 acc 0.65789 roc_auc 0.87692 prc_auc 0.91573[0m
[92maverage training of epoch 75: loss -7.61707 acc 0.66667 roc_auc 0.84510 prc_auc 0.86516[0m
[93maverage test of epoch 75: loss -7.07512 acc 0.65789 roc_auc 0.85846 prc_auc 0.92699[0m
[92maverage training of epoch 76: loss -7.78444 acc 0.66667 roc_auc 0.85190 prc_auc 0.87764[0m
[93maverage test of epoch 76: loss -7.14378 acc 0.65789 roc_auc 0.83538 prc_auc 0.90848[0m
[92maverage training of epoch 77: loss -7.95981 acc 0.66667 roc_auc 0.83750 prc_auc 0.87014[0m
[93maverage test of epoch 77: loss -7.33442 acc 0.65789 roc_auc 0.84615 prc_auc 0.90849[0m
[92maverage training of epoch 78: loss -8.16814 acc 0.66667 roc_auc 0.86610 prc_auc 0.89330[0m
[93maverage test of epoch 78: loss -7.49872 acc 0.65789 roc_auc 0.84000 prc_auc 0.90592[0m
[92maverage training of epoch 79: loss -8.34172 acc 0.66667 roc_auc 0.86710 prc_auc 0.89651[0m
[93maverage test of epoch 79: loss -7.66021 acc 0.65789 roc_auc 0.80154 prc_auc 0.88514[0m
[92maverage training of epoch 80: loss -8.59254 acc 0.66667 roc_auc 0.86870 prc_auc 0.89163[0m
[93maverage test of epoch 80: loss -7.93753 acc 0.65789 roc_auc 0.88308 prc_auc 0.90340[0m
[92maverage training of epoch 81: loss -8.75627 acc 0.66667 roc_auc 0.81360 prc_auc 0.85204[0m
[93maverage test of epoch 81: loss -8.19340 acc 0.65789 roc_auc 0.91231 prc_auc 0.93194[0m
[92maverage training of epoch 82: loss -8.99892 acc 0.66667 roc_auc 0.84360 prc_auc 0.87095[0m
[93maverage test of epoch 82: loss -8.22331 acc 0.65789 roc_auc 0.81231 prc_auc 0.87964[0m
[92maverage training of epoch 83: loss -9.15720 acc 0.66667 roc_auc 0.82280 prc_auc 0.86158[0m
[93maverage test of epoch 83: loss -8.38144 acc 0.65789 roc_auc 0.83077 prc_auc 0.88476[0m
[92maverage training of epoch 84: loss -9.39606 acc 0.66667 roc_auc 0.84920 prc_auc 0.87423[0m
[93maverage test of epoch 84: loss -8.59217 acc 0.65789 roc_auc 0.78308 prc_auc 0.84865[0m
[92maverage training of epoch 85: loss -9.63768 acc 0.66667 roc_auc 0.83300 prc_auc 0.86447[0m
[93maverage test of epoch 85: loss -8.78811 acc 0.65789 roc_auc 0.80769 prc_auc 0.85593[0m
[92maverage training of epoch 86: loss -9.84211 acc 0.66667 roc_auc 0.82350 prc_auc 0.85715[0m
[93maverage test of epoch 86: loss -9.01084 acc 0.65789 roc_auc 0.79846 prc_auc 0.85361[0m
[92maverage training of epoch 87: loss -10.05609 acc 0.66667 roc_auc 0.82090 prc_auc 0.85701[0m
[93maverage test of epoch 87: loss -9.23673 acc 0.65789 roc_auc 0.80462 prc_auc 0.85613[0m
[92maverage training of epoch 88: loss -10.29139 acc 0.66667 roc_auc 0.82550 prc_auc 0.85822[0m
[93maverage test of epoch 88: loss -9.39681 acc 0.65789 roc_auc 0.83385 prc_auc 0.88538[0m
[92maverage training of epoch 89: loss -10.50031 acc 0.66667 roc_auc 0.81160 prc_auc 0.84974[0m
[93maverage test of epoch 89: loss -9.72325 acc 0.65789 roc_auc 0.79846 prc_auc 0.85433[0m
[92maverage training of epoch 90: loss -10.75834 acc 0.66667 roc_auc 0.82410 prc_auc 0.85800[0m
[93maverage test of epoch 90: loss -9.83374 acc 0.65789 roc_auc 0.79538 prc_auc 0.85280[0m
[92maverage training of epoch 91: loss -11.00295 acc 0.66667 roc_auc 0.82160 prc_auc 0.85264[0m
[93maverage test of epoch 91: loss -10.05593 acc 0.65789 roc_auc 0.76154 prc_auc 0.84248[0m
[92maverage training of epoch 92: loss -11.26691 acc 0.66667 roc_auc 0.82280 prc_auc 0.85299[0m
[93maverage test of epoch 92: loss -10.34553 acc 0.65789 roc_auc 0.80462 prc_auc 0.85638[0m
[92maverage training of epoch 93: loss -11.48097 acc 0.66667 roc_auc 0.80460 prc_auc 0.84776[0m
[93maverage test of epoch 93: loss -10.48956 acc 0.65789 roc_auc 0.80769 prc_auc 0.85612[0m
[92maverage training of epoch 94: loss -11.74035 acc 0.66667 roc_auc 0.80760 prc_auc 0.84861[0m
[93maverage test of epoch 94: loss -10.68213 acc 0.65789 roc_auc 0.79846 prc_auc 0.85414[0m
[92maverage training of epoch 95: loss -12.00590 acc 0.66667 roc_auc 0.81100 prc_auc 0.84944[0m
[93maverage test of epoch 95: loss -10.95149 acc 0.65789 roc_auc 0.81385 prc_auc 0.85857[0m
[92maverage training of epoch 96: loss -12.29104 acc 0.66667 roc_auc 0.81240 prc_auc 0.85008[0m
[93maverage test of epoch 96: loss -11.19659 acc 0.65789 roc_auc 0.79538 prc_auc 0.85298[0m
[92maverage training of epoch 97: loss -12.52005 acc 0.66667 roc_auc 0.80960 prc_auc 0.84908[0m
[93maverage test of epoch 97: loss -11.42495 acc 0.65789 roc_auc 0.79846 prc_auc 0.85419[0m
[92maverage training of epoch 98: loss -12.81151 acc 0.66667 roc_auc 0.81000 prc_auc 0.84942[0m
[93maverage test of epoch 98: loss -11.65739 acc 0.65789 roc_auc 0.77077 prc_auc 0.84535[0m
[92maverage training of epoch 99: loss -13.08433 acc 0.66667 roc_auc 0.81860 prc_auc 0.85177[0m
[93maverage test of epoch 99: loss -11.85326 acc 0.65789 roc_auc 0.79231 prc_auc 0.85088[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=4, bias=True)
    (ReLU1): ReLU()
    (Linear2): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.15645 acc 0.66667 roc_auc 0.45080 prc_auc 0.65405[0m
[93maverage test of epoch 0: loss -0.21424 acc 0.65789 roc_auc 0.58769 prc_auc 0.77269[0m
[92maverage training of epoch 1: loss -0.28611 acc 0.66667 roc_auc 0.51660 prc_auc 0.68311[0m
[93maverage test of epoch 1: loss -0.31568 acc 0.65789 roc_auc 0.35077 prc_auc 0.62406[0m
[92maverage training of epoch 2: loss -0.35700 acc 0.66667 roc_auc 0.49400 prc_auc 0.68615[0m
[93maverage test of epoch 2: loss -0.37405 acc 0.65789 roc_auc 0.46769 prc_auc 0.71021[0m
[92maverage training of epoch 3: loss -0.41410 acc 0.66667 roc_auc 0.53240 prc_auc 0.71582[0m
[93maverage test of epoch 3: loss -0.42910 acc 0.65789 roc_auc 0.48308 prc_auc 0.66072[0m
[92maverage training of epoch 4: loss -0.48107 acc 0.66667 roc_auc 0.58040 prc_auc 0.74925[0m
[93maverage test of epoch 4: loss -0.49624 acc 0.65789 roc_auc 0.56615 prc_auc 0.72539[0m
[92maverage training of epoch 5: loss -0.54102 acc 0.66667 roc_auc 0.47740 prc_auc 0.67026[0m
[93maverage test of epoch 5: loss -0.56987 acc 0.65789 roc_auc 0.70462 prc_auc 0.81554[0m
[92maverage training of epoch 6: loss -0.60832 acc 0.66667 roc_auc 0.46080 prc_auc 0.67016[0m
[93maverage test of epoch 6: loss -0.62174 acc 0.65789 roc_auc 0.51692 prc_auc 0.67383[0m
[92maverage training of epoch 7: loss -0.69551 acc 0.66667 roc_auc 0.56240 prc_auc 0.71897[0m
[93maverage test of epoch 7: loss -0.73583 acc 0.65789 roc_auc 0.45846 prc_auc 0.66076[0m
[92maverage training of epoch 8: loss -0.84144 acc 0.66667 roc_auc 0.50880 prc_auc 0.69528[0m
[93maverage test of epoch 8: loss -0.95257 acc 0.65789 roc_auc 0.43692 prc_auc 0.68481[0m
[92maverage training of epoch 9: loss -1.33062 acc 0.66667 roc_auc 0.48000 prc_auc 0.65824[0m
[93maverage test of epoch 9: loss -1.59430 acc 0.65789 roc_auc 0.39077 prc_auc 0.68803[0m
[92maverage training of epoch 10: loss -1.96409 acc 0.66667 roc_auc 0.54860 prc_auc 0.71673[0m
[93maverage test of epoch 10: loss -2.18331 acc 0.65789 roc_auc 0.61846 prc_auc 0.78225[0m
[92maverage training of epoch 11: loss -2.43016 acc 0.66667 roc_auc 0.54440 prc_auc 0.69842[0m
[93maverage test of epoch 11: loss -2.54673 acc 0.65789 roc_auc 0.61538 prc_auc 0.76622[0m
[92maverage training of epoch 12: loss -2.75419 acc 0.66667 roc_auc 0.50600 prc_auc 0.68642[0m
[93maverage test of epoch 12: loss -2.88431 acc 0.65789 roc_auc 0.39077 prc_auc 0.65500[0m
[92maverage training of epoch 13: loss -3.08358 acc 0.66667 roc_auc 0.54220 prc_auc 0.71352[0m
[93maverage test of epoch 13: loss -3.19870 acc 0.65789 roc_auc 0.56615 prc_auc 0.73399[0m
[92maverage training of epoch 14: loss -3.40336 acc 0.66667 roc_auc 0.50860 prc_auc 0.68313[0m
[93maverage test of epoch 14: loss -3.50752 acc 0.65789 roc_auc 0.53231 prc_auc 0.71209[0m
[92maverage training of epoch 15: loss -3.70762 acc 0.66667 roc_auc 0.40140 prc_auc 0.61703[0m
[93maverage test of epoch 15: loss -3.85183 acc 0.65789 roc_auc 0.37538 prc_auc 0.56673[0m
[92maverage training of epoch 16: loss -4.07849 acc 0.66667 roc_auc 0.50300 prc_auc 0.68721[0m
[93maverage test of epoch 16: loss -4.25612 acc 0.65789 roc_auc 0.44000 prc_auc 0.63520[0m
[92maverage training of epoch 17: loss -4.50912 acc 0.66667 roc_auc 0.52560 prc_auc 0.68479[0m
[93maverage test of epoch 17: loss -4.70855 acc 0.65789 roc_auc 0.52923 prc_auc 0.68406[0m
[92maverage training of epoch 18: loss -4.97152 acc 0.66667 roc_auc 0.44300 prc_auc 0.65198[0m
[93maverage test of epoch 18: loss -5.11896 acc 0.65789 roc_auc 0.46462 prc_auc 0.65607[0m
[92maverage training of epoch 19: loss -5.44169 acc 0.66667 roc_auc 0.42000 prc_auc 0.62064[0m
[93maverage test of epoch 19: loss -5.62288 acc 0.65789 roc_auc 0.39692 prc_auc 0.62903[0m
[92maverage training of epoch 20: loss -5.91697 acc 0.66667 roc_auc 0.47760 prc_auc 0.67195[0m
[93maverage test of epoch 20: loss -6.08680 acc 0.65789 roc_auc 0.54769 prc_auc 0.69802[0m
[92maverage training of epoch 21: loss -6.35655 acc 0.66667 roc_auc 0.49230 prc_auc 0.67303[0m
[93maverage test of epoch 21: loss -6.53590 acc 0.65789 roc_auc 0.55385 prc_auc 0.70136[0m
[92maverage training of epoch 22: loss -6.81823 acc 0.66667 roc_auc 0.45490 prc_auc 0.62548[0m
[93maverage test of epoch 22: loss -6.97874 acc 0.65789 roc_auc 0.54769 prc_auc 0.75308[0m
[92maverage training of epoch 23: loss -7.27207 acc 0.66667 roc_auc 0.45410 prc_auc 0.64220[0m
[93maverage test of epoch 23: loss -7.44762 acc 0.65789 roc_auc 0.38615 prc_auc 0.67150[0m
[92maverage training of epoch 24: loss -7.74590 acc 0.66667 roc_auc 0.57750 prc_auc 0.68868[0m
[93maverage test of epoch 24: loss -7.90597 acc 0.65789 roc_auc 0.36769 prc_auc 0.64925[0m
[92maverage training of epoch 25: loss -8.20821 acc 0.66667 roc_auc 0.46980 prc_auc 0.65863[0m
[93maverage test of epoch 25: loss -8.39987 acc 0.65789 roc_auc 0.53692 prc_auc 0.72691[0m
[92maverage training of epoch 26: loss -8.69580 acc 0.66667 roc_auc 0.50980 prc_auc 0.68383[0m
[93maverage test of epoch 26: loss -8.87028 acc 0.65789 roc_auc 0.56154 prc_auc 0.65846[0m
[92maverage training of epoch 27: loss -9.19713 acc 0.66667 roc_auc 0.50910 prc_auc 0.71175[0m
[93maverage test of epoch 27: loss -9.36069 acc 0.65789 roc_auc 0.43077 prc_auc 0.65619[0m
[92maverage training of epoch 28: loss -9.70530 acc 0.66667 roc_auc 0.46720 prc_auc 0.65826[0m
[93maverage test of epoch 28: loss -9.86358 acc 0.65789 roc_auc 0.48769 prc_auc 0.71541[0m
[92maverage training of epoch 29: loss -10.22108 acc 0.66667 roc_auc 0.44180 prc_auc 0.62690[0m
[93maverage test of epoch 29: loss -10.41001 acc 0.65789 roc_auc 0.47231 prc_auc 0.67446[0m
[92maverage training of epoch 30: loss -10.75772 acc 0.66667 roc_auc 0.47480 prc_auc 0.65978[0m
[93maverage test of epoch 30: loss -10.93860 acc 0.65789 roc_auc 0.43846 prc_auc 0.64002[0m
[92maverage training of epoch 31: loss -11.29734 acc 0.66667 roc_auc 0.44410 prc_auc 0.62994[0m
[93maverage test of epoch 31: loss -11.49700 acc 0.65789 roc_auc 0.60615 prc_auc 0.75937[0m
[92maverage training of epoch 32: loss -11.86082 acc 0.66667 roc_auc 0.46120 prc_auc 0.64450[0m
[93maverage test of epoch 32: loss -12.05860 acc 0.65789 roc_auc 0.31538 prc_auc 0.59077[0m
[92maverage training of epoch 33: loss -12.42650 acc 0.66667 roc_auc 0.45950 prc_auc 0.63488[0m
[93maverage test of epoch 33: loss -12.63191 acc 0.65789 roc_auc 0.55846 prc_auc 0.70143[0m
[92maverage training of epoch 34: loss -13.00749 acc 0.66667 roc_auc 0.48440 prc_auc 0.67385[0m
[93maverage test of epoch 34: loss -13.20621 acc 0.65789 roc_auc 0.42000 prc_auc 0.62014[0m
[92maverage training of epoch 35: loss -13.60265 acc 0.66667 roc_auc 0.47550 prc_auc 0.66812[0m
[93maverage test of epoch 35: loss -13.80457 acc 0.65789 roc_auc 0.62308 prc_auc 0.78351[0m
[92maverage training of epoch 36: loss -14.21994 acc 0.66667 roc_auc 0.42360 prc_auc 0.60955[0m
[93maverage test of epoch 36: loss -14.41876 acc 0.65789 roc_auc 0.51538 prc_auc 0.68499[0m
[92maverage training of epoch 37: loss -14.82887 acc 0.66667 roc_auc 0.45180 prc_auc 0.63691[0m
[93maverage test of epoch 37: loss -15.04736 acc 0.65789 roc_auc 0.51692 prc_auc 0.65094[0m
[92maverage training of epoch 38: loss -15.45995 acc 0.66667 roc_auc 0.44350 prc_auc 0.62119[0m
[93maverage test of epoch 38: loss -15.69716 acc 0.65789 roc_auc 0.29846 prc_auc 0.57104[0m
[92maverage training of epoch 39: loss -16.10725 acc 0.66667 roc_auc 0.45640 prc_auc 0.63572[0m
[93maverage test of epoch 39: loss -16.33308 acc 0.65789 roc_auc 0.46308 prc_auc 0.64112[0m
[92maverage training of epoch 40: loss -16.78159 acc 0.66667 roc_auc 0.47250 prc_auc 0.66344[0m
[93maverage test of epoch 40: loss -17.02353 acc 0.65789 roc_auc 0.60769 prc_auc 0.71390[0m
[92maverage training of epoch 41: loss -17.45647 acc 0.66667 roc_auc 0.41890 prc_auc 0.61999[0m
[93maverage test of epoch 41: loss -17.67041 acc 0.65789 roc_auc 0.38462 prc_auc 0.60070[0m
[92maverage training of epoch 42: loss -18.15983 acc 0.66667 roc_auc 0.47950 prc_auc 0.64820[0m
[93maverage test of epoch 42: loss -18.39613 acc 0.65789 roc_auc 0.60769 prc_auc 0.71411[0m
[92maverage training of epoch 43: loss -18.87324 acc 0.66667 roc_auc 0.46400 prc_auc 0.63982[0m
[93maverage test of epoch 43: loss -19.11842 acc 0.65789 roc_auc 0.47846 prc_auc 0.64727[0m
[92maverage training of epoch 44: loss -19.59684 acc 0.66667 roc_auc 0.46220 prc_auc 0.64669[0m
[93maverage test of epoch 44: loss -19.83351 acc 0.65789 roc_auc 0.50462 prc_auc 0.66009[0m
[92maverage training of epoch 45: loss -20.33489 acc 0.66667 roc_auc 0.44720 prc_auc 0.63526[0m
[93maverage test of epoch 45: loss -20.60318 acc 0.65789 roc_auc 0.51846 prc_auc 0.66632[0m
[92maverage training of epoch 46: loss -21.09739 acc 0.66667 roc_auc 0.43360 prc_auc 0.63367[0m
[93maverage test of epoch 46: loss -21.37240 acc 0.65789 roc_auc 0.53077 prc_auc 0.67225[0m
[92maverage training of epoch 47: loss -21.88380 acc 0.66667 roc_auc 0.47620 prc_auc 0.65599[0m
[93maverage test of epoch 47: loss -22.13821 acc 0.65789 roc_auc 0.48000 prc_auc 0.64902[0m
[92maverage training of epoch 48: loss -22.68231 acc 0.66667 roc_auc 0.48270 prc_auc 0.65884[0m
[93maverage test of epoch 48: loss -22.95806 acc 0.65789 roc_auc 0.49692 prc_auc 0.65651[0m
[92maverage training of epoch 49: loss -23.51254 acc 0.66667 roc_auc 0.50950 prc_auc 0.67100[0m
[93maverage test of epoch 49: loss -23.78333 acc 0.65789 roc_auc 0.45692 prc_auc 0.63923[0m
[92maverage training of epoch 50: loss -24.34668 acc 0.66667 roc_auc 0.50500 prc_auc 0.66890[0m
[93maverage test of epoch 50: loss -24.65335 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 51: loss -25.20478 acc 0.66667 roc_auc 0.47500 prc_auc 0.65586[0m
[93maverage test of epoch 51: loss -25.52076 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 52: loss -26.09741 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 52: loss -26.39357 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 53: loss -26.99492 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 53: loss -27.32134 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 54: loss -27.92103 acc 0.66667 roc_auc 0.46500 prc_auc 0.65170[0m
[93maverage test of epoch 54: loss -28.25472 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 55: loss -28.86589 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 55: loss -29.20435 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 56: loss -29.84047 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 56: loss -30.18421 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 57: loss -30.84276 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 57: loss -31.18950 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 58: loss -31.85504 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 58: loss -32.22003 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 59: loss -32.89847 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 59: loss -33.26870 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 60: loss -33.96783 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 60: loss -34.35080 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 61: loss -35.06490 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 61: loss -35.45819 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 62: loss -36.18321 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 62: loss -36.59684 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 63: loss -37.34002 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 63: loss -37.75025 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 64: loss -38.52574 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 64: loss -38.94021 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 65: loss -39.73400 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 65: loss -40.16506 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 66: loss -40.96988 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 66: loss -41.40794 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 67: loss -42.24625 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 67: loss -42.70472 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 68: loss -43.54713 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 68: loss -44.00243 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 69: loss -44.88278 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 69: loss -45.35906 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 70: loss -46.25168 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 70: loss -46.74158 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 71: loss -47.65564 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 71: loss -48.16287 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 72: loss -49.09252 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 72: loss -49.60612 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 73: loss -50.57137 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 73: loss -51.08670 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 74: loss -52.08245 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 74: loss -52.61611 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 75: loss -53.62756 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 75: loss -54.17603 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 76: loss -55.21500 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 76: loss -55.77281 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 77: loss -56.83877 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 77: loss -57.40869 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 78: loss -58.50116 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 78: loss -59.08327 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 79: loss -60.20225 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 79: loss -60.79872 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 80: loss -61.94366 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 80: loss -62.55542 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 81: loss -63.72185 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 81: loss -64.34595 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 82: loss -65.53828 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 82: loss -66.17748 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 83: loss -67.39225 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 83: loss -68.04360 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 84: loss -69.29660 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 84: loss -69.95019 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 85: loss -71.23074 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 85: loss -71.89808 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 86: loss -73.20317 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 86: loss -73.88336 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 87: loss -75.20596 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 87: loss -75.89458 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 88: loss -77.24312 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 88: loss -77.92596 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 89: loss -79.30618 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 89: loss -80.00398 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -81.40466 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 90: loss -82.10917 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 91: loss -83.53694 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 91: loss -84.24920 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 92: loss -85.70180 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 92: loss -86.41852 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 93: loss -87.89907 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 93: loss -88.63043 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 94: loss -90.13250 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 94: loss -90.86058 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 95: loss -92.40250 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 95: loss -93.14638 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 96: loss -94.71142 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 96: loss -95.46161 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 97: loss -97.05027 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 97: loss -97.81204 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 98: loss -99.42702 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 98: loss -100.20124 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -101.84497 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 99: loss -102.62354 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=4, bias=True)
    (ReLU1): ReLU()
    (Linear2): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss 0.17549 acc 0.66667 roc_auc 0.42620 prc_auc 0.62820[0m
[93maverage test of epoch 0: loss 0.16474 acc 0.65789 roc_auc 0.51077 prc_auc 0.68632[0m
[92maverage training of epoch 1: loss 0.15274 acc 0.66667 roc_auc 0.47140 prc_auc 0.67126[0m
[93maverage test of epoch 1: loss 0.14723 acc 0.65789 roc_auc 0.37231 prc_auc 0.60519[0m
[92maverage training of epoch 2: loss 0.13264 acc 0.66667 roc_auc 0.42500 prc_auc 0.63793[0m
[93maverage test of epoch 2: loss 0.12072 acc 0.65789 roc_auc 0.50462 prc_auc 0.72146[0m
[92maverage training of epoch 3: loss 0.10530 acc 0.66667 roc_auc 0.52800 prc_auc 0.69536[0m
[93maverage test of epoch 3: loss 0.09466 acc 0.65789 roc_auc 0.52308 prc_auc 0.68313[0m
[92maverage training of epoch 4: loss 0.07815 acc 0.66667 roc_auc 0.47400 prc_auc 0.69128[0m
[93maverage test of epoch 4: loss 0.06266 acc 0.65789 roc_auc 0.54769 prc_auc 0.68204[0m
[92maverage training of epoch 5: loss 0.04370 acc 0.66667 roc_auc 0.45380 prc_auc 0.63820[0m
[93maverage test of epoch 5: loss 0.02446 acc 0.65789 roc_auc 0.44308 prc_auc 0.67041[0m
[92maverage training of epoch 6: loss -0.01238 acc 0.66667 roc_auc 0.43680 prc_auc 0.63350[0m
[93maverage test of epoch 6: loss -0.05675 acc 0.65789 roc_auc 0.83077 prc_auc 0.92173[0m
[92maverage training of epoch 7: loss -0.10333 acc 0.66667 roc_auc 0.50280 prc_auc 0.68288[0m
[93maverage test of epoch 7: loss -0.14602 acc 0.65789 roc_auc 0.59077 prc_auc 0.73195[0m
[92maverage training of epoch 8: loss -0.20333 acc 0.66667 roc_auc 0.45840 prc_auc 0.65163[0m
[93maverage test of epoch 8: loss -0.25520 acc 0.65789 roc_auc 0.52615 prc_auc 0.65221[0m
[92maverage training of epoch 9: loss -0.32294 acc 0.66667 roc_auc 0.45700 prc_auc 0.66452[0m
[93maverage test of epoch 9: loss -0.38041 acc 0.65789 roc_auc 0.38154 prc_auc 0.58850[0m
[92maverage training of epoch 10: loss -0.45869 acc 0.66667 roc_auc 0.41900 prc_auc 0.61888[0m
[93maverage test of epoch 10: loss -0.52936 acc 0.65789 roc_auc 0.60923 prc_auc 0.77475[0m
[92maverage training of epoch 11: loss -0.61734 acc 0.66667 roc_auc 0.41400 prc_auc 0.62330[0m
[93maverage test of epoch 11: loss -0.69703 acc 0.65789 roc_auc 0.76615 prc_auc 0.86539[0m
[92maverage training of epoch 12: loss -0.79168 acc 0.66667 roc_auc 0.44800 prc_auc 0.64987[0m
[93maverage test of epoch 12: loss -0.86966 acc 0.65789 roc_auc 0.34462 prc_auc 0.57473[0m
[92maverage training of epoch 13: loss -0.96791 acc 0.66667 roc_auc 0.43980 prc_auc 0.64774[0m
[93maverage test of epoch 13: loss -1.04531 acc 0.65789 roc_auc 0.52000 prc_auc 0.66927[0m
[92maverage training of epoch 14: loss -1.14845 acc 0.66667 roc_auc 0.42640 prc_auc 0.63107[0m
[93maverage test of epoch 14: loss -1.23434 acc 0.65789 roc_auc 0.60923 prc_auc 0.76555[0m
[92maverage training of epoch 15: loss -1.34349 acc 0.66667 roc_auc 0.47760 prc_auc 0.69453[0m
[93maverage test of epoch 15: loss -1.42990 acc 0.65789 roc_auc 0.52923 prc_auc 0.73541[0m
[92maverage training of epoch 16: loss -1.55857 acc 0.66667 roc_auc 0.47640 prc_auc 0.64904[0m
[93maverage test of epoch 16: loss -1.66134 acc 0.65789 roc_auc 0.58462 prc_auc 0.72147[0m
[92maverage training of epoch 17: loss -1.79461 acc 0.66667 roc_auc 0.47600 prc_auc 0.67323[0m
[93maverage test of epoch 17: loss -1.91201 acc 0.65789 roc_auc 0.57231 prc_auc 0.74784[0m
[92maverage training of epoch 18: loss -2.04380 acc 0.66667 roc_auc 0.37800 prc_auc 0.59437[0m
[93maverage test of epoch 18: loss -2.17758 acc 0.65789 roc_auc 0.56000 prc_auc 0.76688[0m
[92maverage training of epoch 19: loss -2.31879 acc 0.66667 roc_auc 0.39960 prc_auc 0.61788[0m
[93maverage test of epoch 19: loss -2.47490 acc 0.65789 roc_auc 0.77231 prc_auc 0.89063[0m
[92maverage training of epoch 20: loss -2.64365 acc 0.66667 roc_auc 0.42520 prc_auc 0.65451[0m
[93maverage test of epoch 20: loss -2.80393 acc 0.65789 roc_auc 0.72000 prc_auc 0.87508[0m
[92maverage training of epoch 21: loss -2.97165 acc 0.66667 roc_auc 0.50600 prc_auc 0.67977[0m
[93maverage test of epoch 21: loss -3.10712 acc 0.65789 roc_auc 0.41231 prc_auc 0.67402[0m
[92maverage training of epoch 22: loss -3.29220 acc 0.66667 roc_auc 0.47440 prc_auc 0.68494[0m
[93maverage test of epoch 22: loss -3.43008 acc 0.65789 roc_auc 0.50462 prc_auc 0.72625[0m
[92maverage training of epoch 23: loss -3.61150 acc 0.66667 roc_auc 0.44030 prc_auc 0.62805[0m
[93maverage test of epoch 23: loss -3.75009 acc 0.65789 roc_auc 0.40923 prc_auc 0.69249[0m
[92maverage training of epoch 24: loss -3.95349 acc 0.66667 roc_auc 0.50380 prc_auc 0.65836[0m
[93maverage test of epoch 24: loss -4.11926 acc 0.65789 roc_auc 0.68000 prc_auc 0.81428[0m
[92maverage training of epoch 25: loss -4.29734 acc 0.66667 roc_auc 0.41420 prc_auc 0.61906[0m
[93maverage test of epoch 25: loss -4.42981 acc 0.65789 roc_auc 0.48000 prc_auc 0.68660[0m
[92maverage training of epoch 26: loss -4.64572 acc 0.66667 roc_auc 0.41700 prc_auc 0.59982[0m
[93maverage test of epoch 26: loss -4.75993 acc 0.65789 roc_auc 0.43385 prc_auc 0.68871[0m
[92maverage training of epoch 27: loss -5.01607 acc 0.66667 roc_auc 0.47020 prc_auc 0.65041[0m
[93maverage test of epoch 27: loss -5.13524 acc 0.65789 roc_auc 0.36923 prc_auc 0.62577[0m
[92maverage training of epoch 28: loss -5.39475 acc 0.66667 roc_auc 0.46740 prc_auc 0.63178[0m
[93maverage test of epoch 28: loss -5.52187 acc 0.65789 roc_auc 0.62154 prc_auc 0.79632[0m
[92maverage training of epoch 29: loss -5.76907 acc 0.66667 roc_auc 0.43540 prc_auc 0.62293[0m
[93maverage test of epoch 29: loss -5.92089 acc 0.65789 roc_auc 0.40923 prc_auc 0.62708[0m
[92maverage training of epoch 30: loss -6.15212 acc 0.66667 roc_auc 0.43920 prc_auc 0.63096[0m
[93maverage test of epoch 30: loss -6.29788 acc 0.65789 roc_auc 0.48615 prc_auc 0.71721[0m
[92maverage training of epoch 31: loss -6.56988 acc 0.66667 roc_auc 0.46520 prc_auc 0.64668[0m
[93maverage test of epoch 31: loss -6.71480 acc 0.65789 roc_auc 0.54769 prc_auc 0.75449[0m
[92maverage training of epoch 32: loss -6.99733 acc 0.66667 roc_auc 0.36300 prc_auc 0.59064[0m
[93maverage test of epoch 32: loss -7.19385 acc 0.65789 roc_auc 0.52923 prc_auc 0.73286[0m
[92maverage training of epoch 33: loss -7.43874 acc 0.66667 roc_auc 0.44640 prc_auc 0.61536[0m
[93maverage test of epoch 33: loss -7.60635 acc 0.65789 roc_auc 0.34000 prc_auc 0.60761[0m
[92maverage training of epoch 34: loss -7.89743 acc 0.66667 roc_auc 0.46270 prc_auc 0.65343[0m
[93maverage test of epoch 34: loss -8.06843 acc 0.65789 roc_auc 0.61231 prc_auc 0.79969[0m
[92maverage training of epoch 35: loss -8.35503 acc 0.66667 roc_auc 0.39920 prc_auc 0.61144[0m
[93maverage test of epoch 35: loss -8.55315 acc 0.65789 roc_auc 0.59385 prc_auc 0.71749[0m
[92maverage training of epoch 36: loss -8.85713 acc 0.66667 roc_auc 0.37880 prc_auc 0.60312[0m
[93maverage test of epoch 36: loss -9.05041 acc 0.65789 roc_auc 0.47385 prc_auc 0.70997[0m
[92maverage training of epoch 37: loss -9.37114 acc 0.66667 roc_auc 0.40240 prc_auc 0.60523[0m
[93maverage test of epoch 37: loss -9.57098 acc 0.65789 roc_auc 0.40000 prc_auc 0.62759[0m
[92maverage training of epoch 38: loss -9.87504 acc 0.66667 roc_auc 0.36740 prc_auc 0.59298[0m
[93maverage test of epoch 38: loss -10.08692 acc 0.65789 roc_auc 0.56154 prc_auc 0.67909[0m
[92maverage training of epoch 39: loss -10.42138 acc 0.66667 roc_auc 0.40600 prc_auc 0.61092[0m
[93maverage test of epoch 39: loss -10.62936 acc 0.65789 roc_auc 0.61846 prc_auc 0.79656[0m
[92maverage training of epoch 40: loss -10.98711 acc 0.66667 roc_auc 0.40450 prc_auc 0.59950[0m
[93maverage test of epoch 40: loss -11.18977 acc 0.65789 roc_auc 0.49231 prc_auc 0.69051[0m
[92maverage training of epoch 41: loss -11.55889 acc 0.66667 roc_auc 0.37680 prc_auc 0.59225[0m
[93maverage test of epoch 41: loss -11.81944 acc 0.65789 roc_auc 0.76769 prc_auc 0.85342[0m
[92maverage training of epoch 42: loss -12.18504 acc 0.66667 roc_auc 0.44710 prc_auc 0.62634[0m
[93maverage test of epoch 42: loss -12.42558 acc 0.65789 roc_auc 0.43077 prc_auc 0.63517[0m
[92maverage training of epoch 43: loss -12.80169 acc 0.66667 roc_auc 0.40990 prc_auc 0.60610[0m
[93maverage test of epoch 43: loss -13.06709 acc 0.65789 roc_auc 0.67846 prc_auc 0.74366[0m
[92maverage training of epoch 44: loss -13.45532 acc 0.66667 roc_auc 0.36980 prc_auc 0.57440[0m
[93maverage test of epoch 44: loss -13.71914 acc 0.65789 roc_auc 0.67231 prc_auc 0.78087[0m
[92maverage training of epoch 45: loss -14.14939 acc 0.66667 roc_auc 0.44010 prc_auc 0.61181[0m
[93maverage test of epoch 45: loss -14.42929 acc 0.65789 roc_auc 0.40000 prc_auc 0.62464[0m
[92maverage training of epoch 46: loss -14.86680 acc 0.66667 roc_auc 0.43090 prc_auc 0.61158[0m
[93maverage test of epoch 46: loss -15.16026 acc 0.65789 roc_auc 0.61538 prc_auc 0.74692[0m
[92maverage training of epoch 47: loss -15.60018 acc 0.66667 roc_auc 0.46050 prc_auc 0.64874[0m
[93maverage test of epoch 47: loss -15.90811 acc 0.65789 roc_auc 0.42769 prc_auc 0.61947[0m
[92maverage training of epoch 48: loss -16.36812 acc 0.66667 roc_auc 0.42300 prc_auc 0.61289[0m
[93maverage test of epoch 48: loss -16.70200 acc 0.65789 roc_auc 0.56462 prc_auc 0.70964[0m
[92maverage training of epoch 49: loss -17.17972 acc 0.66667 roc_auc 0.40970 prc_auc 0.60108[0m
[93maverage test of epoch 49: loss -17.51084 acc 0.65789 roc_auc 0.39077 prc_auc 0.59659[0m
[92maverage training of epoch 50: loss -18.01897 acc 0.66667 roc_auc 0.40850 prc_auc 0.60317[0m
[93maverage test of epoch 50: loss -18.37222 acc 0.65789 roc_auc 0.28615 prc_auc 0.55647[0m
[92maverage training of epoch 51: loss -18.90579 acc 0.66667 roc_auc 0.38690 prc_auc 0.59114[0m
[93maverage test of epoch 51: loss -19.28252 acc 0.65789 roc_auc 0.47846 prc_auc 0.64828[0m
[92maverage training of epoch 52: loss -19.80832 acc 0.66667 roc_auc 0.41770 prc_auc 0.61093[0m
[93maverage test of epoch 52: loss -20.20533 acc 0.65789 roc_auc 0.54615 prc_auc 0.68449[0m
[92maverage training of epoch 53: loss -20.79482 acc 0.66667 roc_auc 0.39270 prc_auc 0.59389[0m
[93maverage test of epoch 53: loss -21.20283 acc 0.65789 roc_auc 0.53231 prc_auc 0.67914[0m
[92maverage training of epoch 54: loss -21.78552 acc 0.66667 roc_auc 0.39930 prc_auc 0.60390[0m
[93maverage test of epoch 54: loss -22.22333 acc 0.65789 roc_auc 0.56308 prc_auc 0.70123[0m
[92maverage training of epoch 55: loss -22.84774 acc 0.66667 roc_auc 0.40930 prc_auc 0.61675[0m
[93maverage test of epoch 55: loss -23.29041 acc 0.65789 roc_auc 0.34308 prc_auc 0.58438[0m
[92maverage training of epoch 56: loss -23.94103 acc 0.66667 roc_auc 0.38640 prc_auc 0.59114[0m
[93maverage test of epoch 56: loss -24.43243 acc 0.65789 roc_auc 0.52923 prc_auc 0.67217[0m
[92maverage training of epoch 57: loss -25.10088 acc 0.66667 roc_auc 0.44360 prc_auc 0.61788[0m
[93maverage test of epoch 57: loss -25.61107 acc 0.65789 roc_auc 0.43385 prc_auc 0.62211[0m
[92maverage training of epoch 58: loss -26.30500 acc 0.66667 roc_auc 0.41170 prc_auc 0.60456[0m
[93maverage test of epoch 58: loss -26.83125 acc 0.65789 roc_auc 0.43692 prc_auc 0.61497[0m
[92maverage training of epoch 59: loss -27.55942 acc 0.66667 roc_auc 0.43580 prc_auc 0.62330[0m
[93maverage test of epoch 59: loss -28.10659 acc 0.65789 roc_auc 0.52462 prc_auc 0.69683[0m
[92maverage training of epoch 60: loss -28.86998 acc 0.66667 roc_auc 0.40270 prc_auc 0.61581[0m
[93maverage test of epoch 60: loss -29.43939 acc 0.65789 roc_auc 0.35846 prc_auc 0.58714[0m
[92maverage training of epoch 61: loss -30.22227 acc 0.66667 roc_auc 0.40250 prc_auc 0.60522[0m
[93maverage test of epoch 61: loss -30.84358 acc 0.65789 roc_auc 0.55692 prc_auc 0.68486[0m
[92maverage training of epoch 62: loss -31.62209 acc 0.66667 roc_auc 0.41870 prc_auc 0.62149[0m
[93maverage test of epoch 62: loss -32.25654 acc 0.65789 roc_auc 0.41231 prc_auc 0.61260[0m
[92maverage training of epoch 63: loss -33.09329 acc 0.66667 roc_auc 0.38000 prc_auc 0.60504[0m
[93maverage test of epoch 63: loss -33.74296 acc 0.65789 roc_auc 0.65538 prc_auc 0.75504[0m
[92maverage training of epoch 64: loss -34.59828 acc 0.66667 roc_auc 0.39640 prc_auc 0.60958[0m
[93maverage test of epoch 64: loss -35.28014 acc 0.65789 roc_auc 0.61231 prc_auc 0.71958[0m
[92maverage training of epoch 65: loss -36.13765 acc 0.66667 roc_auc 0.37440 prc_auc 0.60821[0m
[93maverage test of epoch 65: loss -36.83993 acc 0.65789 roc_auc 0.60923 prc_auc 0.74353[0m
[92maverage training of epoch 66: loss -37.74579 acc 0.66667 roc_auc 0.39960 prc_auc 0.61041[0m
[93maverage test of epoch 66: loss -38.46535 acc 0.65789 roc_auc 0.45538 prc_auc 0.63730[0m
[92maverage training of epoch 67: loss -39.38185 acc 0.66667 roc_auc 0.42360 prc_auc 0.63499[0m
[93maverage test of epoch 67: loss -40.11136 acc 0.65789 roc_auc 0.67846 prc_auc 0.76445[0m
[92maverage training of epoch 68: loss -41.07189 acc 0.66667 roc_auc 0.37920 prc_auc 0.59965[0m
[93maverage test of epoch 68: loss -41.83278 acc 0.65789 roc_auc 0.49385 prc_auc 0.65512[0m
[92maverage training of epoch 69: loss -42.80512 acc 0.66667 roc_auc 0.40720 prc_auc 0.60803[0m
[93maverage test of epoch 69: loss -43.58281 acc 0.65789 roc_auc 0.49538 prc_auc 0.65814[0m
[92maverage training of epoch 70: loss -44.57854 acc 0.66667 roc_auc 0.39210 prc_auc 0.61087[0m
[93maverage test of epoch 70: loss -45.39441 acc 0.65789 roc_auc 0.52923 prc_auc 0.67394[0m
[92maverage training of epoch 71: loss -46.40114 acc 0.66667 roc_auc 0.39760 prc_auc 0.61006[0m
[93maverage test of epoch 71: loss -47.23345 acc 0.65789 roc_auc 0.45846 prc_auc 0.63849[0m
[92maverage training of epoch 72: loss -48.26864 acc 0.66667 roc_auc 0.39400 prc_auc 0.62170[0m
[93maverage test of epoch 72: loss -49.13016 acc 0.65789 roc_auc 0.52462 prc_auc 0.67211[0m
[92maverage training of epoch 73: loss -50.18056 acc 0.66667 roc_auc 0.37450 prc_auc 0.59653[0m
[93maverage test of epoch 73: loss -51.05037 acc 0.65789 roc_auc 0.53077 prc_auc 0.68886[0m
[92maverage training of epoch 74: loss -52.13292 acc 0.66667 roc_auc 0.40010 prc_auc 0.61813[0m
[93maverage test of epoch 74: loss -53.03479 acc 0.65789 roc_auc 0.35692 prc_auc 0.59960[0m
[92maverage training of epoch 75: loss -54.12959 acc 0.66667 roc_auc 0.41230 prc_auc 0.61137[0m
[93maverage test of epoch 75: loss -55.04896 acc 0.65789 roc_auc 0.60462 prc_auc 0.71414[0m
[92maverage training of epoch 76: loss -56.16396 acc 0.66667 roc_auc 0.40600 prc_auc 0.61184[0m
[93maverage test of epoch 76: loss -57.10141 acc 0.65789 roc_auc 0.45692 prc_auc 0.63870[0m
[92maverage training of epoch 77: loss -58.24932 acc 0.66667 roc_auc 0.39410 prc_auc 0.60958[0m
[93maverage test of epoch 77: loss -59.21263 acc 0.65789 roc_auc 0.40000 prc_auc 0.61495[0m
[92maverage training of epoch 78: loss -60.37674 acc 0.66667 roc_auc 0.39580 prc_auc 0.60625[0m
[93maverage test of epoch 78: loss -61.36799 acc 0.65789 roc_auc 0.45385 prc_auc 0.63816[0m
[92maverage training of epoch 79: loss -62.55492 acc 0.66667 roc_auc 0.38990 prc_auc 0.60019[0m
[93maverage test of epoch 79: loss -63.57223 acc 0.65789 roc_auc 0.53846 prc_auc 0.67568[0m
[92maverage training of epoch 80: loss -64.78062 acc 0.66667 roc_auc 0.38770 prc_auc 0.60373[0m
[93maverage test of epoch 80: loss -65.80351 acc 0.65789 roc_auc 0.59231 prc_auc 0.70396[0m
[92maverage training of epoch 81: loss -67.05427 acc 0.66667 roc_auc 0.38090 prc_auc 0.60042[0m
[93maverage test of epoch 81: loss -68.10708 acc 0.65789 roc_auc 0.42000 prc_auc 0.62409[0m
[92maverage training of epoch 82: loss -69.37894 acc 0.66667 roc_auc 0.38820 prc_auc 0.60574[0m
[93maverage test of epoch 82: loss -70.45968 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 83: loss -71.75592 acc 0.66667 roc_auc 0.39430 prc_auc 0.61129[0m
[93maverage test of epoch 83: loss -72.85227 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 84: loss -74.18410 acc 0.66667 roc_auc 0.40110 prc_auc 0.61717[0m
[93maverage test of epoch 84: loss -75.30318 acc 0.65789 roc_auc 0.48000 prc_auc 0.64902[0m
[92maverage training of epoch 85: loss -76.65878 acc 0.66667 roc_auc 0.38540 prc_auc 0.60634[0m
[93maverage test of epoch 85: loss -77.79931 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 86: loss -79.18594 acc 0.66667 roc_auc 0.37930 prc_auc 0.60477[0m
[93maverage test of epoch 86: loss -80.37718 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 87: loss -81.78011 acc 0.66667 roc_auc 0.38720 prc_auc 0.61305[0m
[93maverage test of epoch 87: loss -82.97036 acc 0.65789 roc_auc 0.53692 prc_auc 0.67498[0m
[92maverage training of epoch 88: loss -84.42135 acc 0.66667 roc_auc 0.38690 prc_auc 0.61224[0m
[93maverage test of epoch 88: loss -85.63992 acc 0.65789 roc_auc 0.46000 prc_auc 0.64041[0m
[92maverage training of epoch 89: loss -87.11066 acc 0.66667 roc_auc 0.40490 prc_auc 0.62161[0m
[93maverage test of epoch 89: loss -88.37308 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -89.86339 acc 0.66667 roc_auc 0.45080 prc_auc 0.64584[0m
[93maverage test of epoch 90: loss -91.15621 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 91: loss -92.67666 acc 0.66667 roc_auc 0.39830 prc_auc 0.62277[0m
[93maverage test of epoch 91: loss -93.99428 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 92: loss -95.54476 acc 0.66667 roc_auc 0.38820 prc_auc 0.62302[0m
[93maverage test of epoch 92: loss -96.88528 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 93: loss -98.46882 acc 0.66667 roc_auc 0.38760 prc_auc 0.62584[0m
[93maverage test of epoch 93: loss -99.83545 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 94: loss -101.45665 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 94: loss -102.84947 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 95: loss -104.49696 acc 0.66667 roc_auc 0.47500 prc_auc 0.65579[0m
[93maverage test of epoch 95: loss -105.92300 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 96: loss -107.60297 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 96: loss -109.05299 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 97: loss -110.76689 acc 0.66667 roc_auc 0.47500 prc_auc 0.65578[0m
[93maverage test of epoch 97: loss -112.23646 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 98: loss -113.99708 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 98: loss -115.49880 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -117.28064 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 99: loss -118.81937 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=4, bias=True)
    (ReLU1): ReLU()
    (Linear2): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.23813 acc 0.33775 roc_auc 0.55137 prc_auc 0.67802[0m
[93maverage test of epoch 0: loss -0.29222 acc 0.32432 roc_auc 0.49000 prc_auc 0.70921[0m
[92maverage training of epoch 1: loss -0.35775 acc 0.33775 roc_auc 0.56255 prc_auc 0.74094[0m
[93maverage test of epoch 1: loss -0.40965 acc 0.32432 roc_auc 0.47667 prc_auc 0.65907[0m
[92maverage training of epoch 2: loss -0.46488 acc 0.33775 roc_auc 0.56961 prc_auc 0.69945[0m
[93maverage test of epoch 2: loss -0.50372 acc 0.32432 roc_auc 0.33333 prc_auc 0.61119[0m
[92maverage training of epoch 3: loss -0.56669 acc 0.33775 roc_auc 0.58471 prc_auc 0.70878[0m
[93maverage test of epoch 3: loss -0.60552 acc 0.32432 roc_auc 0.64667 prc_auc 0.80368[0m
[92maverage training of epoch 4: loss -0.67600 acc 0.33775 roc_auc 0.59059 prc_auc 0.74782[0m
[93maverage test of epoch 4: loss -0.72002 acc 0.32432 roc_auc 0.48000 prc_auc 0.66444[0m
[92maverage training of epoch 5: loss -0.80395 acc 0.33775 roc_auc 0.53784 prc_auc 0.67812[0m
[93maverage test of epoch 5: loss -0.85592 acc 0.32432 roc_auc 0.64000 prc_auc 0.81131[0m
[92maverage training of epoch 6: loss -0.94966 acc 0.33775 roc_auc 0.54255 prc_auc 0.68272[0m
[93maverage test of epoch 6: loss -1.01021 acc 0.32432 roc_auc 0.43000 prc_auc 0.70556[0m
[92maverage training of epoch 7: loss -1.11306 acc 0.33775 roc_auc 0.58020 prc_auc 0.69696[0m
[93maverage test of epoch 7: loss -1.17763 acc 0.32432 roc_auc 0.70667 prc_auc 0.83532[0m
[92maverage training of epoch 8: loss -1.29220 acc 0.33775 roc_auc 0.56569 prc_auc 0.69795[0m
[93maverage test of epoch 8: loss -1.36575 acc 0.32432 roc_auc 0.46000 prc_auc 0.67963[0m
[92maverage training of epoch 9: loss -1.48595 acc 0.33775 roc_auc 0.54039 prc_auc 0.70047[0m
[93maverage test of epoch 9: loss -1.57967 acc 0.32432 roc_auc 0.60000 prc_auc 0.71724[0m
[92maverage training of epoch 10: loss -1.71155 acc 0.33775 roc_auc 0.57078 prc_auc 0.71269[0m
[93maverage test of epoch 10: loss -1.80396 acc 0.32432 roc_auc 0.49000 prc_auc 0.67652[0m
[92maverage training of epoch 11: loss -1.96477 acc 0.33775 roc_auc 0.51176 prc_auc 0.67313[0m
[93maverage test of epoch 11: loss -2.07740 acc 0.32432 roc_auc 0.37000 prc_auc 0.65221[0m
[92maverage training of epoch 12: loss -2.24524 acc 0.33775 roc_auc 0.55118 prc_auc 0.66955[0m
[93maverage test of epoch 12: loss -2.36044 acc 0.32432 roc_auc 0.37000 prc_auc 0.61589[0m
[92maverage training of epoch 13: loss -2.54453 acc 0.33775 roc_auc 0.55392 prc_auc 0.70869[0m
[93maverage test of epoch 13: loss -2.66977 acc 0.32432 roc_auc 0.51333 prc_auc 0.74355[0m
[92maverage training of epoch 14: loss -2.83817 acc 0.33775 roc_auc 0.50039 prc_auc 0.63911[0m
[93maverage test of epoch 14: loss -2.95682 acc 0.32432 roc_auc 0.47000 prc_auc 0.64977[0m
[92maverage training of epoch 15: loss -3.13271 acc 0.33775 roc_auc 0.53529 prc_auc 0.70042[0m
[93maverage test of epoch 15: loss -3.24055 acc 0.32432 roc_auc 0.27333 prc_auc 0.59507[0m
[92maverage training of epoch 16: loss -3.42324 acc 0.33775 roc_auc 0.50431 prc_auc 0.66331[0m
[93maverage test of epoch 16: loss -3.53355 acc 0.32432 roc_auc 0.49000 prc_auc 0.68656[0m
[92maverage training of epoch 17: loss -3.71679 acc 0.33775 roc_auc 0.57020 prc_auc 0.71166[0m
[93maverage test of epoch 17: loss -3.82340 acc 0.32432 roc_auc 0.59333 prc_auc 0.70653[0m
[92maverage training of epoch 18: loss -4.01288 acc 0.33775 roc_auc 0.55627 prc_auc 0.69317[0m
[93maverage test of epoch 18: loss -4.12315 acc 0.32432 roc_auc 0.57333 prc_auc 0.71746[0m
[92maverage training of epoch 19: loss -4.31072 acc 0.33775 roc_auc 0.55706 prc_auc 0.71846[0m
[93maverage test of epoch 19: loss -4.42305 acc 0.32432 roc_auc 0.50333 prc_auc 0.72179[0m
[92maverage training of epoch 20: loss -4.61459 acc 0.33775 roc_auc 0.51588 prc_auc 0.67325[0m
[93maverage test of epoch 20: loss -4.73831 acc 0.32432 roc_auc 0.44333 prc_auc 0.66203[0m
[92maverage training of epoch 21: loss -4.92946 acc 0.33775 roc_auc 0.54373 prc_auc 0.68429[0m
[93maverage test of epoch 21: loss -5.04264 acc 0.32432 roc_auc 0.57000 prc_auc 0.70680[0m
[92maverage training of epoch 22: loss -5.24087 acc 0.33775 roc_auc 0.55078 prc_auc 0.70578[0m
[93maverage test of epoch 22: loss -5.35560 acc 0.32432 roc_auc 0.60000 prc_auc 0.74893[0m
[92maverage training of epoch 23: loss -5.56949 acc 0.33775 roc_auc 0.55118 prc_auc 0.67216[0m
[93maverage test of epoch 23: loss -5.69986 acc 0.32432 roc_auc 0.40333 prc_auc 0.66187[0m
[92maverage training of epoch 24: loss -5.90147 acc 0.33775 roc_auc 0.53137 prc_auc 0.65477[0m
[93maverage test of epoch 24: loss -6.02890 acc 0.32432 roc_auc 0.39667 prc_auc 0.64595[0m
[92maverage training of epoch 25: loss -6.23942 acc 0.33775 roc_auc 0.50314 prc_auc 0.64034[0m
[93maverage test of epoch 25: loss -6.37334 acc 0.32432 roc_auc 0.38333 prc_auc 0.62623[0m
[92maverage training of epoch 26: loss -6.59236 acc 0.33775 roc_auc 0.52176 prc_auc 0.68768[0m
[93maverage test of epoch 26: loss -6.73594 acc 0.32432 roc_auc 0.61000 prc_auc 0.79785[0m
[92maverage training of epoch 27: loss -6.96406 acc 0.33775 roc_auc 0.51431 prc_auc 0.68360[0m
[93maverage test of epoch 27: loss -7.10147 acc 0.32432 roc_auc 0.41667 prc_auc 0.63545[0m
[92maverage training of epoch 28: loss -7.33226 acc 0.33775 roc_auc 0.52471 prc_auc 0.66618[0m
[93maverage test of epoch 28: loss -7.46961 acc 0.32432 roc_auc 0.37667 prc_auc 0.64989[0m
[92maverage training of epoch 29: loss -7.71082 acc 0.33775 roc_auc 0.52627 prc_auc 0.67485[0m
[93maverage test of epoch 29: loss -7.85480 acc 0.32432 roc_auc 0.54667 prc_auc 0.76513[0m
[92maverage training of epoch 30: loss -8.11151 acc 0.33775 roc_auc 0.53667 prc_auc 0.70004[0m
[93maverage test of epoch 30: loss -8.25806 acc 0.32432 roc_auc 0.50000 prc_auc 0.69409[0m
[92maverage training of epoch 31: loss -8.51554 acc 0.33775 roc_auc 0.56510 prc_auc 0.71858[0m
[93maverage test of epoch 31: loss -8.66948 acc 0.32432 roc_auc 0.40667 prc_auc 0.62869[0m
[92maverage training of epoch 32: loss -8.92845 acc 0.33775 roc_auc 0.50569 prc_auc 0.67421[0m
[93maverage test of epoch 32: loss -9.06906 acc 0.32432 roc_auc 0.47667 prc_auc 0.73609[0m
[92maverage training of epoch 33: loss -9.35514 acc 0.33775 roc_auc 0.52686 prc_auc 0.66539[0m
[93maverage test of epoch 33: loss -9.50829 acc 0.32432 roc_auc 0.43167 prc_auc 0.62814[0m
[92maverage training of epoch 34: loss -9.78345 acc 0.33775 roc_auc 0.54324 prc_auc 0.71063[0m
[93maverage test of epoch 34: loss -9.94399 acc 0.32432 roc_auc 0.35000 prc_auc 0.60902[0mUsing backend: pytorch

[92maverage training of epoch 35: loss -10.22702 acc 0.33775 roc_auc 0.48784 prc_auc 0.64106[0m
[93maverage test of epoch 35: loss -10.40005 acc 0.32432 roc_auc 0.48667 prc_auc 0.69302[0m
[92maverage training of epoch 36: loss -10.67961 acc 0.33775 roc_auc 0.54392 prc_auc 0.69474[0m
[93maverage test of epoch 36: loss -10.84484 acc 0.32432 roc_auc 0.45667 prc_auc 0.69106[0m
[92maverage training of epoch 37: loss -11.14695 acc 0.33775 roc_auc 0.47157 prc_auc 0.63368[0m
[93maverage test of epoch 37: loss -11.32011 acc 0.32432 roc_auc 0.53000 prc_auc 0.73166[0m
[92maverage training of epoch 38: loss -11.61720 acc 0.33775 roc_auc 0.49412 prc_auc 0.66458[0m
[93maverage test of epoch 38: loss -11.80382 acc 0.32432 roc_auc 0.46333 prc_auc 0.66708[0m
[92maverage training of epoch 39: loss -12.10801 acc 0.33775 roc_auc 0.49627 prc_auc 0.65587[0m
[93maverage test of epoch 39: loss -12.29204 acc 0.32432 roc_auc 0.34333 prc_auc 0.59777[0m
[92maverage training of epoch 40: loss -12.60478 acc 0.33775 roc_auc 0.53510 prc_auc 0.70358[0m
[93maverage test of epoch 40: loss -12.79402 acc 0.32432 roc_auc 0.45000 prc_auc 0.71488[0m
[92maverage training of epoch 41: loss -13.11836 acc 0.33775 roc_auc 0.49510 prc_auc 0.67439[0m
[93maverage test of epoch 41: loss -13.29534 acc 0.32432 roc_auc 0.49000 prc_auc 0.72687[0m
[92maverage training of epoch 42: loss -13.63575 acc 0.33775 roc_auc 0.52412 prc_auc 0.67930[0m
[93maverage test of epoch 42: loss -13.83350 acc 0.32432 roc_auc 0.62500 prc_auc 0.75922[0m
[92maverage training of epoch 43: loss -14.17259 acc 0.33775 roc_auc 0.47118 prc_auc 0.62669[0m
[93maverage test of epoch 43: loss -14.38187 acc 0.32432 roc_auc 0.46833 prc_auc 0.67918[0m
[92maverage training of epoch 44: loss -14.72023 acc 0.33775 roc_auc 0.50020 prc_auc 0.67037[0m
[93maverage test of epoch 44: loss -14.93460 acc 0.32432 roc_auc 0.65500 prc_auc 0.82596[0m
[92maverage training of epoch 45: loss -15.28246 acc 0.33775 roc_auc 0.48745 prc_auc 0.65083[0m
[93maverage test of epoch 45: loss -15.50024 acc 0.32432 roc_auc 0.65000 prc_auc 0.78837[0m
[92maverage training of epoch 46: loss -15.85042 acc 0.33775 roc_auc 0.53725 prc_auc 0.68787[0m
[93maverage test of epoch 46: loss -16.07362 acc 0.32432 roc_auc 0.50667 prc_auc 0.69947[0m
[92maverage training of epoch 47: loss -16.42942 acc 0.33775 roc_auc 0.48392 prc_auc 0.65440[0m
[93maverage test of epoch 47: loss -16.65969 acc 0.32432 roc_auc 0.40000 prc_auc 0.63447[0m
[92maverage training of epoch 48: loss -17.02747 acc 0.33775 roc_auc 0.50020 prc_auc 0.65810[0m
[93maverage test of epoch 48: loss -17.26106 acc 0.32432 roc_auc 0.53333 prc_auc 0.70457[0m
[92maverage training of epoch 49: loss -17.63669 acc 0.33775 roc_auc 0.47627 prc_auc 0.63392[0m
[93maverage test of epoch 49: loss -17.87909 acc 0.32432 roc_auc 0.49667 prc_auc 0.72331[0m
[92maverage training of epoch 50: loss -18.25653 acc 0.33775 roc_auc 0.45480 prc_auc 0.65845[0m
[93maverage test of epoch 50: loss -18.49491 acc 0.32432 roc_auc 0.58500 prc_auc 0.78762[0m
[92maverage training of epoch 51: loss -18.89154 acc 0.33775 roc_auc 0.47961 prc_auc 0.64531[0m
[93maverage test of epoch 51: loss -19.14167 acc 0.32432 roc_auc 0.55667 prc_auc 0.78855[0m
[92maverage training of epoch 52: loss -19.53819 acc 0.33775 roc_auc 0.48412 prc_auc 0.66679[0m
[93maverage test of epoch 52: loss -19.79630 acc 0.32432 roc_auc 0.44833 prc_auc 0.67237[0m
[92maverage training of epoch 53: loss -20.19532 acc 0.33775 roc_auc 0.45529 prc_auc 0.65909[0m
[93maverage test of epoch 53: loss -20.44712 acc 0.32432 roc_auc 0.44333 prc_auc 0.65679[0m
[92maverage training of epoch 54: loss -20.86680 acc 0.33775 roc_auc 0.43725 prc_auc 0.60497[0m
[93maverage test of epoch 54: loss -21.13217 acc 0.32432 roc_auc 0.48833 prc_auc 0.74719[0m
[92maverage training of epoch 55: loss -21.55762 acc 0.33775 roc_auc 0.47706 prc_auc 0.67170[0m
[93maverage test of epoch 55: loss -21.83111 acc 0.32432 roc_auc 0.60000 prc_auc 0.82101[0m
[92maverage training of epoch 56: loss -22.25834 acc 0.33775 roc_auc 0.47275 prc_auc 0.65272[0m
[93maverage test of epoch 56: loss -22.53736 acc 0.32432 roc_auc 0.52833 prc_auc 0.70510[0m
[92maverage training of epoch 57: loss -22.97251 acc 0.33775 roc_auc 0.46686 prc_auc 0.65611[0m
[93maverage test of epoch 57: loss -23.25843 acc 0.32432 roc_auc 0.44667 prc_auc 0.65470[0m
[92maverage training of epoch 58: loss -23.70280 acc 0.33775 roc_auc 0.43461 prc_auc 0.63093[0m
[93maverage test of epoch 58: loss -24.00158 acc 0.32432 roc_auc 0.41167 prc_auc 0.65349[0m
[92maverage training of epoch 59: loss -24.44842 acc 0.33775 roc_auc 0.43069 prc_auc 0.64052[0m
[93maverage test of epoch 59: loss -24.74800 acc 0.32432 roc_auc 0.48500 prc_auc 0.69623[0m
[92maverage training of epoch 60: loss -25.20555 acc 0.33775 roc_auc 0.42314 prc_auc 0.61495[0m
[93maverage test of epoch 60: loss -25.51525 acc 0.32432 roc_auc 0.36333 prc_auc 0.59459[0m
[92maverage training of epoch 61: loss -25.97813 acc 0.33775 roc_auc 0.44500 prc_auc 0.63798[0m
[93maverage test of epoch 61: loss -26.29511 acc 0.32432 roc_auc 0.36333 prc_auc 0.62433[0m
[92maverage training of epoch 62: loss -26.76790 acc 0.33775 roc_auc 0.45588 prc_auc 0.66895[0m
[93maverage test of epoch 62: loss -27.09275 acc 0.32432 roc_auc 0.54000 prc_auc 0.76163[0m
[92maverage training of epoch 63: loss -27.57202 acc 0.33775 roc_auc 0.43520 prc_auc 0.66175[0m
[93maverage test of epoch 63: loss -27.89717 acc 0.32432 roc_auc 0.59000 prc_auc 0.77429[0m
[92maverage training of epoch 64: loss -28.39691 acc 0.33775 roc_auc 0.43804 prc_auc 0.65036[0m
[93maverage test of epoch 64: loss -28.72634 acc 0.32432 roc_auc 0.35833 prc_auc 0.59504[0m
[92maverage training of epoch 65: loss -29.22809 acc 0.33775 roc_auc 0.42490 prc_auc 0.62832[0m
[93maverage test of epoch 65: loss -29.57545 acc 0.32432 roc_auc 0.54333 prc_auc 0.79283[0m
[92maverage training of epoch 66: loss -30.07812 acc 0.33775 roc_auc 0.42471 prc_auc 0.61417[0m
[93maverage test of epoch 66: loss -30.42993 acc 0.32432 roc_auc 0.68333 prc_auc 0.83438[0m
[92maverage training of epoch 67: loss -30.94526 acc 0.33775 roc_auc 0.39294 prc_auc 0.60356[0m
[93maverage test of epoch 67: loss -31.30429 acc 0.32432 roc_auc 0.33667 prc_auc 0.59893[0m
[92maverage training of epoch 68: loss -31.82679 acc 0.33775 roc_auc 0.41490 prc_auc 0.61508[0m
[93maverage test of epoch 68: loss -32.19440 acc 0.32432 roc_auc 0.45833 prc_auc 0.69291[0m
[92maverage training of epoch 69: loss -32.72776 acc 0.33775 roc_auc 0.39549 prc_auc 0.61988[0m
[93maverage test of epoch 69: loss -33.10673 acc 0.32432 roc_auc 0.45167 prc_auc 0.74242[0m
[92maverage training of epoch 70: loss -33.64462 acc 0.33775 roc_auc 0.38314 prc_auc 0.59541[0m
[93maverage test of epoch 70: loss -34.02600 acc 0.32432 roc_auc 0.57333 prc_auc 0.75996[0m
[92maverage training of epoch 71: loss -34.57642 acc 0.33775 roc_auc 0.39451 prc_auc 0.62999[0m
[93maverage test of epoch 71: loss -34.96504 acc 0.32432 roc_auc 0.44333 prc_auc 0.67358[0m
[92maverage training of epoch 72: loss -35.52635 acc 0.33775 roc_auc 0.38627 prc_auc 0.61870[0m
[93maverage test of epoch 72: loss -35.92570 acc 0.32432 roc_auc 0.36167 prc_auc 0.61321[0m
[92maverage training of epoch 73: loss -36.48895 acc 0.33775 roc_auc 0.39216 prc_auc 0.60700[0m
[93maverage test of epoch 73: loss -36.90167 acc 0.32432 roc_auc 0.53833 prc_auc 0.73045[0m
[92maverage training of epoch 74: loss -37.47665 acc 0.33775 roc_auc 0.42637 prc_auc 0.61162[0m
[93maverage test of epoch 74: loss -37.91274 acc 0.32432 roc_auc 0.42500 prc_auc 0.63370[0m
[92maverage training of epoch 75: loss -38.54502 acc 0.33775 roc_auc 0.47765 prc_auc 0.64302[0m
[93maverage test of epoch 75: loss -39.02411 acc 0.32432 roc_auc 0.56833 prc_auc 0.77228[0m
[92maverage training of epoch 76: loss -39.67964 acc 0.33775 roc_auc 0.43471 prc_auc 0.61558[0m
[93maverage test of epoch 76: loss -40.17046 acc 0.32432 roc_auc 0.39333 prc_auc 0.69380[0m
[92maverage training of epoch 77: loss -40.84405 acc 0.33775 roc_auc 0.44608 prc_auc 0.62735[0m
[93maverage test of epoch 77: loss -41.34791 acc 0.32432 roc_auc 0.23167 prc_auc 0.58623[0m
[92maverage training of epoch 78: loss -42.02642 acc 0.33775 roc_auc 0.42598 prc_auc 0.63354[0m
[93maverage test of epoch 78: loss -42.54554 acc 0.32432 roc_auc 0.39500 prc_auc 0.65036[0m
[92maverage training of epoch 79: loss -43.23122 acc 0.33775 roc_auc 0.41216 prc_auc 0.61139[0m
[93maverage test of epoch 79: loss -43.75635 acc 0.32432 roc_auc 0.54667 prc_auc 0.70764[0m
[92maverage training of epoch 80: loss -44.45347 acc 0.33775 roc_auc 0.40745 prc_auc 0.62254[0m
[93maverage test of epoch 80: loss -44.98696 acc 0.32432 roc_auc 0.54333 prc_auc 0.76081[0m
[92maverage training of epoch 81: loss -45.70021 acc 0.33775 roc_auc 0.38784 prc_auc 0.60829[0m
[93maverage test of epoch 81: loss -46.24364 acc 0.32432 roc_auc 0.46833 prc_auc 0.72188[0m
[92maverage training of epoch 82: loss -46.96648 acc 0.33775 roc_auc 0.37912 prc_auc 0.58956[0m
[93maverage test of epoch 82: loss -47.52318 acc 0.32432 roc_auc 0.34500 prc_auc 0.61055[0m
[92maverage training of epoch 83: loss -48.25826 acc 0.33775 roc_auc 0.37157 prc_auc 0.60290[0m
[93maverage test of epoch 83: loss -48.83019 acc 0.32432 roc_auc 0.48500 prc_auc 0.72531[0m
[92maverage training of epoch 84: loss -49.57199 acc 0.33775 roc_auc 0.36961 prc_auc 0.59433[0m
[93maverage test of epoch 84: loss -50.15508 acc 0.32432 roc_auc 0.59000 prc_auc 0.77738[0m
[92maverage training of epoch 85: loss -50.91452 acc 0.33775 roc_auc 0.36569 prc_auc 0.58367[0m
[93maverage test of epoch 85: loss -51.50556 acc 0.32432 roc_auc 0.44667 prc_auc 0.64633[0m
[92maverage training of epoch 86: loss -52.28056 acc 0.33775 roc_auc 0.38373 prc_auc 0.61510[0m
[93maverage test of epoch 86: loss -52.89112 acc 0.32432 roc_auc 0.51500 prc_auc 0.70815[0m
[92maverage training of epoch 87: loss -53.67247 acc 0.33775 roc_auc 0.38078 prc_auc 0.59527[0m
[93maverage test of epoch 87: loss -54.29561 acc 0.32432 roc_auc 0.57333 prc_auc 0.72274[0m
[92maverage training of epoch 88: loss -55.09228 acc 0.33775 roc_auc 0.38118 prc_auc 0.59130[0m
[93maverage test of epoch 88: loss -55.73081 acc 0.32432 roc_auc 0.56500 prc_auc 0.75419[0m
[92maverage training of epoch 89: loss -56.53894 acc 0.33775 roc_auc 0.38098 prc_auc 0.58971[0m
[93maverage test of epoch 89: loss -57.19054 acc 0.32432 roc_auc 0.50167 prc_auc 0.67638[0m
[92maverage training of epoch 90: loss -58.01314 acc 0.33775 roc_auc 0.37608 prc_auc 0.59301[0m
[93maverage test of epoch 90: loss -58.67596 acc 0.32432 roc_auc 0.46667 prc_auc 0.65900[0m
[92maverage training of epoch 91: loss -59.51545 acc 0.33775 roc_auc 0.37745 prc_auc 0.58895[0m
[93maverage test of epoch 91: loss -60.19365 acc 0.32432 roc_auc 0.54000 prc_auc 0.71797[0m
[92maverage training of epoch 92: loss -61.04254 acc 0.33775 roc_auc 0.37275 prc_auc 0.58489[0m
[93maverage test of epoch 92: loss -61.73653 acc 0.32432 roc_auc 0.49667 prc_auc 0.70961[0m
[92maverage training of epoch 93: loss -62.60078 acc 0.33775 roc_auc 0.37608 prc_auc 0.58948[0m
[93maverage test of epoch 93: loss -63.30895 acc 0.32432 roc_auc 0.40000 prc_auc 0.64006[0m
[92maverage training of epoch 94: loss -64.18889 acc 0.33775 roc_auc 0.37451 prc_auc 0.58787[0m
[93maverage test of epoch 94: loss -64.91368 acc 0.32432 roc_auc 0.55667 prc_auc 0.76913[0m
[92maverage training of epoch 95: loss -65.80523 acc 0.33775 roc_auc 0.37275 prc_auc 0.58706[0m
[93maverage test of epoch 95: loss -66.54212 acc 0.32432 roc_auc 0.79833 prc_auc 0.90089[0m
[92maverage training of epoch 96: loss -67.45162 acc 0.33775 roc_auc 0.36804 prc_auc 0.58368[0m
[93maverage test of epoch 96: loss -68.20675 acc 0.32432 roc_auc 0.52500 prc_auc 0.70652[0m
[92maverage training of epoch 97: loss -69.12689 acc 0.33775 roc_auc 0.36294 prc_auc 0.57869[0m
[93maverage test of epoch 97: loss -69.89940 acc 0.32432 roc_auc 0.17667 prc_auc 0.54905[0m
[92maverage training of epoch 98: loss -70.83285 acc 0.33775 roc_auc 0.36412 prc_auc 0.57471[0m
[93maverage test of epoch 98: loss -71.62306 acc 0.32432 roc_auc 0.61167 prc_auc 0.78474[0m
[92maverage training of epoch 99: loss -72.57015 acc 0.33775 roc_auc 0.36098 prc_auc 0.58366[0m
[93maverage test of epoch 99: loss -73.37710 acc 0.32432 roc_auc 0.48667 prc_auc 0.68824[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=4, bias=True)
    (ReLU1): ReLU()
    (Linear2): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.59877 acc 0.66225 roc_auc 0.40922 prc_auc 0.62023[0m
[93maverage test of epoch 0: loss -0.67243 acc 0.67568 roc_auc 0.45000 prc_auc 0.65462[0m
[92maverage training of epoch 1: loss -0.73499 acc 0.66225 roc_auc 0.43667 prc_auc 0.61392[0m
[93maverage test of epoch 1: loss -0.81464 acc 0.67568 roc_auc 0.40667 prc_auc 0.60882[0m
[92maverage training of epoch 2: loss -0.90924 acc 0.66225 roc_auc 0.46608 prc_auc 0.65037[0m
[93maverage test of epoch 2: loss -1.01526 acc 0.67568 roc_auc 0.60000 prc_auc 0.78903[0m
[92maverage training of epoch 3: loss -1.10479 acc 0.66225 roc_auc 0.49588 prc_auc 0.64701[0m
[93maverage test of epoch 3: loss -1.23073 acc 0.67568 roc_auc 0.65667 prc_auc 0.83570[0m
[92maverage training of epoch 4: loss -1.31523 acc 0.66225 roc_auc 0.57686 prc_auc 0.73768[0m
[93maverage test of epoch 4: loss -1.42025 acc 0.67568 roc_auc 0.37667 prc_auc 0.67042[0m
[92maverage training of epoch 5: loss -1.52682 acc 0.66225 roc_auc 0.54765 prc_auc 0.70626[0m
[93maverage test of epoch 5: loss -1.62904 acc 0.67568 roc_auc 0.43000 prc_auc 0.71846[0m
[92maverage training of epoch 6: loss -1.74548 acc 0.66225 roc_auc 0.50039 prc_auc 0.69560[0m
[93maverage test of epoch 6: loss -1.90026 acc 0.67568 roc_auc 0.66000 prc_auc 0.82517[0m
[92maverage training of epoch 7: loss -1.98915 acc 0.66225 roc_auc 0.52804 prc_auc 0.71441[0m
[93maverage test of epoch 7: loss -2.15730 acc 0.67568 roc_auc 0.56333 prc_auc 0.77345[0m
[92maverage training of epoch 8: loss -2.26245 acc 0.66225 roc_auc 0.55451 prc_auc 0.70194[0m
[93maverage test of epoch 8: loss -2.47972 acc 0.67568 roc_auc 0.66000 prc_auc 0.83797[0m
[92maverage training of epoch 9: loss -2.57534 acc 0.66225 roc_auc 0.55569 prc_auc 0.69466[0m
[93maverage test of epoch 9: loss -2.82113 acc 0.67568 roc_auc 0.66000 prc_auc 0.79301[0m
[92maverage training of epoch 10: loss -2.92106 acc 0.66225 roc_auc 0.59275 prc_auc 0.74138[0m
[93maverage test of epoch 10: loss -3.15030 acc 0.67568 roc_auc 0.58333 prc_auc 0.78477[0m
[92maverage training of epoch 11: loss -3.27849 acc 0.66225 roc_auc 0.49078 prc_auc 0.68971[0m
[93maverage test of epoch 11: loss -3.50608 acc 0.67568 roc_auc 0.56333 prc_auc 0.78265[0m
[92maverage training of epoch 12: loss -3.66574 acc 0.66225 roc_auc 0.49980 prc_auc 0.67239[0m
[93maverage test of epoch 12: loss -3.93882 acc 0.67568 roc_auc 0.55333 prc_auc 0.79380[0m
[92maverage training of epoch 13: loss -4.06715 acc 0.66225 roc_auc 0.48353 prc_auc 0.67633[0m
[93maverage test of epoch 13: loss -4.35992 acc 0.67568 roc_auc 0.84000 prc_auc 0.92747[0m
[92maverage training of epoch 14: loss -4.51146 acc 0.66225 roc_auc 0.55412 prc_auc 0.69396[0m
[93maverage test of epoch 14: loss -4.72373 acc 0.67568 roc_auc 0.53333 prc_auc 0.70654[0m
[92maverage training of epoch 15: loss -4.93291 acc 0.66225 roc_auc 0.46804 prc_auc 0.65006[0m
[93maverage test of epoch 15: loss -5.20163 acc 0.67568 roc_auc 0.49167 prc_auc 0.67881[0m
[92maverage training of epoch 16: loss -5.35913 acc 0.66225 roc_auc 0.43716 prc_auc 0.63207[0m
[93maverage test of epoch 16: loss -5.73498 acc 0.67568 roc_auc 0.82333 prc_auc 0.91724[0m
[92maverage training of epoch 17: loss -5.81595 acc 0.66225 roc_auc 0.48784 prc_auc 0.64584[0m
[93maverage test of epoch 17: loss -6.15760 acc 0.67568 roc_auc 0.59667 prc_auc 0.74882[0m
[92maverage training of epoch 18: loss -6.28223 acc 0.66225 roc_auc 0.44431 prc_auc 0.60989[0m
[93maverage test of epoch 18: loss -6.67147 acc 0.67568 roc_auc 0.58000 prc_auc 0.78739[0m
[92maverage training of epoch 19: loss -6.79698 acc 0.66225 roc_auc 0.45441 prc_auc 0.64414[0m
[93maverage test of epoch 19: loss -7.16821 acc 0.67568 roc_auc 0.49000 prc_auc 0.68658[0m
[92maverage training of epoch 20: loss -7.35341 acc 0.66225 roc_auc 0.45471 prc_auc 0.63074[0m
[93maverage test of epoch 20: loss -7.72514 acc 0.67568 roc_auc 0.42333 prc_auc 0.66880[0m
[92maverage training of epoch 21: loss -7.90199 acc 0.66225 roc_auc 0.45588 prc_auc 0.64582[0m
[93maverage test of epoch 21: loss -8.34651 acc 0.67568 roc_auc 0.60167 prc_auc 0.75884[0m
[92maverage training of epoch 22: loss -8.46414 acc 0.66225 roc_auc 0.48735 prc_auc 0.65821[0m
[93maverage test of epoch 22: loss -8.85243 acc 0.67568 roc_auc 0.50833 prc_auc 0.68714[0m
[92maverage training of epoch 23: loss -9.04354 acc 0.66225 roc_auc 0.48373 prc_auc 0.64490[0m
[93maverage test of epoch 23: loss -9.46014 acc 0.67568 roc_auc 0.38167 prc_auc 0.60212[0m
[92maverage training of epoch 24: loss -9.65057 acc 0.66225 roc_auc 0.43902 prc_auc 0.62181[0m
[93maverage test of epoch 24: loss -10.13383 acc 0.67568 roc_auc 0.55833 prc_auc 0.75362[0m
[92maverage training of epoch 25: loss -10.29797 acc 0.66225 roc_auc 0.39706 prc_auc 0.59779[0m
[93maverage test of epoch 25: loss -10.70206 acc 0.67568 roc_auc 0.34500 prc_auc 0.60484[0m
[92maverage training of epoch 26: loss -10.94170 acc 0.66225 roc_auc 0.44363 prc_auc 0.62577[0m
[93maverage test of epoch 26: loss -11.49872 acc 0.67568 roc_auc 0.54333 prc_auc 0.69024[0m
[92maverage training of epoch 27: loss -11.62416 acc 0.66225 roc_auc 0.48559 prc_auc 0.64489[0m
[93maverage test of epoch 27: loss -12.17512 acc 0.67568 roc_auc 0.52500 prc_auc 0.68466[0m
[92maverage training of epoch 28: loss -12.32378 acc 0.66225 roc_auc 0.47922 prc_auc 0.64660[0m
[93maverage test of epoch 28: loss -12.79967 acc 0.67568 roc_auc 0.47333 prc_auc 0.65292[0m
[92maverage training of epoch 29: loss -13.02068 acc 0.66225 roc_auc 0.38941 prc_auc 0.58973[0m
[93maverage test of epoch 29: loss -13.54590 acc 0.67568 roc_auc 0.30500 prc_auc 0.59020[0m
[92maverage training of epoch 30: loss -13.79028 acc 0.66225 roc_auc 0.49951 prc_auc 0.66369[0m
[93maverage test of epoch 30: loss -14.30706 acc 0.67568 roc_auc 0.44833 prc_auc 0.66501[0m
[92maverage training of epoch 31: loss -14.54951 acc 0.66225 roc_auc 0.42098 prc_auc 0.61267[0m
[93maverage test of epoch 31: loss -15.16164 acc 0.67568 roc_auc 0.62833 prc_auc 0.73499[0m
[92maverage training of epoch 32: loss -15.33341 acc 0.66225 roc_auc 0.44755 prc_auc 0.63513[0m
[93maverage test of epoch 32: loss -15.93651 acc 0.67568 roc_auc 0.49000 prc_auc 0.67083[0m
[92maverage training of epoch 33: loss -16.14101 acc 0.66225 roc_auc 0.44922 prc_auc 0.63941[0m
[93maverage test of epoch 33: loss -16.79225 acc 0.67568 roc_auc 0.59167 prc_auc 0.72550[0m
[92maverage training of epoch 34: loss -16.97012 acc 0.66225 roc_auc 0.50118 prc_auc 0.66279[0m
[93maverage test of epoch 34: loss -17.58015 acc 0.67568 roc_auc 0.48000 prc_auc 0.66703[0m
[92maverage training of epoch 35: loss -17.80000 acc 0.66225 roc_auc 0.41412 prc_auc 0.62776[0m
[93maverage test of epoch 35: loss -18.48883 acc 0.67568 roc_auc 0.56500 prc_auc 0.70560[0m
[92maverage training of epoch 36: loss -18.67002 acc 0.66225 roc_auc 0.49441 prc_auc 0.65976[0m
[93maverage test of epoch 36: loss -19.40825 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 37: loss -19.63568 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 37: loss -20.28175 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 38: loss -20.53711 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 38: loss -21.33084 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 39: loss -21.48461 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 39: loss -22.23523 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -22.47730 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 40: loss -23.28040 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -23.50304 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 41: loss -24.30930 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -24.45212 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 42: loss -25.35835 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -25.55522 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 43: loss -26.37449 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -26.68892 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 44: loss -27.60337 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -27.78542 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 45: loss -28.63682 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -28.94106 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 46: loss -29.81258 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -30.08859 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 47: loss -31.03164 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -31.27439 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 48: loss -32.29959 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -32.49989 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 49: loss -33.53115 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 50: loss -33.80378 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 50: loss -34.79253 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 51: loss -35.04823 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 51: loss -36.20164 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 52: loss -36.38212 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 52: loss -37.48575 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 53: loss -37.75952 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 53: loss -38.90222 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 54: loss -39.14821 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 54: loss -40.30054 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 55: loss -40.56053 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 55: loss -41.75124 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 56: loss -42.03904 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 56: loss -43.21645 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 57: loss -43.52979 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 57: loss -44.77529 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 58: loss -45.03460 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 58: loss -46.37167 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 59: loss -46.63401 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 59: loss -47.92593 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 60: loss -48.21619 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 60: loss -49.56395 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 61: loss -49.83648 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 61: loss -51.26908 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 62: loss -51.49461 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 62: loss -52.97285 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 63: loss -53.21473 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 63: loss -54.70374 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 64: loss -54.97792 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 64: loss -56.48278 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 65: loss -56.74975 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 65: loss -58.29480 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 66: loss -58.56817 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 66: loss -60.13610 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 67: loss -60.42107 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 67: loss -62.02705 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 68: loss -62.31637 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 68: loss -63.98765 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 69: loss -64.26536 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 69: loss -65.97257 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 70: loss -66.23772 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 70: loss -67.95804 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 71: loss -68.27746 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 71: loss -70.02390 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 72: loss -70.30635 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 72: loss -72.09440 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 73: loss -72.42791 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 73: loss -74.26809 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 74: loss -74.55216 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 74: loss -76.44117 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 75: loss -76.74144 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 75: loss -78.69812 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 76: loss -78.96104 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 76: loss -80.92564 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 77: loss -81.24204 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 77: loss -83.24517 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 78: loss -83.53583 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 78: loss -85.61580 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 79: loss -85.87912 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 79: loss -87.99442 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 80: loss -88.26528 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 80: loss -90.39944 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 81: loss -90.71285 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 81: loss -92.88282 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 82: loss -93.17159 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 82: loss -95.43773 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 83: loss -95.70676 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 83: loss -97.95156 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 84: loss -98.25463 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 84: loss -100.60469 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 85: loss -100.87065 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 85: loss -103.25532 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 86: loss -103.51753 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 86: loss -105.93514 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 87: loss -106.22442 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 87: loss -108.66772 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 88: loss -108.96013 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 88: loss -111.47853 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 89: loss -111.74245 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 89: loss -114.32498 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 90: loss -114.59948 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 90: loss -117.20115 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 91: loss -117.47412 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 91: loss -120.13232 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 92: loss -120.40177 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 92: loss -123.12202 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 93: loss -123.38689 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 93: loss -126.15372 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 94: loss -126.41995 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 94: loss -129.23702 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 95: loss -129.49808 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 95: loss -132.37176 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 96: loss -132.62232 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 96: loss -135.55477 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 97: loss -135.81123 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 97: loss -138.75036 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 98: loss -139.04474 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 98: loss -142.07194 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 99: loss -142.31084 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 99: loss -145.39082 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 2)
('lr', 0.0001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.59474 ROC_AUC (avg): 0.55579 PRC_AUC (avg): 0.70612 

Average forward propagation time taken(ms): 4.577819085371646
Average backward propagation time taken(ms): 1.6337801267520424

