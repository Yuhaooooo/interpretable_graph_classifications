# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.0001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-03-55-10/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-03-55-10/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 16,
 'epochs': 100,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 8,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.0001,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 1,
 'num_workers': 8,
 'number_of_mlp_layer': 0,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-18-03-55-10',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 100, 'learning_rate': 0.0001, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.23135 acc 0.33333 roc_auc 0.44620 prc_auc 0.66789[0m
[93maverage test of epoch 0: loss -0.38474 acc 0.34211 roc_auc 0.58462 prc_auc 0.81408[0m
[92maverage training of epoch 1: loss -0.51315 acc 0.33333 roc_auc 0.43400 prc_auc 0.65300[0m
[93maverage test of epoch 1: loss -0.64772 acc 0.34211 roc_auc 0.37846 prc_auc 0.69609[0m
[92maverage training of epoch 2: loss -0.76450 acc 0.34000 roc_auc 0.42520 prc_auc 0.64645[0m
[93maverage test of epoch 2: loss -0.88201 acc 0.34211 roc_auc 0.20923 prc_auc 0.57323[0m
[92maverage training of epoch 3: loss -0.99044 acc 0.34667 roc_auc 0.42320 prc_auc 0.64543[0m
[93maverage test of epoch 3: loss -1.09529 acc 0.34211 roc_auc 0.20615 prc_auc 0.57240[0m
[92maverage training of epoch 4: loss -1.19859 acc 0.35333 roc_auc 0.42560 prc_auc 0.64852[0m
[93maverage test of epoch 4: loss -1.29390 acc 0.36842 roc_auc 0.21538 prc_auc 0.58006[0m
[92maverage training of epoch 5: loss -1.39407 acc 0.57333 roc_auc 0.42820 prc_auc 0.64991[0m
[93maverage test of epoch 5: loss -1.48167 acc 0.65789 roc_auc 0.22154 prc_auc 0.58214[0m
[92maverage training of epoch 6: loss -1.58037 acc 0.66667 roc_auc 0.43180 prc_auc 0.65676[0m
[93maverage test of epoch 6: loss -1.66246 acc 0.65789 roc_auc 0.29538 prc_auc 0.62833[0m
[92maverage training of epoch 7: loss -1.76348 acc 0.66667 roc_auc 0.43660 prc_auc 0.65997[0m
[93maverage test of epoch 7: loss -1.84622 acc 0.65789 roc_auc 0.30154 prc_auc 0.62359[0m
[92maverage training of epoch 8: loss -1.95957 acc 0.66667 roc_auc 0.44240 prc_auc 0.66443[0m
[93maverage test of epoch 8: loss -2.05520 acc 0.65789 roc_auc 0.42154 prc_auc 0.72709[0m
[92maverage training of epoch 9: loss -2.18266 acc 0.66667 roc_auc 0.43660 prc_auc 0.65599[0m
[93maverage test of epoch 9: loss -2.28244 acc 0.65789 roc_auc 0.80615 prc_auc 0.87686[0m
[92maverage training of epoch 10: loss -2.40731 acc 0.66667 roc_auc 0.43780 prc_auc 0.65826[0m
[93maverage test of epoch 10: loss -2.49996 acc 0.65789 roc_auc 0.87231 prc_auc 0.91936[0m
[92maverage training of epoch 11: loss -2.62882 acc 0.66667 roc_auc 0.44060 prc_auc 0.66028[0m
[93maverage test of epoch 11: loss -2.72467 acc 0.65789 roc_auc 0.86923 prc_auc 0.92242[0m
[92maverage training of epoch 12: loss -2.86564 acc 0.66667 roc_auc 0.44220 prc_auc 0.66273[0m
[93maverage test of epoch 12: loss -2.97093 acc 0.65789 roc_auc 0.87385 prc_auc 0.93682[0m
[92maverage training of epoch 13: loss -3.12246 acc 0.66667 roc_auc 0.44380 prc_auc 0.66843[0m
[93maverage test of epoch 13: loss -3.23131 acc 0.65789 roc_auc 0.87385 prc_auc 0.93682[0m
[92maverage training of epoch 14: loss -3.38255 acc 0.66667 roc_auc 0.45000 prc_auc 0.67310[0m
[93maverage test of epoch 14: loss -3.48178 acc 0.65789 roc_auc 0.87385 prc_auc 0.93448[0m
[92maverage training of epoch 15: loss -3.62347 acc 0.66667 roc_auc 0.45680 prc_auc 0.67755[0m
[93maverage test of epoch 15: loss -3.70647 acc 0.65789 roc_auc 0.87692 prc_auc 0.93544[0m
[92maverage training of epoch 16: loss -3.83654 acc 0.66667 roc_auc 0.46440 prc_auc 0.67987[0m
[93maverage test of epoch 16: loss -3.90418 acc 0.65789 roc_auc 0.87538 prc_auc 0.93448[0m
[92maverage training of epoch 17: loss -4.02390 acc 0.66667 roc_auc 0.45340 prc_auc 0.67140[0m
[93maverage test of epoch 17: loss -4.07936 acc 0.65789 roc_auc 0.87385 prc_auc 0.93448[0m
[92maverage training of epoch 18: loss -4.19109 acc 0.66667 roc_auc 0.44600 prc_auc 0.66790[0m
[93maverage test of epoch 18: loss -4.23760 acc 0.65789 roc_auc 0.87692 prc_auc 0.93781[0m
[92maverage training of epoch 19: loss -4.34346 acc 0.66667 roc_auc 0.45210 prc_auc 0.67941[0m
[93maverage test of epoch 19: loss -4.38347 acc 0.65789 roc_auc 0.87692 prc_auc 0.93781[0m
[92maverage training of epoch 20: loss -4.48499 acc 0.66667 roc_auc 0.45870 prc_auc 0.68966[0m
[93maverage test of epoch 20: loss -4.52014 acc 0.65789 roc_auc 0.87692 prc_auc 0.93781[0m
[92maverage training of epoch 21: loss -4.61838 acc 0.66667 roc_auc 0.45890 prc_auc 0.68435[0m
[93maverage test of epoch 21: loss -4.64980 acc 0.65789 roc_auc 0.87692 prc_auc 0.93811[0m
[92maverage training of epoch 22: loss -4.74549 acc 0.66667 roc_auc 0.46140 prc_auc 0.68401[0m
[93maverage test of epoch 22: loss -4.77397 acc 0.65789 roc_auc 0.87692 prc_auc 0.93781[0m
[92maverage training of epoch 23: loss -4.86766 acc 0.66667 roc_auc 0.46340 prc_auc 0.68712[0m
[93maverage test of epoch 23: loss -4.89380 acc 0.65789 roc_auc 0.87692 prc_auc 0.93781[0m
[92maverage training of epoch 24: loss -4.98589 acc 0.66667 roc_auc 0.46520 prc_auc 0.69179[0m
[93maverage test of epoch 24: loss -5.01012 acc 0.65789 roc_auc 0.87692 prc_auc 0.93811[0m
[92maverage training of epoch 25: loss -5.10092 acc 0.66667 roc_auc 0.46380 prc_auc 0.69292[0m
[93maverage test of epoch 25: loss -5.12362 acc 0.65789 roc_auc 0.87692 prc_auc 0.93811[0m
[92maverage training of epoch 26: loss -5.21338 acc 0.66667 roc_auc 0.46490 prc_auc 0.69658[0m
[93maverage test of epoch 26: loss -5.23481 acc 0.65789 roc_auc 0.87538 prc_auc 0.93682[0m
[92maverage training of epoch 27: loss -5.32375 acc 0.66667 roc_auc 0.46900 prc_auc 0.69963[0m
[93maverage test of epoch 27: loss -5.34415 acc 0.65789 roc_auc 0.87538 prc_auc 0.93712[0m
[92maverage training of epoch 28: loss -5.43242 acc 0.66667 roc_auc 0.47350 prc_auc 0.70418[0m
[93maverage test of epoch 28: loss -5.45198 acc 0.65789 roc_auc 0.87077 prc_auc 0.93633[0m
[92maverage training of epoch 29: loss -5.53972 acc 0.66667 roc_auc 0.47670 prc_auc 0.70739[0m
[93maverage test of epoch 29: loss -5.55861 acc 0.65789 roc_auc 0.86923 prc_auc 0.93534[0m
[92maverage training of epoch 30: loss -5.64592 acc 0.66667 roc_auc 0.48260 prc_auc 0.71329[0m
[93maverage test of epoch 30: loss -5.66427 acc 0.65789 roc_auc 0.87077 prc_auc 0.93633[0m
[92maverage training of epoch 31: loss -5.75125 acc 0.66667 roc_auc 0.48900 prc_auc 0.72049[0m
[93maverage test of epoch 31: loss -5.76919 acc 0.65789 roc_auc 0.86615 prc_auc 0.93441[0m
[92maverage training of epoch 32: loss -5.85591 acc 0.66667 roc_auc 0.49370 prc_auc 0.72506[0m
[93maverage test of epoch 32: loss -5.87353 acc 0.65789 roc_auc 0.86154 prc_auc 0.93174[0m
[92maverage training of epoch 33: loss -5.96006 acc 0.66667 roc_auc 0.50080 prc_auc 0.73054[0m
[93maverage test of epoch 33: loss -5.97745 acc 0.65789 roc_auc 0.86308 prc_auc 0.93301[0m
[92maverage training of epoch 34: loss -6.06383 acc 0.66667 roc_auc 0.50670 prc_auc 0.73516[0m
[93maverage test of epoch 34: loss -6.08107 acc 0.65789 roc_auc 0.86000 prc_auc 0.93116[0m
[92maverage training of epoch 35: loss -6.16735 acc 0.66667 roc_auc 0.51320 prc_auc 0.73958[0m
[93maverage test of epoch 35: loss -6.18450 acc 0.65789 roc_auc 0.86154 prc_auc 0.93174[0m
[92maverage training of epoch 36: loss -6.27071 acc 0.66667 roc_auc 0.51820 prc_auc 0.74230[0m
[93maverage test of epoch 36: loss -6.28782 acc 0.65789 roc_auc 0.86000 prc_auc 0.93174[0m
[92maverage training of epoch 37: loss -6.37399 acc 0.66667 roc_auc 0.52160 prc_auc 0.74432[0m
[93maverage test of epoch 37: loss -6.39111 acc 0.65789 roc_auc 0.85846 prc_auc 0.93048[0m
[92maverage training of epoch 38: loss -6.47726 acc 0.66667 roc_auc 0.52570 prc_auc 0.74614[0m
[93maverage test of epoch 38: loss -6.49444 acc 0.65789 roc_auc 0.86000 prc_auc 0.93174[0m
[92maverage training of epoch 39: loss -6.58059 acc 0.66667 roc_auc 0.52800 prc_auc 0.74701[0m
[93maverage test of epoch 39: loss -6.59785 acc 0.65789 roc_auc 0.86308 prc_auc 0.93482[0m
[92maverage training of epoch 40: loss -6.68401 acc 0.66667 roc_auc 0.53000 prc_auc 0.74810[0m
[93maverage test of epoch 40: loss -6.70139 acc 0.65789 roc_auc 0.86308 prc_auc 0.93482[0m
[92maverage training of epoch 41: loss -6.78756 acc 0.66667 roc_auc 0.53130 prc_auc 0.74879[0m
[93maverage test of epoch 41: loss -6.80507 acc 0.65789 roc_auc 0.86769 prc_auc 0.93768[0m
[92maverage training of epoch 42: loss -6.89127 acc 0.66667 roc_auc 0.53240 prc_auc 0.74910[0m
[93maverage test of epoch 42: loss -6.90893 acc 0.65789 roc_auc 0.86462 prc_auc 0.93768[0m
[92maverage training of epoch 43: loss -6.99515 acc 0.66667 roc_auc 0.53310 prc_auc 0.74945[0m
[93maverage test of epoch 43: loss -7.01295 acc 0.65789 roc_auc 0.86462 prc_auc 0.93768[0m
[92maverage training of epoch 44: loss -7.09920 acc 0.66667 roc_auc 0.53330 prc_auc 0.74952[0m
[93maverage test of epoch 44: loss -7.11715 acc 0.65789 roc_auc 0.86615 prc_auc 0.93768[0m
[92maverage training of epoch 45: loss -7.20342 acc 0.66667 roc_auc 0.53320 prc_auc 0.74973[0m
[93maverage test of epoch 45: loss -7.22151 acc 0.65789 roc_auc 0.86615 prc_auc 0.93777[0m
[92maverage training of epoch 46: loss -7.30780 acc 0.66667 roc_auc 0.53440 prc_auc 0.75083[0m
[93maverage test of epoch 46: loss -7.32601 acc 0.65789 roc_auc 0.86308 prc_auc 0.93673[0m
[92maverage training of epoch 47: loss -7.41234 acc 0.66667 roc_auc 0.53630 prc_auc 0.75302[0m
[93maverage test of epoch 47: loss -7.43063 acc 0.65789 roc_auc 0.86462 prc_auc 0.93768[0m
[92maverage training of epoch 48: loss -7.51702 acc 0.66667 roc_auc 0.53760 prc_auc 0.75457[0m
[93maverage test of epoch 48: loss -7.53535 acc 0.65789 roc_auc 0.86615 prc_auc 0.93736[0m
[92maverage training of epoch 49: loss -7.62191 acc 0.66667 roc_auc 0.54210 prc_auc 0.75721[0m
[93maverage test of epoch 49: loss -7.64017 acc 0.65789 roc_auc 0.86462 prc_auc 0.93709[0m
[92maverage training of epoch 50: loss -7.72725 acc 0.66667 roc_auc 0.55810 prc_auc 0.76527[0m
[93maverage test of epoch 50: loss -7.74517 acc 0.65789 roc_auc 0.86615 prc_auc 0.93768[0m
[92maverage training of epoch 51: loss -7.83335 acc 0.66667 roc_auc 0.58890 prc_auc 0.78550[0m
[93maverage test of epoch 51: loss -7.85071 acc 0.65789 roc_auc 0.87231 prc_auc 0.94200[0m
[92maverage training of epoch 52: loss -7.93998 acc 0.66667 roc_auc 0.63860 prc_auc 0.82081[0m
[93maverage test of epoch 52: loss -7.95975 acc 0.65789 roc_auc 0.87538 prc_auc 0.94418[0m
[92maverage training of epoch 53: loss -8.05239 acc 0.66667 roc_auc 0.72000 prc_auc 0.86822[0m
[93maverage test of epoch 53: loss -8.09573 acc 0.65789 roc_auc 0.86769 prc_auc 0.93902[0m
[92maverage training of epoch 54: loss -8.16542 acc 0.66667 roc_auc 0.85310 prc_auc 0.91869[0m
[93maverage test of epoch 54: loss -8.21022 acc 0.65789 roc_auc 0.86769 prc_auc 0.93902[0m
[92maverage training of epoch 55: loss -8.26306 acc 0.66667 roc_auc 0.88840 prc_auc 0.93783[0m
[93maverage test of epoch 55: loss -8.30038 acc 0.65789 roc_auc 0.86769 prc_auc 0.93902[0m
[92maverage training of epoch 56: loss -8.35523 acc 0.66667 roc_auc 0.89460 prc_auc 0.94116[0m
[93maverage test of epoch 56: loss -8.39372 acc 0.65789 roc_auc 0.86769 prc_auc 0.93902[0m
[92maverage training of epoch 57: loss -8.44667 acc 0.66667 roc_auc 0.89860 prc_auc 0.94356[0m
[93maverage test of epoch 57: loss -8.48731 acc 0.65789 roc_auc 0.86769 prc_auc 0.93902[0m
[92maverage training of epoch 58: loss -8.53845 acc 0.66667 roc_auc 0.89940 prc_auc 0.94416[0m
[93maverage test of epoch 58: loss -8.58090 acc 0.65789 roc_auc 0.87077 prc_auc 0.94003[0m
[92maverage training of epoch 59: loss -8.63044 acc 0.66667 roc_auc 0.90100 prc_auc 0.94489[0m
[93maverage test of epoch 59: loss -8.67436 acc 0.65789 roc_auc 0.87077 prc_auc 0.94003[0m
[92maverage training of epoch 60: loss -8.72265 acc 0.66667 roc_auc 0.90140 prc_auc 0.94524[0m
[93maverage test of epoch 60: loss -8.76761 acc 0.65789 roc_auc 0.87385 prc_auc 0.94269[0m
[92maverage training of epoch 61: loss -8.81498 acc 0.66667 roc_auc 0.90180 prc_auc 0.94559[0m
[93maverage test of epoch 61: loss -8.86072 acc 0.65789 roc_auc 0.87385 prc_auc 0.94269[0m
[92maverage training of epoch 62: loss -8.90711 acc 0.66667 roc_auc 0.90240 prc_auc 0.94615[0m
[93maverage test of epoch 62: loss -8.95358 acc 0.65789 roc_auc 0.87385 prc_auc 0.94269[0m
[92maverage training of epoch 63: loss -8.99902 acc 0.66667 roc_auc 0.90260 prc_auc 0.94628[0m
[93maverage test of epoch 63: loss -9.04637 acc 0.65789 roc_auc 0.87385 prc_auc 0.94269[0m
[92maverage training of epoch 64: loss -9.09069 acc 0.66667 roc_auc 0.90240 prc_auc 0.94589[0m
[93maverage test of epoch 64: loss -9.13862 acc 0.65789 roc_auc 0.87692 prc_auc 0.94362[0m
[92maverage training of epoch 65: loss -9.18268 acc 0.66667 roc_auc 0.90160 prc_auc 0.94583[0m
[93maverage test of epoch 65: loss -9.22962 acc 0.65789 roc_auc 0.87692 prc_auc 0.94362[0m
[92maverage training of epoch 66: loss -9.27371 acc 0.66667 roc_auc 0.90200 prc_auc 0.94602[0m
[93maverage test of epoch 66: loss -9.32026 acc 0.65789 roc_auc 0.87385 prc_auc 0.94196[0m
[92maverage training of epoch 67: loss -9.36429 acc 0.66667 roc_auc 0.90240 prc_auc 0.94692[0m
[93maverage test of epoch 67: loss -9.41047 acc 0.65789 roc_auc 0.87385 prc_auc 0.94196[0m
[92maverage training of epoch 68: loss -9.45529 acc 0.66667 roc_auc 0.90260 prc_auc 0.94713[0m
[93maverage test of epoch 68: loss -9.50047 acc 0.65789 roc_auc 0.87385 prc_auc 0.94196[0m
[92maverage training of epoch 69: loss -9.54681 acc 0.66667 roc_auc 0.90320 prc_auc 0.94762[0m
[93maverage test of epoch 69: loss -9.59030 acc 0.65789 roc_auc 0.87385 prc_auc 0.94196[0m
[92maverage training of epoch 70: loss -9.63887 acc 0.66667 roc_auc 0.90300 prc_auc 0.94781[0m
[93maverage test of epoch 70: loss -9.68027 acc 0.65789 roc_auc 0.87385 prc_auc 0.94196[0m
[92maverage training of epoch 71: loss -9.73164 acc 0.66667 roc_auc 0.90300 prc_auc 0.94751[0m
[93maverage test of epoch 71: loss -9.77048 acc 0.65789 roc_auc 0.88000 prc_auc 0.94421[0m
[92maverage training of epoch 72: loss -9.82510 acc 0.66667 roc_auc 0.90460 prc_auc 0.94818[0m
[93maverage test of epoch 72: loss -9.86083 acc 0.65789 roc_auc 0.88308 prc_auc 0.94529[0m
[92maverage training of epoch 73: loss -9.91928 acc 0.66667 roc_auc 0.90540 prc_auc 0.94858[0m
[93maverage test of epoch 73: loss -9.95139 acc 0.65789 roc_auc 0.88154 prc_auc 0.94445[0m
[92maverage training of epoch 74: loss -10.01417 acc 0.66667 roc_auc 0.90460 prc_auc 0.94798[0m
[93maverage test of epoch 74: loss -10.04207 acc 0.65789 roc_auc 0.87385 prc_auc 0.94193[0m
[92maverage training of epoch 75: loss -10.10976 acc 0.66667 roc_auc 0.90440 prc_auc 0.94777[0m
[93maverage test of epoch 75: loss -10.13290 acc 0.65789 roc_auc 0.87077 prc_auc 0.93926[0m
[92maverage training of epoch 76: loss -10.20604 acc 0.66667 roc_auc 0.90280 prc_auc 0.94666[0m
[93maverage test of epoch 76: loss -10.22374 acc 0.65789 roc_auc 0.86769 prc_auc 0.93841[0m
[92maverage training of epoch 77: loss -10.30280 acc 0.66667 roc_auc 0.90180 prc_auc 0.94579[0m
[93maverage test of epoch 77: loss -10.31433 acc 0.65789 roc_auc 0.86462 prc_auc 0.93760[0m
[92maverage training of epoch 78: loss -10.39980 acc 0.66667 roc_auc 0.90060 prc_auc 0.94473[0m
[93maverage test of epoch 78: loss -10.40399 acc 0.65789 roc_auc 0.86462 prc_auc 0.93760[0m
[92maverage training of epoch 79: loss -10.49696 acc 0.66667 roc_auc 0.90060 prc_auc 0.94446[0m
[93maverage test of epoch 79: loss -10.49298 acc 0.65789 roc_auc 0.86462 prc_auc 0.93760[0m
[92maverage training of epoch 80: loss -10.59407 acc 0.66667 roc_auc 0.90060 prc_auc 0.94430[0m
[93maverage test of epoch 80: loss -10.58129 acc 0.65789 roc_auc 0.86462 prc_auc 0.93760[0m
[92maverage training of epoch 81: loss -10.69106 acc 0.66667 roc_auc 0.89960 prc_auc 0.94349[0m
[93maverage test of epoch 81: loss -10.66956 acc 0.65789 roc_auc 0.86462 prc_auc 0.93760[0m
[92maverage training of epoch 82: loss -10.78783 acc 0.66667 roc_auc 0.89950 prc_auc 0.94325[0m
[93maverage test of epoch 82: loss -10.75797 acc 0.65789 roc_auc 0.86462 prc_auc 0.93760[0m
[92maverage training of epoch 83: loss -10.88429 acc 0.66667 roc_auc 0.89840 prc_auc 0.94262[0m
[93maverage test of epoch 83: loss -10.84689 acc 0.65789 roc_auc 0.86769 prc_auc 0.94027[0m
[92maverage training of epoch 84: loss -10.98041 acc 0.66667 roc_auc 0.89720 prc_auc 0.94168[0m
[93maverage test of epoch 84: loss -10.93669 acc 0.65789 roc_auc 0.86769 prc_auc 0.94027[0m
[92maverage training of epoch 85: loss -11.07630 acc 0.66667 roc_auc 0.89740 prc_auc 0.94066[0m
[93maverage test of epoch 85: loss -11.02732 acc 0.65789 roc_auc 0.86462 prc_auc 0.93952[0m
[92maverage training of epoch 86: loss -11.17196 acc 0.66667 roc_auc 0.89760 prc_auc 0.94112[0m
[93maverage test of epoch 86: loss -11.11857 acc 0.65789 roc_auc 0.86769 prc_auc 0.94051[0m
[92maverage training of epoch 87: loss -11.26743 acc 0.66667 roc_auc 0.89650 prc_auc 0.93967[0m
[93maverage test of epoch 87: loss -11.21034 acc 0.65789 roc_auc 0.86769 prc_auc 0.94051[0m
[92maverage training of epoch 88: loss -11.36281 acc 0.66667 roc_auc 0.89660 prc_auc 0.93935[0m
[93maverage test of epoch 88: loss -11.30253 acc 0.65789 roc_auc 0.86769 prc_auc 0.94051[0m
[92maverage training of epoch 89: loss -11.45823 acc 0.66667 roc_auc 0.89510 prc_auc 0.93718[0m
[93maverage test of epoch 89: loss -11.39505 acc 0.65789 roc_auc 0.86923 prc_auc 0.94051[0m
[92maverage training of epoch 90: loss -11.55375 acc 0.66667 roc_auc 0.89360 prc_auc 0.93499[0m
[93maverage test of epoch 90: loss -11.48780 acc 0.65789 roc_auc 0.87077 prc_auc 0.94224[0m
[92maverage training of epoch 91: loss -11.64935 acc 0.66667 roc_auc 0.89210 prc_auc 0.93320[0m
[93maverage test of epoch 91: loss -11.58070 acc 0.65789 roc_auc 0.87077 prc_auc 0.94224[0m
[92maverage training of epoch 92: loss -11.74495 acc 0.66667 roc_auc 0.89060 prc_auc 0.93117[0m
[93maverage test of epoch 92: loss -11.67370 acc 0.65789 roc_auc 0.87077 prc_auc 0.94131[0m
[92maverage training of epoch 93: loss -11.84055 acc 0.66667 roc_auc 0.88900 prc_auc 0.92877[0m
[93maverage test of epoch 93: loss -11.76675 acc 0.65789 roc_auc 0.87077 prc_auc 0.94131[0m
[92maverage training of epoch 94: loss -11.93620 acc 0.66667 roc_auc 0.88750 prc_auc 0.92723[0m
[93maverage test of epoch 94: loss -11.85974 acc 0.65789 roc_auc 0.87077 prc_auc 0.94131[0m
[92maverage training of epoch 95: loss -12.03195 acc 0.66667 roc_auc 0.88530 prc_auc 0.92335[0m
[93maverage test of epoch 95: loss -11.95262 acc 0.65789 roc_auc 0.87231 prc_auc 0.94131[0m
[92maverage training of epoch 96: loss -12.12783 acc 0.66667 roc_auc 0.88380 prc_auc 0.92075[0m
[93maverage test of epoch 96: loss -12.04534 acc 0.65789 roc_auc 0.87231 prc_auc 0.94131[0m
[92maverage training of epoch 97: loss -12.22396 acc 0.66667 roc_auc 0.88060 prc_auc 0.91728[0m
[93maverage test of epoch 97: loss -12.13784 acc 0.65789 roc_auc 0.87231 prc_auc 0.94131[0m
[92maverage training of epoch 98: loss -12.32046 acc 0.66667 roc_auc 0.87810 prc_auc 0.91483[0m
[93maverage test of epoch 98: loss -12.23015 acc 0.65789 roc_auc 0.87231 prc_auc 0.94131[0m
[92maverage training of epoch 99: loss -12.41730 acc 0.66667 roc_auc 0.87560 prc_auc 0.91012[0m
[93maverage test of epoch 99: loss -12.32233 acc 0.65789 roc_auc 0.87231 prc_auc 0.94131[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss 0.21551 acc 0.66667 roc_auc 0.44860 prc_auc 0.64294[0m
[93maverage test of epoch 0: loss 0.06749 acc 0.65789 roc_auc 0.57231 prc_auc 0.78833[0m
[92maverage training of epoch 1: loss -0.06934 acc 0.66667 roc_auc 0.47720 prc_auc 0.66840[0m
[93maverage test of epoch 1: loss -0.21862 acc 0.65789 roc_auc 0.66769 prc_auc 0.83731[0m
[92maverage training of epoch 2: loss -0.37192 acc 0.66667 roc_auc 0.49240 prc_auc 0.68181[0m
[93maverage test of epoch 2: loss -0.55652 acc 0.65789 roc_auc 0.80923 prc_auc 0.89655[0m
[92maverage training of epoch 3: loss -0.77801 acc 0.66667 roc_auc 0.50620 prc_auc 0.68744[0m
[93maverage test of epoch 3: loss -1.05057 acc 0.65789 roc_auc 0.86769 prc_auc 0.91887[0m
[92maverage training of epoch 4: loss -1.30480 acc 0.66667 roc_auc 0.50460 prc_auc 0.68529[0m
[93maverage test of epoch 4: loss -1.54514 acc 0.65789 roc_auc 0.82769 prc_auc 0.88224[0m
[92maverage training of epoch 5: loss -1.73123 acc 0.66667 roc_auc 0.49280 prc_auc 0.67132[0m
[93maverage test of epoch 5: loss -1.90206 acc 0.65789 roc_auc 0.78462 prc_auc 0.85621[0m
[92maverage training of epoch 6: loss -2.06793 acc 0.66667 roc_auc 0.49120 prc_auc 0.67051[0m
[93maverage test of epoch 6: loss -2.22082 acc 0.65789 roc_auc 0.71385 prc_auc 0.81115[0m
[92maverage training of epoch 7: loss -2.39803 acc 0.66667 roc_auc 0.48600 prc_auc 0.66774[0m
[93maverage test of epoch 7: loss -2.55774 acc 0.65789 roc_auc 0.64923 prc_auc 0.78127[0m
[92maverage training of epoch 8: loss -2.74526 acc 0.66667 roc_auc 0.48140 prc_auc 0.66906[0m
[93maverage test of epoch 8: loss -2.90309 acc 0.65789 roc_auc 0.62769 prc_auc 0.77708[0m
[92maverage training of epoch 9: loss -3.08388 acc 0.66667 roc_auc 0.48020 prc_auc 0.66858[0m
[93maverage test of epoch 9: loss -3.23867 acc 0.65789 roc_auc 0.63692 prc_auc 0.78477[0m
[92maverage training of epoch 10: loss -3.42971 acc 0.66667 roc_auc 0.48280 prc_auc 0.67022[0m
[93maverage test of epoch 10: loss -3.60486 acc 0.65789 roc_auc 0.72615 prc_auc 0.82059[0m
[92maverage training of epoch 11: loss -3.80572 acc 0.66667 roc_auc 0.48760 prc_auc 0.67257[0m
[93maverage test of epoch 11: loss -3.97841 acc 0.65789 roc_auc 0.78462 prc_auc 0.86121[0m
[92maverage training of epoch 12: loss -4.14326 acc 0.66667 roc_auc 0.49120 prc_auc 0.67631[0m
[93maverage test of epoch 12: loss -4.27290 acc 0.65789 roc_auc 0.75385 prc_auc 0.84647[0m
[92maverage training of epoch 13: loss -4.40132 acc 0.66667 roc_auc 0.48100 prc_auc 0.66643[0m
[93maverage test of epoch 13: loss -4.49865 acc 0.65789 roc_auc 0.71692 prc_auc 0.82784[0m
[92maverage training of epoch 14: loss -4.60792 acc 0.66667 roc_auc 0.46460 prc_auc 0.64654[0m
[93maverage test of epoch 14: loss -4.68728 acc 0.65789 roc_auc 0.70769 prc_auc 0.82650[0m
[92maverage training of epoch 15: loss -4.78580 acc 0.66667 roc_auc 0.44980 prc_auc 0.63324[0m
[93maverage test of epoch 15: loss -4.85394 acc 0.65789 roc_auc 0.70154 prc_auc 0.83530[0m
[92maverage training of epoch 16: loss -4.94554 acc 0.66667 roc_auc 0.43600 prc_auc 0.62376[0m
[93maverage test of epoch 16: loss -5.00581 acc 0.65789 roc_auc 0.68615 prc_auc 0.82964[0m
[92maverage training of epoch 17: loss -5.09254 acc 0.66667 roc_auc 0.42910 prc_auc 0.61583[0m
[93maverage test of epoch 17: loss -5.14691 acc 0.65789 roc_auc 0.68923 prc_auc 0.83535[0m
[92maverage training of epoch 18: loss -5.23003 acc 0.66667 roc_auc 0.42530 prc_auc 0.61142[0m
[93maverage test of epoch 18: loss -5.27979 acc 0.65789 roc_auc 0.68308 prc_auc 0.83341[0m
[92maverage training of epoch 19: loss -5.36018 acc 0.66667 roc_auc 0.42300 prc_auc 0.60967[0m
[93maverage test of epoch 19: loss -5.40626 acc 0.65789 roc_auc 0.67231 prc_auc 0.82510[0m
[92maverage training of epoch 20: loss -5.48455 acc 0.66667 roc_auc 0.42040 prc_auc 0.60893[0m
[93maverage test of epoch 20: loss -5.52765 acc 0.65789 roc_auc 0.64769 prc_auc 0.81400[0m
[92maverage training of epoch 21: loss -5.60434 acc 0.66667 roc_auc 0.42140 prc_auc 0.61050[0m
[93maverage test of epoch 21: loss -5.64506 acc 0.65789 roc_auc 0.64615 prc_auc 0.81419[0m
[92maverage training of epoch 22: loss -5.72058 acc 0.66667 roc_auc 0.42220 prc_auc 0.61170[0m
[93maverage test of epoch 22: loss -5.75945 acc 0.65789 roc_auc 0.63846 prc_auc 0.80902[0m
[92maverage training of epoch 23: loss -5.83422 acc 0.66667 roc_auc 0.42420 prc_auc 0.61461[0m
[93maverage test of epoch 23: loss -5.87178 acc 0.65789 roc_auc 0.56923 prc_auc 0.78723[0m
[92maverage training of epoch 24: loss -5.94629 acc 0.66667 roc_auc 0.42010 prc_auc 0.62628[0m
[93maverage test of epoch 24: loss -5.98320 acc 0.65789 roc_auc 0.56308 prc_auc 0.78439[0m
[92maverage training of epoch 25: loss -6.05804 acc 0.66667 roc_auc 0.41970 prc_auc 0.63104[0m
[93maverage test of epoch 25: loss -6.09513 acc 0.65789 roc_auc 0.49385 prc_auc 0.75387[0m
[92maverage training of epoch 26: loss -6.17114 acc 0.66667 roc_auc 0.40930 prc_auc 0.62923[0m
[93maverage test of epoch 26: loss -6.20943 acc 0.65789 roc_auc 0.42462 prc_auc 0.72765[0m
[92maverage training of epoch 27: loss -6.28750 acc 0.66667 roc_auc 0.39860 prc_auc 0.63028[0m
[93maverage test of epoch 27: loss -6.32793 acc 0.65789 roc_auc 0.35692 prc_auc 0.69017[0m
[92maverage training of epoch 28: loss -6.40845 acc 0.66667 roc_auc 0.36900 prc_auc 0.60023[0m
[93maverage test of epoch 28: loss -6.45103 acc 0.65789 roc_auc 0.24154 prc_auc 0.63010[0m
[92maverage training of epoch 29: loss -6.53304 acc 0.66667 roc_auc 0.32920 prc_auc 0.57479[0m
[93maverage test of epoch 29: loss -6.57633 acc 0.65789 roc_auc 0.23385 prc_auc 0.62279[0m
[92maverage training of epoch 30: loss -6.65809 acc 0.66667 roc_auc 0.30080 prc_auc 0.56815[0m
[93maverage test of epoch 30: loss -6.70044 acc 0.65789 roc_auc 0.19077 prc_auc 0.59925[0m
[92maverage training of epoch 31: loss -6.78102 acc 0.66667 roc_auc 0.30520 prc_auc 0.56547[0m
[93maverage test of epoch 31: loss -6.82185 acc 0.65789 roc_auc 0.13538 prc_auc 0.54147[0m
[92maverage training of epoch 32: loss -6.90125 acc 0.66667 roc_auc 0.34200 prc_auc 0.57392[0m
[93maverage test of epoch 32: loss -6.94061 acc 0.65789 roc_auc 0.14154 prc_auc 0.54384[0m
[92maverage training of epoch 33: loss -7.01909 acc 0.66667 roc_auc 0.36280 prc_auc 0.57974[0m
[93maverage test of epoch 33: loss -7.05713 acc 0.65789 roc_auc 0.15692 prc_auc 0.54723[0m
[92maverage training of epoch 34: loss -7.13490 acc 0.66667 roc_auc 0.38000 prc_auc 0.58597[0m
[93maverage test of epoch 34: loss -7.17176 acc 0.65789 roc_auc 0.17538 prc_auc 0.55343[0m
[92maverage training of epoch 35: loss -7.24895 acc 0.66667 roc_auc 0.38840 prc_auc 0.58956[0m
[93maverage test of epoch 35: loss -7.28473 acc 0.65789 roc_auc 0.18462 prc_auc 0.55522[0m
[92maverage training of epoch 36: loss -7.36143 acc 0.66667 roc_auc 0.39440 prc_auc 0.59233[0m
[93maverage test of epoch 36: loss -7.39622 acc 0.65789 roc_auc 0.19385 prc_auc 0.56011[0m
[92maverage training of epoch 37: loss -7.47253 acc 0.66667 roc_auc 0.39790 prc_auc 0.59409[0m
[93maverage test of epoch 37: loss -7.50639 acc 0.65789 roc_auc 0.19692 prc_auc 0.56062[0m
[92maverage training of epoch 38: loss -7.58237 acc 0.66667 roc_auc 0.40320 prc_auc 0.59659[0m
[93maverage test of epoch 38: loss -7.61537 acc 0.65789 roc_auc 0.19692 prc_auc 0.56138[0m
[92maverage training of epoch 39: loss -7.69110 acc 0.66667 roc_auc 0.40550 prc_auc 0.59746[0m
[93maverage test of epoch 39: loss -7.72330 acc 0.65789 roc_auc 0.19385 prc_auc 0.56105[0m
[92maverage training of epoch 40: loss -7.79883 acc 0.66667 roc_auc 0.40850 prc_auc 0.59886[0m
[93maverage test of epoch 40: loss -7.83029 acc 0.65789 roc_auc 0.18769 prc_auc 0.55745[0m
[92maverage training of epoch 41: loss -7.90567 acc 0.66667 roc_auc 0.40990 prc_auc 0.59981[0m
[93maverage test of epoch 41: loss -7.93643 acc 0.65789 roc_auc 0.18769 prc_auc 0.55802[0m
[92maverage training of epoch 42: loss -8.01173 acc 0.66667 roc_auc 0.41150 prc_auc 0.59989[0m
[93maverage test of epoch 42: loss -8.04184 acc 0.65789 roc_auc 0.18923 prc_auc 0.55921[0m
[92maverage training of epoch 43: loss -8.11709 acc 0.66667 roc_auc 0.41270 prc_auc 0.60099[0m
[93maverage test of epoch 43: loss -8.14658 acc 0.65789 roc_auc 0.18308 prc_auc 0.55959[0m
[92maverage training of epoch 44: loss -8.22182 acc 0.66667 roc_auc 0.41420 prc_auc 0.60200[0m
[93maverage test of epoch 44: loss -8.25074 acc 0.65789 roc_auc 0.18769 prc_auc 0.55813[0m
[92maverage training of epoch 45: loss -8.32601 acc 0.66667 roc_auc 0.41620 prc_auc 0.60288[0m
[93maverage test of epoch 45: loss -8.35437 acc 0.65789 roc_auc 0.18615 prc_auc 0.55927[0m
[92maverage training of epoch 46: loss -8.42970 acc 0.66667 roc_auc 0.41700 prc_auc 0.60406[0m
[93maverage test of epoch 46: loss -8.45755 acc 0.65789 roc_auc 0.18462 prc_auc 0.56333[0m
[92maverage training of epoch 47: loss -8.53296 acc 0.66667 roc_auc 0.41660 prc_auc 0.60337[0m
[93maverage test of epoch 47: loss -8.56031 acc 0.65789 roc_auc 0.18308 prc_auc 0.56442[0m
[92maverage training of epoch 48: loss -8.63583 acc 0.66667 roc_auc 0.41780 prc_auc 0.60582[0m
[93maverage test of epoch 48: loss -8.66271 acc 0.65789 roc_auc 0.19077 prc_auc 0.56830[0m
[92maverage training of epoch 49: loss -8.73836 acc 0.66667 roc_auc 0.41820 prc_auc 0.60603[0m
[93maverage test of epoch 49: loss -8.76478 acc 0.65789 roc_auc 0.18308 prc_auc 0.56969[0m
[92maverage training of epoch 50: loss -8.84058 acc 0.66667 roc_auc 0.41900 prc_auc 0.60831[0m
[93maverage test of epoch 50: loss -8.86656 acc 0.65789 roc_auc 0.18462 prc_auc 0.57690[0m
[92maverage training of epoch 51: loss -8.94252 acc 0.66667 roc_auc 0.41900 prc_auc 0.60831[0m
[93maverage test of epoch 51: loss -8.96808 acc 0.65789 roc_auc 0.18769 prc_auc 0.57377[0m
[92maverage training of epoch 52: loss -9.04422 acc 0.66667 roc_auc 0.41940 prc_auc 0.61002[0m
[93maverage test of epoch 52: loss -9.06937 acc 0.65789 roc_auc 0.18462 prc_auc 0.57615[0m
[92maverage training of epoch 53: loss -9.14570 acc 0.66667 roc_auc 0.41940 prc_auc 0.60999[0m
[93maverage test of epoch 53: loss -9.17046 acc 0.65789 roc_auc 0.16308 prc_auc 0.57905[0m
[92maverage training of epoch 54: loss -9.24698 acc 0.66667 roc_auc 0.41970 prc_auc 0.61007[0m
[93maverage test of epoch 54: loss -9.27135 acc 0.65789 roc_auc 0.16308 prc_auc 0.57971[0m
[92maverage training of epoch 55: loss -9.34808 acc 0.66667 roc_auc 0.42020 prc_auc 0.61231[0m
[93maverage test of epoch 55: loss -9.37208 acc 0.65789 roc_auc 0.17077 prc_auc 0.59104[0m
[92maverage training of epoch 56: loss -9.44903 acc 0.66667 roc_auc 0.42050 prc_auc 0.60745[0m
[93maverage test of epoch 56: loss -9.47266 acc 0.65789 roc_auc 0.19692 prc_auc 0.60153[0m
[92maverage training of epoch 57: loss -9.54983 acc 0.66667 roc_auc 0.42050 prc_auc 0.60799[0m
[93maverage test of epoch 57: loss -9.57310 acc 0.65789 roc_auc 0.19846 prc_auc 0.61641[0m
[92maverage training of epoch 58: loss -9.65051 acc 0.66667 roc_auc 0.42050 prc_auc 0.60799[0m
[93maverage test of epoch 58: loss -9.67342 acc 0.65789 roc_auc 0.30769 prc_auc 0.64316[0m
[92maverage training of epoch 59: loss -9.75107 acc 0.66667 roc_auc 0.42060 prc_auc 0.60804[0m
[93maverage test of epoch 59: loss -9.77363 acc 0.65789 roc_auc 0.24154 prc_auc 0.66930[0m
[92maverage training of epoch 60: loss -9.85152 acc 0.66667 roc_auc 0.42060 prc_auc 0.60804[0m
[93maverage test of epoch 60: loss -9.87375 acc 0.65789 roc_auc 0.19538 prc_auc 0.63053[0m
[92maverage training of epoch 61: loss -9.95188 acc 0.66667 roc_auc 0.42060 prc_auc 0.60804[0m
[93maverage test of epoch 61: loss -9.97377 acc 0.65789 roc_auc 0.24615 prc_auc 0.64632[0m
[92maverage training of epoch 62: loss -10.05216 acc 0.66667 roc_auc 0.42040 prc_auc 0.60593[0m
[93maverage test of epoch 62: loss -10.07372 acc 0.65789 roc_auc 0.44000 prc_auc 0.64794[0m
[92maverage training of epoch 63: loss -10.15236 acc 0.66667 roc_auc 0.42070 prc_auc 0.60655[0m
[93maverage test of epoch 63: loss -10.17359 acc 0.65789 roc_auc 0.50462 prc_auc 0.68526[0m
[92maverage training of epoch 64: loss -10.25250 acc 0.66667 roc_auc 0.42080 prc_auc 0.60655[0m
[93maverage test of epoch 64: loss -10.27340 acc 0.65789 roc_auc 0.49231 prc_auc 0.67857[0m
[92maverage training of epoch 65: loss -10.35257 acc 0.66667 roc_auc 0.42040 prc_auc 0.60559[0m
[93maverage test of epoch 65: loss -10.37315 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 66: loss -10.45258 acc 0.66667 roc_auc 0.42040 prc_auc 0.60516[0m
[93maverage test of epoch 66: loss -10.47285 acc 0.65789 roc_auc 0.39077 prc_auc 0.63827[0m
[92maverage training of epoch 67: loss -10.55254 acc 0.66667 roc_auc 0.42040 prc_auc 0.60521[0m
[93maverage test of epoch 67: loss -10.57249 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 68: loss -10.65245 acc 0.66667 roc_auc 0.42050 prc_auc 0.60521[0m
[93maverage test of epoch 68: loss -10.67210 acc 0.65789 roc_auc 0.48308 prc_auc 0.67506[0m
[92maverage training of epoch 69: loss -10.75232 acc 0.66667 roc_auc 0.42040 prc_auc 0.60524[0m
[93maverage test of epoch 69: loss -10.77166 acc 0.65789 roc_auc 0.47846 prc_auc 0.67600[0m
[92maverage training of epoch 70: loss -10.85216 acc 0.66667 roc_auc 0.42060 prc_auc 0.60521[0m
[93maverage test of epoch 70: loss -10.87118 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 71: loss -10.95195 acc 0.66667 roc_auc 0.42030 prc_auc 0.60494[0m
[93maverage test of epoch 71: loss -10.97067 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 72: loss -11.05172 acc 0.66667 roc_auc 0.42010 prc_auc 0.60494[0m
[93maverage test of epoch 72: loss -11.07014 acc 0.65789 roc_auc 0.58000 prc_auc 0.71263[0m
[92maverage training of epoch 73: loss -11.15145 acc 0.66667 roc_auc 0.42020 prc_auc 0.60458[0m
[93maverage test of epoch 73: loss -11.16957 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 74: loss -11.25116 acc 0.66667 roc_auc 0.42030 prc_auc 0.60494[0m
[93maverage test of epoch 74: loss -11.26898 acc 0.65789 roc_auc 0.51538 prc_auc 0.67659[0m
[92maverage training of epoch 75: loss -11.35085 acc 0.66667 roc_auc 0.42010 prc_auc 0.60494[0m
[93maverage test of epoch 75: loss -11.36837 acc 0.65789 roc_auc 0.41692 prc_auc 0.65251[0m
[92maverage training of epoch 76: loss -11.45051 acc 0.66667 roc_auc 0.42020 prc_auc 0.60455[0m
[93maverage test of epoch 76: loss -11.46773 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 77: loss -11.55016 acc 0.66667 roc_auc 0.42020 prc_auc 0.60494[0m
[93maverage test of epoch 77: loss -11.56708 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 78: loss -11.64978 acc 0.66667 roc_auc 0.42020 prc_auc 0.60461[0m
[93maverage test of epoch 78: loss -11.66641 acc 0.65789 roc_auc 0.62462 prc_auc 0.74070[0m
[92maverage training of epoch 79: loss -11.74939 acc 0.66667 roc_auc 0.42010 prc_auc 0.60458[0m
[93maverage test of epoch 79: loss -11.76573 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 80: loss -11.84899 acc 0.66667 roc_auc 0.42020 prc_auc 0.60458[0m
[93maverage test of epoch 80: loss -11.86503 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 81: loss -11.94857 acc 0.66667 roc_auc 0.42030 prc_auc 0.60497[0m
[93maverage test of epoch 81: loss -11.96431 acc 0.65789 roc_auc 0.58615 prc_auc 0.70895[0m
[92maverage training of epoch 82: loss -12.04814 acc 0.66667 roc_auc 0.42020 prc_auc 0.60455[0m
[93maverage test of epoch 82: loss -12.06359 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 83: loss -12.14769 acc 0.66667 roc_auc 0.42030 prc_auc 0.60455[0m
[93maverage test of epoch 83: loss -12.16286 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 84: loss -12.24724 acc 0.66667 roc_auc 0.42010 prc_auc 0.60455[0m
[93maverage test of epoch 84: loss -12.26211 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 85: loss -12.34678 acc 0.66667 roc_auc 0.42030 prc_auc 0.60458[0m
[93maverage test of epoch 85: loss -12.36136 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 86: loss -12.44630 acc 0.66667 roc_auc 0.42020 prc_auc 0.60458[0m
[93maverage test of epoch 86: loss -12.46060 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 87: loss -12.54582 acc 0.66667 roc_auc 0.42020 prc_auc 0.60494[0m
[93maverage test of epoch 87: loss -12.55983 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 88: loss -12.64534 acc 0.66667 roc_auc 0.42020 prc_auc 0.60455[0m
[93maverage test of epoch 88: loss -12.65905 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 89: loss -12.74484 acc 0.66667 roc_auc 0.42030 prc_auc 0.60458[0m
[93maverage test of epoch 89: loss -12.75827 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 90: loss -12.84434 acc 0.66667 roc_auc 0.42030 prc_auc 0.60494[0m
[93maverage test of epoch 90: loss -12.85748 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 91: loss -12.94383 acc 0.66667 roc_auc 0.42020 prc_auc 0.60497[0m
[93maverage test of epoch 91: loss -12.95669 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 92: loss -13.04332 acc 0.66667 roc_auc 0.42020 prc_auc 0.60497[0m
[93maverage test of epoch 92: loss -13.05589 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 93: loss -13.14281 acc 0.66667 roc_auc 0.42030 prc_auc 0.60458[0m
[93maverage test of epoch 93: loss -13.15509 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 94: loss -13.24229 acc 0.66667 roc_auc 0.42020 prc_auc 0.60461[0m
[93maverage test of epoch 94: loss -13.25428 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 95: loss -13.34176 acc 0.66667 roc_auc 0.42030 prc_auc 0.60500[0m
[93maverage test of epoch 95: loss -13.35347 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 96: loss -13.44124 acc 0.66667 roc_auc 0.42030 prc_auc 0.60500[0m
[93maverage test of epoch 96: loss -13.45266 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 97: loss -13.54070 acc 0.66667 roc_auc 0.42030 prc_auc 0.60497[0m
[93maverage test of epoch 97: loss -13.55184 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 98: loss -13.64017 acc 0.66667 roc_auc 0.42030 prc_auc 0.60497[0m
[93maverage test of epoch 98: loss -13.65102 acc 0.65789 roc_auc 0.66923 prc_auc 0.76496[0m
[92maverage training of epoch 99: loss -13.73963 acc 0.66667 roc_auc 0.42030 prc_auc 0.60458[0m
[93maverage test of epoch 99: loss -13.75020 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.45772 acc 0.66667 roc_auc 0.34600 prc_auc 0.57499[0m
[93maverage test of epoch 0: loss -0.55241 acc 0.65789 roc_auc 0.17231 prc_auc 0.56450[0m
[92maverage training of epoch 1: loss -0.66817 acc 0.66667 roc_auc 0.38700 prc_auc 0.60152[0m
[93maverage test of epoch 1: loss -0.76830 acc 0.65789 roc_auc 0.22462 prc_auc 0.59637[0m
[92maverage training of epoch 2: loss -0.89967 acc 0.66667 roc_auc 0.42380 prc_auc 0.62831[0m
[93maverage test of epoch 2: loss -1.00422 acc 0.65789 roc_auc 0.35077 prc_auc 0.66886[0m
[92maverage training of epoch 3: loss -1.15021 acc 0.66667 roc_auc 0.46900 prc_auc 0.66949[0m
[93maverage test of epoch 3: loss -1.25491 acc 0.65789 roc_auc 0.74154 prc_auc 0.89789[0m
[92maverage training of epoch 4: loss -1.40657 acc 0.66667 roc_auc 0.52440 prc_auc 0.72534[0m
[93maverage test of epoch 4: loss -1.50098 acc 0.65789 roc_auc 0.90154 prc_auc 0.96226[0m
[92maverage training of epoch 5: loss -1.64457 acc 0.66667 roc_auc 0.56900 prc_auc 0.76365[0m
[93maverage test of epoch 5: loss -1.71951 acc 0.65789 roc_auc 0.93846 prc_auc 0.97373[0m
[92maverage training of epoch 6: loss -1.85175 acc 0.66667 roc_auc 0.59300 prc_auc 0.78317[0m
[93maverage test of epoch 6: loss -1.90912 acc 0.65789 roc_auc 0.95385 prc_auc 0.97886[0m
[92maverage training of epoch 7: loss -2.03451 acc 0.66667 roc_auc 0.59900 prc_auc 0.78529[0m
[93maverage test of epoch 7: loss -2.07993 acc 0.65789 roc_auc 0.95385 prc_auc 0.97886[0m
[92maverage training of epoch 8: loss -2.20251 acc 0.66667 roc_auc 0.59420 prc_auc 0.77938[0m
[93maverage test of epoch 8: loss -2.24034 acc 0.65789 roc_auc 0.95385 prc_auc 0.97886[0m
[92maverage training of epoch 9: loss -2.36303 acc 0.66667 roc_auc 0.58600 prc_auc 0.76974[0m
[93maverage test of epoch 9: loss -2.39676 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 10: loss -2.52250 acc 0.66667 roc_auc 0.57640 prc_auc 0.75980[0m
[93maverage test of epoch 10: loss -2.55596 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 11: loss -2.68883 acc 0.66667 roc_auc 0.56740 prc_auc 0.75221[0m
[93maverage test of epoch 11: loss -2.72716 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 12: loss -2.87215 acc 0.66667 roc_auc 0.55480 prc_auc 0.74029[0m
[93maverage test of epoch 12: loss -2.92063 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 13: loss -3.07932 acc 0.66667 roc_auc 0.53490 prc_auc 0.72373[0m
[93maverage test of epoch 13: loss -3.13699 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 14: loss -3.30125 acc 0.66667 roc_auc 0.51490 prc_auc 0.70845[0m
[93maverage test of epoch 14: loss -3.35731 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 15: loss -3.51670 acc 0.66667 roc_auc 0.50880 prc_auc 0.70448[0m
[93maverage test of epoch 15: loss -3.56255 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 16: loss -3.71447 acc 0.66667 roc_auc 0.50640 prc_auc 0.70391[0m
[93maverage test of epoch 16: loss -3.74956 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 17: loss -3.89567 acc 0.66667 roc_auc 0.50730 prc_auc 0.70448[0m
[93maverage test of epoch 17: loss -3.92233 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 18: loss -4.06446 acc 0.66667 roc_auc 0.51220 prc_auc 0.70759[0m
[93maverage test of epoch 18: loss -4.08502 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 19: loss -4.22459 acc 0.66667 roc_auc 0.52140 prc_auc 0.71593[0m
[93maverage test of epoch 19: loss -4.24119 acc 0.65789 roc_auc 0.94923 prc_auc 0.97644[0m
[92maverage training of epoch 20: loss -4.37953 acc 0.66667 roc_auc 0.53320 prc_auc 0.72502[0m
[93maverage test of epoch 20: loss -4.39420 acc 0.65789 roc_auc 0.95077 prc_auc 0.97702[0m
[92maverage training of epoch 21: loss -4.53219 acc 0.66667 roc_auc 0.54840 prc_auc 0.73973[0m
[93maverage test of epoch 21: loss -4.54595 acc 0.65789 roc_auc 0.94923 prc_auc 0.97644[0m
[92maverage training of epoch 22: loss -4.68341 acc 0.66667 roc_auc 0.55100 prc_auc 0.74332[0m
[93maverage test of epoch 22: loss -4.69568 acc 0.65789 roc_auc 0.94769 prc_auc 0.97490[0m
[92maverage training of epoch 23: loss -4.83174 acc 0.66667 roc_auc 0.54830 prc_auc 0.73861[0m
[93maverage test of epoch 23: loss -4.84152 acc 0.65789 roc_auc 0.94769 prc_auc 0.97555[0m
[92maverage training of epoch 24: loss -4.97561 acc 0.66667 roc_auc 0.53730 prc_auc 0.72789[0m
[93maverage test of epoch 24: loss -4.98249 acc 0.65789 roc_auc 0.95077 prc_auc 0.97663[0m
[92maverage training of epoch 25: loss -5.11458 acc 0.66667 roc_auc 0.52480 prc_auc 0.71593[0m
[93maverage test of epoch 25: loss -5.11866 acc 0.65789 roc_auc 0.95077 prc_auc 0.97663[0m
[92maverage training of epoch 26: loss -5.24894 acc 0.66667 roc_auc 0.51390 prc_auc 0.70460[0m
[93maverage test of epoch 26: loss -5.25047 acc 0.65789 roc_auc 0.95077 prc_auc 0.97663[0m
[92maverage training of epoch 27: loss -5.37919 acc 0.66667 roc_auc 0.50260 prc_auc 0.69504[0m
[93maverage test of epoch 27: loss -5.37848 acc 0.65789 roc_auc 0.94154 prc_auc 0.97246[0m
[92maverage training of epoch 28: loss -5.50587 acc 0.66667 roc_auc 0.48970 prc_auc 0.68250[0m
[93maverage test of epoch 28: loss -5.50319 acc 0.65789 roc_auc 0.95077 prc_auc 0.97663[0m
[92maverage training of epoch 29: loss -5.62947 acc 0.66667 roc_auc 0.48000 prc_auc 0.67549[0m
[93maverage test of epoch 29: loss -5.62506 acc 0.65789 roc_auc 0.94308 prc_auc 0.97264[0m
[92maverage training of epoch 30: loss -5.75041 acc 0.66667 roc_auc 0.46970 prc_auc 0.66748[0m
[93maverage test of epoch 30: loss -5.74448 acc 0.65789 roc_auc 0.94308 prc_auc 0.97264[0m
[92maverage training of epoch 31: loss -5.86905 acc 0.66667 roc_auc 0.46090 prc_auc 0.66116[0m
[93maverage test of epoch 31: loss -5.86176 acc 0.65789 roc_auc 0.95231 prc_auc 0.97663[0m
[92maverage training of epoch 32: loss -5.98568 acc 0.66667 roc_auc 0.45420 prc_auc 0.65794[0m
[93maverage test of epoch 32: loss -5.97718 acc 0.65789 roc_auc 0.94308 prc_auc 0.97264[0m
[92maverage training of epoch 33: loss -6.10056 acc 0.66667 roc_auc 0.44690 prc_auc 0.65211[0m
[93maverage test of epoch 33: loss -6.09098 acc 0.65789 roc_auc 0.94308 prc_auc 0.97264[0m
[92maverage training of epoch 34: loss -6.21391 acc 0.66667 roc_auc 0.44310 prc_auc 0.65129[0m
[93maverage test of epoch 34: loss -6.20334 acc 0.65789 roc_auc 0.95385 prc_auc 0.97663[0m
[92maverage training of epoch 35: loss -6.32591 acc 0.66667 roc_auc 0.43890 prc_auc 0.64692[0m
[93maverage test of epoch 35: loss -6.31443 acc 0.65789 roc_auc 0.95846 prc_auc 0.97574[0m
[92maverage training of epoch 36: loss -6.43670 acc 0.66667 roc_auc 0.43600 prc_auc 0.64547[0m
[93maverage test of epoch 36: loss -6.42440 acc 0.65789 roc_auc 0.94923 prc_auc 0.97264[0m
[92maverage training of epoch 37: loss -6.54643 acc 0.66667 roc_auc 0.43270 prc_auc 0.64393[0m
[93maverage test of epoch 37: loss -6.53336 acc 0.65789 roc_auc 0.94000 prc_auc 0.96603[0m
[92maverage training of epoch 38: loss -6.65521 acc 0.66667 roc_auc 0.42940 prc_auc 0.64132[0m
[93maverage test of epoch 38: loss -6.64143 acc 0.65789 roc_auc 0.95231 prc_auc 0.96803[0m
[92maverage training of epoch 39: loss -6.76314 acc 0.66667 roc_auc 0.42570 prc_auc 0.63770[0m
[93maverage test of epoch 39: loss -6.74869 acc 0.65789 roc_auc 0.94462 prc_auc 0.96805[0m
[92maverage training of epoch 40: loss -6.87030 acc 0.66667 roc_auc 0.42180 prc_auc 0.63674[0m
[93maverage test of epoch 40: loss -6.85523 acc 0.65789 roc_auc 0.96154 prc_auc 0.97298[0m
[92maverage training of epoch 41: loss -6.97676 acc 0.66667 roc_auc 0.41980 prc_auc 0.63508[0m
[93maverage test of epoch 41: loss -6.96111 acc 0.65789 roc_auc 0.91846 prc_auc 0.94492[0m
[92maverage training of epoch 42: loss -7.08261 acc 0.66667 roc_auc 0.41800 prc_auc 0.63389[0m
[93maverage test of epoch 42: loss -7.06640 acc 0.65789 roc_auc 0.90615 prc_auc 0.93892[0m
[92maverage training of epoch 43: loss -7.18790 acc 0.66667 roc_auc 0.41290 prc_auc 0.63101[0m
[93maverage test of epoch 43: loss -7.17116 acc 0.65789 roc_auc 0.91846 prc_auc 0.93804[0m
[92maverage training of epoch 44: loss -7.29267 acc 0.66667 roc_auc 0.41190 prc_auc 0.62851[0m
[93maverage test of epoch 44: loss -7.27543 acc 0.65789 roc_auc 0.93385 prc_auc 0.94632[0m
[92maverage training of epoch 45: loss -7.39698 acc 0.66667 roc_auc 0.40830 prc_auc 0.62580[0m
[93maverage test of epoch 45: loss -7.37926 acc 0.65789 roc_auc 0.88923 prc_auc 0.91529[0m
[92maverage training of epoch 46: loss -7.50088 acc 0.66667 roc_auc 0.40610 prc_auc 0.62438[0m
[93maverage test of epoch 46: loss -7.48270 acc 0.65789 roc_auc 0.89231 prc_auc 0.90632[0m
[92maverage training of epoch 47: loss -7.60439 acc 0.66667 roc_auc 0.40620 prc_auc 0.62431[0m
[93maverage test of epoch 47: loss -7.58576 acc 0.65789 roc_auc 0.72000 prc_auc 0.80842[0m
[92maverage training of epoch 48: loss -7.70755 acc 0.66667 roc_auc 0.40330 prc_auc 0.62350[0m
[93maverage test of epoch 48: loss -7.68850 acc 0.65789 roc_auc 0.84000 prc_auc 0.89053[0m
[92maverage training of epoch 49: loss -7.81039 acc 0.66667 roc_auc 0.40270 prc_auc 0.62364[0m
[93maverage test of epoch 49: loss -7.79093 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 50: loss -7.91295 acc 0.66667 roc_auc 0.40050 prc_auc 0.61617[0m
[93maverage test of epoch 50: loss -7.89308 acc 0.65789 roc_auc 0.84000 prc_auc 0.89053[0m
[92maverage training of epoch 51: loss -8.01524 acc 0.66667 roc_auc 0.39440 prc_auc 0.60851[0m
[93maverage test of epoch 51: loss -7.99498 acc 0.65789 roc_auc 0.67231 prc_auc 0.74632[0m
[92maverage training of epoch 52: loss -8.11729 acc 0.66667 roc_auc 0.39490 prc_auc 0.60398[0m
[93maverage test of epoch 52: loss -8.09665 acc 0.65789 roc_auc 0.82000 prc_auc 0.87684[0m
[92maverage training of epoch 53: loss -8.21912 acc 0.66667 roc_auc 0.39370 prc_auc 0.60649[0m
[93maverage test of epoch 53: loss -8.19811 acc 0.65789 roc_auc 0.88000 prc_auc 0.91789[0m
[92maverage training of epoch 54: loss -8.32074 acc 0.66667 roc_auc 0.39110 prc_auc 0.60329[0m
[93maverage test of epoch 54: loss -8.29937 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 55: loss -8.42219 acc 0.66667 roc_auc 0.39260 prc_auc 0.60778[0m
[93maverage test of epoch 55: loss -8.40045 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 56: loss -8.52346 acc 0.66667 roc_auc 0.39110 prc_auc 0.60860[0m
[93maverage test of epoch 56: loss -8.50138 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 57: loss -8.62458 acc 0.66667 roc_auc 0.39130 prc_auc 0.60980[0m
[93maverage test of epoch 57: loss -8.60216 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 58: loss -8.72556 acc 0.66667 roc_auc 0.39030 prc_auc 0.60132[0m
[93maverage test of epoch 58: loss -8.70280 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 59: loss -8.82641 acc 0.66667 roc_auc 0.38830 prc_auc 0.60182[0m
[93maverage test of epoch 59: loss -8.80331 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 60: loss -8.92714 acc 0.66667 roc_auc 0.38660 prc_auc 0.59933[0m
[93maverage test of epoch 60: loss -8.90371 acc 0.65789 roc_auc 0.82000 prc_auc 0.87684[0m
[92maverage training of epoch 61: loss -9.02776 acc 0.66667 roc_auc 0.38870 prc_auc 0.60173[0m
[93maverage test of epoch 61: loss -9.00401 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 62: loss -9.12828 acc 0.66667 roc_auc 0.38580 prc_auc 0.60105[0m
[93maverage test of epoch 62: loss -9.10421 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 63: loss -9.22872 acc 0.66667 roc_auc 0.38950 prc_auc 0.60164[0m
[93maverage test of epoch 63: loss -9.20433 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 64: loss -9.32906 acc 0.66667 roc_auc 0.38670 prc_auc 0.59733[0m
[93maverage test of epoch 64: loss -9.30436 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 65: loss -9.42934 acc 0.66667 roc_auc 0.38500 prc_auc 0.59774[0m
[93maverage test of epoch 65: loss -9.40432 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 66: loss -9.52954 acc 0.66667 roc_auc 0.38530 prc_auc 0.59667[0m
[93maverage test of epoch 66: loss -9.50421 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 67: loss -9.62968 acc 0.66667 roc_auc 0.38230 prc_auc 0.59554[0m
[93maverage test of epoch 67: loss -9.60405 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 68: loss -9.72976 acc 0.66667 roc_auc 0.38850 prc_auc 0.60027[0m
[93maverage test of epoch 68: loss -9.70382 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 69: loss -9.82978 acc 0.66667 roc_auc 0.38620 prc_auc 0.59919[0m
[93maverage test of epoch 69: loss -9.80354 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 70: loss -9.92976 acc 0.66667 roc_auc 0.38590 prc_auc 0.59995[0m
[93maverage test of epoch 70: loss -9.90322 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 71: loss -10.02969 acc 0.66667 roc_auc 0.38900 prc_auc 0.60133[0m
[93maverage test of epoch 71: loss -10.00285 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 72: loss -10.12958 acc 0.66667 roc_auc 0.38620 prc_auc 0.60121[0m
[93maverage test of epoch 72: loss -10.10244 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 73: loss -10.22943 acc 0.66667 roc_auc 0.38940 prc_auc 0.59983[0m
[93maverage test of epoch 73: loss -10.20199 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 74: loss -10.32924 acc 0.66667 roc_auc 0.38940 prc_auc 0.60434[0m
[93maverage test of epoch 74: loss -10.30151 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 75: loss -10.42903 acc 0.66667 roc_auc 0.38910 prc_auc 0.60235[0m
[93maverage test of epoch 75: loss -10.40100 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 76: loss -10.52878 acc 0.66667 roc_auc 0.38790 prc_auc 0.60237[0m
[93maverage test of epoch 76: loss -10.50046 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 77: loss -10.62851 acc 0.66667 roc_auc 0.38230 prc_auc 0.59518[0m
[93maverage test of epoch 77: loss -10.59989 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 78: loss -10.72821 acc 0.66667 roc_auc 0.38970 prc_auc 0.60126[0m
[93maverage test of epoch 78: loss -10.69931 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 79: loss -10.82789 acc 0.66667 roc_auc 0.39180 prc_auc 0.60179[0m
[93maverage test of epoch 79: loss -10.79869 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 80: loss -10.92755 acc 0.66667 roc_auc 0.38670 prc_auc 0.59904[0m
[93maverage test of epoch 80: loss -10.89806 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 81: loss -11.02719 acc 0.66667 roc_auc 0.38830 prc_auc 0.59990[0m
[93maverage test of epoch 81: loss -10.99741 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 82: loss -11.12682 acc 0.66667 roc_auc 0.38530 prc_auc 0.59330[0m
[93maverage test of epoch 82: loss -11.09675 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 83: loss -11.22642 acc 0.66667 roc_auc 0.37490 prc_auc 0.58717[0m
[93maverage test of epoch 83: loss -11.19606 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 84: loss -11.32601 acc 0.66667 roc_auc 0.39450 prc_auc 0.60327[0m
[93maverage test of epoch 84: loss -11.29537 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 85: loss -11.42559 acc 0.66667 roc_auc 0.38180 prc_auc 0.58766[0m
[93maverage test of epoch 85: loss -11.39466 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 86: loss -11.52516 acc 0.66667 roc_auc 0.38410 prc_auc 0.58935[0m
[93maverage test of epoch 86: loss -11.49393 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 87: loss -11.62471 acc 0.66667 roc_auc 0.39330 prc_auc 0.60294[0m
[93maverage test of epoch 87: loss -11.59320 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 88: loss -11.72425 acc 0.66667 roc_auc 0.38920 prc_auc 0.59480[0m
[93maverage test of epoch 88: loss -11.69245 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 89: loss -11.82378 acc 0.66667 roc_auc 0.37860 prc_auc 0.58400[0m
[93maverage test of epoch 89: loss -11.79170 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -11.92331 acc 0.66667 roc_auc 0.38780 prc_auc 0.59394[0m
[93maverage test of epoch 90: loss -11.89093 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 91: loss -12.02282 acc 0.66667 roc_auc 0.38500 prc_auc 0.58973[0m
[93maverage test of epoch 91: loss -11.99016 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 92: loss -12.12233 acc 0.66667 roc_auc 0.37990 prc_auc 0.58778[0m
[93maverage test of epoch 92: loss -12.08938 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 93: loss -12.22183 acc 0.66667 roc_auc 0.38650 prc_auc 0.59263[0m
[93maverage test of epoch 93: loss -12.18860 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 94: loss -12.32132 acc 0.66667 roc_auc 0.38970 prc_auc 0.59398[0m
[93maverage test of epoch 94: loss -12.28781 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 95: loss -12.42081 acc 0.66667 roc_auc 0.37980 prc_auc 0.58592[0m
[93maverage test of epoch 95: loss -12.38701 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 96: loss -12.52029 acc 0.66667 roc_auc 0.38130 prc_auc 0.58942[0m
[93maverage test of epoch 96: loss -12.48620 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 97: loss -12.61977 acc 0.66667 roc_auc 0.37680 prc_auc 0.58797[0m
[93maverage test of epoch 97: loss -12.58539 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 98: loss -12.71924 acc 0.66667 roc_auc 0.38230 prc_auc 0.58848[0m
[93maverage test of epoch 98: loss -12.68458 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -12.81870 acc 0.66667 roc_auc 0.39070 prc_auc 0.59462[0m
[93maverage test of epoch 99: loss -12.78376 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.38019 acc 0.66225 roc_auc 0.37039 prc_auc 0.58748[0m
[93maverage test of epoch 0: loss -0.53270 acc 0.67568 roc_auc 0.15333 prc_auc 0.53726[0m
[92maverage training of epoch 1: loss -0.65365 acc 0.66225 roc_auc 0.40980 prc_auc 0.61268[0m
[93maverage test of epoch 1: loss -0.81057 acc 0.67568 roc_auc 0.39333 prc_auc 0.73336[0m
[92maverage training of epoch 2: loss -0.94259 acc 0.66225 roc_auc 0.45039 prc_auc 0.64364[0m
[93maverage test of epoch 2: loss -1.11503 acc 0.67568 roc_auc 0.71667 prc_auc 0.87790[0m
[92maverage training of epoch 3: loss -1.24091 acc 0.66225 roc_auc 0.46765 prc_auc 0.65411[0m
[93maverage test of epoch 3: loss -1.40124 acc 0.67568 roc_auc 0.83667 prc_auc 0.92112[0m
[92maverage training of epoch 4: loss -1.50278 acc 0.66225 roc_auc 0.46373 prc_auc 0.65024[0m
[93maverage test of epoch 4: loss -1.64326 acc 0.67568 roc_auc 0.84167 prc_auc 0.92028[0m
[92maverage training of epoch 5: loss -1.72676 acc 0.66225 roc_auc 0.45157 prc_auc 0.64025[0m
[93maverage test of epoch 5: loss -1.85583 acc 0.67568 roc_auc 0.84000 prc_auc 0.92019[0m
[92maverage training of epoch 6: loss -1.92836 acc 0.66225 roc_auc 0.43941 prc_auc 0.62958[0m
[93maverage test of epoch 6: loss -2.05127 acc 0.67568 roc_auc 0.83667 prc_auc 0.92298[0m
[92maverage training of epoch 7: loss -2.11722 acc 0.66225 roc_auc 0.43569 prc_auc 0.62651[0m
[93maverage test of epoch 7: loss -2.23785 acc 0.67568 roc_auc 0.84333 prc_auc 0.92023[0m
[92maverage training of epoch 8: loss -2.30254 acc 0.66225 roc_auc 0.43941 prc_auc 0.63060[0m
[93maverage test of epoch 8: loss -2.42659 acc 0.67568 roc_auc 0.83667 prc_auc 0.92082[0m
[92maverage training of epoch 9: loss -2.49639 acc 0.66225 roc_auc 0.44725 prc_auc 0.63957[0m
[93maverage test of epoch 9: loss -2.62982 acc 0.67568 roc_auc 0.82667 prc_auc 0.91300[0m
[92maverage training of epoch 10: loss -2.70775 acc 0.66225 roc_auc 0.45441 prc_auc 0.64529[0m
[93maverage test of epoch 10: loss -2.85276 acc 0.67568 roc_auc 0.84000 prc_auc 0.92021[0m
[92maverage training of epoch 11: loss -2.93779 acc 0.66225 roc_auc 0.45608 prc_auc 0.64771[0m
[93maverage test of epoch 11: loss -3.09386 acc 0.67568 roc_auc 0.83667 prc_auc 0.91945[0m
[92maverage training of epoch 12: loss -3.18236 acc 0.66225 roc_auc 0.45765 prc_auc 0.64907[0m
[93maverage test of epoch 12: loss -3.34469 acc 0.67568 roc_auc 0.85000 prc_auc 0.92424[0m
[92maverage training of epoch 13: loss -3.42744 acc 0.66225 roc_auc 0.45941 prc_auc 0.65057[0m
[93maverage test of epoch 13: loss -3.58529 acc 0.67568 roc_auc 0.85667 prc_auc 0.92813[0m
[92maverage training of epoch 14: loss -3.65438 acc 0.66225 roc_auc 0.45980 prc_auc 0.65009[0m
[93maverage test of epoch 14: loss -3.80166 acc 0.67568 roc_auc 0.86333 prc_auc 0.93369[0m
[92maverage training of epoch 15: loss -3.85761 acc 0.66225 roc_auc 0.46255 prc_auc 0.65172[0m
[93maverage test of epoch 15: loss -3.99656 acc 0.67568 roc_auc 0.86167 prc_auc 0.93294[0m
[92maverage training of epoch 16: loss -4.04425 acc 0.66225 roc_auc 0.46039 prc_auc 0.64964[0m
[93maverage test of epoch 16: loss -4.18086 acc 0.67568 roc_auc 0.87000 prc_auc 0.93779[0m
[92maverage training of epoch 17: loss -4.22680 acc 0.66225 roc_auc 0.45843 prc_auc 0.65084[0m
[93maverage test of epoch 17: loss -4.36950 acc 0.67568 roc_auc 0.86667 prc_auc 0.93494[0m
[92maverage training of epoch 18: loss -4.42029 acc 0.66225 roc_auc 0.46824 prc_auc 0.66509[0m
[93maverage test of epoch 18: loss -4.57409 acc 0.67568 roc_auc 0.81000 prc_auc 0.90602[0m
[92maverage training of epoch 19: loss -4.62257 acc 0.66225 roc_auc 0.50294 prc_auc 0.69632[0m
[93maverage test of epoch 19: loss -4.76983 acc 0.67568 roc_auc 0.84667 prc_auc 0.91927[0m
[92maverage training of epoch 20: loss -4.80303 acc 0.66225 roc_auc 0.52324 prc_auc 0.70796[0m
[93maverage test of epoch 20: loss -4.93853 acc 0.67568 roc_auc 0.85000 prc_auc 0.92040[0m
[92maverage training of epoch 21: loss -4.96199 acc 0.66225 roc_auc 0.51363 prc_auc 0.69410[0m
[93maverage test of epoch 21: loss -5.09240 acc 0.67568 roc_auc 0.85667 prc_auc 0.92293[0m
[92maverage training of epoch 22: loss -5.10978 acc 0.66225 roc_auc 0.49980 prc_auc 0.68168[0m
[93maverage test of epoch 22: loss -5.23742 acc 0.67568 roc_auc 0.85667 prc_auc 0.92293[0m
[92maverage training of epoch 23: loss -5.25033 acc 0.66225 roc_auc 0.48941 prc_auc 0.67497[0m
[93maverage test of epoch 23: loss -5.37612 acc 0.67568 roc_auc 0.85667 prc_auc 0.92293[0m
[92maverage training of epoch 24: loss -5.38545 acc 0.66225 roc_auc 0.47765 prc_auc 0.66535[0m
[93maverage test of epoch 24: loss -5.50988 acc 0.67568 roc_auc 0.85667 prc_auc 0.92293[0m
[92maverage training of epoch 25: loss -5.51622 acc 0.66225 roc_auc 0.46510 prc_auc 0.65602[0m
[93maverage test of epoch 25: loss -5.63961 acc 0.67568 roc_auc 0.85667 prc_auc 0.92293[0m
[92maverage training of epoch 26: loss -5.64339 acc 0.66225 roc_auc 0.45725 prc_auc 0.65031[0m
[93maverage test of epoch 26: loss -5.76599 acc 0.67568 roc_auc 0.85667 prc_auc 0.92293[0m
[92maverage training of epoch 27: loss -5.76754 acc 0.66225 roc_auc 0.44902 prc_auc 0.64439[0m
[93maverage test of epoch 27: loss -5.88951 acc 0.67568 roc_auc 0.85667 prc_auc 0.92312[0m
[92maverage training of epoch 28: loss -5.88907 acc 0.66225 roc_auc 0.44206 prc_auc 0.63682[0m
[93maverage test of epoch 28: loss -6.01057 acc 0.67568 roc_auc 0.85667 prc_auc 0.92327[0m
[92maverage training of epoch 29: loss -6.00836 acc 0.66225 roc_auc 0.43843 prc_auc 0.63465[0m
[93maverage test of epoch 29: loss -6.12949 acc 0.67568 roc_auc 0.85667 prc_auc 0.92308[0m
[92maverage training of epoch 30: loss -6.12568 acc 0.66225 roc_auc 0.43235 prc_auc 0.62787[0m
[93maverage test of epoch 30: loss -6.24654 acc 0.67568 roc_auc 0.85667 prc_auc 0.92327[0m
[92maverage training of epoch 31: loss -6.24127 acc 0.66225 roc_auc 0.42784 prc_auc 0.62333[0m
[93maverage test of epoch 31: loss -6.36193 acc 0.67568 roc_auc 0.85667 prc_auc 0.92381[0m
[92maverage training of epoch 32: loss -6.35533 acc 0.66225 roc_auc 0.42353 prc_auc 0.62030[0m
[93maverage test of epoch 32: loss -6.47587 acc 0.67568 roc_auc 0.86000 prc_auc 0.92337[0m
[92maverage training of epoch 33: loss -6.46804 acc 0.66225 roc_auc 0.41902 prc_auc 0.61634[0m
[93maverage test of epoch 33: loss -6.58850 acc 0.67568 roc_auc 0.85667 prc_auc 0.92353[0m
[92maverage training of epoch 34: loss -6.57953 acc 0.66225 roc_auc 0.41627 prc_auc 0.61265[0m
[93maverage test of epoch 34: loss -6.69997 acc 0.67568 roc_auc 0.85667 prc_auc 0.92419[0m
[92maverage training of epoch 35: loss -6.68994 acc 0.66225 roc_auc 0.41314 prc_auc 0.61046[0m
[93maverage test of epoch 35: loss -6.81041 acc 0.67568 roc_auc 0.86000 prc_auc 0.92419[0m
[92maverage training of epoch 36: loss -6.79938 acc 0.66225 roc_auc 0.41196 prc_auc 0.61016[0m
[93maverage test of epoch 36: loss -6.91991 acc 0.67568 roc_auc 0.85833 prc_auc 0.92070[0m
[92maverage training of epoch 37: loss -6.90794 acc 0.66225 roc_auc 0.41000 prc_auc 0.60959[0m
[93maverage test of epoch 37: loss -7.02857 acc 0.67568 roc_auc 0.86000 prc_auc 0.92174[0m
[92maverage training of epoch 38: loss -7.01572 acc 0.66225 roc_auc 0.40833 prc_auc 0.60785[0m
[93maverage test of epoch 38: loss -7.13648 acc 0.67568 roc_auc 0.85833 prc_auc 0.91670[0m
[92maverage training of epoch 39: loss -7.12279 acc 0.66225 roc_auc 0.40686 prc_auc 0.60640[0mUsing backend: pytorch
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))

[93maverage test of epoch 39: loss -7.24370 acc 0.67568 roc_auc 0.85833 prc_auc 0.92106[0m
[92maverage training of epoch 40: loss -7.22922 acc 0.66225 roc_auc 0.40480 prc_auc 0.60503[0m
[93maverage test of epoch 40: loss -7.35031 acc 0.67568 roc_auc 0.86167 prc_auc 0.92211[0m
[92maverage training of epoch 41: loss -7.33507 acc 0.66225 roc_auc 0.40451 prc_auc 0.60532[0m
[93maverage test of epoch 41: loss -7.45635 acc 0.67568 roc_auc 0.85500 prc_auc 0.91722[0m
[92maverage training of epoch 42: loss -7.44039 acc 0.66225 roc_auc 0.40324 prc_auc 0.60445[0m
[93maverage test of epoch 42: loss -7.56189 acc 0.67568 roc_auc 0.86167 prc_auc 0.91876[0m
[92maverage training of epoch 43: loss -7.54524 acc 0.66225 roc_auc 0.40108 prc_auc 0.60294[0m
[93maverage test of epoch 43: loss -7.66697 acc 0.67568 roc_auc 0.85167 prc_auc 0.90009[0m
[92maverage training of epoch 44: loss -7.64965 acc 0.66225 roc_auc 0.39961 prc_auc 0.60201[0m
[93maverage test of epoch 44: loss -7.77164 acc 0.67568 roc_auc 0.85500 prc_auc 0.91801[0m
[92maverage training of epoch 45: loss -7.75367 acc 0.66225 roc_auc 0.39922 prc_auc 0.60119[0m
[93maverage test of epoch 45: loss -7.87592 acc 0.67568 roc_auc 0.84500 prc_auc 0.89349[0m
[92maverage training of epoch 46: loss -7.85733 acc 0.66225 roc_auc 0.39745 prc_auc 0.59996[0m
[93maverage test of epoch 46: loss -7.97986 acc 0.67568 roc_auc 0.87333 prc_auc 0.92239[0m
[92maverage training of epoch 47: loss -7.96066 acc 0.66225 roc_auc 0.39578 prc_auc 0.59871[0m
[93maverage test of epoch 47: loss -8.08349 acc 0.67568 roc_auc 0.84667 prc_auc 0.90526[0m
[92maverage training of epoch 48: loss -8.06369 acc 0.66225 roc_auc 0.39265 prc_auc 0.58937[0m
[93maverage test of epoch 48: loss -8.18683 acc 0.67568 roc_auc 0.86000 prc_auc 0.89762[0m
[92maverage training of epoch 49: loss -8.16646 acc 0.66225 roc_auc 0.39069 prc_auc 0.58775[0m
[93maverage test of epoch 49: loss -8.28991 acc 0.67568 roc_auc 0.83667 prc_auc 0.87743[0m
[92maverage training of epoch 50: loss -8.26898 acc 0.66225 roc_auc 0.39000 prc_auc 0.58686[0m
[93maverage test of epoch 50: loss -8.39275 acc 0.67568 roc_auc 0.85833 prc_auc 0.90094[0m
[92maverage training of epoch 51: loss -8.37128 acc 0.66225 roc_auc 0.38804 prc_auc 0.58559[0m
[93maverage test of epoch 51: loss -8.49538 acc 0.67568 roc_auc 0.86333 prc_auc 0.89727[0m
[92maverage training of epoch 52: loss -8.47336 acc 0.66225 roc_auc 0.38765 prc_auc 0.58536[0m
[93maverage test of epoch 52: loss -8.59780 acc 0.67568 roc_auc 0.81833 prc_auc 0.86511[0m
[92maverage training of epoch 53: loss -8.57526 acc 0.66225 roc_auc 0.38706 prc_auc 0.58560[0m
[93maverage test of epoch 53: loss -8.70005 acc 0.67568 roc_auc 0.85000 prc_auc 0.88746[0m
[92maverage training of epoch 54: loss -8.67699 acc 0.66225 roc_auc 0.38618 prc_auc 0.58494[0m
[93maverage test of epoch 54: loss -8.80213 acc 0.67568 roc_auc 0.85333 prc_auc 0.89350[0m
[92maverage training of epoch 55: loss -8.77857 acc 0.66225 roc_auc 0.38569 prc_auc 0.58520[0m
[93maverage test of epoch 55: loss -8.90406 acc 0.67568 roc_auc 0.87000 prc_auc 0.89571[0m
[92maverage training of epoch 56: loss -8.88000 acc 0.66225 roc_auc 0.38510 prc_auc 0.58465[0m
[93maverage test of epoch 56: loss -9.00586 acc 0.67568 roc_auc 0.76833 prc_auc 0.83318[0m
[92maverage training of epoch 57: loss -8.98130 acc 0.66225 roc_auc 0.38441 prc_auc 0.58417[0m
[93maverage test of epoch 57: loss -9.10753 acc 0.67568 roc_auc 0.72000 prc_auc 0.79199[0m
[92maverage training of epoch 58: loss -9.08248 acc 0.66225 roc_auc 0.38412 prc_auc 0.58386[0m
[93maverage test of epoch 58: loss -9.20908 acc 0.67568 roc_auc 0.70000 prc_auc 0.78933[0m
[92maverage training of epoch 59: loss -9.18355 acc 0.66225 roc_auc 0.38402 prc_auc 0.58368[0m
[93maverage test of epoch 59: loss -9.31053 acc 0.67568 roc_auc 0.86000 prc_auc 0.89108[0m
[92maverage training of epoch 60: loss -9.28452 acc 0.66225 roc_auc 0.38402 prc_auc 0.58331[0m
[93maverage test of epoch 60: loss -9.41188 acc 0.67568 roc_auc 0.84000 prc_auc 0.87252[0m
[92maverage training of epoch 61: loss -9.38540 acc 0.66225 roc_auc 0.38373 prc_auc 0.58372[0m
[93maverage test of epoch 61: loss -9.51314 acc 0.67568 roc_auc 0.86000 prc_auc 0.89108[0m
[92maverage training of epoch 62: loss -9.48620 acc 0.66225 roc_auc 0.38363 prc_auc 0.58359[0m
[93maverage test of epoch 62: loss -9.61433 acc 0.67568 roc_auc 0.58000 prc_auc 0.71644[0m
[92maverage training of epoch 63: loss -9.58692 acc 0.66225 roc_auc 0.38324 prc_auc 0.58358[0m
[93maverage test of epoch 63: loss -9.71544 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 64: loss -9.68756 acc 0.66225 roc_auc 0.38304 prc_auc 0.58348[0m
[93maverage test of epoch 64: loss -9.81648 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 65: loss -9.78815 acc 0.66225 roc_auc 0.38275 prc_auc 0.58338[0m
[93maverage test of epoch 65: loss -9.91746 acc 0.67568 roc_auc 0.60000 prc_auc 0.72571[0m
[92maverage training of epoch 66: loss -9.88867 acc 0.66225 roc_auc 0.38196 prc_auc 0.58239[0m
[93maverage test of epoch 66: loss -10.01838 acc 0.67568 roc_auc 0.60000 prc_auc 0.72571[0m
[92maverage training of epoch 67: loss -9.98915 acc 0.66225 roc_auc 0.38294 prc_auc 0.58366[0m
[93maverage test of epoch 67: loss -10.11926 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 68: loss -10.08957 acc 0.66225 roc_auc 0.38265 prc_auc 0.58311[0m
[93maverage test of epoch 68: loss -10.22008 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 69: loss -10.18994 acc 0.66225 roc_auc 0.38314 prc_auc 0.58354[0m
[93maverage test of epoch 69: loss -10.32086 acc 0.67568 roc_auc 0.74000 prc_auc 0.81658[0m
[92maverage training of epoch 70: loss -10.29028 acc 0.66225 roc_auc 0.38324 prc_auc 0.58382[0m
[93maverage test of epoch 70: loss -10.42160 acc 0.67568 roc_auc 0.84000 prc_auc 0.87854[0m
[92maverage training of epoch 71: loss -10.39058 acc 0.66225 roc_auc 0.38216 prc_auc 0.58213[0m
[93maverage test of epoch 71: loss -10.52231 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 72: loss -10.49084 acc 0.66225 roc_auc 0.38216 prc_auc 0.58268[0m
[93maverage test of epoch 72: loss -10.62298 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 73: loss -10.59107 acc 0.66225 roc_auc 0.38157 prc_auc 0.58179[0m
[93maverage test of epoch 73: loss -10.72362 acc 0.67568 roc_auc 0.68000 prc_auc 0.78032[0m
[92maverage training of epoch 74: loss -10.69127 acc 0.66225 roc_auc 0.38235 prc_auc 0.57674[0m
[93maverage test of epoch 74: loss -10.82423 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 75: loss -10.79145 acc 0.66225 roc_auc 0.38167 prc_auc 0.57526[0m
[93maverage test of epoch 75: loss -10.92482 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 76: loss -10.89160 acc 0.66225 roc_auc 0.38069 prc_auc 0.57406[0m
[93maverage test of epoch 76: loss -11.02538 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 77: loss -10.99172 acc 0.66225 roc_auc 0.38098 prc_auc 0.57386[0m
[93maverage test of epoch 77: loss -11.12593 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 78: loss -11.09183 acc 0.66225 roc_auc 0.38020 prc_auc 0.57284[0m
[93maverage test of epoch 78: loss -11.22645 acc 0.67568 roc_auc 0.86000 prc_auc 0.89108[0m
[92maverage training of epoch 79: loss -11.19191 acc 0.66225 roc_auc 0.37941 prc_auc 0.57167[0m
[93maverage test of epoch 79: loss -11.32695 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 80: loss -11.29198 acc 0.66225 roc_auc 0.37931 prc_auc 0.57212[0m
[93maverage test of epoch 80: loss -11.42743 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 81: loss -11.39204 acc 0.66225 roc_auc 0.37931 prc_auc 0.57199[0m
[93maverage test of epoch 81: loss -11.52790 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 82: loss -11.49207 acc 0.66225 roc_auc 0.37853 prc_auc 0.57201[0m
[93maverage test of epoch 82: loss -11.62836 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 83: loss -11.59210 acc 0.66225 roc_auc 0.37824 prc_auc 0.57140[0m
[93maverage test of epoch 83: loss -11.72880 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 84: loss -11.69211 acc 0.66225 roc_auc 0.37873 prc_auc 0.57217[0m
[93maverage test of epoch 84: loss -11.82923 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 85: loss -11.79211 acc 0.66225 roc_auc 0.37814 prc_auc 0.57216[0m
[93maverage test of epoch 85: loss -11.92965 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 86: loss -11.89210 acc 0.66225 roc_auc 0.37755 prc_auc 0.57121[0m
[93maverage test of epoch 86: loss -12.03006 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 87: loss -11.99208 acc 0.66225 roc_auc 0.37755 prc_auc 0.57152[0m
[93maverage test of epoch 87: loss -12.13046 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 88: loss -12.09205 acc 0.66225 roc_auc 0.37716 prc_auc 0.57103[0m
[93maverage test of epoch 88: loss -12.23085 acc 0.67568 roc_auc 0.60000 prc_auc 0.72655[0m
[92maverage training of epoch 89: loss -12.19201 acc 0.66225 roc_auc 0.37765 prc_auc 0.57155[0m
[93maverage test of epoch 89: loss -12.33124 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 90: loss -12.29197 acc 0.66225 roc_auc 0.37716 prc_auc 0.57181[0m
[93maverage test of epoch 90: loss -12.43161 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 91: loss -12.39192 acc 0.66225 roc_auc 0.37686 prc_auc 0.57103[0m
[93maverage test of epoch 91: loss -12.53198 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 92: loss -12.49186 acc 0.66225 roc_auc 0.37608 prc_auc 0.57062[0m
[93maverage test of epoch 92: loss -12.63235 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 93: loss -12.59180 acc 0.66225 roc_auc 0.37667 prc_auc 0.57205[0m
[93maverage test of epoch 93: loss -12.73271 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 94: loss -12.69173 acc 0.66225 roc_auc 0.37676 prc_auc 0.57187[0m
[93maverage test of epoch 94: loss -12.83306 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 95: loss -12.79165 acc 0.66225 roc_auc 0.37667 prc_auc 0.57264[0m
[93maverage test of epoch 95: loss -12.93341 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 96: loss -12.89158 acc 0.66225 roc_auc 0.37608 prc_auc 0.57140[0m
[93maverage test of epoch 96: loss -13.03375 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 97: loss -12.99149 acc 0.66225 roc_auc 0.37588 prc_auc 0.57159[0m
[93maverage test of epoch 97: loss -13.13409 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 98: loss -13.09141 acc 0.66225 roc_auc 0.37647 prc_auc 0.57232[0m
[93maverage test of epoch 98: loss -13.23443 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 99: loss -13.19132 acc 0.66225 roc_auc 0.37627 prc_auc 0.57171[0m
[93maverage test of epoch 99: loss -13.33477 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss 0.02463 acc 0.64901 roc_auc 0.32118 prc_auc 0.57018[0m
[93maverage test of epoch 0: loss -0.05657 acc 0.67568 roc_auc 0.33667 prc_auc 0.68251[0m
[92maverage training of epoch 1: loss -0.13015 acc 0.66225 roc_auc 0.41863 prc_auc 0.65092[0m
[93maverage test of epoch 1: loss -0.21308 acc 0.67568 roc_auc 0.57000 prc_auc 0.82014[0m
[92maverage training of epoch 2: loss -0.28047 acc 0.66225 roc_auc 0.52863 prc_auc 0.74039[0m
[93maverage test of epoch 2: loss -0.36097 acc 0.67568 roc_auc 0.87333 prc_auc 0.95242[0m
[92maverage training of epoch 3: loss -0.42212 acc 0.66225 roc_auc 0.63196 prc_auc 0.80947[0m
[93maverage test of epoch 3: loss -0.50219 acc 0.67568 roc_auc 0.92667 prc_auc 0.97175[0m
[92maverage training of epoch 4: loss -0.56140 acc 0.66225 roc_auc 0.70824 prc_auc 0.85322[0m
[93maverage test of epoch 4: loss -0.64557 acc 0.67568 roc_auc 0.92667 prc_auc 0.97247[0m
[92maverage training of epoch 5: loss -0.70418 acc 0.66225 roc_auc 0.78275 prc_auc 0.88847[0m
[93maverage test of epoch 5: loss -0.79254 acc 0.67568 roc_auc 0.93000 prc_auc 0.97420[0m
[92maverage training of epoch 6: loss -0.84934 acc 0.66225 roc_auc 0.84471 prc_auc 0.91364[0m
[93maverage test of epoch 6: loss -0.94136 acc 0.67568 roc_auc 0.93667 prc_auc 0.97575[0m
[92maverage training of epoch 7: loss -0.99704 acc 0.66225 roc_auc 0.86490 prc_auc 0.92435[0m
[93maverage test of epoch 7: loss -1.09561 acc 0.67568 roc_auc 0.94000 prc_auc 0.97659[0m
[92maverage training of epoch 8: loss -1.15094 acc 0.66225 roc_auc 0.86471 prc_auc 0.92474[0m
[93maverage test of epoch 8: loss -1.26039 acc 0.67568 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 9: loss -1.31394 acc 0.66225 roc_auc 0.86569 prc_auc 0.92572[0m
[93maverage test of epoch 9: loss -1.43398 acc 0.67568 roc_auc 0.94000 prc_auc 0.97574[0m
[92maverage training of epoch 10: loss -1.48428 acc 0.66225 roc_auc 0.87039 prc_auc 0.92967[0m
[93maverage test of epoch 10: loss -1.61122 acc 0.67568 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 11: loss -1.66220 acc 0.66225 roc_auc 0.87176 prc_auc 0.93098[0m
[93maverage test of epoch 11: loss -1.79716 acc 0.67568 roc_auc 0.94000 prc_auc 0.97659[0m
[92maverage training of epoch 12: loss -1.85341 acc 0.66225 roc_auc 0.87235 prc_auc 0.93228[0m
[93maverage test of epoch 12: loss -1.99758 acc 0.67568 roc_auc 0.93667 prc_auc 0.97575[0m
[92maverage training of epoch 13: loss -2.05737 acc 0.66225 roc_auc 0.87196 prc_auc 0.93236[0m
[93maverage test of epoch 13: loss -2.20243 acc 0.67568 roc_auc 0.93667 prc_auc 0.97575[0m
[92maverage training of epoch 14: loss -2.26460 acc 0.72848 roc_auc 0.87627 prc_auc 0.93503[0m
[93maverage test of epoch 14: loss -2.39995 acc 0.83784 roc_auc 0.93333 prc_auc 0.97496[0m
[92maverage training of epoch 15: loss -2.46348 acc 0.82119 roc_auc 0.87863 prc_auc 0.93612[0m
[93maverage test of epoch 15: loss -2.58571 acc 0.83784 roc_auc 0.93000 prc_auc 0.97420[0m
[92maverage training of epoch 16: loss -2.64701 acc 0.82781 roc_auc 0.88020 prc_auc 0.93668[0m
[93maverage test of epoch 16: loss -2.75830 acc 0.83784 roc_auc 0.93000 prc_auc 0.97420[0m
[92maverage training of epoch 17: loss -2.81465 acc 0.83444 roc_auc 0.87804 prc_auc 0.93575[0m
[93maverage test of epoch 17: loss -2.91545 acc 0.83784 roc_auc 0.94000 prc_auc 0.97659[0m
[92maverage training of epoch 18: loss -2.96542 acc 0.83444 roc_auc 0.87216 prc_auc 0.93302[0m
[93maverage test of epoch 18: loss -3.05664 acc 0.83784 roc_auc 0.94000 prc_auc 0.97659[0m
[92maverage training of epoch 19: loss -3.10025 acc 0.82781 roc_auc 0.87059 prc_auc 0.93183[0m
[93maverage test of epoch 19: loss -3.18613 acc 0.83784 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 20: loss -3.22387 acc 0.82781 roc_auc 0.86961 prc_auc 0.93104[0m
[93maverage test of epoch 20: loss -3.30801 acc 0.83784 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 21: loss -3.34098 acc 0.83444 roc_auc 0.86843 prc_auc 0.92999[0m
[93maverage test of epoch 21: loss -3.42457 acc 0.83784 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 22: loss -3.45451 acc 0.83444 roc_auc 0.86784 prc_auc 0.92904[0m
[93maverage test of epoch 22: loss -3.53712 acc 0.83784 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 23: loss -3.56547 acc 0.83444 roc_auc 0.86784 prc_auc 0.92871[0m
[93maverage test of epoch 23: loss -3.64648 acc 0.83784 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 24: loss -3.67356 acc 0.83444 roc_auc 0.86725 prc_auc 0.92801[0m
[93maverage test of epoch 24: loss -3.75342 acc 0.83784 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 25: loss -3.77863 acc 0.83444 roc_auc 0.86490 prc_auc 0.92573[0m
[93maverage test of epoch 25: loss -3.85873 acc 0.83784 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 26: loss -3.88186 acc 0.83444 roc_auc 0.86353 prc_auc 0.92442[0m
[93maverage test of epoch 26: loss -3.96292 acc 0.83784 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 27: loss -3.98417 acc 0.83444 roc_auc 0.86078 prc_auc 0.92233[0m
[93maverage test of epoch 27: loss -4.06619 acc 0.83784 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 28: loss -4.08576 acc 0.83444 roc_auc 0.85922 prc_auc 0.92115[0m
[93maverage test of epoch 28: loss -4.16879 acc 0.83784 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 29: loss -4.18667 acc 0.83444 roc_auc 0.85725 prc_auc 0.91895[0m
[93maverage test of epoch 29: loss -4.27091 acc 0.83784 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 30: loss -4.28699 acc 0.83444 roc_auc 0.85451 prc_auc 0.91404[0m
[93maverage test of epoch 30: loss -4.37265 acc 0.83784 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 31: loss -4.38700 acc 0.83444 roc_auc 0.85294 prc_auc 0.91107[0m
[93maverage test of epoch 31: loss -4.47414 acc 0.83784 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 32: loss -4.48635 acc 0.83444 roc_auc 0.85039 prc_auc 0.90870[0m
[93maverage test of epoch 32: loss -4.57528 acc 0.83784 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 33: loss -4.58505 acc 0.83444 roc_auc 0.84578 prc_auc 0.90259[0m
[93maverage test of epoch 33: loss -4.67597 acc 0.83784 roc_auc 0.94000 prc_auc 0.97659[0m
[92maverage training of epoch 34: loss -4.68347 acc 0.83444 roc_auc 0.84255 prc_auc 0.89905[0m
[93maverage test of epoch 34: loss -4.77628 acc 0.83784 roc_auc 0.94000 prc_auc 0.97659[0m
[92maverage training of epoch 35: loss -4.78115 acc 0.83444 roc_auc 0.83931 prc_auc 0.89543[0m
[93maverage test of epoch 35: loss -4.87599 acc 0.83784 roc_auc 0.94333 prc_auc 0.97777[0m
[92maverage training of epoch 36: loss -4.87863 acc 0.83444 roc_auc 0.83431 prc_auc 0.89112[0m
[93maverage test of epoch 36: loss -4.97533 acc 0.83784 roc_auc 0.94333 prc_auc 0.97777[0m
[92maverage training of epoch 37: loss -4.97388 acc 0.83444 roc_auc 0.83176 prc_auc 0.88685[0m
[93maverage test of epoch 37: loss -5.07323 acc 0.83784 roc_auc 0.94333 prc_auc 0.97777[0m
[92maverage training of epoch 38: loss -5.07080 acc 0.83444 roc_auc 0.82275 prc_auc 0.87831[0m
[93maverage test of epoch 38: loss -5.17105 acc 0.83784 roc_auc 0.94000 prc_auc 0.97693[0m
[92maverage training of epoch 39: loss -5.14361 acc 0.82781 roc_auc 0.82049 prc_auc 0.87614[0m
[93maverage test of epoch 39: loss -5.26777 acc 0.83784 roc_auc 0.94000 prc_auc 0.97693[0m
[92maverage training of epoch 40: loss -5.23913 acc 0.82781 roc_auc 0.81520 prc_auc 0.87078[0m
[93maverage test of epoch 40: loss -5.36358 acc 0.83784 roc_auc 0.94000 prc_auc 0.97693[0m
[92maverage training of epoch 41: loss -5.33012 acc 0.82781 roc_auc 0.81020 prc_auc 0.86461[0m
[93maverage test of epoch 41: loss -5.45876 acc 0.83784 roc_auc 0.94000 prc_auc 0.97693[0m
[92maverage training of epoch 42: loss -5.42200 acc 0.82781 roc_auc 0.80304 prc_auc 0.85968[0m
[93maverage test of epoch 42: loss -5.55378 acc 0.83784 roc_auc 0.94000 prc_auc 0.97693[0m
[92maverage training of epoch 43: loss -5.49201 acc 0.82119 roc_auc 0.80549 prc_auc 0.85979[0m
[93maverage test of epoch 43: loss -5.64781 acc 0.83784 roc_auc 0.94000 prc_auc 0.97693[0m
[92maverage training of epoch 44: loss -5.60569 acc 0.82781 roc_auc 0.79353 prc_auc 0.84892[0m
[93maverage test of epoch 44: loss -5.74165 acc 0.83784 roc_auc 0.94000 prc_auc 0.97693[0m
[92maverage training of epoch 45: loss -5.70203 acc 0.82781 roc_auc 0.79676 prc_auc 0.85129[0m
[93maverage test of epoch 45: loss -5.83574 acc 0.83784 roc_auc 0.94000 prc_auc 0.97693[0m
[92maverage training of epoch 46: loss -5.78989 acc 0.82781 roc_auc 0.78804 prc_auc 0.84433[0m
[93maverage test of epoch 46: loss -5.92925 acc 0.83784 roc_auc 0.93667 prc_auc 0.97614[0m
[92maverage training of epoch 47: loss -5.88551 acc 0.82781 roc_auc 0.79294 prc_auc 0.84741[0m
[93maverage test of epoch 47: loss -6.02290 acc 0.83784 roc_auc 0.94000 prc_auc 0.97693[0m
[92maverage training of epoch 48: loss -5.96977 acc 0.82781 roc_auc 0.78431 prc_auc 0.84037[0m
[93maverage test of epoch 48: loss -6.11626 acc 0.83784 roc_auc 0.93333 prc_auc 0.97539[0m
[92maverage training of epoch 49: loss -6.06845 acc 0.82781 roc_auc 0.78696 prc_auc 0.84241[0m
[93maverage test of epoch 49: loss -6.20975 acc 0.83784 roc_auc 0.94000 prc_auc 0.97693[0m
[92maverage training of epoch 50: loss -6.12480 acc 0.82119 roc_auc 0.77990 prc_auc 0.83627[0m
[93maverage test of epoch 50: loss -6.30195 acc 0.83784 roc_auc 0.93333 prc_auc 0.97539[0m
[92maverage training of epoch 51: loss -6.24993 acc 0.82781 roc_auc 0.78059 prc_auc 0.83628[0m
[93maverage test of epoch 51: loss -6.39496 acc 0.83784 roc_auc 0.93667 prc_auc 0.97614[0m
[92maverage training of epoch 52: loss -6.31580 acc 0.82781 roc_auc 0.77490 prc_auc 0.83194[0m
[93maverage test of epoch 52: loss -6.48689 acc 0.83784 roc_auc 0.93667 prc_auc 0.97614[0m
[92maverage training of epoch 53: loss -6.43040 acc 0.82781 roc_auc 0.77941 prc_auc 0.83505[0m
[93maverage test of epoch 53: loss -6.57881 acc 0.83784 roc_auc 0.93333 prc_auc 0.97539[0m
[92maverage training of epoch 54: loss -6.52021 acc 0.82781 roc_auc 0.77510 prc_auc 0.83022[0m
[93maverage test of epoch 54: loss -6.67088 acc 0.83784 roc_auc 0.93333 prc_auc 0.97539[0m
[92maverage training of epoch 55: loss -6.61026 acc 0.82781 roc_auc 0.77686 prc_auc 0.83198[0m
[93maverage test of epoch 55: loss -6.76257 acc 0.83784 roc_auc 0.93333 prc_auc 0.97539[0m
[92maverage training of epoch 56: loss -6.69990 acc 0.82781 roc_auc 0.77216 prc_auc 0.82597[0m
[93maverage test of epoch 56: loss -6.85423 acc 0.83784 roc_auc 0.93333 prc_auc 0.97539[0m
[92maverage training of epoch 57: loss -6.78955 acc 0.82781 roc_auc 0.77186 prc_auc 0.82570[0m
[93maverage test of epoch 57: loss -6.94578 acc 0.83784 roc_auc 0.93333 prc_auc 0.97539[0m
[92maverage training of epoch 58: loss -6.87905 acc 0.82781 roc_auc 0.76990 prc_auc 0.82331[0m
[93maverage test of epoch 58: loss -7.03724 acc 0.83784 roc_auc 0.93333 prc_auc 0.97539[0m
[92maverage training of epoch 59: loss -6.96845 acc 0.82781 roc_auc 0.76843 prc_auc 0.82206[0m
[93maverage test of epoch 59: loss -7.12856 acc 0.83784 roc_auc 0.93333 prc_auc 0.97539[0m
[92maverage training of epoch 60: loss -7.05771 acc 0.82781 roc_auc 0.76765 prc_auc 0.82047[0m
[93maverage test of epoch 60: loss -7.21974 acc 0.83784 roc_auc 0.93333 prc_auc 0.97539[0m
[92maverage training of epoch 61: loss -7.14681 acc 0.82781 roc_auc 0.76618 prc_auc 0.82002[0m
[93maverage test of epoch 61: loss -7.31075 acc 0.83784 roc_auc 0.93333 prc_auc 0.97539[0m
[92maverage training of epoch 62: loss -7.23574 acc 0.82781 roc_auc 0.76363 prc_auc 0.81921[0m
[93maverage test of epoch 62: loss -7.40156 acc 0.83784 roc_auc 0.93667 prc_auc 0.97614[0m
[92maverage training of epoch 63: loss -7.32446 acc 0.82781 roc_auc 0.76167 prc_auc 0.81834[0m
[93maverage test of epoch 63: loss -7.49218 acc 0.83784 roc_auc 0.93667 prc_auc 0.97614[0m
[92maverage training of epoch 64: loss -7.41298 acc 0.82781 roc_auc 0.76000 prc_auc 0.81657[0m
[93maverage test of epoch 64: loss -7.58258 acc 0.83784 roc_auc 0.93667 prc_auc 0.97614[0m
[92maverage training of epoch 65: loss -7.50128 acc 0.82781 roc_auc 0.75814 prc_auc 0.81311[0m
[93maverage test of epoch 65: loss -7.67275 acc 0.83784 roc_auc 0.93667 prc_auc 0.97635[0m
[92maverage training of epoch 66: loss -7.58935 acc 0.82781 roc_auc 0.75667 prc_auc 0.81233[0m
[93maverage test of epoch 66: loss -7.76268 acc 0.83784 roc_auc 0.93667 prc_auc 0.97614[0m
[92maverage training of epoch 67: loss -7.67718 acc 0.82781 roc_auc 0.75549 prc_auc 0.81191[0m
[93maverage test of epoch 67: loss -7.85236 acc 0.83784 roc_auc 0.93667 prc_auc 0.97635[0m
[92maverage training of epoch 68: loss -7.76480 acc 0.82781 roc_auc 0.75490 prc_auc 0.81169[0m
[93maverage test of epoch 68: loss -7.94181 acc 0.83784 roc_auc 0.93667 prc_auc 0.97635[0m
[92maverage training of epoch 69: loss -7.82307 acc 0.82119 roc_auc 0.74824 prc_auc 0.81025[0m
[93maverage test of epoch 69: loss -8.03083 acc 0.83784 roc_auc 0.93667 prc_auc 0.97635[0m
[92maverage training of epoch 70: loss -7.85138 acc 0.80795 roc_auc 0.72294 prc_auc 0.79547[0m
[93maverage test of epoch 70: loss -8.11926 acc 0.83784 roc_auc 0.93667 prc_auc 0.97635[0m
[92maverage training of epoch 71: loss -7.83009 acc 0.78808 roc_auc 0.69676 prc_auc 0.77946[0m
[93maverage test of epoch 71: loss -8.20658 acc 0.83784 roc_auc 0.93333 prc_auc 0.97398[0m
[92maverage training of epoch 72: loss -7.94383 acc 0.79470 roc_auc 0.70500 prc_auc 0.78354[0m
[93maverage test of epoch 72: loss -8.29370 acc 0.83784 roc_auc 0.93667 prc_auc 0.97635[0m
[92maverage training of epoch 73: loss -8.11631 acc 0.81457 roc_auc 0.75441 prc_auc 0.81960[0m
[93maverage test of epoch 73: loss -8.38051 acc 0.83784 roc_auc 0.93333 prc_auc 0.97440[0m
[92maverage training of epoch 74: loss -8.30876 acc 0.83444 roc_auc 0.75618 prc_auc 0.81194[0m
[93maverage test of epoch 74: loss -8.46716 acc 0.83784 roc_auc 0.94000 prc_auc 0.97693[0m
[92maverage training of epoch 75: loss -8.36449 acc 0.82781 roc_auc 0.76078 prc_auc 0.81487[0m
[93maverage test of epoch 75: loss -8.55393 acc 0.83784 roc_auc 0.94500 prc_auc 0.97693[0m
[92maverage training of epoch 76: loss -8.44933 acc 0.82781 roc_auc 0.75902 prc_auc 0.81338[0m
[93maverage test of epoch 76: loss -8.64064 acc 0.83784 roc_auc 0.94000 prc_auc 0.97693[0m
[92maverage training of epoch 77: loss -8.53410 acc 0.82781 roc_auc 0.75745 prc_auc 0.81251[0m
[93maverage test of epoch 77: loss -8.72726 acc 0.83784 roc_auc 0.94000 prc_auc 0.97714[0m
[92maverage training of epoch 78: loss -8.61878 acc 0.82781 roc_auc 0.75676 prc_auc 0.81249[0m
[93maverage test of epoch 78: loss -8.81380 acc 0.83784 roc_auc 0.94000 prc_auc 0.97714[0m
[92maverage training of epoch 79: loss -8.70338 acc 0.82781 roc_auc 0.75588 prc_auc 0.81311[0m
[93maverage test of epoch 79: loss -8.90025 acc 0.83784 roc_auc 0.94000 prc_auc 0.97714[0m
[92maverage training of epoch 80: loss -8.78788 acc 0.82781 roc_auc 0.75520 prc_auc 0.81202[0m
[93maverage test of epoch 80: loss -8.98660 acc 0.83784 roc_auc 0.94667 prc_auc 0.97714[0m
[92maverage training of epoch 81: loss -8.87228 acc 0.82781 roc_auc 0.75333 prc_auc 0.81064[0m
[93maverage test of epoch 81: loss -9.07285 acc 0.83784 roc_auc 0.94500 prc_auc 0.97575[0m
[92maverage training of epoch 82: loss -8.95656 acc 0.82781 roc_auc 0.75157 prc_auc 0.80835[0m
[93maverage test of epoch 82: loss -9.15898 acc 0.83784 roc_auc 0.94333 prc_auc 0.97019[0m
[92maverage training of epoch 83: loss -9.01007 acc 0.82119 roc_auc 0.74627 prc_auc 0.80505[0m
[93maverage test of epoch 83: loss -9.24487 acc 0.83784 roc_auc 0.94333 prc_auc 0.97019[0m
[92maverage training of epoch 84: loss -8.92571 acc 0.80795 roc_auc 0.75451 prc_auc 0.80818[0m
[93maverage test of epoch 84: loss -9.32780 acc 0.83784 roc_auc 0.93000 prc_auc 0.96862[0m
[92maverage training of epoch 85: loss -9.20580 acc 0.82781 roc_auc 0.75196 prc_auc 0.80164[0m
[93maverage test of epoch 85: loss -9.41338 acc 0.83784 roc_auc 0.93667 prc_auc 0.96323[0m
[92maverage training of epoch 86: loss -9.28946 acc 0.82781 roc_auc 0.75069 prc_auc 0.80310[0m
[93maverage test of epoch 86: loss -9.49888 acc 0.83784 roc_auc 0.95333 prc_auc 0.97714[0m
[92maverage training of epoch 87: loss -9.37305 acc 0.82781 roc_auc 0.75098 prc_auc 0.80898[0m
[93maverage test of epoch 87: loss -9.58430 acc 0.83784 roc_auc 0.95333 prc_auc 0.97714[0m
[92maverage training of epoch 88: loss -9.45654 acc 0.82781 roc_auc 0.74882 prc_auc 0.79644[0m
[93maverage test of epoch 88: loss -9.66965 acc 0.83784 roc_auc 0.92833 prc_auc 0.95565[0m
[92maverage training of epoch 89: loss -9.53997 acc 0.82781 roc_auc 0.75029 prc_auc 0.80585[0m
[93maverage test of epoch 89: loss -9.75492 acc 0.83784 roc_auc 0.95000 prc_auc 0.97478[0m
[92maverage training of epoch 90: loss -9.62332 acc 0.82781 roc_auc 0.75010 prc_auc 0.80065[0m
[93maverage test of epoch 90: loss -9.84011 acc 0.83784 roc_auc 0.90000 prc_auc 0.93143[0m
[92maverage training of epoch 91: loss -9.70659 acc 0.82781 roc_auc 0.74843 prc_auc 0.80461[0m
[93maverage test of epoch 91: loss -9.92522 acc 0.83784 roc_auc 0.91000 prc_auc 0.93652[0m
[92maverage training of epoch 92: loss -9.75802 acc 0.82119 roc_auc 0.74245 prc_auc 0.80395[0m
[93maverage test of epoch 92: loss -10.01012 acc 0.83784 roc_auc 0.95333 prc_auc 0.97562[0m
[92maverage training of epoch 93: loss -9.82318 acc 0.82781 roc_auc 0.75324 prc_auc 0.79614[0m
[93maverage test of epoch 93: loss -10.09376 acc 0.83784 roc_auc 0.87167 prc_auc 0.91056[0m
[92maverage training of epoch 94: loss -9.60407 acc 0.80795 roc_auc 0.79549 prc_auc 0.83404[0m
[93maverage test of epoch 94: loss -10.17290 acc 0.83784 roc_auc 0.93333 prc_auc 0.96212[0m
[92maverage training of epoch 95: loss -10.03206 acc 0.83444 roc_auc 0.75049 prc_auc 0.79585[0m
[93maverage test of epoch 95: loss -10.25643 acc 0.83784 roc_auc 0.89167 prc_auc 0.92650[0m
[92maverage training of epoch 96: loss -10.11371 acc 0.82781 roc_auc 0.74667 prc_auc 0.79177[0m
[93maverage test of epoch 96: loss -10.34043 acc 0.83784 roc_auc 0.76667 prc_auc 0.82305[0m
[92maverage training of epoch 97: loss -10.13047 acc 0.82119 roc_auc 0.75176 prc_auc 0.79977[0m
[93maverage test of epoch 97: loss -10.42378 acc 0.83784 roc_auc 0.87667 prc_auc 0.91271[0m
[92maverage training of epoch 98: loss -10.24394 acc 0.82781 roc_auc 0.75412 prc_auc 0.80044[0m
[93maverage test of epoch 98: loss -10.50723 acc 0.83784 roc_auc 0.91000 prc_auc 0.93652[0m
[92maverage training of epoch 99: loss -10.35612 acc 0.83444 roc_auc 0.75314 prc_auc 0.79658[0m
[93maverage test of epoch 99: loss -10.59078 acc 0.83784 roc_auc 0.76667 prc_auc 0.82305[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.0001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.69744 ROC_AUC (avg): 0.63979 PRC_AUC (avg): 0.75923 

Average forward propagation time taken(ms): 2.471424609649244
Average backward propagation time taken(ms): 0.8707116771118492

