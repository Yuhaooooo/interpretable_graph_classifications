# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.0001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-21-38-09/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-21-38-09/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 16,
 'epochs': 50,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 4,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.0001,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 2,
 'num_workers': 8,
 'number_of_mlp_layer': 0,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-17-21-38-09',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 50, 'learning_rate': 0.0001, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss 0.59812 acc 0.66667 roc_auc 0.43800 prc_auc 0.64402[0m
[93maverage test of epoch 0: loss 0.52005 acc 0.65789 roc_auc 0.62154 prc_auc 0.77261[0m
[92maverage training of epoch 1: loss 0.43190 acc 0.66667 roc_auc 0.48640 prc_auc 0.68572[0m
[93maverage test of epoch 1: loss 0.35553 acc 0.65789 roc_auc 0.66462 prc_auc 0.79829[0m
[92maverage training of epoch 2: loss 0.27202 acc 0.66667 roc_auc 0.45760 prc_auc 0.68884[0m
[93maverage test of epoch 2: loss 0.19358 acc 0.65789 roc_auc 0.67385 prc_auc 0.82352[0m
[92maverage training of epoch 3: loss 0.12922 acc 0.66667 roc_auc 0.52640 prc_auc 0.71953[0m
[93maverage test of epoch 3: loss 0.06923 acc 0.65789 roc_auc 0.71692 prc_auc 0.87345[0m
[92maverage training of epoch 4: loss -0.01045 acc 0.66667 roc_auc 0.53000 prc_auc 0.72297[0m
[93maverage test of epoch 4: loss -0.06605 acc 0.65789 roc_auc 0.62769 prc_auc 0.81440[0m
[92maverage training of epoch 5: loss -0.14412 acc 0.66667 roc_auc 0.52600 prc_auc 0.73402[0m
[93maverage test of epoch 5: loss -0.19567 acc 0.65789 roc_auc 0.53231 prc_auc 0.75327[0m
[92maverage training of epoch 6: loss -0.27123 acc 0.66667 roc_auc 0.52740 prc_auc 0.69574[0m
[93maverage test of epoch 6: loss -0.33900 acc 0.65789 roc_auc 0.60923 prc_auc 0.79653[0m
[92maverage training of epoch 7: loss -0.42223 acc 0.66667 roc_auc 0.47880 prc_auc 0.67925[0m
[93maverage test of epoch 7: loss -0.51354 acc 0.65789 roc_auc 0.50769 prc_auc 0.71870[0m
[92maverage training of epoch 8: loss -0.60677 acc 0.66667 roc_auc 0.52220 prc_auc 0.71440[0m
[93maverage test of epoch 8: loss -0.70116 acc 0.65789 roc_auc 0.64923 prc_auc 0.79333[0m
[92maverage training of epoch 9: loss -0.78905 acc 0.66667 roc_auc 0.50580 prc_auc 0.67985[0m
[93maverage test of epoch 9: loss -0.88062 acc 0.65789 roc_auc 0.57538 prc_auc 0.74395[0m
[92maverage training of epoch 10: loss -0.97016 acc 0.66667 roc_auc 0.51140 prc_auc 0.67992[0m
[93maverage test of epoch 10: loss -1.05027 acc 0.65789 roc_auc 0.72308 prc_auc 0.86304[0m
[92maverage training of epoch 11: loss -1.12184 acc 0.66667 roc_auc 0.45080 prc_auc 0.65594[0m
[93maverage test of epoch 11: loss -1.24633 acc 0.65789 roc_auc 0.68615 prc_auc 0.80958[0m
[92maverage training of epoch 12: loss -1.28245 acc 0.66667 roc_auc 0.51620 prc_auc 0.71370[0m
[93maverage test of epoch 12: loss -1.35444 acc 0.65789 roc_auc 0.55385 prc_auc 0.73434[0m
[92maverage training of epoch 13: loss -1.43692 acc 0.66667 roc_auc 0.43380 prc_auc 0.61919[0m
[93maverage test of epoch 13: loss -1.53072 acc 0.65789 roc_auc 0.53538 prc_auc 0.75152[0m
[92maverage training of epoch 14: loss -1.59748 acc 0.66667 roc_auc 0.56380 prc_auc 0.70535[0m
[93maverage test of epoch 14: loss -1.62068 acc 0.65789 roc_auc 0.38462 prc_auc 0.59435[0m
[92maverage training of epoch 15: loss -1.74297 acc 0.66667 roc_auc 0.51940 prc_auc 0.65868[0m
[93maverage test of epoch 15: loss -1.80322 acc 0.65789 roc_auc 0.35692 prc_auc 0.59339[0m
[92maverage training of epoch 16: loss -1.87676 acc 0.66667 roc_auc 0.51200 prc_auc 0.69717[0m
[93maverage test of epoch 16: loss -1.91591 acc 0.65789 roc_auc 0.69538 prc_auc 0.84704[0m
[92maverage training of epoch 17: loss -2.00689 acc 0.66667 roc_auc 0.51940 prc_auc 0.69636[0m
[93maverage test of epoch 17: loss -2.02186 acc 0.65789 roc_auc 0.56308 prc_auc 0.69589[0m
[92maverage training of epoch 18: loss -2.10925 acc 0.66667 roc_auc 0.45720 prc_auc 0.64085[0m
[93maverage test of epoch 18: loss -2.13470 acc 0.65789 roc_auc 0.54154 prc_auc 0.71414[0m
[92maverage training of epoch 19: loss -2.19100 acc 0.66667 roc_auc 0.43560 prc_auc 0.63022[0m
[93maverage test of epoch 19: loss -2.23611 acc 0.65789 roc_auc 0.56308 prc_auc 0.74233[0m
[92maverage training of epoch 20: loss -2.31480 acc 0.66667 roc_auc 0.57940 prc_auc 0.74675[0m
[93maverage test of epoch 20: loss -2.32992 acc 0.65789 roc_auc 0.50154 prc_auc 0.73341[0m
[92maverage training of epoch 21: loss -2.38500 acc 0.66667 roc_auc 0.42100 prc_auc 0.65486[0m
[93maverage test of epoch 21: loss -2.40940 acc 0.65789 roc_auc 0.52000 prc_auc 0.70948[0m
[92maverage training of epoch 22: loss -2.45845 acc 0.66667 roc_auc 0.46870 prc_auc 0.64389[0m
[93maverage test of epoch 22: loss -2.47980 acc 0.65789 roc_auc 0.49231 prc_auc 0.69555[0m
[92maverage training of epoch 23: loss -2.54454 acc 0.66667 roc_auc 0.50740 prc_auc 0.68404[0m
[93maverage test of epoch 23: loss -2.54869 acc 0.65789 roc_auc 0.39692 prc_auc 0.64151[0m
[92maverage training of epoch 24: loss -2.61152 acc 0.66667 roc_auc 0.47580 prc_auc 0.63088[0m
[93maverage test of epoch 24: loss -2.62795 acc 0.65789 roc_auc 0.50769 prc_auc 0.65928[0m
[92maverage training of epoch 25: loss -2.68641 acc 0.66667 roc_auc 0.50540 prc_auc 0.65281[0m
[93maverage test of epoch 25: loss -2.68022 acc 0.65789 roc_auc 0.52615 prc_auc 0.73082[0m
[92maverage training of epoch 26: loss -2.73834 acc 0.66667 roc_auc 0.43160 prc_auc 0.61216[0m
[93maverage test of epoch 26: loss -2.75217 acc 0.65789 roc_auc 0.45231 prc_auc 0.63693[0m
[92maverage training of epoch 27: loss -2.81991 acc 0.66667 roc_auc 0.47820 prc_auc 0.64310[0m
[93maverage test of epoch 27: loss -2.81810 acc 0.65789 roc_auc 0.47385 prc_auc 0.65849[0m
[92maverage training of epoch 28: loss -2.88598 acc 0.66667 roc_auc 0.51840 prc_auc 0.64341[0m
[93maverage test of epoch 28: loss -2.88096 acc 0.65789 roc_auc 0.36308 prc_auc 0.58109[0m
[92maverage training of epoch 29: loss -2.94665 acc 0.66667 roc_auc 0.51640 prc_auc 0.69356[0m
[93maverage test of epoch 29: loss -2.94670 acc 0.65789 roc_auc 0.43077 prc_auc 0.67722[0m
[92maverage training of epoch 30: loss -3.00530 acc 0.66667 roc_auc 0.51020 prc_auc 0.67670[0m
[93maverage test of epoch 30: loss -3.03648 acc 0.65789 roc_auc 0.71385 prc_auc 0.79590[0m
[92maverage training of epoch 31: loss -3.06341 acc 0.66667 roc_auc 0.44820 prc_auc 0.65459[0m
[93maverage test of epoch 31: loss -3.07921 acc 0.65789 roc_auc 0.56615 prc_auc 0.70082[0m
[92maverage training of epoch 32: loss -3.13599 acc 0.66667 roc_auc 0.53640 prc_auc 0.71024[0m
[93maverage test of epoch 32: loss -3.13200 acc 0.65789 roc_auc 0.50462 prc_auc 0.70479[0m
[92maverage training of epoch 33: loss -3.19703 acc 0.66667 roc_auc 0.52940 prc_auc 0.67267[0m
[93maverage test of epoch 33: loss -3.18508 acc 0.65789 roc_auc 0.54154 prc_auc 0.69496[0m
[92maverage training of epoch 34: loss -3.25279 acc 0.66667 roc_auc 0.47080 prc_auc 0.65571[0m
[93maverage test of epoch 34: loss -3.26332 acc 0.65789 roc_auc 0.45846 prc_auc 0.62162[0m
[92maverage training of epoch 35: loss -3.30766 acc 0.66667 roc_auc 0.45140 prc_auc 0.64945[0m
[93maverage test of epoch 35: loss -3.30427 acc 0.65789 roc_auc 0.32615 prc_auc 0.59598[0m
[92maverage training of epoch 36: loss -3.37986 acc 0.66667 roc_auc 0.51640 prc_auc 0.65975[0m
[93maverage test of epoch 36: loss -3.36549 acc 0.65789 roc_auc 0.55385 prc_auc 0.74186[0m
[92maverage training of epoch 37: loss -3.43702 acc 0.66667 roc_auc 0.53520 prc_auc 0.68609[0m
[93maverage test of epoch 37: loss -3.44577 acc 0.65789 roc_auc 0.65231 prc_auc 0.81701[0m
[92maverage training of epoch 38: loss -3.49895 acc 0.66667 roc_auc 0.42720 prc_auc 0.61138[0m
[93maverage test of epoch 38: loss -3.47860 acc 0.65789 roc_auc 0.39385 prc_auc 0.65141[0m
[92maverage training of epoch 39: loss -3.56127 acc 0.66667 roc_auc 0.51950 prc_auc 0.65708[0m
[93maverage test of epoch 39: loss -3.54432 acc 0.65789 roc_auc 0.39385 prc_auc 0.64303[0m
[92maverage training of epoch 40: loss -3.61781 acc 0.66667 roc_auc 0.54740 prc_auc 0.69278[0m
[93maverage test of epoch 40: loss -3.61604 acc 0.65789 roc_auc 0.58154 prc_auc 0.74794[0m
[92maverage training of epoch 41: loss -3.68040 acc 0.66667 roc_auc 0.50990 prc_auc 0.66081[0m
[93maverage test of epoch 41: loss -3.66828 acc 0.65789 roc_auc 0.63077 prc_auc 0.81057[0m
[92maverage training of epoch 42: loss -3.73592 acc 0.66667 roc_auc 0.43070 prc_auc 0.64053[0m
[93maverage test of epoch 42: loss -3.73633 acc 0.65789 roc_auc 0.52615 prc_auc 0.71330[0m
[92maverage training of epoch 43: loss -3.79442 acc 0.66667 roc_auc 0.46510 prc_auc 0.63913[0m
[93maverage test of epoch 43: loss -3.80319 acc 0.65789 roc_auc 0.68308 prc_auc 0.79195[0m
[92maverage training of epoch 44: loss -3.85605 acc 0.66667 roc_auc 0.42320 prc_auc 0.59551[0m
[93maverage test of epoch 44: loss -3.85595 acc 0.65789 roc_auc 0.49846 prc_auc 0.70598[0m
[92maverage training of epoch 45: loss -3.91712 acc 0.66667 roc_auc 0.46020 prc_auc 0.63800[0m
[93maverage test of epoch 45: loss -3.90755 acc 0.65789 roc_auc 0.38462 prc_auc 0.57433[0m
[92maverage training of epoch 46: loss -3.97484 acc 0.66667 roc_auc 0.48980 prc_auc 0.63695[0m
[93maverage test of epoch 46: loss -3.96228 acc 0.65789 roc_auc 0.45846 prc_auc 0.63966[0m
[92maverage training of epoch 47: loss -4.02944 acc 0.66667 roc_auc 0.58980 prc_auc 0.70408[0m
[93maverage test of epoch 47: loss -4.02352 acc 0.65789 roc_auc 0.28000 prc_auc 0.57228[0m
[92maverage training of epoch 48: loss -4.09037 acc 0.66667 roc_auc 0.40300 prc_auc 0.61369[0m
[93maverage test of epoch 48: loss -4.08195 acc 0.65789 roc_auc 0.37538 prc_auc 0.64957[0m
[92maverage training of epoch 49: loss -4.14574 acc 0.66667 roc_auc 0.44290 prc_auc 0.62303[0m
[93maverage test of epoch 49: loss -4.14786 acc 0.65789 roc_auc 0.51077 prc_auc 0.73225[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss 1.12083 acc 0.33333 roc_auc 0.48500 prc_auc 0.66465[0m
[93maverage test of epoch 0: loss 0.99990 acc 0.34211 roc_auc 0.60923 prc_auc 0.80068[0m
[92maverage training of epoch 1: loss 0.92067 acc 0.33333 roc_auc 0.52320 prc_auc 0.70931[0m
[93maverage test of epoch 1: loss 0.80160 acc 0.34211 roc_auc 0.52615 prc_auc 0.74797[0m
[92maverage training of epoch 2: loss 0.71363 acc 0.33333 roc_auc 0.50120 prc_auc 0.68278[0m
[93maverage test of epoch 2: loss 0.57833 acc 0.34211 roc_auc 0.56000 prc_auc 0.75529[0m
[92maverage training of epoch 3: loss 0.49630 acc 0.33333 roc_auc 0.47100 prc_auc 0.66567[0m
[93maverage test of epoch 3: loss 0.36102 acc 0.34211 roc_auc 0.45231 prc_auc 0.71968[0m
[92maverage training of epoch 4: loss 0.23911 acc 0.33333 roc_auc 0.58480 prc_auc 0.73893[0m
[93maverage test of epoch 4: loss 0.11781 acc 0.34211 roc_auc 0.44000 prc_auc 0.67815[0m
[92maverage training of epoch 5: loss -0.01521 acc 0.33333 roc_auc 0.54120 prc_auc 0.71519[0m
[93maverage test of epoch 5: loss -0.12529 acc 0.34211 roc_auc 0.34154 prc_auc 0.63548[0m
[92maverage training of epoch 6: loss -0.30025 acc 0.33333 roc_auc 0.53460 prc_auc 0.70291[0m
[93maverage test of epoch 6: loss -0.49433 acc 0.34211 roc_auc 0.71692 prc_auc 0.81600[0m
[92maverage training of epoch 7: loss -0.72572 acc 0.33333 roc_auc 0.55360 prc_auc 0.71530[0m
[93maverage test of epoch 7: loss -0.97533 acc 0.34211 roc_auc 0.56000 prc_auc 0.69061[0m
[92maverage training of epoch 8: loss -1.17796 acc 0.36667 roc_auc 0.54160 prc_auc 0.68377[0m
[93maverage test of epoch 8: loss -1.36383 acc 0.39474 roc_auc 0.45846 prc_auc 0.72375[0m
[92maverage training of epoch 9: loss -1.46835 acc 0.52667 roc_auc 0.47280 prc_auc 0.67359[0m
[93maverage test of epoch 9: loss -1.58944 acc 0.60526 roc_auc 0.42154 prc_auc 0.66851[0m
[92maverage training of epoch 10: loss -1.67549 acc 0.66000 roc_auc 0.51500 prc_auc 0.66516[0m
[93maverage test of epoch 10: loss -1.77124 acc 0.65789 roc_auc 0.58154 prc_auc 0.76293[0m
[92maverage training of epoch 11: loss -1.83485 acc 0.66667 roc_auc 0.51880 prc_auc 0.66709[0m
[93maverage test of epoch 11: loss -1.88514 acc 0.65789 roc_auc 0.35385 prc_auc 0.59037[0m
[92maverage training of epoch 12: loss -1.96787 acc 0.66667 roc_auc 0.46820 prc_auc 0.64237[0m
[93maverage test of epoch 12: loss -2.03554 acc 0.65789 roc_auc 0.53538 prc_auc 0.73922[0m
[92maverage training of epoch 13: loss -2.09017 acc 0.66667 roc_auc 0.55920 prc_auc 0.70762[0m
[93maverage test of epoch 13: loss -2.14059 acc 0.65789 roc_auc 0.48308 prc_auc 0.70183[0m
[92maverage training of epoch 14: loss -2.19945 acc 0.66667 roc_auc 0.51100 prc_auc 0.69400[0m
[93maverage test of epoch 14: loss -2.24821 acc 0.65789 roc_auc 0.56615 prc_auc 0.67047[0m
[92maverage training of epoch 15: loss -2.29900 acc 0.66667 roc_auc 0.55320 prc_auc 0.71952[0m
[93maverage test of epoch 15: loss -2.34961 acc 0.65789 roc_auc 0.75077 prc_auc 0.84576[0m
[92maverage training of epoch 16: loss -2.40420 acc 0.66667 roc_auc 0.47860 prc_auc 0.67779[0m
[93maverage test of epoch 16: loss -2.43451 acc 0.65789 roc_auc 0.50462 prc_auc 0.73923[0m
[92maverage training of epoch 17: loss -2.48066 acc 0.66667 roc_auc 0.45140 prc_auc 0.66097[0m
[93maverage test of epoch 17: loss -2.50276 acc 0.65789 roc_auc 0.36615 prc_auc 0.58410[0m
[92maverage training of epoch 18: loss -2.57854 acc 0.66667 roc_auc 0.54770 prc_auc 0.74792[0m
[93maverage test of epoch 18: loss -2.62417 acc 0.65789 roc_auc 0.67077 prc_auc 0.76100[0m
[92maverage training of epoch 19: loss -2.65684 acc 0.66667 roc_auc 0.44900 prc_auc 0.65854[0m
[93maverage test of epoch 19: loss -2.68975 acc 0.65789 roc_auc 0.54769 prc_auc 0.72650[0m
[92maverage training of epoch 20: loss -2.73904 acc 0.66667 roc_auc 0.50900 prc_auc 0.67820[0m
[93maverage test of epoch 20: loss -2.76039 acc 0.65789 roc_auc 0.70154 prc_auc 0.79283[0m
[92maverage training of epoch 21: loss -2.79749 acc 0.66667 roc_auc 0.40670 prc_auc 0.63574[0m
[93maverage test of epoch 21: loss -2.82649 acc 0.65789 roc_auc 0.49538 prc_auc 0.67248[0m
[92maverage training of epoch 22: loss -2.88151 acc 0.66667 roc_auc 0.46720 prc_auc 0.64216[0m
[93maverage test of epoch 22: loss -2.89354 acc 0.65789 roc_auc 0.40923 prc_auc 0.63832[0m
[92maverage training of epoch 23: loss -2.94865 acc 0.66667 roc_auc 0.48620 prc_auc 0.66555[0m
[93maverage test of epoch 23: loss -2.96580 acc 0.65789 roc_auc 0.19077 prc_auc 0.50443[0m
[92maverage training of epoch 24: loss -3.01510 acc 0.66667 roc_auc 0.58440 prc_auc 0.73234[0m
[93maverage test of epoch 24: loss -3.04683 acc 0.65789 roc_auc 0.54154 prc_auc 0.67977[0m
[92maverage training of epoch 25: loss -3.08200 acc 0.66667 roc_auc 0.48860 prc_auc 0.66289[0m
[93maverage test of epoch 25: loss -3.10284 acc 0.65789 roc_auc 0.50462 prc_auc 0.66360[0m
[92maverage training of epoch 26: loss -3.14533 acc 0.66667 roc_auc 0.54560 prc_auc 0.69434[0m
[93maverage test of epoch 26: loss -3.15955 acc 0.65789 roc_auc 0.36923 prc_auc 0.64602[0m
[92maverage training of epoch 27: loss -3.20231 acc 0.66667 roc_auc 0.40820 prc_auc 0.61162[0m
[93maverage test of epoch 27: loss -3.21745 acc 0.65789 roc_auc 0.37846 prc_auc 0.62661[0m
[92maverage training of epoch 28: loss -3.26773 acc 0.66667 roc_auc 0.54780 prc_auc 0.69879[0m
[93maverage test of epoch 28: loss -3.28734 acc 0.65789 roc_auc 0.44000 prc_auc 0.64524[0m
[92maverage training of epoch 29: loss -3.32909 acc 0.66667 roc_auc 0.55220 prc_auc 0.70566[0m
[93maverage test of epoch 29: loss -3.34834 acc 0.65789 roc_auc 0.46462 prc_auc 0.64924[0m
[92maverage training of epoch 30: loss -3.39077 acc 0.66667 roc_auc 0.52000 prc_auc 0.69236[0m
[93maverage test of epoch 30: loss -3.41609 acc 0.65789 roc_auc 0.53538 prc_auc 0.66157[0m
[92maverage training of epoch 31: loss -3.44501 acc 0.66667 roc_auc 0.45900 prc_auc 0.66643[0m
[93maverage test of epoch 31: loss -3.46061 acc 0.65789 roc_auc 0.45846 prc_auc 0.65280[0m
[92maverage training of epoch 32: loss -3.49980 acc 0.66667 roc_auc 0.44740 prc_auc 0.62408[0m
[93maverage test of epoch 32: loss -3.51615 acc 0.65789 roc_auc 0.42154 prc_auc 0.61674[0m
[92maverage training of epoch 33: loss -3.56435 acc 0.66667 roc_auc 0.47920 prc_auc 0.63751[0m
[93maverage test of epoch 33: loss -3.57931 acc 0.65789 roc_auc 0.54769 prc_auc 0.68459[0m
[92maverage training of epoch 34: loss -3.61711 acc 0.66667 roc_auc 0.46240 prc_auc 0.64445[0m
[93maverage test of epoch 34: loss -3.63281 acc 0.65789 roc_auc 0.49231 prc_auc 0.69607[0m
[92maverage training of epoch 35: loss -3.67482 acc 0.66667 roc_auc 0.52060 prc_auc 0.66437[0m
[93maverage test of epoch 35: loss -3.68966 acc 0.65789 roc_auc 0.51692 prc_auc 0.75039[0m
[92maverage training of epoch 36: loss -3.72909 acc 0.66667 roc_auc 0.42880 prc_auc 0.62632[0m
[93maverage test of epoch 36: loss -3.74949 acc 0.65789 roc_auc 0.57231 prc_auc 0.78626[0m
[92maverage training of epoch 37: loss -3.78653 acc 0.66667 roc_auc 0.43440 prc_auc 0.60746[0m
[93maverage test of epoch 37: loss -3.81233 acc 0.65789 roc_auc 0.70462 prc_auc 0.81256[0m
[92maverage training of epoch 38: loss -3.84745 acc 0.66667 roc_auc 0.49640 prc_auc 0.67034[0m
[93maverage test of epoch 38: loss -3.86800 acc 0.65789 roc_auc 0.39385 prc_auc 0.58452[0m
[92maverage training of epoch 39: loss -3.91235 acc 0.66667 roc_auc 0.52900 prc_auc 0.69171[0m
[93maverage test of epoch 39: loss -3.93450 acc 0.65789 roc_auc 0.48923 prc_auc 0.63143[0m
[92maverage training of epoch 40: loss -3.98176 acc 0.66667 roc_auc 0.50840 prc_auc 0.65366[0m
[93maverage test of epoch 40: loss -3.99302 acc 0.65789 roc_auc 0.52308 prc_auc 0.71924[0m
[92maverage training of epoch 41: loss -4.04887 acc 0.66667 roc_auc 0.47660 prc_auc 0.68231[0m
[93maverage test of epoch 41: loss -4.06281 acc 0.65789 roc_auc 0.48000 prc_auc 0.63229[0m
[92maverage training of epoch 42: loss -4.13035 acc 0.66667 roc_auc 0.49860 prc_auc 0.68962[0m
[93maverage test of epoch 42: loss -4.16357 acc 0.65789 roc_auc 0.59692 prc_auc 0.72845[0m
[92maverage training of epoch 43: loss -4.20179 acc 0.66667 roc_auc 0.43700 prc_auc 0.62952[0m
[93maverage test of epoch 43: loss -4.24724 acc 0.65789 roc_auc 0.61538 prc_auc 0.79787[0m
[92maverage training of epoch 44: loss -4.29177 acc 0.66667 roc_auc 0.51520 prc_auc 0.69122[0m
[93maverage test of epoch 44: loss -4.31126 acc 0.65789 roc_auc 0.57231 prc_auc 0.72931[0m
[92maverage training of epoch 45: loss -4.38271 acc 0.66667 roc_auc 0.42860 prc_auc 0.62496[0m
[93maverage test of epoch 45: loss -4.40391 acc 0.65789 roc_auc 0.40000 prc_auc 0.59653[0m
[92maverage training of epoch 46: loss -4.48802 acc 0.66667 roc_auc 0.50400 prc_auc 0.66474[0m
[93maverage test of epoch 46: loss -4.51244 acc 0.65789 roc_auc 0.45846 prc_auc 0.66785[0m
[92maverage training of epoch 47: loss -4.58292 acc 0.66667 roc_auc 0.51040 prc_auc 0.70575[0m
[93maverage test of epoch 47: loss -4.61600 acc 0.65789 roc_auc 0.44923 prc_auc 0.62903[0m
[92maverage training of epoch 48: loss -4.68436 acc 0.66667 roc_auc 0.53640 prc_auc 0.73020[0m
[93maverage test of epoch 48: loss -4.70458 acc 0.65789 roc_auc 0.63385 prc_auc 0.78457[0m
[92maverage training of epoch 49: loss -4.75825 acc 0.66667 roc_auc 0.43620 prc_auc 0.64366[0m
[93maverage test of epoch 49: loss -4.79147 acc 0.65789 roc_auc 0.65538 prc_auc 0.78516[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.36692 acc 0.50667 roc_auc 0.54040 prc_auc 0.70036[0m
[93maverage test of epoch 0: loss -0.48775 acc 0.71053 roc_auc 0.54154 prc_auc 0.71857[0m
[92maverage training of epoch 1: loss -0.58989 acc 0.63333 roc_auc 0.47440 prc_auc 0.65696[0m
[93maverage test of epoch 1: loss -0.66997 acc 0.65789 roc_auc 0.64308 prc_auc 0.79507[0m
[92maverage training of epoch 2: loss -0.80139 acc 0.66667 roc_auc 0.45200 prc_auc 0.65532[0m
[93maverage test of epoch 2: loss -0.86781 acc 0.65789 roc_auc 0.49231 prc_auc 0.72047[0m
[92maverage training of epoch 3: loss -0.97139 acc 0.66667 roc_auc 0.44900 prc_auc 0.63626[0m
[93maverage test of epoch 3: loss -1.08700 acc 0.65789 roc_auc 0.58462 prc_auc 0.71339[0m
[92maverage training of epoch 4: loss -1.18608 acc 0.66667 roc_auc 0.52240 prc_auc 0.67115[0m
[93maverage test of epoch 4: loss -1.27263 acc 0.65789 roc_auc 0.45231 prc_auc 0.64547[0m
[92maverage training of epoch 5: loss -1.38601 acc 0.66667 roc_auc 0.52700 prc_auc 0.67068[0m
[93maverage test of epoch 5: loss -1.50548 acc 0.65789 roc_auc 0.55077 prc_auc 0.69396[0m
[92maverage training of epoch 6: loss -1.59621 acc 0.66667 roc_auc 0.45500 prc_auc 0.66869[0m
[93maverage test of epoch 6: loss -1.66972 acc 0.65789 roc_auc 0.50462 prc_auc 0.71608[0m
[92maverage training of epoch 7: loss -1.80658 acc 0.66667 roc_auc 0.49360 prc_auc 0.68314[0m
[93maverage test of epoch 7: loss -1.88566 acc 0.65789 roc_auc 0.52923 prc_auc 0.75676[0m
[92maverage training of epoch 8: loss -2.01803 acc 0.66667 roc_auc 0.52340 prc_auc 0.70393[0m
[93maverage test of epoch 8: loss -2.10168 acc 0.65789 roc_auc 0.42462 prc_auc 0.62052[0m
[92maverage training of epoch 9: loss -2.22593 acc 0.66667 roc_auc 0.53100 prc_auc 0.67904[0m
[93maverage test of epoch 9: loss -2.30801 acc 0.65789 roc_auc 0.39692 prc_auc 0.65025[0m
[92maverage training of epoch 10: loss -2.47250 acc 0.66667 roc_auc 0.47100 prc_auc 0.65659[0m
[93maverage test of epoch 10: loss -2.57191 acc 0.65789 roc_auc 0.50769 prc_auc 0.73280[0m
[92maverage training of epoch 11: loss -2.71188 acc 0.66667 roc_auc 0.47620 prc_auc 0.64370[0m
[93maverage test of epoch 11: loss -2.81581 acc 0.65789 roc_auc 0.53846 prc_auc 0.67584[0m
[92maverage training of epoch 12: loss -2.94527 acc 0.66667 roc_auc 0.51220 prc_auc 0.68442[0m
[93maverage test of epoch 12: loss -3.04219 acc 0.65789 roc_auc 0.69846 prc_auc 0.81201[0m
[92maverage training of epoch 13: loss -3.12635 acc 0.66667 roc_auc 0.48820 prc_auc 0.66960[0m
[93maverage test of epoch 13: loss -3.17317 acc 0.65789 roc_auc 0.49846 prc_auc 0.68429[0m
[92maverage training of epoch 14: loss -3.26349 acc 0.66667 roc_auc 0.42880 prc_auc 0.65973[0m
[93maverage test of epoch 14: loss -3.30300 acc 0.65789 roc_auc 0.52923 prc_auc 0.69337[0m
[92maverage training of epoch 15: loss -3.39373 acc 0.66667 roc_auc 0.46600 prc_auc 0.65369[0m
[93maverage test of epoch 15: loss -3.41808 acc 0.65789 roc_auc 0.54462 prc_auc 0.77197[0m
[92maverage training of epoch 16: loss -3.49830 acc 0.66667 roc_auc 0.50340 prc_auc 0.66237[0m
[93maverage test of epoch 16: loss -3.54276 acc 0.65789 roc_auc 0.63692 prc_auc 0.77361[0m
[92maverage training of epoch 17: loss -3.61706 acc 0.66667 roc_auc 0.40760 prc_auc 0.62914[0m
[93maverage test of epoch 17: loss -3.62792 acc 0.65789 roc_auc 0.55077 prc_auc 0.69433[0m
[92maverage training of epoch 18: loss -3.69518 acc 0.66667 roc_auc 0.43800 prc_auc 0.61909[0m
[93maverage test of epoch 18: loss -3.74177 acc 0.65789 roc_auc 0.43077 prc_auc 0.69162[0m
[92maverage training of epoch 19: loss -3.79566 acc 0.66667 roc_auc 0.46910 prc_auc 0.68839[0m
[93maverage test of epoch 19: loss -3.81714 acc 0.65789 roc_auc 0.45538 prc_auc 0.61987[0m
[92maverage training of epoch 20: loss -3.89474 acc 0.66667 roc_auc 0.51500 prc_auc 0.71831[0m
[93maverage test of epoch 20: loss -3.90396 acc 0.65789 roc_auc 0.60923 prc_auc 0.78577[0m
[92maverage training of epoch 21: loss -3.96649 acc 0.66667 roc_auc 0.51740 prc_auc 0.69488[0m
[93maverage test of epoch 21: loss -3.97161 acc 0.65789 roc_auc 0.35077 prc_auc 0.64732[0m
[92maverage training of epoch 22: loss -4.06702 acc 0.66667 roc_auc 0.45440 prc_auc 0.65281[0m
[93maverage test of epoch 22: loss -4.07501 acc 0.65789 roc_auc 0.57538 prc_auc 0.74372[0m
[92maverage training of epoch 23: loss -4.15122 acc 0.66667 roc_auc 0.59070 prc_auc 0.70477[0m
[93maverage test of epoch 23: loss -4.15820 acc 0.65789 roc_auc 0.48000 prc_auc 0.66889[0m
[92maverage training of epoch 24: loss -4.21914 acc 0.66667 roc_auc 0.46120 prc_auc 0.63208[0m
[93maverage test of epoch 24: loss -4.23753 acc 0.65789 roc_auc 0.56615 prc_auc 0.70877[0m
[92maverage training of epoch 25: loss -4.29617 acc 0.66667 roc_auc 0.42280 prc_auc 0.63225[0m
[93maverage test of epoch 25: loss -4.31535 acc 0.65789 roc_auc 0.53846 prc_auc 0.68388[0m
[92maverage training of epoch 26: loss -4.36936 acc 0.66667 roc_auc 0.42440 prc_auc 0.62369[0m
[93maverage test of epoch 26: loss -4.36107 acc 0.65789 roc_auc 0.52000 prc_auc 0.71449[0m
[92maverage training of epoch 27: loss -4.44346 acc 0.66667 roc_auc 0.50140 prc_auc 0.66021[0m
[93maverage test of epoch 27: loss -4.44469 acc 0.65789 roc_auc 0.57231 prc_auc 0.76115[0m
[92maverage training of epoch 28: loss -4.51405 acc 0.66667 roc_auc 0.53080 prc_auc 0.69146[0m
[93maverage test of epoch 28: loss -4.52306 acc 0.65789 roc_auc 0.56615 prc_auc 0.72549[0m
[92maverage training of epoch 29: loss -4.59102 acc 0.66667 roc_auc 0.48820 prc_auc 0.67826[0m
[93maverage test of epoch 29: loss -4.57186 acc 0.65789 roc_auc 0.39692 prc_auc 0.60880[0m
[92maverage training of epoch 30: loss -4.65584 acc 0.66667 roc_auc 0.44380 prc_auc 0.65752[0m
[93maverage test of epoch 30: loss -4.66978 acc 0.65789 roc_auc 0.50462 prc_auc 0.70700[0m
[92maverage training of epoch 31: loss -4.72249 acc 0.66667 roc_auc 0.52580 prc_auc 0.66591[0m
[93maverage test of epoch 31: loss -4.73694 acc 0.65789 roc_auc 0.74154 prc_auc 0.82942[0m
[92maverage training of epoch 32: loss -4.80611 acc 0.66667 roc_auc 0.49980 prc_auc 0.65989[0m
[93maverage test of epoch 32: loss -4.77792 acc 0.65789 roc_auc 0.42769 prc_auc 0.64452[0m
[92maverage training of epoch 33: loss -4.87132 acc 0.66667 roc_auc 0.55360 prc_auc 0.70946[0m
[93maverage test of epoch 33: loss -4.86455 acc 0.65789 roc_auc 0.39077 prc_auc 0.59818[0m
[92maverage training of epoch 34: loss -4.93175 acc 0.66667 roc_auc 0.49390 prc_auc 0.65556[0m
[93maverage test of epoch 34: loss -4.92183 acc 0.65789 roc_auc 0.41846 prc_auc 0.66725[0m
[92maverage training of epoch 35: loss -4.99441 acc 0.66667 roc_auc 0.43410 prc_auc 0.61428[0m
[93maverage test of epoch 35: loss -5.00200 acc 0.65789 roc_auc 0.41692 prc_auc 0.64414[0m
[92maverage training of epoch 36: loss -5.05842 acc 0.66667 roc_auc 0.40060 prc_auc 0.61439[0m
[93maverage test of epoch 36: loss -5.03684 acc 0.65789 roc_auc 0.44769 prc_auc 0.65633[0m
[92maverage training of epoch 37: loss -5.11897 acc 0.66667 roc_auc 0.50000 prc_auc 0.66793[0m
[93maverage test of epoch 37: loss -5.11450 acc 0.65789 roc_auc 0.36923 prc_auc 0.63181[0m
[92maverage training of epoch 38: loss -5.19004 acc 0.66667 roc_auc 0.42080 prc_auc 0.64813[0m
[93maverage test of epoch 38: loss -5.18468 acc 0.65789 roc_auc 0.40308 prc_auc 0.61896[0m
[92maverage training of epoch 39: loss -5.24622 acc 0.66667 roc_auc 0.46180 prc_auc 0.62439[0m
[93maverage test of epoch 39: loss -5.24098 acc 0.65789 roc_auc 0.44000 prc_auc 0.70241[0m
[92maverage training of epoch 40: loss -5.31259 acc 0.66667 roc_auc 0.51160 prc_auc 0.66303[0m
[93maverage test of epoch 40: loss -5.29848 acc 0.65789 roc_auc 0.46769 prc_auc 0.61624[0m
[92maverage training of epoch 41: loss -5.36920 acc 0.66667 roc_auc 0.42360 prc_auc 0.61696[0m
[93maverage test of epoch 41: loss -5.37033 acc 0.65789 roc_auc 0.58769 prc_auc 0.75155[0m
[92maverage training of epoch 42: loss -5.43470 acc 0.66667 roc_auc 0.52240 prc_auc 0.67237[0m
[93maverage test of epoch 42: loss -5.41857 acc 0.65789 roc_auc 0.36769 prc_auc 0.60062[0m
[92maverage training of epoch 43: loss -5.49376 acc 0.66667 roc_auc 0.43130 prc_auc 0.63140[0m
[93maverage test of epoch 43: loss -5.48985 acc 0.65789 roc_auc 0.50615 prc_auc 0.72916[0m
[92maverage training of epoch 44: loss -5.55159 acc 0.66667 roc_auc 0.49010 prc_auc 0.66860[0m
[93maverage test of epoch 44: loss -5.54829 acc 0.65789 roc_auc 0.38923 prc_auc 0.62707[0m
[92maverage training of epoch 45: loss -5.61968 acc 0.66667 roc_auc 0.49090 prc_auc 0.66307[0m
[93maverage test of epoch 45: loss -5.60833 acc 0.65789 roc_auc 0.69846 prc_auc 0.85117[0m
[92maverage training of epoch 46: loss -5.67156 acc 0.66667 roc_auc 0.48630 prc_auc 0.64239[0m
[93maverage test of epoch 46: loss -5.66101 acc 0.65789 roc_auc 0.50308 prc_auc 0.72176[0m
[92maverage training of epoch 47: loss -5.73176 acc 0.66667 roc_auc 0.43340 prc_auc 0.62478[0m
[93maverage test of epoch 47: loss -5.72004 acc 0.65789 roc_auc 0.56462 prc_auc 0.67843[0m
[92maverage training of epoch 48: loss -5.79097 acc 0.66667 roc_auc 0.51450 prc_auc 0.67475[0m
[93maverage test of epoch 48: loss -5.78394 acc 0.65789 roc_auc 0.57538 prc_auc 0.72960[0m
[92maverage training of epoch 49: loss -5.85086 acc 0.66667 roc_auc 0.41550 prc_auc 0.62144[0m
[93maverage test of epoch 49: loss -5.84112 acc 0.65789 roc_auc 0.50308 prc_auc 0.70035[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.58361 acc 0.33775 roc_auc 0.57706 prc_auc 0.72556[0m
[93maverage test of epoch 0: loss -0.62151 acc 0.32432 roc_auc 0.46667 prc_auc 0.71659[0m
[92maverage training of epoch 1: loss -0.67961 acc 0.33775 roc_auc 0.49294 prc_auc 0.70370[0m
[93maverage test of epoch 1: loss -0.73837 acc 0.32432 roc_auc 0.74333 prc_auc 0.86256[0m
[92maverage training of epoch 2: loss -0.78521 acc 0.34437 roc_auc 0.61647 prc_auc 0.77030[0m
[93maverage test of epoch 2: loss -0.81247 acc 0.35135 roc_auc 0.50667 prc_auc 0.72356[0m
[92maverage training of epoch 3: loss -0.87259 acc 0.35099 roc_auc 0.57137 prc_auc 0.72497[0m
[93maverage test of epoch 3: loss -0.89804 acc 0.35135 roc_auc 0.51333 prc_auc 0.70485[0m
[92maverage training of epoch 4: loss -0.96784 acc 0.35762 roc_auc 0.64608 prc_auc 0.77178[0m
[93maverage test of epoch 4: loss -0.99371 acc 0.35135 roc_auc 0.54667 prc_auc 0.73505[0m
[92maverage training of epoch 5: loss -1.04618 acc 0.37086 roc_auc 0.55725 prc_auc 0.74439[0m
[93maverage test of epoch 5: loss -1.08974 acc 0.37838 roc_auc 0.64667 prc_auc 0.80346[0m
[92maverage training of epoch 6: loss -1.16253 acc 0.43709 roc_auc 0.73353 prc_auc 0.86876[0m
[93maverage test of epoch 6: loss -1.16925 acc 0.43243 roc_auc 0.52333 prc_auc 0.75085[0m
[92maverage training of epoch 7: loss -1.24974 acc 0.49669 roc_auc 0.70608 prc_auc 0.83346[0m
[93maverage test of epoch 7: loss -1.27428 acc 0.37838 roc_auc 0.66333 prc_auc 0.79878[0m
[92maverage training of epoch 8: loss -1.35975 acc 0.60265 roc_auc 0.76569 prc_auc 0.88092[0m
[93maverage test of epoch 8: loss -1.37582 acc 0.54054 roc_auc 0.67000 prc_auc 0.84527[0m
[92maverage training of epoch 9: loss -1.47784 acc 0.67550 roc_auc 0.78275 prc_auc 0.88932[0m
[93maverage test of epoch 9: loss -1.50009 acc 0.62162 roc_auc 0.75667 prc_auc 0.88730[0m
[92maverage training of epoch 10: loss -1.62811 acc 0.78808 roc_auc 0.85118 prc_auc 0.92263[0m
[93maverage test of epoch 10: loss -1.63474 acc 0.78378 roc_auc 0.83000 prc_auc 0.90988[0m
[92maverage training of epoch 11: loss -1.77256 acc 0.75497 roc_auc 0.85549 prc_auc 0.92335[0m
[93maverage test of epoch 11: loss -1.81372 acc 0.75676 roc_auc 0.86000 prc_auc 0.92421[0m
[92maverage training of epoch 12: loss -1.91718 acc 0.74834 roc_auc 0.87706 prc_auc 0.93075[0m
[93maverage test of epoch 12: loss -1.93133 acc 0.72973 roc_auc 0.83000 prc_auc 0.90520[0m
[92maverage training of epoch 13: loss -2.04762 acc 0.75497 roc_auc 0.88725 prc_auc 0.93413[0m
[93maverage test of epoch 13: loss -2.02614 acc 0.70270 roc_auc 0.83000 prc_auc 0.90916[0m
[92maverage training of epoch 14: loss -2.17463 acc 0.76821 roc_auc 0.88569 prc_auc 0.91219[0m
[93maverage test of epoch 14: loss -2.19068 acc 0.78378 roc_auc 0.86333 prc_auc 0.92147[0m
[92maverage training of epoch 15: loss -2.28163 acc 0.75497 roc_auc 0.89765 prc_auc 0.94876[0m
[93maverage test of epoch 15: loss -2.27258 acc 0.72973 roc_auc 0.85000 prc_auc 0.92030[0m
[92maverage training of epoch 16: loss -2.36723 acc 0.78146 roc_auc 0.88235 prc_auc 0.92721[0m
[93maverage test of epoch 16: loss -2.38091 acc 0.72973 roc_auc 0.83667 prc_auc 0.90681[0m
[92maverage training of epoch 17: loss -2.45909 acc 0.77483 roc_auc 0.88647 prc_auc 0.93073[0m
[93maverage test of epoch 17: loss -2.51064 acc 0.83784 roc_auc 0.89000 prc_auc 0.93998[0m
[92maverage training of epoch 18: loss -2.55903 acc 0.81457 roc_auc 0.88510 prc_auc 0.93232[0m
[93maverage test of epoch 18: loss -2.58992 acc 0.81081 roc_auc 0.87000 prc_auc 0.91819[0m
[92maverage training of epoch 19: loss -2.65783 acc 0.82781 roc_auc 0.89039 prc_auc 0.92330[0m
[93maverage test of epoch 19: loss -2.64205 acc 0.83784 roc_auc 0.85000 prc_auc 0.89636[0m
[92maverage training of epoch 20: loss -2.74844 acc 0.84106 roc_auc 0.88922 prc_auc 0.92338[0m
[93maverage test of epoch 20: loss -2.72131 acc 0.81081 roc_auc 0.84667 prc_auc 0.89433[0m
[92maverage training of epoch 21: loss -2.82050 acc 0.84768 roc_auc 0.87745 prc_auc 0.91687[0m
[93maverage test of epoch 21: loss -2.80046 acc 0.81081 roc_auc 0.85667 prc_auc 0.92070[0m
[92maverage training of epoch 22: loss -2.89263 acc 0.82781 roc_auc 0.89471 prc_auc 0.92821[0m
[93maverage test of epoch 22: loss -2.87893 acc 0.83784 roc_auc 0.85667 prc_auc 0.91935[0m
[92maverage training of epoch 23: loss -2.98455 acc 0.86093 roc_auc 0.87922 prc_auc 0.90637[0m
[93maverage test of epoch 23: loss -2.97030 acc 0.86486 roc_auc 0.85667 prc_auc 0.92293[0m
[92maverage training of epoch 24: loss -3.07279 acc 0.83444 roc_auc 0.90373 prc_auc 0.93468[0m
[93maverage test of epoch 24: loss -3.05032 acc 0.86486 roc_auc 0.88333 prc_auc 0.93802[0m
[92maverage training of epoch 25: loss -3.14696 acc 0.84768 roc_auc 0.89157 prc_auc 0.93584[0m
[93maverage test of epoch 25: loss -3.15059 acc 0.86486 roc_auc 0.86333 prc_auc 0.91563[0m
[92maverage training of epoch 26: loss -3.21278 acc 0.86093 roc_auc 0.89196 prc_auc 0.92662[0m
[93maverage test of epoch 26: loss -3.20605 acc 0.83784 roc_auc 0.86667 prc_auc 0.91247[0m
[92maverage training of epoch 27: loss -3.27937 acc 0.85430 roc_auc 0.88431 prc_auc 0.92222[0m
[93maverage test of epoch 27: loss -3.25982 acc 0.83784 roc_auc 0.85333 prc_auc 0.89949[0m
[92maverage training of epoch 28: loss -3.34416 acc 0.84768 roc_auc 0.87647 prc_auc 0.91650[0m
[93maverage test of epoch 28: loss -3.33032 acc 0.86486 roc_auc 0.84333 prc_auc 0.91323[0m
[92maverage training of epoch 29: loss -3.42932 acc 0.85430 roc_auc 0.88647 prc_auc 0.92665[0m
[93maverage test of epoch 29: loss -3.42307 acc 0.86486 roc_auc 0.85000 prc_auc 0.91648[0m
[92maverage training of epoch 30: loss -3.50950 acc 0.85430 roc_auc 0.90216 prc_auc 0.94252[0m
[93maverage test of epoch 30: loss -3.46142 acc 0.86486 roc_auc 0.87667 prc_auc 0.93462[0m
[92maverage training of epoch 31: loss -3.56596 acc 0.85430 roc_auc 0.89235 prc_auc 0.92942[0m
[93maverage test of epoch 31: loss -3.49193 acc 0.83784 roc_auc 0.85333 prc_auc 0.92446[0m
[92maverage training of epoch 32: loss -3.62567 acc 0.85430 roc_auc 0.88216 prc_auc 0.91305[0m
[93maverage test of epoch 32: loss -3.58879 acc 0.86486 roc_auc 0.86000 prc_auc 0.92427[0m
[92maverage training of epoch 33: loss -3.69291 acc 0.84768 roc_auc 0.88216 prc_auc 0.90379[0m
[93maverage test of epoch 33: loss -3.65682 acc 0.86486 roc_auc 0.83333 prc_auc 0.84908[0m
[92maverage training of epoch 34: loss -3.75376 acc 0.86093 roc_auc 0.90667 prc_auc 0.94608[0m
[93maverage test of epoch 34: loss -3.71514 acc 0.83784 roc_auc 0.86333 prc_auc 0.93424[0m
[92maverage training of epoch 35: loss -3.81334 acc 0.85430 roc_auc 0.89333 prc_auc 0.93472[0m
[93maverage test of epoch 35: loss -3.80188 acc 0.86486 roc_auc 0.88000 prc_auc 0.94004[0m
[92maverage training of epoch 36: loss -3.86754 acc 0.84768 roc_auc 0.89294 prc_auc 0.91625[0m
[93maverage test of epoch 36: loss -3.89194 acc 0.86486 roc_auc 0.89000 prc_auc 0.94283[0m
[92maverage training of epoch 37: loss -3.94096 acc 0.85430 roc_auc 0.89510 prc_auc 0.93802[0m
[93maverage test of epoch 37: loss -3.95083 acc 0.86486 roc_auc 0.84333 prc_auc 0.87877[0m
[92maverage training of epoch 38: loss -3.96108 acc 0.85430 roc_auc 0.87941 prc_auc 0.91714[0m
[93maverage test of epoch 38: loss -3.97869 acc 0.86486 roc_auc 0.86667 prc_auc 0.92858[0m
[92maverage training of epoch 39: loss -4.05401 acc 0.86093 roc_auc 0.89667 prc_auc 0.94050[0m
[93maverage test of epoch 39: loss -4.05731 acc 0.86486 roc_auc 0.85667 prc_auc 0.91780[0m
[92maverage training of epoch 40: loss -4.12025 acc 0.85430 roc_auc 0.90980 prc_auc 0.95569[0m
[93maverage test of epoch 40: loss -4.10964 acc 0.86486 roc_auc 0.85000 prc_auc 0.89744[0m
[92maverage training of epoch 41: loss -4.20163 acc 0.86093 roc_auc 0.87608 prc_auc 0.90561[0m
[93maverage test of epoch 41: loss -4.12938 acc 0.86486 roc_auc 0.84333 prc_auc 0.89996[0m
[92maverage training of epoch 42: loss -4.26318 acc 0.85430 roc_auc 0.89980 prc_auc 0.91741[0m
[93maverage test of epoch 42: loss -4.19996 acc 0.86486 roc_auc 0.80667 prc_auc 0.86634[0m
[92maverage training of epoch 43: loss -4.28835 acc 0.85430 roc_auc 0.88667 prc_auc 0.91979[0m
[93maverage test of epoch 43: loss -4.29111 acc 0.86486 roc_auc 0.85000 prc_auc 0.92618[0m
[92maverage training of epoch 44: loss -4.36907 acc 0.86093 roc_auc 0.89275 prc_auc 0.93447[0m
[93maverage test of epoch 44: loss -4.36915 acc 0.86486 roc_auc 0.84667 prc_auc 0.90552[0m
[92maverage training of epoch 45: loss -4.44384 acc 0.86755 roc_auc 0.89471 prc_auc 0.91189[0m
[93maverage test of epoch 45: loss -4.40807 acc 0.86486 roc_auc 0.86667 prc_auc 0.92877[0m
[92maverage training of epoch 46: loss -4.46873 acc 0.85430 roc_auc 0.87706 prc_auc 0.91093[0m
[93maverage test of epoch 46: loss -4.47187 acc 0.86486 roc_auc 0.86333 prc_auc 0.92230[0m
[92maverage training of epoch 47: loss -4.53190 acc 0.85430 roc_auc 0.89843 prc_auc 0.92375[0m
[93maverage test of epoch 47: loss -4.52352 acc 0.86486 roc_auc 0.83333 prc_auc 0.89796[0m
[92maverage training of epoch 48: loss -4.60688 acc 0.86093 roc_auc 0.89706 prc_auc 0.92768[0m
[93maverage test of epoch 48: loss -4.56742 acc 0.86486 roc_auc 0.88333 prc_auc 0.94834[0m
[92maverage training of epoch 49: loss -4.64670 acc 0.85430 roc_auc 0.87765 prc_auc 0.88927[0m
[93maverage test of epoch 49: loss -4.62337 acc 0.86486 roc_auc 0.86000 prc_auc 0.93478[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.64609 acc 0.37748 roc_auc 0.43843 prc_auc 0.63553[0m
[93maverage test of epoch 0: loss -0.70095 acc 0.32432 roc_auc 0.54000 prc_auc 0.69233[0m
[92maverage training of epoch 1: loss -0.75407 acc 0.32450 roc_auc 0.43549 prc_auc 0.61584[0m
[93maverage test of epoch 1: loss -0.81373 acc 0.35135 roc_auc 0.57333 prc_auc 0.76780[0m
[92maverage training of epoch 2: loss -0.85442 acc 0.34437 roc_auc 0.39078 prc_auc 0.59243[0m
[93maverage test of epoch 2: loss -0.92108 acc 0.32432 roc_auc 0.73333 prc_auc 0.84039[0m
[92maverage training of epoch 3: loss -0.95670 acc 0.33113 roc_auc 0.44235 prc_auc 0.63279[0m
[93maverage test of epoch 3: loss -1.01112 acc 0.35135 roc_auc 0.58667 prc_auc 0.76416[0m
[92maverage training of epoch 4: loss -1.04543 acc 0.34437 roc_auc 0.44922 prc_auc 0.66225[0m
[93maverage test of epoch 4: loss -1.09529 acc 0.32432 roc_auc 0.52000 prc_auc 0.72106[0m
[92maverage training of epoch 5: loss -1.13251 acc 0.36424 roc_auc 0.50333 prc_auc 0.68771[0m
[93maverage test of epoch 5: loss -1.18401 acc 0.32432 roc_auc 0.55333 prc_auc 0.79240[0m
[92maverage training of epoch 6: loss -1.21292 acc 0.37748 roc_auc 0.49745 prc_auc 0.70761[0m
[93maverage test of epoch 6: loss -1.25255 acc 0.32432 roc_auc 0.57000 prc_auc 0.75641[0m
[92maverage training of epoch 7: loss -1.29243 acc 0.37086 roc_auc 0.56549 prc_auc 0.74785[0mUsing backend: pytorch

[93maverage test of epoch 7: loss -1.33088 acc 0.32432 roc_auc 0.55667 prc_auc 0.74355[0m
[92maverage training of epoch 8: loss -1.36269 acc 0.39735 roc_auc 0.47078 prc_auc 0.69281[0m
[93maverage test of epoch 8: loss -1.39036 acc 0.32432 roc_auc 0.45000 prc_auc 0.64692[0m
[92maverage training of epoch 9: loss -1.43519 acc 0.37748 roc_auc 0.47353 prc_auc 0.69541[0m
[93maverage test of epoch 9: loss -1.46308 acc 0.35135 roc_auc 0.45000 prc_auc 0.69913[0m
[92maverage training of epoch 10: loss -1.51080 acc 0.41722 roc_auc 0.47902 prc_auc 0.69826[0m
[93maverage test of epoch 10: loss -1.54337 acc 0.40541 roc_auc 0.44333 prc_auc 0.69936[0m
[92maverage training of epoch 11: loss -1.58368 acc 0.42384 roc_auc 0.61392 prc_auc 0.77618[0m
[93maverage test of epoch 11: loss -1.60936 acc 0.45946 roc_auc 0.50000 prc_auc 0.74900[0m
[92maverage training of epoch 12: loss -1.65427 acc 0.49669 roc_auc 0.60882 prc_auc 0.77976[0m
[93maverage test of epoch 12: loss -1.68430 acc 0.40541 roc_auc 0.53000 prc_auc 0.75399[0m
[92maverage training of epoch 13: loss -1.72089 acc 0.48344 roc_auc 0.51471 prc_auc 0.70961[0m
[93maverage test of epoch 13: loss -1.76771 acc 0.59459 roc_auc 0.59667 prc_auc 0.75613[0m
[92maverage training of epoch 14: loss -1.79372 acc 0.50993 roc_auc 0.52235 prc_auc 0.72808[0m
[93maverage test of epoch 14: loss -1.83907 acc 0.67568 roc_auc 0.75333 prc_auc 0.88408[0m
[92maverage training of epoch 15: loss -1.86267 acc 0.56291 roc_auc 0.49314 prc_auc 0.71230[0m
[93maverage test of epoch 15: loss -1.89912 acc 0.51351 roc_auc 0.53333 prc_auc 0.75808[0m
[92maverage training of epoch 16: loss -1.93405 acc 0.60265 roc_auc 0.53392 prc_auc 0.73652[0m
[93maverage test of epoch 16: loss -1.97574 acc 0.59459 roc_auc 0.59000 prc_auc 0.79537[0m
[92maverage training of epoch 17: loss -2.00774 acc 0.61589 roc_auc 0.54667 prc_auc 0.74762[0m
[93maverage test of epoch 17: loss -2.04463 acc 0.75676 roc_auc 0.50667 prc_auc 0.69951[0m
[92maverage training of epoch 18: loss -2.08088 acc 0.64238 roc_auc 0.66078 prc_auc 0.81282[0m
[93maverage test of epoch 18: loss -2.11891 acc 0.67568 roc_auc 0.74667 prc_auc 0.88091[0m
[92maverage training of epoch 19: loss -2.15075 acc 0.67550 roc_auc 0.66137 prc_auc 0.81954[0m
[93maverage test of epoch 19: loss -2.18149 acc 0.64865 roc_auc 0.56000 prc_auc 0.78824[0m
[92maverage training of epoch 20: loss -2.21057 acc 0.64238 roc_auc 0.48980 prc_auc 0.71625[0m
[93maverage test of epoch 20: loss -2.23862 acc 0.56757 roc_auc 0.50000 prc_auc 0.75470[0m
[92maverage training of epoch 21: loss -2.28840 acc 0.66225 roc_auc 0.62176 prc_auc 0.79443[0m
[93maverage test of epoch 21: loss -2.32663 acc 0.67568 roc_auc 0.70667 prc_auc 0.81921[0m
[92maverage training of epoch 22: loss -2.35351 acc 0.65563 roc_auc 0.62431 prc_auc 0.79172[0m
[93maverage test of epoch 22: loss -2.38816 acc 0.67568 roc_auc 0.56667 prc_auc 0.81140[0m
[92maverage training of epoch 23: loss -2.42125 acc 0.66225 roc_auc 0.61569 prc_auc 0.79794[0m
[93maverage test of epoch 23: loss -2.45971 acc 0.67568 roc_auc 0.60333 prc_auc 0.77006[0m
[92maverage training of epoch 24: loss -2.48710 acc 0.66225 roc_auc 0.62510 prc_auc 0.78959[0m
[93maverage test of epoch 24: loss -2.52960 acc 0.67568 roc_auc 0.72667 prc_auc 0.86792[0m
[92maverage training of epoch 25: loss -2.55921 acc 0.66225 roc_auc 0.69569 prc_auc 0.83330[0m
[93maverage test of epoch 25: loss -2.59605 acc 0.67568 roc_auc 0.73333 prc_auc 0.87347[0m
[92maverage training of epoch 26: loss -2.61795 acc 0.66225 roc_auc 0.61765 prc_auc 0.78412[0m
[93maverage test of epoch 26: loss -2.66420 acc 0.67568 roc_auc 0.74667 prc_auc 0.89116[0m
[92maverage training of epoch 27: loss -2.68699 acc 0.66225 roc_auc 0.64549 prc_auc 0.81272[0m
[93maverage test of epoch 27: loss -2.72004 acc 0.67568 roc_auc 0.56667 prc_auc 0.79072[0m
[92maverage training of epoch 28: loss -2.75536 acc 0.66225 roc_auc 0.67412 prc_auc 0.82544[0m
[93maverage test of epoch 28: loss -2.79218 acc 0.67568 roc_auc 0.72667 prc_auc 0.87369[0m
[92maverage training of epoch 29: loss -2.81906 acc 0.66225 roc_auc 0.69176 prc_auc 0.83689[0m
[93maverage test of epoch 29: loss -2.86298 acc 0.67568 roc_auc 0.76333 prc_auc 0.89370[0m
[92maverage training of epoch 30: loss -2.88192 acc 0.66225 roc_auc 0.66902 prc_auc 0.79757[0m
[93maverage test of epoch 30: loss -2.91582 acc 0.67568 roc_auc 0.61333 prc_auc 0.83308[0m
[92maverage training of epoch 31: loss -2.94932 acc 0.66225 roc_auc 0.71745 prc_auc 0.85656[0m
[93maverage test of epoch 31: loss -2.99369 acc 0.67568 roc_auc 0.86667 prc_auc 0.93926[0m
[92maverage training of epoch 32: loss -3.00999 acc 0.66225 roc_auc 0.70000 prc_auc 0.80982[0m
[93maverage test of epoch 32: loss -3.04849 acc 0.67568 roc_auc 0.75333 prc_auc 0.87918[0m
[92maverage training of epoch 33: loss -3.07831 acc 0.66225 roc_auc 0.72706 prc_auc 0.82805[0m
[93maverage test of epoch 33: loss -3.11554 acc 0.67568 roc_auc 0.78333 prc_auc 0.91550[0m
[92maverage training of epoch 34: loss -3.14645 acc 0.66225 roc_auc 0.83392 prc_auc 0.91530[0m
[93maverage test of epoch 34: loss -3.17445 acc 0.67568 roc_auc 0.73333 prc_auc 0.87509[0m
[92maverage training of epoch 35: loss -3.21054 acc 0.66225 roc_auc 0.80176 prc_auc 0.88460[0m
[93maverage test of epoch 35: loss -3.24113 acc 0.67568 roc_auc 0.81333 prc_auc 0.91443[0m
[92maverage training of epoch 36: loss -3.27100 acc 0.66225 roc_auc 0.80451 prc_auc 0.89562[0m
[93maverage test of epoch 36: loss -3.31109 acc 0.67568 roc_auc 0.76333 prc_auc 0.87385[0m
[92maverage training of epoch 37: loss -3.33447 acc 0.66225 roc_auc 0.81333 prc_auc 0.88097[0m
[93maverage test of epoch 37: loss -3.37825 acc 0.67568 roc_auc 0.90667 prc_auc 0.95968[0m
[92maverage training of epoch 38: loss -3.39628 acc 0.66225 roc_auc 0.79863 prc_auc 0.86801[0m
[93maverage test of epoch 38: loss -3.43120 acc 0.67568 roc_auc 0.85333 prc_auc 0.92920[0m
[92maverage training of epoch 39: loss -3.45724 acc 0.66225 roc_auc 0.84000 prc_auc 0.88968[0m
[93maverage test of epoch 39: loss -3.50449 acc 0.67568 roc_auc 0.90333 prc_auc 0.96052[0m
[92maverage training of epoch 40: loss -3.52640 acc 0.66225 roc_auc 0.87961 prc_auc 0.93563[0m
[93maverage test of epoch 40: loss -3.54469 acc 0.67568 roc_auc 0.79667 prc_auc 0.91133[0m
[92maverage training of epoch 41: loss -3.58590 acc 0.66225 roc_auc 0.85373 prc_auc 0.90291[0m
[93maverage test of epoch 41: loss -3.63546 acc 0.67568 roc_auc 0.95333 prc_auc 0.97876[0m
[92maverage training of epoch 42: loss -3.64278 acc 0.66225 roc_auc 0.82294 prc_auc 0.86636[0m
[93maverage test of epoch 42: loss -3.67630 acc 0.67568 roc_auc 0.89667 prc_auc 0.96078[0m
[92maverage training of epoch 43: loss -3.70886 acc 0.66225 roc_auc 0.84922 prc_auc 0.87944[0m
[93maverage test of epoch 43: loss -3.75148 acc 0.67568 roc_auc 0.93333 prc_auc 0.96979[0m
[92maverage training of epoch 44: loss -3.76902 acc 0.66225 roc_auc 0.85157 prc_auc 0.89434[0m
[93maverage test of epoch 44: loss -3.80605 acc 0.67568 roc_auc 0.90333 prc_auc 0.96382[0m
[92maverage training of epoch 45: loss -3.83487 acc 0.66225 roc_auc 0.85804 prc_auc 0.90038[0m
[93maverage test of epoch 45: loss -3.87031 acc 0.67568 roc_auc 0.91667 prc_auc 0.96577[0m
[92maverage training of epoch 46: loss -3.89386 acc 0.66887 roc_auc 0.84843 prc_auc 0.88051[0m
[93maverage test of epoch 46: loss -3.93377 acc 0.67568 roc_auc 0.89667 prc_auc 0.95948[0m
[92maverage training of epoch 47: loss -3.95228 acc 0.66887 roc_auc 0.84431 prc_auc 0.86564[0m
[93maverage test of epoch 47: loss -3.98940 acc 0.67568 roc_auc 0.87333 prc_auc 0.94957[0m
[92maverage training of epoch 48: loss -4.01263 acc 0.67550 roc_auc 0.87941 prc_auc 0.92839[0m
[93maverage test of epoch 48: loss -4.06323 acc 0.67568 roc_auc 0.93333 prc_auc 0.97296[0m
[92maverage training of epoch 49: loss -4.07904 acc 0.66887 roc_auc 0.87902 prc_auc 0.92402[0m
[93maverage test of epoch 49: loss -4.11480 acc 0.70270 roc_auc 0.92000 prc_auc 0.97052[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.0001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.70825 ROC_AUC (avg): 0.68985 PRC_AUC (avg): 0.82461 

Average forward propagation time taken(ms): 3.954036461780173
Average backward propagation time taken(ms): 1.5072224143615387

