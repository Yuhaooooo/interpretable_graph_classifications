# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-18-59-31/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-18-59-31/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 16,
 'epochs': 50,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 8,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.001,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 1,
 'num_workers': 8,
 'number_of_mlp_layer': 0,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-17-18-59-31',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 50, 'learning_rate': 0.001, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -1.19514 acc 0.45333 roc_auc 0.42480 prc_auc 0.63668[0m
[93maverage test of epoch 0: loss -2.14204 acc 0.65789 roc_auc 0.56615 prc_auc 0.79509[0m
[92maverage training of epoch 1: loss -3.22064 acc 0.66667 roc_auc 0.40720 prc_auc 0.62340[0m
[93maverage test of epoch 1: loss -4.28413 acc 0.65789 roc_auc 0.87846 prc_auc 0.93781[0m
[92maverage training of epoch 2: loss -5.04852 acc 0.66667 roc_auc 0.38820 prc_auc 0.60419[0m
[93maverage test of epoch 2: loss -5.68280 acc 0.65789 roc_auc 0.87231 prc_auc 0.93534[0m
[92maverage training of epoch 3: loss -6.29327 acc 0.66667 roc_auc 0.42000 prc_auc 0.63500[0m
[93maverage test of epoch 3: loss -6.85054 acc 0.65789 roc_auc 0.86769 prc_auc 0.93736[0m
[92maverage training of epoch 4: loss -7.46139 acc 0.66667 roc_auc 0.42900 prc_auc 0.64146[0m
[93maverage test of epoch 4: loss -8.02654 acc 0.65789 roc_auc 0.87385 prc_auc 0.94252[0m
[92maverage training of epoch 5: loss -8.63738 acc 0.66667 roc_auc 0.38280 prc_auc 0.60998[0m
[93maverage test of epoch 5: loss -9.19135 acc 0.65789 roc_auc 0.87846 prc_auc 0.94346[0m
[92maverage training of epoch 6: loss -9.78156 acc 0.66667 roc_auc 0.37060 prc_auc 0.58658[0m
[93maverage test of epoch 6: loss -10.31123 acc 0.65789 roc_auc 0.87231 prc_auc 0.94166[0m
[92maverage training of epoch 7: loss -10.88572 acc 0.66667 roc_auc 0.36640 prc_auc 0.57930[0m
[93maverage test of epoch 7: loss -11.39652 acc 0.65789 roc_auc 0.86462 prc_auc 0.92033[0m
[92maverage training of epoch 8: loss -11.96183 acc 0.66667 roc_auc 0.36080 prc_auc 0.56516[0m
[93maverage test of epoch 8: loss -12.45901 acc 0.65789 roc_auc 0.80000 prc_auc 0.86316[0m
[92maverage training of epoch 9: loss -13.01906 acc 0.66667 roc_auc 0.35900 prc_auc 0.56353[0m
[93maverage test of epoch 9: loss -13.50589 acc 0.65789 roc_auc 0.72000 prc_auc 0.80842[0m
[92maverage training of epoch 10: loss -14.06302 acc 0.66667 roc_auc 0.35780 prc_auc 0.56257[0m
[93maverage test of epoch 10: loss -14.54153 acc 0.65789 roc_auc 0.76000 prc_auc 0.83579[0m
[92maverage training of epoch 11: loss -15.09724 acc 0.66667 roc_auc 0.35750 prc_auc 0.56208[0m
[93maverage test of epoch 11: loss -15.56878 acc 0.65789 roc_auc 0.68000 prc_auc 0.78105[0m
[92maverage training of epoch 12: loss -16.12408 acc 0.66667 roc_auc 0.35710 prc_auc 0.56207[0m
[93maverage test of epoch 12: loss -16.58959 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 13: loss -17.14517 acc 0.66667 roc_auc 0.35710 prc_auc 0.56196[0m
[93maverage test of epoch 13: loss -17.60533 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 14: loss -18.16173 acc 0.66667 roc_auc 0.35700 prc_auc 0.56185[0m
[93maverage test of epoch 14: loss -18.61701 acc 0.65789 roc_auc 0.52000 prc_auc 0.67158[0m
[92maverage training of epoch 15: loss -19.17461 acc 0.66667 roc_auc 0.35730 prc_auc 0.56172[0m
[93maverage test of epoch 15: loss -19.62542 acc 0.65789 roc_auc 0.52000 prc_auc 0.67158[0m
[92maverage training of epoch 16: loss -20.18452 acc 0.66667 roc_auc 0.35750 prc_auc 0.56165[0m
[93maverage test of epoch 16: loss -20.63114 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 17: loss -21.19198 acc 0.66667 roc_auc 0.35690 prc_auc 0.56167[0m
[93maverage test of epoch 17: loss -21.63464 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 18: loss -22.19741 acc 0.66667 roc_auc 0.35740 prc_auc 0.56237[0m
[93maverage test of epoch 18: loss -22.63631 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -23.20115 acc 0.66667 roc_auc 0.35790 prc_auc 0.56341[0m
[93maverage test of epoch 19: loss -23.63643 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -24.20347 acc 0.66667 roc_auc 0.35770 prc_auc 0.56280[0m
[93maverage test of epoch 20: loss -24.63525 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -25.20459 acc 0.66667 roc_auc 0.35760 prc_auc 0.56505[0m
[93maverage test of epoch 21: loss -25.63299 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -26.20470 acc 0.66667 roc_auc 0.35820 prc_auc 0.56251[0m
[93maverage test of epoch 22: loss -26.62979 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -27.20395 acc 0.66667 roc_auc 0.35990 prc_auc 0.56552[0m
[93maverage test of epoch 23: loss -27.62581 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -28.20248 acc 0.66667 roc_auc 0.35960 prc_auc 0.56616[0m
[93maverage test of epoch 24: loss -28.62116 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -29.20038 acc 0.66667 roc_auc 0.35510 prc_auc 0.56600[0m
[93maverage test of epoch 25: loss -29.61594 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -30.19776 acc 0.66667 roc_auc 0.35900 prc_auc 0.56838[0m
[93maverage test of epoch 26: loss -30.61024 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -31.19469 acc 0.66667 roc_auc 0.36290 prc_auc 0.57637[0m
[93maverage test of epoch 27: loss -31.60411 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -32.19122 acc 0.66667 roc_auc 0.35680 prc_auc 0.56894[0m
[93maverage test of epoch 28: loss -32.59763 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -33.18742 acc 0.66667 roc_auc 0.36410 prc_auc 0.57688[0m
[93maverage test of epoch 29: loss -33.59083 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -34.18334 acc 0.66667 roc_auc 0.37160 prc_auc 0.58715[0m
[93maverage test of epoch 30: loss -34.58378 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -35.17901 acc 0.66667 roc_auc 0.36300 prc_auc 0.58518[0m
[93maverage test of epoch 31: loss -35.57651 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -36.17447 acc 0.66667 roc_auc 0.36290 prc_auc 0.58935[0m
[93maverage test of epoch 32: loss -36.56903 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -37.16974 acc 0.66667 roc_auc 0.36410 prc_auc 0.59343[0m
[93maverage test of epoch 33: loss -37.56137 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -38.16486 acc 0.66667 roc_auc 0.39420 prc_auc 0.62590[0m
[93maverage test of epoch 34: loss -38.55358 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -39.15984 acc 0.66667 roc_auc 0.36880 prc_auc 0.60448[0m
[93maverage test of epoch 35: loss -39.54566 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -40.15469 acc 0.66667 roc_auc 0.41540 prc_auc 0.62872[0m
[93maverage test of epoch 36: loss -40.53762 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -41.14944 acc 0.66667 roc_auc 0.42380 prc_auc 0.63316[0m
[93maverage test of epoch 37: loss -41.52949 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -42.14411 acc 0.66667 roc_auc 0.36170 prc_auc 0.61668[0m
[93maverage test of epoch 38: loss -42.52128 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -43.13870 acc 0.66667 roc_auc 0.40000 prc_auc 0.64000[0m
[93maverage test of epoch 39: loss -43.51300 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -44.13322 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -44.50465 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -45.12769 acc 0.66667 roc_auc 0.43000 prc_auc 0.63767[0m
[93maverage test of epoch 41: loss -45.49625 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -46.12210 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -46.48780 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -47.11647 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -47.47932 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -48.11080 acc 0.66667 roc_auc 0.37500 prc_auc 0.63506[0m
[93maverage test of epoch 44: loss -48.47080 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -49.10510 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -49.46224 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -50.09937 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -50.45366 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -51.09361 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -51.44506 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -52.08783 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -52.43643 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -53.08203 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -53.42778 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -1.22922 acc 0.66667 roc_auc 0.46820 prc_auc 0.65576[0m
[93maverage test of epoch 0: loss -2.94545 acc 0.65789 roc_auc 0.53231 prc_auc 0.73435[0m
[92maverage training of epoch 1: loss -4.46297 acc 0.66667 roc_auc 0.43160 prc_auc 0.60901[0m
[93maverage test of epoch 1: loss -5.45891 acc 0.65789 roc_auc 0.69231 prc_auc 0.83898[0m
[92maverage training of epoch 2: loss -6.08969 acc 0.66667 roc_auc 0.42440 prc_auc 0.61097[0m
[93maverage test of epoch 2: loss -6.65771 acc 0.65789 roc_auc 0.56154 prc_auc 0.77355[0m
[92maverage training of epoch 3: loss -7.27431 acc 0.66667 roc_auc 0.40020 prc_auc 0.60299[0m
[93maverage test of epoch 3: loss -7.89928 acc 0.65789 roc_auc 0.17692 prc_auc 0.55224[0m
[92maverage training of epoch 4: loss -8.53795 acc 0.66667 roc_auc 0.41320 prc_auc 0.59551[0m
[93maverage test of epoch 4: loss -9.11989 acc 0.65789 roc_auc 0.19077 prc_auc 0.56346[0m
[92maverage training of epoch 5: loss -9.70780 acc 0.66667 roc_auc 0.41980 prc_auc 0.60403[0m
[93maverage test of epoch 5: loss -10.24586 acc 0.65789 roc_auc 0.16923 prc_auc 0.58458[0m
[92maverage training of epoch 6: loss -10.81373 acc 0.66667 roc_auc 0.42020 prc_auc 0.60491[0m
[93maverage test of epoch 6: loss -11.32952 acc 0.65789 roc_auc 0.23538 prc_auc 0.66118[0m
[92maverage training of epoch 7: loss -11.88769 acc 0.66667 roc_auc 0.42030 prc_auc 0.60491[0m
[93maverage test of epoch 7: loss -12.38915 acc 0.65789 roc_auc 0.35692 prc_auc 0.64702[0m
[92maverage training of epoch 8: loss -12.94217 acc 0.66667 roc_auc 0.42030 prc_auc 0.60470[0m
[93maverage test of epoch 8: loss -13.43316 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 9: loss -13.98349 acc 0.66667 roc_auc 0.42030 prc_auc 0.60470[0m
[93maverage test of epoch 9: loss -14.46622 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 10: loss -15.01535 acc 0.66667 roc_auc 0.42020 prc_auc 0.60455[0m
[93maverage test of epoch 10: loss -15.49122 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 11: loss -16.04013 acc 0.66667 roc_auc 0.42020 prc_auc 0.60458[0m
[93maverage test of epoch 11: loss -16.51007 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 12: loss -17.05946 acc 0.66667 roc_auc 0.42010 prc_auc 0.60497[0m
[93maverage test of epoch 12: loss -17.52413 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 13: loss -18.07448 acc 0.66667 roc_auc 0.42010 prc_auc 0.60497[0m
[93maverage test of epoch 13: loss -18.53439 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 14: loss -19.08606 acc 0.66667 roc_auc 0.42020 prc_auc 0.60494[0m
[93maverage test of epoch 14: loss -19.54157 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 15: loss -20.09485 acc 0.66667 roc_auc 0.42030 prc_auc 0.60458[0m
[93maverage test of epoch 15: loss -20.54624 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 16: loss -21.10136 acc 0.66667 roc_auc 0.42030 prc_auc 0.60461[0m
[93maverage test of epoch 16: loss -21.54886 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 17: loss -22.10598 acc 0.66667 roc_auc 0.42020 prc_auc 0.60548[0m
[93maverage test of epoch 17: loss -22.54977 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 18: loss -23.10903 acc 0.66667 roc_auc 0.42040 prc_auc 0.60558[0m
[93maverage test of epoch 18: loss -23.54925 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 19: loss -24.11077 acc 0.66667 roc_auc 0.42040 prc_auc 0.60566[0m
[93maverage test of epoch 19: loss -24.54753 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 20: loss -25.11139 acc 0.66667 roc_auc 0.42050 prc_auc 0.60553[0m
[93maverage test of epoch 20: loss -25.54480 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 21: loss -26.11109 acc 0.66667 roc_auc 0.42060 prc_auc 0.60447[0m
[93maverage test of epoch 21: loss -26.54122 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -27.11000 acc 0.66667 roc_auc 0.42110 prc_auc 0.60631[0m
[93maverage test of epoch 22: loss -27.53692 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -28.10823 acc 0.66667 roc_auc 0.42010 prc_auc 0.60247[0m
[93maverage test of epoch 23: loss -28.53200 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 24: loss -29.10589 acc 0.66667 roc_auc 0.42010 prc_auc 0.60503[0m
[93maverage test of epoch 24: loss -29.52656 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -30.10307 acc 0.66667 roc_auc 0.42100 prc_auc 0.60417[0m
[93maverage test of epoch 25: loss -30.52067 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -31.09983 acc 0.66667 roc_auc 0.41940 prc_auc 0.60106[0m
[93maverage test of epoch 26: loss -31.51440 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -32.09624 acc 0.66667 roc_auc 0.42070 prc_auc 0.60096[0m
[93maverage test of epoch 27: loss -32.50779 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 28: loss -33.09233 acc 0.66667 roc_auc 0.42160 prc_auc 0.60476[0m
[93maverage test of epoch 28: loss -33.50091 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -34.08817 acc 0.66667 roc_auc 0.41980 prc_auc 0.60371[0m
[93maverage test of epoch 29: loss -34.49378 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -35.08378 acc 0.66667 roc_auc 0.42390 prc_auc 0.60985[0m
[93maverage test of epoch 30: loss -35.48645 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -36.07919 acc 0.66667 roc_auc 0.42360 prc_auc 0.60659[0m
[93maverage test of epoch 31: loss -36.47893 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -37.07444 acc 0.66667 roc_auc 0.42450 prc_auc 0.60955[0m
[93maverage test of epoch 32: loss -37.47127 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -38.06954 acc 0.66667 roc_auc 0.42970 prc_auc 0.61590[0m
[93maverage test of epoch 33: loss -38.46346 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -39.06452 acc 0.66667 roc_auc 0.42630 prc_auc 0.62011[0m
[93maverage test of epoch 34: loss -39.45555 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -40.05939 acc 0.66667 roc_auc 0.43650 prc_auc 0.62779[0m
[93maverage test of epoch 35: loss -40.44753 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -41.05416 acc 0.66667 roc_auc 0.45980 prc_auc 0.64223[0m
[93maverage test of epoch 36: loss -41.43941 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -42.04885 acc 0.66667 roc_auc 0.45700 prc_auc 0.64225[0m
[93maverage test of epoch 37: loss -42.43123 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -43.04346 acc 0.66667 roc_auc 0.46910 prc_auc 0.65176[0m
[93maverage test of epoch 38: loss -43.42297 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -44.03802 acc 0.66667 roc_auc 0.46220 prc_auc 0.64797[0m
[93maverage test of epoch 39: loss -44.41466 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -45.03252 acc 0.66667 roc_auc 0.46500 prc_auc 0.65168[0m
[93maverage test of epoch 40: loss -45.40630 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -46.02698 acc 0.66667 roc_auc 0.48000 prc_auc 0.65797[0m
[93maverage test of epoch 41: loss -46.39790 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -47.02139 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -47.38947 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -48.01578 acc 0.66667 roc_auc 0.49500 prc_auc 0.66445[0m
[93maverage test of epoch 43: loss -48.38100 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -49.01013 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -49.37250 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -50.00446 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -50.36399 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -50.99877 acc 0.66667 roc_auc 0.46000 prc_auc 0.64965[0m
[93maverage test of epoch 46: loss -51.35544 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -51.99305 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -52.34687 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -52.98731 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -53.33829 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -53.98155 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -54.32969 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -1.35275 acc 0.66667 roc_auc 0.43740 prc_auc 0.64990[0m
[93maverage test of epoch 0: loss -2.31782 acc 0.65789 roc_auc 0.95385 prc_auc 0.97886[0m
[92maverage training of epoch 1: loss -3.19916 acc 0.66667 roc_auc 0.44210 prc_auc 0.64653[0m
[93maverage test of epoch 1: loss -4.11372 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 2: loss -4.97608 acc 0.66667 roc_auc 0.41390 prc_auc 0.62271[0m
[93maverage test of epoch 2: loss -5.68734 acc 0.65789 roc_auc 0.95077 prc_auc 0.97702[0m
[92maverage training of epoch 3: loss -6.44609 acc 0.66667 roc_auc 0.40060 prc_auc 0.61110[0m
[93maverage test of epoch 3: loss -7.05100 acc 0.65789 roc_auc 0.95846 prc_auc 0.97574[0m
[92maverage training of epoch 4: loss -7.72046 acc 0.66667 roc_auc 0.38980 prc_auc 0.60373[0m
[93maverage test of epoch 4: loss -8.25165 acc 0.65789 roc_auc 0.94308 prc_auc 0.96232[0m
[92maverage training of epoch 5: loss -8.88577 acc 0.66667 roc_auc 0.38620 prc_auc 0.60062[0m
[93maverage test of epoch 5: loss -9.38232 acc 0.65789 roc_auc 0.86462 prc_auc 0.87965[0m
[92maverage training of epoch 6: loss -9.99891 acc 0.66667 roc_auc 0.38610 prc_auc 0.59971[0m
[93maverage test of epoch 6: loss -10.47451 acc 0.65789 roc_auc 0.92000 prc_auc 0.94526[0m
[92maverage training of epoch 7: loss -11.08127 acc 0.66667 roc_auc 0.38490 prc_auc 0.59300[0m
[93maverage test of epoch 7: loss -11.54236 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 8: loss -12.14338 acc 0.66667 roc_auc 0.38350 prc_auc 0.59082[0m
[93maverage test of epoch 8: loss -12.59352 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 9: loss -13.19123 acc 0.66667 roc_auc 0.37970 prc_auc 0.58602[0m
[93maverage test of epoch 9: loss -13.63263 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 10: loss -14.22860 acc 0.66667 roc_auc 0.38010 prc_auc 0.57854[0m
[93maverage test of epoch 10: loss -14.66269 acc 0.65789 roc_auc 0.74923 prc_auc 0.79432[0m
[92maverage training of epoch 11: loss -15.25800 acc 0.66667 roc_auc 0.38260 prc_auc 0.58101[0m
[93maverage test of epoch 11: loss -15.68580 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 12: loss -16.28119 acc 0.66667 roc_auc 0.37990 prc_auc 0.58318[0m
[93maverage test of epoch 12: loss -16.70343 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 13: loss -17.29947 acc 0.66667 roc_auc 0.38170 prc_auc 0.58282[0m
[93maverage test of epoch 13: loss -17.71669 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 14: loss -18.31380 acc 0.66667 roc_auc 0.37130 prc_auc 0.58027[0m
[93maverage test of epoch 14: loss -18.72640 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 15: loss -19.32491 acc 0.66667 roc_auc 0.38670 prc_auc 0.59247[0m
[93maverage test of epoch 15: loss -19.73321 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 16: loss -20.33337 acc 0.66667 roc_auc 0.38580 prc_auc 0.59400[0m
[93maverage test of epoch 16: loss -20.73763 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 17: loss -21.33963 acc 0.66667 roc_auc 0.37510 prc_auc 0.59163[0m
[93maverage test of epoch 17: loss -21.74006 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 18: loss -22.34408 acc 0.66667 roc_auc 0.38990 prc_auc 0.60425[0m
[93maverage test of epoch 18: loss -22.74083 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -23.34699 acc 0.66667 roc_auc 0.39400 prc_auc 0.60775[0m
[93maverage test of epoch 19: loss -23.74020 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -24.34861 acc 0.66667 roc_auc 0.40940 prc_auc 0.61722[0m
[93maverage test of epoch 20: loss -24.73839 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -25.34915 acc 0.66667 roc_auc 0.43580 prc_auc 0.63240[0m
[93maverage test of epoch 21: loss -25.73559 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -26.34877 acc 0.66667 roc_auc 0.44020 prc_auc 0.63795[0m
[93maverage test of epoch 22: loss -26.73195 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -27.34761 acc 0.66667 roc_auc 0.44670 prc_auc 0.64103[0m
[93maverage test of epoch 23: loss -27.72758 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -28.34577 acc 0.66667 roc_auc 0.44500 prc_auc 0.64353[0m
[93maverage test of epoch 24: loss -28.72260 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -29.34337 acc 0.66667 roc_auc 0.44000 prc_auc 0.64157[0m
[93maverage test of epoch 25: loss -29.71709 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -30.34048 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 26: loss -30.71113 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -31.33716 acc 0.66667 roc_auc 0.49500 prc_auc 0.66445[0m
[93maverage test of epoch 27: loss -31.70479 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -32.33350 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 28: loss -32.69812 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -33.32952 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 29: loss -33.69116 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -34.32528 acc 0.66667 roc_auc 0.44500 prc_auc 0.64353[0m
[93maverage test of epoch 30: loss -34.68396 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -35.32081 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 31: loss -35.67655 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -36.31614 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 32: loss -36.66895 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -37.31130 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 33: loss -37.66120 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -38.30633 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -38.65332 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -39.30121 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -39.64531 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -40.29599 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -40.63721 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -41.29068 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -41.62901 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -42.28529 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -42.62075 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -43.27982 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -43.61241 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -44.27429 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -44.60401 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -45.26871 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -45.59557 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -46.26307 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -46.58707 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -47.25740 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -47.57854 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -48.25168 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -48.56998 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -49.24594 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -49.56138 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -50.24016 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -50.55276 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -51.23436 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -51.54410 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -52.22854 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -52.53543 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -53.22269 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -53.52674 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -1.44197 acc 0.66225 roc_auc 0.42137 prc_auc 0.61290[0m
[93maverage test of epoch 0: loss -2.50422 acc 0.67568 roc_auc 0.83333 prc_auc 0.91751[0m
[92maverage training of epoch 1: loss -3.48850 acc 0.66225 roc_auc 0.42863 prc_auc 0.61164[0m
[93maverage test of epoch 1: loss -4.61888 acc 0.67568 roc_auc 0.84833 prc_auc 0.92548[0m
[92maverage training of epoch 2: loss -5.43437 acc 0.66225 roc_auc 0.40216 prc_auc 0.59622[0m
[93maverage test of epoch 2: loss -6.28013 acc 0.67568 roc_auc 0.85833 prc_auc 0.92419[0m
[92maverage training of epoch 3: loss -6.85292 acc 0.66225 roc_auc 0.39206 prc_auc 0.58775[0m
[93maverage test of epoch 3: loss -7.55454 acc 0.67568 roc_auc 0.86000 prc_auc 0.92404[0m
[92maverage training of epoch 4: loss -8.06046 acc 0.66225 roc_auc 0.38608 prc_auc 0.57750[0m
[93maverage test of epoch 4: loss -8.71937 acc 0.67568 roc_auc 0.86167 prc_auc 0.91588[0m
[92maverage training of epoch 5: loss -9.19269 acc 0.66225 roc_auc 0.38265 prc_auc 0.57532[0m
[93maverage test of epoch 5: loss -9.83283 acc 0.67568 roc_auc 0.84333 prc_auc 0.89024[0m
[92maverage training of epoch 6: loss -10.28580 acc 0.66225 roc_auc 0.38069 prc_auc 0.57316[0m
[93maverage test of epoch 6: loss -10.91661 acc 0.67568 roc_auc 0.84000 prc_auc 0.87252[0m
[92maverage training of epoch 7: loss -11.35503 acc 0.66225 roc_auc 0.37843 prc_auc 0.57178[0m
[93maverage test of epoch 7: loss -11.98123 acc 0.67568 roc_auc 0.66000 prc_auc 0.76849[0m
[92maverage training of epoch 8: loss -12.40829 acc 0.66225 roc_auc 0.37784 prc_auc 0.57109[0m
[93maverage test of epoch 8: loss -13.03255 acc 0.67568 roc_auc 0.72000 prc_auc 0.80439[0m
[92maverage training of epoch 9: loss -13.45021 acc 0.66225 roc_auc 0.37716 prc_auc 0.57087[0m
[93maverage test of epoch 9: loss -14.07420 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 10: loss -14.48374 acc 0.66225 roc_auc 0.37676 prc_auc 0.57007[0m
[93maverage test of epoch 10: loss -15.10856 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 11: loss -15.51086 acc 0.66225 roc_auc 0.37667 prc_auc 0.57100[0m
[93maverage test of epoch 11: loss -16.13729 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 12: loss -16.53298 acc 0.66225 roc_auc 0.37657 prc_auc 0.57030[0m
[93maverage test of epoch 12: loss -17.16157 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 13: loss -17.55113 acc 0.66225 roc_auc 0.37647 prc_auc 0.57048[0m
[93maverage test of epoch 13: loss -18.18230 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 14: loss -18.56608 acc 0.66225 roc_auc 0.37598 prc_auc 0.57063[0m
[93maverage test of epoch 14: loss -19.20014 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 15: loss -19.57842 acc 0.66225 roc_auc 0.37618 prc_auc 0.57188[0m
[93maverage test of epoch 15: loss -20.21561 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 16: loss -20.58861 acc 0.66225 roc_auc 0.37578 prc_auc 0.57151[0m
[93maverage test of epoch 16: loss -21.22914 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 17: loss -21.59702 acc 0.66225 roc_auc 0.37510 prc_auc 0.57160[0m
[93maverage test of epoch 17: loss -22.24104 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 18: loss -22.60395 acc 0.66225 roc_auc 0.37667 prc_auc 0.57343[0m
[93maverage test of epoch 18: loss -23.25158 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 19: loss -23.60965 acc 0.66225 roc_auc 0.37676 prc_auc 0.57133[0m
[93maverage test of epoch 19: loss -24.26098 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 20: loss -24.61429 acc 0.66225 roc_auc 0.37676 prc_auc 0.57318[0m
[93maverage test of epoch 20: loss -25.26942 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 21: loss -25.61805 acc 0.66225 roc_auc 0.37588 prc_auc 0.57449[0m
[93maverage test of epoch 21: loss -26.27705 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 22: loss -26.62107 acc 0.66225 roc_auc 0.37647 prc_auc 0.57652[0m
[93maverage test of epoch 22: loss -27.28399 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 23: loss -27.62344 acc 0.66225 roc_auc 0.37539 prc_auc 0.57513[0m
[93maverage test of epoch 23: loss -28.29034 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 24: loss -28.62528 acc 0.66225 roc_auc 0.37402 prc_auc 0.57990[0m
[93maverage test of epoch 24: loss -29.29619 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 25: loss -29.62665 acc 0.66225 roc_auc 0.37137 prc_auc 0.57740[0m
[93maverage test of epoch 25: loss -30.30161 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 26: loss -30.62763 acc 0.66225 roc_auc 0.37794 prc_auc 0.58639[0m
[93maverage test of epoch 26: loss -31.30666 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 27: loss -31.62827 acc 0.66225 roc_auc 0.38794 prc_auc 0.59488[0m
[93maverage test of epoch 27: loss -32.31141 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 28: loss -32.62861 acc 0.66225 roc_auc 0.38294 prc_auc 0.59435[0m
[93maverage test of epoch 28: loss -33.31588 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 29: loss -33.62872 acc 0.66225 roc_auc 0.38814 prc_auc 0.60271[0m
[93maverage test of epoch 29: loss -34.32013 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 30: loss -34.62861 acc 0.66225 roc_auc 0.43951 prc_auc 0.63208[0m
[93maverage test of epoch 30: loss -35.32417 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 31: loss -35.62832 acc 0.66225 roc_auc 0.36284 prc_auc 0.60009[0m
[93maverage test of epoch 31: loss -36.32805 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 32: loss -36.62787 acc 0.66225 roc_auc 0.42784 prc_auc 0.63226[0m
[93maverage test of epoch 32: loss -37.33178 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 33: loss -37.62727 acc 0.66225 roc_auc 0.39088 prc_auc 0.61963[0m
[93maverage test of epoch 33: loss -38.33537 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 34: loss -38.62656 acc 0.66225 roc_auc 0.35931 prc_auc 0.62372[0m
[93maverage test of epoch 34: loss -39.33885 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 35: loss -39.62574 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 35: loss -40.34225 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 36: loss -40.62484 acc 0.66225 roc_auc 0.43745 prc_auc 0.63606[0m
[93maverage test of epoch 36: loss -41.34555 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 37: loss -41.62386 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 37: loss -42.34879 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 38: loss -42.62282 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 38: loss -43.35197 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 39: loss -43.62171 acc 0.66225 roc_auc 0.44176 prc_auc 0.64652[0m
[93maverage test of epoch 39: loss -44.35509 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -44.62055 acc 0.66225 roc_auc 0.48441 prc_auc 0.65536[0m
[93maverage test of epoch 40: loss -45.35816 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -45.61935 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 41: loss -46.36119 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -46.61811 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 42: loss -47.36419 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -47.61685 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 43: loss -48.36716 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -48.61555 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 44: loss -49.37011 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -49.61424 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 45: loss -50.37302 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -50.61289 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 46: loss -51.37592 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -51.61153 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 47: loss -52.37880 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -52.61015 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 48: loss -53.38166 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -53.60875 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 49: loss -54.38451 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -0.55256 acc 0.65563 roc_auc 0.50137 prc_auc 0.71154[0m
[93maverage test of epoch 0: loss -1.26280 acc 0.67568 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 1: loss -2.09533 acc 0.66225 roc_auc 0.78686 prc_auc 0.87558[0m
[93maverage test of epoch 1: loss -3.13055 acc 0.67568 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 2: loss -3.66051 acc 0.73510 roc_auc 0.80569 prc_auc 0.86852[0m
[93maverage test of epoch 2: loss -4.36364 acc 0.81081 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 3: loss -4.85243 acc 0.83444 roc_auc 0.76588 prc_auc 0.82443[0m
[93maverage test of epoch 3: loss -5.38817 acc 0.81081 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 4: loss -5.88375 acc 0.82119 roc_auc 0.76000 prc_auc 0.82738[0m
[93maverage test of epoch 4: loss -6.52787 acc 0.83784 roc_auc 0.94333 prc_auc 0.97748[0mUsing backend: pytorch
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))

[92maverage training of epoch 5: loss -6.95882 acc 0.84768 roc_auc 0.77804 prc_auc 0.82090[0m
[93maverage test of epoch 5: loss -7.36579 acc 0.81081 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 6: loss -7.88226 acc 0.84768 roc_auc 0.76588 prc_auc 0.80737[0m
[93maverage test of epoch 6: loss -8.48186 acc 0.83784 roc_auc 0.94833 prc_auc 0.97770[0m
[92maverage training of epoch 7: loss -8.77722 acc 0.84768 roc_auc 0.78402 prc_auc 0.81491[0m
[93maverage test of epoch 7: loss -9.39215 acc 0.83784 roc_auc 0.94667 prc_auc 0.97610[0m
[92maverage training of epoch 8: loss -9.74650 acc 0.84768 roc_auc 0.77245 prc_auc 0.81655[0m
[93maverage test of epoch 8: loss -10.30821 acc 0.83784 roc_auc 0.94333 prc_auc 0.97415[0m
[92maverage training of epoch 9: loss -10.60297 acc 0.84106 roc_auc 0.75431 prc_auc 0.79524[0m
[93maverage test of epoch 9: loss -11.21220 acc 0.83784 roc_auc 0.94000 prc_auc 0.96912[0m
[92maverage training of epoch 10: loss -11.51436 acc 0.84768 roc_auc 0.77137 prc_auc 0.81205[0m
[93maverage test of epoch 10: loss -12.10090 acc 0.83784 roc_auc 0.80333 prc_auc 0.84711[0m
[92maverage training of epoch 11: loss -12.34319 acc 0.84106 roc_auc 0.75392 prc_auc 0.79755[0m
[93maverage test of epoch 11: loss -12.98202 acc 0.83784 roc_auc 0.77333 prc_auc 0.82479[0m
[92maverage training of epoch 12: loss -13.19848 acc 0.84106 roc_auc 0.75284 prc_auc 0.79311[0m
[93maverage test of epoch 12: loss -13.85306 acc 0.83784 roc_auc 0.77333 prc_auc 0.82479[0m
[92maverage training of epoch 13: loss -14.04641 acc 0.84106 roc_auc 0.75941 prc_auc 0.81006[0m
[93maverage test of epoch 13: loss -14.71708 acc 0.83784 roc_auc 0.77333 prc_auc 0.82479[0m
[92maverage training of epoch 14: loss -14.90833 acc 0.86093 roc_auc 0.79608 prc_auc 0.83510[0m
[93maverage test of epoch 14: loss -15.16988 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 15: loss -15.75310 acc 0.85430 roc_auc 0.78010 prc_auc 0.82912[0m
[93maverage test of epoch 15: loss -15.99601 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 16: loss -16.70638 acc 0.85430 roc_auc 0.80608 prc_auc 0.84617[0m
[93maverage test of epoch 16: loss -16.82849 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 17: loss -17.34580 acc 0.85430 roc_auc 0.80598 prc_auc 0.84966[0m
[93maverage test of epoch 17: loss -17.64166 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 18: loss -17.48056 acc 0.81457 roc_auc 0.80275 prc_auc 0.85679[0m
[93maverage test of epoch 18: loss -18.43081 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 19: loss -19.09721 acc 0.85430 roc_auc 0.80873 prc_auc 0.85073[0m
[93maverage test of epoch 19: loss -19.25063 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 20: loss -20.12354 acc 0.87417 roc_auc 0.85049 prc_auc 0.88314[0m
[93maverage test of epoch 20: loss -20.59128 acc 0.83784 roc_auc 0.77333 prc_auc 0.82479[0m
[92maverage training of epoch 21: loss -20.79892 acc 0.86755 roc_auc 0.83843 prc_auc 0.87367[0m
[93maverage test of epoch 21: loss -21.42782 acc 0.83784 roc_auc 0.77333 prc_auc 0.82479[0m
[92maverage training of epoch 22: loss -21.58586 acc 0.85430 roc_auc 0.81206 prc_auc 0.85168[0m
[93maverage test of epoch 22: loss -21.69041 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 23: loss -22.47511 acc 0.86755 roc_auc 0.84412 prc_auc 0.88037[0m
[93maverage test of epoch 23: loss -22.49972 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 24: loss -23.54898 acc 0.88079 roc_auc 0.84255 prc_auc 0.87572[0m
[93maverage test of epoch 24: loss -23.31789 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 25: loss -23.88388 acc 0.85430 roc_auc 0.82461 prc_auc 0.86373[0m
[93maverage test of epoch 25: loss -24.12080 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 26: loss -24.94998 acc 0.86093 roc_auc 0.82216 prc_auc 0.85950[0m
[93maverage test of epoch 26: loss -24.93177 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 27: loss -25.77593 acc 0.86093 roc_auc 0.82216 prc_auc 0.85950[0m
[93maverage test of epoch 27: loss -25.74253 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 28: loss -26.60116 acc 0.86093 roc_auc 0.82235 prc_auc 0.85956[0m
[93maverage test of epoch 28: loss -26.55269 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 29: loss -27.42596 acc 0.86093 roc_auc 0.82235 prc_auc 0.85956[0m
[93maverage test of epoch 29: loss -27.36230 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 30: loss -28.25038 acc 0.86093 roc_auc 0.82235 prc_auc 0.85956[0m
[93maverage test of epoch 30: loss -28.17145 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 31: loss -29.07445 acc 0.86093 roc_auc 0.82235 prc_auc 0.85956[0m
[93maverage test of epoch 31: loss -28.98022 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 32: loss -29.89821 acc 0.86093 roc_auc 0.82255 prc_auc 0.85962[0m
[93maverage test of epoch 32: loss -29.78863 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 33: loss -30.72166 acc 0.86093 roc_auc 0.82275 prc_auc 0.85968[0m
[93maverage test of epoch 33: loss -30.59675 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 34: loss -31.54481 acc 0.86093 roc_auc 0.82314 prc_auc 0.85979[0m
[93maverage test of epoch 34: loss -31.40460 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 35: loss -31.30285 acc 0.74172 roc_auc 0.81745 prc_auc 0.86241[0m
[93maverage test of epoch 35: loss -32.38905 acc 0.67568 roc_auc 0.90500 prc_auc 0.93756[0m
[92maverage training of epoch 36: loss -32.63813 acc 0.66225 roc_auc 0.82667 prc_auc 0.86444[0m
[93maverage test of epoch 36: loss -33.26482 acc 0.67568 roc_auc 0.80333 prc_auc 0.84711[0m
[92maverage training of epoch 37: loss -33.54797 acc 0.70861 roc_auc 0.78765 prc_auc 0.83186[0m
[93maverage test of epoch 37: loss -33.30247 acc 0.86486 roc_auc 0.90167 prc_auc 0.93597[0m
[92maverage training of epoch 38: loss -34.48524 acc 0.86093 roc_auc 0.82912 prc_auc 0.86504[0m
[93maverage test of epoch 38: loss -35.17815 acc 0.83784 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 39: loss -35.56016 acc 0.86093 roc_auc 0.82255 prc_auc 0.85960[0m
[93maverage test of epoch 39: loss -35.42007 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 40: loss -35.83571 acc 0.85430 roc_auc 0.83392 prc_auc 0.87075[0m
[93maverage test of epoch 40: loss -36.21341 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 41: loss -37.20159 acc 0.86093 roc_auc 0.82294 prc_auc 0.85971[0m
[93maverage test of epoch 41: loss -37.01957 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 42: loss -38.02247 acc 0.86093 roc_auc 0.82314 prc_auc 0.85976[0m
[93maverage test of epoch 42: loss -37.82593 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 43: loss -38.84314 acc 0.86093 roc_auc 0.82314 prc_auc 0.85976[0m
[93maverage test of epoch 43: loss -38.63223 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 44: loss -39.66375 acc 0.86093 roc_auc 0.82275 prc_auc 0.85968[0m
[93maverage test of epoch 44: loss -39.43846 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 45: loss -40.48431 acc 0.86093 roc_auc 0.82294 prc_auc 0.85974[0m
[93maverage test of epoch 45: loss -40.24462 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 46: loss -41.30484 acc 0.86093 roc_auc 0.82314 prc_auc 0.85980[0m
[93maverage test of epoch 46: loss -41.05072 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 47: loss -42.12533 acc 0.86093 roc_auc 0.82333 prc_auc 0.85985[0m
[93maverage test of epoch 47: loss -41.85676 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 48: loss -42.94580 acc 0.86093 roc_auc 0.82392 prc_auc 0.85998[0m
[93maverage test of epoch 48: loss -42.66275 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 49: loss -43.76623 acc 0.86093 roc_auc 0.82392 prc_auc 0.85998[0m
[93maverage test of epoch 49: loss -43.46871 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.69203 ROC_AUC (avg): 0.553 PRC_AUC (avg): 0.6937 

Average forward propagation time taken(ms): 2.4800223663986296
Average backward propagation time taken(ms): 0.8720815241724152

