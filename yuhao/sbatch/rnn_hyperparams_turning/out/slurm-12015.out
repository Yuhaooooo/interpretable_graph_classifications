# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 1)
('lr', 0.0001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-07-52-37/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-07-52-37/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 8,
 'epochs': 100,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 8,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.0001,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 2,
 'num_workers': 8,
 'number_of_mlp_layer': 1,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-18-07-52-37',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 100, 'learning_rate': 0.0001, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.37930 acc 0.33333 roc_auc 0.42080 prc_auc 0.62662[0m
[93maverage test of epoch 0: loss -0.60572 acc 0.34211 roc_auc 0.34154 prc_auc 0.62948[0m
[92maverage training of epoch 1: loss -0.87085 acc 0.33333 roc_auc 0.37420 prc_auc 0.60448[0m
[93maverage test of epoch 1: loss -1.10631 acc 0.34211 roc_auc 0.31385 prc_auc 0.57681[0m
[92maverage training of epoch 2: loss -1.32284 acc 0.34667 roc_auc 0.43360 prc_auc 0.66432[0m
[93maverage test of epoch 2: loss -1.54005 acc 0.39474 roc_auc 0.49846 prc_auc 0.75128[0m
[92maverage training of epoch 3: loss -1.74494 acc 0.42667 roc_auc 0.42340 prc_auc 0.64961[0m
[93maverage test of epoch 3: loss -1.99432 acc 0.42105 roc_auc 0.48308 prc_auc 0.67861[0m
[92maverage training of epoch 4: loss -2.20789 acc 0.56667 roc_auc 0.46820 prc_auc 0.63502[0m
[93maverage test of epoch 4: loss -2.44027 acc 0.57895 roc_auc 0.57538 prc_auc 0.76111[0m
[92maverage training of epoch 5: loss -2.66055 acc 0.60667 roc_auc 0.47480 prc_auc 0.68650[0m
[93maverage test of epoch 5: loss -2.90465 acc 0.63158 roc_auc 0.34769 prc_auc 0.57398[0m
[92maverage training of epoch 6: loss -3.14219 acc 0.65333 roc_auc 0.53760 prc_auc 0.69615[0m
[93maverage test of epoch 6: loss -3.37440 acc 0.63158 roc_auc 0.56000 prc_auc 0.67663[0m
[92maverage training of epoch 7: loss -3.63487 acc 0.66667 roc_auc 0.45460 prc_auc 0.64064[0m
[93maverage test of epoch 7: loss -3.99554 acc 0.65789 roc_auc 0.50769 prc_auc 0.67531[0m
[92maverage training of epoch 8: loss -4.40058 acc 0.66667 roc_auc 0.42760 prc_auc 0.64357[0m
[93maverage test of epoch 8: loss -4.75752 acc 0.65789 roc_auc 0.58769 prc_auc 0.76533[0m
[92maverage training of epoch 9: loss -5.16997 acc 0.66667 roc_auc 0.44120 prc_auc 0.62965[0m
[93maverage test of epoch 9: loss -5.53143 acc 0.65789 roc_auc 0.51692 prc_auc 0.67390[0m
[92maverage training of epoch 10: loss -5.89278 acc 0.66667 roc_auc 0.37300 prc_auc 0.61844[0m
[93maverage test of epoch 10: loss -6.29307 acc 0.65789 roc_auc 0.45538 prc_auc 0.61606[0m
[92maverage training of epoch 11: loss -6.66069 acc 0.66667 roc_auc 0.45140 prc_auc 0.65558[0m
[93maverage test of epoch 11: loss -7.00430 acc 0.65789 roc_auc 0.55385 prc_auc 0.70745[0m
[92maverage training of epoch 12: loss -7.37979 acc 0.66667 roc_auc 0.49500 prc_auc 0.71375[0m
[93maverage test of epoch 12: loss -7.72508 acc 0.65789 roc_auc 0.55692 prc_auc 0.76474[0m
[92maverage training of epoch 13: loss -8.10295 acc 0.66667 roc_auc 0.47000 prc_auc 0.65087[0m
[93maverage test of epoch 13: loss -8.38707 acc 0.65789 roc_auc 0.32308 prc_auc 0.55228[0m
[92maverage training of epoch 14: loss -8.78228 acc 0.66667 roc_auc 0.41700 prc_auc 0.63282[0m
[93maverage test of epoch 14: loss -9.09129 acc 0.65789 roc_auc 0.44308 prc_auc 0.61512[0m
[92maverage training of epoch 15: loss -9.46081 acc 0.66667 roc_auc 0.42220 prc_auc 0.60979[0m
[93maverage test of epoch 15: loss -9.76611 acc 0.65789 roc_auc 0.34154 prc_auc 0.59571[0m
[92maverage training of epoch 16: loss -10.14035 acc 0.66667 roc_auc 0.40240 prc_auc 0.59888[0m
[93maverage test of epoch 16: loss -10.42115 acc 0.65789 roc_auc 0.48923 prc_auc 0.66326[0m
[92maverage training of epoch 17: loss -10.79804 acc 0.66667 roc_auc 0.42500 prc_auc 0.63352[0m
[93maverage test of epoch 17: loss -11.10102 acc 0.65789 roc_auc 0.49538 prc_auc 0.61882[0m
[92maverage training of epoch 18: loss -11.44696 acc 0.66667 roc_auc 0.39780 prc_auc 0.63433[0m
[93maverage test of epoch 18: loss -11.74287 acc 0.65789 roc_auc 0.57538 prc_auc 0.71747[0m
[92maverage training of epoch 19: loss -12.10748 acc 0.66667 roc_auc 0.43260 prc_auc 0.64202[0m
[93maverage test of epoch 19: loss -12.37266 acc 0.65789 roc_auc 0.41846 prc_auc 0.64505[0m
[92maverage training of epoch 20: loss -12.76948 acc 0.66667 roc_auc 0.38160 prc_auc 0.60914[0m
[93maverage test of epoch 20: loss -13.03654 acc 0.65789 roc_auc 0.49077 prc_auc 0.66562[0m
[92maverage training of epoch 21: loss -13.42912 acc 0.66667 roc_auc 0.37420 prc_auc 0.59797[0m
[93maverage test of epoch 21: loss -13.69684 acc 0.65789 roc_auc 0.48000 prc_auc 0.67234[0m
[92maverage training of epoch 22: loss -14.09414 acc 0.66667 roc_auc 0.40280 prc_auc 0.61278[0m
[93maverage test of epoch 22: loss -14.36741 acc 0.65789 roc_auc 0.40615 prc_auc 0.58987[0m
[92maverage training of epoch 23: loss -14.76486 acc 0.66667 roc_auc 0.38950 prc_auc 0.61917[0m
[93maverage test of epoch 23: loss -15.05869 acc 0.65789 roc_auc 0.40615 prc_auc 0.60534[0m
[92maverage training of epoch 24: loss -15.45998 acc 0.66667 roc_auc 0.41100 prc_auc 0.62664[0m
[93maverage test of epoch 24: loss -15.76308 acc 0.65789 roc_auc 0.54308 prc_auc 0.70754[0m
[92maverage training of epoch 25: loss -16.14911 acc 0.66667 roc_auc 0.41060 prc_auc 0.61191[0m
[93maverage test of epoch 25: loss -16.43562 acc 0.65789 roc_auc 0.42308 prc_auc 0.62124[0m
[92maverage training of epoch 26: loss -16.85812 acc 0.66667 roc_auc 0.38620 prc_auc 0.60336[0m
[93maverage test of epoch 26: loss -17.15104 acc 0.65789 roc_auc 0.45231 prc_auc 0.65722[0m
[92maverage training of epoch 27: loss -17.56908 acc 0.66667 roc_auc 0.41000 prc_auc 0.61940[0m
[93maverage test of epoch 27: loss -17.85321 acc 0.65789 roc_auc 0.68769 prc_auc 0.79186[0m
[92maverage training of epoch 28: loss -18.30642 acc 0.66667 roc_auc 0.41200 prc_auc 0.61596[0m
[93maverage test of epoch 28: loss -18.58724 acc 0.65789 roc_auc 0.51846 prc_auc 0.71424[0m
[92maverage training of epoch 29: loss -19.03409 acc 0.66667 roc_auc 0.38130 prc_auc 0.59264[0m
[93maverage test of epoch 29: loss -19.35531 acc 0.65789 roc_auc 0.52615 prc_auc 0.67413[0m
[92maverage training of epoch 30: loss -19.79528 acc 0.66667 roc_auc 0.40020 prc_auc 0.61250[0m
[93maverage test of epoch 30: loss -20.10441 acc 0.65789 roc_auc 0.68154 prc_auc 0.79338[0m
[92maverage training of epoch 31: loss -20.55175 acc 0.66667 roc_auc 0.39890 prc_auc 0.61072[0m
[93maverage test of epoch 31: loss -20.85555 acc 0.65789 roc_auc 0.60154 prc_auc 0.69195[0m
[92maverage training of epoch 32: loss -21.33361 acc 0.66667 roc_auc 0.39170 prc_auc 0.60383[0m
[93maverage test of epoch 32: loss -21.64125 acc 0.65789 roc_auc 0.45385 prc_auc 0.71205[0m
[92maverage training of epoch 33: loss -22.12450 acc 0.66667 roc_auc 0.40550 prc_auc 0.61635[0m
[93maverage test of epoch 33: loss -22.43227 acc 0.65789 roc_auc 0.53077 prc_auc 0.67453[0m
[92maverage training of epoch 34: loss -22.92510 acc 0.66667 roc_auc 0.40000 prc_auc 0.60986[0m
[93maverage test of epoch 34: loss -23.22346 acc 0.65789 roc_auc 0.46615 prc_auc 0.63735[0m
[92maverage training of epoch 35: loss -23.74030 acc 0.66667 roc_auc 0.40040 prc_auc 0.61319[0m
[93maverage test of epoch 35: loss -24.05458 acc 0.65789 roc_auc 0.55538 prc_auc 0.71830[0m
[92maverage training of epoch 36: loss -24.56560 acc 0.66667 roc_auc 0.37410 prc_auc 0.58987[0m
[93maverage test of epoch 36: loss -24.90442 acc 0.65789 roc_auc 0.54000 prc_auc 0.67579[0m
[92maverage training of epoch 37: loss -25.41305 acc 0.66667 roc_auc 0.42080 prc_auc 0.61790[0m
[93maverage test of epoch 37: loss -25.73999 acc 0.65789 roc_auc 0.54154 prc_auc 0.68130[0m
[92maverage training of epoch 38: loss -26.27200 acc 0.66667 roc_auc 0.39450 prc_auc 0.60955[0m
[93maverage test of epoch 38: loss -26.58621 acc 0.65789 roc_auc 0.49077 prc_auc 0.65499[0m
[92maverage training of epoch 39: loss -27.13554 acc 0.66667 roc_auc 0.39930 prc_auc 0.61865[0m
[93maverage test of epoch 39: loss -27.46800 acc 0.65789 roc_auc 0.47231 prc_auc 0.64727[0m
[92maverage training of epoch 40: loss -28.02488 acc 0.66667 roc_auc 0.38300 prc_auc 0.60646[0m
[93maverage test of epoch 40: loss -28.34532 acc 0.65789 roc_auc 0.46000 prc_auc 0.64041[0m
[92maverage training of epoch 41: loss -28.92218 acc 0.66667 roc_auc 0.40340 prc_auc 0.62264[0m
[93maverage test of epoch 41: loss -29.24972 acc 0.65789 roc_auc 0.58923 prc_auc 0.70230[0m
[92maverage training of epoch 42: loss -29.82314 acc 0.66667 roc_auc 0.43300 prc_auc 0.63902[0m
[93maverage test of epoch 42: loss -30.16218 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -30.75029 acc 0.66667 roc_auc 0.44500 prc_auc 0.64349[0m
[93maverage test of epoch 43: loss -31.09292 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -31.68451 acc 0.66667 roc_auc 0.46000 prc_auc 0.64944[0m
[93maverage test of epoch 44: loss -32.03154 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -32.62762 acc 0.66667 roc_auc 0.45000 prc_auc 0.64540[0m
[93maverage test of epoch 45: loss -32.97643 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -33.58828 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -33.94407 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -34.56351 acc 0.66667 roc_auc 0.42000 prc_auc 0.63495[0m
[93maverage test of epoch 47: loss -34.91038 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -35.54893 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -35.90596 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -36.54769 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -36.90984 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 50: loss -37.56275 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 50: loss -37.92420 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 51: loss -38.58469 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 51: loss -38.94702 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 52: loss -39.62667 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 52: loss -39.98692 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 53: loss -40.67503 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 53: loss -41.04468 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 54: loss -41.74332 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 54: loss -42.11195 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 55: loss -42.82358 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 55: loss -43.19684 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 56: loss -43.91693 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 56: loss -44.29208 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 57: loss -45.02193 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 57: loss -45.40163 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 58: loss -46.14511 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 58: loss -46.52087 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 59: loss -47.28002 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 59: loss -47.66141 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 60: loss -48.42624 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 60: loss -48.81020 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 61: loss -49.59103 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 61: loss -49.97722 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 62: loss -50.76541 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 62: loss -51.15568 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 63: loss -51.95591 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 63: loss -52.34476 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 64: loss -53.15671 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 64: loss -53.54585 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 65: loss -54.37323 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 65: loss -54.76814 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 66: loss -55.60548 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 66: loss -56.00016 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 67: loss -56.84921 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 67: loss -57.24356 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 68: loss -58.10689 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 68: loss -58.50607 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 69: loss -59.37937 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 69: loss -59.78100 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 70: loss -60.66720 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 70: loss -61.06954 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 71: loss -61.96844 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 71: loss -62.37428 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 72: loss -63.28366 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 72: loss -63.69237 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 73: loss -64.61452 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 73: loss -65.02360 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 74: loss -65.95966 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 74: loss -66.36973 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 75: loss -67.31841 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 75: loss -67.73248 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 76: loss -68.69293 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 76: loss -69.10744 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 77: loss -70.08262 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 77: loss -70.49730 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 78: loss -71.48683 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 78: loss -71.90564 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 79: loss -72.90560 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 79: loss -73.32477 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 80: loss -74.33809 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 80: loss -74.75754 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 81: loss -75.78680 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 81: loss -76.21008 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 82: loss -77.25105 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 82: loss -77.67688 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 83: loss -78.72936 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 83: loss -79.15533 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 84: loss -80.22341 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 84: loss -80.65000 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 85: loss -81.73196 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 85: loss -82.16055 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 86: loss -83.25510 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 86: loss -83.68761 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 87: loss -84.79444 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 87: loss -85.22701 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 88: loss -86.34760 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 88: loss -86.78129 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 89: loss -87.91708 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 89: loss -88.35361 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -89.50152 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 90: loss -89.93895 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 91: loss -91.10045 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 91: loss -91.53878 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 92: loss -92.71536 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 92: loss -93.15437 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 93: loss -94.34520 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 93: loss -94.78533 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 94: loss -95.99002 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 94: loss -96.43164 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 95: loss -97.65015 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 95: loss -98.09345 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 96: loss -99.32584 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 96: loss -99.76972 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 97: loss -101.01623 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 97: loss -101.46141 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 98: loss -102.72230 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 98: loss -103.16862 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -104.44357 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 99: loss -104.88914 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.80885 acc 0.34667 roc_auc 0.54900 prc_auc 0.71800[0m
[93maverage test of epoch 0: loss -1.08198 acc 0.34211 roc_auc 0.35385 prc_auc 0.57272[0m
[92maverage training of epoch 1: loss -1.33734 acc 0.33333 roc_auc 0.46320 prc_auc 0.67540[0m
[93maverage test of epoch 1: loss -1.63880 acc 0.34211 roc_auc 0.51385 prc_auc 0.67410[0m
[92maverage training of epoch 2: loss -1.93618 acc 0.33333 roc_auc 0.56900 prc_auc 0.73998[0m
[93maverage test of epoch 2: loss -2.28166 acc 0.34211 roc_auc 0.60615 prc_auc 0.81928[0m
[92maverage training of epoch 3: loss -2.63383 acc 0.33333 roc_auc 0.43680 prc_auc 0.65697[0m
[93maverage test of epoch 3: loss -2.96987 acc 0.34211 roc_auc 0.53231 prc_auc 0.70816[0m
[92maverage training of epoch 4: loss -3.24053 acc 0.33333 roc_auc 0.46440 prc_auc 0.64140[0m
[93maverage test of epoch 4: loss -3.53548 acc 0.34211 roc_auc 0.43077 prc_auc 0.66961[0m
[92maverage training of epoch 5: loss -3.77364 acc 0.33333 roc_auc 0.54600 prc_auc 0.70796[0m
[93maverage test of epoch 5: loss -4.07906 acc 0.34211 roc_auc 0.59385 prc_auc 0.77956[0m
[92maverage training of epoch 6: loss -4.31672 acc 0.33333 roc_auc 0.53520 prc_auc 0.68318[0m
[93maverage test of epoch 6: loss -4.57110 acc 0.34211 roc_auc 0.50154 prc_auc 0.65408[0m
[92maverage training of epoch 7: loss -4.83130 acc 0.33333 roc_auc 0.48720 prc_auc 0.63929[0m
[93maverage test of epoch 7: loss -5.14139 acc 0.34211 roc_auc 0.36000 prc_auc 0.62700[0m
[92maverage training of epoch 8: loss -5.41842 acc 0.33333 roc_auc 0.45760 prc_auc 0.65906[0m
[93maverage test of epoch 8: loss -5.75977 acc 0.34211 roc_auc 0.41538 prc_auc 0.63016[0m
[92maverage training of epoch 9: loss -6.13021 acc 0.33333 roc_auc 0.43300 prc_auc 0.63428[0m
[93maverage test of epoch 9: loss -6.53874 acc 0.34211 roc_auc 0.49538 prc_auc 0.68566[0m
[92maverage training of epoch 10: loss -7.00047 acc 0.44667 roc_auc 0.45000 prc_auc 0.66653[0m
[93maverage test of epoch 10: loss -7.48531 acc 0.65789 roc_auc 0.44308 prc_auc 0.60386[0m
[92maverage training of epoch 11: loss -8.00005 acc 0.66667 roc_auc 0.47120 prc_auc 0.66742[0m
[93maverage test of epoch 11: loss -8.46426 acc 0.65789 roc_auc 0.32308 prc_auc 0.59457[0m
[92maverage training of epoch 12: loss -8.91880 acc 0.66667 roc_auc 0.45360 prc_auc 0.63228[0m
[93maverage test of epoch 12: loss -9.33030 acc 0.65789 roc_auc 0.44923 prc_auc 0.69323[0m
[92maverage training of epoch 13: loss -9.70707 acc 0.66667 roc_auc 0.45680 prc_auc 0.63842[0m
[93maverage test of epoch 13: loss -10.09823 acc 0.65789 roc_auc 0.57231 prc_auc 0.68574[0m
[92maverage training of epoch 14: loss -10.43611 acc 0.66667 roc_auc 0.43320 prc_auc 0.61405[0m
[93maverage test of epoch 14: loss -10.78588 acc 0.65789 roc_auc 0.59077 prc_auc 0.76142[0m
[92maverage training of epoch 15: loss -11.11385 acc 0.66667 roc_auc 0.44660 prc_auc 0.62953[0m
[93maverage test of epoch 15: loss -11.40853 acc 0.65789 roc_auc 0.45846 prc_auc 0.74428[0m
[92maverage training of epoch 16: loss -11.75853 acc 0.66667 roc_auc 0.47320 prc_auc 0.68082[0m
[93maverage test of epoch 16: loss -12.07374 acc 0.65789 roc_auc 0.50154 prc_auc 0.70717[0m
[92maverage training of epoch 17: loss -12.41614 acc 0.66667 roc_auc 0.44520 prc_auc 0.63985[0m
[93maverage test of epoch 17: loss -12.74381 acc 0.65789 roc_auc 0.55692 prc_auc 0.74261[0m
[92maverage training of epoch 18: loss -13.03985 acc 0.66667 roc_auc 0.43760 prc_auc 0.62135[0m
[93maverage test of epoch 18: loss -13.36243 acc 0.65789 roc_auc 0.55385 prc_auc 0.71085[0m
[92maverage training of epoch 19: loss -13.68955 acc 0.66667 roc_auc 0.44420 prc_auc 0.63158[0m
[93maverage test of epoch 19: loss -13.99604 acc 0.65789 roc_auc 0.28000 prc_auc 0.55155[0m
[92maverage training of epoch 20: loss -14.33542 acc 0.66667 roc_auc 0.46100 prc_auc 0.64403[0m
[93maverage test of epoch 20: loss -14.66201 acc 0.65789 roc_auc 0.41846 prc_auc 0.59830[0m
[92maverage training of epoch 21: loss -14.97313 acc 0.66667 roc_auc 0.44840 prc_auc 0.62171[0m
[93maverage test of epoch 21: loss -15.30807 acc 0.65789 roc_auc 0.53538 prc_auc 0.70230[0m
[92maverage training of epoch 22: loss -15.64411 acc 0.66667 roc_auc 0.45940 prc_auc 0.65827[0m
[93maverage test of epoch 22: loss -15.97096 acc 0.65789 roc_auc 0.56308 prc_auc 0.74106[0m
[92maverage training of epoch 23: loss -16.30653 acc 0.66667 roc_auc 0.45920 prc_auc 0.64657[0m
[93maverage test of epoch 23: loss -16.62954 acc 0.65789 roc_auc 0.52923 prc_auc 0.75285[0m
[92maverage training of epoch 24: loss -16.98851 acc 0.66667 roc_auc 0.44080 prc_auc 0.63447[0m
[93maverage test of epoch 24: loss -17.31392 acc 0.65789 roc_auc 0.62769 prc_auc 0.74999[0m
[92maverage training of epoch 25: loss -17.67136 acc 0.66667 roc_auc 0.45460 prc_auc 0.65413[0m
[93maverage test of epoch 25: loss -17.99039 acc 0.65789 roc_auc 0.58462 prc_auc 0.76381[0m
[92maverage training of epoch 26: loss -18.35925 acc 0.66667 roc_auc 0.44760 prc_auc 0.63256[0m
[93maverage test of epoch 26: loss -18.70346 acc 0.65789 roc_auc 0.52308 prc_auc 0.70831[0m
[92maverage training of epoch 27: loss -19.06726 acc 0.66667 roc_auc 0.44240 prc_auc 0.63580[0m
[93maverage test of epoch 27: loss -19.40234 acc 0.65789 roc_auc 0.47846 prc_auc 0.68934[0m
[92maverage training of epoch 28: loss -19.78417 acc 0.66667 roc_auc 0.45040 prc_auc 0.62892[0m
[93maverage test of epoch 28: loss -20.13306 acc 0.65789 roc_auc 0.42462 prc_auc 0.64867[0m
[92maverage training of epoch 29: loss -20.50369 acc 0.66667 roc_auc 0.45620 prc_auc 0.63694[0m
[93maverage test of epoch 29: loss -20.84961 acc 0.65789 roc_auc 0.53231 prc_auc 0.70346[0m
[92maverage training of epoch 30: loss -21.24027 acc 0.66667 roc_auc 0.45580 prc_auc 0.62944[0m
[93maverage test of epoch 30: loss -21.59219 acc 0.65789 roc_auc 0.58154 prc_auc 0.71567[0m
[92maverage training of epoch 31: loss -21.98877 acc 0.66667 roc_auc 0.45480 prc_auc 0.63140[0m
[93maverage test of epoch 31: loss -22.34126 acc 0.65789 roc_auc 0.33077 prc_auc 0.55327[0m
[92maverage training of epoch 32: loss -22.74787 acc 0.66667 roc_auc 0.45240 prc_auc 0.64895[0m
[93maverage test of epoch 32: loss -23.08599 acc 0.65789 roc_auc 0.44000 prc_auc 0.67176[0m
[92maverage training of epoch 33: loss -23.51041 acc 0.66667 roc_auc 0.45440 prc_auc 0.63774[0m
[93maverage test of epoch 33: loss -23.87311 acc 0.65789 roc_auc 0.38308 prc_auc 0.58020[0m
[92maverage training of epoch 34: loss -24.28674 acc 0.66667 roc_auc 0.45240 prc_auc 0.63696[0m
[93maverage test of epoch 34: loss -24.66469 acc 0.65789 roc_auc 0.49385 prc_auc 0.66379[0m
[92maverage training of epoch 35: loss -25.08451 acc 0.66667 roc_auc 0.45500 prc_auc 0.63800[0m
[93maverage test of epoch 35: loss -25.44592 acc 0.65789 roc_auc 0.64000 prc_auc 0.81908[0m
[92maverage training of epoch 36: loss -25.88519 acc 0.66667 roc_auc 0.45740 prc_auc 0.64183[0m
[93maverage test of epoch 36: loss -26.24880 acc 0.65789 roc_auc 0.39846 prc_auc 0.61360[0m
[92maverage training of epoch 37: loss -26.69708 acc 0.66667 roc_auc 0.45340 prc_auc 0.64224[0m
[93maverage test of epoch 37: loss -27.07231 acc 0.65789 roc_auc 0.62462 prc_auc 0.80521[0m
[92maverage training of epoch 38: loss -27.52643 acc 0.66667 roc_auc 0.44760 prc_auc 0.63790[0m
[93maverage test of epoch 38: loss -27.91237 acc 0.65789 roc_auc 0.54769 prc_auc 0.67610[0m
[92maverage training of epoch 39: loss -28.36616 acc 0.66667 roc_auc 0.45660 prc_auc 0.63755[0m
[93maverage test of epoch 39: loss -28.75311 acc 0.65789 roc_auc 0.48923 prc_auc 0.64543[0m
[92maverage training of epoch 40: loss -29.21512 acc 0.66667 roc_auc 0.45640 prc_auc 0.64720[0m
[93maverage test of epoch 40: loss -29.61075 acc 0.65789 roc_auc 0.26769 prc_auc 0.56189[0m
[92maverage training of epoch 41: loss -30.07551 acc 0.66667 roc_auc 0.44650 prc_auc 0.63692[0m
[93maverage test of epoch 41: loss -30.47292 acc 0.65789 roc_auc 0.68308 prc_auc 0.73902[0m
[92maverage training of epoch 42: loss -30.95300 acc 0.66667 roc_auc 0.45960 prc_auc 0.64050[0m
[93maverage test of epoch 42: loss -31.34447 acc 0.65789 roc_auc 0.37077 prc_auc 0.59816[0m
[92maverage training of epoch 43: loss -31.84499 acc 0.66667 roc_auc 0.45570 prc_auc 0.63778[0m
[93maverage test of epoch 43: loss -32.26115 acc 0.65789 roc_auc 0.66462 prc_auc 0.80207[0m
[92maverage training of epoch 44: loss -32.78443 acc 0.66667 roc_auc 0.46460 prc_auc 0.64547[0m
[93maverage test of epoch 44: loss -33.20433 acc 0.65789 roc_auc 0.51077 prc_auc 0.72632[0m
[92maverage training of epoch 45: loss -33.74175 acc 0.66667 roc_auc 0.46500 prc_auc 0.64920[0m
[93maverage test of epoch 45: loss -34.17154 acc 0.65789 roc_auc 0.60154 prc_auc 0.79028[0m
[92maverage training of epoch 46: loss -34.71840 acc 0.66667 roc_auc 0.46170 prc_auc 0.64356[0m
[93maverage test of epoch 46: loss -35.15627 acc 0.65789 roc_auc 0.42615 prc_auc 0.61696[0m
[92maverage training of epoch 47: loss -35.71047 acc 0.66667 roc_auc 0.46170 prc_auc 0.63745[0m
[93maverage test of epoch 47: loss -36.15550 acc 0.65789 roc_auc 0.35077 prc_auc 0.55948[0m
[92maverage training of epoch 48: loss -36.71834 acc 0.66667 roc_auc 0.45950 prc_auc 0.64011[0m
[93maverage test of epoch 48: loss -37.15760 acc 0.65789 roc_auc 0.67077 prc_auc 0.79529[0m
[92maverage training of epoch 49: loss -37.73769 acc 0.66667 roc_auc 0.45620 prc_auc 0.64164[0m
[93maverage test of epoch 49: loss -38.18802 acc 0.65789 roc_auc 0.55231 prc_auc 0.69956[0m
[92maverage training of epoch 50: loss -38.77343 acc 0.66667 roc_auc 0.46550 prc_auc 0.65182[0m
[93maverage test of epoch 50: loss -39.22856 acc 0.65789 roc_auc 0.62000 prc_auc 0.74280[0m
[92maverage training of epoch 51: loss -39.82097 acc 0.66667 roc_auc 0.46420 prc_auc 0.64397[0m
[93maverage test of epoch 51: loss -40.27897 acc 0.65789 roc_auc 0.37692 prc_auc 0.60519[0m
[92maverage training of epoch 52: loss -40.88418 acc 0.66667 roc_auc 0.46410 prc_auc 0.64906[0m
[93maverage test of epoch 52: loss -41.34054 acc 0.65789 roc_auc 0.60769 prc_auc 0.72494[0m
[92maverage training of epoch 53: loss -41.95828 acc 0.66667 roc_auc 0.46170 prc_auc 0.64145[0m
[93maverage test of epoch 53: loss -42.42538 acc 0.65789 roc_auc 0.49385 prc_auc 0.66001[0m
[92maverage training of epoch 54: loss -43.04803 acc 0.66667 roc_auc 0.46120 prc_auc 0.63986[0m
[93maverage test of epoch 54: loss -43.51668 acc 0.65789 roc_auc 0.50308 prc_auc 0.65752[0m
[92maverage training of epoch 55: loss -44.15054 acc 0.66667 roc_auc 0.46920 prc_auc 0.64876[0m
[93maverage test of epoch 55: loss -44.62680 acc 0.65789 roc_auc 0.46308 prc_auc 0.63990[0m
[92maverage training of epoch 56: loss -45.26729 acc 0.66667 roc_auc 0.46120 prc_auc 0.64180[0m
[93maverage test of epoch 56: loss -45.73973 acc 0.65789 roc_auc 0.44308 prc_auc 0.63550[0m
[92maverage training of epoch 57: loss -46.39986 acc 0.66667 roc_auc 0.46080 prc_auc 0.63620[0m
[93maverage test of epoch 57: loss -46.88182 acc 0.65789 roc_auc 0.67846 prc_auc 0.75267[0m
[92maverage training of epoch 58: loss -47.54328 acc 0.66667 roc_auc 0.45880 prc_auc 0.63673[0m
[93maverage test of epoch 58: loss -48.02626 acc 0.65789 roc_auc 0.63692 prc_auc 0.72641[0m
[92maverage training of epoch 59: loss -48.70001 acc 0.66667 roc_auc 0.46300 prc_auc 0.63756[0m
[93maverage test of epoch 59: loss -49.19212 acc 0.65789 roc_auc 0.53692 prc_auc 0.67498[0m
[92maverage training of epoch 60: loss -49.87223 acc 0.66667 roc_auc 0.46290 prc_auc 0.64428[0m
[93maverage test of epoch 60: loss -50.36485 acc 0.65789 roc_auc 0.55692 prc_auc 0.68460[0m
[92maverage training of epoch 61: loss -51.06001 acc 0.66667 roc_auc 0.45520 prc_auc 0.63442[0m
[93maverage test of epoch 61: loss -51.55658 acc 0.65789 roc_auc 0.48000 prc_auc 0.64902[0m
[92maverage training of epoch 62: loss -52.26132 acc 0.66667 roc_auc 0.46270 prc_auc 0.63905[0m
[93maverage test of epoch 62: loss -52.76252 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 63: loss -53.47751 acc 0.66667 roc_auc 0.45970 prc_auc 0.64134[0m
[93maverage test of epoch 63: loss -53.98096 acc 0.65789 roc_auc 0.51846 prc_auc 0.66632[0m
[92maverage training of epoch 64: loss -54.70718 acc 0.66667 roc_auc 0.45220 prc_auc 0.63634[0m
[93maverage test of epoch 64: loss -55.21398 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 65: loss -55.95030 acc 0.66667 roc_auc 0.46960 prc_auc 0.64447[0m
[93maverage test of epoch 65: loss -56.46416 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 66: loss -57.20937 acc 0.66667 roc_auc 0.46660 prc_auc 0.64845[0m
[93maverage test of epoch 66: loss -57.72489 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 67: loss -58.48206 acc 0.66667 roc_auc 0.46950 prc_auc 0.65269[0m
[93maverage test of epoch 67: loss -59.00000 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 68: loss -59.76821 acc 0.66667 roc_auc 0.44000 prc_auc 0.64296[0m
[93maverage test of epoch 68: loss -60.29051 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 69: loss -61.07007 acc 0.66667 roc_auc 0.48500 prc_auc 0.66167[0m
[93maverage test of epoch 69: loss -61.59443 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 70: loss -62.38334 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 70: loss -62.91240 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 71: loss -63.71374 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 71: loss -64.24603 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 72: loss -65.05778 acc 0.66667 roc_auc 0.47500 prc_auc 0.65591[0m
[93maverage test of epoch 72: loss -65.59284 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 73: loss -66.41590 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 73: loss -66.95481 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 74: loss -67.78963 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 74: loss -68.33165 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 75: loss -69.17868 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 75: loss -69.72723 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 76: loss -70.58208 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 76: loss -71.13363 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 77: loss -71.99920 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 77: loss -72.55429 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 78: loss -73.43334 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 78: loss -73.99203 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 79: loss -74.88086 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 79: loss -75.44345 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 80: loss -76.34471 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 80: loss -76.90871 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 81: loss -77.82283 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 81: loss -78.38797 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 82: loss -79.31631 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 82: loss -79.88709 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 83: loss -80.82453 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 83: loss -81.40063 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 84: loss -82.34911 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 84: loss -82.92682 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 85: loss -83.88687 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 85: loss -84.46941 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 86: loss -85.44093 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 86: loss -86.02553 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 87: loss -87.00970 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 87: loss -87.59642 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 88: loss -88.59395 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 88: loss -89.18602 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 89: loss -90.19409 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 89: loss -90.78818 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -91.80842 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 90: loss -92.40468 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 91: loss -93.43853 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 91: loss -94.03924 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 92: loss -95.08305 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 92: loss -95.68731 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 93: loss -96.74384 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 93: loss -97.34964 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 94: loss -98.41675 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 94: loss -99.02619 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 95: loss -100.10582 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 95: loss -100.71697 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 96: loss -101.80856 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 96: loss -102.42251 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 97: loss -103.52655 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 97: loss -104.14259 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 98: loss -105.25821 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 98: loss -105.87734 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -107.00567 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 99: loss -107.62778 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss 0.31598 acc 0.66667 roc_auc 0.44760 prc_auc 0.66415[0m
[93maverage test of epoch 0: loss -0.20216 acc 0.65789 roc_auc 0.51077 prc_auc 0.62528[0m
[92maverage training of epoch 1: loss -0.70965 acc 0.66667 roc_auc 0.49480 prc_auc 0.66713[0m
[93maverage test of epoch 1: loss -1.20352 acc 0.65789 roc_auc 0.59077 prc_auc 0.77836[0m
[92maverage training of epoch 2: loss -1.71358 acc 0.66667 roc_auc 0.50780 prc_auc 0.66978[0m
[93maverage test of epoch 2: loss -2.11757 acc 0.65789 roc_auc 0.46154 prc_auc 0.61998[0m
[92maverage training of epoch 3: loss -2.50249 acc 0.66667 roc_auc 0.49020 prc_auc 0.67236[0m
[93maverage test of epoch 3: loss -2.86302 acc 0.65789 roc_auc 0.38769 prc_auc 0.58634[0m
[92maverage training of epoch 4: loss -3.25702 acc 0.66667 roc_auc 0.38940 prc_auc 0.60288[0m
[93maverage test of epoch 4: loss -3.65817 acc 0.65789 roc_auc 0.60615 prc_auc 0.77590[0m
[92maverage training of epoch 5: loss -4.10565 acc 0.66667 roc_auc 0.47080 prc_auc 0.63943[0m
[93maverage test of epoch 5: loss -4.56148 acc 0.65789 roc_auc 0.57538 prc_auc 0.69938[0m
[92maverage training of epoch 6: loss -5.00336 acc 0.66667 roc_auc 0.50120 prc_auc 0.66716[0m
[93maverage test of epoch 6: loss -5.48551 acc 0.65789 roc_auc 0.63077 prc_auc 0.75217[0m
[92maverage training of epoch 7: loss -6.02840 acc 0.66667 roc_auc 0.51160 prc_auc 0.66473[0m
[93maverage test of epoch 7: loss -6.60488 acc 0.65789 roc_auc 0.59385 prc_auc 0.76180[0m
[92maverage training of epoch 8: loss -7.16224 acc 0.66667 roc_auc 0.43520 prc_auc 0.64742[0m
[93maverage test of epoch 8: loss -7.72182 acc 0.65789 roc_auc 0.40308 prc_auc 0.66499[0m
[92maverage training of epoch 9: loss -8.20772 acc 0.66667 roc_auc 0.40480 prc_auc 0.61532[0m
[93maverage test of epoch 9: loss -8.70858 acc 0.65789 roc_auc 0.53538 prc_auc 0.71455[0m
[92maverage training of epoch 10: loss -9.09353 acc 0.66667 roc_auc 0.45480 prc_auc 0.62961[0m
[93maverage test of epoch 10: loss -9.44693 acc 0.65789 roc_auc 0.53231 prc_auc 0.74906[0m
[92maverage training of epoch 11: loss -9.90595 acc 0.66667 roc_auc 0.40940 prc_auc 0.62965[0m
[93maverage test of epoch 11: loss -10.22974 acc 0.65789 roc_auc 0.50462 prc_auc 0.63522[0m
[92maverage training of epoch 12: loss -10.62185 acc 0.66667 roc_auc 0.40240 prc_auc 0.61227[0m
[93maverage test of epoch 12: loss -11.00503 acc 0.65789 roc_auc 0.62462 prc_auc 0.74679[0m
[92maverage training of epoch 13: loss -11.36283 acc 0.66667 roc_auc 0.44480 prc_auc 0.65851[0m
[93maverage test of epoch 13: loss -11.68027 acc 0.65789 roc_auc 0.40615 prc_auc 0.59883[0m
[92maverage training of epoch 14: loss -12.09999 acc 0.66667 roc_auc 0.44100 prc_auc 0.62839[0m
[93maverage test of epoch 14: loss -12.46321 acc 0.65789 roc_auc 0.56000 prc_auc 0.70171[0m
[92maverage training of epoch 15: loss -12.82963 acc 0.66667 roc_auc 0.40320 prc_auc 0.60721[0m
[93maverage test of epoch 15: loss -13.15344 acc 0.65789 roc_auc 0.50769 prc_auc 0.65351[0m
[92maverage training of epoch 16: loss -13.52527 acc 0.66667 roc_auc 0.48000 prc_auc 0.67587[0m
[93maverage test of epoch 16: loss -13.81548 acc 0.65789 roc_auc 0.63077 prc_auc 0.73994[0m
[92maverage training of epoch 17: loss -14.24678 acc 0.66667 roc_auc 0.41000 prc_auc 0.61672[0m
[93maverage test of epoch 17: loss -14.55859 acc 0.65789 roc_auc 0.49538 prc_auc 0.69652[0m
[92maverage training of epoch 18: loss -14.93659 acc 0.66667 roc_auc 0.43400 prc_auc 0.63447[0m
[93maverage test of epoch 18: loss -15.29053 acc 0.65789 roc_auc 0.51846 prc_auc 0.73117[0m
[92maverage training of epoch 19: loss -15.66335 acc 0.66667 roc_auc 0.43320 prc_auc 0.63705[0m
[93maverage test of epoch 19: loss -15.99643 acc 0.65789 roc_auc 0.41538 prc_auc 0.62347[0m
[92maverage training of epoch 20: loss -16.36488 acc 0.66667 roc_auc 0.39800 prc_auc 0.59336[0m
[93maverage test of epoch 20: loss -16.67850 acc 0.65789 roc_auc 0.62769 prc_auc 0.78912[0m
[92maverage training of epoch 21: loss -17.09040 acc 0.66667 roc_auc 0.42480 prc_auc 0.63784[0m
[93maverage test of epoch 21: loss -17.42354 acc 0.65789 roc_auc 0.62154 prc_auc 0.77564[0m
[92maverage training of epoch 22: loss -17.81089 acc 0.66667 roc_auc 0.43280 prc_auc 0.63264[0m
[93maverage test of epoch 22: loss -18.14651 acc 0.65789 roc_auc 0.74000 prc_auc 0.86255[0m
[92maverage training of epoch 23: loss -18.53758 acc 0.66667 roc_auc 0.44640 prc_auc 0.65212[0m
[93maverage test of epoch 23: loss -18.86502 acc 0.65789 roc_auc 0.41538 prc_auc 0.64396[0m
[92maverage training of epoch 24: loss -19.28244 acc 0.66667 roc_auc 0.41840 prc_auc 0.63063[0m
[93maverage test of epoch 24: loss -19.60926 acc 0.65789 roc_auc 0.58769 prc_auc 0.77146[0m
[92maverage training of epoch 25: loss -20.02314 acc 0.66667 roc_auc 0.44360 prc_auc 0.64707[0m
[93maverage test of epoch 25: loss -20.36106 acc 0.65789 roc_auc 0.39692 prc_auc 0.58559[0m
[92maverage training of epoch 26: loss -20.78568 acc 0.66667 roc_auc 0.42670 prc_auc 0.62438[0m
[93maverage test of epoch 26: loss -21.09418 acc 0.65789 roc_auc 0.48769 prc_auc 0.66260[0m
[92maverage training of epoch 27: loss -21.52680 acc 0.66667 roc_auc 0.41630 prc_auc 0.60991[0m
[93maverage test of epoch 27: loss -21.86064 acc 0.65789 roc_auc 0.44923 prc_auc 0.69123[0m
[92maverage training of epoch 28: loss -22.28880 acc 0.66667 roc_auc 0.42400 prc_auc 0.62805[0m
[93maverage test of epoch 28: loss -22.64507 acc 0.65789 roc_auc 0.47538 prc_auc 0.66509[0m
[92maverage training of epoch 29: loss -23.06060 acc 0.66667 roc_auc 0.43110 prc_auc 0.61897[0m
[93maverage test of epoch 29: loss -23.40272 acc 0.65789 roc_auc 0.40923 prc_auc 0.62868[0m
[92maverage training of epoch 30: loss -23.85385 acc 0.66667 roc_auc 0.42430 prc_auc 0.62165[0m
[93maverage test of epoch 30: loss -24.16932 acc 0.65789 roc_auc 0.16923 prc_auc 0.50546[0m
[92maverage training of epoch 31: loss -24.63229 acc 0.66667 roc_auc 0.43270 prc_auc 0.62187[0m
[93maverage test of epoch 31: loss -24.96943 acc 0.65789 roc_auc 0.59077 prc_auc 0.78650[0m
[92maverage training of epoch 32: loss -25.42976 acc 0.66667 roc_auc 0.41980 prc_auc 0.63442[0m
[93maverage test of epoch 32: loss -25.77334 acc 0.65789 roc_auc 0.54923 prc_auc 0.69727[0m
[92maverage training of epoch 33: loss -26.24641 acc 0.66667 roc_auc 0.43730 prc_auc 0.62554[0m
[93maverage test of epoch 33: loss -26.57957 acc 0.65789 roc_auc 0.44462 prc_auc 0.62961[0m
[92maverage training of epoch 34: loss -27.04445 acc 0.66667 roc_auc 0.43250 prc_auc 0.62664[0m
[93maverage test of epoch 34: loss -27.39168 acc 0.65789 roc_auc 0.41692 prc_auc 0.64238[0m
[92maverage training of epoch 35: loss -27.88806 acc 0.66667 roc_auc 0.43970 prc_auc 0.63562[0m
[93maverage test of epoch 35: loss -28.23658 acc 0.65789 roc_auc 0.48308 prc_auc 0.63508[0m
[92maverage training of epoch 36: loss -28.71487 acc 0.66667 roc_auc 0.41760 prc_auc 0.61689[0m
[93maverage test of epoch 36: loss -29.06230 acc 0.65789 roc_auc 0.46154 prc_auc 0.66205[0m
[92maverage training of epoch 37: loss -29.56441 acc 0.66667 roc_auc 0.44360 prc_auc 0.63592[0m
[93maverage test of epoch 37: loss -29.91636 acc 0.65789 roc_auc 0.51385 prc_auc 0.66170[0m
[92maverage training of epoch 38: loss -30.42373 acc 0.66667 roc_auc 0.43760 prc_auc 0.63550[0m
[93maverage test of epoch 38: loss -30.76949 acc 0.65789 roc_auc 0.50615 prc_auc 0.69489[0m
[92maverage training of epoch 39: loss -31.28967 acc 0.66667 roc_auc 0.42840 prc_auc 0.62546[0m
[93maverage test of epoch 39: loss -31.62176 acc 0.65789 roc_auc 0.57077 prc_auc 0.71325[0m
[92maverage training of epoch 40: loss -32.16070 acc 0.66667 roc_auc 0.42630 prc_auc 0.62229[0m
[93maverage test of epoch 40: loss -32.50480 acc 0.65789 roc_auc 0.45231 prc_auc 0.63802[0m
[92maverage training of epoch 41: loss -33.05481 acc 0.66667 roc_auc 0.43190 prc_auc 0.62489[0m
[93maverage test of epoch 41: loss -33.39277 acc 0.65789 roc_auc 0.41846 prc_auc 0.62188[0m
[92maverage training of epoch 42: loss -33.93826 acc 0.66667 roc_auc 0.45420 prc_auc 0.64223[0m
[93maverage test of epoch 42: loss -34.30061 acc 0.65789 roc_auc 0.59846 prc_auc 0.70892[0m
[92maverage training of epoch 43: loss -34.85164 acc 0.66667 roc_auc 0.43520 prc_auc 0.63061[0m
[93maverage test of epoch 43: loss -35.20982 acc 0.65789 roc_auc 0.55692 prc_auc 0.68460[0m
[92maverage training of epoch 44: loss -35.76990 acc 0.66667 roc_auc 0.43110 prc_auc 0.62645[0m
[93maverage test of epoch 44: loss -36.13521 acc 0.65789 roc_auc 0.51231 prc_auc 0.66351[0m
[92maverage training of epoch 45: loss -36.70195 acc 0.66667 roc_auc 0.42610 prc_auc 0.62482[0m
[93maverage test of epoch 45: loss -37.06017 acc 0.65789 roc_auc 0.48000 prc_auc 0.64902[0m
[92maverage training of epoch 46: loss -37.63870 acc 0.66667 roc_auc 0.41820 prc_auc 0.61818[0m
[93maverage test of epoch 46: loss -37.99835 acc 0.65789 roc_auc 0.53846 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -38.59042 acc 0.66667 roc_auc 0.41990 prc_auc 0.62579[0m
[93maverage test of epoch 47: loss -38.95694 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -39.54649 acc 0.66667 roc_auc 0.42950 prc_auc 0.63245[0m
[93maverage test of epoch 48: loss -39.91124 acc 0.65789 roc_auc 0.64923 prc_auc 0.73549[0m
[92maverage training of epoch 49: loss -40.51914 acc 0.66667 roc_auc 0.43680 prc_auc 0.63989[0m
[93maverage test of epoch 49: loss -40.88675 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 50: loss -41.50099 acc 0.66667 roc_auc 0.48710 prc_auc 0.66111[0m
[93maverage test of epoch 50: loss -41.86731 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 51: loss -42.50042 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 51: loss -42.86867 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 52: loss -43.49842 acc 0.66667 roc_auc 0.47500 prc_auc 0.65578[0m
[93maverage test of epoch 52: loss -43.87231 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 53: loss -44.51547 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 53: loss -44.89078 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 54: loss -45.54260 acc 0.66667 roc_auc 0.43500 prc_auc 0.64113[0m
[93maverage test of epoch 54: loss -45.91701 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 55: loss -46.57732 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 55: loss -46.95102 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 56: loss -47.62604 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 56: loss -48.01074 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 57: loss -48.68818 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 57: loss -49.06932 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 58: loss -49.76059 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 58: loss -50.13458 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 59: loss -50.84009 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 59: loss -51.22448 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 60: loss -51.92896 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 60: loss -52.32121 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 61: loss -53.03653 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 61: loss -53.42460 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 62: loss -54.15361 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 62: loss -54.54354 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 63: loss -55.27871 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 63: loss -55.67110 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 64: loss -56.41558 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 64: loss -56.81256 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 65: loss -57.56245 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 65: loss -57.95849 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 66: loss -58.72451 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 66: loss -59.12363 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 67: loss -59.89374 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 67: loss -60.29245 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 68: loss -61.07556 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 68: loss -61.47650 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 69: loss -62.26797 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 69: loss -62.66698 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 70: loss -63.46912 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 70: loss -63.87399 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 71: loss -64.68603 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 71: loss -65.09090 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 72: loss -65.91128 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 72: loss -66.31634 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 73: loss -67.14916 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 73: loss -67.55206 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 74: loss -68.39825 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 74: loss -68.80406 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 75: loss -69.65747 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 75: loss -70.06619 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 76: loss -70.92800 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 76: loss -71.33957 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 77: loss -72.21196 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 77: loss -72.62108 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 78: loss -73.50684 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 78: loss -73.91923 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 79: loss -74.81174 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 79: loss -75.22495 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 80: loss -76.13001 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 80: loss -76.54404 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 81: loss -77.45920 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 81: loss -77.87276 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 82: loss -78.79997 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 82: loss -79.21534 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 83: loss -80.15187 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 83: loss -80.56914 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 84: loss -81.51542 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 84: loss -81.93455 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 85: loss -82.89219 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 85: loss -83.31059 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 86: loss -84.27904 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 86: loss -84.69856 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 87: loss -85.67778 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 87: loss -86.09762 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 88: loss -87.08854 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 88: loss -87.50994 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 89: loss -88.51051 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 89: loss -88.93281 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -89.94541 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 90: loss -90.36800 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 91: loss -91.39061 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 91: loss -91.81342 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 92: loss -92.84824 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 92: loss -93.27237 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 93: loss -94.31739 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 93: loss -94.74209 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 94: loss -95.79848 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 94: loss -96.22318 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 95: loss -97.29194 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 95: loss -97.71637 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 96: loss -98.79748 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 96: loss -99.22427 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 97: loss -100.31427 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 97: loss -100.74059 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 98: loss -101.84288 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 98: loss -102.27021 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -103.38367 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 99: loss -103.81025 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss 0.14047 acc 0.66225 roc_auc 0.32863 prc_auc 0.57678[0m
[93maverage test of epoch 0: loss -0.01097 acc 0.67568 roc_auc 0.36667 prc_auc 0.61597[0m
[92maverage training of epoch 1: loss -0.11835 acc 0.66225 roc_auc 0.49127 prc_auc 0.68506[0m
[93maverage test of epoch 1: loss -0.23473 acc 0.67568 roc_auc 0.35333 prc_auc 0.61988[0m
[92maverage training of epoch 2: loss -0.31129 acc 0.66225 roc_auc 0.41392 prc_auc 0.62405[0m
[93maverage test of epoch 2: loss -0.41534 acc 0.67568 roc_auc 0.54333 prc_auc 0.73205[0m
[92maverage training of epoch 3: loss -0.45195 acc 0.66225 roc_auc 0.46804 prc_auc 0.63780[0m
[93maverage test of epoch 3: loss -0.54431 acc 0.67568 roc_auc 0.39333 prc_auc 0.59327[0m
[92maverage training of epoch 4: loss -0.58977 acc 0.66225 roc_auc 0.42176 prc_auc 0.62588[0m
[93maverage test of epoch 4: loss -0.68621 acc 0.67568 roc_auc 0.50667 prc_auc 0.70031[0m
[92maverage training of epoch 5: loss -0.74225 acc 0.66225 roc_auc 0.52471 prc_auc 0.67761[0m
[93maverage test of epoch 5: loss -0.83138 acc 0.67568 roc_auc 0.31333 prc_auc 0.64285[0m
[92maverage training of epoch 6: loss -0.88342 acc 0.66225 roc_auc 0.46471 prc_auc 0.66761[0m
[93maverage test of epoch 6: loss -1.00289 acc 0.67568 roc_auc 0.68667 prc_auc 0.82280[0m
[92maverage training of epoch 7: loss -1.03880 acc 0.66225 roc_auc 0.50216 prc_auc 0.67788[0m
[93maverage test of epoch 7: loss -1.17838 acc 0.67568 roc_auc 0.67333 prc_auc 0.84514[0m
[92maverage training of epoch 8: loss -1.20503 acc 0.66225 roc_auc 0.51843 prc_auc 0.70588[0m
[93maverage test of epoch 8: loss -1.32053 acc 0.67568 roc_auc 0.42333 prc_auc 0.70030[0m
[92maverage training of epoch 9: loss -1.37145 acc 0.66225 roc_auc 0.51059 prc_auc 0.66311[0m
[93maverage test of epoch 9: loss -1.48994 acc 0.67568 roc_auc 0.40333 prc_auc 0.66999[0m
[92maverage training of epoch 10: loss -1.54145 acc 0.66225 roc_auc 0.49510 prc_auc 0.66593[0m
[93maverage test of epoch 10: loss -1.69411 acc 0.67568 roc_auc 0.64333 prc_auc 0.80469[0m
[92maverage training of epoch 11: loss -1.73133 acc 0.66225 roc_auc 0.50118 prc_auc 0.68703[0m
[93maverage test of epoch 11: loss -1.86139 acc 0.67568 roc_auc 0.41333 prc_auc 0.64198[0m
[92maverage training of epoch 12: loss -1.91484 acc 0.66225 roc_auc 0.48137 prc_auc 0.63591[0m
[93maverage test of epoch 12: loss -2.05421 acc 0.67568 roc_auc 0.37000 prc_auc 0.66850[0m
[92maverage training of epoch 13: loss -2.10940 acc 0.66225 roc_auc 0.46804 prc_auc 0.64689[0m
[93maverage test of epoch 13: loss -2.27889 acc 0.67568 roc_auc 0.71333 prc_auc 0.83032[0m
[92maverage training of epoch 14: loss -2.32252 acc 0.66225 roc_auc 0.49804 prc_auc 0.66474[0m
[93maverage test of epoch 14: loss -2.48855 acc 0.67568 roc_auc 0.66333 prc_auc 0.76430[0m
[92maverage training of epoch 15: loss -2.53411 acc 0.66225 roc_auc 0.50686 prc_auc 0.69792[0m
[93maverage test of epoch 15: loss -2.69455 acc 0.67568 roc_auc 0.45000 prc_auc 0.64257[0m
[92maverage training of epoch 16: loss -2.74835 acc 0.66225 roc_auc 0.51529 prc_auc 0.68240[0m
[93maverage test of epoch 16: loss -2.90062 acc 0.67568 roc_auc 0.36667 prc_auc 0.60463[0m
[92maverage training of epoch 17: loss -2.96998 acc 0.66225 roc_auc 0.47647 prc_auc 0.64603[0m
[93maverage test of epoch 17: loss -3.14017 acc 0.67568 roc_auc 0.49667 prc_auc 0.66329[0m
[92maverage training of epoch 18: loss -3.20367 acc 0.66225 roc_auc 0.43667 prc_auc 0.61493[0m
[93maverage test of epoch 18: loss -3.37751 acc 0.67568 roc_auc 0.39000 prc_auc 0.64587[0m
[92maverage training of epoch 19: loss -3.44738 acc 0.66225 roc_auc 0.48863 prc_auc 0.67963[0m
[93maverage test of epoch 19: loss -3.62798 acc 0.67568 roc_auc 0.61000 prc_auc 0.75911[0m
[92maverage training of epoch 20: loss -3.69658 acc 0.66225 roc_auc 0.46020 prc_auc 0.64438[0m
[93maverage test of epoch 20: loss -3.91246 acc 0.67568 roc_auc 0.44333 prc_auc 0.67380[0m
[92maverage training of epoch 21: loss -3.96765 acc 0.66225 roc_auc 0.51696 prc_auc 0.70568[0m
[93maverage test of epoch 21: loss -4.17889 acc 0.67568 roc_auc 0.68333 prc_auc 0.82783[0m
[92maverage training of epoch 22: loss -4.24854 acc 0.66225 roc_auc 0.48304 prc_auc 0.67086[0m
[93maverage test of epoch 22: loss -4.47237 acc 0.67568 roc_auc 0.57333 prc_auc 0.73965[0m
[92maverage training of epoch 23: loss -4.54965 acc 0.66225 roc_auc 0.48745 prc_auc 0.65218[0m
[93maverage test of epoch 23: loss -4.76772 acc 0.67568 roc_auc 0.40667 prc_auc 0.62716[0m
[92maverage training of epoch 24: loss -4.84947 acc 0.66225 roc_auc 0.49216 prc_auc 0.65487[0m
[93maverage test of epoch 24: loss -5.10022 acc 0.67568 roc_auc 0.78333 prc_auc 0.87897[0m
[92maverage training of epoch 25: loss -5.15554 acc 0.66225 roc_auc 0.42137 prc_auc 0.63826[0m
[93maverage test of epoch 25: loss -5.40974 acc 0.67568 roc_auc 0.62333 prc_auc 0.76148[0m
[92maverage training of epoch 26: loss -5.48907 acc 0.66225 roc_auc 0.50127 prc_auc 0.68174[0m
[93maverage test of epoch 26: loss -5.73310 acc 0.67568 roc_auc 0.60667 prc_auc 0.76924[0m
[92maverage training of epoch 27: loss -5.81261 acc 0.66225 roc_auc 0.44569 prc_auc 0.63212[0m
[93maverage test of epoch 27: loss -6.07616 acc 0.67568 roc_auc 0.49000 prc_auc 0.71181[0m
[92maverage training of epoch 28: loss -6.16547 acc 0.66225 roc_auc 0.50225 prc_auc 0.64567[0m
[93maverage test of epoch 28: loss -6.41915 acc 0.67568 roc_auc 0.45333 prc_auc 0.65807[0m
[92maverage training of epoch 29: loss -6.52358 acc 0.66225 roc_auc 0.43461 prc_auc 0.60989[0m
[93maverage test of epoch 29: loss -6.80611 acc 0.67568 roc_auc 0.57333 prc_auc 0.78823[0m
[92maverage training of epoch 30: loss -6.90839 acc 0.66225 roc_auc 0.44402 prc_auc 0.60887[0m
[93maverage test of epoch 30: loss -7.18743 acc 0.67568 roc_auc 0.44833 prc_auc 0.63024[0m
[92maverage training of epoch 31: loss -7.30554 acc 0.66225 roc_auc 0.51608 prc_auc 0.67804[0m
[93maverage test of epoch 31: loss -7.61256 acc 0.67568 roc_auc 0.63333 prc_auc 0.76522[0m
[92maverage training of epoch 32: loss -7.70305 acc 0.66225 roc_auc 0.42637 prc_auc 0.62320[0m
[93maverage test of epoch 32: loss -7.99476 acc 0.67568 roc_auc 0.45000 prc_auc 0.72155[0m
[92maverage training of epoch 33: loss -8.11633 acc 0.66225 roc_auc 0.49706 prc_auc 0.66119[0m
[93maverage test of epoch 33: loss -8.42670 acc 0.67568 roc_auc 0.47000 prc_auc 0.65455[0m
[92maverage training of epoch 34: loss -8.51148 acc 0.66225 roc_auc 0.38637 prc_auc 0.60651[0m
[93maverage test of epoch 34: loss -8.84865 acc 0.67568 roc_auc 0.52833 prc_auc 0.69501[0mUsing backend: pytorch

[92maverage training of epoch 35: loss -8.93912 acc 0.66225 roc_auc 0.44461 prc_auc 0.60072[0m
[93maverage test of epoch 35: loss -9.27148 acc 0.67568 roc_auc 0.50333 prc_auc 0.67800[0m
[92maverage training of epoch 36: loss -9.35654 acc 0.66225 roc_auc 0.48245 prc_auc 0.64292[0m
[93maverage test of epoch 36: loss -9.68644 acc 0.67568 roc_auc 0.57167 prc_auc 0.78823[0m
[92maverage training of epoch 37: loss -9.77700 acc 0.66225 roc_auc 0.44794 prc_auc 0.60041[0m
[93maverage test of epoch 37: loss -10.11499 acc 0.67568 roc_auc 0.50167 prc_auc 0.68946[0m
[92maverage training of epoch 38: loss -10.20534 acc 0.66225 roc_auc 0.40529 prc_auc 0.59380[0m
[93maverage test of epoch 38: loss -10.54803 acc 0.67568 roc_auc 0.49667 prc_auc 0.67640[0m
[92maverage training of epoch 39: loss -10.64536 acc 0.66225 roc_auc 0.50235 prc_auc 0.64665[0m
[93maverage test of epoch 39: loss -10.98353 acc 0.67568 roc_auc 0.53000 prc_auc 0.75619[0m
[92maverage training of epoch 40: loss -11.08872 acc 0.66225 roc_auc 0.44814 prc_auc 0.62424[0m
[93maverage test of epoch 40: loss -11.43006 acc 0.67568 roc_auc 0.37167 prc_auc 0.60776[0m
[92maverage training of epoch 41: loss -11.52737 acc 0.66225 roc_auc 0.46902 prc_auc 0.62224[0m
[93maverage test of epoch 41: loss -11.88957 acc 0.67568 roc_auc 0.56000 prc_auc 0.73657[0m
[92maverage training of epoch 42: loss -11.97875 acc 0.66225 roc_auc 0.48500 prc_auc 0.66921[0m
[93maverage test of epoch 42: loss -12.35007 acc 0.67568 roc_auc 0.64500 prc_auc 0.77161[0m
[92maverage training of epoch 43: loss -12.44361 acc 0.66225 roc_auc 0.46775 prc_auc 0.62852[0m
[93maverage test of epoch 43: loss -12.81899 acc 0.67568 roc_auc 0.70167 prc_auc 0.81005[0m
[92maverage training of epoch 44: loss -12.90134 acc 0.66225 roc_auc 0.38343 prc_auc 0.58589[0m
[93maverage test of epoch 44: loss -13.28009 acc 0.67568 roc_auc 0.45333 prc_auc 0.65173[0m
[92maverage training of epoch 45: loss -13.38445 acc 0.66225 roc_auc 0.42882 prc_auc 0.61334[0m
[93maverage test of epoch 45: loss -13.77693 acc 0.67568 roc_auc 0.74833 prc_auc 0.82504[0m
[92maverage training of epoch 46: loss -13.86426 acc 0.66225 roc_auc 0.41392 prc_auc 0.59895[0m
[93maverage test of epoch 46: loss -14.25273 acc 0.67568 roc_auc 0.25000 prc_auc 0.56375[0m
[92maverage training of epoch 47: loss -14.35618 acc 0.66225 roc_auc 0.40441 prc_auc 0.58921[0m
[93maverage test of epoch 47: loss -14.75942 acc 0.67568 roc_auc 0.45500 prc_auc 0.69179[0m
[92maverage training of epoch 48: loss -14.85727 acc 0.66225 roc_auc 0.44833 prc_auc 0.64862[0m
[93maverage test of epoch 48: loss -15.25154 acc 0.67568 roc_auc 0.25833 prc_auc 0.56408[0m
[92maverage training of epoch 49: loss -15.36339 acc 0.66225 roc_auc 0.43441 prc_auc 0.60944[0m
[93maverage test of epoch 49: loss -15.76885 acc 0.67568 roc_auc 0.39500 prc_auc 0.62561[0m
[92maverage training of epoch 50: loss -15.87679 acc 0.66225 roc_auc 0.41157 prc_auc 0.61674[0m
[93maverage test of epoch 50: loss -16.29996 acc 0.67568 roc_auc 0.64500 prc_auc 0.76808[0m
[92maverage training of epoch 51: loss -16.39850 acc 0.66225 roc_auc 0.45216 prc_auc 0.64193[0m
[93maverage test of epoch 51: loss -16.82541 acc 0.67568 roc_auc 0.55667 prc_auc 0.70629[0m
[92maverage training of epoch 52: loss -16.92744 acc 0.66225 roc_auc 0.43225 prc_auc 0.62262[0m
[93maverage test of epoch 52: loss -17.35514 acc 0.67568 roc_auc 0.58167 prc_auc 0.72688[0m
[92maverage training of epoch 53: loss -17.46594 acc 0.66225 roc_auc 0.43137 prc_auc 0.61389[0m
[93maverage test of epoch 53: loss -17.90257 acc 0.67568 roc_auc 0.46333 prc_auc 0.65848[0m
[92maverage training of epoch 54: loss -18.00799 acc 0.66225 roc_auc 0.41863 prc_auc 0.61746[0m
[93maverage test of epoch 54: loss -18.43990 acc 0.67568 roc_auc 0.34167 prc_auc 0.61265[0m
[92maverage training of epoch 55: loss -18.55682 acc 0.66225 roc_auc 0.40186 prc_auc 0.60945[0m
[93maverage test of epoch 55: loss -19.00352 acc 0.67568 roc_auc 0.43333 prc_auc 0.64637[0m
[92maverage training of epoch 56: loss -19.11694 acc 0.66225 roc_auc 0.40961 prc_auc 0.60404[0m
[93maverage test of epoch 56: loss -19.57025 acc 0.67568 roc_auc 0.42667 prc_auc 0.64643[0m
[92maverage training of epoch 57: loss -19.68701 acc 0.66225 roc_auc 0.42324 prc_auc 0.61800[0m
[93maverage test of epoch 57: loss -20.14513 acc 0.67568 roc_auc 0.50333 prc_auc 0.68091[0m
[92maverage training of epoch 58: loss -20.25665 acc 0.66225 roc_auc 0.38745 prc_auc 0.60244[0m
[93maverage test of epoch 58: loss -20.73312 acc 0.67568 roc_auc 0.54667 prc_auc 0.69677[0m
[92maverage training of epoch 59: loss -20.84409 acc 0.66225 roc_auc 0.43314 prc_auc 0.62489[0m
[93maverage test of epoch 59: loss -21.31760 acc 0.67568 roc_auc 0.52500 prc_auc 0.68687[0m
[92maverage training of epoch 60: loss -21.43120 acc 0.66225 roc_auc 0.42078 prc_auc 0.62482[0m
[93maverage test of epoch 60: loss -21.91395 acc 0.67568 roc_auc 0.44833 prc_auc 0.65451[0m
[92maverage training of epoch 61: loss -22.03267 acc 0.66225 roc_auc 0.39265 prc_auc 0.61290[0m
[93maverage test of epoch 61: loss -22.52810 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 62: loss -22.64029 acc 0.66225 roc_auc 0.41873 prc_auc 0.62494[0m
[93maverage test of epoch 62: loss -23.14378 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 63: loss -23.25721 acc 0.66225 roc_auc 0.44225 prc_auc 0.63797[0m
[93maverage test of epoch 63: loss -23.76601 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 64: loss -23.88042 acc 0.66225 roc_auc 0.47686 prc_auc 0.65252[0m
[93maverage test of epoch 64: loss -24.39940 acc 0.67568 roc_auc 0.46000 prc_auc 0.65863[0m
[92maverage training of epoch 65: loss -24.51606 acc 0.66225 roc_auc 0.48059 prc_auc 0.65701[0m
[93maverage test of epoch 65: loss -25.04005 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 66: loss -25.15719 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 66: loss -25.68776 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 67: loss -25.80903 acc 0.66225 roc_auc 0.46284 prc_auc 0.64620[0m
[93maverage test of epoch 67: loss -26.34459 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 68: loss -26.46968 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 68: loss -27.01485 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 69: loss -27.14078 acc 0.66225 roc_auc 0.46784 prc_auc 0.64829[0m
[93maverage test of epoch 69: loss -27.69633 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 70: loss -27.81765 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 70: loss -28.38279 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 71: loss -28.50295 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 71: loss -29.07284 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 72: loss -29.19940 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 72: loss -29.77687 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 73: loss -29.90649 acc 0.66225 roc_auc 0.44784 prc_auc 0.64007[0m
[93maverage test of epoch 73: loss -30.49384 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 74: loss -30.61924 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 74: loss -31.21341 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 75: loss -31.34158 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 75: loss -31.94997 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 76: loss -32.07528 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 76: loss -32.68787 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 77: loss -32.81444 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 77: loss -33.43792 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 78: loss -33.56571 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 78: loss -34.19438 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 79: loss -34.32444 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 79: loss -34.96276 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 80: loss -35.09134 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 80: loss -35.73993 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 81: loss -35.86843 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 81: loss -36.52281 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 82: loss -36.65285 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 82: loss -37.31575 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 83: loss -37.44631 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 83: loss -38.12084 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 84: loss -38.25165 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 84: loss -38.93193 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 85: loss -39.06334 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 85: loss -39.75423 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 86: loss -39.88577 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 86: loss -40.58508 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 87: loss -40.71566 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 87: loss -41.42381 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 88: loss -41.55573 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 88: loss -42.27377 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 89: loss -42.40483 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 89: loss -43.13344 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 90: loss -43.26259 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 90: loss -43.99863 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 91: loss -44.13009 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 91: loss -44.87414 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 92: loss -45.00706 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 92: loss -45.76378 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 93: loss -45.89271 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 93: loss -46.65691 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 94: loss -46.78729 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 94: loss -47.56277 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 95: loss -47.69213 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 95: loss -48.47610 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 96: loss -48.60482 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 96: loss -49.39802 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 97: loss -49.52546 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 97: loss -50.32723 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 98: loss -50.45447 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 98: loss -51.26626 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 99: loss -51.39214 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 99: loss -52.21342 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.33224 acc 0.59603 roc_auc 0.52275 prc_auc 0.67074[0m
[93maverage test of epoch 0: loss -0.47154 acc 0.27027 roc_auc 0.32000 prc_auc 0.58734[0m
[92maverage training of epoch 1: loss -0.69400 acc 0.33113 roc_auc 0.57471 prc_auc 0.69932[0m
[93maverage test of epoch 1: loss -0.87563 acc 0.32432 roc_auc 0.58667 prc_auc 0.75335[0m
[92maverage training of epoch 2: loss -1.04495 acc 0.33775 roc_auc 0.57922 prc_auc 0.72505[0m
[93maverage test of epoch 2: loss -1.18889 acc 0.32432 roc_auc 0.39667 prc_auc 0.66680[0m
[92maverage training of epoch 3: loss -1.35324 acc 0.33775 roc_auc 0.42039 prc_auc 0.60847[0m
[93maverage test of epoch 3: loss -1.55383 acc 0.32432 roc_auc 0.46667 prc_auc 0.65522[0m
[92maverage training of epoch 4: loss -2.11779 acc 0.43709 roc_auc 0.40431 prc_auc 0.61477[0m
[93maverage test of epoch 4: loss -2.90102 acc 0.67568 roc_auc 0.56000 prc_auc 0.74267[0m
[92maverage training of epoch 5: loss -3.77811 acc 0.66225 roc_auc 0.46902 prc_auc 0.63847[0m
[93maverage test of epoch 5: loss -4.66605 acc 0.67568 roc_auc 0.58333 prc_auc 0.81138[0m
[92maverage training of epoch 6: loss -5.43731 acc 0.66225 roc_auc 0.49235 prc_auc 0.67605[0m
[93maverage test of epoch 6: loss -6.12681 acc 0.67568 roc_auc 0.51667 prc_auc 0.73614[0m
[92maverage training of epoch 7: loss -6.68883 acc 0.66225 roc_auc 0.47275 prc_auc 0.65574[0m
[93maverage test of epoch 7: loss -7.25741 acc 0.67568 roc_auc 0.25667 prc_auc 0.57832[0m
[92maverage training of epoch 8: loss -7.73422 acc 0.66225 roc_auc 0.47196 prc_auc 0.64639[0m
[93maverage test of epoch 8: loss -8.20062 acc 0.67568 roc_auc 0.55000 prc_auc 0.70502[0m
[92maverage training of epoch 9: loss -8.63253 acc 0.66225 roc_auc 0.54588 prc_auc 0.69349[0m
[93maverage test of epoch 9: loss -9.09852 acc 0.67568 roc_auc 0.42000 prc_auc 0.62998[0m
[92maverage training of epoch 10: loss -9.47554 acc 0.66225 roc_auc 0.44902 prc_auc 0.63175[0m
[93maverage test of epoch 10: loss -9.89915 acc 0.67568 roc_auc 0.50000 prc_auc 0.65110[0m
[92maverage training of epoch 11: loss -10.26209 acc 0.66225 roc_auc 0.48902 prc_auc 0.68407[0m
[93maverage test of epoch 11: loss -10.66589 acc 0.67568 roc_auc 0.48333 prc_auc 0.72915[0m
[92maverage training of epoch 12: loss -11.00962 acc 0.66225 roc_auc 0.46118 prc_auc 0.64438[0m
[93maverage test of epoch 12: loss -11.38519 acc 0.67568 roc_auc 0.50333 prc_auc 0.70117[0m
[92maverage training of epoch 13: loss -11.74510 acc 0.66225 roc_auc 0.47373 prc_auc 0.65805[0m
[93maverage test of epoch 13: loss -12.10658 acc 0.67568 roc_auc 0.42667 prc_auc 0.63948[0m
[92maverage training of epoch 14: loss -12.46095 acc 0.66225 roc_auc 0.48216 prc_auc 0.66692[0m
[93maverage test of epoch 14: loss -12.78213 acc 0.59459 roc_auc 0.44667 prc_auc 0.68843[0m
[92maverage training of epoch 15: loss -13.13385 acc 0.55629 roc_auc 0.48235 prc_auc 0.65341[0m
[93maverage test of epoch 15: loss -13.50970 acc 0.32432 roc_auc 0.70667 prc_auc 0.84985[0m
[92maverage training of epoch 16: loss -13.82441 acc 0.35762 roc_auc 0.44039 prc_auc 0.62711[0m
[93maverage test of epoch 16: loss -14.19975 acc 0.32432 roc_auc 0.67667 prc_auc 0.77223[0m
[92maverage training of epoch 17: loss -14.54199 acc 0.33775 roc_auc 0.47667 prc_auc 0.63567[0m
[93maverage test of epoch 17: loss -14.89084 acc 0.32432 roc_auc 0.40667 prc_auc 0.63465[0m
[92maverage training of epoch 18: loss -15.21786 acc 0.33775 roc_auc 0.49020 prc_auc 0.67041[0m
[93maverage test of epoch 18: loss -15.57015 acc 0.32432 roc_auc 0.55667 prc_auc 0.68529[0m
[92maverage training of epoch 19: loss -15.93826 acc 0.33775 roc_auc 0.43137 prc_auc 0.60821[0m
[93maverage test of epoch 19: loss -16.27450 acc 0.32432 roc_auc 0.46000 prc_auc 0.63696[0m
[92maverage training of epoch 20: loss -16.65139 acc 0.33775 roc_auc 0.45069 prc_auc 0.62784[0m
[93maverage test of epoch 20: loss -17.00525 acc 0.32432 roc_auc 0.42500 prc_auc 0.67594[0m
[92maverage training of epoch 21: loss -17.36390 acc 0.33775 roc_auc 0.47441 prc_auc 0.64907[0m
[93maverage test of epoch 21: loss -17.73839 acc 0.32432 roc_auc 0.39167 prc_auc 0.62274[0m
[92maverage training of epoch 22: loss -18.09080 acc 0.33775 roc_auc 0.41725 prc_auc 0.62469[0m
[93maverage test of epoch 22: loss -18.48712 acc 0.32432 roc_auc 0.56667 prc_auc 0.77624[0m
[92maverage training of epoch 23: loss -18.84249 acc 0.33775 roc_auc 0.43471 prc_auc 0.61899[0m
[93maverage test of epoch 23: loss -19.19479 acc 0.32432 roc_auc 0.39667 prc_auc 0.64587[0m
[92maverage training of epoch 24: loss -19.57683 acc 0.33775 roc_auc 0.41951 prc_auc 0.61440[0m
[93maverage test of epoch 24: loss -19.96706 acc 0.32432 roc_auc 0.55333 prc_auc 0.74534[0m
[92maverage training of epoch 25: loss -20.33719 acc 0.33775 roc_auc 0.40216 prc_auc 0.60996[0m
[93maverage test of epoch 25: loss -20.71942 acc 0.32432 roc_auc 0.53333 prc_auc 0.76262[0m
[92maverage training of epoch 26: loss -21.10935 acc 0.33775 roc_auc 0.40235 prc_auc 0.60331[0m
[93maverage test of epoch 26: loss -21.47557 acc 0.32432 roc_auc 0.55667 prc_auc 0.71730[0m
[92maverage training of epoch 27: loss -21.89060 acc 0.33775 roc_auc 0.39765 prc_auc 0.60470[0m
[93maverage test of epoch 27: loss -22.28827 acc 0.32432 roc_auc 0.52667 prc_auc 0.74951[0m
[92maverage training of epoch 28: loss -22.68422 acc 0.33775 roc_auc 0.40451 prc_auc 0.60254[0m
[93maverage test of epoch 28: loss -23.07579 acc 0.32432 roc_auc 0.36000 prc_auc 0.65161[0m
[92maverage training of epoch 29: loss -23.48822 acc 0.33775 roc_auc 0.40137 prc_auc 0.60325[0m
[93maverage test of epoch 29: loss -23.89934 acc 0.32432 roc_auc 0.52667 prc_auc 0.69847[0m
[92maverage training of epoch 30: loss -24.29336 acc 0.33775 roc_auc 0.39627 prc_auc 0.59499[0m
[93maverage test of epoch 30: loss -24.72079 acc 0.32432 roc_auc 0.27667 prc_auc 0.55496[0m
[92maverage training of epoch 31: loss -25.12145 acc 0.33775 roc_auc 0.39608 prc_auc 0.60200[0m
[93maverage test of epoch 31: loss -25.54408 acc 0.32432 roc_auc 0.57333 prc_auc 0.76031[0m
[92maverage training of epoch 32: loss -25.97666 acc 0.33775 roc_auc 0.39490 prc_auc 0.61153[0m
[93maverage test of epoch 32: loss -26.39485 acc 0.32432 roc_auc 0.46833 prc_auc 0.66076[0m
[92maverage training of epoch 33: loss -26.82716 acc 0.33775 roc_auc 0.39725 prc_auc 0.59743[0m
[93maverage test of epoch 33: loss -27.26759 acc 0.32432 roc_auc 0.42000 prc_auc 0.64160[0m
[92maverage training of epoch 34: loss -27.69741 acc 0.33775 roc_auc 0.39392 prc_auc 0.59103[0m
[93maverage test of epoch 34: loss -28.12663 acc 0.32432 roc_auc 0.34167 prc_auc 0.59281[0m
[92maverage training of epoch 35: loss -28.58051 acc 0.33775 roc_auc 0.38961 prc_auc 0.58949[0m
[93maverage test of epoch 35: loss -29.03030 acc 0.32432 roc_auc 0.51500 prc_auc 0.70526[0m
[92maverage training of epoch 36: loss -29.46841 acc 0.33775 roc_auc 0.38765 prc_auc 0.59821[0m
[93maverage test of epoch 36: loss -29.92849 acc 0.32432 roc_auc 0.49500 prc_auc 0.68665[0m
[92maverage training of epoch 37: loss -30.37908 acc 0.33775 roc_auc 0.39529 prc_auc 0.59138[0m
[93maverage test of epoch 37: loss -30.83979 acc 0.32432 roc_auc 0.43500 prc_auc 0.65162[0m
[92maverage training of epoch 38: loss -31.30388 acc 0.33775 roc_auc 0.39294 prc_auc 0.59295[0m
[93maverage test of epoch 38: loss -31.76486 acc 0.32432 roc_auc 0.72000 prc_auc 0.86246[0m
[92maverage training of epoch 39: loss -32.24142 acc 0.41060 roc_auc 0.39333 prc_auc 0.59185[0m
[93maverage test of epoch 39: loss -32.72275 acc 0.32432 roc_auc 0.47333 prc_auc 0.71013[0m
[92maverage training of epoch 40: loss -33.18695 acc 0.56954 roc_auc 0.38490 prc_auc 0.58682[0m
[93maverage test of epoch 40: loss -33.67031 acc 0.67568 roc_auc 0.53000 prc_auc 0.75288[0m
[92maverage training of epoch 41: loss -34.15374 acc 0.66225 roc_auc 0.38853 prc_auc 0.58474[0m
[93maverage test of epoch 41: loss -34.65345 acc 0.67568 roc_auc 0.37167 prc_auc 0.63988[0m
[92maverage training of epoch 42: loss -35.13257 acc 0.66225 roc_auc 0.38196 prc_auc 0.58273[0m
[93maverage test of epoch 42: loss -35.62922 acc 0.67568 roc_auc 0.44833 prc_auc 0.66629[0m
[92maverage training of epoch 43: loss -36.12481 acc 0.66225 roc_auc 0.38216 prc_auc 0.58533[0m
[93maverage test of epoch 43: loss -36.63615 acc 0.67568 roc_auc 0.37667 prc_auc 0.65284[0m
[92maverage training of epoch 44: loss -37.12755 acc 0.66225 roc_auc 0.37588 prc_auc 0.58065[0m
[93maverage test of epoch 44: loss -37.64823 acc 0.67568 roc_auc 0.51167 prc_auc 0.70539[0m
[92maverage training of epoch 45: loss -38.14799 acc 0.66225 roc_auc 0.37824 prc_auc 0.57899[0m
[93maverage test of epoch 45: loss -38.67899 acc 0.67568 roc_auc 0.49333 prc_auc 0.68310[0m
[92maverage training of epoch 46: loss -39.18839 acc 0.66225 roc_auc 0.37882 prc_auc 0.57919[0m
[93maverage test of epoch 46: loss -39.72136 acc 0.67568 roc_auc 0.58000 prc_auc 0.73258[0m
[92maverage training of epoch 47: loss -40.23630 acc 0.66225 roc_auc 0.37882 prc_auc 0.57826[0m
[93maverage test of epoch 47: loss -40.77496 acc 0.67568 roc_auc 0.32000 prc_auc 0.60587[0m
[92maverage training of epoch 48: loss -41.30033 acc 0.66225 roc_auc 0.37549 prc_auc 0.57720[0m
[93maverage test of epoch 48: loss -41.85088 acc 0.67568 roc_auc 0.48500 prc_auc 0.67710[0m
[92maverage training of epoch 49: loss -42.37392 acc 0.66225 roc_auc 0.37686 prc_auc 0.57574[0m
[93maverage test of epoch 49: loss -42.93930 acc 0.67568 roc_auc 0.32000 prc_auc 0.57699[0m
[92maverage training of epoch 50: loss -43.46871 acc 0.66225 roc_auc 0.37843 prc_auc 0.57674[0m
[93maverage test of epoch 50: loss -44.03438 acc 0.67568 roc_auc 0.59500 prc_auc 0.81312[0m
[92maverage training of epoch 51: loss -44.57977 acc 0.66225 roc_auc 0.37824 prc_auc 0.57712[0m
[93maverage test of epoch 51: loss -45.15269 acc 0.67568 roc_auc 0.60833 prc_auc 0.70512[0m
[92maverage training of epoch 52: loss -45.70359 acc 0.66225 roc_auc 0.37735 prc_auc 0.57700[0m
[93maverage test of epoch 52: loss -46.28479 acc 0.67568 roc_auc 0.54833 prc_auc 0.75954[0m
[92maverage training of epoch 53: loss -46.83930 acc 0.66225 roc_auc 0.37647 prc_auc 0.57552[0m
[93maverage test of epoch 53: loss -47.43278 acc 0.67568 roc_auc 0.26167 prc_auc 0.54911[0m
[92maverage training of epoch 54: loss -47.98896 acc 0.66225 roc_auc 0.37569 prc_auc 0.57365[0m
[93maverage test of epoch 54: loss -48.59754 acc 0.67568 roc_auc 0.52667 prc_auc 0.76950[0m
[92maverage training of epoch 55: loss -49.15589 acc 0.66225 roc_auc 0.37324 prc_auc 0.57246[0m
[93maverage test of epoch 55: loss -49.76916 acc 0.67568 roc_auc 0.62167 prc_auc 0.78730[0m
[92maverage training of epoch 56: loss -50.33843 acc 0.66225 roc_auc 0.37490 prc_auc 0.57327[0m
[93maverage test of epoch 56: loss -50.95792 acc 0.67568 roc_auc 0.39667 prc_auc 0.64433[0m
[92maverage training of epoch 57: loss -51.53500 acc 0.66225 roc_auc 0.37157 prc_auc 0.57092[0m
[93maverage test of epoch 57: loss -52.16953 acc 0.67568 roc_auc 0.33000 prc_auc 0.57633[0m
[92maverage training of epoch 58: loss -52.74553 acc 0.66225 roc_auc 0.37392 prc_auc 0.57277[0m
[93maverage test of epoch 58: loss -53.38440 acc 0.67568 roc_auc 0.50333 prc_auc 0.71754[0m
[92maverage training of epoch 59: loss -53.96935 acc 0.66225 roc_auc 0.37304 prc_auc 0.57415[0m
[93maverage test of epoch 59: loss -54.62383 acc 0.67568 roc_auc 0.46833 prc_auc 0.63933[0m
[92maverage training of epoch 60: loss -55.21515 acc 0.66225 roc_auc 0.37157 prc_auc 0.57076[0m
[93maverage test of epoch 60: loss -55.86867 acc 0.67568 roc_auc 0.50833 prc_auc 0.71287[0m
[92maverage training of epoch 61: loss -56.46924 acc 0.66225 roc_auc 0.37294 prc_auc 0.57252[0m
[93maverage test of epoch 61: loss -57.13384 acc 0.67568 roc_auc 0.59333 prc_auc 0.77560[0m
[92maverage training of epoch 62: loss -57.74033 acc 0.66225 roc_auc 0.37176 prc_auc 0.57130[0m
[93maverage test of epoch 62: loss -58.41382 acc 0.67568 roc_auc 0.49000 prc_auc 0.66600[0m
[92maverage training of epoch 63: loss -59.02373 acc 0.66225 roc_auc 0.37039 prc_auc 0.57016[0m
[93maverage test of epoch 63: loss -59.71325 acc 0.67568 roc_auc 0.37167 prc_auc 0.61315[0m
[92maverage training of epoch 64: loss -60.32440 acc 0.66225 roc_auc 0.36941 prc_auc 0.56875[0m
[93maverage test of epoch 64: loss -61.02033 acc 0.67568 roc_auc 0.64333 prc_auc 0.83102[0m
[92maverage training of epoch 65: loss -61.63948 acc 0.66225 roc_auc 0.36784 prc_auc 0.56776[0m
[93maverage test of epoch 65: loss -62.34717 acc 0.67568 roc_auc 0.61167 prc_auc 0.76315[0m
[92maverage training of epoch 66: loss -62.96868 acc 0.66225 roc_auc 0.36863 prc_auc 0.56812[0m
[93maverage test of epoch 66: loss -63.68790 acc 0.67568 roc_auc 0.66833 prc_auc 0.83392[0m
[92maverage training of epoch 67: loss -64.31485 acc 0.66225 roc_auc 0.36863 prc_auc 0.56805[0m
[93maverage test of epoch 67: loss -65.04243 acc 0.67568 roc_auc 0.38167 prc_auc 0.66543[0m
[92maverage training of epoch 68: loss -65.67548 acc 0.66225 roc_auc 0.36745 prc_auc 0.56731[0m
[93maverage test of epoch 68: loss -66.41288 acc 0.67568 roc_auc 0.45167 prc_auc 0.67088[0m
[92maverage training of epoch 69: loss -67.04995 acc 0.66225 roc_auc 0.36941 prc_auc 0.56830[0m
[93maverage test of epoch 69: loss -67.79418 acc 0.67568 roc_auc 0.35000 prc_auc 0.60603[0m
[92maverage training of epoch 70: loss -68.43723 acc 0.66225 roc_auc 0.36990 prc_auc 0.56858[0m
[93maverage test of epoch 70: loss -69.19637 acc 0.67568 roc_auc 0.40000 prc_auc 0.62856[0m
[92maverage training of epoch 71: loss -69.84047 acc 0.66225 roc_auc 0.36873 prc_auc 0.56828[0m
[93maverage test of epoch 71: loss -70.60747 acc 0.67568 roc_auc 0.65667 prc_auc 0.80252[0m
[92maverage training of epoch 72: loss -71.25666 acc 0.66225 roc_auc 0.37118 prc_auc 0.56984[0m
[93maverage test of epoch 72: loss -72.03441 acc 0.67568 roc_auc 0.49167 prc_auc 0.70208[0m
[92maverage training of epoch 73: loss -72.68798 acc 0.66225 roc_auc 0.36990 prc_auc 0.56878[0m
[93maverage test of epoch 73: loss -73.47495 acc 0.67568 roc_auc 0.53333 prc_auc 0.70063[0m
[92maverage training of epoch 74: loss -74.13156 acc 0.66225 roc_auc 0.36922 prc_auc 0.56706[0m
[93maverage test of epoch 74: loss -74.92941 acc 0.67568 roc_auc 0.35000 prc_auc 0.62547[0m
[92maverage training of epoch 75: loss -75.59101 acc 0.66225 roc_auc 0.36804 prc_auc 0.56742[0m
[93maverage test of epoch 75: loss -76.39792 acc 0.67568 roc_auc 0.62000 prc_auc 0.77792[0m
[92maverage training of epoch 76: loss -77.06541 acc 0.66225 roc_auc 0.36873 prc_auc 0.56742[0m
[93maverage test of epoch 76: loss -77.88292 acc 0.67568 roc_auc 0.53000 prc_auc 0.69141[0m
[92maverage training of epoch 77: loss -78.55313 acc 0.66225 roc_auc 0.36755 prc_auc 0.56593[0m
[93maverage test of epoch 77: loss -79.38158 acc 0.67568 roc_auc 0.45500 prc_auc 0.66068[0m
[92maverage training of epoch 78: loss -80.05480 acc 0.66225 roc_auc 0.36569 prc_auc 0.56421[0m
[93maverage test of epoch 78: loss -80.89443 acc 0.67568 roc_auc 0.41333 prc_auc 0.63856[0m
[92maverage training of epoch 79: loss -81.57262 acc 0.66225 roc_auc 0.36676 prc_auc 0.56441[0m
[93maverage test of epoch 79: loss -82.42139 acc 0.67568 roc_auc 0.55500 prc_auc 0.70716[0m
[92maverage training of epoch 80: loss -83.10434 acc 0.66225 roc_auc 0.36686 prc_auc 0.56533[0m
[93maverage test of epoch 80: loss -83.96393 acc 0.67568 roc_auc 0.48667 prc_auc 0.68411[0m
[92maverage training of epoch 81: loss -84.65125 acc 0.66225 roc_auc 0.36480 prc_auc 0.56261[0m
[93maverage test of epoch 81: loss -85.52216 acc 0.67568 roc_auc 0.42333 prc_auc 0.65519[0m
[92maverage training of epoch 82: loss -86.21233 acc 0.66225 roc_auc 0.36304 prc_auc 0.56038[0m
[93maverage test of epoch 82: loss -87.09430 acc 0.67568 roc_auc 0.46833 prc_auc 0.66955[0m
[92maverage training of epoch 83: loss -87.78765 acc 0.66225 roc_auc 0.36412 prc_auc 0.56162[0m
[93maverage test of epoch 83: loss -88.68259 acc 0.67568 roc_auc 0.47833 prc_auc 0.67809[0m
[92maverage training of epoch 84: loss -89.37934 acc 0.66225 roc_auc 0.36471 prc_auc 0.56275[0m
[93maverage test of epoch 84: loss -90.28485 acc 0.67568 roc_auc 0.54833 prc_auc 0.70127[0m
[92maverage training of epoch 85: loss -90.98477 acc 0.66225 roc_auc 0.36657 prc_auc 0.56549[0m
[93maverage test of epoch 85: loss -91.90123 acc 0.67568 roc_auc 0.50000 prc_auc 0.67981[0m
[92maverage training of epoch 86: loss -92.60547 acc 0.66225 roc_auc 0.36520 prc_auc 0.56462[0m
[93maverage test of epoch 86: loss -93.53285 acc 0.67568 roc_auc 0.36833 prc_auc 0.61515[0m
[92maverage training of epoch 87: loss -94.24166 acc 0.66225 roc_auc 0.36608 prc_auc 0.56443[0m
[93maverage test of epoch 87: loss -95.17963 acc 0.67568 roc_auc 0.46000 prc_auc 0.65219[0m
[92maverage training of epoch 88: loss -95.89194 acc 0.66225 roc_auc 0.36706 prc_auc 0.56938[0m
[93maverage test of epoch 88: loss -96.84256 acc 0.67568 roc_auc 0.49000 prc_auc 0.67160[0m
[92maverage training of epoch 89: loss -97.55705 acc 0.66225 roc_auc 0.36725 prc_auc 0.56781[0m
[93maverage test of epoch 89: loss -98.51916 acc 0.67568 roc_auc 0.49667 prc_auc 0.67566[0m
[92maverage training of epoch 90: loss -99.23752 acc 0.66225 roc_auc 0.36706 prc_auc 0.56832[0m
[93maverage test of epoch 90: loss -100.21165 acc 0.67568 roc_auc 0.34000 prc_auc 0.61039[0m
[92maverage training of epoch 91: loss -100.93249 acc 0.66225 roc_auc 0.36725 prc_auc 0.56918[0m
[93maverage test of epoch 91: loss -101.91926 acc 0.67568 roc_auc 0.48167 prc_auc 0.66775[0m
[92maverage training of epoch 92: loss -102.64305 acc 0.66225 roc_auc 0.36706 prc_auc 0.56841[0m
[93maverage test of epoch 92: loss -103.64038 acc 0.67568 roc_auc 0.48000 prc_auc 0.66703[0m
[92maverage training of epoch 93: loss -104.36666 acc 0.66225 roc_auc 0.36745 prc_auc 0.56786[0m
[93maverage test of epoch 93: loss -105.37564 acc 0.67568 roc_auc 0.48333 prc_auc 0.66847[0m
[92maverage training of epoch 94: loss -106.10461 acc 0.66225 roc_auc 0.36706 prc_auc 0.56831[0m
[93maverage test of epoch 94: loss -107.12611 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 95: loss -107.85720 acc 0.66225 roc_auc 0.36794 prc_auc 0.56872[0m
[93maverage test of epoch 95: loss -108.89018 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 96: loss -109.62314 acc 0.66225 roc_auc 0.37059 prc_auc 0.57412[0m
[93maverage test of epoch 96: loss -110.66775 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 97: loss -111.40379 acc 0.66225 roc_auc 0.36765 prc_auc 0.57046[0m
[93maverage test of epoch 97: loss -112.46020 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 98: loss -113.19870 acc 0.66225 roc_auc 0.36931 prc_auc 0.57229[0m
[93maverage test of epoch 98: loss -114.26734 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 99: loss -115.00840 acc 0.66225 roc_auc 0.37216 prc_auc 0.57881[0m
[93maverage test of epoch 99: loss -116.08958 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 1)
('lr', 0.0001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.66501 ROC_AUC (avg): 0.5 PRC_AUC (avg): 0.66501 

Average forward propagation time taken(ms): 4.28924607258594
Average backward propagation time taken(ms): 1.5758566726815317

