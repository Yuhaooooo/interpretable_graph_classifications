# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-18-15-04/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-18-15-04/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 16,
 'epochs': 50,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 4,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.001,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 1,
 'num_workers': 8,
 'number_of_mlp_layer': 0,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-17-18-15-04',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 50, 'learning_rate': 0.001, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -0.33836 acc 0.33333 roc_auc 0.48400 prc_auc 0.65068[0m
[93maverage test of epoch 0: loss -0.95406 acc 0.34211 roc_auc 0.88615 prc_auc 0.94926[0m
[92maverage training of epoch 1: loss -1.45803 acc 0.50000 roc_auc 0.50160 prc_auc 0.70957[0m
[93maverage test of epoch 1: loss -1.97115 acc 0.65789 roc_auc 0.86462 prc_auc 0.93807[0m
[92maverage training of epoch 2: loss -2.41038 acc 0.71333 roc_auc 0.78800 prc_auc 0.86390[0m
[93maverage test of epoch 2: loss -2.84427 acc 0.76316 roc_auc 0.86462 prc_auc 0.93807[0m
[92maverage training of epoch 3: loss -3.21614 acc 0.76000 roc_auc 0.81440 prc_auc 0.86766[0m
[93maverage test of epoch 3: loss -3.45690 acc 0.65789 roc_auc 0.88615 prc_auc 0.94870[0m
[92maverage training of epoch 4: loss -3.93439 acc 0.78667 roc_auc 0.85260 prc_auc 0.90293[0m
[93maverage test of epoch 4: loss -4.30003 acc 0.81579 roc_auc 0.90769 prc_auc 0.95773[0m
[92maverage training of epoch 5: loss -4.65820 acc 0.84000 roc_auc 0.80700 prc_auc 0.86914[0m
[93maverage test of epoch 5: loss -4.84338 acc 0.78947 roc_auc 0.89231 prc_auc 0.95163[0m
[92maverage training of epoch 6: loss -5.42292 acc 0.88667 roc_auc 0.83500 prc_auc 0.87669[0m
[93maverage test of epoch 6: loss -5.53079 acc 0.81579 roc_auc 0.88308 prc_auc 0.95114[0m
[92maverage training of epoch 7: loss -5.90240 acc 0.83333 roc_auc 0.65540 prc_auc 0.73018[0m
[93maverage test of epoch 7: loss -6.18600 acc 0.84211 roc_auc 0.88923 prc_auc 0.95460[0m
[92maverage training of epoch 8: loss -6.58564 acc 0.87333 roc_auc 0.82900 prc_auc 0.86451[0m
[93maverage test of epoch 8: loss -6.60929 acc 0.81579 roc_auc 0.88000 prc_auc 0.94983[0m
[92maverage training of epoch 9: loss -7.17371 acc 0.88667 roc_auc 0.82520 prc_auc 0.84844[0m
[93maverage test of epoch 9: loss -7.29018 acc 0.84211 roc_auc 0.88923 prc_auc 0.95530[0m
[92maverage training of epoch 10: loss -7.52669 acc 0.82000 roc_auc 0.74520 prc_auc 0.80842[0m
[93maverage test of epoch 10: loss -7.82175 acc 0.84211 roc_auc 0.88615 prc_auc 0.95364[0m
[92maverage training of epoch 11: loss -8.14917 acc 0.84667 roc_auc 0.72420 prc_auc 0.76766[0m
[93maverage test of epoch 11: loss -8.12219 acc 0.76316 roc_auc 0.90462 prc_auc 0.95865[0m
[92maverage training of epoch 12: loss -8.54694 acc 0.80667 roc_auc 0.74340 prc_auc 0.80698[0m
[93maverage test of epoch 12: loss -8.86630 acc 0.84211 roc_auc 0.90769 prc_auc 0.96011[0m
[92maverage training of epoch 13: loss -9.27060 acc 0.86667 roc_auc 0.78460 prc_auc 0.79758[0m
[93maverage test of epoch 13: loss -9.07001 acc 0.73684 roc_auc 0.90615 prc_auc 0.95865[0m
[92maverage training of epoch 14: loss -9.59277 acc 0.80000 roc_auc 0.72900 prc_auc 0.79503[0m
[93maverage test of epoch 14: loss -9.76452 acc 0.81579 roc_auc 0.90154 prc_auc 0.95549[0m
[92maverage training of epoch 15: loss -10.14833 acc 0.84667 roc_auc 0.80000 prc_auc 0.86134[0m
[93maverage test of epoch 15: loss -10.03364 acc 0.78947 roc_auc 0.88923 prc_auc 0.94828[0m
[92maverage training of epoch 16: loss -10.87076 acc 0.87333 roc_auc 0.76690 prc_auc 0.79227[0m
[93maverage test of epoch 16: loss -10.92234 acc 0.84211 roc_auc 0.91231 prc_auc 0.96127[0m
[92maverage training of epoch 17: loss -11.18506 acc 0.82000 roc_auc 0.74340 prc_auc 0.80062[0m
[93maverage test of epoch 17: loss -11.27758 acc 0.81579 roc_auc 0.90308 prc_auc 0.95477[0m
[92maverage training of epoch 18: loss -11.90583 acc 0.88000 roc_auc 0.80700 prc_auc 0.83152[0m
[93maverage test of epoch 18: loss -11.78266 acc 0.81579 roc_auc 0.90769 prc_auc 0.95618[0m
[92maverage training of epoch 19: loss -12.42406 acc 0.88000 roc_auc 0.80630 prc_auc 0.83308[0m
[93maverage test of epoch 19: loss -12.28630 acc 0.81579 roc_auc 0.90154 prc_auc 0.95445[0m
[92maverage training of epoch 20: loss -12.87566 acc 0.84667 roc_auc 0.70440 prc_auc 0.74247[0m
[93maverage test of epoch 20: loss -12.50577 acc 0.71053 roc_auc 0.85692 prc_auc 0.89837[0m
[92maverage training of epoch 21: loss -13.10356 acc 0.75333 roc_auc 0.57920 prc_auc 0.68083[0m
[93maverage test of epoch 21: loss -12.97137 acc 0.65789 roc_auc 0.86923 prc_auc 0.89343[0m
[92maverage training of epoch 22: loss -13.31762 acc 0.66667 roc_auc 0.36540 prc_auc 0.57221[0m
[93maverage test of epoch 22: loss -13.52713 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -13.87507 acc 0.66667 roc_auc 0.36260 prc_auc 0.56790[0m
[93maverage test of epoch 23: loss -14.08268 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -14.43188 acc 0.66667 roc_auc 0.36190 prc_auc 0.56676[0m
[93maverage test of epoch 24: loss -14.63761 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -14.98813 acc 0.66667 roc_auc 0.35970 prc_auc 0.56731[0m
[93maverage test of epoch 25: loss -15.19202 acc 0.65789 roc_auc 0.61538 prc_auc 0.71429[0m
[92maverage training of epoch 26: loss -15.54387 acc 0.66667 roc_auc 0.36030 prc_auc 0.56681[0m
[93maverage test of epoch 26: loss -15.74596 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -16.09919 acc 0.66667 roc_auc 0.36080 prc_auc 0.56785[0m
[93maverage test of epoch 27: loss -16.29950 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -16.65413 acc 0.66667 roc_auc 0.36130 prc_auc 0.56714[0m
[93maverage test of epoch 28: loss -16.85270 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -17.20875 acc 0.66667 roc_auc 0.36040 prc_auc 0.56647[0m
[93maverage test of epoch 29: loss -17.40559 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -17.76308 acc 0.66667 roc_auc 0.35990 prc_auc 0.56779[0m
[93maverage test of epoch 30: loss -17.95821 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -18.31715 acc 0.66667 roc_auc 0.36350 prc_auc 0.57036[0m
[93maverage test of epoch 31: loss -18.51060 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -18.87101 acc 0.66667 roc_auc 0.36110 prc_auc 0.57029[0m
[93maverage test of epoch 32: loss -19.06278 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -19.42468 acc 0.66667 roc_auc 0.36360 prc_auc 0.57346[0m
[93maverage test of epoch 33: loss -19.61478 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -19.97818 acc 0.66667 roc_auc 0.35930 prc_auc 0.57030[0m
[93maverage test of epoch 34: loss -20.16663 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -20.53153 acc 0.66667 roc_auc 0.35980 prc_auc 0.57366[0m
[93maverage test of epoch 35: loss -20.71834 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -21.08475 acc 0.66667 roc_auc 0.36070 prc_auc 0.57320[0m
[93maverage test of epoch 36: loss -21.26993 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -21.63786 acc 0.66667 roc_auc 0.36800 prc_auc 0.57959[0m
[93maverage test of epoch 37: loss -21.82141 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -22.19087 acc 0.66667 roc_auc 0.36200 prc_auc 0.57791[0m
[93maverage test of epoch 38: loss -22.37279 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -22.74379 acc 0.66667 roc_auc 0.35890 prc_auc 0.58382[0m
[93maverage test of epoch 39: loss -22.92410 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -23.29663 acc 0.66667 roc_auc 0.36500 prc_auc 0.58520[0m
[93maverage test of epoch 40: loss -23.47533 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -23.84940 acc 0.66667 roc_auc 0.35860 prc_auc 0.58194[0m
[93maverage test of epoch 41: loss -24.02650 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -24.40212 acc 0.66667 roc_auc 0.36450 prc_auc 0.58945[0m
[93maverage test of epoch 42: loss -24.57762 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -24.95478 acc 0.66667 roc_auc 0.37000 prc_auc 0.59731[0m
[93maverage test of epoch 43: loss -25.12868 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -25.50739 acc 0.66667 roc_auc 0.37100 prc_auc 0.59854[0m
[93maverage test of epoch 44: loss -25.67970 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -26.05997 acc 0.66667 roc_auc 0.36060 prc_auc 0.59470[0m
[93maverage test of epoch 45: loss -26.23067 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -26.61250 acc 0.66667 roc_auc 0.38610 prc_auc 0.61015[0m
[93maverage test of epoch 46: loss -26.78162 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -27.16501 acc 0.66667 roc_auc 0.39710 prc_auc 0.61488[0m
[93maverage test of epoch 47: loss -27.33254 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -27.71749 acc 0.66667 roc_auc 0.42790 prc_auc 0.63206[0m
[93maverage test of epoch 48: loss -27.88343 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -28.26994 acc 0.66667 roc_auc 0.42820 prc_auc 0.63240[0m
[93maverage test of epoch 49: loss -28.43429 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -1.13624 acc 0.43333 roc_auc 0.46600 prc_auc 0.65907[0m
[93maverage test of epoch 0: loss -2.47877 acc 0.65789 roc_auc 0.79692 prc_auc 0.89472[0m
[92maverage training of epoch 1: loss -3.15434 acc 0.66667 roc_auc 0.47160 prc_auc 0.66250[0m
[93maverage test of epoch 1: loss -3.64656 acc 0.65789 roc_auc 0.80462 prc_auc 0.90072[0m
[92maverage training of epoch 2: loss -4.03562 acc 0.66667 roc_auc 0.43920 prc_auc 0.61841[0m
[93maverage test of epoch 2: loss -4.39146 acc 0.65789 roc_auc 0.80462 prc_auc 0.90058[0m
[92maverage training of epoch 3: loss -4.74144 acc 0.66667 roc_auc 0.42520 prc_auc 0.60229[0m
[93maverage test of epoch 3: loss -5.06309 acc 0.65789 roc_auc 0.80462 prc_auc 0.90058[0m
[92maverage training of epoch 4: loss -5.39575 acc 0.66667 roc_auc 0.42200 prc_auc 0.59888[0m
[93maverage test of epoch 4: loss -5.69785 acc 0.65789 roc_auc 0.80308 prc_auc 0.89908[0m
[92maverage training of epoch 5: loss -6.02034 acc 0.66667 roc_auc 0.42020 prc_auc 0.59967[0m
[93maverage test of epoch 5: loss -6.30914 acc 0.65789 roc_auc 0.79385 prc_auc 0.88780[0m
[92maverage training of epoch 6: loss -6.62562 acc 0.66667 roc_auc 0.42140 prc_auc 0.60590[0m
[93maverage test of epoch 6: loss -6.90500 acc 0.65789 roc_auc 0.87846 prc_auc 0.92352[0m
[92maverage training of epoch 7: loss -7.21800 acc 0.66667 roc_auc 0.42300 prc_auc 0.61138[0m
[93maverage test of epoch 7: loss -7.49037 acc 0.65789 roc_auc 0.86769 prc_auc 0.91703[0m
[92maverage training of epoch 8: loss -7.80143 acc 0.66667 roc_auc 0.42240 prc_auc 0.61092[0m
[93maverage test of epoch 8: loss -8.06835 acc 0.65789 roc_auc 0.87077 prc_auc 0.91434[0m
[92maverage training of epoch 9: loss -8.37843 acc 0.66667 roc_auc 0.42220 prc_auc 0.60970[0m
[93maverage test of epoch 9: loss -8.64090 acc 0.65789 roc_auc 0.86154 prc_auc 0.89346[0m
[92maverage training of epoch 10: loss -8.95065 acc 0.66667 roc_auc 0.42180 prc_auc 0.60960[0m
[93maverage test of epoch 10: loss -9.20938 acc 0.65789 roc_auc 0.86462 prc_auc 0.89079[0m
[92maverage training of epoch 11: loss -9.51924 acc 0.66667 roc_auc 0.42170 prc_auc 0.60810[0m
[93maverage test of epoch 11: loss -9.77470 acc 0.65789 roc_auc 0.87077 prc_auc 0.89689[0m
[92maverage training of epoch 12: loss -10.08498 acc 0.66667 roc_auc 0.42160 prc_auc 0.60810[0m
[93maverage test of epoch 12: loss -10.33753 acc 0.65789 roc_auc 0.82462 prc_auc 0.84889[0m
[92maverage training of epoch 13: loss -10.64847 acc 0.66667 roc_auc 0.42140 prc_auc 0.60715[0m
[93maverage test of epoch 13: loss -10.89838 acc 0.65789 roc_auc 0.82462 prc_auc 0.84889[0m
[92maverage training of epoch 14: loss -11.21015 acc 0.66667 roc_auc 0.42100 prc_auc 0.60588[0m
[93maverage test of epoch 14: loss -11.45761 acc 0.65789 roc_auc 0.82769 prc_auc 0.85173[0m
[92maverage training of epoch 15: loss -11.77035 acc 0.66667 roc_auc 0.42070 prc_auc 0.60517[0m
[93maverage test of epoch 15: loss -12.01552 acc 0.65789 roc_auc 0.81231 prc_auc 0.84174[0m
[92maverage training of epoch 16: loss -12.32934 acc 0.66667 roc_auc 0.42060 prc_auc 0.60510[0m
[93maverage test of epoch 16: loss -12.57235 acc 0.65789 roc_auc 0.80462 prc_auc 0.83625[0m
[92maverage training of epoch 17: loss -12.88732 acc 0.66667 roc_auc 0.42040 prc_auc 0.60495[0m
[93maverage test of epoch 17: loss -13.12826 acc 0.65789 roc_auc 0.82308 prc_auc 0.84667[0m
[92maverage training of epoch 18: loss -13.44446 acc 0.66667 roc_auc 0.42060 prc_auc 0.60502[0m
[93maverage test of epoch 18: loss -13.68341 acc 0.65789 roc_auc 0.81846 prc_auc 0.84819[0m
[92maverage training of epoch 19: loss -14.00090 acc 0.66667 roc_auc 0.42020 prc_auc 0.60458[0m
[93maverage test of epoch 19: loss -14.23793 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 20: loss -14.55674 acc 0.66667 roc_auc 0.42030 prc_auc 0.60458[0m
[93maverage test of epoch 20: loss -14.79191 acc 0.65789 roc_auc 0.68000 prc_auc 0.78105[0m
[92maverage training of epoch 21: loss -15.11208 acc 0.66667 roc_auc 0.42030 prc_auc 0.60458[0m
[93maverage test of epoch 21: loss -15.34543 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 22: loss -15.66700 acc 0.66667 roc_auc 0.42030 prc_auc 0.60458[0m
[93maverage test of epoch 22: loss -15.89856 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 23: loss -16.22155 acc 0.66667 roc_auc 0.42030 prc_auc 0.60497[0m
[93maverage test of epoch 23: loss -16.45136 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 24: loss -16.77580 acc 0.66667 roc_auc 0.42030 prc_auc 0.60497[0m
[93maverage test of epoch 24: loss -17.00387 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 25: loss -17.32978 acc 0.66667 roc_auc 0.42020 prc_auc 0.60461[0m
[93maverage test of epoch 25: loss -17.55615 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 26: loss -17.88354 acc 0.66667 roc_auc 0.42020 prc_auc 0.60494[0m
[93maverage test of epoch 26: loss -18.10821 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 27: loss -18.43710 acc 0.66667 roc_auc 0.42030 prc_auc 0.60461[0m
[93maverage test of epoch 27: loss -18.66010 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 28: loss -18.99049 acc 0.66667 roc_auc 0.42030 prc_auc 0.60499[0m
[93maverage test of epoch 28: loss -19.21183 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 29: loss -19.54373 acc 0.66667 roc_auc 0.42010 prc_auc 0.60540[0m
[93maverage test of epoch 29: loss -19.76343 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 30: loss -20.09686 acc 0.66667 roc_auc 0.42050 prc_auc 0.60542[0m
[93maverage test of epoch 30: loss -20.31492 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 31: loss -20.64988 acc 0.66667 roc_auc 0.42060 prc_auc 0.60552[0m
[93maverage test of epoch 31: loss -20.86631 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 32: loss -21.20280 acc 0.66667 roc_auc 0.42040 prc_auc 0.60566[0m
[93maverage test of epoch 32: loss -21.41761 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 33: loss -21.75564 acc 0.66667 roc_auc 0.42020 prc_auc 0.60537[0m
[93maverage test of epoch 33: loss -21.96884 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -22.30842 acc 0.66667 roc_auc 0.42090 prc_auc 0.60543[0m
[93maverage test of epoch 34: loss -22.52000 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 35: loss -22.86113 acc 0.66667 roc_auc 0.42130 prc_auc 0.60570[0m
[93maverage test of epoch 35: loss -23.07111 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 36: loss -23.41379 acc 0.66667 roc_auc 0.42050 prc_auc 0.60404[0m
[93maverage test of epoch 36: loss -23.62217 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -23.96641 acc 0.66667 roc_auc 0.42020 prc_auc 0.60461[0m
[93maverage test of epoch 37: loss -24.17318 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -24.51898 acc 0.66667 roc_auc 0.42070 prc_auc 0.60550[0m
[93maverage test of epoch 38: loss -24.72417 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -25.07152 acc 0.66667 roc_auc 0.42120 prc_auc 0.60547[0m
[93maverage test of epoch 39: loss -25.27511 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -25.62403 acc 0.66667 roc_auc 0.42040 prc_auc 0.60386[0m
[93maverage test of epoch 40: loss -25.82603 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -26.17652 acc 0.66667 roc_auc 0.42030 prc_auc 0.60260[0m
[93maverage test of epoch 41: loss -26.37693 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -26.72898 acc 0.66667 roc_auc 0.41970 prc_auc 0.60210[0m
[93maverage test of epoch 42: loss -26.92780 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -27.28142 acc 0.66667 roc_auc 0.41990 prc_auc 0.60302[0m
[93maverage test of epoch 43: loss -27.47865 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -27.83384 acc 0.66667 roc_auc 0.41980 prc_auc 0.59945[0m
[93maverage test of epoch 44: loss -28.02949 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -28.38625 acc 0.66667 roc_auc 0.41960 prc_auc 0.60582[0m
[93maverage test of epoch 45: loss -28.58031 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -28.93864 acc 0.66667 roc_auc 0.42040 prc_auc 0.60548[0m
[93maverage test of epoch 46: loss -29.13112 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -29.49102 acc 0.66667 roc_auc 0.42010 prc_auc 0.59957[0m
[93maverage test of epoch 47: loss -29.68192 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -30.04339 acc 0.66667 roc_auc 0.42450 prc_auc 0.60981[0m
[93maverage test of epoch 48: loss -30.23271 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -30.59575 acc 0.66667 roc_auc 0.41710 prc_auc 0.59673[0m
[93maverage test of epoch 49: loss -30.78349 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -0.11268 acc 0.54000 roc_auc 0.41840 prc_auc 0.63460[0m
[93maverage test of epoch 0: loss -0.54858 acc 0.65789 roc_auc 0.95077 prc_auc 0.97861[0m
[92maverage training of epoch 1: loss -1.26706 acc 0.66667 roc_auc 0.45500 prc_auc 0.65970[0m
[93maverage test of epoch 1: loss -2.04607 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 2: loss -2.78470 acc 0.66667 roc_auc 0.45680 prc_auc 0.66397[0m
[93maverage test of epoch 2: loss -3.36986 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 3: loss -3.81973 acc 0.66667 roc_auc 0.42750 prc_auc 0.63595[0m
[93maverage test of epoch 3: loss -4.18307 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 4: loss -4.56937 acc 0.66667 roc_auc 0.41260 prc_auc 0.62056[0m
[93maverage test of epoch 4: loss -4.88115 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 5: loss -5.24263 acc 0.66667 roc_auc 0.40080 prc_auc 0.61013[0m
[93maverage test of epoch 5: loss -5.53010 acc 0.65789 roc_auc 0.95231 prc_auc 0.97791[0m
[92maverage training of epoch 6: loss -5.87874 acc 0.66667 roc_auc 0.39320 prc_auc 0.60619[0m
[93maverage test of epoch 6: loss -6.15165 acc 0.65789 roc_auc 0.95231 prc_auc 0.97791[0m
[92maverage training of epoch 7: loss -6.49285 acc 0.66667 roc_auc 0.38880 prc_auc 0.60458[0m
[93maverage test of epoch 7: loss -6.75585 acc 0.65789 roc_auc 0.95385 prc_auc 0.97946[0m
[92maverage training of epoch 8: loss -7.09254 acc 0.66667 roc_auc 0.38710 prc_auc 0.60286[0m
[93maverage test of epoch 8: loss -7.34821 acc 0.65789 roc_auc 0.95077 prc_auc 0.97663[0m
[92maverage training of epoch 9: loss -7.68214 acc 0.66667 roc_auc 0.38620 prc_auc 0.60073[0m
[93maverage test of epoch 9: loss -7.93207 acc 0.65789 roc_auc 0.94615 prc_auc 0.97264[0m
[92maverage training of epoch 10: loss -8.26436 acc 0.66667 roc_auc 0.38420 prc_auc 0.59334[0m
[93maverage test of epoch 10: loss -8.50959 acc 0.65789 roc_auc 0.94462 prc_auc 0.97298[0m
[92maverage training of epoch 11: loss -8.84099 acc 0.66667 roc_auc 0.38170 prc_auc 0.58744[0m
[93maverage test of epoch 11: loss -9.08223 acc 0.65789 roc_auc 0.93385 prc_auc 0.95526[0m
[92maverage training of epoch 12: loss -9.41329 acc 0.66667 roc_auc 0.38090 prc_auc 0.58747[0m
[93maverage test of epoch 12: loss -9.65107 acc 0.65789 roc_auc 0.91846 prc_auc 0.93000[0m
[92maverage training of epoch 13: loss -9.98219 acc 0.66667 roc_auc 0.38010 prc_auc 0.57905[0m
[93maverage test of epoch 13: loss -10.21688 acc 0.65789 roc_auc 0.86923 prc_auc 0.90632[0m
[92maverage training of epoch 14: loss -10.54834 acc 0.66667 roc_auc 0.37910 prc_auc 0.57743[0m
[93maverage test of epoch 14: loss -10.78023 acc 0.65789 roc_auc 0.92000 prc_auc 0.94526[0m
[92maverage training of epoch 15: loss -11.11227 acc 0.66667 roc_auc 0.37890 prc_auc 0.57707[0m
[93maverage test of epoch 15: loss -11.34158 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 16: loss -11.67438 acc 0.66667 roc_auc 0.37850 prc_auc 0.57635[0m
[93maverage test of epoch 16: loss -11.90128 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 17: loss -12.23498 acc 0.66667 roc_auc 0.37780 prc_auc 0.57563[0m
[93maverage test of epoch 17: loss -12.45962 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 18: loss -12.79432 acc 0.66667 roc_auc 0.37750 prc_auc 0.57556[0m
[93maverage test of epoch 18: loss -13.01682 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -13.35262 acc 0.66667 roc_auc 0.37700 prc_auc 0.57521[0m
[93maverage test of epoch 19: loss -13.57306 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -13.91004 acc 0.66667 roc_auc 0.37680 prc_auc 0.57591[0m
[93maverage test of epoch 20: loss -14.12849 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -14.46671 acc 0.66667 roc_auc 0.37680 prc_auc 0.57590[0m
[93maverage test of epoch 21: loss -14.68324 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -15.02275 acc 0.66667 roc_auc 0.37700 prc_auc 0.57665[0m
[93maverage test of epoch 22: loss -15.23742 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -15.57826 acc 0.66667 roc_auc 0.37670 prc_auc 0.57662[0m
[93maverage test of epoch 23: loss -15.79110 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -16.13331 acc 0.66667 roc_auc 0.37690 prc_auc 0.57571[0m
[93maverage test of epoch 24: loss -16.34436 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -16.68796 acc 0.66667 roc_auc 0.37680 prc_auc 0.57840[0m
[93maverage test of epoch 25: loss -16.89726 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -17.24229 acc 0.66667 roc_auc 0.37680 prc_auc 0.57679[0m
[93maverage test of epoch 26: loss -17.44986 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -17.79633 acc 0.66667 roc_auc 0.37710 prc_auc 0.57946[0m
[93maverage test of epoch 27: loss -18.00219 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -18.35013 acc 0.66667 roc_auc 0.37740 prc_auc 0.57717[0m
[93maverage test of epoch 28: loss -18.55430 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -18.90371 acc 0.66667 roc_auc 0.37690 prc_auc 0.57385[0m
[93maverage test of epoch 29: loss -19.10621 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -19.45712 acc 0.66667 roc_auc 0.37620 prc_auc 0.57873[0m
[93maverage test of epoch 30: loss -19.65796 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -20.01037 acc 0.66667 roc_auc 0.37680 prc_auc 0.57763[0m
[93maverage test of epoch 31: loss -20.20956 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -20.56349 acc 0.66667 roc_auc 0.37770 prc_auc 0.57708[0m
[93maverage test of epoch 32: loss -20.76104 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -21.11649 acc 0.66667 roc_auc 0.37880 prc_auc 0.57848[0m
[93maverage test of epoch 33: loss -21.31242 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -21.66940 acc 0.66667 roc_auc 0.38150 prc_auc 0.58353[0m
[93maverage test of epoch 34: loss -21.86370 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -22.22222 acc 0.66667 roc_auc 0.37810 prc_auc 0.58051[0m
[93maverage test of epoch 35: loss -22.41490 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -22.77496 acc 0.66667 roc_auc 0.38280 prc_auc 0.58575[0m
[93maverage test of epoch 36: loss -22.96603 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -23.32764 acc 0.66667 roc_auc 0.38120 prc_auc 0.58920[0m
[93maverage test of epoch 37: loss -23.51710 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -23.88026 acc 0.66667 roc_auc 0.37860 prc_auc 0.58249[0m
[93maverage test of epoch 38: loss -24.06812 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -24.43283 acc 0.66667 roc_auc 0.38400 prc_auc 0.59013[0m
[93maverage test of epoch 39: loss -24.61910 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -24.98536 acc 0.66667 roc_auc 0.37430 prc_auc 0.58054[0m
[93maverage test of epoch 40: loss -25.17003 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -25.53786 acc 0.66667 roc_auc 0.37950 prc_auc 0.58596[0m
[93maverage test of epoch 41: loss -25.72094 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -26.09032 acc 0.66667 roc_auc 0.38650 prc_auc 0.59119[0m
[93maverage test of epoch 42: loss -26.27181 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -26.64276 acc 0.66667 roc_auc 0.38510 prc_auc 0.58943[0m
[93maverage test of epoch 43: loss -26.82266 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -27.19517 acc 0.66667 roc_auc 0.38240 prc_auc 0.59001[0m
[93maverage test of epoch 44: loss -27.37348 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -27.74755 acc 0.66667 roc_auc 0.39030 prc_auc 0.59910[0m
[93maverage test of epoch 45: loss -27.92428 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -28.29992 acc 0.66667 roc_auc 0.38560 prc_auc 0.59493[0m
[93maverage test of epoch 46: loss -28.47506 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -28.85227 acc 0.66667 roc_auc 0.38070 prc_auc 0.59568[0m
[93maverage test of epoch 47: loss -29.02583 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -29.40460 acc 0.66667 roc_auc 0.38620 prc_auc 0.60032[0m
[93maverage test of epoch 48: loss -29.57657 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -29.95692 acc 0.66667 roc_auc 0.40140 prc_auc 0.61322[0m
[93maverage test of epoch 49: loss -30.12731 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -0.19392 acc 0.60927 roc_auc 0.53157 prc_auc 0.66222[0m
[93maverage test of epoch 0: loss -0.43759 acc 0.35135 roc_auc 0.87333 prc_auc 0.93181[0m
[92maverage training of epoch 1: loss -0.72351 acc 0.35099 roc_auc 0.68431 prc_auc 0.83696[0m
[93maverage test of epoch 1: loss -1.05705 acc 0.35135 roc_auc 0.86000 prc_auc 0.92282[0m
[92maverage training of epoch 2: loss -1.55655 acc 0.34437 roc_auc 0.53667 prc_auc 0.75045[0m
[93maverage test of epoch 2: loss -2.00498 acc 0.32432 roc_auc 0.23000 prc_auc 0.57923[0m
[92maverage training of epoch 3: loss -2.39662 acc 0.33775 roc_auc 0.36765 prc_auc 0.57246[0m
[93maverage test of epoch 3: loss -2.75663 acc 0.32432 roc_auc 0.28500 prc_auc 0.67521[0m
[92maverage training of epoch 4: loss -3.10257 acc 0.33775 roc_auc 0.37216 prc_auc 0.56698[0m
[93maverage test of epoch 4: loss -3.43174 acc 0.32432 roc_auc 0.29667 prc_auc 0.67869[0m
[92maverage training of epoch 5: loss -3.75479 acc 0.33775 roc_auc 0.37353 prc_auc 0.56780[0m
[93maverage test of epoch 5: loss -4.06942 acc 0.32432 roc_auc 0.31167 prc_auc 0.68263[0m
[92maverage training of epoch 6: loss -4.37833 acc 0.33775 roc_auc 0.37510 prc_auc 0.56924[0m
[93maverage test of epoch 6: loss -4.68526 acc 0.32432 roc_auc 0.31000 prc_auc 0.67987[0m
[92maverage training of epoch 7: loss -4.98427 acc 0.33775 roc_auc 0.37529 prc_auc 0.56892[0m
[93maverage test of epoch 7: loss -5.28702 acc 0.32432 roc_auc 0.36333 prc_auc 0.70017[0m
[92maverage training of epoch 8: loss -5.57849 acc 0.30464 roc_auc 0.37608 prc_auc 0.57006[0m
[93maverage test of epoch 8: loss -5.87903 acc 0.67568 roc_auc 0.52667 prc_auc 0.74655[0m
[92maverage training of epoch 9: loss -6.16440 acc 0.66225 roc_auc 0.37588 prc_auc 0.56998[0m
[93maverage test of epoch 9: loss -6.46400 acc 0.67568 roc_auc 0.58167 prc_auc 0.75364[0m
[92maverage training of epoch 10: loss -6.74421 acc 0.66225 roc_auc 0.37608 prc_auc 0.57008[0m
[93maverage test of epoch 10: loss -7.04368 acc 0.67568 roc_auc 0.54667 prc_auc 0.71176[0m
[92maverage training of epoch 11: loss -7.31938 acc 0.66225 roc_auc 0.37588 prc_auc 0.56971[0m
[93maverage test of epoch 11: loss -7.61929 acc 0.67568 roc_auc 0.64000 prc_auc 0.77262[0m
[92maverage training of epoch 12: loss -7.89093 acc 0.66225 roc_auc 0.37588 prc_auc 0.56971[0m
[93maverage test of epoch 12: loss -8.19170 acc 0.67568 roc_auc 0.34000 prc_auc 0.61569[0m
[92maverage training of epoch 13: loss -8.45963 acc 0.66225 roc_auc 0.37588 prc_auc 0.56971[0m
[93maverage test of epoch 13: loss -8.76155 acc 0.67568 roc_auc 0.42500 prc_auc 0.64400[0m
[92maverage training of epoch 14: loss -9.02603 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 14: loss -9.32934 acc 0.67568 roc_auc 0.58000 prc_auc 0.71494[0m
[92maverage training of epoch 15: loss -9.59056 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 15: loss -9.89543 acc 0.67568 roc_auc 0.62000 prc_auc 0.73274[0m
[92maverage training of epoch 16: loss -10.15356 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 16: loss -10.46014 acc 0.67568 roc_auc 0.16000 prc_auc 0.62824[0m
[92maverage training of epoch 17: loss -10.71529 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 17: loss -11.02368 acc 0.67568 roc_auc 0.12000 prc_auc 0.62703[0m
[92maverage training of epoch 18: loss -11.27597 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 18: loss -11.58626 acc 0.67568 roc_auc 0.34000 prc_auc 0.61318[0m
[92maverage training of epoch 19: loss -11.83576 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 19: loss -12.14804 acc 0.67568 roc_auc 0.54000 prc_auc 0.69491[0m
[92maverage training of epoch 20: loss -12.39481 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 20: loss -12.70913 acc 0.67568 roc_auc 0.70000 prc_auc 0.79644[0m
[92maverage training of epoch 21: loss -12.95323 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 21: loss -13.26964 acc 0.67568 roc_auc 0.77333 prc_auc 0.86097[0m
[92maverage training of epoch 22: loss -13.51113 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 22: loss -13.82966 acc 0.67568 roc_auc 0.62000 prc_auc 0.75103[0m
[92maverage training of epoch 23: loss -14.06857 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 23: loss -14.38927 acc 0.67568 roc_auc 0.40000 prc_auc 0.63392[0m
[92maverage training of epoch 24: loss -14.62562 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 24: loss -14.94852 acc 0.67568 roc_auc 0.83500 prc_auc 0.86790[0m
[92maverage training of epoch 25: loss -15.18236 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 25: loss -15.50747 acc 0.67568 roc_auc 0.74000 prc_auc 0.81658[0m
[92maverage training of epoch 26: loss -15.73881 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 26: loss -16.06616 acc 0.67568 roc_auc 0.68000 prc_auc 0.78032[0m
[92maverage training of epoch 27: loss -16.29502 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 27: loss -16.62463 acc 0.67568 roc_auc 0.58000 prc_auc 0.71961[0m
[92maverage training of epoch 28: loss -16.85103 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 28: loss -17.18291 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 29: loss -17.40687 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 29: loss -17.74103 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 30: loss -17.96255 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 30: loss -18.29901 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 31: loss -18.51810 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 31: loss -18.85687 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 32: loss -19.07355 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 32: loss -19.41463 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 33: loss -19.62890 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 33: loss -19.97230 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 34: loss -20.18416 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 34: loss -20.52989 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 35: loss -20.73936 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 35: loss -21.08741 acc 0.67568 roc_auc 0.72000 prc_auc 0.80439[0m
[92maverage training of epoch 36: loss -21.29449 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 36: loss -21.64488 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 37: loss -21.84958 acc 0.66225 roc_auc 0.37578 prc_auc 0.56962[0m
[93maverage test of epoch 37: loss -22.20230 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 38: loss -22.40461 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 38: loss -22.75968 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 39: loss -22.95960 acc 0.66225 roc_auc 0.37578 prc_auc 0.56962[0m
[93maverage test of epoch 39: loss -23.31701 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 40: loss -23.51456 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 40: loss -23.87431 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 41: loss -24.06948 acc 0.66225 roc_auc 0.37588 prc_auc 0.56962[0m
[93maverage test of epoch 41: loss -24.43159 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 42: loss -24.62438 acc 0.66225 roc_auc 0.37588 prc_auc 0.56968[0m
[93maverage test of epoch 42: loss -24.98883 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -25.17925 acc 0.66225 roc_auc 0.37569 prc_auc 0.56937[0m
[93maverage test of epoch 43: loss -25.54606 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -25.73411 acc 0.66225 roc_auc 0.37578 prc_auc 0.56968[0m
[93maverage test of epoch 44: loss -26.10328 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -26.28896 acc 0.66225 roc_auc 0.37569 prc_auc 0.56993[0m
[93maverage test of epoch 45: loss -26.66047 acc 0.67568 roc_auc 0.32333 prc_auc 0.61317[0m
[92maverage training of epoch 46: loss -26.84378 acc 0.66225 roc_auc 0.37598 prc_auc 0.56972[0m
[93maverage test of epoch 46: loss -27.21766 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -27.39860 acc 0.66225 roc_auc 0.37559 prc_auc 0.56984[0m
[93maverage test of epoch 47: loss -27.77483 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -27.95341 acc 0.66225 roc_auc 0.37588 prc_auc 0.57082[0m
[93maverage test of epoch 48: loss -28.33199 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -28.50820 acc 0.66225 roc_auc 0.37588 prc_auc 0.56942[0m
[93maverage test of epoch 49: loss -28.88915 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -0.86847 acc 0.66225 roc_auc 0.39118 prc_auc 0.61203[0m
[93maverage test of epoch 0: loss -1.25238 acc 0.67568 roc_auc 0.92667 prc_auc 0.97089[0m
[92maverage training of epoch 1: loss -1.59482 acc 0.66225 roc_auc 0.43412 prc_auc 0.64581[0m
[93maverage test of epoch 1: loss -1.98787 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 2: loss -2.32336 acc 0.66225 roc_auc 0.41980 prc_auc 0.62801[0m
[93maverage test of epoch 2: loss -2.71711 acc 0.67568 roc_auc 0.92667 prc_auc 0.97104[0m
[92maverage training of epoch 3: loss -3.02987 acc 0.66225 roc_auc 0.39529 prc_auc 0.60647[0m
[93maverage test of epoch 3: loss -3.40621 acc 0.67568 roc_auc 0.93333 prc_auc 0.97377[0m
[92maverage training of epoch 4: loss -3.69180 acc 0.66225 roc_auc 0.38137 prc_auc 0.59772[0m
[93maverage test of epoch 4: loss -4.05134 acc 0.67568 roc_auc 0.93167 prc_auc 0.97104[0m
[92maverage training of epoch 5: loss -4.31875 acc 0.66225 roc_auc 0.37843 prc_auc 0.58897[0m
[93maverage test of epoch 5: loss -4.66893 acc 0.67568 roc_auc 0.93167 prc_auc 0.97104[0m
[92maverage training of epoch 6: loss -4.92455 acc 0.66225 roc_auc 0.37804 prc_auc 0.59065[0mUsing backend: pytorch
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))

[93maverage test of epoch 6: loss -5.26995 acc 0.67568 roc_auc 0.93000 prc_auc 0.96958[0m
[92maverage training of epoch 7: loss -5.51724 acc 0.66225 roc_auc 0.37686 prc_auc 0.57751[0m
[93maverage test of epoch 7: loss -5.86036 acc 0.67568 roc_auc 0.93333 prc_auc 0.96845[0m
[92maverage training of epoch 8: loss -6.10122 acc 0.66225 roc_auc 0.37451 prc_auc 0.57198[0m
[93maverage test of epoch 8: loss -6.44347 acc 0.67568 roc_auc 0.93333 prc_auc 0.96845[0m
[92maverage training of epoch 9: loss -6.67908 acc 0.66225 roc_auc 0.37294 prc_auc 0.57087[0m
[93maverage test of epoch 9: loss -7.02135 acc 0.67568 roc_auc 0.93333 prc_auc 0.96845[0m
[92maverage training of epoch 10: loss -7.25243 acc 0.66225 roc_auc 0.37216 prc_auc 0.56989[0m
[93maverage test of epoch 10: loss -7.59529 acc 0.67568 roc_auc 0.93667 prc_auc 0.96845[0m
[92maverage training of epoch 11: loss -7.82236 acc 0.66225 roc_auc 0.37078 prc_auc 0.56889[0m
[93maverage test of epoch 11: loss -8.16622 acc 0.67568 roc_auc 0.93333 prc_auc 0.96875[0m
[92maverage training of epoch 12: loss -8.38964 acc 0.66225 roc_auc 0.37098 prc_auc 0.56906[0m
[93maverage test of epoch 12: loss -8.73478 acc 0.67568 roc_auc 0.92333 prc_auc 0.95512[0m
[92maverage training of epoch 13: loss -8.95481 acc 0.66225 roc_auc 0.37039 prc_auc 0.56861[0m
[93maverage test of epoch 13: loss -9.30145 acc 0.67568 roc_auc 0.91333 prc_auc 0.94698[0m
[92maverage training of epoch 14: loss -9.51828 acc 0.66225 roc_auc 0.37020 prc_auc 0.56846[0m
[93maverage test of epoch 14: loss -9.86658 acc 0.67568 roc_auc 0.79667 prc_auc 0.83926[0m
[92maverage training of epoch 15: loss -10.08038 acc 0.66225 roc_auc 0.37020 prc_auc 0.56846[0m
[93maverage test of epoch 15: loss -10.43046 acc 0.67568 roc_auc 0.66833 prc_auc 0.75939[0m
[92maverage training of epoch 16: loss -10.64133 acc 0.66225 roc_auc 0.37020 prc_auc 0.56846[0m
[93maverage test of epoch 16: loss -10.99330 acc 0.67568 roc_auc 0.79333 prc_auc 0.83776[0m
[92maverage training of epoch 17: loss -11.20135 acc 0.66225 roc_auc 0.37000 prc_auc 0.56832[0m
[93maverage test of epoch 17: loss -11.55528 acc 0.67568 roc_auc 0.84000 prc_auc 0.89622[0m
[92maverage training of epoch 18: loss -11.76058 acc 0.66225 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 18: loss -12.11655 acc 0.67568 roc_auc 0.79333 prc_auc 0.83776[0m
[92maverage training of epoch 19: loss -12.31916 acc 0.66225 roc_auc 0.36990 prc_auc 0.56821[0m
[93maverage test of epoch 19: loss -12.67721 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 20: loss -12.87718 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 20: loss -13.23736 acc 0.67568 roc_auc 0.75167 prc_auc 0.80977[0m
[92maverage training of epoch 21: loss -13.43474 acc 0.66225 roc_auc 0.36971 prc_auc 0.56804[0m
[93maverage test of epoch 21: loss -13.79708 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 22: loss -13.99190 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 22: loss -14.35643 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 23: loss -14.54873 acc 0.66225 roc_auc 0.36980 prc_auc 0.56801[0m
[93maverage test of epoch 23: loss -14.91547 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 24: loss -15.10526 acc 0.66225 roc_auc 0.36990 prc_auc 0.56804[0m
[93maverage test of epoch 24: loss -15.47425 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 25: loss -15.66156 acc 0.66225 roc_auc 0.36990 prc_auc 0.56821[0m
[93maverage test of epoch 25: loss -16.03280 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 26: loss -16.21764 acc 0.66225 roc_auc 0.37000 prc_auc 0.56821[0m
[93maverage test of epoch 26: loss -16.59115 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 27: loss -16.77355 acc 0.66225 roc_auc 0.36990 prc_auc 0.56825[0m
[93maverage test of epoch 27: loss -17.14934 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 28: loss -17.32930 acc 0.66225 roc_auc 0.36990 prc_auc 0.56804[0m
[93maverage test of epoch 28: loss -17.70739 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 29: loss -17.88492 acc 0.66225 roc_auc 0.37000 prc_auc 0.56827[0m
[93maverage test of epoch 29: loss -18.26531 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 30: loss -18.44043 acc 0.66225 roc_auc 0.37010 prc_auc 0.56846[0m
[93maverage test of epoch 30: loss -18.82313 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 31: loss -18.99583 acc 0.66225 roc_auc 0.36980 prc_auc 0.56887[0m
[93maverage test of epoch 31: loss -19.38085 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 32: loss -19.55115 acc 0.66225 roc_auc 0.37000 prc_auc 0.56942[0m
[93maverage test of epoch 32: loss -19.93850 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 33: loss -20.10640 acc 0.66225 roc_auc 0.36990 prc_auc 0.56949[0m
[93maverage test of epoch 33: loss -20.49608 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 34: loss -20.66159 acc 0.66225 roc_auc 0.37000 prc_auc 0.56925[0m
[93maverage test of epoch 34: loss -21.05360 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 35: loss -21.21672 acc 0.66225 roc_auc 0.37000 prc_auc 0.56972[0m
[93maverage test of epoch 35: loss -21.61106 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 36: loss -21.77180 acc 0.66225 roc_auc 0.37020 prc_auc 0.57005[0m
[93maverage test of epoch 36: loss -22.16848 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 37: loss -22.32683 acc 0.66225 roc_auc 0.36941 prc_auc 0.57147[0m
[93maverage test of epoch 37: loss -22.72586 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 38: loss -22.88184 acc 0.66225 roc_auc 0.36882 prc_auc 0.56854[0m
[93maverage test of epoch 38: loss -23.28321 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 39: loss -23.43681 acc 0.66225 roc_auc 0.36902 prc_auc 0.57009[0m
[93maverage test of epoch 39: loss -23.84053 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -23.99176 acc 0.66225 roc_auc 0.36892 prc_auc 0.56907[0m
[93maverage test of epoch 40: loss -24.39783 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -24.54668 acc 0.66225 roc_auc 0.36873 prc_auc 0.57127[0m
[93maverage test of epoch 41: loss -24.95510 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -25.10158 acc 0.66225 roc_auc 0.36951 prc_auc 0.56852[0m
[93maverage test of epoch 42: loss -25.51236 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -25.65646 acc 0.66225 roc_auc 0.36863 prc_auc 0.57157[0m
[93maverage test of epoch 43: loss -26.06959 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -26.21133 acc 0.66225 roc_auc 0.36755 prc_auc 0.57012[0m
[93maverage test of epoch 44: loss -26.62681 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -26.76618 acc 0.66225 roc_auc 0.36892 prc_auc 0.56912[0m
[93maverage test of epoch 45: loss -27.18402 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -27.32102 acc 0.66225 roc_auc 0.36549 prc_auc 0.56716[0m
[93maverage test of epoch 46: loss -27.74122 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -27.87585 acc 0.66225 roc_auc 0.36716 prc_auc 0.56853[0m
[93maverage test of epoch 47: loss -28.29840 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -28.43067 acc 0.66225 roc_auc 0.36559 prc_auc 0.57002[0m
[93maverage test of epoch 48: loss -28.85557 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -28.98547 acc 0.66225 roc_auc 0.36569 prc_auc 0.57033[0m
[93maverage test of epoch 49: loss -29.41273 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.66501 ROC_AUC (avg): 0.5 PRC_AUC (avg): 0.66501 

Average forward propagation time taken(ms): 2.4882614900571425
Average backward propagation time taken(ms): 0.8768672630111906

