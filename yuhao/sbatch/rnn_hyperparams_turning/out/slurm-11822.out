# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 1)
('lr', 0.001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-17-00-12/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-17-00-12/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 8,
 'epochs': 50,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 4,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.001,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 1,
 'num_workers': 8,
 'number_of_mlp_layer': 1,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-17-17-00-12',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 50, 'learning_rate': 0.001, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -1.29277 acc 0.33333 roc_auc 0.57840 prc_auc 0.72352[0m
[93maverage test of epoch 0: loss -3.47186 acc 0.34211 roc_auc 0.28308 prc_auc 0.63042[0m
[92maverage training of epoch 1: loss -7.31191 acc 0.33333 roc_auc 0.56920 prc_auc 0.72588[0m
[93maverage test of epoch 1: loss -10.74491 acc 0.34211 roc_auc 0.67692 prc_auc 0.84641[0m
[92maverage training of epoch 2: loss -12.88883 acc 0.33333 roc_auc 0.42300 prc_auc 0.60346[0m
[93maverage test of epoch 2: loss -14.98654 acc 0.34211 roc_auc 0.10154 prc_auc 0.48796[0m
[92maverage training of epoch 3: loss -16.98733 acc 0.33333 roc_auc 0.37590 prc_auc 0.58674[0m
[93maverage test of epoch 3: loss -19.08162 acc 0.34211 roc_auc 0.11385 prc_auc 0.48509[0m
[92maverage training of epoch 4: loss -21.18807 acc 0.33333 roc_auc 0.37000 prc_auc 0.58058[0m
[93maverage test of epoch 4: loss -23.41282 acc 0.34211 roc_auc 0.12923 prc_auc 0.50281[0m
[92maverage training of epoch 5: loss -25.66207 acc 0.33333 roc_auc 0.35840 prc_auc 0.57070[0m
[93maverage test of epoch 5: loss -28.02336 acc 0.34211 roc_auc 0.25692 prc_auc 0.58678[0m
[92maverage training of epoch 6: loss -30.40363 acc 0.33333 roc_auc 0.36170 prc_auc 0.56904[0m
[93maverage test of epoch 6: loss -32.90156 acc 0.34211 roc_auc 0.30923 prc_auc 0.58253[0m
[92maverage training of epoch 7: loss -35.42720 acc 0.33333 roc_auc 0.36200 prc_auc 0.56801[0m
[93maverage test of epoch 7: loss -38.07060 acc 0.34211 roc_auc 0.29846 prc_auc 0.63111[0m
[92maverage training of epoch 8: loss -40.74960 acc 0.48667 roc_auc 0.36020 prc_auc 0.56449[0m
[93maverage test of epoch 8: loss -43.54268 acc 0.65789 roc_auc 0.33231 prc_auc 0.59364[0m
[92maverage training of epoch 9: loss -46.38005 acc 0.66667 roc_auc 0.35800 prc_auc 0.56540[0m
[93maverage test of epoch 9: loss -49.32487 acc 0.65789 roc_auc 0.56308 prc_auc 0.69146[0m
[92maverage training of epoch 10: loss -52.32409 acc 0.66667 roc_auc 0.35800 prc_auc 0.56646[0m
[93maverage test of epoch 10: loss -55.42160 acc 0.65789 roc_auc 0.59231 prc_auc 0.73047[0m
[92maverage training of epoch 11: loss -58.58533 acc 0.66667 roc_auc 0.35980 prc_auc 0.56800[0m
[93maverage test of epoch 11: loss -61.83589 acc 0.65789 roc_auc 0.50923 prc_auc 0.66211[0m
[92maverage training of epoch 12: loss -65.16628 acc 0.66667 roc_auc 0.36060 prc_auc 0.56952[0m
[93maverage test of epoch 12: loss -68.56990 acc 0.65789 roc_auc 0.49077 prc_auc 0.66135[0m
[92maverage training of epoch 13: loss -72.06878 acc 0.66667 roc_auc 0.36060 prc_auc 0.56973[0m
[93maverage test of epoch 13: loss -75.62518 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 14: loss -79.29417 acc 0.66667 roc_auc 0.36300 prc_auc 0.57189[0m
[93maverage test of epoch 14: loss -83.00297 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 15: loss -86.84358 acc 0.66667 roc_auc 0.36450 prc_auc 0.57282[0m
[93maverage test of epoch 15: loss -90.70429 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 16: loss -94.71791 acc 0.66667 roc_auc 0.36560 prc_auc 0.57659[0m
[93maverage test of epoch 16: loss -98.72995 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 17: loss -102.91792 acc 0.66667 roc_auc 0.36690 prc_auc 0.57505[0m
[93maverage test of epoch 17: loss -107.08066 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 18: loss -111.44423 acc 0.66667 roc_auc 0.36900 prc_auc 0.58385[0m
[93maverage test of epoch 18: loss -115.75703 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -120.29736 acc 0.66667 roc_auc 0.38450 prc_auc 0.60627[0m
[93maverage test of epoch 19: loss -124.75947 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -129.47785 acc 0.66667 roc_auc 0.43500 prc_auc 0.63948[0m
[93maverage test of epoch 20: loss -134.08857 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -138.98611 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 21: loss -143.74468 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -148.82244 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 22: loss -153.72809 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -158.98733 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 23: loss -164.03932 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -169.48095 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 24: loss -174.67829 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -180.30359 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 25: loss -185.64574 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -191.45561 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 26: loss -196.94153 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -202.93704 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 27: loss -208.56589 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -214.74812 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 28: loss -220.51914 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -226.88913 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 29: loss -232.80123 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -239.35978 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 30: loss -245.41227 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -252.16058 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 31: loss -258.35264 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -265.29192 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 32: loss -271.62273 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -278.75367 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 33: loss -285.22216 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -292.54593 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -299.15120 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -306.66863 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -313.40984 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -321.12231 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -327.99885 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -335.90759 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -342.94652 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -352.06472 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -360.50817 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -370.24243 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -379.01305 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -389.06375 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -398.04366 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -408.33017 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -417.45946 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -427.99336 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -437.29166 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -448.07308 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -457.52688 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -468.56036 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -478.17691 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -489.47213 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -499.25784 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -510.82112 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -520.77944 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -532.61625 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -542.74967 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -554.86414 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -565.17424 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -577.57023 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -588.05836 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -0.28584 acc 0.66667 roc_auc 0.42000 prc_auc 0.62541[0m
[93maverage test of epoch 0: loss -0.72127 acc 0.65789 roc_auc 0.25846 prc_auc 0.55434[0m
[92maverage training of epoch 1: loss -1.91455 acc 0.66667 roc_auc 0.46960 prc_auc 0.65590[0m
[93maverage test of epoch 1: loss -3.81225 acc 0.65789 roc_auc 0.84923 prc_auc 0.91434[0m
[92maverage training of epoch 2: loss -5.80555 acc 0.66667 roc_auc 0.46980 prc_auc 0.65135[0m
[93maverage test of epoch 2: loss -8.37729 acc 0.65789 roc_auc 0.86769 prc_auc 0.92125[0m
[92maverage training of epoch 3: loss -10.58656 acc 0.66667 roc_auc 0.46960 prc_auc 0.65097[0m
[93maverage test of epoch 3: loss -12.60430 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 4: loss -14.61308 acc 0.66667 roc_auc 0.46960 prc_auc 0.65097[0m
[93maverage test of epoch 4: loss -16.54226 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 5: loss -18.69156 acc 0.66667 roc_auc 0.46670 prc_auc 0.64426[0m
[93maverage test of epoch 5: loss -20.74526 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 6: loss -23.07202 acc 0.66667 roc_auc 0.47210 prc_auc 0.65063[0m
[93maverage test of epoch 6: loss -25.27271 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 7: loss -27.77823 acc 0.66667 roc_auc 0.48260 prc_auc 0.65748[0m
[93maverage test of epoch 7: loss -30.11947 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 8: loss -32.79527 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 8: loss -35.26334 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 9: loss -38.10462 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 9: loss -40.70013 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 10: loss -43.71198 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 10: loss -46.43822 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 11: loss -49.62427 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 11: loss -52.48316 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 12: loss -55.84622 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 12: loss -58.83885 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 13: loss -62.38124 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 13: loss -65.50821 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 14: loss -69.23192 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 14: loss -72.49352 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 15: loss -76.40033 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 15: loss -79.79655 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 16: loss -83.88808 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 16: loss -87.41879 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 17: loss -91.69659 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 17: loss -95.36157 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 18: loss -99.82703 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 18: loss -103.62589 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -108.28042 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 19: loss -112.21273 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -117.05764 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 20: loss -121.12291 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -126.15950 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 21: loss -130.35718 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -135.58668 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 22: loss -139.91625 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -145.33985 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 23: loss -149.80055 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -155.41947 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 24: loss -160.01068 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -165.82603 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 25: loss -170.54714 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -176.56016 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 26: loss -181.41039 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -187.62217 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 27: loss -192.60081 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -199.01237 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 28: loss -204.11872 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -210.73123 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 29: loss -215.96437 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -222.77890 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 30: loss -228.13832 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -235.15576 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 31: loss -240.64029 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -247.86204 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 32: loss -253.47088 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -260.89775 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 33: loss -266.63036 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -274.26336 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -280.11853 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -287.95874 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -293.93603 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -301.98442 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -308.08233 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -316.34003 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -322.55838 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -331.02637 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -337.36393 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -346.04319 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -352.49905 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -361.39029 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -367.96353 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -377.06812 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -383.75805 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -393.07688 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -399.88253 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -409.41657 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -416.33715 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -426.08738 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -433.12181 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -443.08929 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -450.23670 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -460.42227 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -467.68180 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -478.08613 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -485.45631 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -496.08068 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -503.56127 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -514.40695 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -521.99706 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -0.45046 acc 0.52000 roc_auc 0.39570 prc_auc 0.60424[0m
[93maverage test of epoch 0: loss -0.52145 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 1: loss -0.82062 acc 0.66667 roc_auc 0.44660 prc_auc 0.65181[0m
[93maverage test of epoch 1: loss -1.67654 acc 0.65789 roc_auc 0.94462 prc_auc 0.97618[0m
[92maverage training of epoch 2: loss -3.13975 acc 0.66667 roc_auc 0.43100 prc_auc 0.63210[0m
[93maverage test of epoch 2: loss -4.46513 acc 0.65789 roc_auc 0.95231 prc_auc 0.97791[0m
[92maverage training of epoch 3: loss -5.58860 acc 0.66667 roc_auc 0.41000 prc_auc 0.61491[0m
[93maverage test of epoch 3: loss -6.67374 acc 0.65789 roc_auc 0.95538 prc_auc 0.97946[0m
[92maverage training of epoch 4: loss -7.86804 acc 0.66667 roc_auc 0.39900 prc_auc 0.60485[0m
[93maverage test of epoch 4: loss -9.05521 acc 0.65789 roc_auc 0.93077 prc_auc 0.95076[0m
[92maverage training of epoch 5: loss -10.42093 acc 0.66667 roc_auc 0.39600 prc_auc 0.60208[0m
[93maverage test of epoch 5: loss -11.77918 acc 0.65789 roc_auc 0.67231 prc_auc 0.74632[0m
[92maverage training of epoch 6: loss -13.34993 acc 0.66667 roc_auc 0.39610 prc_auc 0.60123[0m
[93maverage test of epoch 6: loss -14.90654 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 7: loss -16.69873 acc 0.66667 roc_auc 0.39640 prc_auc 0.60088[0m
[93maverage test of epoch 7: loss -18.46694 acc 0.65789 roc_auc 0.69231 prc_auc 0.75758[0m
[92maverage training of epoch 8: loss -20.48863 acc 0.66667 roc_auc 0.39980 prc_auc 0.60498[0m
[93maverage test of epoch 8: loss -22.47398 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 9: loss -24.72822 acc 0.66667 roc_auc 0.40260 prc_auc 0.60692[0m
[93maverage test of epoch 9: loss -26.93133 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 10: loss -29.41807 acc 0.66667 roc_auc 0.40730 prc_auc 0.60280[0m
[93maverage test of epoch 10: loss -31.83654 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 11: loss -34.54808 acc 0.66667 roc_auc 0.40900 prc_auc 0.60542[0m
[93maverage test of epoch 11: loss -37.15914 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 12: loss -40.05104 acc 0.66667 roc_auc 0.41560 prc_auc 0.61616[0m
[93maverage test of epoch 12: loss -42.82223 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 13: loss -45.89555 acc 0.66667 roc_auc 0.42820 prc_auc 0.63311[0m
[93maverage test of epoch 13: loss -48.82815 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 14: loss -52.08715 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 14: loss -55.18147 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 15: loss -58.62793 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 15: loss -61.87824 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 16: loss -65.49383 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 16: loss -68.87384 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 17: loss -72.65486 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 17: loss -76.16492 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 18: loss -80.11475 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 18: loss -83.75638 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -87.87789 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 19: loss -91.65217 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -95.94785 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 20: loss -99.85546 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -104.32760 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 21: loss -108.36895 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -113.01956 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 22: loss -117.19495 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -122.02594 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 23: loss -126.33542 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -131.34861 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 24: loss -135.79218 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -140.98919 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 25: loss -145.56665 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -150.94912 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 26: loss -155.66027 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -161.22973 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 27: loss -166.07429 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -171.83214 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 28: loss -176.80962 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -182.75727 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 29: loss -187.86728 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -194.00618 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 30: loss -199.24824 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -205.57954 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 31: loss -210.95306 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -217.47817 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 32: loss -222.98259 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -229.70276 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 33: loss -235.33752 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -242.25384 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -248.01808 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -255.13183 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -261.02513 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -268.33736 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -274.35880 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -281.87075 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -288.01963 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -295.73248 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -302.00808 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -309.92293 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -316.32450 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -324.44228 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -330.96942 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -339.29088 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -345.94193 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -354.46911 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -361.24364 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -369.97630 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -376.87356 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -385.81410 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -392.83358 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -401.98127 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -409.12082 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -418.47823 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -425.73850 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -435.30670 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -442.68671 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -452.46571 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -459.96265 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -469.95312 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -477.56751 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -0.42832 acc 0.35762 roc_auc 0.40549 prc_auc 0.63023[0m
[93maverage test of epoch 0: loss -1.06247 acc 0.37838 roc_auc 0.68667 prc_auc 0.86255[0m
[92maverage training of epoch 1: loss -1.95549 acc 0.56954 roc_auc 0.40431 prc_auc 0.60230[0m
[93maverage test of epoch 1: loss -3.10835 acc 0.67568 roc_auc 0.38333 prc_auc 0.72111[0m
[92maverage training of epoch 2: loss -4.72662 acc 0.66225 roc_auc 0.42784 prc_auc 0.62609[0m
[93maverage test of epoch 2: loss -6.66400 acc 0.67568 roc_auc 0.85000 prc_auc 0.91796[0m
[92maverage training of epoch 3: loss -8.46257 acc 0.66225 roc_auc 0.42255 prc_auc 0.63909[0m
[93maverage test of epoch 3: loss -10.42694 acc 0.67568 roc_auc 0.85500 prc_auc 0.92043[0m
[92maverage training of epoch 4: loss -12.59848 acc 0.66225 roc_auc 0.46314 prc_auc 0.70304[0m
[93maverage test of epoch 4: loss -15.12127 acc 0.67568 roc_auc 0.86667 prc_auc 0.93131[0m
[92maverage training of epoch 5: loss -17.86582 acc 0.66225 roc_auc 0.36627 prc_auc 0.56649[0m
[93maverage test of epoch 5: loss -20.79131 acc 0.67568 roc_auc 0.14167 prc_auc 0.50761[0m
[92maverage training of epoch 6: loss -23.65521 acc 0.66225 roc_auc 0.38843 prc_auc 0.58056[0m
[93maverage test of epoch 6: loss -26.73634 acc 0.67568 roc_auc 0.14000 prc_auc 0.51826[0m
[92maverage training of epoch 7: loss -29.74696 acc 0.66225 roc_auc 0.39765 prc_auc 0.58762[0m
[93maverage test of epoch 7: loss -33.04322 acc 0.67568 roc_auc 0.48000 prc_auc 0.66703[0m
[92maverage training of epoch 8: loss -36.24446 acc 0.66225 roc_auc 0.40343 prc_auc 0.59184[0m
[93maverage test of epoch 8: loss -39.79703 acc 0.67568 roc_auc 0.54000 prc_auc 0.70036[0m
[92maverage training of epoch 9: loss -43.20692 acc 0.66225 roc_auc 0.40833 prc_auc 0.59482[0m
[93maverage test of epoch 9: loss -47.03572 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 10: loss -50.66194 acc 0.66225 roc_auc 0.41176 prc_auc 0.59585[0m
[93maverage test of epoch 10: loss -54.77898 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 11: loss -58.62486 acc 0.66225 roc_auc 0.41529 prc_auc 0.59938[0m
[93maverage test of epoch 11: loss -63.03843 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 12: loss -67.10498 acc 0.66225 roc_auc 0.43010 prc_auc 0.62525[0m
[93maverage test of epoch 12: loss -71.82122 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 13: loss -76.10802 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 13: loss -81.13162 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 14: loss -85.63722 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 14: loss -90.97183 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 15: loss -95.69408 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 15: loss -101.34243 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 16: loss -106.27041 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 16: loss -112.21435 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 17: loss -117.32597 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 17: loss -123.55637 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 18: loss -128.85221 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 18: loss -135.37335 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 19: loss -140.85357 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 19: loss -147.66934 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 20: loss -153.33369 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 20: loss -160.44764 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 21: loss -166.29553 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 21: loss -173.71095 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 22: loss -179.74156 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 22: loss -187.46158 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 23: loss -193.67389 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 23: loss -201.70153 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 24: loss -208.09447 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 24: loss -216.43265 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 25: loss -223.00483 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 25: loss -231.65628 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 26: loss -238.40642 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 26: loss -247.37398 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 27: loss -254.30053 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 27: loss -263.58672 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 28: loss -270.68817 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 28: loss -280.29569 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 29: loss -287.57040 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 29: loss -297.50178 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 30: loss -304.94811 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 30: loss -315.20583 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 31: loss -322.82207 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 31: loss -333.40856 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 32: loss -341.19288 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 32: loss -352.11067 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 33: loss -360.06131 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 33: loss -371.31267 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 34: loss -379.42779 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 34: loss -391.01522 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 35: loss -399.29296 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 35: loss -411.21872 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 36: loss -419.65702 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 36: loss -431.92342 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 37: loss -440.52051 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 37: loss -453.13009 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 38: loss -461.88405 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 38: loss -474.83888 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 39: loss -483.74758 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 39: loss -497.05000 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -506.11142 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 40: loss -519.76337 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -528.97533 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 41: loss -542.97934 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -552.34032 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 42: loss -566.69894 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -576.20685 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 43: loss -590.92222 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -600.57492 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 44: loss -615.64906 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -625.44445 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 45: loss -640.87962 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -650.81561 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 46: loss -666.61392 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -676.68852 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 47: loss -692.85232 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -703.06312 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 48: loss -719.59393 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -729.93870 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 49: loss -746.83923 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -0.18124 acc 0.33775 roc_auc 0.31647 prc_auc 0.55503[0m
[93maverage test of epoch 0: loss -0.81031 acc 0.32432 roc_auc 0.06667 prc_auc 0.48823[0m
[92maverage training of epoch 1: loss -1.81623 acc 0.33775 roc_auc 0.47471 prc_auc 0.63394[0m
[93maverage test of epoch 1: loss -3.17899 acc 0.32432 roc_auc 0.91000 prc_auc 0.96521[0m
[92maverage training of epoch 2: loss -4.26236 acc 0.33775 roc_auc 0.74824 prc_auc 0.88420[0mUsing backend: pytorch
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))

[93maverage test of epoch 2: loss -5.38037 acc 0.32432 roc_auc 0.90000 prc_auc 0.96141[0m
[92maverage training of epoch 3: loss -6.69196 acc 0.33775 roc_auc 0.45627 prc_auc 0.66881[0m
[93maverage test of epoch 3: loss -7.91697 acc 0.32432 roc_auc 0.14667 prc_auc 0.51372[0m
[92maverage training of epoch 4: loss -9.13699 acc 0.33775 roc_auc 0.38275 prc_auc 0.58682[0m
[93maverage test of epoch 4: loss -10.49874 acc 0.32432 roc_auc 0.08500 prc_auc 0.49503[0m
[92maverage training of epoch 5: loss -12.10072 acc 0.37748 roc_auc 0.38608 prc_auc 0.58604[0m
[93maverage test of epoch 5: loss -13.84067 acc 0.67568 roc_auc 0.13167 prc_auc 0.50554[0m
[92maverage training of epoch 6: loss -15.64624 acc 0.66225 roc_auc 0.38627 prc_auc 0.58619[0m
[93maverage test of epoch 6: loss -17.62355 acc 0.67568 roc_auc 0.49167 prc_auc 0.71043[0m
[92maverage training of epoch 7: loss -19.63431 acc 0.66225 roc_auc 0.38549 prc_auc 0.58529[0m
[93maverage test of epoch 7: loss -21.87761 acc 0.67568 roc_auc 0.77333 prc_auc 0.87879[0m
[92maverage training of epoch 8: loss -24.12318 acc 0.66225 roc_auc 0.38451 prc_auc 0.58490[0m
[93maverage test of epoch 8: loss -26.65854 acc 0.67568 roc_auc 0.46000 prc_auc 0.65863[0m
[92maverage training of epoch 9: loss -29.15791 acc 0.66225 roc_auc 0.38569 prc_auc 0.58622[0m
[93maverage test of epoch 9: loss -32.00692 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 10: loss -34.77622 acc 0.66225 roc_auc 0.38549 prc_auc 0.58597[0m
[93maverage test of epoch 10: loss -37.95644 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 11: loss -41.00581 acc 0.66225 roc_auc 0.38667 prc_auc 0.58541[0m
[93maverage test of epoch 11: loss -44.52945 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 12: loss -47.86321 acc 0.66225 roc_auc 0.40137 prc_auc 0.59297[0m
[93maverage test of epoch 12: loss -51.73746 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 13: loss -55.35496 acc 0.66225 roc_auc 0.38824 prc_auc 0.59235[0m
[93maverage test of epoch 13: loss -59.58292 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 14: loss -63.47987 acc 0.66225 roc_auc 0.40784 prc_auc 0.62019[0m
[93maverage test of epoch 14: loss -68.06175 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 15: loss -72.22427 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 15: loss -77.13939 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 16: loss -81.52046 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 16: loss -86.74349 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 17: loss -91.33793 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 17: loss -96.87209 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 18: loss -101.67060 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 18: loss -107.49815 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 19: loss -112.47644 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 19: loss -118.58450 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 20: loss -123.74298 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 20: loss -130.13637 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 21: loss -135.47557 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 21: loss -142.15863 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 22: loss -147.67855 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 22: loss -154.65517 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 23: loss -160.35560 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 23: loss -167.62946 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 24: loss -173.50971 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 24: loss -181.08423 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 25: loss -187.14364 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 25: loss -195.02212 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 26: loss -201.25981 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 26: loss -209.44548 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 27: loss -215.86019 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 27: loss -224.35592 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 28: loss -230.94661 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 28: loss -239.75543 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 29: loss -246.52092 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 29: loss -255.64569 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 30: loss -262.58455 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 30: loss -272.02820 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 31: loss -279.13891 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 31: loss -288.90407 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 32: loss -296.18525 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 32: loss -306.27463 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 33: loss -313.72478 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 33: loss -324.14088 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 34: loss -331.75818 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 34: loss -342.50370 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 35: loss -350.28654 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 35: loss -361.36388 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 36: loss -369.31045 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 36: loss -380.72203 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 37: loss -388.83055 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 37: loss -400.57894 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 38: loss -408.84785 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 38: loss -420.93562 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 39: loss -429.36313 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 39: loss -441.79264 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -450.46228 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 40: loss -463.74990 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -473.79725 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 41: loss -488.36118 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -498.73140 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 42: loss -513.79546 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -524.39423 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 43: loss -539.88627 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -550.64014 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 44: loss -566.53032 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -577.45416 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 45: loss -593.75044 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -604.83738 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 46: loss -621.54335 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -632.80287 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 47: loss -649.93151 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -661.36811 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 48: loss -678.92836 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -690.54486 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 49: loss -708.54442 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 1)
('lr', 0.001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.66501 ROC_AUC (avg): 0.5 PRC_AUC (avg): 0.66501 

Average forward propagation time taken(ms): 2.7661223781577604
Average backward propagation time taken(ms): 0.931070864969827

