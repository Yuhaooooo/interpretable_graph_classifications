# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 2)
('lr', 0.0001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-21-17-06/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-21-17-06/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 8,
 'epochs': 50,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 8,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.0001,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 2,
 'num_workers': 8,
 'number_of_mlp_layer': 2,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-17-21-17-06',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 50, 'learning_rate': 0.0001, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=8, bias=True)
    (ReLU1): ReLU()
    (Linear2): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.27256 acc 0.33333 roc_auc 0.46280 prc_auc 0.65269[0m
[93maverage test of epoch 0: loss -0.37678 acc 0.34211 roc_auc 0.51385 prc_auc 0.69994[0m
[92maverage training of epoch 1: loss -0.45120 acc 0.33333 roc_auc 0.39820 prc_auc 0.62570[0m
[93maverage test of epoch 1: loss -0.53272 acc 0.34211 roc_auc 0.29538 prc_auc 0.53892[0m
[92maverage training of epoch 2: loss -0.63219 acc 0.33333 roc_auc 0.39600 prc_auc 0.60537[0m
[93maverage test of epoch 2: loss -0.75321 acc 0.34211 roc_auc 0.53231 prc_auc 0.74623[0m
[92maverage training of epoch 3: loss -0.86452 acc 0.33333 roc_auc 0.43140 prc_auc 0.64736[0m
[93maverage test of epoch 3: loss -1.02698 acc 0.34211 roc_auc 0.55385 prc_auc 0.77185[0m
[92maverage training of epoch 4: loss -1.17943 acc 0.32667 roc_auc 0.44140 prc_auc 0.63333[0m
[93maverage test of epoch 4: loss -1.36427 acc 0.50000 roc_auc 0.45538 prc_auc 0.70013[0m
[92maverage training of epoch 5: loss -1.60444 acc 0.62667 roc_auc 0.39280 prc_auc 0.60018[0m
[93maverage test of epoch 5: loss -1.85826 acc 0.65789 roc_auc 0.34154 prc_auc 0.55699[0m
[92maverage training of epoch 6: loss -2.14124 acc 0.66667 roc_auc 0.45600 prc_auc 0.66185[0m
[93maverage test of epoch 6: loss -2.46343 acc 0.65789 roc_auc 0.54154 prc_auc 0.72352[0m
[92maverage training of epoch 7: loss -2.92081 acc 0.66667 roc_auc 0.44060 prc_auc 0.65334[0m
[93maverage test of epoch 7: loss -3.36689 acc 0.65789 roc_auc 0.57846 prc_auc 0.76249[0m
[92maverage training of epoch 8: loss -3.78287 acc 0.66667 roc_auc 0.40120 prc_auc 0.62763[0m
[93maverage test of epoch 8: loss -4.17812 acc 0.65789 roc_auc 0.68308 prc_auc 0.80183[0m
[92maverage training of epoch 9: loss -4.58061 acc 0.66667 roc_auc 0.36700 prc_auc 0.59062[0m
[93maverage test of epoch 9: loss -4.98251 acc 0.65789 roc_auc 0.56615 prc_auc 0.69584[0m
[92maverage training of epoch 10: loss -5.37838 acc 0.66667 roc_auc 0.40300 prc_auc 0.60784[0m
[93maverage test of epoch 10: loss -5.78806 acc 0.65789 roc_auc 0.65846 prc_auc 0.77912[0m
[92maverage training of epoch 11: loss -6.20123 acc 0.66667 roc_auc 0.40280 prc_auc 0.63368[0m
[93maverage test of epoch 11: loss -6.60200 acc 0.65789 roc_auc 0.31385 prc_auc 0.57528[0m
[92maverage training of epoch 12: loss -7.03341 acc 0.66667 roc_auc 0.45340 prc_auc 0.66079[0m
[93maverage test of epoch 12: loss -7.43681 acc 0.65789 roc_auc 0.42462 prc_auc 0.65321[0m
[92maverage training of epoch 13: loss -7.89690 acc 0.66667 roc_auc 0.40360 prc_auc 0.62393[0m
[93maverage test of epoch 13: loss -8.33158 acc 0.65789 roc_auc 0.44615 prc_auc 0.65424[0m
[92maverage training of epoch 14: loss -8.80291 acc 0.66667 roc_auc 0.40600 prc_auc 0.60118[0m
[93maverage test of epoch 14: loss -9.26970 acc 0.65789 roc_auc 0.64308 prc_auc 0.75470[0m
[92maverage training of epoch 15: loss -9.74186 acc 0.66667 roc_auc 0.38520 prc_auc 0.58349[0m
[93maverage test of epoch 15: loss -10.20211 acc 0.65789 roc_auc 0.46154 prc_auc 0.64007[0m
[92maverage training of epoch 16: loss -10.71817 acc 0.66667 roc_auc 0.40780 prc_auc 0.61575[0m
[93maverage test of epoch 16: loss -11.18700 acc 0.65789 roc_auc 0.40923 prc_auc 0.58508[0m
[92maverage training of epoch 17: loss -11.72489 acc 0.66667 roc_auc 0.38180 prc_auc 0.58327[0m
[93maverage test of epoch 17: loss -12.21094 acc 0.65789 roc_auc 0.42154 prc_auc 0.65402[0m
[92maverage training of epoch 18: loss -12.80488 acc 0.66667 roc_auc 0.41000 prc_auc 0.63241[0m
[93maverage test of epoch 18: loss -13.35015 acc 0.65789 roc_auc 0.45538 prc_auc 0.62018[0m
[92maverage training of epoch 19: loss -14.04497 acc 0.66667 roc_auc 0.41560 prc_auc 0.62002[0m
[93maverage test of epoch 19: loss -14.69526 acc 0.65789 roc_auc 0.46154 prc_auc 0.65445[0m
[92maverage training of epoch 20: loss -15.38243 acc 0.66667 roc_auc 0.40260 prc_auc 0.61042[0m
[93maverage test of epoch 20: loss -16.03210 acc 0.65789 roc_auc 0.54769 prc_auc 0.66352[0m
[92maverage training of epoch 21: loss -16.72320 acc 0.66667 roc_auc 0.40660 prc_auc 0.62318[0m
[93maverage test of epoch 21: loss -17.34992 acc 0.65789 roc_auc 0.48000 prc_auc 0.64287[0m
[92maverage training of epoch 22: loss -18.08746 acc 0.66667 roc_auc 0.40940 prc_auc 0.61992[0m
[93maverage test of epoch 22: loss -18.70716 acc 0.65789 roc_auc 0.29846 prc_auc 0.56329[0m
[92maverage training of epoch 23: loss -19.48943 acc 0.66667 roc_auc 0.41810 prc_auc 0.62164[0m
[93maverage test of epoch 23: loss -20.14879 acc 0.65789 roc_auc 0.41538 prc_auc 0.64946[0m
[92maverage training of epoch 24: loss -20.93795 acc 0.66667 roc_auc 0.41390 prc_auc 0.62613[0m
[93maverage test of epoch 24: loss -21.61892 acc 0.65789 roc_auc 0.46000 prc_auc 0.65268[0m
[92maverage training of epoch 25: loss -22.44317 acc 0.66667 roc_auc 0.41070 prc_auc 0.61628[0m
[93maverage test of epoch 25: loss -23.14297 acc 0.65789 roc_auc 0.57692 prc_auc 0.68774[0m
[92maverage training of epoch 26: loss -24.00779 acc 0.66667 roc_auc 0.39690 prc_auc 0.59987[0m
[93maverage test of epoch 26: loss -24.75235 acc 0.65789 roc_auc 0.56000 prc_auc 0.71362[0m
[92maverage training of epoch 27: loss -25.65106 acc 0.66667 roc_auc 0.41030 prc_auc 0.62116[0m
[93maverage test of epoch 27: loss -26.41572 acc 0.65789 roc_auc 0.52000 prc_auc 0.68187[0m
[92maverage training of epoch 28: loss -27.37090 acc 0.66667 roc_auc 0.40820 prc_auc 0.62127[0m
[93maverage test of epoch 28: loss -28.16284 acc 0.65789 roc_auc 0.49846 prc_auc 0.66456[0m
[92maverage training of epoch 29: loss -29.16857 acc 0.66667 roc_auc 0.42300 prc_auc 0.63319[0m
[93maverage test of epoch 29: loss -30.04565 acc 0.65789 roc_auc 0.59385 prc_auc 0.70369[0m
[92maverage training of epoch 30: loss -31.11710 acc 0.66667 roc_auc 0.39410 prc_auc 0.60304[0m
[93maverage test of epoch 30: loss -32.05576 acc 0.65789 roc_auc 0.61077 prc_auc 0.71559[0m
[92maverage training of epoch 31: loss -33.19749 acc 0.66667 roc_auc 0.40300 prc_auc 0.60969[0m
[93maverage test of epoch 31: loss -34.18833 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -35.40252 acc 0.66667 roc_auc 0.40200 prc_auc 0.61594[0m
[93maverage test of epoch 32: loss -36.43131 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -37.68725 acc 0.66667 roc_auc 0.41760 prc_auc 0.62919[0m
[93maverage test of epoch 33: loss -38.76208 acc 0.65789 roc_auc 0.46000 prc_auc 0.64041[0m
[92maverage training of epoch 34: loss -40.09246 acc 0.66667 roc_auc 0.43500 prc_auc 0.64022[0m
[93maverage test of epoch 34: loss -41.22336 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -42.59218 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -43.76615 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -45.21709 acc 0.66667 roc_auc 0.48000 prc_auc 0.65791[0m
[93maverage test of epoch 36: loss -46.44706 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -47.94991 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -49.22796 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -50.81029 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -52.14619 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -53.80443 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -55.18865 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -56.93386 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -58.40361 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -60.21209 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -61.75670 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -63.65330 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -65.25300 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -67.25048 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -68.93671 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -71.01529 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -72.77359 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -74.93774 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -76.79178 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -79.02377 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -80.94413 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -83.27263 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -85.26554 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -87.66461 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -89.73720 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -92.21413 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -94.35418 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=8, bias=True)
    (ReLU1): ReLU()
    (Linear2): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss 0.31750 acc 0.33333 roc_auc 0.46160 prc_auc 0.63007[0m
[93maverage test of epoch 0: loss 0.06510 acc 0.34211 roc_auc 0.71385 prc_auc 0.79569[0m
[92maverage training of epoch 1: loss -0.05756 acc 0.33333 roc_auc 0.44780 prc_auc 0.62422[0m
[93maverage test of epoch 1: loss -0.23101 acc 0.34211 roc_auc 0.55077 prc_auc 0.72850[0m
[92maverage training of epoch 2: loss -0.36531 acc 0.33333 roc_auc 0.52860 prc_auc 0.69156[0m
[93maverage test of epoch 2: loss -0.52520 acc 0.34211 roc_auc 0.50154 prc_auc 0.65446[0m
[92maverage training of epoch 3: loss -0.68412 acc 0.33333 roc_auc 0.56400 prc_auc 0.73866[0m
[93maverage test of epoch 3: loss -0.83361 acc 0.34211 roc_auc 0.30462 prc_auc 0.56409[0m
[92maverage training of epoch 4: loss -0.96804 acc 0.33333 roc_auc 0.43580 prc_auc 0.64310[0m
[93maverage test of epoch 4: loss -1.13639 acc 0.34211 roc_auc 0.53846 prc_auc 0.71569[0m
[92maverage training of epoch 5: loss -1.30824 acc 0.33333 roc_auc 0.57960 prc_auc 0.71201[0m
[93maverage test of epoch 5: loss -1.50859 acc 0.34211 roc_auc 0.54769 prc_auc 0.68260[0m
[92maverage training of epoch 6: loss -1.74545 acc 0.33333 roc_auc 0.59180 prc_auc 0.75099[0m
[93maverage test of epoch 6: loss -1.99296 acc 0.34211 roc_auc 0.58462 prc_auc 0.72945[0m
[92maverage training of epoch 7: loss -2.29178 acc 0.33333 roc_auc 0.50940 prc_auc 0.66433[0m
[93maverage test of epoch 7: loss -2.63518 acc 0.34211 roc_auc 0.48615 prc_auc 0.72321[0m
[92maverage training of epoch 8: loss -3.02638 acc 0.33333 roc_auc 0.49180 prc_auc 0.65822[0m
[93maverage test of epoch 8: loss -3.47733 acc 0.34211 roc_auc 0.51692 prc_auc 0.70899[0m
[92maverage training of epoch 9: loss -3.90235 acc 0.33333 roc_auc 0.49420 prc_auc 0.65431[0m
[93maverage test of epoch 9: loss -4.36109 acc 0.34211 roc_auc 0.36615 prc_auc 0.58652[0m
[92maverage training of epoch 10: loss -4.83492 acc 0.33333 roc_auc 0.46120 prc_auc 0.66917[0m
[93maverage test of epoch 10: loss -5.30853 acc 0.34211 roc_auc 0.47692 prc_auc 0.67088[0m
[92maverage training of epoch 11: loss -5.79695 acc 0.33333 roc_auc 0.45740 prc_auc 0.65774[0m
[93maverage test of epoch 11: loss -6.33142 acc 0.34211 roc_auc 0.39385 prc_auc 0.63209[0m
[92maverage training of epoch 12: loss -6.81768 acc 0.33333 roc_auc 0.49580 prc_auc 0.66333[0m
[93maverage test of epoch 12: loss -7.44404 acc 0.34211 roc_auc 0.46769 prc_auc 0.62142[0m
[92maverage training of epoch 13: loss -7.89579 acc 0.33333 roc_auc 0.47660 prc_auc 0.65412[0m
[93maverage test of epoch 13: loss -8.52329 acc 0.34211 roc_auc 0.55692 prc_auc 0.72344[0m
[92maverage training of epoch 14: loss -9.01028 acc 0.33333 roc_auc 0.41860 prc_auc 0.63603[0m
[93maverage test of epoch 14: loss -9.65082 acc 0.34211 roc_auc 0.46462 prc_auc 0.64005[0m
[92maverage training of epoch 15: loss -10.19615 acc 0.33333 roc_auc 0.46260 prc_auc 0.65546[0m
[93maverage test of epoch 15: loss -10.85962 acc 0.34211 roc_auc 0.51692 prc_auc 0.73084[0m
[92maverage training of epoch 16: loss -11.40892 acc 0.33333 roc_auc 0.44260 prc_auc 0.63523[0m
[93maverage test of epoch 16: loss -12.08804 acc 0.34211 roc_auc 0.54154 prc_auc 0.71669[0m
[92maverage training of epoch 17: loss -12.69846 acc 0.33333 roc_auc 0.56440 prc_auc 0.73317[0m
[93maverage test of epoch 17: loss -13.37091 acc 0.34211 roc_auc 0.54154 prc_auc 0.68400[0m
[92maverage training of epoch 18: loss -14.04652 acc 0.33333 roc_auc 0.57180 prc_auc 0.75199[0m
[93maverage test of epoch 18: loss -14.78298 acc 0.34211 roc_auc 0.55077 prc_auc 0.75204[0m
[92maverage training of epoch 19: loss -15.46338 acc 0.33333 roc_auc 0.47800 prc_auc 0.65660[0m
[93maverage test of epoch 19: loss -16.25152 acc 0.34211 roc_auc 0.33538 prc_auc 0.55421[0m
[92maverage training of epoch 20: loss -16.93819 acc 0.33333 roc_auc 0.50060 prc_auc 0.68082[0m
[93maverage test of epoch 20: loss -17.77786 acc 0.34211 roc_auc 0.56615 prc_auc 0.73123[0m
[92maverage training of epoch 21: loss -18.50871 acc 0.33333 roc_auc 0.50560 prc_auc 0.67987[0m
[93maverage test of epoch 21: loss -19.37735 acc 0.34211 roc_auc 0.36615 prc_auc 0.56599[0m
[92maverage training of epoch 22: loss -20.17498 acc 0.33333 roc_auc 0.50960 prc_auc 0.69073[0m
[93maverage test of epoch 22: loss -21.05320 acc 0.34211 roc_auc 0.64000 prc_auc 0.83073[0m
[92maverage training of epoch 23: loss -21.90120 acc 0.33333 roc_auc 0.49620 prc_auc 0.63794[0m
[93maverage test of epoch 23: loss -22.85036 acc 0.34211 roc_auc 0.37385 prc_auc 0.60893[0m
[92maverage training of epoch 24: loss -23.72203 acc 0.33333 roc_auc 0.50400 prc_auc 0.67508[0m
[93maverage test of epoch 24: loss -24.74497 acc 0.34211 roc_auc 0.60000 prc_auc 0.82150[0m
[92maverage training of epoch 25: loss -25.62445 acc 0.33333 roc_auc 0.53300 prc_auc 0.67010[0m
[93maverage test of epoch 25: loss -26.67730 acc 0.34211 roc_auc 0.38462 prc_auc 0.64572[0m
[92maverage training of epoch 26: loss -27.62308 acc 0.33333 roc_auc 0.52440 prc_auc 0.69105[0m
[93maverage test of epoch 26: loss -28.69944 acc 0.34211 roc_auc 0.45231 prc_auc 0.65617[0m
[92maverage training of epoch 27: loss -29.70425 acc 0.33333 roc_auc 0.50200 prc_auc 0.64886[0m
[93maverage test of epoch 27: loss -30.82503 acc 0.34211 roc_auc 0.57231 prc_auc 0.73860[0m
[92maverage training of epoch 28: loss -31.88364 acc 0.33333 roc_auc 0.53980 prc_auc 0.69382[0m
[93maverage test of epoch 28: loss -33.10093 acc 0.34211 roc_auc 0.44000 prc_auc 0.67520[0m
[92maverage training of epoch 29: loss -34.16337 acc 0.33333 roc_auc 0.52960 prc_auc 0.66852[0m
[93maverage test of epoch 29: loss -35.40953 acc 0.34211 roc_auc 0.58154 prc_auc 0.72622[0m
[92maverage training of epoch 30: loss -36.52442 acc 0.33333 roc_auc 0.52220 prc_auc 0.66130[0m
[93maverage test of epoch 30: loss -37.83289 acc 0.34211 roc_auc 0.57538 prc_auc 0.75117[0m
[92maverage training of epoch 31: loss -39.01047 acc 0.33333 roc_auc 0.52260 prc_auc 0.66147[0m
[93maverage test of epoch 31: loss -40.38209 acc 0.34211 roc_auc 0.60615 prc_auc 0.75198[0m
[92maverage training of epoch 32: loss -41.60323 acc 0.33333 roc_auc 0.53240 prc_auc 0.67591[0m
[93maverage test of epoch 32: loss -43.02967 acc 0.34211 roc_auc 0.42923 prc_auc 0.64314[0m
[92maverage training of epoch 33: loss -44.30593 acc 0.33333 roc_auc 0.52700 prc_auc 0.66970[0m
[93maverage test of epoch 33: loss -45.75110 acc 0.34211 roc_auc 0.56000 prc_auc 0.71407[0m
[92maverage training of epoch 34: loss -47.11381 acc 0.33333 roc_auc 0.52440 prc_auc 0.66767[0m
[93maverage test of epoch 34: loss -48.67573 acc 0.34211 roc_auc 0.34154 prc_auc 0.56938[0m
[92maverage training of epoch 35: loss -50.04834 acc 0.33333 roc_auc 0.53200 prc_auc 0.66565[0m
[93maverage test of epoch 35: loss -51.65999 acc 0.34211 roc_auc 0.61692 prc_auc 0.75504[0m
[92maverage training of epoch 36: loss -53.09585 acc 0.33333 roc_auc 0.52680 prc_auc 0.66898[0m
[93maverage test of epoch 36: loss -54.77376 acc 0.34211 roc_auc 0.60308 prc_auc 0.75156[0m
[92maverage training of epoch 37: loss -56.25452 acc 0.33333 roc_auc 0.52400 prc_auc 0.66139[0m
[93maverage test of epoch 37: loss -57.99086 acc 0.34211 roc_auc 0.56308 prc_auc 0.74911[0m
[92maverage training of epoch 38: loss -59.53711 acc 0.33333 roc_auc 0.53380 prc_auc 0.66820[0m
[93maverage test of epoch 38: loss -61.35936 acc 0.34211 roc_auc 0.48462 prc_auc 0.70607[0m
[92maverage training of epoch 39: loss -62.94310 acc 0.33333 roc_auc 0.52760 prc_auc 0.67548[0m
[93maverage test of epoch 39: loss -64.81977 acc 0.34211 roc_auc 0.44615 prc_auc 0.67694[0m
[92maverage training of epoch 40: loss -66.46667 acc 0.33333 roc_auc 0.52880 prc_auc 0.67043[0m
[93maverage test of epoch 40: loss -68.41153 acc 0.34211 roc_auc 0.53846 prc_auc 0.73324[0m
[92maverage training of epoch 41: loss -70.11599 acc 0.33333 roc_auc 0.52640 prc_auc 0.66751[0m
[93maverage test of epoch 41: loss -72.13120 acc 0.34211 roc_auc 0.61692 prc_auc 0.77967[0m
[92maverage training of epoch 42: loss -73.89298 acc 0.33333 roc_auc 0.52720 prc_auc 0.68356[0m
[93maverage test of epoch 42: loss -76.01734 acc 0.34211 roc_auc 0.42462 prc_auc 0.63201[0m
[92maverage training of epoch 43: loss -77.81452 acc 0.33333 roc_auc 0.52160 prc_auc 0.66332[0m
[93maverage test of epoch 43: loss -80.00299 acc 0.34211 roc_auc 0.29077 prc_auc 0.55743[0m
[92maverage training of epoch 44: loss -81.88548 acc 0.33333 roc_auc 0.52260 prc_auc 0.65923[0m
[93maverage test of epoch 44: loss -84.14086 acc 0.34211 roc_auc 0.44923 prc_auc 0.63717[0m
[92maverage training of epoch 45: loss -86.08981 acc 0.33333 roc_auc 0.53040 prc_auc 0.66894[0m
[93maverage test of epoch 45: loss -88.42797 acc 0.34211 roc_auc 0.44308 prc_auc 0.62095[0m
[92maverage training of epoch 46: loss -90.46596 acc 0.33333 roc_auc 0.52300 prc_auc 0.66746[0m
[93maverage test of epoch 46: loss -92.89633 acc 0.34211 roc_auc 0.40923 prc_auc 0.66840[0m
[92maverage training of epoch 47: loss -94.98970 acc 0.33333 roc_auc 0.52520 prc_auc 0.66033[0m
[93maverage test of epoch 47: loss -97.52122 acc 0.34211 roc_auc 0.46923 prc_auc 0.69928[0m
[92maverage training of epoch 48: loss -99.67674 acc 0.33333 roc_auc 0.52560 prc_auc 0.66516[0m
[93maverage test of epoch 48: loss -102.28729 acc 0.34211 roc_auc 0.43385 prc_auc 0.64075[0m
[92maverage training of epoch 49: loss -104.52630 acc 0.33333 roc_auc 0.52870 prc_auc 0.66565[0m
[93maverage test of epoch 49: loss -107.22463 acc 0.34211 roc_auc 0.45077 prc_auc 0.62146[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=8, bias=True)
    (ReLU1): ReLU()
    (Linear2): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.76049 acc 0.66667 roc_auc 0.47940 prc_auc 0.67866[0m
[93maverage test of epoch 0: loss -1.01641 acc 0.65789 roc_auc 0.55692 prc_auc 0.73523[0m
[92maverage training of epoch 1: loss -1.28304 acc 0.66667 roc_auc 0.41980 prc_auc 0.61370[0m
[93maverage test of epoch 1: loss -1.57494 acc 0.65789 roc_auc 0.24615 prc_auc 0.57321[0m
[92maverage training of epoch 2: loss -1.96215 acc 0.66667 roc_auc 0.44280 prc_auc 0.63632[0m
[93maverage test of epoch 2: loss -2.35123 acc 0.65789 roc_auc 0.50769 prc_auc 0.62817[0m
[92maverage training of epoch 3: loss -2.80014 acc 0.66667 roc_auc 0.42740 prc_auc 0.62233[0m
[93maverage test of epoch 3: loss -3.26758 acc 0.65789 roc_auc 0.49231 prc_auc 0.63629[0m
[92maverage training of epoch 4: loss -3.83293 acc 0.66667 roc_auc 0.43520 prc_auc 0.62778[0m
[93maverage test of epoch 4: loss -4.32922 acc 0.65789 roc_auc 0.39692 prc_auc 0.63490[0m
[92maverage training of epoch 5: loss -4.88436 acc 0.66667 roc_auc 0.42220 prc_auc 0.62298[0m
[93maverage test of epoch 5: loss -5.34536 acc 0.65789 roc_auc 0.54462 prc_auc 0.72810[0m
[92maverage training of epoch 6: loss -5.85555 acc 0.66667 roc_auc 0.42160 prc_auc 0.61821[0m
[93maverage test of epoch 6: loss -6.27902 acc 0.65789 roc_auc 0.48923 prc_auc 0.70915[0m
[92maverage training of epoch 7: loss -6.79249 acc 0.66667 roc_auc 0.42700 prc_auc 0.62950[0m
[93maverage test of epoch 7: loss -7.19994 acc 0.65789 roc_auc 0.48615 prc_auc 0.67784[0m
[92maverage training of epoch 8: loss -7.69120 acc 0.66667 roc_auc 0.41870 prc_auc 0.65708[0m
[93maverage test of epoch 8: loss -8.09515 acc 0.65789 roc_auc 0.61231 prc_auc 0.75593[0m
[92maverage training of epoch 9: loss -8.64277 acc 0.66667 roc_auc 0.43550 prc_auc 0.65257[0m
[93maverage test of epoch 9: loss -9.05603 acc 0.65789 roc_auc 0.48769 prc_auc 0.75557[0m
[92maverage training of epoch 10: loss -9.57660 acc 0.66667 roc_auc 0.40750 prc_auc 0.61780[0m
[93maverage test of epoch 10: loss -9.99362 acc 0.65789 roc_auc 0.47077 prc_auc 0.68081[0m
[92maverage training of epoch 11: loss -10.52591 acc 0.66667 roc_auc 0.44160 prc_auc 0.66114[0m
[93maverage test of epoch 11: loss -10.87280 acc 0.65789 roc_auc 0.30769 prc_auc 0.64337[0m
[92maverage training of epoch 12: loss -11.43991 acc 0.66667 roc_auc 0.43020 prc_auc 0.64283[0m
[93maverage test of epoch 12: loss -11.83857 acc 0.65789 roc_auc 0.34769 prc_auc 0.60776[0m
[92maverage training of epoch 13: loss -12.39597 acc 0.66667 roc_auc 0.46350 prc_auc 0.64501[0m
[93maverage test of epoch 13: loss -12.78585 acc 0.65789 roc_auc 0.51846 prc_auc 0.70597[0m
[92maverage training of epoch 14: loss -13.38963 acc 0.66667 roc_auc 0.44970 prc_auc 0.64251[0m
[93maverage test of epoch 14: loss -13.81358 acc 0.65789 roc_auc 0.52000 prc_auc 0.69407[0m
[92maverage training of epoch 15: loss -14.41182 acc 0.66667 roc_auc 0.45270 prc_auc 0.66192[0m
[93maverage test of epoch 15: loss -14.87154 acc 0.65789 roc_auc 0.63385 prc_auc 0.80472[0m
[92maverage training of epoch 16: loss -15.48056 acc 0.66667 roc_auc 0.43900 prc_auc 0.64455[0m
[93maverage test of epoch 16: loss -15.93273 acc 0.65789 roc_auc 0.49385 prc_auc 0.65550[0m
[92maverage training of epoch 17: loss -16.59767 acc 0.66667 roc_auc 0.44000 prc_auc 0.63805[0m
[93maverage test of epoch 17: loss -17.04756 acc 0.65789 roc_auc 0.34000 prc_auc 0.58592[0m
[92maverage training of epoch 18: loss -17.75992 acc 0.66667 roc_auc 0.45290 prc_auc 0.64819[0m
[93maverage test of epoch 18: loss -18.24302 acc 0.65789 roc_auc 0.49846 prc_auc 0.66004[0m
[92maverage training of epoch 19: loss -18.97356 acc 0.66667 roc_auc 0.43710 prc_auc 0.64164[0m
[93maverage test of epoch 19: loss -19.47914 acc 0.65789 roc_auc 0.46000 prc_auc 0.64041[0m
[92maverage training of epoch 20: loss -20.23869 acc 0.66667 roc_auc 0.42190 prc_auc 0.63099[0m
[93maverage test of epoch 20: loss -20.74907 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -21.55403 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 21: loss -22.10290 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -22.92022 acc 0.66667 roc_auc 0.45000 prc_auc 0.64551[0m
[93maverage test of epoch 22: loss -23.46961 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -24.34503 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 23: loss -24.94296 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -25.81329 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 24: loss -26.42691 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -27.35143 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 25: loss -27.98836 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -28.94258 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 26: loss -29.60564 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -30.60000 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 27: loss -31.28045 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -32.31211 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 28: loss -32.99729 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -34.07173 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 29: loss -34.78113 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -35.89646 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 30: loss -36.60648 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -37.75778 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 31: loss -38.49012 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -39.68113 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 32: loss -40.44195 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -41.66396 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 33: loss -42.42787 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -43.69282 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -44.47765 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -45.78883 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -46.59107 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -47.93002 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -48.75495 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -50.13482 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -50.96765 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -52.39206 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -53.25012 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -54.71508 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -55.57746 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -57.09357 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -57.98602 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -59.53725 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -60.44001 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -62.03974 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -62.96400 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -64.60481 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -65.54743 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -67.24403 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -68.19799 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -69.93735 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -70.92206 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -72.69883 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -73.70118 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -75.52333 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -76.53903 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -78.41613 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -79.45519 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -81.44171 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -82.59726 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=8, bias=True)
    (ReLU1): ReLU()
    (Linear2): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.26281 acc 0.66225 roc_auc 0.41804 prc_auc 0.63239[0m
[93maverage test of epoch 0: loss -0.45838 acc 0.67568 roc_auc 0.40333 prc_auc 0.62062[0m
[92maverage training of epoch 1: loss -0.63220 acc 0.66225 roc_auc 0.45686 prc_auc 0.65079[0m
[93maverage test of epoch 1: loss -0.84606 acc 0.67568 roc_auc 0.51667 prc_auc 0.67018[0m
[92maverage training of epoch 2: loss -1.00501 acc 0.66225 roc_auc 0.42373 prc_auc 0.62631[0m
[93maverage test of epoch 2: loss -1.23350 acc 0.67568 roc_auc 0.41333 prc_auc 0.61145[0m
[92maverage training of epoch 3: loss -1.44360 acc 0.66225 roc_auc 0.46725 prc_auc 0.63888[0m
[93maverage test of epoch 3: loss -1.74222 acc 0.67568 roc_auc 0.57000 prc_auc 0.74093[0m
[92maverage training of epoch 4: loss -1.93571 acc 0.66225 roc_auc 0.42510 prc_auc 0.62206[0m
[93maverage test of epoch 4: loss -2.26055 acc 0.67568 roc_auc 0.56333 prc_auc 0.76490[0m
[92maverage training of epoch 5: loss -2.56522 acc 0.66225 roc_auc 0.43922 prc_auc 0.61483[0m
[93maverage test of epoch 5: loss -3.06120 acc 0.67568 roc_auc 0.49333 prc_auc 0.64900[0m
[92maverage training of epoch 6: loss -3.37597 acc 0.66225 roc_auc 0.45294 prc_auc 0.63406[0m
[93maverage test of epoch 6: loss -3.88965 acc 0.67568 roc_auc 0.64667 prc_auc 0.81586[0m
[92maverage training of epoch 7: loss -4.17857 acc 0.66225 roc_auc 0.46902 prc_auc 0.64140[0m
[93maverage test of epoch 7: loss -4.73075 acc 0.67568 roc_auc 0.69500 prc_auc 0.81789[0m
[92maverage training of epoch 8: loss -4.96907 acc 0.66225 roc_auc 0.41275 prc_auc 0.60403[0m
[93maverage test of epoch 8: loss -5.59171 acc 0.67568 roc_auc 0.54333 prc_auc 0.77519[0m
[92maverage training of epoch 9: loss -5.84367 acc 0.66225 roc_auc 0.41510 prc_auc 0.61524[0m
[93maverage test of epoch 9: loss -6.45168 acc 0.67568 roc_auc 0.65500 prc_auc 0.80731[0m
[92maverage training of epoch 10: loss -6.70425 acc 0.66225 roc_auc 0.45706 prc_auc 0.64270[0m
[93maverage test of epoch 10: loss -7.26975 acc 0.67568 roc_auc 0.68333 prc_auc 0.79732[0m
[92maverage training of epoch 11: loss -7.56288 acc 0.66225 roc_auc 0.42235 prc_auc 0.61314[0m
[93maverage test of epoch 11: loss -8.20911 acc 0.67568 roc_auc 0.59333 prc_auc 0.74101[0m
[92maverage training of epoch 12: loss -8.45504 acc 0.66225 roc_auc 0.43716 prc_auc 0.63834[0m
[93maverage test of epoch 12: loss -9.06578 acc 0.67568 roc_auc 0.46000 prc_auc 0.69060[0m
[92maverage training of epoch 13: loss -9.35821 acc 0.66225 roc_auc 0.45618 prc_auc 0.64575[0m
[93maverage test of epoch 13: loss -10.04933 acc 0.67568 roc_auc 0.50000 prc_auc 0.67609[0m
[92maverage training of epoch 14: loss -10.29231 acc 0.66225 roc_auc 0.45412 prc_auc 0.64165[0m
[93maverage test of epoch 14: loss -10.98923 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 15: loss -11.26332 acc 0.66225 roc_auc 0.48167 prc_auc 0.65421[0m
[93maverage test of epoch 15: loss -11.94613 acc 0.67568 roc_auc 0.48000 prc_auc 0.66703[0m
[92maverage training of epoch 16: loss -12.24124 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 16: loss -12.98284 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 17: loss -13.30854 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 17: loss -14.15450 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 18: loss -14.43589 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 18: loss -15.34747 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 19: loss -15.66259 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 19: loss -16.63494 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 20: loss -17.12439 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 20: loss -18.29147 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 21: loss -18.84123 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 21: loss -20.03887 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 22: loss -20.58831 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 22: loss -21.92538 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 23: loss -22.45515 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 23: loss -23.86030 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 24: loss -24.40060 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 24: loss -25.83554 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 25: loss -26.42463 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 25: loss -27.92257 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 26: loss -28.56320 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 26: loss -30.14814 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 27: loss -30.77699 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 27: loss -32.44519 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 28: loss -33.09924 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 28: loss -34.87903 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 29: loss -35.52255 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 29: loss -37.36349 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 30: loss -38.05463 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 30: loss -40.00267 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 31: loss -40.69877 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 31: loss -42.74935 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 32: loss -43.47171 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 32: loss -45.54628 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 33: loss -46.34738 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 33: loss -48.54986 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 34: loss -49.35376 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 34: loss -51.68945 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 35: loss -52.48144 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 35: loss -54.88972 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 36: loss -55.72634 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 36: loss -58.26152 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 37: loss -59.11277 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 37: loss -61.73084 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 38: loss -62.61253 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 38: loss -65.34553 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 39: loss -66.25708 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 39: loss -69.08674 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -70.04496 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 40: loss -72.97083 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -73.97229 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 41: loss -77.03055 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -78.05411 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 42: loss -81.24036 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -82.30585 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 43: loss -85.60972 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -86.70934 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 44: loss -90.15696 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -91.27332 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 45: loss -94.86403 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -96.02323 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 46: loss -99.76008 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -100.96295 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 47: loss -104.81106 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -106.07139 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 48: loss -110.07958 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -111.37364 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 49: loss -115.52877 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=8, bias=True)
    (ReLU1): ReLU()
    (Linear2): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.49340 acc 0.57616 roc_auc 0.34235 prc_auc 0.56765[0m
[93maverage test of epoch 0: loss -0.76362 acc 0.67568 roc_auc 0.41667 prc_auc 0.69091[0m
[92maverage training of epoch 1: loss -1.04544 acc 0.66225 roc_auc 0.40804 prc_auc 0.61145[0mUsing backend: pytorch

[93maverage test of epoch 1: loss -1.32775 acc 0.67568 roc_auc 0.25667 prc_auc 0.56129[0m
[92maverage training of epoch 2: loss -1.73818 acc 0.66225 roc_auc 0.41353 prc_auc 0.60480[0m
[93maverage test of epoch 2: loss -2.29194 acc 0.67568 roc_auc 0.47333 prc_auc 0.65190[0m
[92maverage training of epoch 3: loss -2.78052 acc 0.66225 roc_auc 0.41922 prc_auc 0.62990[0m
[93maverage test of epoch 3: loss -3.41024 acc 0.67568 roc_auc 0.54667 prc_auc 0.71674[0m
[92maverage training of epoch 4: loss -3.99921 acc 0.66225 roc_auc 0.44137 prc_auc 0.61651[0m
[93maverage test of epoch 4: loss -4.70549 acc 0.67568 roc_auc 0.63333 prc_auc 0.76532[0m
[92maverage training of epoch 5: loss -5.21815 acc 0.66225 roc_auc 0.38902 prc_auc 0.60019[0m
[93maverage test of epoch 5: loss -6.00818 acc 0.67568 roc_auc 0.43000 prc_auc 0.63756[0m
[92maverage training of epoch 6: loss -6.76421 acc 0.66225 roc_auc 0.38039 prc_auc 0.60990[0m
[93maverage test of epoch 6: loss -7.57387 acc 0.67568 roc_auc 0.37667 prc_auc 0.59119[0m
[92maverage training of epoch 7: loss -8.44356 acc 0.66225 roc_auc 0.42314 prc_auc 0.63983[0m
[93maverage test of epoch 7: loss -9.37630 acc 0.67568 roc_auc 0.40333 prc_auc 0.64675[0m
[92maverage training of epoch 8: loss -10.08550 acc 0.66225 roc_auc 0.43353 prc_auc 0.60039[0m
[93maverage test of epoch 8: loss -10.97740 acc 0.67568 roc_auc 0.53333 prc_auc 0.67182[0m
[92maverage training of epoch 9: loss -11.67787 acc 0.66225 roc_auc 0.39902 prc_auc 0.60018[0m
[93maverage test of epoch 9: loss -12.45303 acc 0.67568 roc_auc 0.36000 prc_auc 0.63728[0m
[92maverage training of epoch 10: loss -13.15138 acc 0.66225 roc_auc 0.43196 prc_auc 0.61154[0m
[93maverage test of epoch 10: loss -13.97082 acc 0.67568 roc_auc 0.54000 prc_auc 0.69242[0m
[92maverage training of epoch 11: loss -14.70884 acc 0.66225 roc_auc 0.39755 prc_auc 0.59000[0m
[93maverage test of epoch 11: loss -15.57076 acc 0.67568 roc_auc 0.63833 prc_auc 0.83178[0m
[92maverage training of epoch 12: loss -16.29221 acc 0.66225 roc_auc 0.40647 prc_auc 0.61430[0m
[93maverage test of epoch 12: loss -17.17104 acc 0.67568 roc_auc 0.52333 prc_auc 0.69985[0m
[92maverage training of epoch 13: loss -17.94204 acc 0.66225 roc_auc 0.44912 prc_auc 0.65674[0m
[93maverage test of epoch 13: loss -18.91261 acc 0.67568 roc_auc 0.51833 prc_auc 0.66539[0m
[92maverage training of epoch 14: loss -19.68146 acc 0.66225 roc_auc 0.36363 prc_auc 0.56701[0m
[93maverage test of epoch 14: loss -20.68857 acc 0.67568 roc_auc 0.50000 prc_auc 0.72299[0m
[92maverage training of epoch 15: loss -21.50612 acc 0.66225 roc_auc 0.42490 prc_auc 0.61648[0m
[93maverage test of epoch 15: loss -22.61221 acc 0.67568 roc_auc 0.68500 prc_auc 0.82667[0m
[92maverage training of epoch 16: loss -23.41112 acc 0.66225 roc_auc 0.39363 prc_auc 0.59673[0m
[93maverage test of epoch 16: loss -24.64190 acc 0.67568 roc_auc 0.48667 prc_auc 0.66547[0m
[92maverage training of epoch 17: loss -25.47768 acc 0.66225 roc_auc 0.43686 prc_auc 0.64881[0m
[93maverage test of epoch 17: loss -26.68377 acc 0.67568 roc_auc 0.47833 prc_auc 0.71124[0m
[92maverage training of epoch 18: loss -27.61931 acc 0.66225 roc_auc 0.42137 prc_auc 0.62147[0m
[93maverage test of epoch 18: loss -28.86331 acc 0.67568 roc_auc 0.46167 prc_auc 0.64298[0m
[92maverage training of epoch 19: loss -29.85445 acc 0.66225 roc_auc 0.43833 prc_auc 0.62574[0m
[93maverage test of epoch 19: loss -31.13427 acc 0.67568 roc_auc 0.55000 prc_auc 0.73385[0m
[92maverage training of epoch 20: loss -32.11540 acc 0.66225 roc_auc 0.38333 prc_auc 0.59321[0m
[93maverage test of epoch 20: loss -33.52165 acc 0.67568 roc_auc 0.48000 prc_auc 0.66360[0m
[92maverage training of epoch 21: loss -34.51213 acc 0.66225 roc_auc 0.39824 prc_auc 0.59953[0m
[93maverage test of epoch 21: loss -35.96577 acc 0.67568 roc_auc 0.43000 prc_auc 0.64407[0m
[92maverage training of epoch 22: loss -37.03273 acc 0.66225 roc_auc 0.40118 prc_auc 0.60063[0m
[93maverage test of epoch 22: loss -38.56429 acc 0.67568 roc_auc 0.46167 prc_auc 0.65936[0m
[92maverage training of epoch 23: loss -39.66176 acc 0.66225 roc_auc 0.40275 prc_auc 0.60926[0m
[93maverage test of epoch 23: loss -41.16675 acc 0.67568 roc_auc 0.46000 prc_auc 0.65903[0m
[92maverage training of epoch 24: loss -42.36166 acc 0.66225 roc_auc 0.41578 prc_auc 0.62465[0m
[93maverage test of epoch 24: loss -43.94463 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 25: loss -45.17268 acc 0.66225 roc_auc 0.48402 prc_auc 0.65519[0m
[93maverage test of epoch 25: loss -46.85984 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 26: loss -48.07901 acc 0.66225 roc_auc 0.42784 prc_auc 0.63226[0m
[93maverage test of epoch 26: loss -49.87823 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 27: loss -51.14367 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 27: loss -52.99258 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 28: loss -54.30205 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 28: loss -56.23280 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 29: loss -57.60589 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 29: loss -59.58983 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 30: loss -61.00936 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 30: loss -63.07591 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 31: loss -64.69478 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 31: loss -67.25074 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 32: loss -69.05718 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 32: loss -71.63820 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 33: loss -73.49326 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 33: loss -76.12836 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 34: loss -77.99236 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 34: loss -80.71401 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 35: loss -82.64368 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 35: loss -85.49074 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 36: loss -87.41310 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 36: loss -90.34296 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 37: loss -92.34233 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 37: loss -95.39974 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 38: loss -97.44849 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 38: loss -100.60625 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 39: loss -102.69181 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 39: loss -105.93871 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -108.12243 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 40: loss -111.54071 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -113.72840 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 41: loss -117.22532 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -119.47984 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 42: loss -123.09858 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -125.42190 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 43: loss -129.17070 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -131.52966 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 44: loss -135.41257 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -137.82266 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 45: loss -141.80874 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -144.29899 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 46: loss -148.42332 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -150.96043 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 47: loss -155.19565 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -157.81067 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 48: loss -162.19332 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -164.85736 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 49: loss -169.39155 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 2)
('lr', 0.0001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.60185 ROC_AUC (avg): 0.49015 PRC_AUC (avg): 0.65772 

Average forward propagation time taken(ms): 4.579859098664856
Average backward propagation time taken(ms): 1.6334618264209757

