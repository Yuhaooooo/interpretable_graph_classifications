# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-02-45-05/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-02-45-05/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 16,
 'epochs': 100,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 4,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.003,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 1,
 'num_workers': 8,
 'number_of_mlp_layer': 0,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-18-02-45-05',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 100, 'learning_rate': 0.003, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.003
[92maverage training of epoch 0: loss -1.22927 acc 0.43333 roc_auc 0.35600 prc_auc 0.58629[0m
[93maverage test of epoch 0: loss -2.70392 acc 0.65789 roc_auc 0.86462 prc_auc 0.93807[0m
[92maverage training of epoch 1: loss -3.89528 acc 0.66667 roc_auc 0.37420 prc_auc 0.59414[0m
[93maverage test of epoch 1: loss -4.99303 acc 0.65789 roc_auc 0.86462 prc_auc 0.93807[0m
[92maverage training of epoch 2: loss -5.96960 acc 0.66667 roc_auc 0.36850 prc_auc 0.57732[0m
[93maverage test of epoch 2: loss -6.90717 acc 0.65789 roc_auc 0.86462 prc_auc 0.93807[0m
[92maverage training of epoch 3: loss -7.82480 acc 0.66667 roc_auc 0.36100 prc_auc 0.56719[0m
[93maverage test of epoch 3: loss -8.70893 acc 0.65789 roc_auc 0.86308 prc_auc 0.93673[0m
[92maverage training of epoch 4: loss -9.60455 acc 0.66667 roc_auc 0.35920 prc_auc 0.56375[0m
[93maverage test of epoch 4: loss -10.46128 acc 0.65789 roc_auc 0.86308 prc_auc 0.93166[0m
[92maverage training of epoch 5: loss -11.34706 acc 0.66667 roc_auc 0.35820 prc_auc 0.56266[0m
[93maverage test of epoch 5: loss -12.18598 acc 0.65789 roc_auc 0.85077 prc_auc 0.90104[0m
[92maverage training of epoch 6: loss -13.06738 acc 0.66667 roc_auc 0.35740 prc_auc 0.56219[0m
[93maverage test of epoch 6: loss -13.89311 acc 0.65789 roc_auc 0.84308 prc_auc 0.91709[0m
[92maverage training of epoch 7: loss -14.77308 acc 0.66667 roc_auc 0.35700 prc_auc 0.56179[0m
[93maverage test of epoch 7: loss -15.58819 acc 0.65789 roc_auc 0.68923 prc_auc 0.75860[0m
[92maverage training of epoch 8: loss -16.46846 acc 0.66667 roc_auc 0.35720 prc_auc 0.56202[0m
[93maverage test of epoch 8: loss -17.27455 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 9: loss -18.15625 acc 0.66667 roc_auc 0.35720 prc_auc 0.56189[0m
[93maverage test of epoch 9: loss -18.95438 acc 0.65789 roc_auc 0.65385 prc_auc 0.73529[0m
[92maverage training of epoch 10: loss -19.83829 acc 0.66667 roc_auc 0.35720 prc_auc 0.56212[0m
[93maverage test of epoch 10: loss -20.62917 acc 0.65789 roc_auc 0.72000 prc_auc 0.80842[0m
[92maverage training of epoch 11: loss -21.51583 acc 0.66667 roc_auc 0.35730 prc_auc 0.56188[0m
[93maverage test of epoch 11: loss -22.30000 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 12: loss -23.18982 acc 0.66667 roc_auc 0.35760 prc_auc 0.56296[0m
[93maverage test of epoch 12: loss -23.96768 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 13: loss -24.86094 acc 0.66667 roc_auc 0.35690 prc_auc 0.56296[0m
[93maverage test of epoch 13: loss -25.63277 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 14: loss -26.52973 acc 0.66667 roc_auc 0.35650 prc_auc 0.56206[0m
[93maverage test of epoch 14: loss -27.29577 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 15: loss -28.19660 acc 0.66667 roc_auc 0.35880 prc_auc 0.56512[0m
[93maverage test of epoch 15: loss -28.95703 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 16: loss -29.86188 acc 0.66667 roc_auc 0.35630 prc_auc 0.56459[0m
[93maverage test of epoch 16: loss -30.61685 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 17: loss -31.52583 acc 0.66667 roc_auc 0.35700 prc_auc 0.56751[0m
[93maverage test of epoch 17: loss -32.27546 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 18: loss -33.18866 acc 0.66667 roc_auc 0.36060 prc_auc 0.57540[0m
[93maverage test of epoch 18: loss -33.93305 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -34.85056 acc 0.66667 roc_auc 0.36640 prc_auc 0.57704[0m
[93maverage test of epoch 19: loss -35.58979 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -36.51165 acc 0.66667 roc_auc 0.37280 prc_auc 0.58682[0m
[93maverage test of epoch 20: loss -37.24578 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -38.17207 acc 0.66667 roc_auc 0.36820 prc_auc 0.59566[0m
[93maverage test of epoch 21: loss -38.90116 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -39.83192 acc 0.66667 roc_auc 0.36610 prc_auc 0.59907[0m
[93maverage test of epoch 22: loss -40.55601 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -41.49127 acc 0.66667 roc_auc 0.36060 prc_auc 0.60370[0m
[93maverage test of epoch 23: loss -42.21039 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -43.15019 acc 0.66667 roc_auc 0.42040 prc_auc 0.63037[0m
[93maverage test of epoch 24: loss -43.86438 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -44.80875 acc 0.66667 roc_auc 0.44500 prc_auc 0.64342[0m
[93maverage test of epoch 25: loss -45.51805 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -46.46699 acc 0.66667 roc_auc 0.46000 prc_auc 0.64951[0m
[93maverage test of epoch 26: loss -47.17140 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -48.12495 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 27: loss -48.82451 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -49.78268 acc 0.66667 roc_auc 0.44500 prc_auc 0.64342[0m
[93maverage test of epoch 28: loss -50.47741 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -51.44021 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 29: loss -52.13010 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -53.09755 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 30: loss -53.78263 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -54.75474 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 31: loss -55.43502 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -56.41178 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 32: loss -57.08726 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -58.06870 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 33: loss -58.73939 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -59.72551 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -60.39143 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -61.38223 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -62.04337 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -63.03887 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -63.69524 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -64.69543 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -65.34703 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -66.35191 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -66.99875 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -68.00834 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -68.65043 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -69.66472 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -70.30205 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -71.32104 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -71.95360 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -72.97729 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -73.60508 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -74.63347 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -75.25652 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -76.28961 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -76.90791 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -77.94572 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -78.55927 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -79.60180 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -80.21061 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -81.25786 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -81.86193 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -82.91389 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -83.51322 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -84.56990 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -85.16447 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 50: loss -86.22587 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 50: loss -86.81570 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 51: loss -87.88181 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 51: loss -88.46688 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 52: loss -89.53771 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 52: loss -90.11805 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 53: loss -91.19359 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 53: loss -91.76918 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 54: loss -92.84944 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 54: loss -93.42028 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 55: loss -94.50526 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 55: loss -95.07136 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 56: loss -96.16106 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 56: loss -96.72241 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 57: loss -97.81683 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 57: loss -98.37344 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 58: loss -99.47258 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 58: loss -100.02444 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 59: loss -101.12831 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 59: loss -101.67543 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 60: loss -102.78401 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 60: loss -103.32637 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 61: loss -104.43967 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 61: loss -104.97730 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 62: loss -106.09532 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 62: loss -106.62820 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 63: loss -107.75094 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 63: loss -108.27908 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 64: loss -109.40654 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 64: loss -109.92993 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 65: loss -111.06210 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 65: loss -111.58075 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 66: loss -112.71764 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 66: loss -113.23155 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 67: loss -114.37316 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 67: loss -114.88232 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 68: loss -116.02866 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 68: loss -116.53307 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 69: loss -117.68414 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 69: loss -118.18380 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 70: loss -119.33960 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 70: loss -119.83452 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 71: loss -120.99503 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 71: loss -121.48520 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 72: loss -122.65044 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 72: loss -123.13586 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 73: loss -124.30583 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 73: loss -124.78651 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 74: loss -125.96120 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 74: loss -126.43713 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 75: loss -127.61655 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 75: loss -128.08773 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 76: loss -129.27188 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 76: loss -129.73833 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 77: loss -130.92720 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 77: loss -131.38890 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 78: loss -132.58251 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 78: loss -133.03947 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 79: loss -134.23780 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 79: loss -134.69002 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 80: loss -135.89308 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 80: loss -136.34055 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 81: loss -137.54833 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 81: loss -137.99106 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 82: loss -139.20357 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 82: loss -139.64154 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 83: loss -140.85878 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 83: loss -141.29201 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 84: loss -142.51396 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 84: loss -142.94245 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 85: loss -144.16914 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 85: loss -144.59288 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 86: loss -145.82430 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 86: loss -146.24331 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 87: loss -147.47944 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 87: loss -147.89370 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 88: loss -149.13456 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 88: loss -149.54407 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 89: loss -150.78965 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 89: loss -151.19441 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -152.44472 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 90: loss -152.84473 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 91: loss -154.09977 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 91: loss -154.49502 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 92: loss -155.75479 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 92: loss -156.14531 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 93: loss -157.40980 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 93: loss -157.79555 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 94: loss -159.06477 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 94: loss -159.44577 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 95: loss -160.71971 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 95: loss -161.09596 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 96: loss -162.37462 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 96: loss -162.74612 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 97: loss -164.02950 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 97: loss -164.39624 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 98: loss -165.68437 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 98: loss -166.04637 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -167.33922 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 99: loss -167.69648 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.003
[92maverage training of epoch 0: loss -2.59207 acc 0.58000 roc_auc 0.42900 prc_auc 0.60063[0m
[93maverage test of epoch 0: loss -4.27569 acc 0.65789 roc_auc 0.79538 prc_auc 0.89566[0m
[92maverage training of epoch 1: loss -5.28924 acc 0.66667 roc_auc 0.41640 prc_auc 0.59616[0m
[93maverage test of epoch 1: loss -6.24600 acc 0.65789 roc_auc 0.79385 prc_auc 0.88533[0m
[92maverage training of epoch 2: loss -7.16487 acc 0.66667 roc_auc 0.42040 prc_auc 0.60512[0m
[93maverage test of epoch 2: loss -8.04604 acc 0.65789 roc_auc 0.88462 prc_auc 0.92169[0m
[92maverage training of epoch 3: loss -8.93729 acc 0.66667 roc_auc 0.42060 prc_auc 0.60505[0m
[93maverage test of epoch 3: loss -9.78733 acc 0.65789 roc_auc 0.86462 prc_auc 0.89079[0m
[92maverage training of epoch 4: loss -10.66848 acc 0.66667 roc_auc 0.42020 prc_auc 0.60463[0m
[93maverage test of epoch 4: loss -11.50057 acc 0.65789 roc_auc 0.82000 prc_auc 0.84667[0m
[92maverage training of epoch 5: loss -12.37804 acc 0.66667 roc_auc 0.42010 prc_auc 0.60455[0m
[93maverage test of epoch 5: loss -13.19754 acc 0.65789 roc_auc 0.71692 prc_auc 0.77697[0m
[92maverage training of epoch 6: loss -14.07436 acc 0.66667 roc_auc 0.42010 prc_auc 0.60455[0m
[93maverage test of epoch 6: loss -14.88396 acc 0.65789 roc_auc 0.79846 prc_auc 0.83587[0m
[92maverage training of epoch 7: loss -15.76181 acc 0.66667 roc_auc 0.42010 prc_auc 0.60455[0m
[93maverage test of epoch 7: loss -16.56303 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 8: loss -17.44292 acc 0.66667 roc_auc 0.42010 prc_auc 0.60455[0m
[93maverage test of epoch 8: loss -18.23675 acc 0.65789 roc_auc 0.82308 prc_auc 0.84667[0m
[92maverage training of epoch 9: loss -19.11935 acc 0.66667 roc_auc 0.42010 prc_auc 0.60497[0m
[93maverage test of epoch 9: loss -19.90642 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 10: loss -20.79219 acc 0.66667 roc_auc 0.42020 prc_auc 0.60497[0m
[93maverage test of epoch 10: loss -21.57296 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 11: loss -22.46222 acc 0.66667 roc_auc 0.42040 prc_auc 0.60509[0m
[93maverage test of epoch 11: loss -23.23700 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 12: loss -24.13001 acc 0.66667 roc_auc 0.42060 prc_auc 0.60532[0m
[93maverage test of epoch 12: loss -24.89906 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 13: loss -25.79599 acc 0.66667 roc_auc 0.42030 prc_auc 0.60438[0m
[93maverage test of epoch 13: loss -26.55949 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 14: loss -27.46049 acc 0.66667 roc_auc 0.42060 prc_auc 0.60523[0m
[93maverage test of epoch 14: loss -28.21859 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 15: loss -29.12378 acc 0.66667 roc_auc 0.42000 prc_auc 0.60464[0m
[93maverage test of epoch 15: loss -29.87658 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 16: loss -30.78604 acc 0.66667 roc_auc 0.42060 prc_auc 0.60466[0m
[93maverage test of epoch 16: loss -31.53364 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 17: loss -32.44745 acc 0.66667 roc_auc 0.42140 prc_auc 0.60611[0m
[93maverage test of epoch 17: loss -33.18994 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 18: loss -34.10816 acc 0.66667 roc_auc 0.42190 prc_auc 0.60641[0m
[93maverage test of epoch 18: loss -34.84558 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -35.76825 acc 0.66667 roc_auc 0.42650 prc_auc 0.60980[0m
[93maverage test of epoch 19: loss -36.50067 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -37.42783 acc 0.66667 roc_auc 0.42910 prc_auc 0.61742[0m
[93maverage test of epoch 20: loss -38.15528 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -39.08697 acc 0.66667 roc_auc 0.42990 prc_auc 0.62100[0m
[93maverage test of epoch 21: loss -39.80948 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -40.74574 acc 0.66667 roc_auc 0.45470 prc_auc 0.64146[0m
[93maverage test of epoch 22: loss -41.46334 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -42.40418 acc 0.66667 roc_auc 0.45660 prc_auc 0.64143[0m
[93maverage test of epoch 23: loss -43.11690 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -44.06234 acc 0.66667 roc_auc 0.44040 prc_auc 0.63796[0m
[93maverage test of epoch 24: loss -44.77020 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -45.72025 acc 0.66667 roc_auc 0.45000 prc_auc 0.64615[0m
[93maverage test of epoch 25: loss -46.42327 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -47.37795 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 26: loss -48.07614 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -49.03547 acc 0.66667 roc_auc 0.44500 prc_auc 0.64443[0m
[93maverage test of epoch 27: loss -49.72885 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -50.69283 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 28: loss -51.38141 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -52.35006 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 29: loss -53.03384 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -54.00716 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 30: loss -54.68616 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -55.66415 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 31: loss -56.33837 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -57.32105 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 32: loss -57.99049 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -58.97785 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 33: loss -59.64252 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -60.63458 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -61.29449 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -62.29124 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -62.94639 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -63.94784 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -64.59822 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -65.60437 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -66.25001 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -67.26086 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -67.90174 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -68.91730 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -69.55342 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -70.57369 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -71.20507 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -72.23005 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -72.85668 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -73.88636 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -74.50824 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -75.54264 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -76.15977 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -77.19887 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -77.81125 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -78.85508 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -79.46272 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -80.51126 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -81.11416 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -82.16740 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -82.76556 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -83.82352 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -84.41694 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -85.47961 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -86.06828 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 50: loss -87.13567 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 50: loss -87.71959 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 51: loss -88.79171 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 51: loss -89.37088 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 52: loss -90.44771 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 52: loss -91.02214 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 53: loss -92.10368 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 53: loss -92.67337 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 54: loss -93.75963 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 54: loss -94.32458 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 55: loss -95.41556 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 55: loss -95.97577 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 56: loss -97.07147 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 56: loss -97.62693 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 57: loss -98.72735 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 57: loss -99.27807 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 58: loss -100.38321 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 58: loss -100.92918 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 59: loss -102.03904 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 59: loss -102.58027 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 60: loss -103.69487 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 60: loss -104.23136 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 61: loss -105.35067 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 61: loss -105.88242 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 62: loss -107.00645 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 62: loss -107.53346 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 63: loss -108.66221 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 63: loss -109.18447 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 64: loss -110.31794 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 64: loss -110.83546 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 65: loss -111.97365 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 65: loss -112.48642 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 66: loss -113.62933 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 66: loss -114.13736 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 67: loss -115.28500 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 67: loss -115.78828 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 68: loss -116.94063 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 68: loss -117.43916 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 69: loss -118.59622 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 69: loss -119.09000 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 70: loss -120.25180 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 70: loss -120.74084 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 71: loss -121.90736 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 71: loss -122.39165 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 72: loss -123.56289 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 72: loss -124.04242 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 73: loss -125.21839 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 73: loss -125.69319 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 74: loss -126.87386 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 74: loss -127.34391 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 75: loss -128.52931 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 75: loss -128.99462 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 76: loss -130.18474 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 76: loss -130.64531 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 77: loss -131.84016 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 77: loss -132.29598 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 78: loss -133.49555 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 78: loss -133.94662 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 79: loss -135.15092 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 79: loss -135.59725 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 80: loss -136.80627 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 80: loss -137.24785 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 81: loss -138.46158 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 81: loss -138.89842 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 82: loss -140.11689 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 82: loss -140.54897 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 83: loss -141.77215 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 83: loss -142.19948 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 84: loss -143.42736 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 84: loss -143.84993 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 85: loss -145.08254 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 85: loss -145.50038 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 86: loss -146.73770 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 86: loss -147.15079 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 87: loss -148.39284 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 87: loss -148.80119 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 88: loss -150.04793 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 88: loss -150.45151 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 89: loss -151.70300 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 89: loss -152.10184 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -153.35806 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 90: loss -153.75214 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 91: loss -155.01309 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 91: loss -155.40243 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 92: loss -156.66809 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 92: loss -157.05270 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 93: loss -158.32310 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 93: loss -158.70296 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 94: loss -159.97808 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 94: loss -160.35320 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 95: loss -161.63306 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 95: loss -162.00344 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 96: loss -163.28801 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 96: loss -163.65366 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 97: loss -164.94295 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 97: loss -165.30383 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 98: loss -166.59787 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 98: loss -166.95402 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -168.25278 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 99: loss -168.60417 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.003
[92maverage training of epoch 0: loss -0.98324 acc 0.57333 roc_auc 0.43120 prc_auc 0.64113[0m
[93maverage test of epoch 0: loss -2.63973 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 1: loss -4.18387 acc 0.66667 roc_auc 0.39770 prc_auc 0.60718[0m
[93maverage test of epoch 1: loss -5.35458 acc 0.65789 roc_auc 0.95231 prc_auc 0.97791[0m
[92maverage training of epoch 2: loss -6.37616 acc 0.66667 roc_auc 0.38380 prc_auc 0.59336[0m
[93maverage test of epoch 2: loss -7.31232 acc 0.65789 roc_auc 0.95077 prc_auc 0.97663[0m
[92maverage training of epoch 3: loss -8.26408 acc 0.66667 roc_auc 0.37980 prc_auc 0.57757[0m
[93maverage test of epoch 3: loss -9.13935 acc 0.65789 roc_auc 0.93538 prc_auc 0.95662[0m
[92maverage training of epoch 4: loss -10.06464 acc 0.66667 roc_auc 0.37790 prc_auc 0.57529[0m
[93maverage test of epoch 4: loss -10.90879 acc 0.65789 roc_auc 0.86462 prc_auc 0.87965[0m
[92maverage training of epoch 5: loss -11.82174 acc 0.66667 roc_auc 0.37750 prc_auc 0.57480[0m
[93maverage test of epoch 5: loss -12.64588 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 6: loss -13.55289 acc 0.66667 roc_auc 0.37720 prc_auc 0.57449[0m
[93maverage test of epoch 6: loss -14.36238 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 7: loss -15.26689 acc 0.66667 roc_auc 0.37730 prc_auc 0.57487[0m
[93maverage test of epoch 7: loss -16.06476 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 8: loss -16.96880 acc 0.66667 roc_auc 0.37730 prc_auc 0.57547[0m
[93maverage test of epoch 8: loss -17.75692 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 9: loss -18.66183 acc 0.66667 roc_auc 0.37720 prc_auc 0.57741[0m
[93maverage test of epoch 9: loss -19.44142 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 10: loss -20.34811 acc 0.66667 roc_auc 0.37720 prc_auc 0.57674[0m
[93maverage test of epoch 10: loss -21.12004 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 11: loss -22.02913 acc 0.66667 roc_auc 0.37660 prc_auc 0.57928[0m
[93maverage test of epoch 11: loss -22.79401 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 12: loss -23.70599 acc 0.66667 roc_auc 0.37770 prc_auc 0.57468[0m
[93maverage test of epoch 12: loss -24.46428 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 13: loss -25.37950 acc 0.66667 roc_auc 0.37820 prc_auc 0.58000[0m
[93maverage test of epoch 13: loss -26.13155 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 14: loss -27.05028 acc 0.66667 roc_auc 0.37690 prc_auc 0.58124[0m
[93maverage test of epoch 14: loss -27.79636 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 15: loss -28.71881 acc 0.66667 roc_auc 0.38740 prc_auc 0.59286[0m
[93maverage test of epoch 15: loss -29.45914 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 16: loss -30.38549 acc 0.66667 roc_auc 0.38120 prc_auc 0.58924[0m
[93maverage test of epoch 16: loss -31.12023 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 17: loss -32.05061 acc 0.66667 roc_auc 0.39440 prc_auc 0.60082[0m
[93maverage test of epoch 17: loss -32.77992 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 18: loss -33.71444 acc 0.66667 roc_auc 0.38900 prc_auc 0.60504[0m
[93maverage test of epoch 18: loss -34.43841 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -35.37716 acc 0.66667 roc_auc 0.43280 prc_auc 0.63235[0m
[93maverage test of epoch 19: loss -36.09590 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -37.03897 acc 0.66667 roc_auc 0.44150 prc_auc 0.63849[0m
[93maverage test of epoch 20: loss -37.75255 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -38.69999 acc 0.66667 roc_auc 0.47000 prc_auc 0.65366[0m
[93maverage test of epoch 21: loss -39.40847 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -40.36033 acc 0.66667 roc_auc 0.48000 prc_auc 0.65792[0m
[93maverage test of epoch 22: loss -41.06377 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -42.02010 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 23: loss -42.71854 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -43.67937 acc 0.66667 roc_auc 0.47500 prc_auc 0.65578[0m
[93maverage test of epoch 24: loss -44.37286 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -45.33823 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 25: loss -46.02679 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -46.99672 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 26: loss -47.68037 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -48.65489 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 27: loss -49.33367 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -50.31279 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 28: loss -50.98671 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -51.97046 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 29: loss -52.63954 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -53.62791 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 30: loss -54.29216 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -55.28519 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 31: loss -55.94463 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -56.94230 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 32: loss -57.59693 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -58.59928 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 33: loss -59.24912 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -60.25613 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -60.90119 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -61.91288 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -62.55315 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -63.56953 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -64.20503 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -65.22610 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -65.85683 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -66.88259 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -67.50854 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -68.53900 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -69.16018 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -70.19535 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -70.81179 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -71.85166 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -72.46334 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -73.50792 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -74.11484 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -75.16412 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -75.76630 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -76.82028 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -77.41771 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -78.47641 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -79.06910 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -80.13250 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -80.72043 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -81.78855 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -82.37172 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -83.44456 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -84.02298 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -85.10052 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -85.67419 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 50: loss -86.75644 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 50: loss -87.32537 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 51: loss -88.41233 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 51: loss -88.97651 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 52: loss -90.06819 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 52: loss -90.62762 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 53: loss -91.72403 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 53: loss -92.27872 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 54: loss -93.37984 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 54: loss -93.92978 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 55: loss -95.03562 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 55: loss -95.58082 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 56: loss -96.69139 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 56: loss -97.23185 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 57: loss -98.34713 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 57: loss -98.88284 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 58: loss -100.00283 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 58: loss -100.53380 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 59: loss -101.65852 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 59: loss -102.18474 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 60: loss -103.31418 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 60: loss -103.83565 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 61: loss -104.96982 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 61: loss -105.48656 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 62: loss -106.62544 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 62: loss -107.13743 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 63: loss -108.28104 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 63: loss -108.78829 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 64: loss -109.93661 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 64: loss -110.43910 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 65: loss -111.59215 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 65: loss -112.08990 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 66: loss -113.24768 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 66: loss -113.74068 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 67: loss -114.90317 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 67: loss -115.39142 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 68: loss -116.55864 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 68: loss -117.04214 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 69: loss -118.21408 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 69: loss -118.69283 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 70: loss -119.86950 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 70: loss -120.34351 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 71: loss -121.52490 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 71: loss -121.99415 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 72: loss -123.18026 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 72: loss -123.64476 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 73: loss -124.83559 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 73: loss -125.29535 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 74: loss -126.49090 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 74: loss -126.94592 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 75: loss -128.14619 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 75: loss -128.59645 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 76: loss -129.80145 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 76: loss -130.24696 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 77: loss -131.45668 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 77: loss -131.89745 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 78: loss -133.11190 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 78: loss -133.54792 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 79: loss -134.76709 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 79: loss -135.19836 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 80: loss -136.42226 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 80: loss -136.84879 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 81: loss -138.07740 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 81: loss -138.49919 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 82: loss -139.73253 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 82: loss -140.14957 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 83: loss -141.38763 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 83: loss -141.79994 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 84: loss -143.04273 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 84: loss -143.45028 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 85: loss -144.69780 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 85: loss -145.10062 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 86: loss -146.35285 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 86: loss -146.75092 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 87: loss -148.00788 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 87: loss -148.40120 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 88: loss -149.66289 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 88: loss -150.05147 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 89: loss -151.31788 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 89: loss -151.70170 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -152.97284 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 90: loss -153.35191 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 91: loss -154.62778 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 91: loss -155.00212 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 92: loss -156.28270 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 92: loss -156.65228 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 93: loss -157.93760 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 93: loss -158.30243 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 94: loss -159.59247 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 94: loss -159.95256 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 95: loss -161.24732 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 95: loss -161.60265 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 96: loss -162.90215 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 96: loss -163.25273 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 97: loss -164.55694 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 97: loss -164.90278 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 98: loss -166.21173 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 98: loss -166.55282 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -167.86650 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 99: loss -168.20284 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.003
[92maverage training of epoch 0: loss -0.70025 acc 0.56954 roc_auc 0.55941 prc_auc 0.68778[0m
[93maverage test of epoch 0: loss -1.65381 acc 0.32432 roc_auc 0.86000 prc_auc 0.92243[0m
[92maverage training of epoch 1: loss -2.65908 acc 0.62252 roc_auc 0.80118 prc_auc 0.86845[0m
[93maverage test of epoch 1: loss -3.52432 acc 0.62162 roc_auc 0.85667 prc_auc 0.91780[0m
[92maverage training of epoch 2: loss -4.48588 acc 0.87417 roc_auc 0.83039 prc_auc 0.85254[0m
[93maverage test of epoch 2: loss -5.35988 acc 0.86486 roc_auc 0.83333 prc_auc 0.86831[0m
[92maverage training of epoch 3: loss -6.17071 acc 0.85430 roc_auc 0.82980 prc_auc 0.83940[0m
[93maverage test of epoch 3: loss -7.00294 acc 0.86486 roc_auc 0.81167 prc_auc 0.86344[0m
[92maverage training of epoch 4: loss -7.80537 acc 0.86755 roc_auc 0.83353 prc_auc 0.83988[0m
[93maverage test of epoch 4: loss -8.53831 acc 0.81081 roc_auc 0.80333 prc_auc 0.84300[0m
[92maverage training of epoch 5: loss -9.40348 acc 0.86755 roc_auc 0.83196 prc_auc 0.84098[0m
[93maverage test of epoch 5: loss -10.15943 acc 0.81081 roc_auc 0.82667 prc_auc 0.87133[0m
[92maverage training of epoch 6: loss -10.85848 acc 0.83444 roc_auc 0.83392 prc_auc 0.87003[0m
[93maverage test of epoch 6: loss -11.60576 acc 0.83784 roc_auc 0.84833 prc_auc 0.89353[0m
[92maverage training of epoch 7: loss -12.55078 acc 0.88079 roc_auc 0.83706 prc_auc 0.84265[0m
[93maverage test of epoch 7: loss -13.27426 acc 0.81081 roc_auc 0.85000 prc_auc 0.89209[0m
[92maverage training of epoch 8: loss -13.96223 acc 0.83444 roc_auc 0.84549 prc_auc 0.87492[0m
[93maverage test of epoch 8: loss -14.79486 acc 0.86486 roc_auc 0.85000 prc_auc 0.89845[0m
[92maverage training of epoch 9: loss -15.66978 acc 0.88742 roc_auc 0.83637 prc_auc 0.84329[0m
[93maverage test of epoch 9: loss -16.41145 acc 0.81081 roc_auc 0.85000 prc_auc 0.89209[0m
[92maverage training of epoch 10: loss -17.22743 acc 0.87417 roc_auc 0.83637 prc_auc 0.85209[0m
[93maverage test of epoch 10: loss -18.00424 acc 0.86486 roc_auc 0.85000 prc_auc 0.89392[0m
[92maverage training of epoch 11: loss -18.78952 acc 0.87417 roc_auc 0.83608 prc_auc 0.85262[0m
[93maverage test of epoch 11: loss -19.55480 acc 0.86486 roc_auc 0.85667 prc_auc 0.89811[0m
[92maverage training of epoch 12: loss -20.35211 acc 0.88742 roc_auc 0.83529 prc_auc 0.85231[0m
[93maverage test of epoch 12: loss -21.10292 acc 0.86486 roc_auc 0.85333 prc_auc 0.89266[0m
[92maverage training of epoch 13: loss -21.90669 acc 0.88742 roc_auc 0.83725 prc_auc 0.85669[0m
[93maverage test of epoch 13: loss -22.68354 acc 0.86486 roc_auc 0.86000 prc_auc 0.89895[0m
[92maverage training of epoch 14: loss -23.44768 acc 0.88742 roc_auc 0.84569 prc_auc 0.86867[0m
[93maverage test of epoch 14: loss -24.24380 acc 0.86486 roc_auc 0.82500 prc_auc 0.86718[0m
[92maverage training of epoch 15: loss -25.00516 acc 0.88742 roc_auc 0.84863 prc_auc 0.86934[0m
[93maverage test of epoch 15: loss -25.79081 acc 0.86486 roc_auc 0.86000 prc_auc 0.89914[0m
[92maverage training of epoch 16: loss -26.56682 acc 0.89404 roc_auc 0.85431 prc_auc 0.88154[0m
[93maverage test of epoch 16: loss -27.33830 acc 0.86486 roc_auc 0.82500 prc_auc 0.86718[0m
[92maverage training of epoch 17: loss -28.12791 acc 0.89404 roc_auc 0.85373 prc_auc 0.88520[0m
[93maverage test of epoch 17: loss -28.87830 acc 0.86486 roc_auc 0.82500 prc_auc 0.86718[0m
[92maverage training of epoch 18: loss -29.68123 acc 0.89404 roc_auc 0.88775 prc_auc 0.92252[0m
[93maverage test of epoch 18: loss -30.42035 acc 0.86486 roc_auc 0.86333 prc_auc 0.89914[0m
[92maverage training of epoch 19: loss -31.25310 acc 0.90066 roc_auc 0.88431 prc_auc 0.91932[0m
[93maverage test of epoch 19: loss -31.97873 acc 0.86486 roc_auc 0.83833 prc_auc 0.87636[0m
[92maverage training of epoch 20: loss -32.82040 acc 0.90066 roc_auc 0.88608 prc_auc 0.92105[0m
[93maverage test of epoch 20: loss -33.52506 acc 0.86486 roc_auc 0.83833 prc_auc 0.87636[0m
[92maverage training of epoch 21: loss -34.30893 acc 0.90066 roc_auc 0.87755 prc_auc 0.91211[0m
[93maverage test of epoch 21: loss -35.07125 acc 0.86486 roc_auc 0.83833 prc_auc 0.87636[0m
[92maverage training of epoch 22: loss -35.95279 acc 0.90066 roc_auc 0.87843 prc_auc 0.91284[0m
[93maverage test of epoch 22: loss -36.61984 acc 0.86486 roc_auc 0.83500 prc_auc 0.87526[0m
[92maverage training of epoch 23: loss -37.49818 acc 0.90066 roc_auc 0.87882 prc_auc 0.91300[0m
[93maverage test of epoch 23: loss -38.15978 acc 0.86486 roc_auc 0.83500 prc_auc 0.87526[0m
[92maverage training of epoch 24: loss -39.05226 acc 0.89404 roc_auc 0.87863 prc_auc 0.91292[0m
[93maverage test of epoch 24: loss -39.69115 acc 0.86486 roc_auc 0.83500 prc_auc 0.87526[0m
[92maverage training of epoch 25: loss -40.60349 acc 0.89404 roc_auc 0.87863 prc_auc 0.91293[0m
[93maverage test of epoch 25: loss -41.21281 acc 0.86486 roc_auc 0.83167 prc_auc 0.87442[0m
[92maverage training of epoch 26: loss -42.16980 acc 0.89404 roc_auc 0.87882 prc_auc 0.91297[0m
[93maverage test of epoch 26: loss -42.78224 acc 0.86486 roc_auc 0.83167 prc_auc 0.87442[0m
[92maverage training of epoch 27: loss -43.77228 acc 0.90728 roc_auc 0.87990 prc_auc 0.91378[0m
[93maverage test of epoch 27: loss -44.23040 acc 0.86486 roc_auc 0.83167 prc_auc 0.87442[0m
[92maverage training of epoch 28: loss -45.29171 acc 0.89404 roc_auc 0.88078 prc_auc 0.91443[0m
[93maverage test of epoch 28: loss -45.87930 acc 0.86486 roc_auc 0.83500 prc_auc 0.87526[0m
[92maverage training of epoch 29: loss -46.89392 acc 0.90728 roc_auc 0.88078 prc_auc 0.91448[0m
[93maverage test of epoch 29: loss -47.43189 acc 0.86486 roc_auc 0.83167 prc_auc 0.87442[0m
[92maverage training of epoch 30: loss -48.37026 acc 0.89404 roc_auc 0.87951 prc_auc 0.91402[0m
[93maverage test of epoch 30: loss -48.95510 acc 0.86486 roc_auc 0.83333 prc_auc 0.87442[0m
[92maverage training of epoch 31: loss -49.98609 acc 0.90066 roc_auc 0.88069 prc_auc 0.91447[0m
[93maverage test of epoch 31: loss -50.41768 acc 0.83784 roc_auc 0.82833 prc_auc 0.87326[0m
[92maverage training of epoch 32: loss -51.51948 acc 0.89404 roc_auc 0.87137 prc_auc 0.90583[0m
[93maverage test of epoch 32: loss -52.00290 acc 0.86486 roc_auc 0.83167 prc_auc 0.87423[0m
[92maverage training of epoch 33: loss -53.09830 acc 0.90066 roc_auc 0.88039 prc_auc 0.91434[0m
[93maverage test of epoch 33: loss -53.53946 acc 0.86486 roc_auc 0.82833 prc_auc 0.87339[0m
[92maverage training of epoch 34: loss -54.66785 acc 0.90066 roc_auc 0.88059 prc_auc 0.91443[0m
[93maverage test of epoch 34: loss -55.07757 acc 0.86486 roc_auc 0.82833 prc_auc 0.87339[0mUsing backend: pytorch
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))

[92maverage training of epoch 35: loss -56.23519 acc 0.90066 roc_auc 0.88059 prc_auc 0.91443[0m
[93maverage test of epoch 35: loss -56.62654 acc 0.86486 roc_auc 0.82833 prc_auc 0.87339[0m
[92maverage training of epoch 36: loss -57.79610 acc 0.90066 roc_auc 0.88059 prc_auc 0.91443[0m
[93maverage test of epoch 36: loss -58.17793 acc 0.86486 roc_auc 0.82833 prc_auc 0.87326[0m
[92maverage training of epoch 37: loss -59.35033 acc 0.90066 roc_auc 0.88147 prc_auc 0.91516[0m
[93maverage test of epoch 37: loss -59.72601 acc 0.86486 roc_auc 0.82833 prc_auc 0.87326[0m
[92maverage training of epoch 38: loss -60.90586 acc 0.90066 roc_auc 0.88147 prc_auc 0.91516[0m
[93maverage test of epoch 38: loss -61.27236 acc 0.86486 roc_auc 0.83167 prc_auc 0.87415[0m
[92maverage training of epoch 39: loss -62.46242 acc 0.90066 roc_auc 0.88147 prc_auc 0.91516[0m
[93maverage test of epoch 39: loss -62.81495 acc 0.86486 roc_auc 0.83167 prc_auc 0.87415[0m
[92maverage training of epoch 40: loss -64.01105 acc 0.90066 roc_auc 0.88147 prc_auc 0.91516[0m
[93maverage test of epoch 40: loss -64.34243 acc 0.86486 roc_auc 0.83167 prc_auc 0.87415[0m
[92maverage training of epoch 41: loss -65.55767 acc 0.90066 roc_auc 0.88059 prc_auc 0.91443[0m
[93maverage test of epoch 41: loss -65.87517 acc 0.86486 roc_auc 0.83167 prc_auc 0.87423[0m
[92maverage training of epoch 42: loss -67.24995 acc 0.91391 roc_auc 0.89980 prc_auc 0.93245[0m
[93maverage test of epoch 42: loss -65.49770 acc 0.81081 roc_auc 0.80667 prc_auc 0.85513[0m
[92maverage training of epoch 43: loss -68.87197 acc 0.92053 roc_auc 0.90902 prc_auc 0.94141[0m
[93maverage test of epoch 43: loss -68.63688 acc 0.86486 roc_auc 0.83833 prc_auc 0.87473[0m
[92maverage training of epoch 44: loss -70.56612 acc 0.92715 roc_auc 0.90980 prc_auc 0.94192[0m
[93maverage test of epoch 44: loss -70.29332 acc 0.86486 roc_auc 0.83833 prc_auc 0.87526[0m
[92maverage training of epoch 45: loss -72.03190 acc 0.91391 roc_auc 0.90059 prc_auc 0.93279[0m
[93maverage test of epoch 45: loss -70.17786 acc 0.81081 roc_auc 0.82167 prc_auc 0.86101[0m
[92maverage training of epoch 46: loss -73.73719 acc 0.92715 roc_auc 0.91020 prc_auc 0.94207[0m
[93maverage test of epoch 46: loss -71.52607 acc 0.81081 roc_auc 0.82500 prc_auc 0.86212[0m
[92maverage training of epoch 47: loss -75.34921 acc 0.92715 roc_auc 0.91020 prc_auc 0.94213[0m
[93maverage test of epoch 47: loss -73.89425 acc 0.83784 roc_auc 0.83667 prc_auc 0.86994[0m
[92maverage training of epoch 48: loss -76.91556 acc 0.92715 roc_auc 0.91098 prc_auc 0.94240[0m
[93maverage test of epoch 48: loss -75.53886 acc 0.86486 roc_auc 0.83500 prc_auc 0.86899[0m
[92maverage training of epoch 49: loss -78.51436 acc 0.92715 roc_auc 0.91118 prc_auc 0.94271[0m
[93maverage test of epoch 49: loss -77.22881 acc 0.86486 roc_auc 0.83167 prc_auc 0.86899[0m
[92maverage training of epoch 50: loss -80.11143 acc 0.92715 roc_auc 0.91098 prc_auc 0.94270[0m
[93maverage test of epoch 50: loss -78.64499 acc 0.86486 roc_auc 0.83500 prc_auc 0.86994[0m
[92maverage training of epoch 51: loss -81.68155 acc 0.92715 roc_auc 0.91000 prc_auc 0.94210[0m
[93maverage test of epoch 51: loss -80.26849 acc 0.86486 roc_auc 0.83500 prc_auc 0.87209[0m
[92maverage training of epoch 52: loss -83.28334 acc 0.92715 roc_auc 0.91990 prc_auc 0.95190[0m
[93maverage test of epoch 52: loss -81.67310 acc 0.86486 roc_auc 0.83667 prc_auc 0.87185[0m
[92maverage training of epoch 53: loss -84.96657 acc 0.92715 roc_auc 0.92127 prc_auc 0.95221[0m
[93maverage test of epoch 53: loss -82.90717 acc 0.86486 roc_auc 0.84333 prc_auc 0.87532[0m
[92maverage training of epoch 54: loss -86.45711 acc 0.92053 roc_auc 0.93676 prc_auc 0.95715[0m
[93maverage test of epoch 54: loss -84.81246 acc 0.83784 roc_auc 0.84667 prc_auc 0.87622[0m
[92maverage training of epoch 55: loss -88.00554 acc 0.92715 roc_auc 0.93510 prc_auc 0.95067[0m
[93maverage test of epoch 55: loss -85.99252 acc 0.81081 roc_auc 0.81333 prc_auc 0.84746[0m
[92maverage training of epoch 56: loss -89.55114 acc 0.91391 roc_auc 0.93510 prc_auc 0.95041[0m
[93maverage test of epoch 56: loss -87.29554 acc 0.81081 roc_auc 0.80667 prc_auc 0.84513[0m
[92maverage training of epoch 57: loss -91.39847 acc 0.91391 roc_auc 0.94441 prc_auc 0.96006[0m
[93maverage test of epoch 57: loss -88.11594 acc 0.78378 roc_auc 0.80000 prc_auc 0.83996[0m
[92maverage training of epoch 58: loss -93.12661 acc 0.92715 roc_auc 0.95235 prc_auc 0.96925[0m
[93maverage test of epoch 58: loss -89.67909 acc 0.78378 roc_auc 0.80000 prc_auc 0.83996[0m
[92maverage training of epoch 59: loss -94.88816 acc 0.94040 roc_auc 0.96510 prc_auc 0.98717[0m
[93maverage test of epoch 59: loss -91.22100 acc 0.78378 roc_auc 0.82833 prc_auc 0.86706[0m
[92maverage training of epoch 60: loss -96.33844 acc 0.95364 roc_auc 0.96471 prc_auc 0.98703[0m
[93maverage test of epoch 60: loss -91.79096 acc 0.75676 roc_auc 0.83333 prc_auc 0.86594[0m
[92maverage training of epoch 61: loss -98.20435 acc 0.94702 roc_auc 0.96569 prc_auc 0.98755[0m
[93maverage test of epoch 61: loss -93.89888 acc 0.78378 roc_auc 0.80000 prc_auc 0.83996[0m
[92maverage training of epoch 62: loss -100.02326 acc 0.95364 roc_auc 0.96598 prc_auc 0.98096[0m
[93maverage test of epoch 62: loss -96.21933 acc 0.81081 roc_auc 0.80667 prc_auc 0.84513[0m
[92maverage training of epoch 63: loss -101.56492 acc 0.96026 roc_auc 0.96765 prc_auc 0.98824[0m
[93maverage test of epoch 63: loss -97.13168 acc 0.78378 roc_auc 0.79667 prc_auc 0.83874[0m
[92maverage training of epoch 64: loss -103.32646 acc 0.96026 roc_auc 0.97608 prc_auc 0.99121[0m
[93maverage test of epoch 64: loss -99.06401 acc 0.81081 roc_auc 0.80000 prc_auc 0.83996[0m
[92maverage training of epoch 65: loss -105.00550 acc 0.96689 roc_auc 0.97333 prc_auc 0.98985[0m
[93maverage test of epoch 65: loss -99.76713 acc 0.78378 roc_auc 0.79333 prc_auc 0.83749[0m
[92maverage training of epoch 66: loss -106.63732 acc 0.96689 roc_auc 0.96755 prc_auc 0.98160[0m
[93maverage test of epoch 66: loss -101.16030 acc 0.78378 roc_auc 0.79667 prc_auc 0.83874[0m
[92maverage training of epoch 67: loss -108.35154 acc 0.96689 roc_auc 0.97627 prc_auc 0.99125[0m
[93maverage test of epoch 67: loss -104.31186 acc 0.78378 roc_auc 0.80333 prc_auc 0.84391[0m
[92maverage training of epoch 68: loss -110.05803 acc 0.96026 roc_auc 0.96765 prc_auc 0.98166[0m
[93maverage test of epoch 68: loss -105.38744 acc 0.78378 roc_auc 0.80333 prc_auc 0.84391[0m
[92maverage training of epoch 69: loss -111.32792 acc 0.96026 roc_auc 0.95843 prc_auc 0.97196[0m
[93maverage test of epoch 69: loss -106.18887 acc 0.78378 roc_auc 0.79667 prc_auc 0.83874[0m
[92maverage training of epoch 70: loss -113.39771 acc 0.97351 roc_auc 0.96873 prc_auc 0.98217[0m
[93maverage test of epoch 70: loss -109.43417 acc 0.81081 roc_auc 0.77500 prc_auc 0.82215[0m
[92maverage training of epoch 71: loss -114.88094 acc 0.96026 roc_auc 0.95843 prc_auc 0.97209[0m
[93maverage test of epoch 71: loss -110.58845 acc 0.83784 roc_auc 0.81333 prc_auc 0.85014[0m
[92maverage training of epoch 72: loss -116.77297 acc 0.97351 roc_auc 0.97725 prc_auc 0.99168[0m
[93maverage test of epoch 72: loss -111.38989 acc 0.81081 roc_auc 0.79667 prc_auc 0.83874[0m
[92maverage training of epoch 73: loss -118.50779 acc 0.96689 roc_auc 0.96873 prc_auc 0.98217[0m
[93maverage test of epoch 73: loss -101.62262 acc 0.81081 roc_auc 0.76667 prc_auc 0.81633[0m
[92maverage training of epoch 74: loss -120.09745 acc 0.97351 roc_auc 0.96873 prc_auc 0.98217[0m
[93maverage test of epoch 74: loss -101.26630 acc 0.78378 roc_auc 0.76667 prc_auc 0.81633[0m
[92maverage training of epoch 75: loss -121.76867 acc 0.97351 roc_auc 0.96873 prc_auc 0.98215[0m
[93maverage test of epoch 75: loss -113.13490 acc 0.72973 roc_auc 0.75000 prc_auc 0.80419[0m
[92maverage training of epoch 76: loss -123.22019 acc 0.96689 roc_auc 0.97157 prc_auc 0.98950[0m
[93maverage test of epoch 76: loss -112.14529 acc 0.72973 roc_auc 0.75000 prc_auc 0.80419[0m
[92maverage training of epoch 77: loss -125.06344 acc 0.97351 roc_auc 0.96873 prc_auc 0.98217[0m
[93maverage test of epoch 77: loss -101.39638 acc 0.78378 roc_auc 0.75833 prc_auc 0.81035[0m
[92maverage training of epoch 78: loss -126.17216 acc 0.97351 roc_auc 0.97863 prc_auc 0.99219[0m
[93maverage test of epoch 78: loss -118.88678 acc 0.78378 roc_auc 0.76667 prc_auc 0.81633[0m
[92maverage training of epoch 79: loss -127.91486 acc 0.97351 roc_auc 0.96873 prc_auc 0.98215[0m
[93maverage test of epoch 79: loss -112.53864 acc 0.78378 roc_auc 0.79333 prc_auc 0.83749[0m
[92maverage training of epoch 80: loss -129.22788 acc 0.97351 roc_auc 0.96843 prc_auc 0.98200[0m
[93maverage test of epoch 80: loss -121.82927 acc 0.78378 roc_auc 0.79333 prc_auc 0.83749[0m
[92maverage training of epoch 81: loss -131.77310 acc 0.98013 roc_auc 0.97882 prc_auc 0.99227[0m
[93maverage test of epoch 81: loss -117.09675 acc 0.75676 roc_auc 0.79333 prc_auc 0.83749[0m
[92maverage training of epoch 82: loss -133.39630 acc 0.98013 roc_auc 0.97882 prc_auc 0.99227[0m
[93maverage test of epoch 82: loss -124.80264 acc 0.75676 roc_auc 0.78667 prc_auc 0.83215[0m
[92maverage training of epoch 83: loss -134.82303 acc 0.98013 roc_auc 0.97824 prc_auc 0.99207[0m
[93maverage test of epoch 83: loss -116.07278 acc 0.78378 roc_auc 0.79333 prc_auc 0.83749[0m
[92maverage training of epoch 84: loss -136.30872 acc 0.98013 roc_auc 0.97843 prc_auc 0.99214[0m
[93maverage test of epoch 84: loss -127.53903 acc 0.78378 roc_auc 0.79667 prc_auc 0.83874[0m
[92maverage training of epoch 85: loss -138.29807 acc 0.98013 roc_auc 0.97863 prc_auc 0.99219[0m
[93maverage test of epoch 85: loss -129.31802 acc 0.75676 roc_auc 0.78333 prc_auc 0.83108[0m
[92maverage training of epoch 86: loss -139.52483 acc 0.97351 roc_auc 0.97451 prc_auc 0.99043[0m
[93maverage test of epoch 86: loss -129.27596 acc 0.75676 roc_auc 0.79000 prc_auc 0.83341[0m
[92maverage training of epoch 87: loss -141.15812 acc 0.98013 roc_auc 0.97843 prc_auc 0.99212[0m
[93maverage test of epoch 87: loss -132.26961 acc 0.75676 roc_auc 0.78000 prc_auc 0.82979[0m
[92maverage training of epoch 88: loss -141.87697 acc 0.96689 roc_auc 0.95922 prc_auc 0.97250[0m
[93maverage test of epoch 88: loss -117.58899 acc 0.75676 roc_auc 0.75833 prc_auc 0.81035[0m
[92maverage training of epoch 89: loss -130.43893 acc 0.95364 roc_auc 0.93510 prc_auc 0.94644[0m
[93maverage test of epoch 89: loss -113.05867 acc 0.75676 roc_auc 0.75833 prc_auc 0.81035[0m
[92maverage training of epoch 90: loss -130.77055 acc 0.94040 roc_auc 0.92529 prc_auc 0.93742[0m
[93maverage test of epoch 90: loss -119.95853 acc 0.75676 roc_auc 0.75833 prc_auc 0.81035[0m
[92maverage training of epoch 91: loss -134.77002 acc 0.95364 roc_auc 0.94392 prc_auc 0.96091[0m
[93maverage test of epoch 91: loss -138.73681 acc 0.75676 roc_auc 0.81833 prc_auc 0.86042[0m
[92maverage training of epoch 92: loss -148.42463 acc 0.96689 roc_auc 0.95961 prc_auc 0.97898[0m
[93maverage test of epoch 92: loss -134.40588 acc 0.75676 roc_auc 0.79667 prc_auc 0.83581[0m
[92maverage training of epoch 93: loss -148.93180 acc 0.96689 roc_auc 0.97745 prc_auc 0.99173[0m
[93maverage test of epoch 93: loss -141.11826 acc 0.78378 roc_auc 0.79333 prc_auc 0.83766[0m
[92maverage training of epoch 94: loss -150.34610 acc 0.96689 roc_auc 0.96922 prc_auc 0.98229[0m
[93maverage test of epoch 94: loss -122.42061 acc 0.78378 roc_auc 0.76667 prc_auc 0.81633[0m
[92maverage training of epoch 95: loss -151.18346 acc 0.97351 roc_auc 0.96892 prc_auc 0.98220[0m
[93maverage test of epoch 95: loss -143.82196 acc 0.75676 roc_auc 0.79333 prc_auc 0.83473[0m
[92maverage training of epoch 96: loss -155.71064 acc 0.98013 roc_auc 0.97824 prc_auc 0.99207[0m
[93maverage test of epoch 96: loss -145.69631 acc 0.78378 roc_auc 0.79667 prc_auc 0.83888[0m
[92maverage training of epoch 97: loss -157.34886 acc 0.98013 roc_auc 0.97882 prc_auc 0.99227[0m
[93maverage test of epoch 97: loss -137.43790 acc 0.78378 roc_auc 0.79333 prc_auc 0.83766[0m
[92maverage training of epoch 98: loss -158.27226 acc 0.97351 roc_auc 0.97824 prc_auc 0.99205[0m
[93maverage test of epoch 98: loss -148.28158 acc 0.75676 roc_auc 0.76833 prc_auc 0.82710[0m
[92maverage training of epoch 99: loss -159.72108 acc 0.97351 roc_auc 0.97863 prc_auc 0.99219[0m
[93maverage test of epoch 99: loss -148.42453 acc 0.81081 roc_auc 0.79667 prc_auc 0.83874[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.003
[92maverage training of epoch 0: loss -1.55656 acc 0.66225 roc_auc 0.39961 prc_auc 0.60512[0m
[93maverage test of epoch 0: loss -2.68451 acc 0.67568 roc_auc 0.92667 prc_auc 0.97104[0m
[92maverage training of epoch 1: loss -3.64133 acc 0.66225 roc_auc 0.37667 prc_auc 0.57828[0m
[93maverage test of epoch 1: loss -4.65308 acc 0.67568 roc_auc 0.92500 prc_auc 0.96822[0m
[92maverage training of epoch 2: loss -5.49997 acc 0.66225 roc_auc 0.37216 prc_auc 0.56973[0m
[93maverage test of epoch 2: loss -6.45317 acc 0.67568 roc_auc 0.93333 prc_auc 0.96875[0m
[92maverage training of epoch 3: loss -7.26338 acc 0.66225 roc_auc 0.37098 prc_auc 0.56897[0m
[93maverage test of epoch 3: loss -8.20213 acc 0.67568 roc_auc 0.92667 prc_auc 0.95690[0m
[92maverage training of epoch 4: loss -8.99179 acc 0.66225 roc_auc 0.37039 prc_auc 0.56848[0m
[93maverage test of epoch 4: loss -9.92691 acc 0.67568 roc_auc 0.94667 prc_auc 0.96121[0m
[92maverage training of epoch 5: loss -10.70177 acc 0.66225 roc_auc 0.37000 prc_auc 0.56830[0m
[93maverage test of epoch 5: loss -11.63759 acc 0.67568 roc_auc 0.79333 prc_auc 0.83776[0m
[92maverage training of epoch 6: loss -12.40039 acc 0.66225 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 6: loss -13.33907 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 7: loss -14.09132 acc 0.66225 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 7: loss -15.03411 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 8: loss -15.77676 acc 0.66225 roc_auc 0.36980 prc_auc 0.56863[0m
[93maverage test of epoch 8: loss -16.72445 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 9: loss -17.45812 acc 0.66225 roc_auc 0.36990 prc_auc 0.56829[0m
[93maverage test of epoch 9: loss -18.41122 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 10: loss -19.13634 acc 0.66225 roc_auc 0.36990 prc_auc 0.56873[0m
[93maverage test of epoch 10: loss -20.09523 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 11: loss -20.81210 acc 0.66225 roc_auc 0.36980 prc_auc 0.56880[0m
[93maverage test of epoch 11: loss -21.77705 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 12: loss -22.48589 acc 0.66225 roc_auc 0.36990 prc_auc 0.56946[0m
[93maverage test of epoch 12: loss -23.45710 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 13: loss -24.15810 acc 0.66225 roc_auc 0.37039 prc_auc 0.56987[0m
[93maverage test of epoch 13: loss -25.13572 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 14: loss -25.82902 acc 0.66225 roc_auc 0.36931 prc_auc 0.57178[0m
[93maverage test of epoch 14: loss -26.81316 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 15: loss -27.49885 acc 0.66225 roc_auc 0.36951 prc_auc 0.56918[0m
[93maverage test of epoch 15: loss -28.48962 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 16: loss -29.16780 acc 0.66225 roc_auc 0.36843 prc_auc 0.56973[0m
[93maverage test of epoch 16: loss -30.16527 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 17: loss -30.83601 acc 0.66225 roc_auc 0.36608 prc_auc 0.56769[0m
[93maverage test of epoch 17: loss -31.84023 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 18: loss -32.50358 acc 0.66225 roc_auc 0.36647 prc_auc 0.56974[0m
[93maverage test of epoch 18: loss -33.51461 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 19: loss -34.17062 acc 0.66225 roc_auc 0.37225 prc_auc 0.58566[0m
[93maverage test of epoch 19: loss -35.18851 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 20: loss -35.83721 acc 0.66225 roc_auc 0.36627 prc_auc 0.57790[0m
[93maverage test of epoch 20: loss -36.86199 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 21: loss -37.50341 acc 0.66225 roc_auc 0.38961 prc_auc 0.59747[0m
[93maverage test of epoch 21: loss -38.53511 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 22: loss -39.16929 acc 0.66225 roc_auc 0.38127 prc_auc 0.59914[0m
[93maverage test of epoch 22: loss -40.20792 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 23: loss -40.83487 acc 0.66225 roc_auc 0.43422 prc_auc 0.63221[0m
[93maverage test of epoch 23: loss -41.88045 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 24: loss -42.50021 acc 0.66225 roc_auc 0.41814 prc_auc 0.62455[0m
[93maverage test of epoch 24: loss -43.55277 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 25: loss -44.16534 acc 0.66225 roc_auc 0.43608 prc_auc 0.63602[0m
[93maverage test of epoch 25: loss -45.22490 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 26: loss -45.83028 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 26: loss -46.89684 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 27: loss -47.49506 acc 0.66225 roc_auc 0.41108 prc_auc 0.62735[0m
[93maverage test of epoch 27: loss -48.56863 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 28: loss -49.15970 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 28: loss -50.24029 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 29: loss -50.82421 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 29: loss -51.91183 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 30: loss -52.48860 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 30: loss -53.58326 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 31: loss -54.15291 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 31: loss -55.25460 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 32: loss -55.81711 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 32: loss -56.92587 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 33: loss -57.48125 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 33: loss -58.59705 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 34: loss -59.14532 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 34: loss -60.26817 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 35: loss -60.80932 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 35: loss -61.93924 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 36: loss -62.47327 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 36: loss -63.61024 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 37: loss -64.13717 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 37: loss -65.28120 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 38: loss -65.80102 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 38: loss -66.95212 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 39: loss -67.46482 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 39: loss -68.62299 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -69.12858 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 40: loss -70.29381 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -70.79229 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 41: loss -71.96459 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -72.45596 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 42: loss -73.63534 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -74.11960 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 43: loss -75.30605 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -75.78320 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 44: loss -76.97672 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -77.44677 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 45: loss -78.64736 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -79.11031 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 46: loss -80.31797 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -80.77382 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 47: loss -81.98854 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -82.43728 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 48: loss -83.65908 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -84.10072 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 49: loss -85.32960 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 50: loss -85.76413 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 50: loss -87.00009 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 51: loss -87.42752 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 51: loss -88.67056 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 52: loss -89.09087 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 52: loss -90.34099 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 53: loss -90.75421 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 53: loss -92.01140 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 54: loss -92.41752 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 54: loss -93.68180 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 55: loss -94.08082 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 55: loss -95.35218 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 56: loss -95.74410 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 56: loss -97.02253 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 57: loss -97.40736 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 57: loss -98.69287 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 58: loss -99.07060 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 58: loss -100.36319 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 59: loss -100.73381 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 59: loss -102.03350 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 60: loss -102.39702 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 60: loss -103.70378 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 61: loss -104.06019 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 61: loss -105.37403 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 62: loss -105.72333 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 62: loss -107.04426 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 63: loss -107.38647 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 63: loss -108.71447 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 64: loss -109.04957 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 64: loss -110.38466 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 65: loss -110.71266 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 65: loss -112.05484 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 66: loss -112.37573 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 66: loss -113.72499 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 67: loss -114.03877 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 67: loss -115.39511 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 68: loss -115.70179 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 68: loss -117.06521 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 69: loss -117.36477 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 69: loss -118.73527 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 70: loss -119.02773 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 70: loss -120.40530 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 71: loss -120.69066 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 71: loss -122.07533 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 72: loss -122.35357 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 72: loss -123.74532 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 73: loss -124.01644 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 73: loss -125.41526 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 74: loss -125.67927 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 74: loss -127.08517 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 75: loss -127.34206 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 75: loss -128.75505 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 76: loss -129.00483 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 76: loss -130.42490 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 77: loss -130.66757 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 77: loss -132.09472 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 78: loss -132.33029 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 78: loss -133.76452 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 79: loss -133.99298 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 79: loss -135.43430 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 80: loss -135.65565 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 80: loss -137.10404 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 81: loss -137.31829 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 81: loss -138.77377 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 82: loss -138.98091 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 82: loss -140.44348 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 83: loss -140.64351 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 83: loss -142.11319 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 84: loss -142.30610 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 84: loss -143.78285 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 85: loss -143.96867 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 85: loss -145.45249 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 86: loss -145.63122 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 86: loss -147.12216 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 87: loss -147.29376 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 87: loss -148.79176 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 88: loss -148.95628 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 88: loss -150.46138 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 89: loss -150.61878 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 89: loss -152.13096 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 90: loss -152.28126 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 90: loss -153.80052 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 91: loss -153.94371 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 91: loss -155.47005 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 92: loss -155.60613 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 92: loss -157.13956 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 93: loss -157.26853 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 93: loss -158.80906 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 94: loss -158.93092 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 94: loss -160.47853 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 95: loss -160.59327 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 95: loss -162.14797 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 96: loss -162.25560 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 96: loss -163.81740 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 97: loss -163.91790 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 97: loss -165.48677 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 98: loss -165.58017 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 98: loss -167.15613 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 99: loss -167.24241 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 99: loss -168.82546 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.69203 ROC_AUC (avg): 0.55933 PRC_AUC (avg): 0.69762 

Average forward propagation time taken(ms): 2.468701157897432
Average backward propagation time taken(ms): 0.868711416957691

