# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-19-49-57/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-19-49-57/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 8,
 'epochs': 50,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 4,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.003,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 2,
 'num_workers': 8,
 'number_of_mlp_layer': 0,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-17-19-49-57',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 50, 'learning_rate': 0.003, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.003
[92maverage training of epoch 0: loss -2.93873 acc 0.56667 roc_auc 0.41680 prc_auc 0.62563[0m
[93maverage test of epoch 0: loss -5.35594 acc 0.65789 roc_auc 0.50462 prc_auc 0.63790[0m
[92maverage training of epoch 1: loss -6.57507 acc 0.66667 roc_auc 0.35980 prc_auc 0.56819[0m
[93maverage test of epoch 1: loss -7.60888 acc 0.65789 roc_auc 0.55538 prc_auc 0.68261[0m
[92maverage training of epoch 2: loss -8.58046 acc 0.66667 roc_auc 0.35760 prc_auc 0.56264[0m
[93maverage test of epoch 2: loss -9.48385 acc 0.65789 roc_auc 0.62615 prc_auc 0.80189[0m
[92maverage training of epoch 3: loss -10.39616 acc 0.66667 roc_auc 0.35180 prc_auc 0.55892[0m
[93maverage test of epoch 3: loss -11.25694 acc 0.65789 roc_auc 0.36615 prc_auc 0.59602[0m
[92maverage training of epoch 4: loss -12.15591 acc 0.66667 roc_auc 0.34780 prc_auc 0.55971[0m
[93maverage test of epoch 4: loss -12.99256 acc 0.65789 roc_auc 0.46308 prc_auc 0.63670[0m
[92maverage training of epoch 5: loss -13.88770 acc 0.66667 roc_auc 0.35580 prc_auc 0.56201[0m
[93maverage test of epoch 5: loss -14.70835 acc 0.65789 roc_auc 0.66000 prc_auc 0.74318[0m
[92maverage training of epoch 6: loss -15.59876 acc 0.66667 roc_auc 0.35710 prc_auc 0.56220[0m
[93maverage test of epoch 6: loss -16.41139 acc 0.65789 roc_auc 0.50154 prc_auc 0.64902[0m
[92maverage training of epoch 7: loss -17.29793 acc 0.66667 roc_auc 0.35310 prc_auc 0.55998[0m
[93maverage test of epoch 7: loss -18.09870 acc 0.65789 roc_auc 0.66615 prc_auc 0.76705[0m
[92maverage training of epoch 8: loss -18.98819 acc 0.66667 roc_auc 0.36160 prc_auc 0.56374[0m
[93maverage test of epoch 8: loss -19.78179 acc 0.65789 roc_auc 0.55231 prc_auc 0.74037[0m
[92maverage training of epoch 9: loss -20.67231 acc 0.66667 roc_auc 0.36560 prc_auc 0.56758[0m
[93maverage test of epoch 9: loss -21.45783 acc 0.65789 roc_auc 0.38923 prc_auc 0.59367[0m
[92maverage training of epoch 10: loss -22.35144 acc 0.66667 roc_auc 0.35970 prc_auc 0.56605[0m
[93maverage test of epoch 10: loss -23.12796 acc 0.65789 roc_auc 0.39077 prc_auc 0.60529[0m
[92maverage training of epoch 11: loss -24.02585 acc 0.66667 roc_auc 0.35780 prc_auc 0.56212[0m
[93maverage test of epoch 11: loss -24.79701 acc 0.65789 roc_auc 0.34769 prc_auc 0.59040[0m
[92maverage training of epoch 12: loss -25.69878 acc 0.66667 roc_auc 0.35720 prc_auc 0.56293[0m
[93maverage test of epoch 12: loss -26.46490 acc 0.65789 roc_auc 0.52923 prc_auc 0.67714[0m
[92maverage training of epoch 13: loss -27.36790 acc 0.66667 roc_auc 0.35800 prc_auc 0.56493[0m
[93maverage test of epoch 13: loss -28.12737 acc 0.65789 roc_auc 0.54154 prc_auc 0.68006[0m
[92maverage training of epoch 14: loss -29.03597 acc 0.66667 roc_auc 0.36320 prc_auc 0.57060[0m
[93maverage test of epoch 14: loss -29.78831 acc 0.65789 roc_auc 0.47077 prc_auc 0.64543[0m
[92maverage training of epoch 15: loss -30.70087 acc 0.66667 roc_auc 0.36360 prc_auc 0.57120[0m
[93maverage test of epoch 15: loss -31.44784 acc 0.65789 roc_auc 0.50308 prc_auc 0.65936[0m
[92maverage training of epoch 16: loss -32.36544 acc 0.66667 roc_auc 0.35860 prc_auc 0.57039[0m
[93maverage test of epoch 16: loss -33.10898 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 17: loss -34.02817 acc 0.66667 roc_auc 0.35860 prc_auc 0.57682[0m
[93maverage test of epoch 17: loss -34.76601 acc 0.65789 roc_auc 0.48000 prc_auc 0.64902[0m
[92maverage training of epoch 18: loss -35.69104 acc 0.66667 roc_auc 0.36280 prc_auc 0.58294[0m
[93maverage test of epoch 18: loss -36.42418 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -37.35227 acc 0.66667 roc_auc 0.38130 prc_auc 0.60270[0m
[93maverage test of epoch 19: loss -38.08002 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -39.01253 acc 0.66667 roc_auc 0.38780 prc_auc 0.60986[0m
[93maverage test of epoch 20: loss -39.73397 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -40.67363 acc 0.66667 roc_auc 0.41980 prc_auc 0.62798[0m
[93maverage test of epoch 21: loss -41.39119 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -42.33300 acc 0.66667 roc_auc 0.37370 prc_auc 0.61404[0m
[93maverage test of epoch 22: loss -43.04515 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -43.99198 acc 0.66667 roc_auc 0.39500 prc_auc 0.62742[0m
[93maverage test of epoch 23: loss -44.69925 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -45.65086 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 24: loss -46.35251 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -47.30901 acc 0.66667 roc_auc 0.40000 prc_auc 0.63077[0m
[93maverage test of epoch 25: loss -48.00666 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -48.96713 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 26: loss -49.65907 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -50.62535 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 27: loss -51.31289 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -52.28262 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 28: loss -52.96559 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -53.94007 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 29: loss -54.61790 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -55.59729 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 30: loss -56.27074 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -57.25437 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 31: loss -57.92288 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -58.91164 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 32: loss -59.57477 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -60.56835 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 33: loss -61.22709 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -62.22483 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -62.87918 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -63.88151 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -64.53117 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -65.53844 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -66.18294 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -67.19480 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -67.83472 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -68.85133 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -69.48597 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -70.50785 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -71.13699 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -72.16408 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -72.78884 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -73.82013 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -74.43986 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -75.47664 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -76.09241 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -77.13268 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -77.74382 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -78.78886 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -79.39507 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -80.44485 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -81.04615 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -82.10094 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -82.69791 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -83.75692 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -84.34908 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -85.41289 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -86.00044 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -87.06891 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -87.65139 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.003
[92maverage training of epoch 0: loss -2.48162 acc 0.33333 roc_auc 0.38100 prc_auc 0.58979[0m
[93maverage test of epoch 0: loss -4.09960 acc 0.34211 roc_auc 0.67077 prc_auc 0.82972[0m
[92maverage training of epoch 1: loss -5.05294 acc 0.33333 roc_auc 0.42040 prc_auc 0.60072[0m
[93maverage test of epoch 1: loss -6.00601 acc 0.34211 roc_auc 0.48308 prc_auc 0.68683[0m
[92maverage training of epoch 2: loss -6.87731 acc 0.44000 roc_auc 0.42380 prc_auc 0.61064[0m
[93maverage test of epoch 2: loss -7.77220 acc 0.65789 roc_auc 0.59231 prc_auc 0.74198[0m
[92maverage training of epoch 3: loss -8.63395 acc 0.66667 roc_auc 0.42140 prc_auc 0.60693[0m
[93maverage test of epoch 3: loss -9.50011 acc 0.65789 roc_auc 0.39385 prc_auc 0.63920[0m
[92maverage training of epoch 4: loss -10.34750 acc 0.66667 roc_auc 0.41740 prc_auc 0.59902[0m
[93maverage test of epoch 4: loss -11.20713 acc 0.65789 roc_auc 0.69077 prc_auc 0.80844[0m
[92maverage training of epoch 5: loss -12.05257 acc 0.66667 roc_auc 0.41860 prc_auc 0.60324[0m
[93maverage test of epoch 5: loss -12.89506 acc 0.65789 roc_auc 0.46154 prc_auc 0.67592[0m
[92maverage training of epoch 6: loss -13.74203 acc 0.66667 roc_auc 0.41920 prc_auc 0.60392[0m
[93maverage test of epoch 6: loss -14.57913 acc 0.65789 roc_auc 0.72308 prc_auc 0.87868[0m
[92maverage training of epoch 7: loss -15.42662 acc 0.66667 roc_auc 0.42380 prc_auc 0.60844[0m
[93maverage test of epoch 7: loss -16.25409 acc 0.65789 roc_auc 0.57231 prc_auc 0.70108[0m
[92maverage training of epoch 8: loss -17.10440 acc 0.66667 roc_auc 0.41840 prc_auc 0.60363[0m
[93maverage test of epoch 8: loss -17.92253 acc 0.65789 roc_auc 0.57846 prc_auc 0.76491[0m
[92maverage training of epoch 9: loss -18.77895 acc 0.66667 roc_auc 0.41900 prc_auc 0.60573[0m
[93maverage test of epoch 9: loss -19.59311 acc 0.65789 roc_auc 0.42154 prc_auc 0.64103[0m
[92maverage training of epoch 10: loss -20.45030 acc 0.66667 roc_auc 0.42040 prc_auc 0.60111[0m
[93maverage test of epoch 10: loss -21.25785 acc 0.65789 roc_auc 0.62769 prc_auc 0.77772[0m
[92maverage training of epoch 11: loss -22.11897 acc 0.66667 roc_auc 0.42080 prc_auc 0.60725[0m
[93maverage test of epoch 11: loss -22.92038 acc 0.65789 roc_auc 0.37846 prc_auc 0.58782[0m
[92maverage training of epoch 12: loss -23.78527 acc 0.66667 roc_auc 0.42200 prc_auc 0.60679[0m
[93maverage test of epoch 12: loss -24.58178 acc 0.65789 roc_auc 0.68000 prc_auc 0.78740[0m
[92maverage training of epoch 13: loss -25.45107 acc 0.66667 roc_auc 0.42140 prc_auc 0.60531[0m
[93maverage test of epoch 13: loss -26.24107 acc 0.65789 roc_auc 0.47231 prc_auc 0.64150[0m
[92maverage training of epoch 14: loss -27.11440 acc 0.66667 roc_auc 0.42030 prc_auc 0.60364[0m
[93maverage test of epoch 14: loss -27.89945 acc 0.65789 roc_auc 0.54923 prc_auc 0.69448[0m
[92maverage training of epoch 15: loss -28.77788 acc 0.66667 roc_auc 0.42080 prc_auc 0.60326[0m
[93maverage test of epoch 15: loss -29.55506 acc 0.65789 roc_auc 0.53231 prc_auc 0.68690[0m
[92maverage training of epoch 16: loss -30.43951 acc 0.66667 roc_auc 0.42060 prc_auc 0.60484[0m
[93maverage test of epoch 16: loss -31.21393 acc 0.65789 roc_auc 0.58462 prc_auc 0.70092[0m
[92maverage training of epoch 17: loss -32.10039 acc 0.66667 roc_auc 0.41930 prc_auc 0.60387[0m
[93maverage test of epoch 17: loss -32.87015 acc 0.65789 roc_auc 0.50462 prc_auc 0.66009[0m
[92maverage training of epoch 18: loss -33.76117 acc 0.66667 roc_auc 0.42160 prc_auc 0.60659[0m
[93maverage test of epoch 18: loss -34.52462 acc 0.65789 roc_auc 0.51385 prc_auc 0.66487[0m
[92maverage training of epoch 19: loss -35.42061 acc 0.66667 roc_auc 0.42140 prc_auc 0.60618[0m
[93maverage test of epoch 19: loss -36.17975 acc 0.65789 roc_auc 0.49692 prc_auc 0.65651[0m
[92maverage training of epoch 20: loss -37.07992 acc 0.66667 roc_auc 0.42050 prc_auc 0.60413[0m
[93maverage test of epoch 20: loss -37.83434 acc 0.65789 roc_auc 0.45692 prc_auc 0.63870[0m
[92maverage training of epoch 21: loss -38.73830 acc 0.66667 roc_auc 0.41960 prc_auc 0.60601[0m
[93maverage test of epoch 21: loss -39.48799 acc 0.65789 roc_auc 0.53846 prc_auc 0.67568[0m
[92maverage training of epoch 22: loss -40.39796 acc 0.66667 roc_auc 0.41910 prc_auc 0.60234[0m
[93maverage test of epoch 22: loss -41.14190 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -42.05597 acc 0.66667 roc_auc 0.41890 prc_auc 0.59869[0m
[93maverage test of epoch 23: loss -42.79553 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -43.71421 acc 0.66667 roc_auc 0.41950 prc_auc 0.60292[0m
[93maverage test of epoch 24: loss -44.44876 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -45.37196 acc 0.66667 roc_auc 0.42010 prc_auc 0.60667[0m
[93maverage test of epoch 25: loss -46.10166 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -47.02979 acc 0.66667 roc_auc 0.43120 prc_auc 0.61677[0m
[93maverage test of epoch 26: loss -47.75459 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -48.68723 acc 0.66667 roc_auc 0.44140 prc_auc 0.62680[0m
[93maverage test of epoch 27: loss -49.40737 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -50.34458 acc 0.66667 roc_auc 0.42810 prc_auc 0.62837[0m
[93maverage test of epoch 28: loss -51.05966 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -52.00173 acc 0.66667 roc_auc 0.45370 prc_auc 0.64149[0m
[93maverage test of epoch 29: loss -52.71166 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -53.65864 acc 0.66667 roc_auc 0.46000 prc_auc 0.64962[0m
[93maverage test of epoch 30: loss -54.36406 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -55.31583 acc 0.66667 roc_auc 0.47000 prc_auc 0.65374[0m
[93maverage test of epoch 31: loss -56.01603 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -56.97260 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 32: loss -57.66863 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -58.62949 acc 0.66667 roc_auc 0.46000 prc_auc 0.64962[0m
[93maverage test of epoch 33: loss -59.32084 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -60.28620 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -60.97264 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -61.94289 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -62.62453 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -63.59959 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -64.27646 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -65.25593 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -65.92808 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -66.91248 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -67.57987 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -68.56869 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -69.23174 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -70.22534 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -70.88328 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -71.88174 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -72.53453 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -73.53784 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -74.18629 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -75.19424 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -75.83808 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -76.85048 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -77.48956 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -78.50666 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -79.14078 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -80.16288 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -80.79223 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -81.81896 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -82.44381 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -83.47519 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -84.09513 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -85.13123 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -85.74640 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.003
[92maverage training of epoch 0: loss -1.91027 acc 0.66667 roc_auc 0.39640 prc_auc 0.60510[0m
[93maverage test of epoch 0: loss -3.29185 acc 0.65789 roc_auc 0.54769 prc_auc 0.68701[0m
[92maverage training of epoch 1: loss -4.30679 acc 0.66667 roc_auc 0.39540 prc_auc 0.59402[0m
[93maverage test of epoch 1: loss -5.24859 acc 0.65789 roc_auc 0.63846 prc_auc 0.76882[0m
[92maverage training of epoch 2: loss -6.15882 acc 0.66667 roc_auc 0.36940 prc_auc 0.57285[0m
[93maverage test of epoch 2: loss -7.03052 acc 0.65789 roc_auc 0.57231 prc_auc 0.77138[0m
[92maverage training of epoch 3: loss -7.91902 acc 0.66667 roc_auc 0.37680 prc_auc 0.58104[0m
[93maverage test of epoch 3: loss -8.76242 acc 0.65789 roc_auc 0.61846 prc_auc 0.75521[0m
[92maverage training of epoch 4: loss -9.64319 acc 0.66667 roc_auc 0.37920 prc_auc 0.58502[0m
[93maverage test of epoch 4: loss -10.46864 acc 0.65789 roc_auc 0.50308 prc_auc 0.63697[0m
[92maverage training of epoch 5: loss -11.35052 acc 0.66667 roc_auc 0.38220 prc_auc 0.58806[0m
[93maverage test of epoch 5: loss -12.16509 acc 0.65789 roc_auc 0.57231 prc_auc 0.68901[0m
[92maverage training of epoch 6: loss -13.04432 acc 0.66667 roc_auc 0.37930 prc_auc 0.57697[0m
[93maverage test of epoch 6: loss -13.85056 acc 0.65789 roc_auc 0.52154 prc_auc 0.65604[0m
[92maverage training of epoch 7: loss -14.73052 acc 0.66667 roc_auc 0.37890 prc_auc 0.57250[0m
[93maverage test of epoch 7: loss -15.52667 acc 0.65789 roc_auc 0.54923 prc_auc 0.69496[0m
[92maverage training of epoch 8: loss -16.41131 acc 0.66667 roc_auc 0.38260 prc_auc 0.57839[0m
[93maverage test of epoch 8: loss -17.19949 acc 0.65789 roc_auc 0.38923 prc_auc 0.60214[0m
[92maverage training of epoch 9: loss -18.08662 acc 0.66667 roc_auc 0.37810 prc_auc 0.57495[0m
[93maverage test of epoch 9: loss -18.86735 acc 0.65789 roc_auc 0.62615 prc_auc 0.75220[0m
[92maverage training of epoch 10: loss -19.75790 acc 0.66667 roc_auc 0.37700 prc_auc 0.57660[0m
[93maverage test of epoch 10: loss -20.53527 acc 0.65789 roc_auc 0.60923 prc_auc 0.71230[0m
[92maverage training of epoch 11: loss -21.42851 acc 0.66667 roc_auc 0.37590 prc_auc 0.57504[0m
[93maverage test of epoch 11: loss -22.19813 acc 0.65789 roc_auc 0.52769 prc_auc 0.68585[0m
[92maverage training of epoch 12: loss -23.09611 acc 0.66667 roc_auc 0.37860 prc_auc 0.58183[0m
[93maverage test of epoch 12: loss -23.85923 acc 0.65789 roc_auc 0.32769 prc_auc 0.58160[0m
[92maverage training of epoch 13: loss -24.76116 acc 0.66667 roc_auc 0.37670 prc_auc 0.57469[0m
[93maverage test of epoch 13: loss -25.52051 acc 0.65789 roc_auc 0.60769 prc_auc 0.71185[0m
[92maverage training of epoch 14: loss -26.42509 acc 0.66667 roc_auc 0.37850 prc_auc 0.57837[0m
[93maverage test of epoch 14: loss -27.18024 acc 0.65789 roc_auc 0.39692 prc_auc 0.61610[0m
[92maverage training of epoch 15: loss -28.08849 acc 0.66667 roc_auc 0.37840 prc_auc 0.57706[0m
[93maverage test of epoch 15: loss -28.83685 acc 0.65789 roc_auc 0.49846 prc_auc 0.65720[0m
[92maverage training of epoch 16: loss -29.75088 acc 0.66667 roc_auc 0.38160 prc_auc 0.58597[0m
[93maverage test of epoch 16: loss -30.49392 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 17: loss -31.41173 acc 0.66667 roc_auc 0.38270 prc_auc 0.58757[0m
[93maverage test of epoch 17: loss -32.15013 acc 0.65789 roc_auc 0.68308 prc_auc 0.76646[0m
[92maverage training of epoch 18: loss -33.07216 acc 0.66667 roc_auc 0.38520 prc_auc 0.58914[0m
[93maverage test of epoch 18: loss -33.80649 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -34.73256 acc 0.66667 roc_auc 0.39340 prc_auc 0.60099[0m
[93maverage test of epoch 19: loss -35.46131 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -36.39182 acc 0.66667 roc_auc 0.37800 prc_auc 0.59991[0m
[93maverage test of epoch 20: loss -37.11492 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -38.05086 acc 0.66667 roc_auc 0.41420 prc_auc 0.62710[0m
[93maverage test of epoch 21: loss -38.76898 acc 0.65789 roc_auc 0.46000 prc_auc 0.64041[0m
[92maverage training of epoch 22: loss -39.70990 acc 0.66667 roc_auc 0.40500 prc_auc 0.61985[0m
[93maverage test of epoch 22: loss -40.42239 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -41.36773 acc 0.66667 roc_auc 0.44000 prc_auc 0.64157[0m
[93maverage test of epoch 23: loss -42.07598 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -43.02605 acc 0.66667 roc_auc 0.45500 prc_auc 0.64752[0m
[93maverage test of epoch 24: loss -43.72940 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -44.68374 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 25: loss -45.38289 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -46.34128 acc 0.66667 roc_auc 0.44500 prc_auc 0.64353[0m
[93maverage test of epoch 26: loss -47.03579 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -47.99860 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 27: loss -48.68847 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -49.65614 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 28: loss -50.34089 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -51.31308 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 29: loss -51.99309 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -52.97032 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 30: loss -53.64499 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -54.62713 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 31: loss -55.29765 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -56.28359 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 32: loss -56.94930 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -57.94055 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 33: loss -58.60126 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -59.59712 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -60.25268 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -61.25343 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -61.90465 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -62.91004 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -63.55617 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -64.56655 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -65.20794 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -66.22282 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -66.85975 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -67.87923 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -68.51145 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -69.53545 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -70.16274 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -71.19168 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -71.81406 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -72.84791 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -73.46578 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -74.50411 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -75.11691 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -76.16021 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -76.76865 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -77.81622 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -78.41971 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -79.47227 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -80.07121 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -81.12816 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -81.72245 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -82.78426 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -83.37364 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -84.44029 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -85.02490 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.003
[92maverage training of epoch 0: loss -0.51652 acc 0.64901 roc_auc 0.42137 prc_auc 0.61927[0m
[93maverage test of epoch 0: loss -2.15214 acc 0.67568 roc_auc 0.58667 prc_auc 0.72880[0m
[92maverage training of epoch 1: loss -3.38058 acc 0.66225 roc_auc 0.45451 prc_auc 0.65834[0m
[93maverage test of epoch 1: loss -5.04002 acc 0.67568 roc_auc 0.62833 prc_auc 0.76707[0m
[92maverage training of epoch 2: loss -6.06778 acc 0.66225 roc_auc 0.40971 prc_auc 0.60726[0m
[93maverage test of epoch 2: loss -7.22960 acc 0.67568 roc_auc 0.49833 prc_auc 0.70642[0m
[92maverage training of epoch 3: loss -8.07699 acc 0.66225 roc_auc 0.37353 prc_auc 0.57117[0m
[93maverage test of epoch 3: loss -9.14721 acc 0.67568 roc_auc 0.47167 prc_auc 0.68568[0m
[92maverage training of epoch 4: loss -9.94453 acc 0.66225 roc_auc 0.38196 prc_auc 0.57736[0m
[93maverage test of epoch 4: loss -10.98049 acc 0.67568 roc_auc 0.57833 prc_auc 0.75844[0m
[92maverage training of epoch 5: loss -11.73931 acc 0.66225 roc_auc 0.37716 prc_auc 0.57201[0m
[93maverage test of epoch 5: loss -12.76689 acc 0.67568 roc_auc 0.56667 prc_auc 0.72009[0m
[92maverage training of epoch 6: loss -13.50137 acc 0.66225 roc_auc 0.37696 prc_auc 0.57092[0m
[93maverage test of epoch 6: loss -14.52107 acc 0.67568 roc_auc 0.50833 prc_auc 0.67658[0m
[92maverage training of epoch 7: loss -15.24086 acc 0.66225 roc_auc 0.37108 prc_auc 0.56929[0m
[93maverage test of epoch 7: loss -16.26191 acc 0.67568 roc_auc 0.68833 prc_auc 0.78570[0m
[92maverage training of epoch 8: loss -16.96595 acc 0.66225 roc_auc 0.37804 prc_auc 0.57184[0m
[93maverage test of epoch 8: loss -17.98450 acc 0.67568 roc_auc 0.60667 prc_auc 0.73132[0m
[92maverage training of epoch 9: loss -18.67638 acc 0.66225 roc_auc 0.38539 prc_auc 0.58755[0m
[93maverage test of epoch 9: loss -19.69763 acc 0.67568 roc_auc 0.54667 prc_auc 0.69677[0m
[92maverage training of epoch 10: loss -20.37894 acc 0.66225 roc_auc 0.37127 prc_auc 0.57130[0m
[93maverage test of epoch 10: loss -21.40409 acc 0.67568 roc_auc 0.48000 prc_auc 0.66703[0m
[92maverage training of epoch 11: loss -22.07581 acc 0.66225 roc_auc 0.37745 prc_auc 0.57989[0m
[93maverage test of epoch 11: loss -23.10448 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 12: loss -23.76667 acc 0.66225 roc_auc 0.38431 prc_auc 0.58829[0m
[93maverage test of epoch 12: loss -24.80017 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 13: loss -25.45142 acc 0.66225 roc_auc 0.37941 prc_auc 0.58914[0m
[93maverage test of epoch 13: loss -26.49086 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 14: loss -27.13413 acc 0.66225 roc_auc 0.38196 prc_auc 0.59936[0m
[93maverage test of epoch 14: loss -28.17899 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 15: loss -28.81367 acc 0.66225 roc_auc 0.44000 prc_auc 0.62994[0m
[93maverage test of epoch 15: loss -29.86463 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 16: loss -30.49099 acc 0.66225 roc_auc 0.43461 prc_auc 0.63035[0m
[93maverage test of epoch 16: loss -31.54776 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 17: loss -32.16669 acc 0.66225 roc_auc 0.47284 prc_auc 0.65040[0m
[93maverage test of epoch 17: loss -33.22861 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 18: loss -33.84012 acc 0.66225 roc_auc 0.48784 prc_auc 0.65687[0m
[93maverage test of epoch 18: loss -34.90847 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 19: loss -35.51195 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 19: loss -36.58704 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 20: loss -37.18278 acc 0.66225 roc_auc 0.46784 prc_auc 0.64829[0m
[93maverage test of epoch 20: loss -38.26436 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 21: loss -38.85292 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 21: loss -39.94099 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 22: loss -40.52179 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 22: loss -41.61694 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 23: loss -42.18984 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 23: loss -43.29135 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 24: loss -43.85744 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 24: loss -44.96539 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 25: loss -45.52437 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 25: loss -46.63901 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 26: loss -47.19089 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 26: loss -48.31388 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 27: loss -48.85723 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 27: loss -49.98539 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 28: loss -50.52330 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 28: loss -51.65850 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 29: loss -52.18833 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 29: loss -53.33148 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 30: loss -53.85374 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 30: loss -55.00386 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 31: loss -55.51894 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 31: loss -56.67583 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 32: loss -57.18369 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 32: loss -58.34725 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 33: loss -58.84823 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 33: loss -60.01947 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 34: loss -60.51282 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 34: loss -61.69081 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 35: loss -62.17703 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 35: loss -63.36210 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 36: loss -63.84147 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 36: loss -65.03283 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 37: loss -65.50539 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 37: loss -66.70454 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 38: loss -67.16932 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 38: loss -68.37565 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 39: loss -68.83346 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 39: loss -70.04673 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -70.49742 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 40: loss -71.71767 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -72.16113 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 41: loss -73.38853 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -73.82492 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 42: loss -75.05925 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -75.48871 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 43: loss -76.72987 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -77.15226 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 44: loss -78.40089 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -78.81582 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 45: loss -80.07145 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -80.47936 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 46: loss -81.74221 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -82.14288 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 47: loss -83.41270 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -83.80646 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 48: loss -85.08324 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -85.46990 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 49: loss -86.75377 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.003
[92maverage training of epoch 0: loss -2.06802 acc 0.58278 roc_auc 0.39510 prc_auc 0.59703[0m
[93maverage test of epoch 0: loss -3.54536 acc 0.67568 roc_auc 0.60000 prc_auc 0.76644[0m
[92maverage training of epoch 1: loss -4.46845 acc 0.66225 roc_auc 0.35118 prc_auc 0.55622[0m
[93maverage test of epoch 1: loss -5.46922 acc 0.67568 roc_auc 0.45000 prc_auc 0.71003[0m
[92maverage training of epoch 2: loss -6.29154 acc 0.66225 roc_auc 0.37353 prc_auc 0.56861[0m
[93maverage test of epoch 2: loss -7.23312 acc 0.67568 roc_auc 0.66000 prc_auc 0.82115[0m
[92maverage training of epoch 3: loss -8.03843 acc 0.66225 roc_auc 0.36235 prc_auc 0.56457[0m
[93maverage test of epoch 3: loss -8.97503 acc 0.67568 roc_auc 0.32000 prc_auc 0.61984[0m
[92maverage training of epoch 4: loss -9.75701 acc 0.66225 roc_auc 0.36882 prc_auc 0.56913[0m
[93maverage test of epoch 4: loss -10.68956 acc 0.67568 roc_auc 0.34667 prc_auc 0.63441[0mUsing backend: pytorch

[92maverage training of epoch 5: loss -11.45987 acc 0.66225 roc_auc 0.36647 prc_auc 0.56656[0m
[93maverage test of epoch 5: loss -12.39823 acc 0.67568 roc_auc 0.71167 prc_auc 0.82690[0m
[92maverage training of epoch 6: loss -13.15447 acc 0.66225 roc_auc 0.36922 prc_auc 0.57343[0m
[93maverage test of epoch 6: loss -14.09347 acc 0.67568 roc_auc 0.37833 prc_auc 0.61513[0m
[92maverage training of epoch 7: loss -14.84286 acc 0.66225 roc_auc 0.36324 prc_auc 0.56418[0m
[93maverage test of epoch 7: loss -15.78506 acc 0.67568 roc_auc 0.46167 prc_auc 0.64265[0m
[92maverage training of epoch 8: loss -16.52561 acc 0.66225 roc_auc 0.36990 prc_auc 0.56975[0m
[93maverage test of epoch 8: loss -17.47498 acc 0.67568 roc_auc 0.58500 prc_auc 0.72628[0m
[92maverage training of epoch 9: loss -18.20580 acc 0.66225 roc_auc 0.36833 prc_auc 0.56739[0m
[93maverage test of epoch 9: loss -19.16116 acc 0.67568 roc_auc 0.50833 prc_auc 0.67294[0m
[92maverage training of epoch 10: loss -19.88234 acc 0.66225 roc_auc 0.36892 prc_auc 0.56990[0m
[93maverage test of epoch 10: loss -20.84239 acc 0.67568 roc_auc 0.57167 prc_auc 0.72214[0m
[92maverage training of epoch 11: loss -21.55695 acc 0.66225 roc_auc 0.37010 prc_auc 0.57319[0m
[93maverage test of epoch 11: loss -22.52430 acc 0.67568 roc_auc 0.58333 prc_auc 0.71755[0m
[92maverage training of epoch 12: loss -23.23010 acc 0.66225 roc_auc 0.36922 prc_auc 0.57083[0m
[93maverage test of epoch 12: loss -24.20361 acc 0.67568 roc_auc 0.63333 prc_auc 0.74438[0m
[92maverage training of epoch 13: loss -24.90034 acc 0.66225 roc_auc 0.36853 prc_auc 0.57203[0m
[93maverage test of epoch 13: loss -25.88068 acc 0.67568 roc_auc 0.56333 prc_auc 0.71615[0m
[92maverage training of epoch 14: loss -26.57182 acc 0.66225 roc_auc 0.36951 prc_auc 0.57149[0m
[93maverage test of epoch 14: loss -27.55787 acc 0.67568 roc_auc 0.50500 prc_auc 0.67788[0m
[92maverage training of epoch 15: loss -28.24092 acc 0.66225 roc_auc 0.36863 prc_auc 0.56954[0m
[93maverage test of epoch 15: loss -29.23445 acc 0.67568 roc_auc 0.60500 prc_auc 0.72521[0m
[92maverage training of epoch 16: loss -29.90905 acc 0.66225 roc_auc 0.36873 prc_auc 0.57150[0m
[93maverage test of epoch 16: loss -30.90865 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 17: loss -31.57734 acc 0.66225 roc_auc 0.36824 prc_auc 0.57029[0m
[93maverage test of epoch 17: loss -32.58357 acc 0.67568 roc_auc 0.46000 prc_auc 0.65863[0m
[92maverage training of epoch 18: loss -33.24459 acc 0.66225 roc_auc 0.36431 prc_auc 0.56988[0m
[93maverage test of epoch 18: loss -34.25811 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 19: loss -34.91145 acc 0.66225 roc_auc 0.36990 prc_auc 0.57709[0m
[93maverage test of epoch 19: loss -35.93153 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 20: loss -36.57815 acc 0.66225 roc_auc 0.36608 prc_auc 0.58303[0m
[93maverage test of epoch 20: loss -37.60521 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 21: loss -38.24349 acc 0.66225 roc_auc 0.38127 prc_auc 0.59575[0m
[93maverage test of epoch 21: loss -39.27813 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 22: loss -39.90974 acc 0.66225 roc_auc 0.38392 prc_auc 0.60173[0m
[93maverage test of epoch 22: loss -40.95074 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 23: loss -41.57517 acc 0.66225 roc_auc 0.42451 prc_auc 0.62582[0m
[93maverage test of epoch 23: loss -42.62334 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 24: loss -43.24033 acc 0.66225 roc_auc 0.44284 prc_auc 0.63808[0m
[93maverage test of epoch 24: loss -44.29571 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 25: loss -44.90547 acc 0.66225 roc_auc 0.45284 prc_auc 0.64209[0m
[93maverage test of epoch 25: loss -45.96800 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 26: loss -46.57040 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 26: loss -47.63990 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 27: loss -48.23520 acc 0.66225 roc_auc 0.44765 prc_auc 0.64002[0m
[93maverage test of epoch 27: loss -49.31143 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 28: loss -49.89991 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 28: loss -50.98243 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 29: loss -51.56428 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 29: loss -52.65415 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 30: loss -53.22865 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 30: loss -54.32602 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 31: loss -54.89282 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 31: loss -55.99707 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 32: loss -56.55717 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 32: loss -57.66844 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 33: loss -58.22125 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 33: loss -59.33956 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 34: loss -59.88524 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 34: loss -61.01086 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 35: loss -61.54935 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 35: loss -62.68167 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 36: loss -63.21313 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 36: loss -64.35298 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 37: loss -64.87714 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 37: loss -66.02393 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 38: loss -66.54088 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 38: loss -67.69472 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 39: loss -68.20478 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 39: loss -69.36554 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -69.86856 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 40: loss -71.03650 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -71.53218 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 41: loss -72.70724 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -73.19592 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 42: loss -74.37800 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -74.85962 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 43: loss -76.04869 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -76.52318 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 44: loss -77.71908 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -78.18678 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 45: loss -79.38986 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -79.85025 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 46: loss -81.06057 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -81.51372 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 47: loss -82.73089 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -83.17729 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 48: loss -84.40148 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -84.84070 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 49: loss -86.07218 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.66501 ROC_AUC (avg): 0.5 PRC_AUC (avg): 0.66501 

Average forward propagation time taken(ms): 3.9827019112857327
Average backward propagation time taken(ms): 1.5184517494366236

