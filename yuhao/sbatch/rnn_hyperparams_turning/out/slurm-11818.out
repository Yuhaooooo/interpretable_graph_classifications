# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-16-48-36/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-16-48-36/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 8,
 'epochs': 50,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 4,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.003,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 1,
 'num_workers': 8,
 'number_of_mlp_layer': 0,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-17-16-48-36',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 50, 'learning_rate': 0.003, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.003
[92maverage training of epoch 0: loss -1.29755 acc 0.49333 roc_auc 0.44960 prc_auc 0.66189[0m
[93maverage test of epoch 0: loss -2.57313 acc 0.65789 roc_auc 0.85846 prc_auc 0.92975[0m
[92maverage training of epoch 1: loss -3.89097 acc 0.66667 roc_auc 0.38140 prc_auc 0.59260[0m
[93maverage test of epoch 1: loss -5.07686 acc 0.65789 roc_auc 0.86154 prc_auc 0.93134[0m
[92maverage training of epoch 2: loss -6.08653 acc 0.66667 roc_auc 0.36640 prc_auc 0.57020[0m
[93maverage test of epoch 2: loss -7.03830 acc 0.65789 roc_auc 0.85692 prc_auc 0.92034[0m
[92maverage training of epoch 3: loss -7.97448 acc 0.66667 roc_auc 0.36020 prc_auc 0.56447[0m
[93maverage test of epoch 3: loss -8.86367 acc 0.65789 roc_auc 0.83846 prc_auc 0.88953[0m
[92maverage training of epoch 4: loss -9.77311 acc 0.66667 roc_auc 0.35940 prc_auc 0.56353[0m
[93maverage test of epoch 4: loss -10.63111 acc 0.65789 roc_auc 0.85385 prc_auc 0.90932[0m
[92maverage training of epoch 5: loss -11.52831 acc 0.66667 roc_auc 0.35800 prc_auc 0.56260[0m
[93maverage test of epoch 5: loss -12.36643 acc 0.65789 roc_auc 0.83231 prc_auc 0.89898[0m
[92maverage training of epoch 6: loss -13.25782 acc 0.66667 roc_auc 0.35740 prc_auc 0.56208[0m
[93maverage test of epoch 6: loss -14.08144 acc 0.65789 roc_auc 0.61231 prc_auc 0.71354[0m
[92maverage training of epoch 7: loss -14.97045 acc 0.66667 roc_auc 0.35750 prc_auc 0.56213[0m
[93maverage test of epoch 7: loss -15.78258 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 8: loss -16.67124 acc 0.66667 roc_auc 0.35740 prc_auc 0.56193[0m
[93maverage test of epoch 8: loss -17.47373 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 9: loss -18.36334 acc 0.66667 roc_auc 0.35720 prc_auc 0.56197[0m
[93maverage test of epoch 9: loss -19.15740 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 10: loss -20.04885 acc 0.66667 roc_auc 0.35730 prc_auc 0.56168[0m
[93maverage test of epoch 10: loss -20.83531 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 11: loss -21.72924 acc 0.66667 roc_auc 0.35760 prc_auc 0.56252[0m
[93maverage test of epoch 11: loss -22.50871 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 12: loss -23.40557 acc 0.66667 roc_auc 0.35760 prc_auc 0.56253[0m
[93maverage test of epoch 12: loss -24.17851 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 13: loss -25.07865 acc 0.66667 roc_auc 0.35780 prc_auc 0.56347[0m
[93maverage test of epoch 13: loss -25.84539 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 14: loss -26.74907 acc 0.66667 roc_auc 0.35800 prc_auc 0.56292[0m
[93maverage test of epoch 14: loss -27.50987 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 15: loss -28.41731 acc 0.66667 roc_auc 0.35850 prc_auc 0.56557[0m
[93maverage test of epoch 15: loss -29.17239 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 16: loss -30.08374 acc 0.66667 roc_auc 0.36120 prc_auc 0.56802[0m
[93maverage test of epoch 16: loss -30.83327 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 17: loss -31.74867 acc 0.66667 roc_auc 0.35800 prc_auc 0.56954[0m
[93maverage test of epoch 17: loss -32.49277 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 18: loss -33.41233 acc 0.66667 roc_auc 0.36570 prc_auc 0.57767[0m
[93maverage test of epoch 18: loss -34.15112 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -35.07492 acc 0.66667 roc_auc 0.36780 prc_auc 0.58388[0m
[93maverage test of epoch 19: loss -35.80849 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -36.73662 acc 0.66667 roc_auc 0.36480 prc_auc 0.59262[0m
[93maverage test of epoch 20: loss -37.46504 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -38.39756 acc 0.66667 roc_auc 0.37720 prc_auc 0.60493[0m
[93maverage test of epoch 21: loss -39.12090 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -40.05784 acc 0.66667 roc_auc 0.43230 prc_auc 0.63385[0m
[93maverage test of epoch 22: loss -40.77615 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -41.71757 acc 0.66667 roc_auc 0.43220 prc_auc 0.63636[0m
[93maverage test of epoch 23: loss -42.43088 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -43.37681 acc 0.66667 roc_auc 0.46500 prc_auc 0.65153[0m
[93maverage test of epoch 24: loss -44.08517 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -45.03565 acc 0.66667 roc_auc 0.48500 prc_auc 0.66007[0m
[93maverage test of epoch 25: loss -45.73909 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -46.69412 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 26: loss -47.39266 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -48.35228 acc 0.66667 roc_auc 0.47000 prc_auc 0.65364[0m
[93maverage test of epoch 27: loss -49.04595 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -50.01019 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 28: loss -50.69901 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -51.66786 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 29: loss -52.35185 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -53.32534 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 30: loss -54.00449 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -54.98262 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 31: loss -55.65696 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -56.63976 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 32: loss -57.30930 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -58.29676 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 33: loss -58.96151 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -59.95365 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -60.61361 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -61.61044 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -62.26562 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -63.26712 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -63.91753 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -64.92372 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -65.56935 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -66.58024 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -67.22112 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -68.23670 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -68.87280 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -69.89308 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -70.52442 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -71.54941 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -72.17600 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -73.20568 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -73.82750 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -74.86188 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -75.47895 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -76.51805 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -77.13037 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -78.17417 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -78.78174 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -79.83025 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -80.43308 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -81.48631 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -82.08440 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -83.14235 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -83.73570 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -84.79836 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -85.38696 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.003
[92maverage training of epoch 0: loss -1.27472 acc 0.33333 roc_auc 0.50120 prc_auc 0.65743[0m
[93maverage test of epoch 0: loss -2.94384 acc 0.34211 roc_auc 0.11692 prc_auc 0.48489[0m
[92maverage training of epoch 1: loss -3.87827 acc 0.33333 roc_auc 0.41460 prc_auc 0.60337[0m
[93maverage test of epoch 1: loss -4.78139 acc 0.34211 roc_auc 0.23692 prc_auc 0.57327[0m
[92maverage training of epoch 2: loss -5.73958 acc 0.33333 roc_auc 0.44400 prc_auc 0.62902[0m
[93maverage test of epoch 2: loss -6.99189 acc 0.34211 roc_auc 0.88615 prc_auc 0.93117[0m
[92maverage training of epoch 3: loss -8.01941 acc 0.48667 roc_auc 0.42660 prc_auc 0.60911[0m
[93maverage test of epoch 3: loss -9.02591 acc 0.65789 roc_auc 0.86769 prc_auc 0.89875[0m
[92maverage training of epoch 4: loss -9.95369 acc 0.66667 roc_auc 0.42200 prc_auc 0.60574[0m
[93maverage test of epoch 4: loss -10.88245 acc 0.65789 roc_auc 0.84308 prc_auc 0.86841[0m
[92maverage training of epoch 5: loss -11.77830 acc 0.66667 roc_auc 0.42060 prc_auc 0.60484[0m
[93maverage test of epoch 5: loss -12.67119 acc 0.65789 roc_auc 0.78462 prc_auc 0.82556[0m
[92maverage training of epoch 6: loss -13.55224 acc 0.66667 roc_auc 0.42040 prc_auc 0.60478[0m
[93maverage test of epoch 6: loss -14.42261 acc 0.65789 roc_auc 0.84308 prc_auc 0.86222[0m
[92maverage training of epoch 7: loss -15.29620 acc 0.66667 roc_auc 0.42040 prc_auc 0.60516[0m
[93maverage test of epoch 7: loss -16.15032 acc 0.65789 roc_auc 0.84308 prc_auc 0.86222[0m
[92maverage training of epoch 8: loss -17.02034 acc 0.66667 roc_auc 0.42040 prc_auc 0.60478[0m
[93maverage test of epoch 8: loss -17.86168 acc 0.65789 roc_auc 0.82308 prc_auc 0.84667[0m
[92maverage training of epoch 9: loss -18.73045 acc 0.66667 roc_auc 0.42040 prc_auc 0.60478[0m
[93maverage test of epoch 9: loss -19.56117 acc 0.65789 roc_auc 0.82308 prc_auc 0.84667[0m
[92maverage training of epoch 10: loss -20.43020 acc 0.66667 roc_auc 0.42040 prc_auc 0.60478[0m
[93maverage test of epoch 10: loss -21.25173 acc 0.65789 roc_auc 0.64615 prc_auc 0.73714[0m
[92maverage training of epoch 11: loss -22.12205 acc 0.66667 roc_auc 0.42040 prc_auc 0.60478[0m
[93maverage test of epoch 11: loss -22.93538 acc 0.65789 roc_auc 0.57538 prc_auc 0.70162[0m
[92maverage training of epoch 12: loss -23.80773 acc 0.66667 roc_auc 0.42030 prc_auc 0.60470[0m
[93maverage test of epoch 12: loss -24.61359 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 13: loss -25.48851 acc 0.66667 roc_auc 0.42020 prc_auc 0.60458[0m
[93maverage test of epoch 13: loss -26.28742 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 14: loss -27.16532 acc 0.66667 roc_auc 0.42020 prc_auc 0.60458[0m
[93maverage test of epoch 14: loss -27.95772 acc 0.65789 roc_auc 0.60000 prc_auc 0.72632[0m
[92maverage training of epoch 15: loss -28.83891 acc 0.66667 roc_auc 0.42020 prc_auc 0.60497[0m
[93maverage test of epoch 15: loss -29.62510 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 16: loss -30.50985 acc 0.66667 roc_auc 0.42030 prc_auc 0.60497[0m
[93maverage test of epoch 16: loss -31.29008 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 17: loss -32.17857 acc 0.66667 roc_auc 0.42050 prc_auc 0.60497[0m
[93maverage test of epoch 17: loss -32.95306 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 18: loss -33.84546 acc 0.66667 roc_auc 0.42020 prc_auc 0.60551[0m
[93maverage test of epoch 18: loss -34.61437 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -35.51081 acc 0.66667 roc_auc 0.42070 prc_auc 0.60640[0m
[93maverage test of epoch 19: loss -36.27427 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -37.17485 acc 0.66667 roc_auc 0.41970 prc_auc 0.60375[0m
[93maverage test of epoch 20: loss -37.93298 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -38.83780 acc 0.66667 roc_auc 0.42050 prc_auc 0.60270[0m
[93maverage test of epoch 21: loss -39.59068 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -40.49981 acc 0.66667 roc_auc 0.42030 prc_auc 0.60395[0m
[93maverage test of epoch 22: loss -41.24752 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -42.16102 acc 0.66667 roc_auc 0.42070 prc_auc 0.60016[0m
[93maverage test of epoch 23: loss -42.90364 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -43.82156 acc 0.66667 roc_auc 0.42240 prc_auc 0.60527[0m
[93maverage test of epoch 24: loss -44.55912 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -45.48150 acc 0.66667 roc_auc 0.42380 prc_auc 0.60542[0m
[93maverage test of epoch 25: loss -46.21406 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -47.14094 acc 0.66667 roc_auc 0.42930 prc_auc 0.61540[0m
[93maverage test of epoch 26: loss -47.86854 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -48.79996 acc 0.66667 roc_auc 0.43440 prc_auc 0.62037[0m
[93maverage test of epoch 27: loss -49.52261 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -50.45859 acc 0.66667 roc_auc 0.44880 prc_auc 0.63560[0m
[93maverage test of epoch 28: loss -51.17635 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -52.11691 acc 0.66667 roc_auc 0.45640 prc_auc 0.64350[0m
[93maverage test of epoch 29: loss -52.82978 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -53.77494 acc 0.66667 roc_auc 0.44280 prc_auc 0.63807[0m
[93maverage test of epoch 30: loss -54.48295 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -55.43274 acc 0.66667 roc_auc 0.44500 prc_auc 0.64443[0m
[93maverage test of epoch 31: loss -56.13591 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -57.09033 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 32: loss -57.78867 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -58.74773 acc 0.66667 roc_auc 0.43500 prc_auc 0.64096[0m
[93maverage test of epoch 33: loss -59.44125 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -60.40497 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -61.09368 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -62.06207 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -62.74598 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -63.71903 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -64.39816 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -65.37589 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -66.05024 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -67.03265 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -67.70222 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -68.68932 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -69.35412 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -70.34591 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -71.00595 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -72.00244 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -72.65771 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -73.65890 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -74.30941 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -75.31531 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -75.96106 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -76.97166 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -77.61265 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -78.62796 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -79.26419 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -80.28421 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -80.91570 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -81.94042 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -82.56715 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -83.59659 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -84.21857 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -85.25272 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -85.86996 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.003
[92maverage training of epoch 0: loss -2.40717 acc 0.57333 roc_auc 0.40980 prc_auc 0.61799[0m
[93maverage test of epoch 0: loss -4.07280 acc 0.65789 roc_auc 0.95846 prc_auc 0.98092[0m
[92maverage training of epoch 1: loss -5.10974 acc 0.66667 roc_auc 0.39510 prc_auc 0.60325[0m
[93maverage test of epoch 1: loss -6.10412 acc 0.65789 roc_auc 0.92462 prc_auc 0.96368[0m
[92maverage training of epoch 2: loss -7.05626 acc 0.66667 roc_auc 0.37780 prc_auc 0.57495[0m
[93maverage test of epoch 2: loss -7.97180 acc 0.65789 roc_auc 0.90615 prc_auc 0.93752[0m
[92maverage training of epoch 3: loss -8.87924 acc 0.66667 roc_auc 0.37740 prc_auc 0.57500[0m
[93maverage test of epoch 3: loss -9.75142 acc 0.65789 roc_auc 0.62923 prc_auc 0.74632[0m
[92maverage training of epoch 4: loss -10.64100 acc 0.66667 roc_auc 0.37740 prc_auc 0.57497[0m
[93maverage test of epoch 4: loss -11.48940 acc 0.65789 roc_auc 0.82308 prc_auc 0.85885[0m
[92maverage training of epoch 5: loss -12.37127 acc 0.66667 roc_auc 0.37720 prc_auc 0.57467[0m
[93maverage test of epoch 5: loss -13.20382 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 6: loss -14.08263 acc 0.66667 roc_auc 0.37740 prc_auc 0.57486[0m
[93maverage test of epoch 6: loss -14.90321 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 7: loss -15.78145 acc 0.66667 roc_auc 0.37710 prc_auc 0.57458[0m
[93maverage test of epoch 7: loss -16.59226 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 8: loss -17.47143 acc 0.66667 roc_auc 0.37710 prc_auc 0.57458[0m
[93maverage test of epoch 8: loss -18.27383 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 9: loss -19.15489 acc 0.66667 roc_auc 0.37720 prc_auc 0.57477[0m
[93maverage test of epoch 9: loss -19.94977 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 10: loss -20.83340 acc 0.66667 roc_auc 0.37700 prc_auc 0.57474[0m
[93maverage test of epoch 10: loss -21.62139 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 11: loss -22.50804 acc 0.66667 roc_auc 0.37700 prc_auc 0.57465[0m
[93maverage test of epoch 11: loss -23.28959 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 12: loss -24.17960 acc 0.66667 roc_auc 0.37680 prc_auc 0.57587[0m
[93maverage test of epoch 12: loss -24.95506 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 13: loss -25.84870 acc 0.66667 roc_auc 0.37680 prc_auc 0.57575[0m
[93maverage test of epoch 13: loss -26.61831 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 14: loss -27.51579 acc 0.66667 roc_auc 0.37770 prc_auc 0.57742[0m
[93maverage test of epoch 14: loss -28.27975 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 15: loss -29.18121 acc 0.66667 roc_auc 0.37780 prc_auc 0.57514[0m
[93maverage test of epoch 15: loss -29.93969 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 16: loss -30.84526 acc 0.66667 roc_auc 0.37940 prc_auc 0.58174[0m
[93maverage test of epoch 16: loss -31.59838 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 17: loss -32.50816 acc 0.66667 roc_auc 0.37710 prc_auc 0.57976[0m
[93maverage test of epoch 17: loss -33.25601 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 18: loss -34.17009 acc 0.66667 roc_auc 0.38150 prc_auc 0.58307[0m
[93maverage test of epoch 18: loss -34.91277 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -35.83121 acc 0.66667 roc_auc 0.37600 prc_auc 0.58281[0m
[93maverage test of epoch 19: loss -36.56879 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -37.49164 acc 0.66667 roc_auc 0.38000 prc_auc 0.58756[0m
[93maverage test of epoch 20: loss -38.22415 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -39.15148 acc 0.66667 roc_auc 0.38610 prc_auc 0.59779[0m
[93maverage test of epoch 21: loss -39.87899 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -40.81081 acc 0.66667 roc_auc 0.40310 prc_auc 0.61232[0m
[93maverage test of epoch 22: loss -41.53335 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -42.46971 acc 0.66667 roc_auc 0.40470 prc_auc 0.61505[0m
[93maverage test of epoch 23: loss -43.18733 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -44.12825 acc 0.66667 roc_auc 0.44110 prc_auc 0.63840[0m
[93maverage test of epoch 24: loss -44.84097 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -45.78647 acc 0.66667 roc_auc 0.47500 prc_auc 0.65580[0m
[93maverage test of epoch 25: loss -46.49431 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -47.44441 acc 0.66667 roc_auc 0.48000 prc_auc 0.65793[0m
[93maverage test of epoch 26: loss -48.14739 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -49.10211 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 27: loss -49.80025 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -50.75960 acc 0.66667 roc_auc 0.48500 prc_auc 0.66009[0m
[93maverage test of epoch 28: loss -51.45292 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -52.41691 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 29: loss -53.10541 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -54.07406 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 30: loss -54.75775 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -55.73107 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 31: loss -56.40997 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -57.38796 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 32: loss -58.06206 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -59.04474 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 33: loss -59.71406 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -60.70142 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -61.36596 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -62.35801 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -63.01779 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -64.01452 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -64.66953 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -65.67097 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -66.32122 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -67.32736 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -67.97284 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -68.98368 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -69.62441 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -70.63996 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -71.27594 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -72.29620 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -72.92743 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -73.95239 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -74.57887 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -75.60854 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -76.23027 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -77.26466 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -77.88164 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -78.92074 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -79.53296 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -80.57677 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -81.18425 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -82.23277 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -82.83549 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -83.88872 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -84.48670 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -85.54465 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -86.13787 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.003
[92maverage training of epoch 0: loss -1.13020 acc 0.33775 roc_auc 0.51020 prc_auc 0.65981[0m
[93maverage test of epoch 0: loss -2.39319 acc 0.32432 roc_auc 0.84667 prc_auc 0.90948[0m
[92maverage training of epoch 1: loss -3.57246 acc 0.33775 roc_auc 0.37235 prc_auc 0.56937[0m
[93maverage test of epoch 1: loss -4.60250 acc 0.32432 roc_auc 0.10167 prc_auc 0.50043[0m
[92maverage training of epoch 2: loss -5.55770 acc 0.33775 roc_auc 0.37549 prc_auc 0.56933[0m
[93maverage test of epoch 2: loss -6.47772 acc 0.32432 roc_auc 0.13667 prc_auc 0.52648[0m
[92maverage training of epoch 3: loss -7.37811 acc 0.33775 roc_auc 0.37647 prc_auc 0.57000[0m
[93maverage test of epoch 3: loss -8.26980 acc 0.32432 roc_auc 0.16000 prc_auc 0.56493[0m
[92maverage training of epoch 4: loss -9.14180 acc 0.33775 roc_auc 0.37627 prc_auc 0.56989[0m
[93maverage test of epoch 4: loss -10.02332 acc 0.32432 roc_auc 0.11500 prc_auc 0.59290[0m
[92maverage training of epoch 5: loss -10.87620 acc 0.33775 roc_auc 0.37627 prc_auc 0.56989[0m
[93maverage test of epoch 5: loss -11.75466 acc 0.32432 roc_auc 0.17333 prc_auc 0.58369[0m
[92maverage training of epoch 6: loss -12.59276 acc 0.59603 roc_auc 0.37588 prc_auc 0.56998[0m
[93maverage test of epoch 6: loss -13.47170 acc 0.67568 roc_auc 0.43333 prc_auc 0.64665[0m
[92maverage training of epoch 7: loss -14.29742 acc 0.66225 roc_auc 0.37588 prc_auc 0.56998[0m
[93maverage test of epoch 7: loss -15.17882 acc 0.67568 roc_auc 0.48000 prc_auc 0.66703[0m
[92maverage training of epoch 8: loss -15.99361 acc 0.66225 roc_auc 0.37608 prc_auc 0.57008[0m
[93maverage test of epoch 8: loss -16.87873 acc 0.67568 roc_auc 0.38667 prc_auc 0.68487[0m
[92maverage training of epoch 9: loss -17.68355 acc 0.66225 roc_auc 0.37588 prc_auc 0.56971[0m
[93maverage test of epoch 9: loss -18.57321 acc 0.67568 roc_auc 0.60000 prc_auc 0.73027[0m
[92maverage training of epoch 10: loss -19.36871 acc 0.66225 roc_auc 0.37588 prc_auc 0.56971[0m
[93maverage test of epoch 10: loss -20.26348 acc 0.67568 roc_auc 0.54000 prc_auc 0.70310[0m
[92maverage training of epoch 11: loss -21.05014 acc 0.66225 roc_auc 0.37588 prc_auc 0.56971[0m
[93maverage test of epoch 11: loss -21.95044 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 12: loss -22.72862 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 12: loss -23.63475 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 13: loss -24.40471 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 13: loss -25.31691 acc 0.67568 roc_auc 0.38000 prc_auc 0.63880[0m
[92maverage training of epoch 14: loss -26.07884 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 14: loss -26.99730 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 15: loss -27.75138 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 15: loss -28.67623 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 16: loss -29.42258 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 16: loss -30.35395 acc 0.67568 roc_auc 0.84000 prc_auc 0.87252[0m
[92maverage training of epoch 17: loss -31.09267 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 17: loss -32.03064 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 18: loss -32.76183 acc 0.66225 roc_auc 0.37578 prc_auc 0.56962[0m
[93maverage test of epoch 18: loss -33.70648 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 19: loss -34.43019 acc 0.66225 roc_auc 0.37578 prc_auc 0.56982[0m
[93maverage test of epoch 19: loss -35.38159 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 20: loss -36.09789 acc 0.66225 roc_auc 0.37578 prc_auc 0.56954[0m
[93maverage test of epoch 20: loss -37.05608 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 21: loss -37.76502 acc 0.66225 roc_auc 0.37578 prc_auc 0.57064[0m
[93maverage test of epoch 21: loss -38.73005 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 22: loss -39.43167 acc 0.66225 roc_auc 0.37598 prc_auc 0.57047[0m
[93maverage test of epoch 22: loss -40.40357 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 23: loss -41.09789 acc 0.66225 roc_auc 0.37520 prc_auc 0.57169[0m
[93maverage test of epoch 23: loss -42.07670 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 24: loss -42.76377 acc 0.66225 roc_auc 0.37549 prc_auc 0.57197[0m
[93maverage test of epoch 24: loss -43.74951 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 25: loss -44.42933 acc 0.66225 roc_auc 0.37500 prc_auc 0.57132[0m
[93maverage test of epoch 25: loss -45.42202 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 26: loss -46.09463 acc 0.66225 roc_auc 0.37559 prc_auc 0.57192[0m
[93maverage test of epoch 26: loss -47.09429 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 27: loss -47.75969 acc 0.66225 roc_auc 0.37559 prc_auc 0.57536[0m
[93maverage test of epoch 27: loss -48.76634 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 28: loss -49.42456 acc 0.66225 roc_auc 0.37029 prc_auc 0.57470[0m
[93maverage test of epoch 28: loss -50.43821 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 29: loss -51.08925 acc 0.66225 roc_auc 0.37167 prc_auc 0.57746[0m
[93maverage test of epoch 29: loss -52.10991 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 30: loss -52.75378 acc 0.66225 roc_auc 0.37422 prc_auc 0.58492[0m
[93maverage test of epoch 30: loss -53.78146 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 31: loss -54.41818 acc 0.66225 roc_auc 0.38941 prc_auc 0.60103[0m
[93maverage test of epoch 31: loss -55.45288 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 32: loss -56.08246 acc 0.66225 roc_auc 0.36578 prc_auc 0.59722[0m
[93maverage test of epoch 32: loss -57.12419 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 33: loss -57.74663 acc 0.66225 roc_auc 0.42843 prc_auc 0.62777[0m
[93maverage test of epoch 33: loss -58.79541 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 34: loss -59.41071 acc 0.66225 roc_auc 0.43784 prc_auc 0.63611[0m
[93maverage test of epoch 34: loss -60.46654 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 35: loss -61.07471 acc 0.66225 roc_auc 0.44284 prc_auc 0.63808[0m
[93maverage test of epoch 35: loss -62.13759 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 36: loss -62.73863 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 36: loss -63.80857 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 37: loss -64.40250 acc 0.66225 roc_auc 0.42784 prc_auc 0.63226[0m
[93maverage test of epoch 37: loss -65.47950 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 38: loss -66.06629 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 38: loss -67.15036 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 39: loss -67.73004 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 39: loss -68.82116 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -69.39372 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 40: loss -70.49191 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -71.05736 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 41: loss -72.16263 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -72.72096 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 42: loss -73.83329 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -74.38452 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 43: loss -75.50394 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -76.04806 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 44: loss -77.17455 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -77.71157 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 45: loss -78.84513 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -79.37503 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 46: loss -80.51566 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -81.03845 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 47: loss -82.18616 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -82.70184 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 48: loss -83.85663 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -84.36521 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 49: loss -85.52707 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.003
[92maverage training of epoch 0: loss -1.86789 acc 0.66225 roc_auc 0.40627 prc_auc 0.60947[0m
[93maverage test of epoch 0: loss -3.55007 acc 0.67568 roc_auc 0.92500 prc_auc 0.96478[0m
[92maverage training of epoch 1: loss -4.55319 acc 0.66225 roc_auc 0.37471 prc_auc 0.57776[0m
[93maverage test of epoch 1: loss -5.62928 acc 0.67568 roc_auc 0.81333 prc_auc 0.88115[0m
[92maverage training of epoch 2: loss -6.45973 acc 0.66225 roc_auc 0.37196 prc_auc 0.56955[0m
[93maverage test of epoch 2: loss -7.45646 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 3: loss -8.24325 acc 0.66225 roc_auc 0.37078 prc_auc 0.56896[0m
[93maverage test of epoch 3: loss -9.22064 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 4: loss -9.98389 acc 0.66225 roc_auc 0.37039 prc_auc 0.56895[0m
[93maverage test of epoch 4: loss -10.95541 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0mUsing backend: pytorch
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))

[92maverage training of epoch 5: loss -11.70226 acc 0.66225 roc_auc 0.37010 prc_auc 0.56846[0m
[93maverage test of epoch 5: loss -12.67321 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 6: loss -13.40702 acc 0.66225 roc_auc 0.37000 prc_auc 0.56845[0m
[93maverage test of epoch 6: loss -14.38003 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 7: loss -15.10264 acc 0.66225 roc_auc 0.37020 prc_auc 0.56883[0m
[93maverage test of epoch 7: loss -16.07921 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 8: loss -16.79175 acc 0.66225 roc_auc 0.36980 prc_auc 0.56992[0m
[93maverage test of epoch 8: loss -17.77283 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 9: loss -18.47604 acc 0.66225 roc_auc 0.37049 prc_auc 0.56999[0m
[93maverage test of epoch 9: loss -19.46226 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 10: loss -20.15665 acc 0.66225 roc_auc 0.36961 prc_auc 0.56995[0m
[93maverage test of epoch 10: loss -21.14842 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 11: loss -21.83436 acc 0.66225 roc_auc 0.36951 prc_auc 0.56848[0m
[93maverage test of epoch 11: loss -22.83202 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 12: loss -23.50977 acc 0.66225 roc_auc 0.36775 prc_auc 0.56855[0m
[93maverage test of epoch 12: loss -24.51356 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 13: loss -25.18334 acc 0.66225 roc_auc 0.36373 prc_auc 0.56784[0m
[93maverage test of epoch 13: loss -26.19341 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 14: loss -26.85538 acc 0.66225 roc_auc 0.36961 prc_auc 0.58001[0m
[93maverage test of epoch 14: loss -27.87189 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 15: loss -28.52616 acc 0.66225 roc_auc 0.37706 prc_auc 0.58602[0m
[93maverage test of epoch 15: loss -29.54922 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 16: loss -30.19591 acc 0.66225 roc_auc 0.36912 prc_auc 0.58400[0m
[93maverage test of epoch 16: loss -31.22561 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 17: loss -31.86479 acc 0.66225 roc_auc 0.37284 prc_auc 0.59246[0m
[93maverage test of epoch 17: loss -32.90120 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 18: loss -33.53294 acc 0.66225 roc_auc 0.41304 prc_auc 0.61971[0m
[93maverage test of epoch 18: loss -34.57612 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 19: loss -35.20047 acc 0.66225 roc_auc 0.43735 prc_auc 0.63327[0m
[93maverage test of epoch 19: loss -36.25045 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 20: loss -36.86747 acc 0.66225 roc_auc 0.45363 prc_auc 0.64232[0m
[93maverage test of epoch 20: loss -37.92431 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 21: loss -38.53402 acc 0.66225 roc_auc 0.44882 prc_auc 0.64033[0m
[93maverage test of epoch 21: loss -39.59775 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 22: loss -40.20019 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 22: loss -41.27084 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 23: loss -41.86604 acc 0.66225 roc_auc 0.47284 prc_auc 0.65040[0m
[93maverage test of epoch 23: loss -42.94363 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 24: loss -43.53160 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 24: loss -44.61614 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 25: loss -45.19691 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 25: loss -46.28843 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 26: loss -46.86201 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 26: loss -47.96053 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 27: loss -48.52692 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 27: loss -49.63244 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 28: loss -50.19168 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 28: loss -51.30421 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 29: loss -51.85628 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 29: loss -52.97584 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 30: loss -53.52077 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 30: loss -54.64734 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 31: loss -55.18514 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 31: loss -56.31875 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 32: loss -56.84941 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 32: loss -57.99006 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 33: loss -58.51359 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 33: loss -59.66129 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 34: loss -60.17769 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 34: loss -61.33245 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 35: loss -61.84173 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 35: loss -63.00354 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 36: loss -63.50571 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 36: loss -64.67458 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 37: loss -65.16963 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 37: loss -66.34556 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 38: loss -66.83350 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 38: loss -68.01649 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 39: loss -68.49731 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 39: loss -69.68737 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -70.16109 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 40: loss -71.35820 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -71.82482 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 41: loss -73.02901 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -73.48850 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 42: loss -74.69975 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -75.15214 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 43: loss -76.37046 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -76.81574 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 44: loss -78.04113 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -78.47931 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 45: loss -79.71178 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -80.14284 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 46: loss -81.38238 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -81.80634 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 47: loss -83.05294 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -83.46980 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 48: loss -84.72348 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -85.13323 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 49: loss -86.39398 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.66501 ROC_AUC (avg): 0.5 PRC_AUC (avg): 0.66501 

Average forward propagation time taken(ms): 2.4741464252987044
Average backward propagation time taken(ms): 0.8715620817119057

