# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.0001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-18-54-01/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-18-54-01/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 16,
 'epochs': 50,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 8,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.0001,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 1,
 'num_workers': 8,
 'number_of_mlp_layer': 0,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-17-18-54-01',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 50, 'learning_rate': 0.0001, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.23135 acc 0.33333 roc_auc 0.44620 prc_auc 0.66789[0m
[93maverage test of epoch 0: loss -0.38474 acc 0.34211 roc_auc 0.58462 prc_auc 0.81408[0m
[92maverage training of epoch 1: loss -0.51315 acc 0.33333 roc_auc 0.43400 prc_auc 0.65300[0m
[93maverage test of epoch 1: loss -0.64772 acc 0.34211 roc_auc 0.37846 prc_auc 0.69609[0m
[92maverage training of epoch 2: loss -0.76450 acc 0.34000 roc_auc 0.42520 prc_auc 0.64645[0m
[93maverage test of epoch 2: loss -0.88201 acc 0.34211 roc_auc 0.20923 prc_auc 0.57323[0m
[92maverage training of epoch 3: loss -0.99044 acc 0.34667 roc_auc 0.42320 prc_auc 0.64543[0m
[93maverage test of epoch 3: loss -1.09529 acc 0.34211 roc_auc 0.20615 prc_auc 0.57240[0m
[92maverage training of epoch 4: loss -1.19859 acc 0.35333 roc_auc 0.42560 prc_auc 0.64852[0m
[93maverage test of epoch 4: loss -1.29390 acc 0.36842 roc_auc 0.21538 prc_auc 0.58006[0m
[92maverage training of epoch 5: loss -1.39407 acc 0.57333 roc_auc 0.42820 prc_auc 0.64991[0m
[93maverage test of epoch 5: loss -1.48167 acc 0.65789 roc_auc 0.22154 prc_auc 0.58214[0m
[92maverage training of epoch 6: loss -1.58037 acc 0.66667 roc_auc 0.43180 prc_auc 0.65676[0m
[93maverage test of epoch 6: loss -1.66246 acc 0.65789 roc_auc 0.29538 prc_auc 0.62833[0m
[92maverage training of epoch 7: loss -1.76348 acc 0.66667 roc_auc 0.43660 prc_auc 0.65997[0m
[93maverage test of epoch 7: loss -1.84622 acc 0.65789 roc_auc 0.30154 prc_auc 0.62359[0m
[92maverage training of epoch 8: loss -1.95957 acc 0.66667 roc_auc 0.44240 prc_auc 0.66443[0m
[93maverage test of epoch 8: loss -2.05520 acc 0.65789 roc_auc 0.42154 prc_auc 0.72709[0m
[92maverage training of epoch 9: loss -2.18266 acc 0.66667 roc_auc 0.43660 prc_auc 0.65599[0m
[93maverage test of epoch 9: loss -2.28244 acc 0.65789 roc_auc 0.80615 prc_auc 0.87686[0m
[92maverage training of epoch 10: loss -2.40731 acc 0.66667 roc_auc 0.43780 prc_auc 0.65826[0m
[93maverage test of epoch 10: loss -2.49996 acc 0.65789 roc_auc 0.87231 prc_auc 0.91936[0m
[92maverage training of epoch 11: loss -2.62882 acc 0.66667 roc_auc 0.44060 prc_auc 0.66028[0m
[93maverage test of epoch 11: loss -2.72467 acc 0.65789 roc_auc 0.86923 prc_auc 0.92242[0m
[92maverage training of epoch 12: loss -2.86564 acc 0.66667 roc_auc 0.44220 prc_auc 0.66273[0m
[93maverage test of epoch 12: loss -2.97093 acc 0.65789 roc_auc 0.87385 prc_auc 0.93682[0m
[92maverage training of epoch 13: loss -3.12246 acc 0.66667 roc_auc 0.44380 prc_auc 0.66843[0m
[93maverage test of epoch 13: loss -3.23131 acc 0.65789 roc_auc 0.87385 prc_auc 0.93682[0m
[92maverage training of epoch 14: loss -3.38255 acc 0.66667 roc_auc 0.45000 prc_auc 0.67310[0m
[93maverage test of epoch 14: loss -3.48178 acc 0.65789 roc_auc 0.87385 prc_auc 0.93448[0m
[92maverage training of epoch 15: loss -3.62347 acc 0.66667 roc_auc 0.45680 prc_auc 0.67755[0m
[93maverage test of epoch 15: loss -3.70647 acc 0.65789 roc_auc 0.87692 prc_auc 0.93544[0m
[92maverage training of epoch 16: loss -3.83654 acc 0.66667 roc_auc 0.46440 prc_auc 0.67987[0m
[93maverage test of epoch 16: loss -3.90418 acc 0.65789 roc_auc 0.87538 prc_auc 0.93448[0m
[92maverage training of epoch 17: loss -4.02390 acc 0.66667 roc_auc 0.45340 prc_auc 0.67140[0m
[93maverage test of epoch 17: loss -4.07936 acc 0.65789 roc_auc 0.87385 prc_auc 0.93448[0m
[92maverage training of epoch 18: loss -4.19109 acc 0.66667 roc_auc 0.44600 prc_auc 0.66790[0m
[93maverage test of epoch 18: loss -4.23760 acc 0.65789 roc_auc 0.87692 prc_auc 0.93781[0m
[92maverage training of epoch 19: loss -4.34346 acc 0.66667 roc_auc 0.45210 prc_auc 0.67941[0m
[93maverage test of epoch 19: loss -4.38347 acc 0.65789 roc_auc 0.87692 prc_auc 0.93781[0m
[92maverage training of epoch 20: loss -4.48499 acc 0.66667 roc_auc 0.45870 prc_auc 0.68966[0m
[93maverage test of epoch 20: loss -4.52014 acc 0.65789 roc_auc 0.87692 prc_auc 0.93781[0m
[92maverage training of epoch 21: loss -4.61838 acc 0.66667 roc_auc 0.45890 prc_auc 0.68435[0m
[93maverage test of epoch 21: loss -4.64980 acc 0.65789 roc_auc 0.87692 prc_auc 0.93811[0m
[92maverage training of epoch 22: loss -4.74549 acc 0.66667 roc_auc 0.46140 prc_auc 0.68401[0m
[93maverage test of epoch 22: loss -4.77397 acc 0.65789 roc_auc 0.87692 prc_auc 0.93781[0m
[92maverage training of epoch 23: loss -4.86766 acc 0.66667 roc_auc 0.46340 prc_auc 0.68712[0m
[93maverage test of epoch 23: loss -4.89380 acc 0.65789 roc_auc 0.87692 prc_auc 0.93781[0m
[92maverage training of epoch 24: loss -4.98589 acc 0.66667 roc_auc 0.46520 prc_auc 0.69179[0m
[93maverage test of epoch 24: loss -5.01012 acc 0.65789 roc_auc 0.87692 prc_auc 0.93811[0m
[92maverage training of epoch 25: loss -5.10092 acc 0.66667 roc_auc 0.46380 prc_auc 0.69292[0m
[93maverage test of epoch 25: loss -5.12362 acc 0.65789 roc_auc 0.87692 prc_auc 0.93811[0m
[92maverage training of epoch 26: loss -5.21338 acc 0.66667 roc_auc 0.46490 prc_auc 0.69658[0m
[93maverage test of epoch 26: loss -5.23481 acc 0.65789 roc_auc 0.87538 prc_auc 0.93682[0m
[92maverage training of epoch 27: loss -5.32375 acc 0.66667 roc_auc 0.46900 prc_auc 0.69963[0m
[93maverage test of epoch 27: loss -5.34415 acc 0.65789 roc_auc 0.87538 prc_auc 0.93712[0m
[92maverage training of epoch 28: loss -5.43242 acc 0.66667 roc_auc 0.47350 prc_auc 0.70418[0m
[93maverage test of epoch 28: loss -5.45198 acc 0.65789 roc_auc 0.87077 prc_auc 0.93633[0m
[92maverage training of epoch 29: loss -5.53972 acc 0.66667 roc_auc 0.47670 prc_auc 0.70739[0m
[93maverage test of epoch 29: loss -5.55861 acc 0.65789 roc_auc 0.86923 prc_auc 0.93534[0m
[92maverage training of epoch 30: loss -5.64592 acc 0.66667 roc_auc 0.48260 prc_auc 0.71329[0m
[93maverage test of epoch 30: loss -5.66427 acc 0.65789 roc_auc 0.87077 prc_auc 0.93633[0m
[92maverage training of epoch 31: loss -5.75125 acc 0.66667 roc_auc 0.48900 prc_auc 0.72049[0m
[93maverage test of epoch 31: loss -5.76919 acc 0.65789 roc_auc 0.86615 prc_auc 0.93441[0m
[92maverage training of epoch 32: loss -5.85591 acc 0.66667 roc_auc 0.49370 prc_auc 0.72506[0m
[93maverage test of epoch 32: loss -5.87353 acc 0.65789 roc_auc 0.86154 prc_auc 0.93174[0m
[92maverage training of epoch 33: loss -5.96006 acc 0.66667 roc_auc 0.50080 prc_auc 0.73054[0m
[93maverage test of epoch 33: loss -5.97745 acc 0.65789 roc_auc 0.86308 prc_auc 0.93301[0m
[92maverage training of epoch 34: loss -6.06383 acc 0.66667 roc_auc 0.50670 prc_auc 0.73516[0m
[93maverage test of epoch 34: loss -6.08107 acc 0.65789 roc_auc 0.86000 prc_auc 0.93116[0m
[92maverage training of epoch 35: loss -6.16735 acc 0.66667 roc_auc 0.51320 prc_auc 0.73958[0m
[93maverage test of epoch 35: loss -6.18450 acc 0.65789 roc_auc 0.86154 prc_auc 0.93174[0m
[92maverage training of epoch 36: loss -6.27071 acc 0.66667 roc_auc 0.51820 prc_auc 0.74230[0m
[93maverage test of epoch 36: loss -6.28782 acc 0.65789 roc_auc 0.86000 prc_auc 0.93174[0m
[92maverage training of epoch 37: loss -6.37399 acc 0.66667 roc_auc 0.52160 prc_auc 0.74432[0m
[93maverage test of epoch 37: loss -6.39111 acc 0.65789 roc_auc 0.85846 prc_auc 0.93048[0m
[92maverage training of epoch 38: loss -6.47726 acc 0.66667 roc_auc 0.52570 prc_auc 0.74614[0m
[93maverage test of epoch 38: loss -6.49444 acc 0.65789 roc_auc 0.86000 prc_auc 0.93174[0m
[92maverage training of epoch 39: loss -6.58059 acc 0.66667 roc_auc 0.52800 prc_auc 0.74701[0m
[93maverage test of epoch 39: loss -6.59785 acc 0.65789 roc_auc 0.86308 prc_auc 0.93482[0m
[92maverage training of epoch 40: loss -6.68401 acc 0.66667 roc_auc 0.53000 prc_auc 0.74810[0m
[93maverage test of epoch 40: loss -6.70139 acc 0.65789 roc_auc 0.86308 prc_auc 0.93482[0m
[92maverage training of epoch 41: loss -6.78756 acc 0.66667 roc_auc 0.53130 prc_auc 0.74879[0m
[93maverage test of epoch 41: loss -6.80507 acc 0.65789 roc_auc 0.86769 prc_auc 0.93768[0m
[92maverage training of epoch 42: loss -6.89127 acc 0.66667 roc_auc 0.53240 prc_auc 0.74910[0m
[93maverage test of epoch 42: loss -6.90893 acc 0.65789 roc_auc 0.86462 prc_auc 0.93768[0m
[92maverage training of epoch 43: loss -6.99515 acc 0.66667 roc_auc 0.53310 prc_auc 0.74945[0m
[93maverage test of epoch 43: loss -7.01295 acc 0.65789 roc_auc 0.86462 prc_auc 0.93768[0m
[92maverage training of epoch 44: loss -7.09920 acc 0.66667 roc_auc 0.53330 prc_auc 0.74952[0m
[93maverage test of epoch 44: loss -7.11715 acc 0.65789 roc_auc 0.86615 prc_auc 0.93768[0m
[92maverage training of epoch 45: loss -7.20342 acc 0.66667 roc_auc 0.53320 prc_auc 0.74973[0m
[93maverage test of epoch 45: loss -7.22151 acc 0.65789 roc_auc 0.86615 prc_auc 0.93777[0m
[92maverage training of epoch 46: loss -7.30780 acc 0.66667 roc_auc 0.53440 prc_auc 0.75083[0m
[93maverage test of epoch 46: loss -7.32601 acc 0.65789 roc_auc 0.86308 prc_auc 0.93673[0m
[92maverage training of epoch 47: loss -7.41234 acc 0.66667 roc_auc 0.53630 prc_auc 0.75302[0m
[93maverage test of epoch 47: loss -7.43063 acc 0.65789 roc_auc 0.86462 prc_auc 0.93768[0m
[92maverage training of epoch 48: loss -7.51702 acc 0.66667 roc_auc 0.53760 prc_auc 0.75457[0m
[93maverage test of epoch 48: loss -7.53535 acc 0.65789 roc_auc 0.86615 prc_auc 0.93736[0m
[92maverage training of epoch 49: loss -7.62191 acc 0.66667 roc_auc 0.54210 prc_auc 0.75721[0m
[93maverage test of epoch 49: loss -7.64017 acc 0.65789 roc_auc 0.86462 prc_auc 0.93709[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss 0.21551 acc 0.66667 roc_auc 0.44860 prc_auc 0.64294[0m
[93maverage test of epoch 0: loss 0.06749 acc 0.65789 roc_auc 0.57231 prc_auc 0.78833[0m
[92maverage training of epoch 1: loss -0.06934 acc 0.66667 roc_auc 0.47720 prc_auc 0.66840[0m
[93maverage test of epoch 1: loss -0.21862 acc 0.65789 roc_auc 0.66769 prc_auc 0.83731[0m
[92maverage training of epoch 2: loss -0.37192 acc 0.66667 roc_auc 0.49240 prc_auc 0.68181[0m
[93maverage test of epoch 2: loss -0.55652 acc 0.65789 roc_auc 0.80923 prc_auc 0.89655[0m
[92maverage training of epoch 3: loss -0.77801 acc 0.66667 roc_auc 0.50620 prc_auc 0.68744[0m
[93maverage test of epoch 3: loss -1.05057 acc 0.65789 roc_auc 0.86769 prc_auc 0.91887[0m
[92maverage training of epoch 4: loss -1.30480 acc 0.66667 roc_auc 0.50460 prc_auc 0.68529[0m
[93maverage test of epoch 4: loss -1.54514 acc 0.65789 roc_auc 0.82769 prc_auc 0.88224[0m
[92maverage training of epoch 5: loss -1.73123 acc 0.66667 roc_auc 0.49280 prc_auc 0.67132[0m
[93maverage test of epoch 5: loss -1.90206 acc 0.65789 roc_auc 0.78462 prc_auc 0.85621[0m
[92maverage training of epoch 6: loss -2.06793 acc 0.66667 roc_auc 0.49120 prc_auc 0.67051[0m
[93maverage test of epoch 6: loss -2.22082 acc 0.65789 roc_auc 0.71385 prc_auc 0.81115[0m
[92maverage training of epoch 7: loss -2.39803 acc 0.66667 roc_auc 0.48600 prc_auc 0.66774[0m
[93maverage test of epoch 7: loss -2.55774 acc 0.65789 roc_auc 0.64923 prc_auc 0.78127[0m
[92maverage training of epoch 8: loss -2.74526 acc 0.66667 roc_auc 0.48140 prc_auc 0.66906[0m
[93maverage test of epoch 8: loss -2.90309 acc 0.65789 roc_auc 0.62769 prc_auc 0.77708[0m
[92maverage training of epoch 9: loss -3.08388 acc 0.66667 roc_auc 0.48020 prc_auc 0.66858[0m
[93maverage test of epoch 9: loss -3.23867 acc 0.65789 roc_auc 0.63692 prc_auc 0.78477[0m
[92maverage training of epoch 10: loss -3.42971 acc 0.66667 roc_auc 0.48280 prc_auc 0.67022[0m
[93maverage test of epoch 10: loss -3.60486 acc 0.65789 roc_auc 0.72615 prc_auc 0.82059[0m
[92maverage training of epoch 11: loss -3.80572 acc 0.66667 roc_auc 0.48760 prc_auc 0.67257[0m
[93maverage test of epoch 11: loss -3.97841 acc 0.65789 roc_auc 0.78462 prc_auc 0.86121[0m
[92maverage training of epoch 12: loss -4.14326 acc 0.66667 roc_auc 0.49120 prc_auc 0.67631[0m
[93maverage test of epoch 12: loss -4.27290 acc 0.65789 roc_auc 0.75385 prc_auc 0.84647[0m
[92maverage training of epoch 13: loss -4.40132 acc 0.66667 roc_auc 0.48100 prc_auc 0.66643[0m
[93maverage test of epoch 13: loss -4.49865 acc 0.65789 roc_auc 0.71692 prc_auc 0.82784[0m
[92maverage training of epoch 14: loss -4.60792 acc 0.66667 roc_auc 0.46460 prc_auc 0.64654[0m
[93maverage test of epoch 14: loss -4.68728 acc 0.65789 roc_auc 0.70769 prc_auc 0.82650[0m
[92maverage training of epoch 15: loss -4.78580 acc 0.66667 roc_auc 0.44980 prc_auc 0.63324[0m
[93maverage test of epoch 15: loss -4.85394 acc 0.65789 roc_auc 0.70154 prc_auc 0.83530[0m
[92maverage training of epoch 16: loss -4.94554 acc 0.66667 roc_auc 0.43600 prc_auc 0.62376[0m
[93maverage test of epoch 16: loss -5.00581 acc 0.65789 roc_auc 0.68615 prc_auc 0.82964[0m
[92maverage training of epoch 17: loss -5.09254 acc 0.66667 roc_auc 0.42910 prc_auc 0.61583[0m
[93maverage test of epoch 17: loss -5.14691 acc 0.65789 roc_auc 0.68923 prc_auc 0.83535[0m
[92maverage training of epoch 18: loss -5.23003 acc 0.66667 roc_auc 0.42530 prc_auc 0.61142[0m
[93maverage test of epoch 18: loss -5.27979 acc 0.65789 roc_auc 0.68308 prc_auc 0.83341[0m
[92maverage training of epoch 19: loss -5.36018 acc 0.66667 roc_auc 0.42300 prc_auc 0.60967[0m
[93maverage test of epoch 19: loss -5.40626 acc 0.65789 roc_auc 0.67231 prc_auc 0.82510[0m
[92maverage training of epoch 20: loss -5.48455 acc 0.66667 roc_auc 0.42040 prc_auc 0.60893[0m
[93maverage test of epoch 20: loss -5.52765 acc 0.65789 roc_auc 0.64769 prc_auc 0.81400[0m
[92maverage training of epoch 21: loss -5.60434 acc 0.66667 roc_auc 0.42140 prc_auc 0.61050[0m
[93maverage test of epoch 21: loss -5.64506 acc 0.65789 roc_auc 0.64615 prc_auc 0.81419[0m
[92maverage training of epoch 22: loss -5.72058 acc 0.66667 roc_auc 0.42220 prc_auc 0.61170[0m
[93maverage test of epoch 22: loss -5.75945 acc 0.65789 roc_auc 0.63846 prc_auc 0.80902[0m
[92maverage training of epoch 23: loss -5.83422 acc 0.66667 roc_auc 0.42420 prc_auc 0.61461[0m
[93maverage test of epoch 23: loss -5.87178 acc 0.65789 roc_auc 0.56923 prc_auc 0.78723[0m
[92maverage training of epoch 24: loss -5.94629 acc 0.66667 roc_auc 0.42010 prc_auc 0.62628[0m
[93maverage test of epoch 24: loss -5.98320 acc 0.65789 roc_auc 0.56308 prc_auc 0.78439[0m
[92maverage training of epoch 25: loss -6.05804 acc 0.66667 roc_auc 0.41970 prc_auc 0.63104[0m
[93maverage test of epoch 25: loss -6.09513 acc 0.65789 roc_auc 0.49385 prc_auc 0.75387[0m
[92maverage training of epoch 26: loss -6.17114 acc 0.66667 roc_auc 0.40930 prc_auc 0.62923[0m
[93maverage test of epoch 26: loss -6.20943 acc 0.65789 roc_auc 0.42462 prc_auc 0.72765[0m
[92maverage training of epoch 27: loss -6.28750 acc 0.66667 roc_auc 0.39860 prc_auc 0.63028[0m
[93maverage test of epoch 27: loss -6.32793 acc 0.65789 roc_auc 0.35692 prc_auc 0.69017[0m
[92maverage training of epoch 28: loss -6.40845 acc 0.66667 roc_auc 0.36900 prc_auc 0.60023[0m
[93maverage test of epoch 28: loss -6.45103 acc 0.65789 roc_auc 0.24154 prc_auc 0.63010[0m
[92maverage training of epoch 29: loss -6.53304 acc 0.66667 roc_auc 0.32920 prc_auc 0.57479[0m
[93maverage test of epoch 29: loss -6.57633 acc 0.65789 roc_auc 0.23385 prc_auc 0.62279[0m
[92maverage training of epoch 30: loss -6.65809 acc 0.66667 roc_auc 0.30080 prc_auc 0.56815[0m
[93maverage test of epoch 30: loss -6.70044 acc 0.65789 roc_auc 0.19077 prc_auc 0.59925[0m
[92maverage training of epoch 31: loss -6.78102 acc 0.66667 roc_auc 0.30520 prc_auc 0.56547[0m
[93maverage test of epoch 31: loss -6.82185 acc 0.65789 roc_auc 0.13538 prc_auc 0.54147[0m
[92maverage training of epoch 32: loss -6.90125 acc 0.66667 roc_auc 0.34200 prc_auc 0.57392[0m
[93maverage test of epoch 32: loss -6.94061 acc 0.65789 roc_auc 0.14154 prc_auc 0.54384[0m
[92maverage training of epoch 33: loss -7.01909 acc 0.66667 roc_auc 0.36280 prc_auc 0.57974[0m
[93maverage test of epoch 33: loss -7.05713 acc 0.65789 roc_auc 0.15692 prc_auc 0.54723[0m
[92maverage training of epoch 34: loss -7.13490 acc 0.66667 roc_auc 0.38000 prc_auc 0.58597[0m
[93maverage test of epoch 34: loss -7.17176 acc 0.65789 roc_auc 0.17538 prc_auc 0.55343[0m
[92maverage training of epoch 35: loss -7.24895 acc 0.66667 roc_auc 0.38840 prc_auc 0.58956[0m
[93maverage test of epoch 35: loss -7.28473 acc 0.65789 roc_auc 0.18462 prc_auc 0.55522[0m
[92maverage training of epoch 36: loss -7.36143 acc 0.66667 roc_auc 0.39440 prc_auc 0.59233[0m
[93maverage test of epoch 36: loss -7.39622 acc 0.65789 roc_auc 0.19385 prc_auc 0.56011[0m
[92maverage training of epoch 37: loss -7.47253 acc 0.66667 roc_auc 0.39790 prc_auc 0.59409[0m
[93maverage test of epoch 37: loss -7.50639 acc 0.65789 roc_auc 0.19692 prc_auc 0.56062[0m
[92maverage training of epoch 38: loss -7.58237 acc 0.66667 roc_auc 0.40320 prc_auc 0.59659[0m
[93maverage test of epoch 38: loss -7.61537 acc 0.65789 roc_auc 0.19692 prc_auc 0.56138[0m
[92maverage training of epoch 39: loss -7.69110 acc 0.66667 roc_auc 0.40550 prc_auc 0.59746[0m
[93maverage test of epoch 39: loss -7.72330 acc 0.65789 roc_auc 0.19385 prc_auc 0.56105[0m
[92maverage training of epoch 40: loss -7.79883 acc 0.66667 roc_auc 0.40850 prc_auc 0.59886[0m
[93maverage test of epoch 40: loss -7.83029 acc 0.65789 roc_auc 0.18769 prc_auc 0.55745[0m
[92maverage training of epoch 41: loss -7.90567 acc 0.66667 roc_auc 0.40990 prc_auc 0.59981[0m
[93maverage test of epoch 41: loss -7.93643 acc 0.65789 roc_auc 0.18769 prc_auc 0.55802[0m
[92maverage training of epoch 42: loss -8.01173 acc 0.66667 roc_auc 0.41150 prc_auc 0.59989[0m
[93maverage test of epoch 42: loss -8.04184 acc 0.65789 roc_auc 0.18923 prc_auc 0.55921[0m
[92maverage training of epoch 43: loss -8.11709 acc 0.66667 roc_auc 0.41270 prc_auc 0.60099[0m
[93maverage test of epoch 43: loss -8.14658 acc 0.65789 roc_auc 0.18308 prc_auc 0.55959[0m
[92maverage training of epoch 44: loss -8.22182 acc 0.66667 roc_auc 0.41420 prc_auc 0.60200[0m
[93maverage test of epoch 44: loss -8.25074 acc 0.65789 roc_auc 0.18769 prc_auc 0.55813[0m
[92maverage training of epoch 45: loss -8.32601 acc 0.66667 roc_auc 0.41620 prc_auc 0.60288[0m
[93maverage test of epoch 45: loss -8.35437 acc 0.65789 roc_auc 0.18615 prc_auc 0.55927[0m
[92maverage training of epoch 46: loss -8.42970 acc 0.66667 roc_auc 0.41700 prc_auc 0.60406[0m
[93maverage test of epoch 46: loss -8.45755 acc 0.65789 roc_auc 0.18462 prc_auc 0.56333[0m
[92maverage training of epoch 47: loss -8.53296 acc 0.66667 roc_auc 0.41660 prc_auc 0.60337[0m
[93maverage test of epoch 47: loss -8.56031 acc 0.65789 roc_auc 0.18308 prc_auc 0.56442[0m
[92maverage training of epoch 48: loss -8.63583 acc 0.66667 roc_auc 0.41780 prc_auc 0.60582[0m
[93maverage test of epoch 48: loss -8.66271 acc 0.65789 roc_auc 0.19077 prc_auc 0.56830[0m
[92maverage training of epoch 49: loss -8.73836 acc 0.66667 roc_auc 0.41820 prc_auc 0.60603[0m
[93maverage test of epoch 49: loss -8.76478 acc 0.65789 roc_auc 0.18308 prc_auc 0.56969[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.45772 acc 0.66667 roc_auc 0.34600 prc_auc 0.57499[0m
[93maverage test of epoch 0: loss -0.55241 acc 0.65789 roc_auc 0.17231 prc_auc 0.56450[0m
[92maverage training of epoch 1: loss -0.66817 acc 0.66667 roc_auc 0.38700 prc_auc 0.60152[0m
[93maverage test of epoch 1: loss -0.76830 acc 0.65789 roc_auc 0.22462 prc_auc 0.59637[0m
[92maverage training of epoch 2: loss -0.89967 acc 0.66667 roc_auc 0.42380 prc_auc 0.62831[0m
[93maverage test of epoch 2: loss -1.00422 acc 0.65789 roc_auc 0.35077 prc_auc 0.66886[0m
[92maverage training of epoch 3: loss -1.15021 acc 0.66667 roc_auc 0.46900 prc_auc 0.66949[0m
[93maverage test of epoch 3: loss -1.25491 acc 0.65789 roc_auc 0.74154 prc_auc 0.89789[0m
[92maverage training of epoch 4: loss -1.40657 acc 0.66667 roc_auc 0.52440 prc_auc 0.72534[0m
[93maverage test of epoch 4: loss -1.50098 acc 0.65789 roc_auc 0.90154 prc_auc 0.96226[0m
[92maverage training of epoch 5: loss -1.64457 acc 0.66667 roc_auc 0.56900 prc_auc 0.76365[0m
[93maverage test of epoch 5: loss -1.71951 acc 0.65789 roc_auc 0.93846 prc_auc 0.97373[0m
[92maverage training of epoch 6: loss -1.85175 acc 0.66667 roc_auc 0.59300 prc_auc 0.78317[0m
[93maverage test of epoch 6: loss -1.90912 acc 0.65789 roc_auc 0.95385 prc_auc 0.97886[0m
[92maverage training of epoch 7: loss -2.03451 acc 0.66667 roc_auc 0.59900 prc_auc 0.78529[0m
[93maverage test of epoch 7: loss -2.07993 acc 0.65789 roc_auc 0.95385 prc_auc 0.97886[0m
[92maverage training of epoch 8: loss -2.20251 acc 0.66667 roc_auc 0.59420 prc_auc 0.77938[0m
[93maverage test of epoch 8: loss -2.24034 acc 0.65789 roc_auc 0.95385 prc_auc 0.97886[0m
[92maverage training of epoch 9: loss -2.36303 acc 0.66667 roc_auc 0.58600 prc_auc 0.76974[0m
[93maverage test of epoch 9: loss -2.39676 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 10: loss -2.52250 acc 0.66667 roc_auc 0.57640 prc_auc 0.75980[0m
[93maverage test of epoch 10: loss -2.55596 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 11: loss -2.68883 acc 0.66667 roc_auc 0.56740 prc_auc 0.75221[0m
[93maverage test of epoch 11: loss -2.72716 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 12: loss -2.87215 acc 0.66667 roc_auc 0.55480 prc_auc 0.74029[0m
[93maverage test of epoch 12: loss -2.92063 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 13: loss -3.07932 acc 0.66667 roc_auc 0.53490 prc_auc 0.72373[0m
[93maverage test of epoch 13: loss -3.13699 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 14: loss -3.30125 acc 0.66667 roc_auc 0.51490 prc_auc 0.70845[0m
[93maverage test of epoch 14: loss -3.35731 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 15: loss -3.51670 acc 0.66667 roc_auc 0.50880 prc_auc 0.70448[0m
[93maverage test of epoch 15: loss -3.56255 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 16: loss -3.71447 acc 0.66667 roc_auc 0.50640 prc_auc 0.70391[0m
[93maverage test of epoch 16: loss -3.74956 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 17: loss -3.89567 acc 0.66667 roc_auc 0.50730 prc_auc 0.70448[0m
[93maverage test of epoch 17: loss -3.92233 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 18: loss -4.06446 acc 0.66667 roc_auc 0.51220 prc_auc 0.70759[0m
[93maverage test of epoch 18: loss -4.08502 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 19: loss -4.22459 acc 0.66667 roc_auc 0.52140 prc_auc 0.71593[0m
[93maverage test of epoch 19: loss -4.24119 acc 0.65789 roc_auc 0.94923 prc_auc 0.97644[0m
[92maverage training of epoch 20: loss -4.37953 acc 0.66667 roc_auc 0.53320 prc_auc 0.72502[0m
[93maverage test of epoch 20: loss -4.39420 acc 0.65789 roc_auc 0.95077 prc_auc 0.97702[0m
[92maverage training of epoch 21: loss -4.53219 acc 0.66667 roc_auc 0.54840 prc_auc 0.73973[0m
[93maverage test of epoch 21: loss -4.54595 acc 0.65789 roc_auc 0.94923 prc_auc 0.97644[0m
[92maverage training of epoch 22: loss -4.68341 acc 0.66667 roc_auc 0.55100 prc_auc 0.74332[0m
[93maverage test of epoch 22: loss -4.69568 acc 0.65789 roc_auc 0.94769 prc_auc 0.97490[0m
[92maverage training of epoch 23: loss -4.83174 acc 0.66667 roc_auc 0.54830 prc_auc 0.73861[0m
[93maverage test of epoch 23: loss -4.84152 acc 0.65789 roc_auc 0.94769 prc_auc 0.97555[0m
[92maverage training of epoch 24: loss -4.97561 acc 0.66667 roc_auc 0.53730 prc_auc 0.72789[0m
[93maverage test of epoch 24: loss -4.98249 acc 0.65789 roc_auc 0.95077 prc_auc 0.97663[0m
[92maverage training of epoch 25: loss -5.11458 acc 0.66667 roc_auc 0.52480 prc_auc 0.71593[0m
[93maverage test of epoch 25: loss -5.11866 acc 0.65789 roc_auc 0.95077 prc_auc 0.97663[0m
[92maverage training of epoch 26: loss -5.24894 acc 0.66667 roc_auc 0.51390 prc_auc 0.70460[0m
[93maverage test of epoch 26: loss -5.25047 acc 0.65789 roc_auc 0.95077 prc_auc 0.97663[0m
[92maverage training of epoch 27: loss -5.37919 acc 0.66667 roc_auc 0.50260 prc_auc 0.69504[0m
[93maverage test of epoch 27: loss -5.37848 acc 0.65789 roc_auc 0.94154 prc_auc 0.97246[0m
[92maverage training of epoch 28: loss -5.50587 acc 0.66667 roc_auc 0.48970 prc_auc 0.68250[0m
[93maverage test of epoch 28: loss -5.50319 acc 0.65789 roc_auc 0.95077 prc_auc 0.97663[0m
[92maverage training of epoch 29: loss -5.62947 acc 0.66667 roc_auc 0.48000 prc_auc 0.67549[0m
[93maverage test of epoch 29: loss -5.62506 acc 0.65789 roc_auc 0.94308 prc_auc 0.97264[0m
[92maverage training of epoch 30: loss -5.75041 acc 0.66667 roc_auc 0.46970 prc_auc 0.66748[0m
[93maverage test of epoch 30: loss -5.74448 acc 0.65789 roc_auc 0.94308 prc_auc 0.97264[0m
[92maverage training of epoch 31: loss -5.86905 acc 0.66667 roc_auc 0.46090 prc_auc 0.66116[0m
[93maverage test of epoch 31: loss -5.86176 acc 0.65789 roc_auc 0.95231 prc_auc 0.97663[0m
[92maverage training of epoch 32: loss -5.98568 acc 0.66667 roc_auc 0.45420 prc_auc 0.65794[0m
[93maverage test of epoch 32: loss -5.97718 acc 0.65789 roc_auc 0.94308 prc_auc 0.97264[0m
[92maverage training of epoch 33: loss -6.10056 acc 0.66667 roc_auc 0.44690 prc_auc 0.65211[0m
[93maverage test of epoch 33: loss -6.09098 acc 0.65789 roc_auc 0.94308 prc_auc 0.97264[0m
[92maverage training of epoch 34: loss -6.21391 acc 0.66667 roc_auc 0.44310 prc_auc 0.65129[0m
[93maverage test of epoch 34: loss -6.20334 acc 0.65789 roc_auc 0.95385 prc_auc 0.97663[0m
[92maverage training of epoch 35: loss -6.32591 acc 0.66667 roc_auc 0.43890 prc_auc 0.64692[0m
[93maverage test of epoch 35: loss -6.31443 acc 0.65789 roc_auc 0.95846 prc_auc 0.97574[0m
[92maverage training of epoch 36: loss -6.43670 acc 0.66667 roc_auc 0.43600 prc_auc 0.64547[0m
[93maverage test of epoch 36: loss -6.42440 acc 0.65789 roc_auc 0.94923 prc_auc 0.97264[0m
[92maverage training of epoch 37: loss -6.54643 acc 0.66667 roc_auc 0.43270 prc_auc 0.64393[0m
[93maverage test of epoch 37: loss -6.53336 acc 0.65789 roc_auc 0.94000 prc_auc 0.96603[0m
[92maverage training of epoch 38: loss -6.65521 acc 0.66667 roc_auc 0.42940 prc_auc 0.64132[0m
[93maverage test of epoch 38: loss -6.64143 acc 0.65789 roc_auc 0.95231 prc_auc 0.96803[0m
[92maverage training of epoch 39: loss -6.76314 acc 0.66667 roc_auc 0.42570 prc_auc 0.63770[0m
[93maverage test of epoch 39: loss -6.74869 acc 0.65789 roc_auc 0.94462 prc_auc 0.96805[0m
[92maverage training of epoch 40: loss -6.87030 acc 0.66667 roc_auc 0.42180 prc_auc 0.63674[0m
[93maverage test of epoch 40: loss -6.85523 acc 0.65789 roc_auc 0.96154 prc_auc 0.97298[0m
[92maverage training of epoch 41: loss -6.97676 acc 0.66667 roc_auc 0.41980 prc_auc 0.63508[0m
[93maverage test of epoch 41: loss -6.96111 acc 0.65789 roc_auc 0.91846 prc_auc 0.94492[0m
[92maverage training of epoch 42: loss -7.08261 acc 0.66667 roc_auc 0.41800 prc_auc 0.63389[0m
[93maverage test of epoch 42: loss -7.06640 acc 0.65789 roc_auc 0.90615 prc_auc 0.93892[0m
[92maverage training of epoch 43: loss -7.18790 acc 0.66667 roc_auc 0.41290 prc_auc 0.63101[0m
[93maverage test of epoch 43: loss -7.17116 acc 0.65789 roc_auc 0.91846 prc_auc 0.93804[0m
[92maverage training of epoch 44: loss -7.29267 acc 0.66667 roc_auc 0.41190 prc_auc 0.62851[0m
[93maverage test of epoch 44: loss -7.27543 acc 0.65789 roc_auc 0.93385 prc_auc 0.94632[0m
[92maverage training of epoch 45: loss -7.39698 acc 0.66667 roc_auc 0.40830 prc_auc 0.62580[0m
[93maverage test of epoch 45: loss -7.37926 acc 0.65789 roc_auc 0.88923 prc_auc 0.91529[0m
[92maverage training of epoch 46: loss -7.50088 acc 0.66667 roc_auc 0.40610 prc_auc 0.62438[0m
[93maverage test of epoch 46: loss -7.48270 acc 0.65789 roc_auc 0.89231 prc_auc 0.90632[0m
[92maverage training of epoch 47: loss -7.60439 acc 0.66667 roc_auc 0.40620 prc_auc 0.62431[0m
[93maverage test of epoch 47: loss -7.58576 acc 0.65789 roc_auc 0.72000 prc_auc 0.80842[0m
[92maverage training of epoch 48: loss -7.70755 acc 0.66667 roc_auc 0.40330 prc_auc 0.62350[0m
[93maverage test of epoch 48: loss -7.68850 acc 0.65789 roc_auc 0.84000 prc_auc 0.89053[0m
[92maverage training of epoch 49: loss -7.81039 acc 0.66667 roc_auc 0.40270 prc_auc 0.62364[0m
[93maverage test of epoch 49: loss -7.79093 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.38019 acc 0.66225 roc_auc 0.37039 prc_auc 0.58748[0m
[93maverage test of epoch 0: loss -0.53270 acc 0.67568 roc_auc 0.15333 prc_auc 0.53726[0m
[92maverage training of epoch 1: loss -0.65365 acc 0.66225 roc_auc 0.40980 prc_auc 0.61268[0m
[93maverage test of epoch 1: loss -0.81057 acc 0.67568 roc_auc 0.39333 prc_auc 0.73336[0m
[92maverage training of epoch 2: loss -0.94259 acc 0.66225 roc_auc 0.45039 prc_auc 0.64364[0m
[93maverage test of epoch 2: loss -1.11503 acc 0.67568 roc_auc 0.71667 prc_auc 0.87790[0m
[92maverage training of epoch 3: loss -1.24091 acc 0.66225 roc_auc 0.46765 prc_auc 0.65411[0m
[93maverage test of epoch 3: loss -1.40124 acc 0.67568 roc_auc 0.83667 prc_auc 0.92112[0m
[92maverage training of epoch 4: loss -1.50278 acc 0.66225 roc_auc 0.46373 prc_auc 0.65024[0m
[93maverage test of epoch 4: loss -1.64326 acc 0.67568 roc_auc 0.84167 prc_auc 0.92028[0m
[92maverage training of epoch 5: loss -1.72676 acc 0.66225 roc_auc 0.45157 prc_auc 0.64025[0m
[93maverage test of epoch 5: loss -1.85583 acc 0.67568 roc_auc 0.84000 prc_auc 0.92019[0m
[92maverage training of epoch 6: loss -1.92836 acc 0.66225 roc_auc 0.43941 prc_auc 0.62958[0m
[93maverage test of epoch 6: loss -2.05127 acc 0.67568 roc_auc 0.83667 prc_auc 0.92298[0m
[92maverage training of epoch 7: loss -2.11722 acc 0.66225 roc_auc 0.43569 prc_auc 0.62651[0m
[93maverage test of epoch 7: loss -2.23785 acc 0.67568 roc_auc 0.84333 prc_auc 0.92023[0m
[92maverage training of epoch 8: loss -2.30254 acc 0.66225 roc_auc 0.43941 prc_auc 0.63060[0m
[93maverage test of epoch 8: loss -2.42659 acc 0.67568 roc_auc 0.83667 prc_auc 0.92082[0m
[92maverage training of epoch 9: loss -2.49639 acc 0.66225 roc_auc 0.44725 prc_auc 0.63957[0m
[93maverage test of epoch 9: loss -2.62982 acc 0.67568 roc_auc 0.82667 prc_auc 0.91300[0m
[92maverage training of epoch 10: loss -2.70775 acc 0.66225 roc_auc 0.45441 prc_auc 0.64529[0m
[93maverage test of epoch 10: loss -2.85276 acc 0.67568 roc_auc 0.84000 prc_auc 0.92021[0m
[92maverage training of epoch 11: loss -2.93779 acc 0.66225 roc_auc 0.45608 prc_auc 0.64771[0m
[93maverage test of epoch 11: loss -3.09386 acc 0.67568 roc_auc 0.83667 prc_auc 0.91945[0m
[92maverage training of epoch 12: loss -3.18236 acc 0.66225 roc_auc 0.45765 prc_auc 0.64907[0m
[93maverage test of epoch 12: loss -3.34469 acc 0.67568 roc_auc 0.85000 prc_auc 0.92424[0m
[92maverage training of epoch 13: loss -3.42744 acc 0.66225 roc_auc 0.45941 prc_auc 0.65057[0m
[93maverage test of epoch 13: loss -3.58529 acc 0.67568 roc_auc 0.85667 prc_auc 0.92813[0m
[92maverage training of epoch 14: loss -3.65438 acc 0.66225 roc_auc 0.45980 prc_auc 0.65009[0m
[93maverage test of epoch 14: loss -3.80166 acc 0.67568 roc_auc 0.86333 prc_auc 0.93369[0m
[92maverage training of epoch 15: loss -3.85761 acc 0.66225 roc_auc 0.46255 prc_auc 0.65172[0m
[93maverage test of epoch 15: loss -3.99656 acc 0.67568 roc_auc 0.86167 prc_auc 0.93294[0m
[92maverage training of epoch 16: loss -4.04425 acc 0.66225 roc_auc 0.46039 prc_auc 0.64964[0m
[93maverage test of epoch 16: loss -4.18086 acc 0.67568 roc_auc 0.87000 prc_auc 0.93779[0m
[92maverage training of epoch 17: loss -4.22680 acc 0.66225 roc_auc 0.45843 prc_auc 0.65084[0m
[93maverage test of epoch 17: loss -4.36950 acc 0.67568 roc_auc 0.86667 prc_auc 0.93494[0m
[92maverage training of epoch 18: loss -4.42029 acc 0.66225 roc_auc 0.46824 prc_auc 0.66509[0m
[93maverage test of epoch 18: loss -4.57409 acc 0.67568 roc_auc 0.81000 prc_auc 0.90602[0m
[92maverage training of epoch 19: loss -4.62257 acc 0.66225 roc_auc 0.50294 prc_auc 0.69632[0m
[93maverage test of epoch 19: loss -4.76983 acc 0.67568 roc_auc 0.84667 prc_auc 0.91927[0m
[92maverage training of epoch 20: loss -4.80303 acc 0.66225 roc_auc 0.52324 prc_auc 0.70796[0m
[93maverage test of epoch 20: loss -4.93853 acc 0.67568 roc_auc 0.85000 prc_auc 0.92040[0m
[92maverage training of epoch 21: loss -4.96199 acc 0.66225 roc_auc 0.51363 prc_auc 0.69410[0m
[93maverage test of epoch 21: loss -5.09240 acc 0.67568 roc_auc 0.85667 prc_auc 0.92293[0m
[92maverage training of epoch 22: loss -5.10978 acc 0.66225 roc_auc 0.49980 prc_auc 0.68168[0m
[93maverage test of epoch 22: loss -5.23742 acc 0.67568 roc_auc 0.85667 prc_auc 0.92293[0m
[92maverage training of epoch 23: loss -5.25033 acc 0.66225 roc_auc 0.48941 prc_auc 0.67497[0m
[93maverage test of epoch 23: loss -5.37612 acc 0.67568 roc_auc 0.85667 prc_auc 0.92293[0m
[92maverage training of epoch 24: loss -5.38545 acc 0.66225 roc_auc 0.47765 prc_auc 0.66535[0m
[93maverage test of epoch 24: loss -5.50988 acc 0.67568 roc_auc 0.85667 prc_auc 0.92293[0m
[92maverage training of epoch 25: loss -5.51622 acc 0.66225 roc_auc 0.46510 prc_auc 0.65602[0m
[93maverage test of epoch 25: loss -5.63961 acc 0.67568 roc_auc 0.85667 prc_auc 0.92293[0m
[92maverage training of epoch 26: loss -5.64339 acc 0.66225 roc_auc 0.45725 prc_auc 0.65031[0m
[93maverage test of epoch 26: loss -5.76599 acc 0.67568 roc_auc 0.85667 prc_auc 0.92293[0m
[92maverage training of epoch 27: loss -5.76754 acc 0.66225 roc_auc 0.44902 prc_auc 0.64439[0m
[93maverage test of epoch 27: loss -5.88951 acc 0.67568 roc_auc 0.85667 prc_auc 0.92312[0m
[92maverage training of epoch 28: loss -5.88907 acc 0.66225 roc_auc 0.44206 prc_auc 0.63682[0m
[93maverage test of epoch 28: loss -6.01057 acc 0.67568 roc_auc 0.85667 prc_auc 0.92327[0m
[92maverage training of epoch 29: loss -6.00836 acc 0.66225 roc_auc 0.43843 prc_auc 0.63465[0m
[93maverage test of epoch 29: loss -6.12949 acc 0.67568 roc_auc 0.85667 prc_auc 0.92308[0m
[92maverage training of epoch 30: loss -6.12568 acc 0.66225 roc_auc 0.43235 prc_auc 0.62787[0m
[93maverage test of epoch 30: loss -6.24654 acc 0.67568 roc_auc 0.85667 prc_auc 0.92327[0m
[92maverage training of epoch 31: loss -6.24127 acc 0.66225 roc_auc 0.42784 prc_auc 0.62333[0m
[93maverage test of epoch 31: loss -6.36193 acc 0.67568 roc_auc 0.85667 prc_auc 0.92381[0m
[92maverage training of epoch 32: loss -6.35533 acc 0.66225 roc_auc 0.42353 prc_auc 0.62030[0m
[93maverage test of epoch 32: loss -6.47587 acc 0.67568 roc_auc 0.86000 prc_auc 0.92337[0m
[92maverage training of epoch 33: loss -6.46804 acc 0.66225 roc_auc 0.41902 prc_auc 0.61634[0m
[93maverage test of epoch 33: loss -6.58850 acc 0.67568 roc_auc 0.85667 prc_auc 0.92353[0m
[92maverage training of epoch 34: loss -6.57953 acc 0.66225 roc_auc 0.41627 prc_auc 0.61265[0m
[93maverage test of epoch 34: loss -6.69997 acc 0.67568 roc_auc 0.85667 prc_auc 0.92419[0m
[92maverage training of epoch 35: loss -6.68994 acc 0.66225 roc_auc 0.41314 prc_auc 0.61046[0m
[93maverage test of epoch 35: loss -6.81041 acc 0.67568 roc_auc 0.86000 prc_auc 0.92419[0m
[92maverage training of epoch 36: loss -6.79938 acc 0.66225 roc_auc 0.41196 prc_auc 0.61016[0m
[93maverage test of epoch 36: loss -6.91991 acc 0.67568 roc_auc 0.85833 prc_auc 0.92070[0m
[92maverage training of epoch 37: loss -6.90794 acc 0.66225 roc_auc 0.41000 prc_auc 0.60959[0m
[93maverage test of epoch 37: loss -7.02857 acc 0.67568 roc_auc 0.86000 prc_auc 0.92174[0m
[92maverage training of epoch 38: loss -7.01572 acc 0.66225 roc_auc 0.40833 prc_auc 0.60785[0m
[93maverage test of epoch 38: loss -7.13648 acc 0.67568 roc_auc 0.85833 prc_auc 0.91670[0m
[92maverage training of epoch 39: loss -7.12279 acc 0.66225 roc_auc 0.40686 prc_auc 0.60640[0m
[93maverage test of epoch 39: loss -7.24370 acc 0.67568 roc_auc 0.85833 prc_auc 0.92106[0m
[92maverage training of epoch 40: loss -7.22922 acc 0.66225 roc_auc 0.40480 prc_auc 0.60503[0m
[93maverage test of epoch 40: loss -7.35031 acc 0.67568 roc_auc 0.86167 prc_auc 0.92211[0m
[92maverage training of epoch 41: loss -7.33507 acc 0.66225 roc_auc 0.40451 prc_auc 0.60532[0m
[93maverage test of epoch 41: loss -7.45635 acc 0.67568 roc_auc 0.85500 prc_auc 0.91722[0m
[92maverage training of epoch 42: loss -7.44039 acc 0.66225 roc_auc 0.40324 prc_auc 0.60445[0m
[93maverage test of epoch 42: loss -7.56189 acc 0.67568 roc_auc 0.86167 prc_auc 0.91876[0m
[92maverage training of epoch 43: loss -7.54524 acc 0.66225 roc_auc 0.40108 prc_auc 0.60294[0m
[93maverage test of epoch 43: loss -7.66697 acc 0.67568 roc_auc 0.85167 prc_auc 0.90009[0m
[92maverage training of epoch 44: loss -7.64965 acc 0.66225 roc_auc 0.39961 prc_auc 0.60201[0m
[93maverage test of epoch 44: loss -7.77164 acc 0.67568 roc_auc 0.85500 prc_auc 0.91801[0m
[92maverage training of epoch 45: loss -7.75367 acc 0.66225 roc_auc 0.39922 prc_auc 0.60119[0m
[93maverage test of epoch 45: loss -7.87592 acc 0.67568 roc_auc 0.84500 prc_auc 0.89349[0m
[92maverage training of epoch 46: loss -7.85733 acc 0.66225 roc_auc 0.39745 prc_auc 0.59996[0m
[93maverage test of epoch 46: loss -7.97986 acc 0.67568 roc_auc 0.87333 prc_auc 0.92239[0m
[92maverage training of epoch 47: loss -7.96066 acc 0.66225 roc_auc 0.39578 prc_auc 0.59871[0m
[93maverage test of epoch 47: loss -8.08349 acc 0.67568 roc_auc 0.84667 prc_auc 0.90526[0m
[92maverage training of epoch 48: loss -8.06369 acc 0.66225 roc_auc 0.39265 prc_auc 0.58937[0m
[93maverage test of epoch 48: loss -8.18683 acc 0.67568 roc_auc 0.86000 prc_auc 0.89762[0m
[92maverage training of epoch 49: loss -8.16646 acc 0.66225 roc_auc 0.39069 prc_auc 0.58775[0m
[93maverage test of epoch 49: loss -8.28991 acc 0.67568 roc_auc 0.83667 prc_auc 0.87743[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss 0.02463 acc 0.64901 roc_auc 0.32118 prc_auc 0.57018[0m
[93maverage test of epoch 0: loss -0.05657 acc 0.67568 roc_auc 0.33667 prc_auc 0.68251[0m
[92maverage training of epoch 1: loss -0.13015 acc 0.66225 roc_auc 0.41863 prc_auc 0.65092[0m
[93maverage test of epoch 1: loss -0.21308 acc 0.67568 roc_auc 0.57000 prc_auc 0.82014[0m
[92maverage training of epoch 2: loss -0.28047 acc 0.66225 roc_auc 0.52863 prc_auc 0.74039[0m
[93maverage test of epoch 2: loss -0.36097 acc 0.67568 roc_auc 0.87333 prc_auc 0.95242[0m
[92maverage training of epoch 3: loss -0.42212 acc 0.66225 roc_auc 0.63196 prc_auc 0.80947[0m
[93maverage test of epoch 3: loss -0.50219 acc 0.67568 roc_auc 0.92667 prc_auc 0.97175[0m
[92maverage training of epoch 4: loss -0.56140 acc 0.66225 roc_auc 0.70824 prc_auc 0.85322[0m
[93maverage test of epoch 4: loss -0.64557 acc 0.67568 roc_auc 0.92667 prc_auc 0.97247[0m
[92maverage training of epoch 5: loss -0.70418 acc 0.66225 roc_auc 0.78275 prc_auc 0.88847[0m
[93maverage test of epoch 5: loss -0.79254 acc 0.67568 roc_auc 0.93000 prc_auc 0.97420[0m
[92maverage training of epoch 6: loss -0.84934 acc 0.66225 roc_auc 0.84471 prc_auc 0.91364[0m
[93maverage test of epoch 6: loss -0.94136 acc 0.67568 roc_auc 0.93667 prc_auc 0.97575[0m
[92maverage training of epoch 7: loss -0.99704 acc 0.66225 roc_auc 0.86490 prc_auc 0.92435[0mUsing backend: pytorch
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))

[93maverage test of epoch 7: loss -1.09561 acc 0.67568 roc_auc 0.94000 prc_auc 0.97659[0m
[92maverage training of epoch 8: loss -1.15094 acc 0.66225 roc_auc 0.86471 prc_auc 0.92474[0m
[93maverage test of epoch 8: loss -1.26039 acc 0.67568 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 9: loss -1.31394 acc 0.66225 roc_auc 0.86569 prc_auc 0.92572[0m
[93maverage test of epoch 9: loss -1.43398 acc 0.67568 roc_auc 0.94000 prc_auc 0.97574[0m
[92maverage training of epoch 10: loss -1.48428 acc 0.66225 roc_auc 0.87039 prc_auc 0.92967[0m
[93maverage test of epoch 10: loss -1.61122 acc 0.67568 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 11: loss -1.66220 acc 0.66225 roc_auc 0.87176 prc_auc 0.93098[0m
[93maverage test of epoch 11: loss -1.79716 acc 0.67568 roc_auc 0.94000 prc_auc 0.97659[0m
[92maverage training of epoch 12: loss -1.85341 acc 0.66225 roc_auc 0.87235 prc_auc 0.93228[0m
[93maverage test of epoch 12: loss -1.99758 acc 0.67568 roc_auc 0.93667 prc_auc 0.97575[0m
[92maverage training of epoch 13: loss -2.05737 acc 0.66225 roc_auc 0.87196 prc_auc 0.93236[0m
[93maverage test of epoch 13: loss -2.20243 acc 0.67568 roc_auc 0.93667 prc_auc 0.97575[0m
[92maverage training of epoch 14: loss -2.26460 acc 0.72848 roc_auc 0.87627 prc_auc 0.93503[0m
[93maverage test of epoch 14: loss -2.39995 acc 0.83784 roc_auc 0.93333 prc_auc 0.97496[0m
[92maverage training of epoch 15: loss -2.46348 acc 0.82119 roc_auc 0.87863 prc_auc 0.93612[0m
[93maverage test of epoch 15: loss -2.58571 acc 0.83784 roc_auc 0.93000 prc_auc 0.97420[0m
[92maverage training of epoch 16: loss -2.64701 acc 0.82781 roc_auc 0.88020 prc_auc 0.93668[0m
[93maverage test of epoch 16: loss -2.75830 acc 0.83784 roc_auc 0.93000 prc_auc 0.97420[0m
[92maverage training of epoch 17: loss -2.81465 acc 0.83444 roc_auc 0.87804 prc_auc 0.93575[0m
[93maverage test of epoch 17: loss -2.91545 acc 0.83784 roc_auc 0.94000 prc_auc 0.97659[0m
[92maverage training of epoch 18: loss -2.96542 acc 0.83444 roc_auc 0.87216 prc_auc 0.93302[0m
[93maverage test of epoch 18: loss -3.05664 acc 0.83784 roc_auc 0.94000 prc_auc 0.97659[0m
[92maverage training of epoch 19: loss -3.10025 acc 0.82781 roc_auc 0.87059 prc_auc 0.93183[0m
[93maverage test of epoch 19: loss -3.18613 acc 0.83784 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 20: loss -3.22387 acc 0.82781 roc_auc 0.86961 prc_auc 0.93104[0m
[93maverage test of epoch 20: loss -3.30801 acc 0.83784 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 21: loss -3.34098 acc 0.83444 roc_auc 0.86843 prc_auc 0.92999[0m
[93maverage test of epoch 21: loss -3.42457 acc 0.83784 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 22: loss -3.45451 acc 0.83444 roc_auc 0.86784 prc_auc 0.92904[0m
[93maverage test of epoch 22: loss -3.53712 acc 0.83784 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 23: loss -3.56547 acc 0.83444 roc_auc 0.86784 prc_auc 0.92871[0m
[93maverage test of epoch 23: loss -3.64648 acc 0.83784 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 24: loss -3.67356 acc 0.83444 roc_auc 0.86725 prc_auc 0.92801[0m
[93maverage test of epoch 24: loss -3.75342 acc 0.83784 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 25: loss -3.77863 acc 0.83444 roc_auc 0.86490 prc_auc 0.92573[0m
[93maverage test of epoch 25: loss -3.85873 acc 0.83784 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 26: loss -3.88186 acc 0.83444 roc_auc 0.86353 prc_auc 0.92442[0m
[93maverage test of epoch 26: loss -3.96292 acc 0.83784 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 27: loss -3.98417 acc 0.83444 roc_auc 0.86078 prc_auc 0.92233[0m
[93maverage test of epoch 27: loss -4.06619 acc 0.83784 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 28: loss -4.08576 acc 0.83444 roc_auc 0.85922 prc_auc 0.92115[0m
[93maverage test of epoch 28: loss -4.16879 acc 0.83784 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 29: loss -4.18667 acc 0.83444 roc_auc 0.85725 prc_auc 0.91895[0m
[93maverage test of epoch 29: loss -4.27091 acc 0.83784 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 30: loss -4.28699 acc 0.83444 roc_auc 0.85451 prc_auc 0.91404[0m
[93maverage test of epoch 30: loss -4.37265 acc 0.83784 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 31: loss -4.38700 acc 0.83444 roc_auc 0.85294 prc_auc 0.91107[0m
[93maverage test of epoch 31: loss -4.47414 acc 0.83784 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 32: loss -4.48635 acc 0.83444 roc_auc 0.85039 prc_auc 0.90870[0m
[93maverage test of epoch 32: loss -4.57528 acc 0.83784 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 33: loss -4.58505 acc 0.83444 roc_auc 0.84578 prc_auc 0.90259[0m
[93maverage test of epoch 33: loss -4.67597 acc 0.83784 roc_auc 0.94000 prc_auc 0.97659[0m
[92maverage training of epoch 34: loss -4.68347 acc 0.83444 roc_auc 0.84255 prc_auc 0.89905[0m
[93maverage test of epoch 34: loss -4.77628 acc 0.83784 roc_auc 0.94000 prc_auc 0.97659[0m
[92maverage training of epoch 35: loss -4.78115 acc 0.83444 roc_auc 0.83931 prc_auc 0.89543[0m
[93maverage test of epoch 35: loss -4.87599 acc 0.83784 roc_auc 0.94333 prc_auc 0.97777[0m
[92maverage training of epoch 36: loss -4.87863 acc 0.83444 roc_auc 0.83431 prc_auc 0.89112[0m
[93maverage test of epoch 36: loss -4.97533 acc 0.83784 roc_auc 0.94333 prc_auc 0.97777[0m
[92maverage training of epoch 37: loss -4.97388 acc 0.83444 roc_auc 0.83176 prc_auc 0.88685[0m
[93maverage test of epoch 37: loss -5.07323 acc 0.83784 roc_auc 0.94333 prc_auc 0.97777[0m
[92maverage training of epoch 38: loss -5.07080 acc 0.83444 roc_auc 0.82275 prc_auc 0.87831[0m
[93maverage test of epoch 38: loss -5.17105 acc 0.83784 roc_auc 0.94000 prc_auc 0.97693[0m
[92maverage training of epoch 39: loss -5.14361 acc 0.82781 roc_auc 0.82049 prc_auc 0.87614[0m
[93maverage test of epoch 39: loss -5.26777 acc 0.83784 roc_auc 0.94000 prc_auc 0.97693[0m
[92maverage training of epoch 40: loss -5.23913 acc 0.82781 roc_auc 0.81520 prc_auc 0.87078[0m
[93maverage test of epoch 40: loss -5.36358 acc 0.83784 roc_auc 0.94000 prc_auc 0.97693[0m
[92maverage training of epoch 41: loss -5.33012 acc 0.82781 roc_auc 0.81020 prc_auc 0.86461[0m
[93maverage test of epoch 41: loss -5.45876 acc 0.83784 roc_auc 0.94000 prc_auc 0.97693[0m
[92maverage training of epoch 42: loss -5.42200 acc 0.82781 roc_auc 0.80304 prc_auc 0.85968[0m
[93maverage test of epoch 42: loss -5.55378 acc 0.83784 roc_auc 0.94000 prc_auc 0.97693[0m
[92maverage training of epoch 43: loss -5.49201 acc 0.82119 roc_auc 0.80549 prc_auc 0.85979[0m
[93maverage test of epoch 43: loss -5.64781 acc 0.83784 roc_auc 0.94000 prc_auc 0.97693[0m
[92maverage training of epoch 44: loss -5.60569 acc 0.82781 roc_auc 0.79353 prc_auc 0.84892[0m
[93maverage test of epoch 44: loss -5.74165 acc 0.83784 roc_auc 0.94000 prc_auc 0.97693[0m
[92maverage training of epoch 45: loss -5.70203 acc 0.82781 roc_auc 0.79676 prc_auc 0.85129[0m
[93maverage test of epoch 45: loss -5.83574 acc 0.83784 roc_auc 0.94000 prc_auc 0.97693[0m
[92maverage training of epoch 46: loss -5.78989 acc 0.82781 roc_auc 0.78804 prc_auc 0.84433[0m
[93maverage test of epoch 46: loss -5.92925 acc 0.83784 roc_auc 0.93667 prc_auc 0.97614[0m
[92maverage training of epoch 47: loss -5.88551 acc 0.82781 roc_auc 0.79294 prc_auc 0.84741[0m
[93maverage test of epoch 47: loss -6.02290 acc 0.83784 roc_auc 0.94000 prc_auc 0.97693[0m
[92maverage training of epoch 48: loss -5.96977 acc 0.82781 roc_auc 0.78431 prc_auc 0.84037[0m
[93maverage test of epoch 48: loss -6.11626 acc 0.83784 roc_auc 0.93333 prc_auc 0.97539[0m
[92maverage training of epoch 49: loss -6.06845 acc 0.82781 roc_auc 0.78696 prc_auc 0.84241[0m
[93maverage test of epoch 49: loss -6.20975 acc 0.83784 roc_auc 0.94000 prc_auc 0.97693[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.0001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.69744 ROC_AUC (avg): 0.66487 PRC_AUC (avg): 0.80381 

Average forward propagation time taken(ms): 2.4714846255054623
Average backward propagation time taken(ms): 0.8706036741825987

