# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 1)
('lr', 0.0001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-01-29-55/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-01-29-55/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 8,
 'epochs': 100,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 8,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.0001,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 1,
 'num_workers': 8,
 'number_of_mlp_layer': 1,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-18-01-29-55',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 100, 'learning_rate': 0.0001, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.16459 acc 0.66667 roc_auc 0.30380 prc_auc 0.55026[0m
[93maverage test of epoch 0: loss -0.26427 acc 0.65789 roc_auc 0.18769 prc_auc 0.54101[0m
[92maverage training of epoch 1: loss -0.38890 acc 0.66667 roc_auc 0.32400 prc_auc 0.56348[0m
[93maverage test of epoch 1: loss -0.50919 acc 0.65789 roc_auc 0.22462 prc_auc 0.56786[0m
[92maverage training of epoch 2: loss -0.65527 acc 0.66667 roc_auc 0.34800 prc_auc 0.57518[0m
[93maverage test of epoch 2: loss -0.80028 acc 0.65789 roc_auc 0.40000 prc_auc 0.71349[0m
[92maverage training of epoch 3: loss -1.04954 acc 0.66667 roc_auc 0.39740 prc_auc 0.62001[0m
[93maverage test of epoch 3: loss -1.27866 acc 0.65789 roc_auc 0.74769 prc_auc 0.90192[0m
[92maverage training of epoch 4: loss -1.49922 acc 0.66667 roc_auc 0.36600 prc_auc 0.58574[0m
[93maverage test of epoch 4: loss -1.69771 acc 0.65789 roc_auc 0.60462 prc_auc 0.83299[0m
[92maverage training of epoch 5: loss -1.90414 acc 0.66667 roc_auc 0.28260 prc_auc 0.53861[0m
[93maverage test of epoch 5: loss -2.09519 acc 0.65789 roc_auc 0.14769 prc_auc 0.51475[0m
[92maverage training of epoch 6: loss -2.32318 acc 0.66667 roc_auc 0.23740 prc_auc 0.52053[0m
[93maverage test of epoch 6: loss -2.53614 acc 0.65789 roc_auc 0.12923 prc_auc 0.49040[0m
[92maverage training of epoch 7: loss -2.76683 acc 0.66667 roc_auc 0.25680 prc_auc 0.52415[0m
[93maverage test of epoch 7: loss -2.96704 acc 0.65789 roc_auc 0.12000 prc_auc 0.48415[0m
[92maverage training of epoch 8: loss -3.17747 acc 0.66667 roc_auc 0.31960 prc_auc 0.55596[0m
[93maverage test of epoch 8: loss -3.35810 acc 0.65789 roc_auc 0.11385 prc_auc 0.48204[0m
[92maverage training of epoch 9: loss -3.56015 acc 0.66667 roc_auc 0.34480 prc_auc 0.57198[0m
[93maverage test of epoch 9: loss -3.73154 acc 0.65789 roc_auc 0.12154 prc_auc 0.48314[0m
[92maverage training of epoch 10: loss -3.93207 acc 0.66667 roc_auc 0.36540 prc_auc 0.58437[0m
[93maverage test of epoch 10: loss -4.09930 acc 0.65789 roc_auc 0.12615 prc_auc 0.48525[0m
[92maverage training of epoch 11: loss -4.30166 acc 0.66667 roc_auc 0.37220 prc_auc 0.58990[0m
[93maverage test of epoch 11: loss -4.46757 acc 0.65789 roc_auc 0.13538 prc_auc 0.48714[0m
[92maverage training of epoch 12: loss -4.67145 acc 0.66667 roc_auc 0.37580 prc_auc 0.59263[0m
[93maverage test of epoch 12: loss -4.83444 acc 0.65789 roc_auc 0.18154 prc_auc 0.53870[0m
[92maverage training of epoch 13: loss -5.04367 acc 0.66667 roc_auc 0.37580 prc_auc 0.59354[0m
[93maverage test of epoch 13: loss -5.20913 acc 0.65789 roc_auc 0.18923 prc_auc 0.53441[0m
[92maverage training of epoch 14: loss -5.42684 acc 0.66667 roc_auc 0.37420 prc_auc 0.59318[0m
[93maverage test of epoch 14: loss -5.59578 acc 0.65789 roc_auc 0.13846 prc_auc 0.49353[0m
[92maverage training of epoch 15: loss -5.82270 acc 0.66667 roc_auc 0.37120 prc_auc 0.58878[0m
[93maverage test of epoch 15: loss -5.99376 acc 0.65789 roc_auc 0.14308 prc_auc 0.50174[0m
[92maverage training of epoch 16: loss -6.22801 acc 0.66667 roc_auc 0.36390 prc_auc 0.58429[0m
[93maverage test of epoch 16: loss -6.39738 acc 0.65789 roc_auc 0.14154 prc_auc 0.49792[0m
[92maverage training of epoch 17: loss -6.63528 acc 0.66667 roc_auc 0.36160 prc_auc 0.58111[0m
[93maverage test of epoch 17: loss -6.79919 acc 0.65789 roc_auc 0.13385 prc_auc 0.49309[0m
[92maverage training of epoch 18: loss -7.03791 acc 0.66667 roc_auc 0.36460 prc_auc 0.58215[0m
[93maverage test of epoch 18: loss -7.19545 acc 0.65789 roc_auc 0.13538 prc_auc 0.49219[0m
[92maverage training of epoch 19: loss -7.43430 acc 0.66667 roc_auc 0.37410 prc_auc 0.59711[0m
[93maverage test of epoch 19: loss -7.58685 acc 0.65789 roc_auc 0.14769 prc_auc 0.49248[0m
[92maverage training of epoch 20: loss -7.82657 acc 0.66667 roc_auc 0.38470 prc_auc 0.60482[0m
[93maverage test of epoch 20: loss -7.97601 acc 0.65789 roc_auc 0.20462 prc_auc 0.52093[0m
[92maverage training of epoch 21: loss -8.21755 acc 0.66667 roc_auc 0.39290 prc_auc 0.61531[0m
[93maverage test of epoch 21: loss -8.36527 acc 0.65789 roc_auc 0.25077 prc_auc 0.59913[0m
[92maverage training of epoch 22: loss -8.60929 acc 0.66667 roc_auc 0.39840 prc_auc 0.61857[0m
[93maverage test of epoch 22: loss -8.75621 acc 0.65789 roc_auc 0.23846 prc_auc 0.60217[0m
[92maverage training of epoch 23: loss -9.00333 acc 0.66667 roc_auc 0.40060 prc_auc 0.61920[0m
[93maverage test of epoch 23: loss -9.15019 acc 0.65789 roc_auc 0.28462 prc_auc 0.61580[0m
[92maverage training of epoch 24: loss -9.40086 acc 0.66667 roc_auc 0.40160 prc_auc 0.61959[0m
[93maverage test of epoch 24: loss -9.54819 acc 0.65789 roc_auc 0.49538 prc_auc 0.75931[0m
[92maverage training of epoch 25: loss -9.80272 acc 0.66667 roc_auc 0.40110 prc_auc 0.61952[0m
[93maverage test of epoch 25: loss -9.95092 acc 0.65789 roc_auc 0.50462 prc_auc 0.76009[0m
[92maverage training of epoch 26: loss -10.20956 acc 0.66667 roc_auc 0.39970 prc_auc 0.61816[0m
[93maverage test of epoch 26: loss -10.35892 acc 0.65789 roc_auc 0.51385 prc_auc 0.76355[0m
[92maverage training of epoch 27: loss -10.62187 acc 0.66667 roc_auc 0.39840 prc_auc 0.61656[0m
[93maverage test of epoch 27: loss -10.77263 acc 0.65789 roc_auc 0.61692 prc_auc 0.79333[0m
[92maverage training of epoch 28: loss -11.03995 acc 0.66667 roc_auc 0.39660 prc_auc 0.61538[0m
[93maverage test of epoch 28: loss -11.19217 acc 0.65789 roc_auc 0.62000 prc_auc 0.78560[0m
[92maverage training of epoch 29: loss -11.46387 acc 0.66667 roc_auc 0.39440 prc_auc 0.61331[0m
[93maverage test of epoch 29: loss -11.61768 acc 0.65789 roc_auc 0.70769 prc_auc 0.81994[0m
[92maverage training of epoch 30: loss -11.89388 acc 0.66667 roc_auc 0.39230 prc_auc 0.61202[0m
[93maverage test of epoch 30: loss -12.04944 acc 0.65789 roc_auc 0.73077 prc_auc 0.82178[0m
[92maverage training of epoch 31: loss -12.33024 acc 0.66667 roc_auc 0.39060 prc_auc 0.61154[0m
[93maverage test of epoch 31: loss -12.48769 acc 0.65789 roc_auc 0.71077 prc_auc 0.80478[0m
[92maverage training of epoch 32: loss -12.77319 acc 0.66667 roc_auc 0.38850 prc_auc 0.60875[0m
[93maverage test of epoch 32: loss -12.93267 acc 0.65789 roc_auc 0.74462 prc_auc 0.80463[0m
[92maverage training of epoch 33: loss -13.22294 acc 0.66667 roc_auc 0.38680 prc_auc 0.60733[0m
[93maverage test of epoch 33: loss -13.38456 acc 0.65789 roc_auc 0.63077 prc_auc 0.74054[0m
[92maverage training of epoch 34: loss -13.67968 acc 0.66667 roc_auc 0.38550 prc_auc 0.60725[0m
[93maverage test of epoch 34: loss -13.84354 acc 0.65789 roc_auc 0.81385 prc_auc 0.85026[0m
[92maverage training of epoch 35: loss -14.14358 acc 0.66667 roc_auc 0.38450 prc_auc 0.60665[0m
[93maverage test of epoch 35: loss -14.30979 acc 0.65789 roc_auc 0.60000 prc_auc 0.72632[0m
[92maverage training of epoch 36: loss -14.61481 acc 0.66667 roc_auc 0.38250 prc_auc 0.60390[0m
[93maverage test of epoch 36: loss -14.78345 acc 0.65789 roc_auc 0.64000 prc_auc 0.75368[0m
[92maverage training of epoch 37: loss -15.09352 acc 0.66667 roc_auc 0.38160 prc_auc 0.60341[0m
[93maverage test of epoch 37: loss -15.26468 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -15.57978 acc 0.66667 roc_auc 0.37820 prc_auc 0.60146[0m
[93maverage test of epoch 38: loss -15.75334 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -16.07314 acc 0.66667 roc_auc 0.37710 prc_auc 0.59905[0m
[93maverage test of epoch 39: loss -16.24891 acc 0.65789 roc_auc 0.60000 prc_auc 0.72632[0m
[92maverage training of epoch 40: loss -16.57345 acc 0.66667 roc_auc 0.37520 prc_auc 0.59641[0m
[93maverage test of epoch 40: loss -16.75155 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -17.08095 acc 0.66667 roc_auc 0.37580 prc_auc 0.59704[0m
[93maverage test of epoch 41: loss -17.26153 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -17.59591 acc 0.66667 roc_auc 0.37480 prc_auc 0.59802[0m
[93maverage test of epoch 42: loss -17.77910 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -18.11855 acc 0.66667 roc_auc 0.37200 prc_auc 0.59212[0m
[93maverage test of epoch 43: loss -18.30446 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -18.64907 acc 0.66667 roc_auc 0.36910 prc_auc 0.58821[0m
[93maverage test of epoch 44: loss -18.83781 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -19.18766 acc 0.66667 roc_auc 0.36930 prc_auc 0.58795[0m
[93maverage test of epoch 45: loss -19.37931 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -19.73447 acc 0.66667 roc_auc 0.36700 prc_auc 0.58585[0m
[93maverage test of epoch 46: loss -19.92912 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -20.28966 acc 0.66667 roc_auc 0.36760 prc_auc 0.58764[0m
[93maverage test of epoch 47: loss -20.48738 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -20.85335 acc 0.66667 roc_auc 0.37010 prc_auc 0.59097[0m
[93maverage test of epoch 48: loss -21.05422 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -21.42569 acc 0.66667 roc_auc 0.36530 prc_auc 0.59108[0m
[93maverage test of epoch 49: loss -21.62976 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 50: loss -22.00677 acc 0.66667 roc_auc 0.36480 prc_auc 0.58888[0m
[93maverage test of epoch 50: loss -22.21411 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 51: loss -22.59670 acc 0.66667 roc_auc 0.37210 prc_auc 0.58824[0m
[93maverage test of epoch 51: loss -22.80736 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 52: loss -23.19559 acc 0.66667 roc_auc 0.36570 prc_auc 0.58527[0m
[93maverage test of epoch 52: loss -23.40961 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 53: loss -23.80352 acc 0.66667 roc_auc 0.37180 prc_auc 0.58535[0m
[93maverage test of epoch 53: loss -24.02094 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 54: loss -24.42057 acc 0.66667 roc_auc 0.36680 prc_auc 0.58076[0m
[93maverage test of epoch 54: loss -24.64143 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 55: loss -25.04681 acc 0.66667 roc_auc 0.36700 prc_auc 0.58051[0m
[93maverage test of epoch 55: loss -25.27116 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 56: loss -25.68233 acc 0.66667 roc_auc 0.37050 prc_auc 0.58603[0m
[93maverage test of epoch 56: loss -25.91019 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 57: loss -26.32717 acc 0.66667 roc_auc 0.37350 prc_auc 0.59001[0m
[93maverage test of epoch 57: loss -26.55858 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 58: loss -26.98141 acc 0.66667 roc_auc 0.37660 prc_auc 0.58996[0m
[93maverage test of epoch 58: loss -27.21638 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 59: loss -27.64509 acc 0.66667 roc_auc 0.36070 prc_auc 0.58397[0m
[93maverage test of epoch 59: loss -27.88366 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 60: loss -28.31827 acc 0.66667 roc_auc 0.37340 prc_auc 0.59112[0m
[93maverage test of epoch 60: loss -28.56045 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 61: loss -29.00099 acc 0.66667 roc_auc 0.36650 prc_auc 0.59306[0m
[93maverage test of epoch 61: loss -29.24679 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 62: loss -29.69329 acc 0.66667 roc_auc 0.36720 prc_auc 0.59543[0m
[93maverage test of epoch 62: loss -29.94274 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 63: loss -30.39521 acc 0.66667 roc_auc 0.36490 prc_auc 0.59458[0m
[93maverage test of epoch 63: loss -30.64830 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 64: loss -31.10676 acc 0.66667 roc_auc 0.37660 prc_auc 0.60197[0m
[93maverage test of epoch 64: loss -31.36352 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 65: loss -31.82800 acc 0.66667 roc_auc 0.39520 prc_auc 0.61550[0m
[93maverage test of epoch 65: loss -32.08842 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 66: loss -32.55893 acc 0.66667 roc_auc 0.37460 prc_auc 0.60556[0m
[93maverage test of epoch 66: loss -32.82304 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 67: loss -33.29959 acc 0.66667 roc_auc 0.39300 prc_auc 0.61171[0m
[93maverage test of epoch 67: loss -33.56738 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 68: loss -34.05000 acc 0.66667 roc_auc 0.37980 prc_auc 0.61732[0m
[93maverage test of epoch 68: loss -34.32146 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 69: loss -34.81017 acc 0.66667 roc_auc 0.36310 prc_auc 0.60793[0m
[93maverage test of epoch 69: loss -35.08531 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 70: loss -35.58011 acc 0.66667 roc_auc 0.42750 prc_auc 0.63362[0m
[93maverage test of epoch 70: loss -35.85893 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 71: loss -36.35984 acc 0.66667 roc_auc 0.36000 prc_auc 0.60820[0m
[93maverage test of epoch 71: loss -36.64232 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 72: loss -37.14937 acc 0.66667 roc_auc 0.35720 prc_auc 0.61075[0m
[93maverage test of epoch 72: loss -37.43551 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 73: loss -37.94870 acc 0.66667 roc_auc 0.43000 prc_auc 0.63761[0m
[93maverage test of epoch 73: loss -38.23849 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 74: loss -38.75783 acc 0.66667 roc_auc 0.42960 prc_auc 0.63524[0m
[93maverage test of epoch 74: loss -39.05128 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 75: loss -39.57677 acc 0.66667 roc_auc 0.43000 prc_auc 0.63761[0m
[93maverage test of epoch 75: loss -39.87385 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 76: loss -40.40553 acc 0.66667 roc_auc 0.46000 prc_auc 0.64946[0m
[93maverage test of epoch 76: loss -40.70622 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 77: loss -41.24409 acc 0.66667 roc_auc 0.45000 prc_auc 0.64531[0m
[93maverage test of epoch 77: loss -41.54838 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 78: loss -42.09246 acc 0.66667 roc_auc 0.45000 prc_auc 0.64533[0m
[93maverage test of epoch 78: loss -42.40035 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 79: loss -42.95063 acc 0.66667 roc_auc 0.42000 prc_auc 0.63385[0m
[93maverage test of epoch 79: loss -43.26208 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 80: loss -43.81859 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 80: loss -44.13359 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 81: loss -44.69633 acc 0.66667 roc_auc 0.49000 prc_auc 0.66225[0m
[93maverage test of epoch 81: loss -45.01487 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 82: loss -45.58385 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 82: loss -45.90590 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 83: loss -46.48114 acc 0.66667 roc_auc 0.47500 prc_auc 0.65576[0m
[93maverage test of epoch 83: loss -46.80668 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 84: loss -47.38818 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 84: loss -47.71718 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 85: loss -48.30493 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 85: loss -48.63730 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 86: loss -49.23114 acc 0.66667 roc_auc 0.47000 prc_auc 0.65364[0m
[93maverage test of epoch 86: loss -49.56667 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 87: loss -50.16660 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 87: loss -50.50529 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 88: loss -51.11135 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 88: loss -51.45320 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 89: loss -52.06543 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 89: loss -52.41044 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -53.02885 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 90: loss -53.37703 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 91: loss -54.00166 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 91: loss -54.35297 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 92: loss -54.98383 acc 0.66667 roc_auc 0.46000 prc_auc 0.64946[0m
[93maverage test of epoch 92: loss -55.33828 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 93: loss -55.97546 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 93: loss -56.33303 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 94: loss -56.97648 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 94: loss -57.33713 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 95: loss -57.98688 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 95: loss -58.35062 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 96: loss -59.00675 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 96: loss -59.37360 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 97: loss -60.03605 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 97: loss -60.40588 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 98: loss -61.07474 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 98: loss -61.44760 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -62.12284 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 99: loss -62.49872 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -2.35300 acc 0.66667 roc_auc 0.44060 prc_auc 0.63385[0m
[93maverage test of epoch 0: loss -2.49434 acc 0.65789 roc_auc 0.37231 prc_auc 0.67766[0m
[92maverage training of epoch 1: loss -2.69254 acc 0.66667 roc_auc 0.45840 prc_auc 0.64918[0m
[93maverage test of epoch 1: loss -2.84465 acc 0.65789 roc_auc 0.43077 prc_auc 0.69338[0m
[92maverage training of epoch 2: loss -3.05541 acc 0.66667 roc_auc 0.45920 prc_auc 0.64631[0m
[93maverage test of epoch 2: loss -3.21653 acc 0.65789 roc_auc 0.32615 prc_auc 0.65207[0m
[92maverage training of epoch 3: loss -3.43841 acc 0.66667 roc_auc 0.46120 prc_auc 0.64773[0m
[93maverage test of epoch 3: loss -3.60857 acc 0.65789 roc_auc 0.30462 prc_auc 0.64514[0m
[92maverage training of epoch 4: loss -3.84184 acc 0.66667 roc_auc 0.46460 prc_auc 0.64939[0m
[93maverage test of epoch 4: loss -4.02228 acc 0.65789 roc_auc 0.30154 prc_auc 0.63735[0m
[92maverage training of epoch 5: loss -4.26781 acc 0.66667 roc_auc 0.46900 prc_auc 0.64659[0m
[93maverage test of epoch 5: loss -4.45937 acc 0.65789 roc_auc 0.53846 prc_auc 0.76526[0m
[92maverage training of epoch 6: loss -4.71792 acc 0.66667 roc_auc 0.47020 prc_auc 0.64837[0m
[93maverage test of epoch 6: loss -4.92027 acc 0.65789 roc_auc 0.67231 prc_auc 0.82823[0m
[92maverage training of epoch 7: loss -5.19236 acc 0.66667 roc_auc 0.47100 prc_auc 0.65640[0m
[93maverage test of epoch 7: loss -5.40421 acc 0.65789 roc_auc 0.83385 prc_auc 0.92129[0m
[92maverage training of epoch 8: loss -5.68805 acc 0.66667 roc_auc 0.47040 prc_auc 0.65611[0m
[93maverage test of epoch 8: loss -5.90608 acc 0.65789 roc_auc 0.89846 prc_auc 0.95218[0m
[92maverage training of epoch 9: loss -6.19827 acc 0.66667 roc_auc 0.47020 prc_auc 0.65610[0m
[93maverage test of epoch 9: loss -6.41838 acc 0.65789 roc_auc 0.90615 prc_auc 0.96168[0m
[92maverage training of epoch 10: loss -6.71580 acc 0.66667 roc_auc 0.47020 prc_auc 0.65606[0m
[93maverage test of epoch 10: loss -6.93473 acc 0.65789 roc_auc 0.83231 prc_auc 0.93180[0m
[92maverage training of epoch 11: loss -7.23517 acc 0.66667 roc_auc 0.47020 prc_auc 0.65606[0m
[93maverage test of epoch 11: loss -7.45058 acc 0.65789 roc_auc 0.72462 prc_auc 0.88926[0m
[92maverage training of epoch 12: loss -7.75250 acc 0.66667 roc_auc 0.47000 prc_auc 0.65602[0m
[93maverage test of epoch 12: loss -7.96273 acc 0.65789 roc_auc 0.64769 prc_auc 0.82001[0m
[92maverage training of epoch 13: loss -8.26561 acc 0.66667 roc_auc 0.47000 prc_auc 0.65602[0m
[93maverage test of epoch 13: loss -8.47004 acc 0.65789 roc_auc 0.69846 prc_auc 0.86080[0m
[92maverage training of epoch 14: loss -8.77392 acc 0.66667 roc_auc 0.47000 prc_auc 0.65602[0m
[93maverage test of epoch 14: loss -8.97236 acc 0.65789 roc_auc 0.59846 prc_auc 0.73938[0m
[92maverage training of epoch 15: loss -9.27708 acc 0.66667 roc_auc 0.46990 prc_auc 0.65597[0m
[93maverage test of epoch 15: loss -9.46884 acc 0.65789 roc_auc 0.70000 prc_auc 0.79474[0m
[92maverage training of epoch 16: loss -9.77411 acc 0.66667 roc_auc 0.46980 prc_auc 0.65597[0m
[93maverage test of epoch 16: loss -9.95921 acc 0.65789 roc_auc 0.60000 prc_auc 0.72632[0m
[92maverage training of epoch 17: loss -10.26564 acc 0.66667 roc_auc 0.46980 prc_auc 0.65597[0m
[93maverage test of epoch 17: loss -10.44450 acc 0.65789 roc_auc 0.60000 prc_auc 0.72632[0m
[92maverage training of epoch 18: loss -10.75244 acc 0.66667 roc_auc 0.46980 prc_auc 0.65597[0m
[93maverage test of epoch 18: loss -10.92548 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 19: loss -11.23562 acc 0.66667 roc_auc 0.46930 prc_auc 0.65503[0m
[93maverage test of epoch 19: loss -11.40354 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 20: loss -11.71649 acc 0.66667 roc_auc 0.46890 prc_auc 0.65272[0m
[93maverage test of epoch 20: loss -11.87989 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 21: loss -12.19624 acc 0.66667 roc_auc 0.46830 prc_auc 0.65251[0m
[93maverage test of epoch 21: loss -12.35572 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 22: loss -12.67599 acc 0.66667 roc_auc 0.46880 prc_auc 0.65601[0m
[93maverage test of epoch 22: loss -12.83210 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 23: loss -13.15674 acc 0.66667 roc_auc 0.46740 prc_auc 0.65021[0m
[93maverage test of epoch 23: loss -13.30992 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 24: loss -13.63930 acc 0.66667 roc_auc 0.46620 prc_auc 0.64595[0m
[93maverage test of epoch 24: loss -13.78994 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 25: loss -14.12439 acc 0.66667 roc_auc 0.46350 prc_auc 0.64586[0m
[93maverage test of epoch 25: loss -14.27282 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 26: loss -14.61263 acc 0.66667 roc_auc 0.46560 prc_auc 0.64781[0m
[93maverage test of epoch 26: loss -14.75914 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 27: loss -15.10457 acc 0.66667 roc_auc 0.46430 prc_auc 0.64693[0m
[93maverage test of epoch 27: loss -15.24941 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 28: loss -15.60066 acc 0.66667 roc_auc 0.46340 prc_auc 0.65111[0m
[93maverage test of epoch 28: loss -15.74407 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 29: loss -16.10135 acc 0.66667 roc_auc 0.46270 prc_auc 0.65159[0m
[93maverage test of epoch 29: loss -16.24351 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 30: loss -16.60699 acc 0.66667 roc_auc 0.47890 prc_auc 0.65521[0m
[93maverage test of epoch 30: loss -16.74808 acc 0.65789 roc_auc 0.52000 prc_auc 0.67158[0m
[92maverage training of epoch 31: loss -17.11794 acc 0.66667 roc_auc 0.46100 prc_auc 0.64674[0m
[93maverage test of epoch 31: loss -17.25810 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -17.63448 acc 0.66667 roc_auc 0.47310 prc_auc 0.65736[0m
[93maverage test of epoch 32: loss -17.77384 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 33: loss -18.15686 acc 0.66667 roc_auc 0.50570 prc_auc 0.66995[0m
[93maverage test of epoch 33: loss -18.29554 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -18.68534 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -18.82343 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -19.22011 acc 0.66667 roc_auc 0.48000 prc_auc 0.65793[0m
[93maverage test of epoch 35: loss -19.35769 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -19.76138 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -19.89853 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -20.30930 acc 0.66667 roc_auc 0.50500 prc_auc 0.66896[0m
[93maverage test of epoch 37: loss -20.44607 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -20.86403 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -21.00049 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -21.42571 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -21.56189 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -21.99448 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -22.13043 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -22.57045 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -22.70622 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -23.15375 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -23.28933 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -23.74443 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -23.87987 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -24.34263 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -24.47795 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -24.94844 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -25.08366 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -25.56194 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -25.69706 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -26.18319 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -26.31824 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -26.81227 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -26.94722 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -27.44921 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -27.58407 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 50: loss -28.09411 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 50: loss -28.22890 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 51: loss -28.74704 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 51: loss -28.88177 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 52: loss -29.40806 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 52: loss -29.54271 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 53: loss -30.07723 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 53: loss -30.21182 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 54: loss -30.75461 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 54: loss -30.88913 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 55: loss -31.44026 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 55: loss -31.57469 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 56: loss -32.13421 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 56: loss -32.26855 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 57: loss -32.83653 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 57: loss -32.97077 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 58: loss -33.54724 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 58: loss -33.68137 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 59: loss -34.26641 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 59: loss -34.40041 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 60: loss -34.99406 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 60: loss -35.12793 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 61: loss -35.73025 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 61: loss -35.86397 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 62: loss -36.47501 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 62: loss -36.60856 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 63: loss -37.22838 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 63: loss -37.36175 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 64: loss -37.99039 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 64: loss -38.12357 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 65: loss -38.76109 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 65: loss -38.89406 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 66: loss -39.54051 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 66: loss -39.67325 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 67: loss -40.32869 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 67: loss -40.46117 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 68: loss -41.12565 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 68: loss -41.25786 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 69: loss -41.93143 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 69: loss -42.06336 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 70: loss -42.74606 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 70: loss -42.87768 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 71: loss -43.56957 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 71: loss -43.70086 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 72: loss -44.40199 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 72: loss -44.53292 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 73: loss -45.24335 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 73: loss -45.37391 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 74: loss -46.09368 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 74: loss -46.22384 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 75: loss -46.95301 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 75: loss -47.08274 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 76: loss -47.82136 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 76: loss -47.95064 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 77: loss -48.69875 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 77: loss -48.82757 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 78: loss -49.58522 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 78: loss -49.71355 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 79: loss -50.48079 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 79: loss -50.60860 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 80: loss -51.38548 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 80: loss -51.51275 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 81: loss -52.29933 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 81: loss -52.42603 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 82: loss -53.22232 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 82: loss -53.34841 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 83: loss -54.15448 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 83: loss -54.27993 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 84: loss -55.09582 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 84: loss -55.22062 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 85: loss -56.04639 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 85: loss -56.17052 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 86: loss -57.00622 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 86: loss -57.12966 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 87: loss -57.97532 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 87: loss -58.09803 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 88: loss -58.95371 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 88: loss -59.07566 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 89: loss -59.94141 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 89: loss -60.06258 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -60.93844 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 90: loss -61.05880 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 91: loss -61.94481 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 91: loss -62.06431 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 92: loss -62.96051 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 92: loss -63.07914 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 93: loss -63.98558 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 93: loss -64.10332 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 94: loss -65.02005 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 94: loss -65.13686 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 95: loss -66.06393 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 95: loss -66.17978 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 96: loss -67.11724 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 96: loss -67.23210 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 97: loss -68.17997 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 97: loss -68.29382 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 98: loss -69.25213 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 98: loss -69.36490 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -70.33370 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 99: loss -70.44539 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss 0.05504 acc 0.33333 roc_auc 0.39120 prc_auc 0.60301[0m
[93maverage test of epoch 0: loss -0.09672 acc 0.34211 roc_auc 0.88615 prc_auc 0.95503[0m
[92maverage training of epoch 1: loss -0.23140 acc 0.33333 roc_auc 0.44300 prc_auc 0.65962[0m
[93maverage test of epoch 1: loss -0.37757 acc 0.34211 roc_auc 0.93538 prc_auc 0.97114[0m
[92maverage training of epoch 2: loss -0.50872 acc 0.33333 roc_auc 0.51020 prc_auc 0.72040[0m
[93maverage test of epoch 2: loss -0.64946 acc 0.34211 roc_auc 0.95385 prc_auc 0.97918[0m
[92maverage training of epoch 3: loss -0.77769 acc 0.34000 roc_auc 0.55820 prc_auc 0.76858[0m
[93maverage test of epoch 3: loss -0.91417 acc 0.36842 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 4: loss -1.04177 acc 0.48667 roc_auc 0.57960 prc_auc 0.78246[0m
[93maverage test of epoch 4: loss -1.17355 acc 0.63158 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 5: loss -1.30691 acc 0.55333 roc_auc 0.64480 prc_auc 0.81857[0m
[93maverage test of epoch 5: loss -1.45368 acc 0.42105 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 6: loss -1.59821 acc 0.50000 roc_auc 0.59680 prc_auc 0.78910[0m
[93maverage test of epoch 6: loss -1.75259 acc 0.39474 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 7: loss -1.90246 acc 0.50000 roc_auc 0.56660 prc_auc 0.76949[0m
[93maverage test of epoch 7: loss -2.05940 acc 0.39474 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 8: loss -2.21080 acc 0.48667 roc_auc 0.55200 prc_auc 0.76369[0m
[93maverage test of epoch 8: loss -2.36933 acc 0.63158 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 9: loss -2.52544 acc 0.62000 roc_auc 0.54720 prc_auc 0.76083[0m
[93maverage test of epoch 9: loss -2.68975 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 10: loss -2.85374 acc 0.66667 roc_auc 0.54400 prc_auc 0.75992[0m
[93maverage test of epoch 10: loss -3.02658 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 11: loss -3.19973 acc 0.66667 roc_auc 0.54080 prc_auc 0.75755[0m
[93maverage test of epoch 11: loss -3.38158 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 12: loss -3.56272 acc 0.66667 roc_auc 0.54040 prc_auc 0.75729[0m
[93maverage test of epoch 12: loss -3.75199 acc 0.65789 roc_auc 0.95077 prc_auc 0.97808[0m
[92maverage training of epoch 13: loss -3.93983 acc 0.66667 roc_auc 0.54320 prc_auc 0.75756[0m
[93maverage test of epoch 13: loss -4.13567 acc 0.65789 roc_auc 0.94923 prc_auc 0.97644[0m
[92maverage training of epoch 14: loss -4.33003 acc 0.66667 roc_auc 0.54920 prc_auc 0.75899[0m
[93maverage test of epoch 14: loss -4.53311 acc 0.65789 roc_auc 0.94923 prc_auc 0.97644[0m
[92maverage training of epoch 15: loss -4.73635 acc 0.66667 roc_auc 0.54820 prc_auc 0.76099[0m
[93maverage test of epoch 15: loss -4.95043 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 16: loss -5.16762 acc 0.66667 roc_auc 0.55860 prc_auc 0.76542[0m
[93maverage test of epoch 16: loss -5.39877 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 17: loss -5.64465 acc 0.59333 roc_auc 0.58220 prc_auc 0.77241[0m
[93maverage test of epoch 17: loss -5.93109 acc 0.36842 roc_auc 0.94769 prc_auc 0.97644[0m
[92maverage training of epoch 18: loss -6.22357 acc 0.35333 roc_auc 0.59700 prc_auc 0.75526[0m
[93maverage test of epoch 18: loss -6.52938 acc 0.34211 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 19: loss -6.81724 acc 0.33333 roc_auc 0.56580 prc_auc 0.75437[0m
[93maverage test of epoch 19: loss -7.11955 acc 0.34211 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 20: loss -7.40377 acc 0.33333 roc_auc 0.53480 prc_auc 0.74427[0m
[93maverage test of epoch 20: loss -7.70544 acc 0.34211 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 21: loss -7.99058 acc 0.33333 roc_auc 0.51500 prc_auc 0.72388[0m
[93maverage test of epoch 21: loss -8.29510 acc 0.34211 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 22: loss -8.58271 acc 0.33333 roc_auc 0.49860 prc_auc 0.70289[0m
[93maverage test of epoch 22: loss -8.89071 acc 0.34211 roc_auc 0.95231 prc_auc 0.97791[0m
[92maverage training of epoch 23: loss -9.18184 acc 0.33333 roc_auc 0.48240 prc_auc 0.68538[0m
[93maverage test of epoch 23: loss -9.49441 acc 0.34211 roc_auc 0.95077 prc_auc 0.97751[0m
[92maverage training of epoch 24: loss -9.78997 acc 0.33333 roc_auc 0.47100 prc_auc 0.67155[0m
[93maverage test of epoch 24: loss -10.10773 acc 0.34211 roc_auc 0.94462 prc_auc 0.97394[0m
[92maverage training of epoch 25: loss -10.40822 acc 0.33333 roc_auc 0.45940 prc_auc 0.66251[0m
[93maverage test of epoch 25: loss -10.73146 acc 0.34211 roc_auc 0.94154 prc_auc 0.97221[0m
[92maverage training of epoch 26: loss -11.03717 acc 0.33333 roc_auc 0.44700 prc_auc 0.65416[0m
[93maverage test of epoch 26: loss -11.36603 acc 0.34211 roc_auc 0.93846 prc_auc 0.97094[0m
[92maverage training of epoch 27: loss -11.67714 acc 0.33333 roc_auc 0.43280 prc_auc 0.64063[0m
[93maverage test of epoch 27: loss -12.01168 acc 0.34211 roc_auc 0.93846 prc_auc 0.97094[0m
[92maverage training of epoch 28: loss -12.32836 acc 0.33333 roc_auc 0.41580 prc_auc 0.62527[0m
[93maverage test of epoch 28: loss -12.66863 acc 0.34211 roc_auc 0.93538 prc_auc 0.96933[0m
[92maverage training of epoch 29: loss -12.99101 acc 0.33333 roc_auc 0.40680 prc_auc 0.61823[0m
[93maverage test of epoch 29: loss -13.33707 acc 0.34211 roc_auc 0.93692 prc_auc 0.96923[0m
[92maverage training of epoch 30: loss -13.66533 acc 0.33333 roc_auc 0.40260 prc_auc 0.61543[0m
[93maverage test of epoch 30: loss -14.01726 acc 0.34211 roc_auc 0.93846 prc_auc 0.97072[0m
[92maverage training of epoch 31: loss -14.35158 acc 0.33333 roc_auc 0.39900 prc_auc 0.61201[0m
[93maverage test of epoch 31: loss -14.70948 acc 0.34211 roc_auc 0.92923 prc_auc 0.96260[0m
[92maverage training of epoch 32: loss -15.05005 acc 0.33333 roc_auc 0.39960 prc_auc 0.61256[0m
[93maverage test of epoch 32: loss -15.41404 acc 0.34211 roc_auc 0.91846 prc_auc 0.96045[0m
[92maverage training of epoch 33: loss -15.76109 acc 0.33333 roc_auc 0.39980 prc_auc 0.60468[0m
[93maverage test of epoch 33: loss -16.13131 acc 0.34211 roc_auc 0.90000 prc_auc 0.95233[0m
[92maverage training of epoch 34: loss -16.48505 acc 0.33333 roc_auc 0.39820 prc_auc 0.60069[0m
[93maverage test of epoch 34: loss -16.86165 acc 0.34211 roc_auc 0.89077 prc_auc 0.94720[0m
[92maverage training of epoch 35: loss -17.22232 acc 0.33333 roc_auc 0.39600 prc_auc 0.59825[0m
[93maverage test of epoch 35: loss -17.60547 acc 0.34211 roc_auc 0.85385 prc_auc 0.93163[0m
[92maverage training of epoch 36: loss -17.97328 acc 0.33333 roc_auc 0.39440 prc_auc 0.59660[0m
[93maverage test of epoch 36: loss -18.36315 acc 0.34211 roc_auc 0.86615 prc_auc 0.93289[0m
[92maverage training of epoch 37: loss -18.73834 acc 0.33333 roc_auc 0.39200 prc_auc 0.59440[0m
[93maverage test of epoch 37: loss -19.13508 acc 0.34211 roc_auc 0.91846 prc_auc 0.94429[0m
[92maverage training of epoch 38: loss -19.51788 acc 0.33333 roc_auc 0.39020 prc_auc 0.59409[0m
[93maverage test of epoch 38: loss -19.92167 acc 0.34211 roc_auc 0.90462 prc_auc 0.94111[0m
[92maverage training of epoch 39: loss -20.31229 acc 0.33333 roc_auc 0.38900 prc_auc 0.59295[0m
[93maverage test of epoch 39: loss -20.72329 acc 0.34211 roc_auc 0.84462 prc_auc 0.92342[0m
[92maverage training of epoch 40: loss -21.12195 acc 0.33333 roc_auc 0.38640 prc_auc 0.59165[0m
[93maverage test of epoch 40: loss -21.54031 acc 0.34211 roc_auc 0.86615 prc_auc 0.92728[0m
[92maverage training of epoch 41: loss -21.94721 acc 0.33333 roc_auc 0.38560 prc_auc 0.59087[0m
[93maverage test of epoch 41: loss -22.37309 acc 0.34211 roc_auc 0.86769 prc_auc 0.93259[0m
[92maverage training of epoch 42: loss -22.78842 acc 0.33333 roc_auc 0.38400 prc_auc 0.59002[0m
[93maverage test of epoch 42: loss -23.22195 acc 0.34211 roc_auc 0.90923 prc_auc 0.95969[0m
[92maverage training of epoch 43: loss -23.64592 acc 0.33333 roc_auc 0.38300 prc_auc 0.58963[0m
[93maverage test of epoch 43: loss -24.08723 acc 0.34211 roc_auc 0.93538 prc_auc 0.94750[0m
[92maverage training of epoch 44: loss -24.52000 acc 0.33333 roc_auc 0.38140 prc_auc 0.58816[0m
[93maverage test of epoch 44: loss -24.96922 acc 0.34211 roc_auc 0.79846 prc_auc 0.89914[0m
[92maverage training of epoch 45: loss -25.41094 acc 0.33333 roc_auc 0.38060 prc_auc 0.58741[0m
[93maverage test of epoch 45: loss -25.86802 acc 0.34211 roc_auc 0.85231 prc_auc 0.90514[0m
[92maverage training of epoch 46: loss -26.31845 acc 0.33333 roc_auc 0.38000 prc_auc 0.58684[0m
[93maverage test of epoch 46: loss -26.78316 acc 0.34211 roc_auc 0.88615 prc_auc 0.91922[0m
[92maverage training of epoch 47: loss -27.24241 acc 0.46000 roc_auc 0.37850 prc_auc 0.58515[0m
[93maverage test of epoch 47: loss -27.71483 acc 0.65789 roc_auc 0.77692 prc_auc 0.87755[0m
[92maverage training of epoch 48: loss -28.18301 acc 0.66667 roc_auc 0.37800 prc_auc 0.58453[0m
[93maverage test of epoch 48: loss -28.66321 acc 0.65789 roc_auc 0.75077 prc_auc 0.86032[0m
[92maverage training of epoch 49: loss -29.14043 acc 0.66667 roc_auc 0.37900 prc_auc 0.58482[0m
[93maverage test of epoch 49: loss -29.62832 acc 0.65789 roc_auc 0.81538 prc_auc 0.88778[0m
[92maverage training of epoch 50: loss -30.11431 acc 0.66667 roc_auc 0.37840 prc_auc 0.58447[0m
[93maverage test of epoch 50: loss -30.60959 acc 0.65789 roc_auc 0.82615 prc_auc 0.87800[0m
[92maverage training of epoch 51: loss -31.10431 acc 0.66667 roc_auc 0.37770 prc_auc 0.58342[0m
[93maverage test of epoch 51: loss -31.60690 acc 0.65789 roc_auc 0.74923 prc_auc 0.83825[0m
[92maverage training of epoch 52: loss -32.11041 acc 0.66667 roc_auc 0.37650 prc_auc 0.58344[0m
[93maverage test of epoch 52: loss -32.62029 acc 0.65789 roc_auc 0.63231 prc_auc 0.81034[0m
[92maverage training of epoch 53: loss -33.13264 acc 0.66667 roc_auc 0.37680 prc_auc 0.58321[0m
[93maverage test of epoch 53: loss -33.64982 acc 0.65789 roc_auc 0.62000 prc_auc 0.75596[0m
[92maverage training of epoch 54: loss -34.17121 acc 0.66667 roc_auc 0.37660 prc_auc 0.58329[0m
[93maverage test of epoch 54: loss -34.69579 acc 0.65789 roc_auc 0.84462 prc_auc 0.88431[0m
[92maverage training of epoch 55: loss -35.22639 acc 0.66667 roc_auc 0.37640 prc_auc 0.58318[0m
[93maverage test of epoch 55: loss -35.75848 acc 0.65789 roc_auc 0.74462 prc_auc 0.82718[0m
[92maverage training of epoch 56: loss -36.29838 acc 0.66667 roc_auc 0.37560 prc_auc 0.58220[0m
[93maverage test of epoch 56: loss -36.83790 acc 0.65789 roc_auc 0.50769 prc_auc 0.68136[0m
[92maverage training of epoch 57: loss -37.38716 acc 0.66667 roc_auc 0.37650 prc_auc 0.58057[0m
[93maverage test of epoch 57: loss -37.93410 acc 0.65789 roc_auc 0.74000 prc_auc 0.84263[0m
[92maverage training of epoch 58: loss -38.49268 acc 0.66667 roc_auc 0.37780 prc_auc 0.58139[0m
[93maverage test of epoch 58: loss -39.04681 acc 0.65789 roc_auc 0.64000 prc_auc 0.75368[0m
[92maverage training of epoch 59: loss -39.61471 acc 0.66667 roc_auc 0.37820 prc_auc 0.58067[0m
[93maverage test of epoch 59: loss -40.17608 acc 0.65789 roc_auc 0.79077 prc_auc 0.83184[0m
[92maverage training of epoch 60: loss -40.75344 acc 0.66667 roc_auc 0.37800 prc_auc 0.58044[0m
[93maverage test of epoch 60: loss -41.32213 acc 0.65789 roc_auc 0.42923 prc_auc 0.63207[0m
[92maverage training of epoch 61: loss -41.90910 acc 0.66667 roc_auc 0.37840 prc_auc 0.58059[0m
[93maverage test of epoch 61: loss -42.48517 acc 0.65789 roc_auc 0.60000 prc_auc 0.72632[0m
[92maverage training of epoch 62: loss -43.08187 acc 0.66667 roc_auc 0.37810 prc_auc 0.58019[0m
[93maverage test of epoch 62: loss -43.66539 acc 0.65789 roc_auc 0.38000 prc_auc 0.61905[0m
[92maverage training of epoch 63: loss -44.27194 acc 0.66667 roc_auc 0.37860 prc_auc 0.58012[0m
[93maverage test of epoch 63: loss -44.86294 acc 0.65789 roc_auc 0.50000 prc_auc 0.66307[0m
[92maverage training of epoch 64: loss -45.47944 acc 0.66667 roc_auc 0.37920 prc_auc 0.57984[0m
[93maverage test of epoch 64: loss -46.07793 acc 0.65789 roc_auc 0.86154 prc_auc 0.89714[0m
[92maverage training of epoch 65: loss -46.70450 acc 0.66667 roc_auc 0.37920 prc_auc 0.57918[0m
[93maverage test of epoch 65: loss -47.31050 acc 0.65789 roc_auc 0.48000 prc_auc 0.64902[0m
[92maverage training of epoch 66: loss -47.94721 acc 0.66667 roc_auc 0.38000 prc_auc 0.57829[0m
[93maverage test of epoch 66: loss -48.56073 acc 0.65789 roc_auc 0.52000 prc_auc 0.67158[0m
[92maverage training of epoch 67: loss -49.20768 acc 0.66667 roc_auc 0.37880 prc_auc 0.57742[0m
[93maverage test of epoch 67: loss -49.82871 acc 0.65789 roc_auc 0.64923 prc_auc 0.73549[0m
[92maverage training of epoch 68: loss -50.48589 acc 0.66667 roc_auc 0.37740 prc_auc 0.57573[0m
[93maverage test of epoch 68: loss -51.11429 acc 0.65789 roc_auc 0.44923 prc_auc 0.63574[0m
[92maverage training of epoch 69: loss -51.78174 acc 0.66667 roc_auc 0.37700 prc_auc 0.57491[0m
[93maverage test of epoch 69: loss -52.41750 acc 0.65789 roc_auc 0.50000 prc_auc 0.66307[0m
[92maverage training of epoch 70: loss -53.09521 acc 0.66667 roc_auc 0.37620 prc_auc 0.57375[0m
[93maverage test of epoch 70: loss -53.73806 acc 0.65789 roc_auc 0.45846 prc_auc 0.63981[0m
[92maverage training of epoch 71: loss -54.42571 acc 0.66667 roc_auc 0.37570 prc_auc 0.57322[0m
[93maverage test of epoch 71: loss -55.07541 acc 0.65789 roc_auc 0.82000 prc_auc 0.87684[0m
[92maverage training of epoch 72: loss -55.77313 acc 0.66667 roc_auc 0.37620 prc_auc 0.57356[0m
[93maverage test of epoch 72: loss -56.42975 acc 0.65789 roc_auc 0.38000 prc_auc 0.60914[0m
[92maverage training of epoch 73: loss -57.13770 acc 0.66667 roc_auc 0.37500 prc_auc 0.57223[0m
[93maverage test of epoch 73: loss -57.80128 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 74: loss -58.51959 acc 0.66667 roc_auc 0.37520 prc_auc 0.57273[0m
[93maverage test of epoch 74: loss -59.19012 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 75: loss -59.91855 acc 0.66667 roc_auc 0.37480 prc_auc 0.57170[0m
[93maverage test of epoch 75: loss -60.59560 acc 0.65789 roc_auc 0.42000 prc_auc 0.62409[0m
[92maverage training of epoch 76: loss -61.33410 acc 0.66667 roc_auc 0.37630 prc_auc 0.57269[0m
[93maverage test of epoch 76: loss -62.01770 acc 0.65789 roc_auc 0.80154 prc_auc 0.85275[0m
[92maverage training of epoch 77: loss -62.76643 acc 0.66667 roc_auc 0.37600 prc_auc 0.57170[0m
[93maverage test of epoch 77: loss -63.45664 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 78: loss -64.21578 acc 0.66667 roc_auc 0.37500 prc_auc 0.57057[0m
[93maverage test of epoch 78: loss -64.91264 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 79: loss -65.68228 acc 0.66667 roc_auc 0.37550 prc_auc 0.57071[0m
[93maverage test of epoch 79: loss -66.38574 acc 0.65789 roc_auc 0.46000 prc_auc 0.64041[0m
[92maverage training of epoch 80: loss -67.16586 acc 0.66667 roc_auc 0.37650 prc_auc 0.57153[0m
[93maverage test of epoch 80: loss -67.87580 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 81: loss -68.66654 acc 0.66667 roc_auc 0.37720 prc_auc 0.57344[0m
[93maverage test of epoch 81: loss -69.38299 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 82: loss -70.18446 acc 0.66667 roc_auc 0.37610 prc_auc 0.57420[0m
[93maverage test of epoch 82: loss -70.90748 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 83: loss -71.71982 acc 0.66667 roc_auc 0.37710 prc_auc 0.57509[0m
[93maverage test of epoch 83: loss -72.44939 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 84: loss -73.27267 acc 0.66667 roc_auc 0.37760 prc_auc 0.57637[0m
[93maverage test of epoch 84: loss -74.00886 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 85: loss -74.84326 acc 0.66667 roc_auc 0.37860 prc_auc 0.57780[0m
[93maverage test of epoch 85: loss -75.58603 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 86: loss -76.43132 acc 0.66667 roc_auc 0.37890 prc_auc 0.57861[0m
[93maverage test of epoch 86: loss -77.18024 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 87: loss -78.03627 acc 0.66667 roc_auc 0.37940 prc_auc 0.57914[0m
[93maverage test of epoch 87: loss -78.79126 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 88: loss -79.65816 acc 0.66667 roc_auc 0.37880 prc_auc 0.57815[0m
[93maverage test of epoch 88: loss -80.41927 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 89: loss -81.29717 acc 0.66667 roc_auc 0.37810 prc_auc 0.57870[0m
[93maverage test of epoch 89: loss -82.06441 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -82.95344 acc 0.66667 roc_auc 0.37880 prc_auc 0.57963[0m
[93maverage test of epoch 90: loss -83.72681 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 91: loss -84.62706 acc 0.66667 roc_auc 0.38070 prc_auc 0.58218[0m
[93maverage test of epoch 91: loss -85.40657 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 92: loss -86.31821 acc 0.66667 roc_auc 0.38150 prc_auc 0.58319[0m
[93maverage test of epoch 92: loss -87.10388 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 93: loss -88.02698 acc 0.66667 roc_auc 0.38230 prc_auc 0.58962[0m
[93maverage test of epoch 93: loss -88.81882 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 94: loss -89.75349 acc 0.66667 roc_auc 0.38370 prc_auc 0.58510[0m
[93maverage test of epoch 94: loss -90.55147 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 95: loss -91.49785 acc 0.66667 roc_auc 0.38400 prc_auc 0.58489[0m
[93maverage test of epoch 95: loss -92.30202 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 96: loss -93.26017 acc 0.66667 roc_auc 0.38510 prc_auc 0.58778[0m
[93maverage test of epoch 96: loss -94.07045 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 97: loss -95.04045 acc 0.66667 roc_auc 0.38510 prc_auc 0.58456[0m
[93maverage test of epoch 97: loss -95.85686 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 98: loss -96.83879 acc 0.66667 roc_auc 0.38630 prc_auc 0.58983[0m
[93maverage test of epoch 98: loss -97.66126 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -98.65521 acc 0.66667 roc_auc 0.38760 prc_auc 0.58906[0m
[93maverage test of epoch 99: loss -99.48374 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.05420 acc 0.66225 roc_auc 0.54549 prc_auc 0.68640[0m
[93maverage test of epoch 0: loss -0.19321 acc 0.67568 roc_auc 0.24333 prc_auc 0.57791[0m
[92maverage training of epoch 1: loss -0.30777 acc 0.66225 roc_auc 0.48235 prc_auc 0.66697[0m
[93maverage test of epoch 1: loss -0.38737 acc 0.67568 roc_auc 0.19333 prc_auc 0.55737[0m
[92maverage training of epoch 2: loss -0.44843 acc 0.66225 roc_auc 0.42706 prc_auc 0.63178[0m
[93maverage test of epoch 2: loss -0.51862 acc 0.67568 roc_auc 0.19000 prc_auc 0.55642[0m
[92maverage training of epoch 3: loss -0.59110 acc 0.66225 roc_auc 0.42745 prc_auc 0.62666[0m
[93maverage test of epoch 3: loss -0.67512 acc 0.67568 roc_auc 0.14667 prc_auc 0.51323[0m
[92maverage training of epoch 4: loss -0.88850 acc 0.66225 roc_auc 0.53902 prc_auc 0.67724[0m
[93maverage test of epoch 4: loss -1.14884 acc 0.67568 roc_auc 0.19333 prc_auc 0.55724[0m
[92maverage training of epoch 5: loss -1.45039 acc 0.58278 roc_auc 0.55078 prc_auc 0.68810[0m
[93maverage test of epoch 5: loss -1.79860 acc 0.35135 roc_auc 0.67667 prc_auc 0.86528[0m
[92maverage training of epoch 6: loss -2.18382 acc 0.34437 roc_auc 0.57255 prc_auc 0.71614[0m
[93maverage test of epoch 6: loss -2.55429 acc 0.32432 roc_auc 0.85000 prc_auc 0.93224[0m
[92maverage training of epoch 7: loss -2.87463 acc 0.33775 roc_auc 0.57647 prc_auc 0.72189[0m
[93maverage test of epoch 7: loss -3.16748 acc 0.32432 roc_auc 0.78333 prc_auc 0.90668[0m
[92maverage training of epoch 8: loss -3.43779 acc 0.33775 roc_auc 0.57039 prc_auc 0.71348[0m
[93maverage test of epoch 8: loss -3.68943 acc 0.32432 roc_auc 0.72000 prc_auc 0.88073[0m
[92maverage training of epoch 9: loss -3.94108 acc 0.33775 roc_auc 0.56353 prc_auc 0.70620[0m
[93maverage test of epoch 9: loss -4.17542 acc 0.32432 roc_auc 0.67333 prc_auc 0.86294[0m
[92maverage training of epoch 10: loss -4.42010 acc 0.33775 roc_auc 0.55588 prc_auc 0.69417[0m
[93maverage test of epoch 10: loss -4.64608 acc 0.32432 roc_auc 0.62667 prc_auc 0.84033[0m
[92maverage training of epoch 11: loss -4.88844 acc 0.33775 roc_auc 0.54745 prc_auc 0.68799[0m
[93maverage test of epoch 11: loss -5.11003 acc 0.32432 roc_auc 0.61667 prc_auc 0.83148[0m
[92maverage training of epoch 12: loss -5.35234 acc 0.33775 roc_auc 0.53686 prc_auc 0.67747[0m
[93maverage test of epoch 12: loss -5.57134 acc 0.32432 roc_auc 0.60500 prc_auc 0.82699[0m
[92maverage training of epoch 13: loss -5.81415 acc 0.33775 roc_auc 0.53098 prc_auc 0.67315[0m
[93maverage test of epoch 13: loss -6.03116 acc 0.32432 roc_auc 0.58000 prc_auc 0.81318[0m
[92maverage training of epoch 14: loss -6.27532 acc 0.33775 roc_auc 0.52873 prc_auc 0.67240[0m
[93maverage test of epoch 14: loss -6.49127 acc 0.32432 roc_auc 0.57500 prc_auc 0.81151[0m
[92maverage training of epoch 15: loss -6.73742 acc 0.33775 roc_auc 0.52412 prc_auc 0.66828[0m
[93maverage test of epoch 15: loss -6.95295 acc 0.32432 roc_auc 0.56333 prc_auc 0.79927[0m
[92maverage training of epoch 16: loss -7.20153 acc 0.33775 roc_auc 0.51608 prc_auc 0.66084[0m
[93maverage test of epoch 16: loss -7.41714 acc 0.32432 roc_auc 0.53500 prc_auc 0.78550[0m
[92maverage training of epoch 17: loss -7.66851 acc 0.33775 roc_auc 0.50863 prc_auc 0.65639[0m
[93maverage test of epoch 17: loss -7.88462 acc 0.32432 roc_auc 0.50333 prc_auc 0.77251[0m
[92maverage training of epoch 18: loss -8.13905 acc 0.33775 roc_auc 0.50412 prc_auc 0.65259[0m
[93maverage test of epoch 18: loss -8.35601 acc 0.32432 roc_auc 0.46667 prc_auc 0.75649[0m
[92maverage training of epoch 19: loss -8.61374 acc 0.33775 roc_auc 0.49804 prc_auc 0.64888[0m
[93maverage test of epoch 19: loss -8.83185 acc 0.32432 roc_auc 0.44833 prc_auc 0.73851[0m
[92maverage training of epoch 20: loss -9.09304 acc 0.33775 roc_auc 0.49078 prc_auc 0.64467[0m
[93maverage test of epoch 20: loss -9.31253 acc 0.32432 roc_auc 0.44333 prc_auc 0.73553[0m
[92maverage training of epoch 21: loss -9.57726 acc 0.33775 roc_auc 0.48539 prc_auc 0.64289[0m
[93maverage test of epoch 21: loss -9.79823 acc 0.32432 roc_auc 0.39833 prc_auc 0.68779[0m
[92maverage training of epoch 22: loss -10.06633 acc 0.33775 roc_auc 0.47235 prc_auc 0.63709[0m
[93maverage test of epoch 22: loss -10.28862 acc 0.32432 roc_auc 0.36667 prc_auc 0.67523[0m
[92maverage training of epoch 23: loss -10.56000 acc 0.33775 roc_auc 0.45882 prc_auc 0.63056[0m
[93maverage test of epoch 23: loss -10.78372 acc 0.32432 roc_auc 0.32833 prc_auc 0.63958[0m
[92maverage training of epoch 24: loss -11.05845 acc 0.33775 roc_auc 0.45941 prc_auc 0.63103[0m
[93maverage test of epoch 24: loss -11.28377 acc 0.32432 roc_auc 0.27333 prc_auc 0.62300[0m
[92maverage training of epoch 25: loss -11.56205 acc 0.33775 roc_auc 0.45255 prc_auc 0.62695[0m
[93maverage test of epoch 25: loss -11.78929 acc 0.32432 roc_auc 0.23333 prc_auc 0.57917[0m
[92maverage training of epoch 26: loss -12.07137 acc 0.33775 roc_auc 0.44647 prc_auc 0.62494[0m
[93maverage test of epoch 26: loss -12.30086 acc 0.32432 roc_auc 0.23667 prc_auc 0.55844[0m
[92maverage training of epoch 27: loss -12.58695 acc 0.33775 roc_auc 0.44451 prc_auc 0.62272[0m
[93maverage test of epoch 27: loss -12.81896 acc 0.32432 roc_auc 0.26167 prc_auc 0.57757[0m
[92maverage training of epoch 28: loss -13.10924 acc 0.33775 roc_auc 0.44147 prc_auc 0.62300[0m
[93maverage test of epoch 28: loss -13.34402 acc 0.32432 roc_auc 0.25000 prc_auc 0.59454[0m
[92maverage training of epoch 29: loss -13.63863 acc 0.33775 roc_auc 0.43588 prc_auc 0.61814[0m
[93maverage test of epoch 29: loss -13.87639 acc 0.32432 roc_auc 0.26000 prc_auc 0.59535[0m
[92maverage training of epoch 30: loss -14.17545 acc 0.33775 roc_auc 0.43353 prc_auc 0.61788[0m
[93maverage test of epoch 30: loss -14.41638 acc 0.32432 roc_auc 0.25000 prc_auc 0.57037[0m
[92maverage training of epoch 31: loss -14.71999 acc 0.33775 roc_auc 0.43137 prc_auc 0.61331[0m
[93maverage test of epoch 31: loss -14.96425 acc 0.32432 roc_auc 0.25167 prc_auc 0.57435[0m
[92maverage training of epoch 32: loss -15.27249 acc 0.33775 roc_auc 0.42980 prc_auc 0.60595[0m
[93maverage test of epoch 32: loss -15.52023 acc 0.32432 roc_auc 0.18333 prc_auc 0.54600[0m
[92maverage training of epoch 33: loss -15.83317 acc 0.33775 roc_auc 0.42784 prc_auc 0.60324[0m
[93maverage test of epoch 33: loss -16.08452 acc 0.32432 roc_auc 0.32167 prc_auc 0.60719[0m
[92maverage training of epoch 34: loss -16.40222 acc 0.33775 roc_auc 0.42608 prc_auc 0.60259[0m
[93maverage test of epoch 34: loss -16.65730 acc 0.32432 roc_auc 0.26500 prc_auc 0.60452[0m
[92maverage training of epoch 35: loss -16.97979 acc 0.33775 roc_auc 0.42255 prc_auc 0.60234[0m
[93maverage test of epoch 35: loss -17.23870 acc 0.32432 roc_auc 0.35667 prc_auc 0.62948[0mUsing backend: pytorch
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))

[92maverage training of epoch 36: loss -17.56602 acc 0.33775 roc_auc 0.41980 prc_auc 0.60355[0m
[93maverage test of epoch 36: loss -17.82886 acc 0.32432 roc_auc 0.44000 prc_auc 0.65183[0m
[92maverage training of epoch 37: loss -18.16103 acc 0.33775 roc_auc 0.41608 prc_auc 0.60268[0m
[93maverage test of epoch 37: loss -18.42789 acc 0.32432 roc_auc 0.25000 prc_auc 0.58215[0m
[92maverage training of epoch 38: loss -18.76493 acc 0.33775 roc_auc 0.41020 prc_auc 0.59972[0m
[93maverage test of epoch 38: loss -19.03589 acc 0.32432 roc_auc 0.35000 prc_auc 0.62758[0m
[92maverage training of epoch 39: loss -19.37781 acc 0.33775 roc_auc 0.40843 prc_auc 0.59979[0m
[93maverage test of epoch 39: loss -19.65296 acc 0.32432 roc_auc 0.17000 prc_auc 0.59120[0m
[92maverage training of epoch 40: loss -19.99975 acc 0.33775 roc_auc 0.40608 prc_auc 0.60043[0m
[93maverage test of epoch 40: loss -20.27914 acc 0.32432 roc_auc 0.31667 prc_auc 0.60878[0m
[92maverage training of epoch 41: loss -20.63082 acc 0.33775 roc_auc 0.40255 prc_auc 0.59851[0m
[93maverage test of epoch 41: loss -20.91452 acc 0.32432 roc_auc 0.46667 prc_auc 0.65836[0m
[92maverage training of epoch 42: loss -21.27107 acc 0.33775 roc_auc 0.40098 prc_auc 0.60042[0m
[93maverage test of epoch 42: loss -21.55915 acc 0.32432 roc_auc 0.36000 prc_auc 0.62887[0m
[92maverage training of epoch 43: loss -21.92055 acc 0.33775 roc_auc 0.39529 prc_auc 0.60247[0m
[93maverage test of epoch 43: loss -22.21306 acc 0.32432 roc_auc 0.33500 prc_auc 0.61112[0m
[92maverage training of epoch 44: loss -22.57931 acc 0.33775 roc_auc 0.38824 prc_auc 0.59673[0m
[93maverage test of epoch 44: loss -22.87631 acc 0.32432 roc_auc 0.33333 prc_auc 0.64227[0m
[92maverage training of epoch 45: loss -23.24739 acc 0.33775 roc_auc 0.38039 prc_auc 0.59468[0m
[93maverage test of epoch 45: loss -23.54889 acc 0.32432 roc_auc 0.44500 prc_auc 0.66403[0m
[92maverage training of epoch 46: loss -23.92463 acc 0.33775 roc_auc 0.37627 prc_auc 0.59309[0m
[93maverage test of epoch 46: loss -24.23049 acc 0.32432 roc_auc 0.49333 prc_auc 0.67291[0m
[92maverage training of epoch 47: loss -24.61059 acc 0.33775 roc_auc 0.37255 prc_auc 0.59180[0m
[93maverage test of epoch 47: loss -24.92046 acc 0.32432 roc_auc 0.58833 prc_auc 0.75453[0m
[92maverage training of epoch 48: loss -25.30459 acc 0.33775 roc_auc 0.36853 prc_auc 0.58936[0m
[93maverage test of epoch 48: loss -25.61844 acc 0.32432 roc_auc 0.45000 prc_auc 0.68074[0m
[92maverage training of epoch 49: loss -26.00666 acc 0.33775 roc_auc 0.37039 prc_auc 0.58969[0m
[93maverage test of epoch 49: loss -26.32461 acc 0.32432 roc_auc 0.64000 prc_auc 0.75487[0m
[92maverage training of epoch 50: loss -26.71697 acc 0.33775 roc_auc 0.37039 prc_auc 0.58909[0m
[93maverage test of epoch 50: loss -27.03916 acc 0.32432 roc_auc 0.26000 prc_auc 0.59369[0m
[92maverage training of epoch 51: loss -27.43571 acc 0.33775 roc_auc 0.37598 prc_auc 0.59056[0m
[93maverage test of epoch 51: loss -27.76224 acc 0.32432 roc_auc 0.56000 prc_auc 0.71147[0m
[92maverage training of epoch 52: loss -28.16300 acc 0.33775 roc_auc 0.38118 prc_auc 0.59252[0m
[93maverage test of epoch 52: loss -28.49397 acc 0.32432 roc_auc 0.26000 prc_auc 0.59369[0m
[92maverage training of epoch 53: loss -28.89896 acc 0.33775 roc_auc 0.38118 prc_auc 0.59102[0m
[93maverage test of epoch 53: loss -29.23445 acc 0.32432 roc_auc 0.18000 prc_auc 0.60036[0m
[92maverage training of epoch 54: loss -29.64369 acc 0.33775 roc_auc 0.38059 prc_auc 0.58979[0m
[93maverage test of epoch 54: loss -29.98378 acc 0.32432 roc_auc 0.21500 prc_auc 0.59827[0m
[92maverage training of epoch 55: loss -30.39726 acc 0.33775 roc_auc 0.38147 prc_auc 0.58959[0m
[93maverage test of epoch 55: loss -30.74205 acc 0.32432 roc_auc 0.59833 prc_auc 0.74019[0m
[92maverage training of epoch 56: loss -31.15976 acc 0.33775 roc_auc 0.38108 prc_auc 0.58782[0m
[93maverage test of epoch 56: loss -31.50928 acc 0.32432 roc_auc 0.18000 prc_auc 0.58925[0m
[92maverage training of epoch 57: loss -31.93124 acc 0.33775 roc_auc 0.37725 prc_auc 0.58558[0m
[93maverage test of epoch 57: loss -32.28560 acc 0.32432 roc_auc 0.44000 prc_auc 0.64988[0m
[92maverage training of epoch 58: loss -32.71177 acc 0.33775 roc_auc 0.37569 prc_auc 0.58490[0m
[93maverage test of epoch 58: loss -33.07097 acc 0.32432 roc_auc 0.46000 prc_auc 0.65827[0m
[92maverage training of epoch 59: loss -33.50135 acc 0.33775 roc_auc 0.37520 prc_auc 0.58480[0m
[93maverage test of epoch 59: loss -33.86549 acc 0.32432 roc_auc 0.46000 prc_auc 0.65827[0m
[92maverage training of epoch 60: loss -34.30008 acc 0.33775 roc_auc 0.37510 prc_auc 0.58635[0m
[93maverage test of epoch 60: loss -34.66922 acc 0.32432 roc_auc 0.44000 prc_auc 0.65369[0m
[92maverage training of epoch 61: loss -35.10796 acc 0.33775 roc_auc 0.37392 prc_auc 0.58572[0m
[93maverage test of epoch 61: loss -35.48210 acc 0.32432 roc_auc 0.54667 prc_auc 0.71274[0m
[92maverage training of epoch 62: loss -35.92495 acc 0.33775 roc_auc 0.37225 prc_auc 0.58377[0m
[93maverage test of epoch 62: loss -36.30417 acc 0.32432 roc_auc 0.66000 prc_auc 0.77703[0m
[92maverage training of epoch 63: loss -36.75114 acc 0.33775 roc_auc 0.37235 prc_auc 0.58385[0m
[93maverage test of epoch 63: loss -37.13549 acc 0.32432 roc_auc 0.74000 prc_auc 0.82211[0m
[92maverage training of epoch 64: loss -37.58656 acc 0.33775 roc_auc 0.37137 prc_auc 0.58310[0m
[93maverage test of epoch 64: loss -37.97614 acc 0.32432 roc_auc 0.52000 prc_auc 0.69369[0m
[92maverage training of epoch 65: loss -38.43127 acc 0.33775 roc_auc 0.36833 prc_auc 0.58140[0m
[93maverage test of epoch 65: loss -38.82603 acc 0.32432 roc_auc 0.66000 prc_auc 0.76703[0m
[92maverage training of epoch 66: loss -39.28517 acc 0.33775 roc_auc 0.36588 prc_auc 0.58017[0m
[93maverage test of epoch 66: loss -39.68521 acc 0.32432 roc_auc 0.32000 prc_auc 0.60885[0m
[92maverage training of epoch 67: loss -40.14835 acc 0.33775 roc_auc 0.36431 prc_auc 0.57922[0m
[93maverage test of epoch 67: loss -40.55368 acc 0.32432 roc_auc 0.42000 prc_auc 0.64227[0m
[92maverage training of epoch 68: loss -41.02071 acc 0.33775 roc_auc 0.36353 prc_auc 0.57983[0m
[93maverage test of epoch 68: loss -41.43131 acc 0.32432 roc_auc 0.68000 prc_auc 0.77931[0m
[92maverage training of epoch 69: loss -41.90221 acc 0.33775 roc_auc 0.36392 prc_auc 0.57911[0m
[93maverage test of epoch 69: loss -42.31819 acc 0.32432 roc_auc 0.46000 prc_auc 0.65827[0m
[92maverage training of epoch 70: loss -42.79299 acc 0.33775 roc_auc 0.36392 prc_auc 0.57984[0m
[93maverage test of epoch 70: loss -43.21441 acc 0.32432 roc_auc 0.28000 prc_auc 0.59746[0m
[92maverage training of epoch 71: loss -43.69307 acc 0.33775 roc_auc 0.36451 prc_auc 0.57876[0m
[93maverage test of epoch 71: loss -44.11996 acc 0.32432 roc_auc 0.32000 prc_auc 0.60729[0m
[92maverage training of epoch 72: loss -44.60244 acc 0.33775 roc_auc 0.36461 prc_auc 0.57804[0m
[93maverage test of epoch 72: loss -45.03486 acc 0.32432 roc_auc 0.58000 prc_auc 0.72536[0m
[92maverage training of epoch 73: loss -45.52110 acc 0.33775 roc_auc 0.36569 prc_auc 0.57872[0m
[93maverage test of epoch 73: loss -45.95906 acc 0.32432 roc_auc 0.48000 prc_auc 0.66703[0m
[92maverage training of epoch 74: loss -46.44904 acc 0.33775 roc_auc 0.36706 prc_auc 0.57911[0m
[93maverage test of epoch 74: loss -46.89255 acc 0.32432 roc_auc 0.19500 prc_auc 0.60235[0m
[92maverage training of epoch 75: loss -47.38614 acc 0.33775 roc_auc 0.36657 prc_auc 0.57854[0m
[93maverage test of epoch 75: loss -47.83522 acc 0.32432 roc_auc 0.34000 prc_auc 0.61318[0m
[92maverage training of epoch 76: loss -48.33247 acc 0.33775 roc_auc 0.36608 prc_auc 0.57673[0m
[93maverage test of epoch 76: loss -48.78721 acc 0.32432 roc_auc 0.62000 prc_auc 0.75103[0m
[92maverage training of epoch 77: loss -49.28806 acc 0.33775 roc_auc 0.36569 prc_auc 0.57581[0m
[93maverage test of epoch 77: loss -49.74849 acc 0.32432 roc_auc 0.48000 prc_auc 0.66703[0m
[92maverage training of epoch 78: loss -50.25289 acc 0.33775 roc_auc 0.36529 prc_auc 0.57576[0m
[93maverage test of epoch 78: loss -50.71902 acc 0.32432 roc_auc 0.54000 prc_auc 0.69491[0m
[92maverage training of epoch 79: loss -51.22694 acc 0.33775 roc_auc 0.36627 prc_auc 0.57586[0m
[93maverage test of epoch 79: loss -51.69884 acc 0.32432 roc_auc 0.76000 prc_auc 0.84271[0m
[92maverage training of epoch 80: loss -52.21024 acc 0.33775 roc_auc 0.36657 prc_auc 0.57544[0m
[93maverage test of epoch 80: loss -52.68793 acc 0.32432 roc_auc 0.50000 prc_auc 0.68036[0m
[92maverage training of epoch 81: loss -53.20277 acc 0.33775 roc_auc 0.36765 prc_auc 0.57566[0m
[93maverage test of epoch 81: loss -53.68630 acc 0.32432 roc_auc 0.48000 prc_auc 0.66703[0m
[92maverage training of epoch 82: loss -54.20453 acc 0.33775 roc_auc 0.36765 prc_auc 0.57563[0m
[93maverage test of epoch 82: loss -54.69393 acc 0.32432 roc_auc 0.48000 prc_auc 0.66703[0m
[92maverage training of epoch 83: loss -55.21551 acc 0.33775 roc_auc 0.36892 prc_auc 0.57558[0m
[93maverage test of epoch 83: loss -55.71081 acc 0.32432 roc_auc 0.28000 prc_auc 0.59079[0m
[92maverage training of epoch 84: loss -56.23568 acc 0.33775 roc_auc 0.36941 prc_auc 0.57520[0m
[93maverage test of epoch 84: loss -56.73690 acc 0.32432 roc_auc 0.48000 prc_auc 0.66703[0m
[92maverage training of epoch 85: loss -57.26502 acc 0.33775 roc_auc 0.37029 prc_auc 0.57467[0m
[93maverage test of epoch 85: loss -57.77218 acc 0.32432 roc_auc 0.48000 prc_auc 0.66703[0m
[92maverage training of epoch 86: loss -58.30352 acc 0.33775 roc_auc 0.36961 prc_auc 0.57378[0m
[93maverage test of epoch 86: loss -58.81671 acc 0.32432 roc_auc 0.50000 prc_auc 0.68036[0m
[92maverage training of epoch 87: loss -59.35123 acc 0.33775 roc_auc 0.37098 prc_auc 0.57456[0m
[93maverage test of epoch 87: loss -59.87045 acc 0.32432 roc_auc 0.62000 prc_auc 0.73627[0m
[92maverage training of epoch 88: loss -60.40809 acc 0.33775 roc_auc 0.37167 prc_auc 0.57406[0m
[93maverage test of epoch 88: loss -60.93331 acc 0.32432 roc_auc 0.16000 prc_auc 0.62824[0m
[92maverage training of epoch 89: loss -61.47357 acc 0.33775 roc_auc 0.37118 prc_auc 0.57369[0m
[93maverage test of epoch 89: loss -62.00436 acc 0.32432 roc_auc 0.70000 prc_auc 0.80322[0m
[92maverage training of epoch 90: loss -62.54706 acc 0.33775 roc_auc 0.37431 prc_auc 0.57489[0m
[93maverage test of epoch 90: loss -63.08348 acc 0.32432 roc_auc 0.48000 prc_auc 0.66703[0m
[92maverage training of epoch 91: loss -63.62867 acc 0.33775 roc_auc 0.37431 prc_auc 0.57472[0m
[93maverage test of epoch 91: loss -64.17084 acc 0.32432 roc_auc 0.46000 prc_auc 0.65827[0m
[92maverage training of epoch 92: loss -64.71852 acc 0.33775 roc_auc 0.37451 prc_auc 0.57599[0m
[93maverage test of epoch 92: loss -65.26655 acc 0.32432 roc_auc 0.48000 prc_auc 0.66703[0m
[92maverage training of epoch 93: loss -65.81675 acc 0.33775 roc_auc 0.37431 prc_auc 0.57385[0m
[93maverage test of epoch 93: loss -66.37073 acc 0.32432 roc_auc 0.14000 prc_auc 0.61472[0m
[92maverage training of epoch 94: loss -66.92344 acc 0.33775 roc_auc 0.37510 prc_auc 0.57409[0m
[93maverage test of epoch 94: loss -67.48346 acc 0.32432 roc_auc 0.48000 prc_auc 0.66703[0m
[92maverage training of epoch 95: loss -68.03867 acc 0.33775 roc_auc 0.37471 prc_auc 0.57302[0m
[93maverage test of epoch 95: loss -68.60481 acc 0.32432 roc_auc 0.46000 prc_auc 0.68162[0m
[92maverage training of epoch 96: loss -69.16252 acc 0.45033 roc_auc 0.37549 prc_auc 0.57285[0m
[93maverage test of epoch 96: loss -69.73485 acc 0.67568 roc_auc 0.48000 prc_auc 0.66703[0m
[92maverage training of epoch 97: loss -70.29505 acc 0.66225 roc_auc 0.37608 prc_auc 0.57297[0m
[93maverage test of epoch 97: loss -70.87363 acc 0.67568 roc_auc 0.43667 prc_auc 0.66198[0m
[92maverage training of epoch 98: loss -71.43630 acc 0.66225 roc_auc 0.37569 prc_auc 0.57261[0m
[93maverage test of epoch 98: loss -72.02122 acc 0.67568 roc_auc 0.44000 prc_auc 0.64988[0m
[92maverage training of epoch 99: loss -72.58632 acc 0.66225 roc_auc 0.37490 prc_auc 0.57062[0m
[93maverage test of epoch 99: loss -73.17761 acc 0.67568 roc_auc 0.48000 prc_auc 0.66703[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss 0.90372 acc 0.64901 roc_auc 0.55255 prc_auc 0.71437[0m
[93maverage test of epoch 0: loss 0.65184 acc 0.67568 roc_auc 0.35000 prc_auc 0.66080[0m
[92maverage training of epoch 1: loss 0.40839 acc 0.52318 roc_auc 0.47471 prc_auc 0.68375[0m
[93maverage test of epoch 1: loss 0.17254 acc 0.32432 roc_auc 0.41667 prc_auc 0.69396[0m
[92maverage training of epoch 2: loss 0.07502 acc 0.34437 roc_auc 0.38549 prc_auc 0.62347[0m
[93maverage test of epoch 2: loss -0.00147 acc 0.32432 roc_auc 0.25000 prc_auc 0.55296[0m
[92maverage training of epoch 3: loss -0.08102 acc 0.33775 roc_auc 0.32255 prc_auc 0.59349[0m
[93maverage test of epoch 3: loss -0.15799 acc 0.32432 roc_auc 0.17333 prc_auc 0.52591[0m
[92maverage training of epoch 4: loss -0.24282 acc 0.33775 roc_auc 0.28647 prc_auc 0.57120[0m
[93maverage test of epoch 4: loss -0.32580 acc 0.32432 roc_auc 0.13667 prc_auc 0.54522[0m
[92maverage training of epoch 5: loss -0.41913 acc 0.33775 roc_auc 0.25510 prc_auc 0.55669[0m
[93maverage test of epoch 5: loss -0.51087 acc 0.32432 roc_auc 0.12667 prc_auc 0.56303[0m
[92maverage training of epoch 6: loss -0.60925 acc 0.33775 roc_auc 0.23353 prc_auc 0.56034[0m
[93maverage test of epoch 6: loss -0.70519 acc 0.32432 roc_auc 0.15667 prc_auc 0.58572[0m
[92maverage training of epoch 7: loss -0.81386 acc 0.33775 roc_auc 0.31529 prc_auc 0.60423[0m
[93maverage test of epoch 7: loss -0.92466 acc 0.32432 roc_auc 0.19167 prc_auc 0.60756[0m
[92maverage training of epoch 8: loss -1.04784 acc 0.33775 roc_auc 0.35843 prc_auc 0.63289[0m
[93maverage test of epoch 8: loss -1.17574 acc 0.32432 roc_auc 0.17667 prc_auc 0.59623[0m
[92maverage training of epoch 9: loss -1.32332 acc 0.37086 roc_auc 0.37510 prc_auc 0.61177[0m
[93maverage test of epoch 9: loss -1.47749 acc 0.67568 roc_auc 0.40333 prc_auc 0.73732[0m
[92maverage training of epoch 10: loss -1.64606 acc 0.66225 roc_auc 0.44627 prc_auc 0.66608[0m
[93maverage test of epoch 10: loss -1.81698 acc 0.67568 roc_auc 0.92667 prc_auc 0.97104[0m
[92maverage training of epoch 11: loss -1.98213 acc 0.66225 roc_auc 0.47941 prc_auc 0.67472[0m
[93maverage test of epoch 11: loss -2.14686 acc 0.67568 roc_auc 0.93333 prc_auc 0.97304[0m
[92maverage training of epoch 12: loss -2.29969 acc 0.66225 roc_auc 0.46039 prc_auc 0.65583[0m
[93maverage test of epoch 12: loss -2.45530 acc 0.67568 roc_auc 0.87333 prc_auc 0.95069[0m
[92maverage training of epoch 13: loss -2.60036 acc 0.66225 roc_auc 0.43255 prc_auc 0.63764[0m
[93maverage test of epoch 13: loss -2.75195 acc 0.67568 roc_auc 0.62000 prc_auc 0.84905[0m
[92maverage training of epoch 14: loss -2.89203 acc 0.66225 roc_auc 0.40157 prc_auc 0.60883[0m
[93maverage test of epoch 14: loss -3.04186 acc 0.67568 roc_auc 0.19667 prc_auc 0.59822[0m
[92maverage training of epoch 15: loss -3.17925 acc 0.66225 roc_auc 0.37902 prc_auc 0.59636[0m
[93maverage test of epoch 15: loss -3.32911 acc 0.67568 roc_auc 0.16500 prc_auc 0.58856[0m
[92maverage training of epoch 16: loss -3.46427 acc 0.66225 roc_auc 0.37745 prc_auc 0.59715[0m
[93maverage test of epoch 16: loss -3.61465 acc 0.67568 roc_auc 0.20333 prc_auc 0.60125[0m
[92maverage training of epoch 17: loss -3.74841 acc 0.66225 roc_auc 0.37118 prc_auc 0.58530[0m
[93maverage test of epoch 17: loss -3.90022 acc 0.67568 roc_auc 0.17500 prc_auc 0.59129[0m
[92maverage training of epoch 18: loss -4.03254 acc 0.66225 roc_auc 0.36098 prc_auc 0.57982[0m
[93maverage test of epoch 18: loss -4.18557 acc 0.67568 roc_auc 0.13000 prc_auc 0.53483[0m
[92maverage training of epoch 19: loss -4.31740 acc 0.66225 roc_auc 0.36471 prc_auc 0.58383[0m
[93maverage test of epoch 19: loss -4.47251 acc 0.67568 roc_auc 0.13333 prc_auc 0.53650[0m
[92maverage training of epoch 20: loss -4.60347 acc 0.66225 roc_auc 0.35824 prc_auc 0.57782[0m
[93maverage test of epoch 20: loss -4.76065 acc 0.67568 roc_auc 0.13667 prc_auc 0.53841[0m
[92maverage training of epoch 21: loss -4.89127 acc 0.66225 roc_auc 0.35549 prc_auc 0.57733[0m
[93maverage test of epoch 21: loss -5.05067 acc 0.67568 roc_auc 0.14333 prc_auc 0.54233[0m
[92maverage training of epoch 22: loss -5.18115 acc 0.66225 roc_auc 0.34176 prc_auc 0.56613[0m
[93maverage test of epoch 22: loss -5.34293 acc 0.67568 roc_auc 0.13333 prc_auc 0.53674[0m
[92maverage training of epoch 23: loss -5.47357 acc 0.66225 roc_auc 0.34078 prc_auc 0.56505[0m
[93maverage test of epoch 23: loss -5.63785 acc 0.67568 roc_auc 0.12667 prc_auc 0.53377[0m
[92maverage training of epoch 24: loss -5.76882 acc 0.66225 roc_auc 0.33706 prc_auc 0.55456[0m
[93maverage test of epoch 24: loss -5.93545 acc 0.67568 roc_auc 0.12667 prc_auc 0.53377[0m
[92maverage training of epoch 25: loss -6.06715 acc 0.66225 roc_auc 0.32980 prc_auc 0.56056[0m
[93maverage test of epoch 25: loss -6.23686 acc 0.67568 roc_auc 0.13000 prc_auc 0.53522[0m
[92maverage training of epoch 26: loss -6.36952 acc 0.66225 roc_auc 0.33333 prc_auc 0.56216[0m
[93maverage test of epoch 26: loss -6.54220 acc 0.67568 roc_auc 0.12667 prc_auc 0.53377[0m
[92maverage training of epoch 27: loss -6.67615 acc 0.66225 roc_auc 0.33451 prc_auc 0.56669[0m
[93maverage test of epoch 27: loss -6.85250 acc 0.67568 roc_auc 0.13333 prc_auc 0.53674[0m
[92maverage training of epoch 28: loss -6.98831 acc 0.66225 roc_auc 0.34216 prc_auc 0.56545[0m
[93maverage test of epoch 28: loss -7.16891 acc 0.67568 roc_auc 0.14333 prc_auc 0.54233[0m
[92maverage training of epoch 29: loss -7.30762 acc 0.66225 roc_auc 0.35039 prc_auc 0.56916[0m
[93maverage test of epoch 29: loss -7.49341 acc 0.67568 roc_auc 0.14333 prc_auc 0.54233[0m
[92maverage training of epoch 30: loss -7.63617 acc 0.66225 roc_auc 0.35176 prc_auc 0.56111[0m
[93maverage test of epoch 30: loss -7.82833 acc 0.67568 roc_auc 0.13000 prc_auc 0.53522[0m
[92maverage training of epoch 31: loss -7.97575 acc 0.66225 roc_auc 0.35235 prc_auc 0.56070[0m
[93maverage test of epoch 31: loss -8.17445 acc 0.67568 roc_auc 0.12333 prc_auc 0.53209[0m
[92maverage training of epoch 32: loss -8.32566 acc 0.66225 roc_auc 0.35373 prc_auc 0.56117[0m
[93maverage test of epoch 32: loss -8.52984 acc 0.67568 roc_auc 0.08667 prc_auc 0.49366[0m
[92maverage training of epoch 33: loss -8.68367 acc 0.66225 roc_auc 0.35686 prc_auc 0.56589[0m
[93maverage test of epoch 33: loss -8.89230 acc 0.67568 roc_auc 0.07333 prc_auc 0.48872[0m
[92maverage training of epoch 34: loss -9.04785 acc 0.66225 roc_auc 0.36078 prc_auc 0.56922[0m
[93maverage test of epoch 34: loss -9.26022 acc 0.67568 roc_auc 0.07000 prc_auc 0.48739[0m
[92maverage training of epoch 35: loss -9.41700 acc 0.66225 roc_auc 0.36520 prc_auc 0.57368[0m
[93maverage test of epoch 35: loss -9.63288 acc 0.67568 roc_auc 0.06667 prc_auc 0.48630[0m
[92maverage training of epoch 36: loss -9.79068 acc 0.66225 roc_auc 0.36706 prc_auc 0.57530[0m
[93maverage test of epoch 36: loss -10.01011 acc 0.67568 roc_auc 0.06667 prc_auc 0.48630[0m
[92maverage training of epoch 37: loss -10.16888 acc 0.66225 roc_auc 0.37392 prc_auc 0.58290[0m
[93maverage test of epoch 37: loss -10.39199 acc 0.67568 roc_auc 0.05667 prc_auc 0.48606[0m
[92maverage training of epoch 38: loss -10.55160 acc 0.66225 roc_auc 0.37343 prc_auc 0.58112[0m
[93maverage test of epoch 38: loss -10.77832 acc 0.67568 roc_auc 0.05667 prc_auc 0.48442[0m
[92maverage training of epoch 39: loss -10.93883 acc 0.66225 roc_auc 0.37647 prc_auc 0.58317[0m
[93maverage test of epoch 39: loss -11.16935 acc 0.67568 roc_auc 0.05667 prc_auc 0.48501[0m
[92maverage training of epoch 40: loss -11.33092 acc 0.66225 roc_auc 0.37794 prc_auc 0.58459[0m
[93maverage test of epoch 40: loss -11.56530 acc 0.67568 roc_auc 0.05667 prc_auc 0.48755[0m
[92maverage training of epoch 41: loss -11.72794 acc 0.66225 roc_auc 0.38000 prc_auc 0.58655[0m
[93maverage test of epoch 41: loss -11.96635 acc 0.67568 roc_auc 0.05333 prc_auc 0.48741[0m
[92maverage training of epoch 42: loss -12.13011 acc 0.66225 roc_auc 0.38078 prc_auc 0.58719[0m
[93maverage test of epoch 42: loss -12.37265 acc 0.67568 roc_auc 0.05333 prc_auc 0.48371[0m
[92maverage training of epoch 43: loss -12.53759 acc 0.66225 roc_auc 0.38216 prc_auc 0.58806[0m
[93maverage test of epoch 43: loss -12.78435 acc 0.67568 roc_auc 0.05333 prc_auc 0.48849[0m
[92maverage training of epoch 44: loss -12.95051 acc 0.66225 roc_auc 0.38255 prc_auc 0.58840[0m
[93maverage test of epoch 44: loss -13.20158 acc 0.67568 roc_auc 0.06000 prc_auc 0.48882[0m
[92maverage training of epoch 45: loss -13.36898 acc 0.66225 roc_auc 0.38255 prc_auc 0.58842[0m
[93maverage test of epoch 45: loss -13.62443 acc 0.67568 roc_auc 0.06167 prc_auc 0.49176[0m
[92maverage training of epoch 46: loss -13.79309 acc 0.66225 roc_auc 0.38255 prc_auc 0.58855[0m
[93maverage test of epoch 46: loss -14.05300 acc 0.67568 roc_auc 0.06000 prc_auc 0.49178[0m
[92maverage training of epoch 47: loss -14.22294 acc 0.66225 roc_auc 0.38255 prc_auc 0.59017[0m
[93maverage test of epoch 47: loss -14.48736 acc 0.67568 roc_auc 0.06000 prc_auc 0.49870[0m
[92maverage training of epoch 48: loss -14.65858 acc 0.66225 roc_auc 0.38294 prc_auc 0.59057[0m
[93maverage test of epoch 48: loss -14.92757 acc 0.67568 roc_auc 0.06500 prc_auc 0.50046[0m
[92maverage training of epoch 49: loss -15.10010 acc 0.66225 roc_auc 0.38333 prc_auc 0.59119[0m
[93maverage test of epoch 49: loss -15.37371 acc 0.67568 roc_auc 0.07833 prc_auc 0.51292[0m
[92maverage training of epoch 50: loss -15.54752 acc 0.66225 roc_auc 0.38392 prc_auc 0.59184[0m
[93maverage test of epoch 50: loss -15.82581 acc 0.67568 roc_auc 0.08167 prc_auc 0.53120[0m
[92maverage training of epoch 51: loss -16.00091 acc 0.66225 roc_auc 0.38471 prc_auc 0.59224[0m
[93maverage test of epoch 51: loss -16.28392 acc 0.67568 roc_auc 0.09667 prc_auc 0.53960[0m
[92maverage training of epoch 52: loss -16.46030 acc 0.66225 roc_auc 0.38539 prc_auc 0.59251[0m
[93maverage test of epoch 52: loss -16.74809 acc 0.67568 roc_auc 0.14000 prc_auc 0.56913[0m
[92maverage training of epoch 53: loss -16.92575 acc 0.66225 roc_auc 0.38657 prc_auc 0.59323[0m
[93maverage test of epoch 53: loss -17.21834 acc 0.67568 roc_auc 0.23167 prc_auc 0.62383[0m
[92maverage training of epoch 54: loss -17.39716 acc 0.66225 roc_auc 0.38647 prc_auc 0.58832[0m
[93maverage test of epoch 54: loss -17.69444 acc 0.67568 roc_auc 0.29333 prc_auc 0.60896[0m
[92maverage training of epoch 55: loss -17.87435 acc 0.66225 roc_auc 0.38627 prc_auc 0.58673[0m
[93maverage test of epoch 55: loss -18.17635 acc 0.67568 roc_auc 0.20000 prc_auc 0.58722[0m
[92maverage training of epoch 56: loss -18.35736 acc 0.66225 roc_auc 0.38627 prc_auc 0.58598[0m
[93maverage test of epoch 56: loss -18.66415 acc 0.67568 roc_auc 0.37000 prc_auc 0.63351[0m
[92maverage training of epoch 57: loss -18.84627 acc 0.66225 roc_auc 0.38647 prc_auc 0.58641[0m
[93maverage test of epoch 57: loss -19.15791 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 58: loss -19.34115 acc 0.66225 roc_auc 0.38647 prc_auc 0.58626[0m
[93maverage test of epoch 58: loss -19.65770 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 59: loss -19.84205 acc 0.66225 roc_auc 0.38667 prc_auc 0.58702[0m
[93maverage test of epoch 59: loss -20.16356 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 60: loss -20.34903 acc 0.66225 roc_auc 0.38618 prc_auc 0.58629[0m
[93maverage test of epoch 60: loss -20.67555 acc 0.67568 roc_auc 0.50333 prc_auc 0.67714[0m
[92maverage training of epoch 61: loss -20.86211 acc 0.66225 roc_auc 0.38627 prc_auc 0.58666[0m
[93maverage test of epoch 61: loss -21.19369 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 62: loss -21.38135 acc 0.66225 roc_auc 0.38608 prc_auc 0.58678[0m
[93maverage test of epoch 62: loss -21.71803 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 63: loss -21.90677 acc 0.66225 roc_auc 0.38588 prc_auc 0.58658[0m
[93maverage test of epoch 63: loss -22.24859 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 64: loss -22.43840 acc 0.66225 roc_auc 0.38539 prc_auc 0.58598[0m
[93maverage test of epoch 64: loss -22.78540 acc 0.67568 roc_auc 0.56000 prc_auc 0.71459[0m
[92maverage training of epoch 65: loss -22.97626 acc 0.66225 roc_auc 0.38480 prc_auc 0.58536[0m
[93maverage test of epoch 65: loss -23.32847 acc 0.67568 roc_auc 0.62667 prc_auc 0.73663[0m
[92maverage training of epoch 66: loss -23.52035 acc 0.66225 roc_auc 0.38500 prc_auc 0.58552[0m
[93maverage test of epoch 66: loss -23.87781 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 67: loss -24.07071 acc 0.66225 roc_auc 0.38529 prc_auc 0.58605[0m
[93maverage test of epoch 67: loss -24.43344 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 68: loss -24.62732 acc 0.66225 roc_auc 0.38539 prc_auc 0.58631[0m
[93maverage test of epoch 68: loss -24.99536 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 69: loss -25.19020 acc 0.66225 roc_auc 0.38588 prc_auc 0.58621[0m
[93maverage test of epoch 69: loss -25.56359 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 70: loss -25.75937 acc 0.66225 roc_auc 0.38637 prc_auc 0.58665[0m
[93maverage test of epoch 70: loss -26.13813 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 71: loss -26.33482 acc 0.66225 roc_auc 0.38608 prc_auc 0.58608[0m
[93maverage test of epoch 71: loss -26.71898 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 72: loss -26.91656 acc 0.66225 roc_auc 0.38637 prc_auc 0.58683[0m
[93maverage test of epoch 72: loss -27.30615 acc 0.67568 roc_auc 0.44667 prc_auc 0.65366[0m
[92maverage training of epoch 73: loss -27.50458 acc 0.66225 roc_auc 0.38549 prc_auc 0.58615[0m
[93maverage test of epoch 73: loss -27.89962 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 74: loss -28.09888 acc 0.66225 roc_auc 0.38569 prc_auc 0.58597[0m
[93maverage test of epoch 74: loss -28.49941 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 75: loss -28.69948 acc 0.66225 roc_auc 0.38578 prc_auc 0.58641[0m
[93maverage test of epoch 75: loss -29.10551 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 76: loss -29.30634 acc 0.66225 roc_auc 0.38627 prc_auc 0.58724[0m
[93maverage test of epoch 76: loss -29.71784 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 77: loss -29.91900 acc 0.66225 roc_auc 0.38578 prc_auc 0.58674[0m
[93maverage test of epoch 77: loss -30.33556 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 78: loss -30.53690 acc 0.66225 roc_auc 0.38706 prc_auc 0.58510[0m
[93maverage test of epoch 78: loss -30.95859 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 79: loss -31.16015 acc 0.66225 roc_auc 0.38657 prc_auc 0.58759[0m
[93maverage test of epoch 79: loss -31.58705 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 80: loss -31.78885 acc 0.66225 roc_auc 0.38696 prc_auc 0.58655[0m
[93maverage test of epoch 80: loss -32.22105 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 81: loss -32.42312 acc 0.66225 roc_auc 0.38588 prc_auc 0.58529[0m
[93maverage test of epoch 81: loss -32.86069 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 82: loss -33.06305 acc 0.66225 roc_auc 0.38686 prc_auc 0.58615[0m
[93maverage test of epoch 82: loss -33.50606 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 83: loss -33.70869 acc 0.66225 roc_auc 0.38676 prc_auc 0.58454[0m
[93maverage test of epoch 83: loss -34.15720 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 84: loss -34.36012 acc 0.66225 roc_auc 0.38745 prc_auc 0.58512[0m
[93maverage test of epoch 84: loss -34.81418 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 85: loss -35.01738 acc 0.66225 roc_auc 0.38833 prc_auc 0.58728[0m
[93maverage test of epoch 85: loss -35.47705 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 86: loss -35.68053 acc 0.66225 roc_auc 0.38814 prc_auc 0.58668[0m
[93maverage test of epoch 86: loss -36.14584 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 87: loss -36.34959 acc 0.66225 roc_auc 0.38824 prc_auc 0.58731[0m
[93maverage test of epoch 87: loss -36.82059 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 88: loss -37.02460 acc 0.66225 roc_auc 0.39078 prc_auc 0.58495[0m
[93maverage test of epoch 88: loss -37.50134 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 89: loss -37.70559 acc 0.66225 roc_auc 0.39157 prc_auc 0.58761[0m
[93maverage test of epoch 89: loss -38.18810 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 90: loss -38.39256 acc 0.66225 roc_auc 0.38755 prc_auc 0.58402[0m
[93maverage test of epoch 90: loss -38.88089 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 91: loss -39.08558 acc 0.66225 roc_auc 0.39304 prc_auc 0.58512[0m
[93maverage test of epoch 91: loss -39.57975 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 92: loss -39.78461 acc 0.66225 roc_auc 0.39647 prc_auc 0.58767[0m
[93maverage test of epoch 92: loss -40.28465 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 93: loss -40.48967 acc 0.66225 roc_auc 0.39765 prc_auc 0.59064[0m
[93maverage test of epoch 93: loss -40.99562 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 94: loss -41.20082 acc 0.66225 roc_auc 0.39735 prc_auc 0.59163[0m
[93maverage test of epoch 94: loss -41.71275 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 95: loss -41.91806 acc 0.66225 roc_auc 0.39059 prc_auc 0.58937[0m
[93maverage test of epoch 95: loss -42.43596 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 96: loss -42.64136 acc 0.66225 roc_auc 0.39275 prc_auc 0.59116[0m
[93maverage test of epoch 96: loss -43.16523 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 97: loss -43.37071 acc 0.66225 roc_auc 0.39049 prc_auc 0.59072[0m
[93maverage test of epoch 97: loss -43.90063 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 98: loss -44.10613 acc 0.66225 roc_auc 0.39627 prc_auc 0.59543[0m
[93maverage test of epoch 98: loss -44.64209 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 99: loss -44.84763 acc 0.66225 roc_auc 0.38441 prc_auc 0.58826[0m
[93maverage test of epoch 99: loss -45.38969 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 1)
('lr', 0.0001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.66501 ROC_AUC (avg): 0.496 PRC_AUC (avg): 0.66328 

Average forward propagation time taken(ms): 2.818099017271701
Average backward propagation time taken(ms): 0.9443248792388629

