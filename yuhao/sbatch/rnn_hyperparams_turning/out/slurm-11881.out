# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 1)
('lr', 0.0003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-20-01-28/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-20-01-28/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 8,
 'epochs': 50,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 4,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.0003,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 2,
 'num_workers': 8,
 'number_of_mlp_layer': 1,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-17-20-01-28',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 50, 'learning_rate': 0.0003, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss 0.09729 acc 0.33333 roc_auc 0.56940 prc_auc 0.72833[0m
[93maverage test of epoch 0: loss -0.01277 acc 0.34211 roc_auc 0.52000 prc_auc 0.69222[0m
[92maverage training of epoch 1: loss -0.03628 acc 0.33333 roc_auc 0.35800 prc_auc 0.58375[0m
[93maverage test of epoch 1: loss -0.07368 acc 0.34211 roc_auc 0.60000 prc_auc 0.71956[0m
[92maverage training of epoch 2: loss -0.08780 acc 0.33333 roc_auc 0.44500 prc_auc 0.63624[0m
[93maverage test of epoch 2: loss -0.11575 acc 0.34211 roc_auc 0.49538 prc_auc 0.63470[0m
[92maverage training of epoch 3: loss -0.12627 acc 0.33333 roc_auc 0.44300 prc_auc 0.60640[0m
[93maverage test of epoch 3: loss -0.14714 acc 0.34211 roc_auc 0.38769 prc_auc 0.60766[0m
[92maverage training of epoch 4: loss -0.16091 acc 0.33333 roc_auc 0.39270 prc_auc 0.57309[0m
[93maverage test of epoch 4: loss -0.18364 acc 0.34211 roc_auc 0.57692 prc_auc 0.69444[0m
[92maverage training of epoch 5: loss -0.19362 acc 0.33333 roc_auc 0.34790 prc_auc 0.56130[0m
[93maverage test of epoch 5: loss -0.21616 acc 0.34211 roc_auc 0.53846 prc_auc 0.67568[0m
[92maverage training of epoch 6: loss -0.22719 acc 0.33333 roc_auc 0.36860 prc_auc 0.56650[0m
[93maverage test of epoch 6: loss -0.24800 acc 0.34211 roc_auc 0.44000 prc_auc 0.63096[0m
[92maverage training of epoch 7: loss -0.26026 acc 0.33333 roc_auc 0.36480 prc_auc 0.56567[0m
[93maverage test of epoch 7: loss -0.28189 acc 0.34211 roc_auc 0.52000 prc_auc 0.66703[0m
[92maverage training of epoch 8: loss -0.29340 acc 0.33333 roc_auc 0.37440 prc_auc 0.56946[0m
[93maverage test of epoch 8: loss -0.31479 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 9: loss -0.32657 acc 0.33333 roc_auc 0.37560 prc_auc 0.57051[0m
[93maverage test of epoch 9: loss -0.34784 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 10: loss -0.35960 acc 0.33333 roc_auc 0.35140 prc_auc 0.56042[0m
[93maverage test of epoch 10: loss -0.38074 acc 0.34211 roc_auc 0.48000 prc_auc 0.64902[0m
[92maverage training of epoch 11: loss -0.39287 acc 0.33333 roc_auc 0.35250 prc_auc 0.56020[0m
[93maverage test of epoch 11: loss -0.41369 acc 0.34211 roc_auc 0.48000 prc_auc 0.64902[0m
[92maverage training of epoch 12: loss -0.42598 acc 0.33333 roc_auc 0.35340 prc_auc 0.56061[0m
[93maverage test of epoch 12: loss -0.44697 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 13: loss -0.45918 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 13: loss -0.48002 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 14: loss -0.49232 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 14: loss -0.51306 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 15: loss -0.52546 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 15: loss -0.54611 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 16: loss -0.55860 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 16: loss -0.57907 acc 0.34211 roc_auc 0.48000 prc_auc 0.64902[0m
[92maverage training of epoch 17: loss -0.59174 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 17: loss -0.61221 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 18: loss -0.62488 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 18: loss -0.64525 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -0.65803 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 19: loss -0.67830 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -0.69117 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 20: loss -0.71135 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -0.72427 acc 0.33333 roc_auc 0.35480 prc_auc 0.56131[0m
[93maverage test of epoch 21: loss -0.74440 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -0.75745 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 22: loss -0.77745 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -0.79060 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 23: loss -0.81050 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -0.82374 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 24: loss -0.84355 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -0.85691 acc 0.33333 roc_auc 0.36460 prc_auc 0.56387[0m
[93maverage test of epoch 25: loss -0.87659 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -0.89003 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 26: loss -0.90964 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -0.92313 acc 0.33333 roc_auc 0.35520 prc_auc 0.56143[0m
[93maverage test of epoch 27: loss -0.94269 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -0.95631 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 28: loss -0.97574 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -0.98946 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 29: loss -1.00879 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -1.02253 acc 0.33333 roc_auc 0.35680 prc_auc 0.56147[0m
[93maverage test of epoch 30: loss -1.04184 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -1.05574 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 31: loss -1.07489 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -1.08889 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 32: loss -1.10793 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -1.12203 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 33: loss -1.14098 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -1.15517 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 34: loss -1.17403 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -1.18831 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 35: loss -1.20708 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -1.22145 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 36: loss -1.24012 acc 0.34211 roc_auc 0.48000 prc_auc 0.64902[0m
[92maverage training of epoch 37: loss -1.25457 acc 0.33333 roc_auc 0.35420 prc_auc 0.56112[0m
[93maverage test of epoch 37: loss -1.27317 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -1.28774 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 38: loss -1.30622 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -1.32088 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 39: loss -1.33927 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -1.35402 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 40: loss -1.37232 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -1.38717 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 41: loss -1.40536 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -1.42031 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 42: loss -1.43841 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -1.45345 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 43: loss -1.47146 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -1.48659 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 44: loss -1.50451 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -1.51973 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 45: loss -1.53755 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -1.55288 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 46: loss -1.57060 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -1.58602 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 47: loss -1.60365 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -1.61916 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 48: loss -1.63670 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -1.65230 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 49: loss -1.66973 acc 0.34211 roc_auc 0.52000 prc_auc 0.67158[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.66892 acc 0.33333 roc_auc 0.51000 prc_auc 0.68203[0m
[93maverage test of epoch 0: loss -1.01823 acc 0.34211 roc_auc 0.31077 prc_auc 0.58456[0m
[92maverage training of epoch 1: loss -1.36112 acc 0.33333 roc_auc 0.52560 prc_auc 0.68027[0m
[93maverage test of epoch 1: loss -1.75677 acc 0.34211 roc_auc 0.58154 prc_auc 0.76616[0m
[92maverage training of epoch 2: loss -2.07898 acc 0.33333 roc_auc 0.54600 prc_auc 0.68310[0m
[93maverage test of epoch 2: loss -2.44356 acc 0.34211 roc_auc 0.67077 prc_auc 0.80951[0m
[92maverage training of epoch 3: loss -2.80325 acc 0.33333 roc_auc 0.55500 prc_auc 0.71803[0m
[93maverage test of epoch 3: loss -3.18899 acc 0.34211 roc_auc 0.44308 prc_auc 0.62965[0m
[92maverage training of epoch 4: loss -3.54727 acc 0.33333 roc_auc 0.56620 prc_auc 0.71401[0m
[93maverage test of epoch 4: loss -3.94773 acc 0.34211 roc_auc 0.58462 prc_auc 0.78079[0m
[92maverage training of epoch 5: loss -4.30720 acc 0.33333 roc_auc 0.54020 prc_auc 0.66611[0m
[93maverage test of epoch 5: loss -4.72648 acc 0.34211 roc_auc 0.64000 prc_auc 0.81603[0m
[92maverage training of epoch 6: loss -5.09112 acc 0.33333 roc_auc 0.53300 prc_auc 0.66665[0m
[93maverage test of epoch 6: loss -5.49168 acc 0.34211 roc_auc 0.51385 prc_auc 0.72302[0m
[92maverage training of epoch 7: loss -5.84663 acc 0.33333 roc_auc 0.54080 prc_auc 0.69480[0m
[93maverage test of epoch 7: loss -6.29944 acc 0.34211 roc_auc 0.46462 prc_auc 0.66949[0m
[92maverage training of epoch 8: loss -6.65478 acc 0.33333 roc_auc 0.52020 prc_auc 0.67906[0m
[93maverage test of epoch 8: loss -7.11943 acc 0.34211 roc_auc 0.47077 prc_auc 0.68401[0m
[92maverage training of epoch 9: loss -7.47460 acc 0.33333 roc_auc 0.55260 prc_auc 0.68930[0m
[93maverage test of epoch 9: loss -7.93877 acc 0.34211 roc_auc 0.59385 prc_auc 0.79024[0m
[92maverage training of epoch 10: loss -8.31938 acc 0.33333 roc_auc 0.54620 prc_auc 0.71640[0m
[93maverage test of epoch 10: loss -8.81325 acc 0.34211 roc_auc 0.31692 prc_auc 0.55754[0m
[92maverage training of epoch 11: loss -9.19009 acc 0.33333 roc_auc 0.53560 prc_auc 0.68973[0m
[93maverage test of epoch 11: loss -9.67803 acc 0.34211 roc_auc 0.35692 prc_auc 0.59252[0m
[92maverage training of epoch 12: loss -10.10379 acc 0.33333 roc_auc 0.54660 prc_auc 0.70613[0m
[93maverage test of epoch 12: loss -10.58764 acc 0.34211 roc_auc 0.61846 prc_auc 0.76320[0m
[92maverage training of epoch 13: loss -11.03735 acc 0.33333 roc_auc 0.50820 prc_auc 0.68362[0m
[93maverage test of epoch 13: loss -11.54999 acc 0.34211 roc_auc 0.33846 prc_auc 0.62148[0m
[92maverage training of epoch 14: loss -11.98159 acc 0.33333 roc_auc 0.53180 prc_auc 0.69328[0m
[93maverage test of epoch 14: loss -12.51001 acc 0.34211 roc_auc 0.35077 prc_auc 0.59355[0m
[92maverage training of epoch 15: loss -12.96438 acc 0.33333 roc_auc 0.50480 prc_auc 0.66955[0m
[93maverage test of epoch 15: loss -13.52353 acc 0.34211 roc_auc 0.62000 prc_auc 0.77621[0m
[92maverage training of epoch 16: loss -13.98698 acc 0.33333 roc_auc 0.47520 prc_auc 0.63359[0m
[93maverage test of epoch 16: loss -14.54605 acc 0.34211 roc_auc 0.29077 prc_auc 0.62202[0m
[92maverage training of epoch 17: loss -15.01770 acc 0.33333 roc_auc 0.47200 prc_auc 0.64940[0m
[93maverage test of epoch 17: loss -15.59968 acc 0.34211 roc_auc 0.35692 prc_auc 0.59071[0m
[92maverage training of epoch 18: loss -16.08737 acc 0.33333 roc_auc 0.51180 prc_auc 0.65283[0m
[93maverage test of epoch 18: loss -16.65862 acc 0.34211 roc_auc 0.53538 prc_auc 0.71798[0m
[92maverage training of epoch 19: loss -17.16430 acc 0.33333 roc_auc 0.44660 prc_auc 0.62230[0m
[93maverage test of epoch 19: loss -17.76696 acc 0.34211 roc_auc 0.50923 prc_auc 0.73073[0m
[92maverage training of epoch 20: loss -18.26837 acc 0.33333 roc_auc 0.45080 prc_auc 0.64588[0m
[93maverage test of epoch 20: loss -18.88123 acc 0.34211 roc_auc 0.37692 prc_auc 0.60719[0m
[92maverage training of epoch 21: loss -19.40389 acc 0.33333 roc_auc 0.45940 prc_auc 0.66345[0m
[93maverage test of epoch 21: loss -20.02409 acc 0.34211 roc_auc 0.51385 prc_auc 0.71043[0m
[92maverage training of epoch 22: loss -20.56980 acc 0.33333 roc_auc 0.38860 prc_auc 0.58254[0m
[93maverage test of epoch 22: loss -21.20875 acc 0.34211 roc_auc 0.35077 prc_auc 0.61302[0m
[92maverage training of epoch 23: loss -21.74902 acc 0.33333 roc_auc 0.36090 prc_auc 0.59773[0m
[93maverage test of epoch 23: loss -22.38959 acc 0.34211 roc_auc 0.25846 prc_auc 0.53175[0m
[92maverage training of epoch 24: loss -22.96326 acc 0.33333 roc_auc 0.40720 prc_auc 0.63096[0m
[93maverage test of epoch 24: loss -23.62277 acc 0.34211 roc_auc 0.58308 prc_auc 0.71891[0m
[92maverage training of epoch 25: loss -24.19578 acc 0.33333 roc_auc 0.39320 prc_auc 0.60571[0m
[93maverage test of epoch 25: loss -24.88608 acc 0.34211 roc_auc 0.40923 prc_auc 0.64740[0m
[92maverage training of epoch 26: loss -25.46963 acc 0.33333 roc_auc 0.42040 prc_auc 0.63148[0m
[93maverage test of epoch 26: loss -26.16993 acc 0.34211 roc_auc 0.62308 prc_auc 0.81028[0m
[92maverage training of epoch 27: loss -26.76259 acc 0.33333 roc_auc 0.41100 prc_auc 0.60349[0m
[93maverage test of epoch 27: loss -27.46049 acc 0.34211 roc_auc 0.53077 prc_auc 0.70765[0m
[92maverage training of epoch 28: loss -28.08113 acc 0.33333 roc_auc 0.41720 prc_auc 0.60581[0m
[93maverage test of epoch 28: loss -28.81537 acc 0.34211 roc_auc 0.49077 prc_auc 0.72163[0m
[92maverage training of epoch 29: loss -29.43108 acc 0.33333 roc_auc 0.40720 prc_auc 0.62121[0m
[93maverage test of epoch 29: loss -30.17913 acc 0.34211 roc_auc 0.40000 prc_auc 0.67608[0m
[92maverage training of epoch 30: loss -30.81071 acc 0.33333 roc_auc 0.40640 prc_auc 0.59684[0m
[93maverage test of epoch 30: loss -31.56835 acc 0.34211 roc_auc 0.53231 prc_auc 0.71562[0m
[92maverage training of epoch 31: loss -32.21916 acc 0.33333 roc_auc 0.40820 prc_auc 0.60631[0m
[93maverage test of epoch 31: loss -32.98261 acc 0.34211 roc_auc 0.41385 prc_auc 0.64358[0m
[92maverage training of epoch 32: loss -33.65568 acc 0.33333 roc_auc 0.40160 prc_auc 0.61268[0m
[93maverage test of epoch 32: loss -34.44446 acc 0.34211 roc_auc 0.52769 prc_auc 0.65561[0m
[92maverage training of epoch 33: loss -35.11922 acc 0.33333 roc_auc 0.40820 prc_auc 0.60043[0m
[93maverage test of epoch 33: loss -35.91094 acc 0.34211 roc_auc 0.58308 prc_auc 0.72576[0m
[92maverage training of epoch 34: loss -36.61313 acc 0.33333 roc_auc 0.42020 prc_auc 0.61529[0m
[93maverage test of epoch 34: loss -37.42734 acc 0.34211 roc_auc 0.40923 prc_auc 0.60524[0m
[92maverage training of epoch 35: loss -38.13857 acc 0.33333 roc_auc 0.41720 prc_auc 0.61013[0m
[93maverage test of epoch 35: loss -38.96205 acc 0.34211 roc_auc 0.40000 prc_auc 0.60283[0m
[92maverage training of epoch 36: loss -39.77076 acc 0.33333 roc_auc 0.41920 prc_auc 0.59739[0m
[93maverage test of epoch 36: loss -40.73632 acc 0.34211 roc_auc 0.61231 prc_auc 0.75157[0m
[92maverage training of epoch 37: loss -41.63902 acc 0.33333 roc_auc 0.41180 prc_auc 0.58971[0m
[93maverage test of epoch 37: loss -42.64549 acc 0.34211 roc_auc 0.53538 prc_auc 0.72319[0m
[92maverage training of epoch 38: loss -43.56298 acc 0.33333 roc_auc 0.41490 prc_auc 0.59523[0m
[93maverage test of epoch 38: loss -44.57892 acc 0.34211 roc_auc 0.58923 prc_auc 0.76429[0m
[92maverage training of epoch 39: loss -45.52689 acc 0.33333 roc_auc 0.41580 prc_auc 0.59703[0m
[93maverage test of epoch 39: loss -46.57037 acc 0.34211 roc_auc 0.48154 prc_auc 0.74458[0m
[92maverage training of epoch 40: loss -47.52335 acc 0.33333 roc_auc 0.41840 prc_auc 0.59378[0m
[93maverage test of epoch 40: loss -48.58781 acc 0.34211 roc_auc 0.56000 prc_auc 0.68612[0m
[92maverage training of epoch 41: loss -49.56548 acc 0.33333 roc_auc 0.41980 prc_auc 0.59850[0m
[93maverage test of epoch 41: loss -50.64691 acc 0.34211 roc_auc 0.45538 prc_auc 0.67288[0m
[92maverage training of epoch 42: loss -51.64786 acc 0.33333 roc_auc 0.41860 prc_auc 0.59571[0m
[93maverage test of epoch 42: loss -52.74686 acc 0.34211 roc_auc 0.46769 prc_auc 0.66250[0m
[92maverage training of epoch 43: loss -53.77176 acc 0.33333 roc_auc 0.41760 prc_auc 0.59567[0m
[93maverage test of epoch 43: loss -54.89197 acc 0.34211 roc_auc 0.48154 prc_auc 0.66068[0m
[92maverage training of epoch 44: loss -55.93808 acc 0.33333 roc_auc 0.41560 prc_auc 0.59617[0m
[93maverage test of epoch 44: loss -57.07448 acc 0.34211 roc_auc 0.55385 prc_auc 0.68516[0m
[92maverage training of epoch 45: loss -58.14948 acc 0.33333 roc_auc 0.41880 prc_auc 0.60332[0m
[93maverage test of epoch 45: loss -59.30484 acc 0.34211 roc_auc 0.56615 prc_auc 0.67590[0m
[92maverage training of epoch 46: loss -60.40327 acc 0.33333 roc_auc 0.42060 prc_auc 0.60516[0m
[93maverage test of epoch 46: loss -61.57642 acc 0.34211 roc_auc 0.61231 prc_auc 0.70611[0m
[92maverage training of epoch 47: loss -62.69894 acc 0.33333 roc_auc 0.42040 prc_auc 0.60465[0m
[93maverage test of epoch 47: loss -63.89170 acc 0.34211 roc_auc 0.61077 prc_auc 0.71066[0m
[92maverage training of epoch 48: loss -65.04050 acc 0.33333 roc_auc 0.42170 prc_auc 0.60543[0m
[93maverage test of epoch 48: loss -66.24932 acc 0.34211 roc_auc 0.44769 prc_auc 0.65449[0m
[92maverage training of epoch 49: loss -67.42368 acc 0.33333 roc_auc 0.42180 prc_auc 0.60702[0m
[93maverage test of epoch 49: loss -68.65503 acc 0.34211 roc_auc 0.46000 prc_auc 0.66592[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -1.14170 acc 0.33333 roc_auc 0.53280 prc_auc 0.68488[0m
[93maverage test of epoch 0: loss -1.55868 acc 0.34211 roc_auc 0.45846 prc_auc 0.65275[0m
[92maverage training of epoch 1: loss -1.84044 acc 0.33333 roc_auc 0.54280 prc_auc 0.67677[0m
[93maverage test of epoch 1: loss -2.14807 acc 0.34211 roc_auc 0.27077 prc_auc 0.58275[0m
[92maverage training of epoch 2: loss -2.40285 acc 0.33333 roc_auc 0.50380 prc_auc 0.65293[0m
[93maverage test of epoch 2: loss -2.70416 acc 0.34211 roc_auc 0.46154 prc_auc 0.66326[0m
[92maverage training of epoch 3: loss -2.96737 acc 0.33333 roc_auc 0.55880 prc_auc 0.73894[0m
[93maverage test of epoch 3: loss -3.28501 acc 0.34211 roc_auc 0.44308 prc_auc 0.66297[0m
[92maverage training of epoch 4: loss -3.56652 acc 0.33333 roc_auc 0.52700 prc_auc 0.68514[0m
[93maverage test of epoch 4: loss -3.91615 acc 0.34211 roc_auc 0.48615 prc_auc 0.72551[0m
[92maverage training of epoch 5: loss -4.21491 acc 0.33333 roc_auc 0.50520 prc_auc 0.64991[0m
[93maverage test of epoch 5: loss -4.56281 acc 0.34211 roc_auc 0.65538 prc_auc 0.78515[0m
[92maverage training of epoch 6: loss -4.90519 acc 0.33333 roc_auc 0.54000 prc_auc 0.69080[0m
[93maverage test of epoch 6: loss -5.36279 acc 0.34211 roc_auc 0.51385 prc_auc 0.71297[0m
[92maverage training of epoch 7: loss -5.77481 acc 0.33333 roc_auc 0.52940 prc_auc 0.67352[0m
[93maverage test of epoch 7: loss -6.26247 acc 0.34211 roc_auc 0.52615 prc_auc 0.72441[0m
[92maverage training of epoch 8: loss -6.70799 acc 0.33333 roc_auc 0.53720 prc_auc 0.68378[0m
[93maverage test of epoch 8: loss -7.22941 acc 0.34211 roc_auc 0.53538 prc_auc 0.74352[0m
[92maverage training of epoch 9: loss -7.67296 acc 0.33333 roc_auc 0.52840 prc_auc 0.66278[0m
[93maverage test of epoch 9: loss -8.21156 acc 0.34211 roc_auc 0.47385 prc_auc 0.63079[0m
[92maverage training of epoch 10: loss -8.67569 acc 0.33333 roc_auc 0.53740 prc_auc 0.69359[0m
[93maverage test of epoch 10: loss -9.20924 acc 0.34211 roc_auc 0.49846 prc_auc 0.71312[0m
[92maverage training of epoch 11: loss -9.68651 acc 0.33333 roc_auc 0.50840 prc_auc 0.66434[0m
[93maverage test of epoch 11: loss -10.27313 acc 0.34211 roc_auc 0.41846 prc_auc 0.64822[0m
[92maverage training of epoch 12: loss -10.74129 acc 0.33333 roc_auc 0.53140 prc_auc 0.68949[0m
[93maverage test of epoch 12: loss -11.32267 acc 0.34211 roc_auc 0.22769 prc_auc 0.51761[0m
[92maverage training of epoch 13: loss -11.82514 acc 0.33333 roc_auc 0.54780 prc_auc 0.69908[0m
[93maverage test of epoch 13: loss -12.44127 acc 0.34211 roc_auc 0.52308 prc_auc 0.72995[0m
[92maverage training of epoch 14: loss -12.95673 acc 0.33333 roc_auc 0.54780 prc_auc 0.71262[0m
[93maverage test of epoch 14: loss -13.58422 acc 0.34211 roc_auc 0.49231 prc_auc 0.68466[0m
[92maverage training of epoch 15: loss -14.11537 acc 0.33333 roc_auc 0.50400 prc_auc 0.68438[0m
[93maverage test of epoch 15: loss -14.77650 acc 0.34211 roc_auc 0.45846 prc_auc 0.65877[0m
[92maverage training of epoch 16: loss -15.32930 acc 0.33333 roc_auc 0.54140 prc_auc 0.67086[0m
[93maverage test of epoch 16: loss -15.99331 acc 0.34211 roc_auc 0.30154 prc_auc 0.55876[0m
[92maverage training of epoch 17: loss -16.57367 acc 0.33333 roc_auc 0.52490 prc_auc 0.68804[0m
[93maverage test of epoch 17: loss -17.28038 acc 0.34211 roc_auc 0.45231 prc_auc 0.68029[0m
[92maverage training of epoch 18: loss -17.87129 acc 0.33333 roc_auc 0.52540 prc_auc 0.69002[0m
[93maverage test of epoch 18: loss -18.59268 acc 0.34211 roc_auc 0.45538 prc_auc 0.65940[0m
[92maverage training of epoch 19: loss -19.20865 acc 0.33333 roc_auc 0.48370 prc_auc 0.66697[0m
[93maverage test of epoch 19: loss -19.95424 acc 0.34211 roc_auc 0.52615 prc_auc 0.71679[0m
[92maverage training of epoch 20: loss -20.59380 acc 0.33333 roc_auc 0.50560 prc_auc 0.68624[0m
[93maverage test of epoch 20: loss -21.38704 acc 0.34211 roc_auc 0.55077 prc_auc 0.76456[0m
[92maverage training of epoch 21: loss -22.03544 acc 0.33333 roc_auc 0.48930 prc_auc 0.67818[0m
[93maverage test of epoch 21: loss -22.84567 acc 0.34211 roc_auc 0.54308 prc_auc 0.72294[0m
[92maverage training of epoch 22: loss -23.52668 acc 0.33333 roc_auc 0.46260 prc_auc 0.61807[0m
[93maverage test of epoch 22: loss -24.35232 acc 0.34211 roc_auc 0.48923 prc_auc 0.72130[0m
[92maverage training of epoch 23: loss -25.05509 acc 0.33333 roc_auc 0.44220 prc_auc 0.61728[0m
[93maverage test of epoch 23: loss -25.92157 acc 0.34211 roc_auc 0.58000 prc_auc 0.77690[0m
[92maverage training of epoch 24: loss -26.63949 acc 0.33333 roc_auc 0.46780 prc_auc 0.63870[0m
[93maverage test of epoch 24: loss -27.52572 acc 0.34211 roc_auc 0.62769 prc_auc 0.79483[0m
[92maverage training of epoch 25: loss -28.26433 acc 0.33333 roc_auc 0.44200 prc_auc 0.61850[0m
[93maverage test of epoch 25: loss -29.18235 acc 0.34211 roc_auc 0.40154 prc_auc 0.65325[0m
[92maverage training of epoch 26: loss -29.93817 acc 0.33333 roc_auc 0.42310 prc_auc 0.62986[0m
[93maverage test of epoch 26: loss -30.87209 acc 0.34211 roc_auc 0.44308 prc_auc 0.59513[0m
[92maverage training of epoch 27: loss -31.64914 acc 0.33333 roc_auc 0.44550 prc_auc 0.65023[0m
[93maverage test of epoch 27: loss -32.59454 acc 0.34211 roc_auc 0.49538 prc_auc 0.68077[0m
[92maverage training of epoch 28: loss -33.41470 acc 0.33333 roc_auc 0.44250 prc_auc 0.62414[0m
[93maverage test of epoch 28: loss -34.39096 acc 0.34211 roc_auc 0.38769 prc_auc 0.61257[0m
[92maverage training of epoch 29: loss -35.20749 acc 0.33333 roc_auc 0.43640 prc_auc 0.63260[0m
[93maverage test of epoch 29: loss -36.22263 acc 0.34211 roc_auc 0.52154 prc_auc 0.72779[0m
[92maverage training of epoch 30: loss -37.06078 acc 0.33333 roc_auc 0.43700 prc_auc 0.64081[0m
[93maverage test of epoch 30: loss -38.09050 acc 0.34211 roc_auc 0.54308 prc_auc 0.74240[0m
[92maverage training of epoch 31: loss -38.95450 acc 0.33333 roc_auc 0.41640 prc_auc 0.61797[0m
[93maverage test of epoch 31: loss -40.00890 acc 0.34211 roc_auc 0.57538 prc_auc 0.70959[0m
[92maverage training of epoch 32: loss -40.89835 acc 0.33333 roc_auc 0.42420 prc_auc 0.62169[0m
[93maverage test of epoch 32: loss -41.97073 acc 0.34211 roc_auc 0.50000 prc_auc 0.73797[0m
[92maverage training of epoch 33: loss -42.88107 acc 0.33333 roc_auc 0.40650 prc_auc 0.62947[0m
[93maverage test of epoch 33: loss -43.97883 acc 0.34211 roc_auc 0.50923 prc_auc 0.67190[0m
[92maverage training of epoch 34: loss -44.91484 acc 0.33333 roc_auc 0.39340 prc_auc 0.60641[0m
[93maverage test of epoch 34: loss -46.03258 acc 0.34211 roc_auc 0.50615 prc_auc 0.68062[0m
[92maverage training of epoch 35: loss -46.98272 acc 0.33333 roc_auc 0.38540 prc_auc 0.59431[0m
[93maverage test of epoch 35: loss -48.12544 acc 0.34211 roc_auc 0.26308 prc_auc 0.58223[0m
[92maverage training of epoch 36: loss -49.10201 acc 0.33333 roc_auc 0.39320 prc_auc 0.60863[0m
[93maverage test of epoch 36: loss -50.26645 acc 0.34211 roc_auc 0.40615 prc_auc 0.60714[0m
[92maverage training of epoch 37: loss -51.25556 acc 0.33333 roc_auc 0.39420 prc_auc 0.60682[0m
[93maverage test of epoch 37: loss -52.43133 acc 0.34211 roc_auc 0.64615 prc_auc 0.75345[0m
[92maverage training of epoch 38: loss -53.45300 acc 0.33333 roc_auc 0.39720 prc_auc 0.60010[0m
[93maverage test of epoch 38: loss -54.65363 acc 0.34211 roc_auc 0.63692 prc_auc 0.77489[0m
[92maverage training of epoch 39: loss -55.68685 acc 0.33333 roc_auc 0.39260 prc_auc 0.59716[0m
[93maverage test of epoch 39: loss -56.90854 acc 0.34211 roc_auc 0.53077 prc_auc 0.69829[0m
[92maverage training of epoch 40: loss -57.96387 acc 0.33333 roc_auc 0.39180 prc_auc 0.59473[0m
[93maverage test of epoch 40: loss -59.20022 acc 0.34211 roc_auc 0.42462 prc_auc 0.63271[0m
[92maverage training of epoch 41: loss -60.27733 acc 0.33333 roc_auc 0.38700 prc_auc 0.58876[0m
[93maverage test of epoch 41: loss -61.53800 acc 0.34211 roc_auc 0.57692 prc_auc 0.75312[0m
[92maverage training of epoch 42: loss -62.63685 acc 0.33333 roc_auc 0.38540 prc_auc 0.58975[0m
[93maverage test of epoch 42: loss -63.91534 acc 0.34211 roc_auc 0.39846 prc_auc 0.64492[0m
[92maverage training of epoch 43: loss -65.03441 acc 0.33333 roc_auc 0.38560 prc_auc 0.59325[0m
[93maverage test of epoch 43: loss -66.33400 acc 0.34211 roc_auc 0.53231 prc_auc 0.65129[0m
[92maverage training of epoch 44: loss -67.47909 acc 0.33333 roc_auc 0.38200 prc_auc 0.58754[0m
[93maverage test of epoch 44: loss -68.80208 acc 0.34211 roc_auc 0.47692 prc_auc 0.67970[0m
[92maverage training of epoch 45: loss -69.96685 acc 0.33333 roc_auc 0.38040 prc_auc 0.59426[0m
[93maverage test of epoch 45: loss -71.30517 acc 0.34211 roc_auc 0.39692 prc_auc 0.63311[0m
[92maverage training of epoch 46: loss -72.49227 acc 0.33333 roc_auc 0.38020 prc_auc 0.58386[0m
[93maverage test of epoch 46: loss -73.85443 acc 0.34211 roc_auc 0.68308 prc_auc 0.80442[0m
[92maverage training of epoch 47: loss -75.06549 acc 0.33333 roc_auc 0.37600 prc_auc 0.58361[0m
[93maverage test of epoch 47: loss -76.44582 acc 0.34211 roc_auc 0.52923 prc_auc 0.72816[0m
[92maverage training of epoch 48: loss -77.67913 acc 0.33333 roc_auc 0.37560 prc_auc 0.58255[0m
[93maverage test of epoch 48: loss -79.08431 acc 0.34211 roc_auc 0.44923 prc_auc 0.62702[0m
[92maverage training of epoch 49: loss -80.34024 acc 0.33333 roc_auc 0.37840 prc_auc 0.59090[0m
[93maverage test of epoch 49: loss -81.76272 acc 0.34211 roc_auc 0.49846 prc_auc 0.72421[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.25303 acc 0.66225 roc_auc 0.53157 prc_auc 0.66720[0m
[93maverage test of epoch 0: loss -0.36552 acc 0.67568 roc_auc 0.53000 prc_auc 0.70782[0m
[92maverage training of epoch 1: loss -0.51789 acc 0.56291 roc_auc 0.54020 prc_auc 0.67653[0m
[93maverage test of epoch 1: loss -0.72327 acc 0.32432 roc_auc 0.36667 prc_auc 0.64553[0m
[92maverage training of epoch 2: loss -1.09847 acc 0.33775 roc_auc 0.52725 prc_auc 0.70190[0m
[93maverage test of epoch 2: loss -1.45375 acc 0.32432 roc_auc 0.63333 prc_auc 0.78361[0m
[92maverage training of epoch 3: loss -1.83907 acc 0.33775 roc_auc 0.52471 prc_auc 0.65280[0m
[93maverage test of epoch 3: loss -2.27615 acc 0.32432 roc_auc 0.70000 prc_auc 0.86434[0m
[92maverage training of epoch 4: loss -2.63635 acc 0.33775 roc_auc 0.56176 prc_auc 0.68960[0m
[93maverage test of epoch 4: loss -2.92636 acc 0.32432 roc_auc 0.31000 prc_auc 0.62007[0m
[92maverage training of epoch 5: loss -3.29794 acc 0.33775 roc_auc 0.49980 prc_auc 0.64121[0m
[93maverage test of epoch 5: loss -3.62966 acc 0.32432 roc_auc 0.50667 prc_auc 0.70818[0m
[92maverage training of epoch 6: loss -3.98908 acc 0.33775 roc_auc 0.58118 prc_auc 0.74226[0m
[93maverage test of epoch 6: loss -4.27208 acc 0.32432 roc_auc 0.49333 prc_auc 0.69890[0m
[92maverage training of epoch 7: loss -4.68143 acc 0.33775 roc_auc 0.50333 prc_auc 0.69492[0m
[93maverage test of epoch 7: loss -4.96710 acc 0.32432 roc_auc 0.41333 prc_auc 0.68130[0m
[92maverage training of epoch 8: loss -5.37619 acc 0.33775 roc_auc 0.54451 prc_auc 0.69309[0m
[93maverage test of epoch 8: loss -5.66049 acc 0.32432 roc_auc 0.64333 prc_auc 0.80269[0m
[92maverage training of epoch 9: loss -6.08140 acc 0.33775 roc_auc 0.54647 prc_auc 0.71073[0m
[93maverage test of epoch 9: loss -6.36578 acc 0.32432 roc_auc 0.35000 prc_auc 0.60529[0m
[92maverage training of epoch 10: loss -6.82133 acc 0.33775 roc_auc 0.53647 prc_auc 0.69012[0m
[93maverage test of epoch 10: loss -7.12687 acc 0.32432 roc_auc 0.40333 prc_auc 0.61986[0m
[92maverage training of epoch 11: loss -7.58719 acc 0.33775 roc_auc 0.52255 prc_auc 0.68618[0m
[93maverage test of epoch 11: loss -7.90368 acc 0.32432 roc_auc 0.35167 prc_auc 0.60323[0m
[92maverage training of epoch 12: loss -8.39315 acc 0.33775 roc_auc 0.53078 prc_auc 0.67658[0m
[93maverage test of epoch 12: loss -8.71566 acc 0.32432 roc_auc 0.24667 prc_auc 0.55728[0m
[92maverage training of epoch 13: loss -9.22773 acc 0.33775 roc_auc 0.49216 prc_auc 0.64892[0m
[93maverage test of epoch 13: loss -9.57045 acc 0.32432 roc_auc 0.50000 prc_auc 0.65124[0m
[92maverage training of epoch 14: loss -10.09001 acc 0.33775 roc_auc 0.48706 prc_auc 0.68031[0m
[93maverage test of epoch 14: loss -10.45431 acc 0.32432 roc_auc 0.37000 prc_auc 0.61804[0m
[92maverage training of epoch 15: loss -10.98379 acc 0.33775 roc_auc 0.50784 prc_auc 0.65818[0m
[93maverage test of epoch 15: loss -11.36079 acc 0.32432 roc_auc 0.50333 prc_auc 0.71982[0m
[92maverage training of epoch 16: loss -11.92062 acc 0.33775 roc_auc 0.52843 prc_auc 0.69348[0m
[93maverage test of epoch 16: loss -12.32116 acc 0.32432 roc_auc 0.46000 prc_auc 0.73646[0m
[92maverage training of epoch 17: loss -12.89571 acc 0.33775 roc_auc 0.50333 prc_auc 0.65859[0m
[93maverage test of epoch 17: loss -13.30787 acc 0.32432 roc_auc 0.51667 prc_auc 0.73920[0m
[92maverage training of epoch 18: loss -13.89788 acc 0.33775 roc_auc 0.47824 prc_auc 0.63676[0m
[93maverage test of epoch 18: loss -14.32326 acc 0.32432 roc_auc 0.33667 prc_auc 0.58450[0m
[92maverage training of epoch 19: loss -14.93581 acc 0.33775 roc_auc 0.49451 prc_auc 0.66240[0m
[93maverage test of epoch 19: loss -15.37924 acc 0.32432 roc_auc 0.48667 prc_auc 0.71576[0m
[92maverage training of epoch 20: loss -16.00848 acc 0.33775 roc_auc 0.52275 prc_auc 0.69141[0m
[93maverage test of epoch 20: loss -16.46179 acc 0.32432 roc_auc 0.36167 prc_auc 0.63856[0m
[92maverage training of epoch 21: loss -17.11484 acc 0.33775 roc_auc 0.46098 prc_auc 0.62885[0m
[93maverage test of epoch 21: loss -17.59229 acc 0.32432 roc_auc 0.59000 prc_auc 0.80954[0m
[92maverage training of epoch 22: loss -18.25589 acc 0.33775 roc_auc 0.46608 prc_auc 0.65807[0m
[93maverage test of epoch 22: loss -18.73687 acc 0.32432 roc_auc 0.45167 prc_auc 0.69902[0m
[92maverage training of epoch 23: loss -19.42210 acc 0.33775 roc_auc 0.45118 prc_auc 0.66000[0m
[93maverage test of epoch 23: loss -19.91657 acc 0.32432 roc_auc 0.35833 prc_auc 0.59908[0m
[92maverage training of epoch 24: loss -20.61888 acc 0.33775 roc_auc 0.44059 prc_auc 0.60847[0m
[93maverage test of epoch 24: loss -21.13066 acc 0.32432 roc_auc 0.25333 prc_auc 0.56255[0m
[92maverage training of epoch 25: loss -21.84369 acc 0.33775 roc_auc 0.43431 prc_auc 0.60934[0m
[93maverage test of epoch 25: loss -22.36220 acc 0.32432 roc_auc 0.58500 prc_auc 0.72265[0m
[92maverage training of epoch 26: loss -23.07975 acc 0.33775 roc_auc 0.40843 prc_auc 0.62512[0m
[93maverage test of epoch 26: loss -23.60753 acc 0.32432 roc_auc 0.58667 prc_auc 0.77655[0m
[92maverage training of epoch 27: loss -24.34832 acc 0.33775 roc_auc 0.40588 prc_auc 0.63043[0m
[93maverage test of epoch 27: loss -24.88103 acc 0.32432 roc_auc 0.46167 prc_auc 0.65078[0m
[92maverage training of epoch 28: loss -25.63641 acc 0.33775 roc_auc 0.41373 prc_auc 0.63108[0m
[93maverage test of epoch 28: loss -26.18664 acc 0.32432 roc_auc 0.43167 prc_auc 0.69284[0m
[92maverage training of epoch 29: loss -26.94664 acc 0.33775 roc_auc 0.37961 prc_auc 0.59906[0m
[93maverage test of epoch 29: loss -27.51003 acc 0.32432 roc_auc 0.44500 prc_auc 0.66567[0m
[92maverage training of epoch 30: loss -28.28721 acc 0.33775 roc_auc 0.36922 prc_auc 0.59080[0m
[93maverage test of epoch 30: loss -28.86273 acc 0.32432 roc_auc 0.50833 prc_auc 0.71466[0m
[92maverage training of epoch 31: loss -29.64815 acc 0.33775 roc_auc 0.37647 prc_auc 0.58755[0m
[93maverage test of epoch 31: loss -30.23853 acc 0.32432 roc_auc 0.51167 prc_auc 0.73780[0m
[92maverage training of epoch 32: loss -31.03984 acc 0.33775 roc_auc 0.37804 prc_auc 0.60869[0m
[93maverage test of epoch 32: loss -31.63634 acc 0.32432 roc_auc 0.46667 prc_auc 0.73373[0m
[92maverage training of epoch 33: loss -32.45761 acc 0.33775 roc_auc 0.37569 prc_auc 0.58533[0m
[93maverage test of epoch 33: loss -33.07128 acc 0.32432 roc_auc 0.42000 prc_auc 0.67331[0m
[92maverage training of epoch 34: loss -33.90128 acc 0.33775 roc_auc 0.38765 prc_auc 0.59834[0m
[93maverage test of epoch 34: loss -34.53035 acc 0.32432 roc_auc 0.29333 prc_auc 0.62149[0m
[92maverage training of epoch 35: loss -35.37436 acc 0.33775 roc_auc 0.38686 prc_auc 0.60347[0m
[93maverage test of epoch 35: loss -36.01395 acc 0.32432 roc_auc 0.52000 prc_auc 0.71630[0m
[92maverage training of epoch 36: loss -36.87121 acc 0.33775 roc_auc 0.38667 prc_auc 0.59881[0m
[93maverage test of epoch 36: loss -37.53565 acc 0.32432 roc_auc 0.47667 prc_auc 0.70567[0m
[92maverage training of epoch 37: loss -38.40222 acc 0.33775 roc_auc 0.38608 prc_auc 0.61045[0m
[93maverage test of epoch 37: loss -39.07637 acc 0.32432 roc_auc 0.46500 prc_auc 0.65265[0m
[92maverage training of epoch 38: loss -39.96028 acc 0.33775 roc_auc 0.37353 prc_auc 0.59257[0m
[93maverage test of epoch 38: loss -40.64977 acc 0.32432 roc_auc 0.39500 prc_auc 0.63435[0m
[92maverage training of epoch 39: loss -41.54665 acc 0.33775 roc_auc 0.37882 prc_auc 0.60777[0m
[93maverage test of epoch 39: loss -42.25307 acc 0.32432 roc_auc 0.55500 prc_auc 0.77325[0m
[92maverage training of epoch 40: loss -43.15958 acc 0.33775 roc_auc 0.37431 prc_auc 0.60283[0m
[93maverage test of epoch 40: loss -43.88279 acc 0.32432 roc_auc 0.38000 prc_auc 0.67553[0m
[92maverage training of epoch 41: loss -44.80454 acc 0.33775 roc_auc 0.36784 prc_auc 0.58099[0m
[93maverage test of epoch 41: loss -45.54444 acc 0.32432 roc_auc 0.58333 prc_auc 0.76896[0m
[92maverage training of epoch 42: loss -46.47595 acc 0.33775 roc_auc 0.36608 prc_auc 0.58570[0m
[93maverage test of epoch 42: loss -47.23372 acc 0.32432 roc_auc 0.44167 prc_auc 0.67378[0m
[92maverage training of epoch 43: loss -48.18135 acc 0.33775 roc_auc 0.36157 prc_auc 0.57992[0m
[93maverage test of epoch 43: loss -48.95207 acc 0.32432 roc_auc 0.68000 prc_auc 0.81568[0m
[92maverage training of epoch 44: loss -49.91377 acc 0.33775 roc_auc 0.36431 prc_auc 0.58709[0m
[93maverage test of epoch 44: loss -50.70117 acc 0.32432 roc_auc 0.46000 prc_auc 0.68054[0m
[92maverage training of epoch 45: loss -51.67512 acc 0.33775 roc_auc 0.36588 prc_auc 0.58166[0m
[93maverage test of epoch 45: loss -52.48014 acc 0.32432 roc_auc 0.58167 prc_auc 0.72901[0m
[92maverage training of epoch 46: loss -53.46532 acc 0.33775 roc_auc 0.36745 prc_auc 0.58968[0m
[93maverage test of epoch 46: loss -54.28663 acc 0.32432 roc_auc 0.55833 prc_auc 0.76646[0m
[92maverage training of epoch 47: loss -55.28497 acc 0.33775 roc_auc 0.36667 prc_auc 0.58612[0m
[93maverage test of epoch 47: loss -56.12576 acc 0.32432 roc_auc 0.72833 prc_auc 0.84723[0m
[92maverage training of epoch 48: loss -57.13648 acc 0.33775 roc_auc 0.36922 prc_auc 0.58401[0m
[93maverage test of epoch 48: loss -57.99167 acc 0.32432 roc_auc 0.45167 prc_auc 0.66565[0m
[92maverage training of epoch 49: loss -59.01600 acc 0.33775 roc_auc 0.36843 prc_auc 0.58568[0m
[93maverage test of epoch 49: loss -59.88910 acc 0.32432 roc_auc 0.60500 prc_auc 0.77174[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.09167 acc 0.35099 roc_auc 0.41902 prc_auc 0.62610[0m
[93maverage test of epoch 0: loss -0.80321 acc 0.64865 roc_auc 0.58000 prc_auc 0.75780[0m
[92maverage training of epoch 1: loss -1.98206 acc 0.66225 roc_auc 0.42275 prc_auc 0.61700[0m
[93maverage test of epoch 1: loss -3.00109 acc 0.67568 roc_auc 0.44667 prc_auc 0.70795[0m
[92maverage training of epoch 2: loss -3.51014 acc 0.66225 roc_auc 0.45490 prc_auc 0.65081[0m
[93maverage test of epoch 2: loss -4.03826 acc 0.67568 roc_auc 0.67000 prc_auc 0.82900[0m
[92maverage training of epoch 3: loss -4.45329 acc 0.66225 roc_auc 0.39353 prc_auc 0.60461[0m
[93maverage test of epoch 3: loss -4.95959 acc 0.67568 roc_auc 0.40667 prc_auc 0.65652[0m
[92maverage training of epoch 4: loss -5.37514 acc 0.66225 roc_auc 0.39941 prc_auc 0.61458[0mUsing backend: pytorch

[93maverage test of epoch 4: loss -5.90947 acc 0.67568 roc_auc 0.53000 prc_auc 0.68195[0m
[92maverage training of epoch 5: loss -6.32545 acc 0.66225 roc_auc 0.42235 prc_auc 0.63269[0m
[93maverage test of epoch 5: loss -6.86912 acc 0.67568 roc_auc 0.62667 prc_auc 0.78996[0m
[92maverage training of epoch 6: loss -7.30089 acc 0.66225 roc_auc 0.39784 prc_auc 0.59808[0m
[93maverage test of epoch 6: loss -7.89403 acc 0.67568 roc_auc 0.45667 prc_auc 0.70057[0m
[92maverage training of epoch 7: loss -8.31504 acc 0.66225 roc_auc 0.40137 prc_auc 0.60768[0m
[93maverage test of epoch 7: loss -8.93923 acc 0.67568 roc_auc 0.55000 prc_auc 0.73889[0m
[92maverage training of epoch 8: loss -9.37958 acc 0.66225 roc_auc 0.40549 prc_auc 0.60132[0m
[93maverage test of epoch 8: loss -10.02965 acc 0.67568 roc_auc 0.64167 prc_auc 0.80054[0m
[92maverage training of epoch 9: loss -10.48741 acc 0.66225 roc_auc 0.44216 prc_auc 0.62334[0m
[93maverage test of epoch 9: loss -11.15286 acc 0.67568 roc_auc 0.42000 prc_auc 0.64276[0m
[92maverage training of epoch 10: loss -11.64307 acc 0.66225 roc_auc 0.39059 prc_auc 0.60771[0m
[93maverage test of epoch 10: loss -12.32637 acc 0.67568 roc_auc 0.30167 prc_auc 0.62903[0m
[92maverage training of epoch 11: loss -12.83831 acc 0.66225 roc_auc 0.41059 prc_auc 0.62620[0m
[93maverage test of epoch 11: loss -13.58656 acc 0.67568 roc_auc 0.60167 prc_auc 0.78120[0m
[92maverage training of epoch 12: loss -14.09816 acc 0.66225 roc_auc 0.41569 prc_auc 0.60725[0m
[93maverage test of epoch 12: loss -14.85955 acc 0.67568 roc_auc 0.42167 prc_auc 0.66865[0m
[92maverage training of epoch 13: loss -15.39724 acc 0.66225 roc_auc 0.41137 prc_auc 0.60999[0m
[93maverage test of epoch 13: loss -16.18322 acc 0.67568 roc_auc 0.49667 prc_auc 0.66118[0m
[92maverage training of epoch 14: loss -16.75516 acc 0.66225 roc_auc 0.42039 prc_auc 0.61300[0m
[93maverage test of epoch 14: loss -17.58344 acc 0.67568 roc_auc 0.55000 prc_auc 0.69488[0m
[92maverage training of epoch 15: loss -18.14249 acc 0.66225 roc_auc 0.40578 prc_auc 0.61293[0m
[93maverage test of epoch 15: loss -19.01528 acc 0.67568 roc_auc 0.40000 prc_auc 0.62634[0m
[92maverage training of epoch 16: loss -19.59794 acc 0.66225 roc_auc 0.41000 prc_auc 0.62450[0m
[93maverage test of epoch 16: loss -20.50485 acc 0.67568 roc_auc 0.41500 prc_auc 0.62976[0m
[92maverage training of epoch 17: loss -21.10103 acc 0.66225 roc_auc 0.40176 prc_auc 0.59800[0m
[93maverage test of epoch 17: loss -22.04279 acc 0.67568 roc_auc 0.68167 prc_auc 0.78256[0m
[92maverage training of epoch 18: loss -22.65264 acc 0.66225 roc_auc 0.40971 prc_auc 0.59987[0m
[93maverage test of epoch 18: loss -23.63493 acc 0.67568 roc_auc 0.51833 prc_auc 0.68323[0m
[92maverage training of epoch 19: loss -24.24822 acc 0.66225 roc_auc 0.41167 prc_auc 0.60707[0m
[93maverage test of epoch 19: loss -25.25569 acc 0.67568 roc_auc 0.50167 prc_auc 0.67641[0m
[92maverage training of epoch 20: loss -25.88681 acc 0.66225 roc_auc 0.40637 prc_auc 0.60918[0m
[93maverage test of epoch 20: loss -26.92471 acc 0.67568 roc_auc 0.48833 prc_auc 0.67063[0m
[92maverage training of epoch 21: loss -27.56430 acc 0.66225 roc_auc 0.40049 prc_auc 0.61026[0m
[93maverage test of epoch 21: loss -28.62968 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 22: loss -29.28644 acc 0.66225 roc_auc 0.42029 prc_auc 0.62394[0m
[93maverage test of epoch 22: loss -30.37895 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 23: loss -31.05140 acc 0.66225 roc_auc 0.42088 prc_auc 0.63077[0m
[93maverage test of epoch 23: loss -32.17707 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 24: loss -32.85770 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 24: loss -34.01453 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 25: loss -34.70736 acc 0.66225 roc_auc 0.52422 prc_auc 0.67327[0m
[93maverage test of epoch 25: loss -35.89909 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 26: loss -36.59162 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 26: loss -37.80730 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 27: loss -38.51972 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 27: loss -39.77461 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 28: loss -40.49124 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 28: loss -41.77855 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 29: loss -42.50637 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 29: loss -43.82331 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 30: loss -44.55962 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 30: loss -45.90707 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 31: loss -46.65713 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 31: loss -48.04624 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 32: loss -48.79655 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 32: loss -50.21957 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 33: loss -50.98425 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 33: loss -52.43773 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 34: loss -53.21238 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 34: loss -54.70378 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 35: loss -55.48338 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 35: loss -57.01231 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 36: loss -57.80032 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 36: loss -59.36422 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 37: loss -60.16532 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 37: loss -61.76481 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 38: loss -62.57479 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 38: loss -64.20894 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 39: loss -65.02793 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 39: loss -66.69481 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -67.52878 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 40: loss -69.23547 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -70.07147 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 41: loss -71.81661 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -72.65724 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 42: loss -74.43582 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -75.28822 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 43: loss -77.10147 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -77.95878 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 44: loss -79.80926 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -80.67655 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 45: loss -82.56027 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -83.43483 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 46: loss -85.35996 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -86.24041 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 47: loss -88.19859 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -89.08735 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 48: loss -91.08295 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -91.97917 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 49: loss -94.01185 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 1)
('lr', 0.0003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.40526 ROC_AUC (avg): 0.51669 PRC_AUC (avg): 0.70183 

Average forward propagation time taken(ms): 4.300186733589993
Average backward propagation time taken(ms): 1.5830651893845

