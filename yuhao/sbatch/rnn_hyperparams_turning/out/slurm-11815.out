# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.0001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-16-40-08/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-16-40-08/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 8,
 'epochs': 50,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 4,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.0001,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 1,
 'num_workers': 8,
 'number_of_mlp_layer': 0,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-17-16-40-08',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 50, 'learning_rate': 0.0001, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss 0.02279 acc 0.33333 roc_auc 0.44400 prc_auc 0.69195[0m
[93maverage test of epoch 0: loss -0.03386 acc 0.34211 roc_auc 0.51692 prc_auc 0.78475[0m
[92maverage training of epoch 1: loss -0.08011 acc 0.33333 roc_auc 0.47240 prc_auc 0.71267[0m
[93maverage test of epoch 1: loss -0.13933 acc 0.34211 roc_auc 0.77538 prc_auc 0.89364[0m
[92maverage training of epoch 2: loss -0.19190 acc 0.33333 roc_auc 0.51380 prc_auc 0.74628[0m
[93maverage test of epoch 2: loss -0.25516 acc 0.34211 roc_auc 0.85538 prc_auc 0.92845[0m
[92maverage training of epoch 3: loss -0.31542 acc 0.33333 roc_auc 0.53360 prc_auc 0.75890[0m
[93maverage test of epoch 3: loss -0.38424 acc 0.34211 roc_auc 0.83692 prc_auc 0.92213[0m
[92maverage training of epoch 4: loss -0.44854 acc 0.33333 roc_auc 0.54520 prc_auc 0.76659[0m
[93maverage test of epoch 4: loss -0.51972 acc 0.34211 roc_auc 0.81846 prc_auc 0.91518[0m
[92maverage training of epoch 5: loss -0.58248 acc 0.35333 roc_auc 0.55900 prc_auc 0.77565[0m
[93maverage test of epoch 5: loss -0.65140 acc 0.34211 roc_auc 0.81846 prc_auc 0.91528[0m
[92maverage training of epoch 6: loss -0.71027 acc 0.35333 roc_auc 0.57420 prc_auc 0.78759[0m
[93maverage test of epoch 6: loss -0.77416 acc 0.34211 roc_auc 0.81846 prc_auc 0.91549[0m
[92maverage training of epoch 7: loss -0.82817 acc 0.35333 roc_auc 0.58760 prc_auc 0.79558[0m
[93maverage test of epoch 7: loss -0.88683 acc 0.39474 roc_auc 0.83077 prc_auc 0.92502[0m
[92maverage training of epoch 8: loss -0.93661 acc 0.37333 roc_auc 0.59740 prc_auc 0.80142[0m
[93maverage test of epoch 8: loss -0.99172 acc 0.39474 roc_auc 0.83692 prc_auc 0.92698[0m
[92maverage training of epoch 9: loss -1.03844 acc 0.37333 roc_auc 0.61220 prc_auc 0.81019[0m
[93maverage test of epoch 9: loss -1.09195 acc 0.42105 roc_auc 0.85538 prc_auc 0.93130[0m
[92maverage training of epoch 10: loss -1.13664 acc 0.44667 roc_auc 0.63140 prc_auc 0.82206[0m
[93maverage test of epoch 10: loss -1.18998 acc 0.50000 roc_auc 0.86154 prc_auc 0.93308[0m
[92maverage training of epoch 11: loss -1.23353 acc 0.56000 roc_auc 0.64680 prc_auc 0.83125[0m
[93maverage test of epoch 11: loss -1.28722 acc 0.81579 roc_auc 0.86154 prc_auc 0.93308[0m
[92maverage training of epoch 12: loss -1.33032 acc 0.68667 roc_auc 0.67800 prc_auc 0.84674[0m
[93maverage test of epoch 12: loss -1.38366 acc 0.65789 roc_auc 0.86462 prc_auc 0.93401[0m
[92maverage training of epoch 13: loss -1.42633 acc 0.66667 roc_auc 0.70920 prc_auc 0.86379[0m
[93maverage test of epoch 13: loss -1.47767 acc 0.65789 roc_auc 0.86462 prc_auc 0.93401[0m
[92maverage training of epoch 14: loss -1.51943 acc 0.66667 roc_auc 0.74700 prc_auc 0.88057[0m
[93maverage test of epoch 14: loss -1.56755 acc 0.65789 roc_auc 0.86462 prc_auc 0.93401[0m
[92maverage training of epoch 15: loss -1.60864 acc 0.66667 roc_auc 0.77740 prc_auc 0.89422[0m
[93maverage test of epoch 15: loss -1.65379 acc 0.65789 roc_auc 0.86462 prc_auc 0.93401[0m
[92maverage training of epoch 16: loss -1.69554 acc 0.66667 roc_auc 0.80320 prc_auc 0.90516[0m
[93maverage test of epoch 16: loss -1.73892 acc 0.65789 roc_auc 0.86462 prc_auc 0.93401[0m
[92maverage training of epoch 17: loss -1.78302 acc 0.66667 roc_auc 0.82080 prc_auc 0.91185[0m
[93maverage test of epoch 17: loss -1.82579 acc 0.65789 roc_auc 0.86462 prc_auc 0.93401[0m
[92maverage training of epoch 18: loss -1.87322 acc 0.66667 roc_auc 0.83680 prc_auc 0.91766[0m
[93maverage test of epoch 18: loss -1.91537 acc 0.65789 roc_auc 0.86462 prc_auc 0.93401[0m
[92maverage training of epoch 19: loss -1.96549 acc 0.66667 roc_auc 0.84430 prc_auc 0.91942[0m
[93maverage test of epoch 19: loss -2.00576 acc 0.65789 roc_auc 0.86462 prc_auc 0.93401[0m
[92maverage training of epoch 20: loss -2.05724 acc 0.66667 roc_auc 0.85140 prc_auc 0.92145[0m
[93maverage test of epoch 20: loss -2.09488 acc 0.65789 roc_auc 0.86462 prc_auc 0.93401[0m
[92maverage training of epoch 21: loss -2.14726 acc 0.66667 roc_auc 0.86080 prc_auc 0.92414[0m
[93maverage test of epoch 21: loss -2.18275 acc 0.65789 roc_auc 0.86462 prc_auc 0.93401[0m
[92maverage training of epoch 22: loss -2.23625 acc 0.66667 roc_auc 0.86580 prc_auc 0.92472[0m
[93maverage test of epoch 22: loss -2.27044 acc 0.65789 roc_auc 0.86462 prc_auc 0.93401[0m
[92maverage training of epoch 23: loss -2.32538 acc 0.66667 roc_auc 0.86660 prc_auc 0.92475[0m
[93maverage test of epoch 23: loss -2.35877 acc 0.65789 roc_auc 0.86462 prc_auc 0.93401[0m
[92maverage training of epoch 24: loss -2.41525 acc 0.66667 roc_auc 0.86520 prc_auc 0.92370[0m
[93maverage test of epoch 24: loss -2.44797 acc 0.65789 roc_auc 0.86462 prc_auc 0.93401[0m
[92maverage training of epoch 25: loss -2.50577 acc 0.66667 roc_auc 0.86220 prc_auc 0.92265[0m
[93maverage test of epoch 25: loss -2.53762 acc 0.65789 roc_auc 0.86154 prc_auc 0.93308[0m
[92maverage training of epoch 26: loss -2.59636 acc 0.66667 roc_auc 0.85760 prc_auc 0.92084[0m
[93maverage test of epoch 26: loss -2.62701 acc 0.65789 roc_auc 0.86154 prc_auc 0.93308[0m
[92maverage training of epoch 27: loss -2.68634 acc 0.66667 roc_auc 0.85500 prc_auc 0.92006[0m
[93maverage test of epoch 27: loss -2.71548 acc 0.65789 roc_auc 0.86154 prc_auc 0.93308[0m
[92maverage training of epoch 28: loss -2.77510 acc 0.66667 roc_auc 0.85360 prc_auc 0.91860[0m
[93maverage test of epoch 28: loss -2.80252 acc 0.65789 roc_auc 0.86154 prc_auc 0.93308[0m
[92maverage training of epoch 29: loss -2.86217 acc 0.66667 roc_auc 0.85240 prc_auc 0.91584[0m
[93maverage test of epoch 29: loss -2.88782 acc 0.65789 roc_auc 0.86154 prc_auc 0.93308[0m
[92maverage training of epoch 30: loss -2.94729 acc 0.66667 roc_auc 0.85260 prc_auc 0.91485[0m
[93maverage test of epoch 30: loss -2.97120 acc 0.65789 roc_auc 0.86154 prc_auc 0.93308[0m
[92maverage training of epoch 31: loss -3.03038 acc 0.66667 roc_auc 0.85120 prc_auc 0.91161[0m
[93maverage test of epoch 31: loss -3.05263 acc 0.65789 roc_auc 0.86462 prc_auc 0.93401[0m
[92maverage training of epoch 32: loss -3.11145 acc 0.66667 roc_auc 0.85000 prc_auc 0.90817[0m
[93maverage test of epoch 32: loss -3.13214 acc 0.65789 roc_auc 0.86462 prc_auc 0.93401[0m
[92maverage training of epoch 33: loss -3.19058 acc 0.66667 roc_auc 0.84820 prc_auc 0.90556[0m
[93maverage test of epoch 33: loss -3.20983 acc 0.65789 roc_auc 0.86462 prc_auc 0.93401[0m
[92maverage training of epoch 34: loss -3.26789 acc 0.66667 roc_auc 0.84500 prc_auc 0.90163[0m
[93maverage test of epoch 34: loss -3.28582 acc 0.65789 roc_auc 0.86462 prc_auc 0.93401[0m
[92maverage training of epoch 35: loss -3.34351 acc 0.66667 roc_auc 0.84120 prc_auc 0.89860[0m
[93maverage test of epoch 35: loss -3.36025 acc 0.65789 roc_auc 0.86462 prc_auc 0.93401[0m
[92maverage training of epoch 36: loss -3.41758 acc 0.66667 roc_auc 0.83590 prc_auc 0.89515[0m
[93maverage test of epoch 36: loss -3.43324 acc 0.65789 roc_auc 0.86462 prc_auc 0.93401[0m
[92maverage training of epoch 37: loss -3.49023 acc 0.66667 roc_auc 0.83100 prc_auc 0.89095[0m
[93maverage test of epoch 37: loss -3.50490 acc 0.65789 roc_auc 0.86462 prc_auc 0.93401[0m
[92maverage training of epoch 38: loss -3.56158 acc 0.66667 roc_auc 0.82240 prc_auc 0.88295[0m
[93maverage test of epoch 38: loss -3.57534 acc 0.65789 roc_auc 0.86462 prc_auc 0.93401[0m
[92maverage training of epoch 39: loss -3.63174 acc 0.66667 roc_auc 0.81540 prc_auc 0.87747[0m
[93maverage test of epoch 39: loss -3.64467 acc 0.65789 roc_auc 0.86462 prc_auc 0.93401[0m
[92maverage training of epoch 40: loss -3.70081 acc 0.66667 roc_auc 0.80860 prc_auc 0.87363[0m
[93maverage test of epoch 40: loss -3.71298 acc 0.65789 roc_auc 0.86462 prc_auc 0.93401[0m
[92maverage training of epoch 41: loss -3.76887 acc 0.66667 roc_auc 0.80140 prc_auc 0.86379[0m
[93maverage test of epoch 41: loss -3.78035 acc 0.65789 roc_auc 0.86462 prc_auc 0.93401[0m
[92maverage training of epoch 42: loss -3.83602 acc 0.66667 roc_auc 0.79280 prc_auc 0.85774[0m
[93maverage test of epoch 42: loss -3.84685 acc 0.65789 roc_auc 0.86462 prc_auc 0.93401[0m
[92maverage training of epoch 43: loss -3.90233 acc 0.66667 roc_auc 0.78540 prc_auc 0.85233[0m
[93maverage test of epoch 43: loss -3.91256 acc 0.65789 roc_auc 0.86462 prc_auc 0.93401[0m
[92maverage training of epoch 44: loss -3.96785 acc 0.66667 roc_auc 0.77380 prc_auc 0.84656[0m
[93maverage test of epoch 44: loss -3.97753 acc 0.65789 roc_auc 0.86462 prc_auc 0.93401[0m
[92maverage training of epoch 45: loss -4.03267 acc 0.66667 roc_auc 0.75760 prc_auc 0.83862[0m
[93maverage test of epoch 45: loss -4.04183 acc 0.65789 roc_auc 0.86462 prc_auc 0.93401[0m
[92maverage training of epoch 46: loss -4.09682 acc 0.66667 roc_auc 0.74080 prc_auc 0.82870[0m
[93maverage test of epoch 46: loss -4.10549 acc 0.65789 roc_auc 0.86462 prc_auc 0.93401[0m
[92maverage training of epoch 47: loss -4.16036 acc 0.66667 roc_auc 0.72550 prc_auc 0.82022[0m
[93maverage test of epoch 47: loss -4.16857 acc 0.65789 roc_auc 0.86462 prc_auc 0.93401[0m
[92maverage training of epoch 48: loss -4.22333 acc 0.66667 roc_auc 0.70860 prc_auc 0.81251[0m
[93maverage test of epoch 48: loss -4.23112 acc 0.65789 roc_auc 0.86462 prc_auc 0.93401[0m
[92maverage training of epoch 49: loss -4.28578 acc 0.66667 roc_auc 0.68930 prc_auc 0.80165[0m
[93maverage test of epoch 49: loss -4.29316 acc 0.65789 roc_auc 0.86462 prc_auc 0.93401[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss 0.33976 acc 0.33333 roc_auc 0.63320 prc_auc 0.80265[0m
[93maverage test of epoch 0: loss 0.28140 acc 0.34211 roc_auc 0.72308 prc_auc 0.87482[0m
[92maverage training of epoch 1: loss 0.25025 acc 0.33333 roc_auc 0.63100 prc_auc 0.80229[0m
[93maverage test of epoch 1: loss 0.19151 acc 0.34211 roc_auc 0.71692 prc_auc 0.87436[0m
[92maverage training of epoch 2: loss 0.15831 acc 0.33333 roc_auc 0.62320 prc_auc 0.79501[0m
[93maverage test of epoch 2: loss 0.09744 acc 0.34211 roc_auc 0.71385 prc_auc 0.87359[0m
[92maverage training of epoch 3: loss 0.06188 acc 0.33333 roc_auc 0.60600 prc_auc 0.77510[0m
[93maverage test of epoch 3: loss -0.00163 acc 0.34211 roc_auc 0.67692 prc_auc 0.84640[0m
[92maverage training of epoch 4: loss -0.03931 acc 0.33333 roc_auc 0.56620 prc_auc 0.72664[0m
[93maverage test of epoch 4: loss -0.10574 acc 0.34211 roc_auc 0.46462 prc_auc 0.73891[0m
[92maverage training of epoch 5: loss -0.14573 acc 0.33333 roc_auc 0.51360 prc_auc 0.68378[0m
[93maverage test of epoch 5: loss -0.21662 acc 0.34211 roc_auc 0.21231 prc_auc 0.55739[0m
[92maverage training of epoch 6: loss -0.26015 acc 0.33333 roc_auc 0.44780 prc_auc 0.62156[0m
[93maverage test of epoch 6: loss -0.33842 acc 0.34211 roc_auc 0.10154 prc_auc 0.48146[0m
[92maverage training of epoch 7: loss -0.38825 acc 0.33333 roc_auc 0.39220 prc_auc 0.59406[0m
[93maverage test of epoch 7: loss -0.47887 acc 0.34211 roc_auc 0.11692 prc_auc 0.48528[0m
[92maverage training of epoch 8: loss -0.53992 acc 0.33333 roc_auc 0.36440 prc_auc 0.58126[0m
[93maverage test of epoch 8: loss -0.65015 acc 0.34211 roc_auc 0.12000 prc_auc 0.48608[0m
[92maverage training of epoch 9: loss -0.72766 acc 0.33333 roc_auc 0.34320 prc_auc 0.57201[0m
[93maverage test of epoch 9: loss -0.86149 acc 0.34211 roc_auc 0.12000 prc_auc 0.48608[0m
[92maverage training of epoch 10: loss -0.95018 acc 0.33333 roc_auc 0.32360 prc_auc 0.56222[0m
[93maverage test of epoch 10: loss -1.09514 acc 0.34211 roc_auc 0.12000 prc_auc 0.48608[0m
[92maverage training of epoch 11: loss -1.17561 acc 0.33333 roc_auc 0.28680 prc_auc 0.54424[0m
[93maverage test of epoch 11: loss -1.30770 acc 0.34211 roc_auc 0.12000 prc_auc 0.48608[0m
[92maverage training of epoch 12: loss -1.36624 acc 0.33333 roc_auc 0.24380 prc_auc 0.52549[0m
[93maverage test of epoch 12: loss -1.47505 acc 0.34211 roc_auc 0.12000 prc_auc 0.48608[0m
[92maverage training of epoch 13: loss -1.51606 acc 0.33333 roc_auc 0.19360 prc_auc 0.50375[0m
[93maverage test of epoch 13: loss -1.60808 acc 0.34211 roc_auc 0.12000 prc_auc 0.48608[0m
[92maverage training of epoch 14: loss -1.63913 acc 0.33333 roc_auc 0.14660 prc_auc 0.48629[0m
[93maverage test of epoch 14: loss -1.72158 acc 0.34211 roc_auc 0.12000 prc_auc 0.48608[0m
[92maverage training of epoch 15: loss -1.74687 acc 0.33333 roc_auc 0.11720 prc_auc 0.47769[0m
[93maverage test of epoch 15: loss -1.82382 acc 0.34211 roc_auc 0.12000 prc_auc 0.48608[0m
[92maverage training of epoch 16: loss -1.84538 acc 0.33333 roc_auc 0.09620 prc_auc 0.47226[0m
[93maverage test of epoch 16: loss -1.91896 acc 0.34211 roc_auc 0.12000 prc_auc 0.48608[0m
[92maverage training of epoch 17: loss -1.93782 acc 0.33333 roc_auc 0.08420 prc_auc 0.46948[0m
[93maverage test of epoch 17: loss -2.00922 acc 0.34211 roc_auc 0.12000 prc_auc 0.48608[0m
[92maverage training of epoch 18: loss -2.02597 acc 0.33333 roc_auc 0.07760 prc_auc 0.46809[0m
[93maverage test of epoch 18: loss -2.09588 acc 0.34211 roc_auc 0.12000 prc_auc 0.48608[0m
[92maverage training of epoch 19: loss -2.11091 acc 0.33333 roc_auc 0.07720 prc_auc 0.46806[0m
[93maverage test of epoch 19: loss -2.17976 acc 0.34211 roc_auc 0.12000 prc_auc 0.48608[0m
[92maverage training of epoch 20: loss -2.19331 acc 0.33333 roc_auc 0.08560 prc_auc 0.46997[0m
[93maverage test of epoch 20: loss -2.26137 acc 0.34211 roc_auc 0.12000 prc_auc 0.48608[0m
[92maverage training of epoch 21: loss -2.27363 acc 0.33333 roc_auc 0.10260 prc_auc 0.47426[0m
[93maverage test of epoch 21: loss -2.34106 acc 0.34211 roc_auc 0.11692 prc_auc 0.48512[0m
[92maverage training of epoch 22: loss -2.35217 acc 0.33333 roc_auc 0.12120 prc_auc 0.47977[0m
[93maverage test of epoch 22: loss -2.41906 acc 0.34211 roc_auc 0.11692 prc_auc 0.48512[0m
[92maverage training of epoch 23: loss -2.42912 acc 0.33333 roc_auc 0.14280 prc_auc 0.48658[0m
[93maverage test of epoch 23: loss -2.49552 acc 0.34211 roc_auc 0.11692 prc_auc 0.48512[0m
[92maverage training of epoch 24: loss -2.50461 acc 0.33333 roc_auc 0.16600 prc_auc 0.49385[0m
[93maverage test of epoch 24: loss -2.57053 acc 0.34211 roc_auc 0.11692 prc_auc 0.48512[0m
[92maverage training of epoch 25: loss -2.57873 acc 0.33333 roc_auc 0.20040 prc_auc 0.50481[0m
[93maverage test of epoch 25: loss -2.64415 acc 0.34211 roc_auc 0.11692 prc_auc 0.48512[0m
[92maverage training of epoch 26: loss -2.65152 acc 0.33333 roc_auc 0.24320 prc_auc 0.51929[0m
[93maverage test of epoch 26: loss -2.71641 acc 0.34211 roc_auc 0.11692 prc_auc 0.48512[0m
[92maverage training of epoch 27: loss -2.72299 acc 0.33333 roc_auc 0.27600 prc_auc 0.53070[0m
[93maverage test of epoch 27: loss -2.78731 acc 0.34211 roc_auc 0.11692 prc_auc 0.48512[0m
[92maverage training of epoch 28: loss -2.79317 acc 0.33333 roc_auc 0.29880 prc_auc 0.53988[0m
[93maverage test of epoch 28: loss -2.85688 acc 0.34211 roc_auc 0.11692 prc_auc 0.48497[0m
[92maverage training of epoch 29: loss -2.86206 acc 0.33333 roc_auc 0.31640 prc_auc 0.54694[0m
[93maverage test of epoch 29: loss -2.92512 acc 0.34211 roc_auc 0.12000 prc_auc 0.48584[0m
[92maverage training of epoch 30: loss -2.92967 acc 0.33333 roc_auc 0.33200 prc_auc 0.55317[0m
[93maverage test of epoch 30: loss -2.99204 acc 0.34211 roc_auc 0.12923 prc_auc 0.48859[0m
[92maverage training of epoch 31: loss -2.99601 acc 0.33333 roc_auc 0.34520 prc_auc 0.55853[0m
[93maverage test of epoch 31: loss -3.05766 acc 0.34211 roc_auc 0.12923 prc_auc 0.48859[0m
[92maverage training of epoch 32: loss -3.06111 acc 0.33333 roc_auc 0.35960 prc_auc 0.56466[0m
[93maverage test of epoch 32: loss -3.12201 acc 0.34211 roc_auc 0.12923 prc_auc 0.48859[0m
[92maverage training of epoch 33: loss -3.12499 acc 0.33333 roc_auc 0.36770 prc_auc 0.56837[0m
[93maverage test of epoch 33: loss -3.18513 acc 0.34211 roc_auc 0.13846 prc_auc 0.49031[0m
[92maverage training of epoch 34: loss -3.18768 acc 0.33333 roc_auc 0.37120 prc_auc 0.57026[0m
[93maverage test of epoch 34: loss -3.24704 acc 0.34211 roc_auc 0.14462 prc_auc 0.49213[0m
[92maverage training of epoch 35: loss -3.24923 acc 0.33333 roc_auc 0.37940 prc_auc 0.57423[0m
[93maverage test of epoch 35: loss -3.30781 acc 0.34211 roc_auc 0.15077 prc_auc 0.49340[0m
[92maverage training of epoch 36: loss -3.30969 acc 0.33333 roc_auc 0.38380 prc_auc 0.57665[0m
[93maverage test of epoch 36: loss -3.36748 acc 0.34211 roc_auc 0.16615 prc_auc 0.50769[0m
[92maverage training of epoch 37: loss -3.36910 acc 0.33333 roc_auc 0.38660 prc_auc 0.57769[0m
[93maverage test of epoch 37: loss -3.42612 acc 0.34211 roc_auc 0.16615 prc_auc 0.52674[0m
[92maverage training of epoch 38: loss -3.42752 acc 0.33333 roc_auc 0.39100 prc_auc 0.57954[0m
[93maverage test of epoch 38: loss -3.48380 acc 0.34211 roc_auc 0.16923 prc_auc 0.52769[0m
[92maverage training of epoch 39: loss -3.48504 acc 0.33333 roc_auc 0.39300 prc_auc 0.58052[0m
[93maverage test of epoch 39: loss -3.54059 acc 0.34211 roc_auc 0.17077 prc_auc 0.52760[0m
[92maverage training of epoch 40: loss -3.54171 acc 0.33333 roc_auc 0.39540 prc_auc 0.58140[0m
[93maverage test of epoch 40: loss -3.59657 acc 0.34211 roc_auc 0.17231 prc_auc 0.52963[0m
[92maverage training of epoch 41: loss -3.59762 acc 0.33333 roc_auc 0.40000 prc_auc 0.58230[0m
[93maverage test of epoch 41: loss -3.65185 acc 0.34211 roc_auc 0.18000 prc_auc 0.53014[0m
[92maverage training of epoch 42: loss -3.65288 acc 0.33333 roc_auc 0.40340 prc_auc 0.58431[0m
[93maverage test of epoch 42: loss -3.70655 acc 0.34211 roc_auc 0.18923 prc_auc 0.53280[0m
[92maverage training of epoch 43: loss -3.70761 acc 0.33333 roc_auc 0.41040 prc_auc 0.59869[0m
[93maverage test of epoch 43: loss -3.76079 acc 0.34211 roc_auc 0.23385 prc_auc 0.57058[0m
[92maverage training of epoch 44: loss -3.76195 acc 0.33333 roc_auc 0.41620 prc_auc 0.60795[0m
[93maverage test of epoch 44: loss -3.81477 acc 0.34211 roc_auc 0.28308 prc_auc 0.61126[0m
[92maverage training of epoch 45: loss -3.81610 acc 0.33333 roc_auc 0.42140 prc_auc 0.61296[0m
[93maverage test of epoch 45: loss -3.86871 acc 0.34211 roc_auc 0.29692 prc_auc 0.62983[0m
[92maverage training of epoch 46: loss -3.87030 acc 0.33333 roc_auc 0.42680 prc_auc 0.61792[0m
[93maverage test of epoch 46: loss -3.92292 acc 0.34211 roc_auc 0.31846 prc_auc 0.63785[0m
[92maverage training of epoch 47: loss -3.92490 acc 0.33333 roc_auc 0.43120 prc_auc 0.62074[0m
[93maverage test of epoch 47: loss -3.97778 acc 0.34211 roc_auc 0.33077 prc_auc 0.64092[0m
[92maverage training of epoch 48: loss -3.98032 acc 0.33333 roc_auc 0.43760 prc_auc 0.62676[0m
[93maverage test of epoch 48: loss -4.03382 acc 0.34211 roc_auc 0.34769 prc_auc 0.64622[0m
[92maverage training of epoch 49: loss -4.03710 acc 0.33333 roc_auc 0.44220 prc_auc 0.63120[0m
[93maverage test of epoch 49: loss -4.09166 acc 0.34211 roc_auc 0.36923 prc_auc 0.66998[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.65427 acc 0.33333 roc_auc 0.40180 prc_auc 0.60779[0m
[93maverage test of epoch 0: loss -0.73609 acc 0.34211 roc_auc 0.06769 prc_auc 0.46855[0m
[92maverage training of epoch 1: loss -0.79677 acc 0.33333 roc_auc 0.40860 prc_auc 0.61227[0m
[93maverage test of epoch 1: loss -0.87554 acc 0.34211 roc_auc 0.07077 prc_auc 0.46973[0m
[92maverage training of epoch 2: loss -0.93667 acc 0.33333 roc_auc 0.41780 prc_auc 0.62102[0m
[93maverage test of epoch 2: loss -1.01197 acc 0.34211 roc_auc 0.07385 prc_auc 0.47052[0m
[92maverage training of epoch 3: loss -1.07348 acc 0.33333 roc_auc 0.42620 prc_auc 0.63390[0m
[93maverage test of epoch 3: loss -1.14531 acc 0.34211 roc_auc 0.08615 prc_auc 0.47428[0m
[92maverage training of epoch 4: loss -1.20730 acc 0.33333 roc_auc 0.43740 prc_auc 0.64300[0m
[93maverage test of epoch 4: loss -1.27583 acc 0.34211 roc_auc 0.14769 prc_auc 0.52391[0m
[92maverage training of epoch 5: loss -1.33851 acc 0.48667 roc_auc 0.44740 prc_auc 0.65567[0m
[93maverage test of epoch 5: loss -1.40414 acc 0.65789 roc_auc 0.21538 prc_auc 0.55160[0m
[92maverage training of epoch 6: loss -1.46808 acc 0.66667 roc_auc 0.45320 prc_auc 0.66085[0m
[93maverage test of epoch 6: loss -1.53176 acc 0.65789 roc_auc 0.69846 prc_auc 0.87310[0m
[92maverage training of epoch 7: loss -1.59838 acc 0.66667 roc_auc 0.45760 prc_auc 0.66396[0m
[93maverage test of epoch 7: loss -1.66215 acc 0.65789 roc_auc 0.80923 prc_auc 0.92594[0m
[92maverage training of epoch 8: loss -1.73469 acc 0.66667 roc_auc 0.46200 prc_auc 0.66587[0m
[93maverage test of epoch 8: loss -1.80259 acc 0.65789 roc_auc 0.86462 prc_auc 0.94617[0m
[92maverage training of epoch 9: loss -1.88743 acc 0.66667 roc_auc 0.46680 prc_auc 0.67100[0m
[93maverage test of epoch 9: loss -1.96634 acc 0.65789 roc_auc 0.90769 prc_auc 0.96508[0m
[92maverage training of epoch 10: loss -2.07306 acc 0.66667 roc_auc 0.47480 prc_auc 0.68154[0m
[93maverage test of epoch 10: loss -2.17058 acc 0.65789 roc_auc 0.95692 prc_auc 0.98286[0m
[92maverage training of epoch 11: loss -2.30308 acc 0.66667 roc_auc 0.49520 prc_auc 0.69801[0m
[93maverage test of epoch 11: loss -2.41377 acc 0.65789 roc_auc 0.96000 prc_auc 0.98200[0m
[92maverage training of epoch 12: loss -2.54219 acc 0.66667 roc_auc 0.56460 prc_auc 0.75918[0m
[93maverage test of epoch 12: loss -2.63017 acc 0.65789 roc_auc 0.95692 prc_auc 0.98047[0m
[92maverage training of epoch 13: loss -2.72763 acc 0.66667 roc_auc 0.60360 prc_auc 0.78710[0m
[93maverage test of epoch 13: loss -2.78514 acc 0.65789 roc_auc 0.96000 prc_auc 0.98229[0m
[92maverage training of epoch 14: loss -2.86566 acc 0.66667 roc_auc 0.59800 prc_auc 0.77687[0m
[93maverage test of epoch 14: loss -2.90849 acc 0.65789 roc_auc 0.95692 prc_auc 0.98069[0m
[92maverage training of epoch 15: loss -2.98160 acc 0.66667 roc_auc 0.58280 prc_auc 0.76041[0m
[93maverage test of epoch 15: loss -3.01707 acc 0.65789 roc_auc 0.95692 prc_auc 0.98069[0m
[92maverage training of epoch 16: loss -3.08611 acc 0.66667 roc_auc 0.56100 prc_auc 0.74183[0m
[93maverage test of epoch 16: loss -3.11701 acc 0.65789 roc_auc 0.95692 prc_auc 0.98069[0m
[92maverage training of epoch 17: loss -3.18328 acc 0.66667 roc_auc 0.53420 prc_auc 0.71896[0m
[93maverage test of epoch 17: loss -3.21090 acc 0.65789 roc_auc 0.95692 prc_auc 0.98069[0m
[92maverage training of epoch 18: loss -3.27505 acc 0.66667 roc_auc 0.51780 prc_auc 0.70697[0m
[93maverage test of epoch 18: loss -3.30009 acc 0.65789 roc_auc 0.95692 prc_auc 0.98069[0m
[92maverage training of epoch 19: loss -3.36249 acc 0.66667 roc_auc 0.49780 prc_auc 0.69490[0m
[93maverage test of epoch 19: loss -3.38541 acc 0.65789 roc_auc 0.95692 prc_auc 0.98069[0m
[92maverage training of epoch 20: loss -3.44631 acc 0.66667 roc_auc 0.47520 prc_auc 0.68127[0m
[93maverage test of epoch 20: loss -3.46743 acc 0.65789 roc_auc 0.95692 prc_auc 0.98069[0m
[92maverage training of epoch 21: loss -3.52702 acc 0.66667 roc_auc 0.46360 prc_auc 0.67610[0m
[93maverage test of epoch 21: loss -3.54660 acc 0.65789 roc_auc 0.94769 prc_auc 0.97585[0m
[92maverage training of epoch 22: loss -3.60502 acc 0.66667 roc_auc 0.45220 prc_auc 0.67145[0m
[93maverage test of epoch 22: loss -3.62326 acc 0.65789 roc_auc 0.94462 prc_auc 0.97443[0m
[92maverage training of epoch 23: loss -3.68065 acc 0.66667 roc_auc 0.44580 prc_auc 0.66943[0m
[93maverage test of epoch 23: loss -3.69772 acc 0.65789 roc_auc 0.93231 prc_auc 0.96984[0m
[92maverage training of epoch 24: loss -3.75418 acc 0.66667 roc_auc 0.44420 prc_auc 0.66755[0m
[93maverage test of epoch 24: loss -3.77023 acc 0.65789 roc_auc 0.90769 prc_auc 0.96125[0m
[92maverage training of epoch 25: loss -3.82586 acc 0.66667 roc_auc 0.43880 prc_auc 0.65992[0m
[93maverage test of epoch 25: loss -3.84102 acc 0.65789 roc_auc 0.90154 prc_auc 0.95779[0m
[92maverage training of epoch 26: loss -3.89591 acc 0.66667 roc_auc 0.42960 prc_auc 0.65316[0m
[93maverage test of epoch 26: loss -3.91030 acc 0.65789 roc_auc 0.89846 prc_auc 0.95626[0m
[92maverage training of epoch 27: loss -3.96452 acc 0.66667 roc_auc 0.42410 prc_auc 0.64900[0m
[93maverage test of epoch 27: loss -3.97825 acc 0.65789 roc_auc 0.88154 prc_auc 0.94702[0m
[92maverage training of epoch 28: loss -4.03188 acc 0.66667 roc_auc 0.42180 prc_auc 0.64667[0m
[93maverage test of epoch 28: loss -4.04503 acc 0.65789 roc_auc 0.88000 prc_auc 0.94816[0m
[92maverage training of epoch 29: loss -4.09813 acc 0.66667 roc_auc 0.41580 prc_auc 0.64350[0m
[93maverage test of epoch 29: loss -4.11079 acc 0.65789 roc_auc 0.86462 prc_auc 0.94410[0m
[92maverage training of epoch 30: loss -4.16342 acc 0.66667 roc_auc 0.41260 prc_auc 0.63954[0m
[93maverage test of epoch 30: loss -4.17566 acc 0.65789 roc_auc 0.85231 prc_auc 0.93760[0m
[92maverage training of epoch 31: loss -4.22788 acc 0.66667 roc_auc 0.41280 prc_auc 0.63960[0m
[93maverage test of epoch 31: loss -4.23978 acc 0.65789 roc_auc 0.84308 prc_auc 0.93389[0m
[92maverage training of epoch 32: loss -4.29162 acc 0.66667 roc_auc 0.41180 prc_auc 0.63771[0m
[93maverage test of epoch 32: loss -4.30323 acc 0.65789 roc_auc 0.82923 prc_auc 0.92908[0m
[92maverage training of epoch 33: loss -4.35475 acc 0.66667 roc_auc 0.40820 prc_auc 0.63230[0m
[93maverage test of epoch 33: loss -4.36613 acc 0.65789 roc_auc 0.80308 prc_auc 0.92092[0m
[92maverage training of epoch 34: loss -4.41736 acc 0.66667 roc_auc 0.40900 prc_auc 0.62985[0m
[93maverage test of epoch 34: loss -4.42855 acc 0.65789 roc_auc 0.79846 prc_auc 0.91989[0m
[92maverage training of epoch 35: loss -4.47953 acc 0.66667 roc_auc 0.41020 prc_auc 0.63118[0m
[93maverage test of epoch 35: loss -4.49057 acc 0.65789 roc_auc 0.78923 prc_auc 0.91596[0m
[92maverage training of epoch 36: loss -4.54133 acc 0.66667 roc_auc 0.40940 prc_auc 0.62903[0m
[93maverage test of epoch 36: loss -4.55226 acc 0.65789 roc_auc 0.78154 prc_auc 0.91262[0m
[92maverage training of epoch 37: loss -4.60282 acc 0.66667 roc_auc 0.40840 prc_auc 0.62819[0m
[93maverage test of epoch 37: loss -4.61366 acc 0.65789 roc_auc 0.77385 prc_auc 0.90867[0m
[92maverage training of epoch 38: loss -4.66405 acc 0.66667 roc_auc 0.40870 prc_auc 0.62816[0m
[93maverage test of epoch 38: loss -4.67483 acc 0.65789 roc_auc 0.75846 prc_auc 0.90333[0m
[92maverage training of epoch 39: loss -4.72506 acc 0.66667 roc_auc 0.40920 prc_auc 0.62857[0m
[93maverage test of epoch 39: loss -4.73580 acc 0.65789 roc_auc 0.74308 prc_auc 0.89631[0m
[92maverage training of epoch 40: loss -4.78589 acc 0.66667 roc_auc 0.41030 prc_auc 0.62916[0m
[93maverage test of epoch 40: loss -4.79660 acc 0.65789 roc_auc 0.72615 prc_auc 0.89085[0m
[92maverage training of epoch 41: loss -4.84656 acc 0.66667 roc_auc 0.40940 prc_auc 0.62868[0m
[93maverage test of epoch 41: loss -4.85725 acc 0.65789 roc_auc 0.71846 prc_auc 0.88733[0m
[92maverage training of epoch 42: loss -4.90710 acc 0.66667 roc_auc 0.40880 prc_auc 0.62843[0m
[93maverage test of epoch 42: loss -4.91777 acc 0.65789 roc_auc 0.70462 prc_auc 0.88365[0m
[92maverage training of epoch 43: loss -4.96751 acc 0.66667 roc_auc 0.40730 prc_auc 0.62719[0m
[93maverage test of epoch 43: loss -4.97817 acc 0.65789 roc_auc 0.69077 prc_auc 0.87749[0m
[92maverage training of epoch 44: loss -5.02781 acc 0.66667 roc_auc 0.40650 prc_auc 0.62682[0m
[93maverage test of epoch 44: loss -5.03845 acc 0.65789 roc_auc 0.69231 prc_auc 0.87591[0m
[92maverage training of epoch 45: loss -5.08801 acc 0.66667 roc_auc 0.40520 prc_auc 0.62636[0m
[93maverage test of epoch 45: loss -5.09862 acc 0.65789 roc_auc 0.69231 prc_auc 0.87563[0m
[92maverage training of epoch 46: loss -5.14809 acc 0.66667 roc_auc 0.40320 prc_auc 0.62542[0m
[93maverage test of epoch 46: loss -5.15867 acc 0.65789 roc_auc 0.66000 prc_auc 0.85675[0m
[92maverage training of epoch 47: loss -5.20806 acc 0.66667 roc_auc 0.40150 prc_auc 0.62380[0m
[93maverage test of epoch 47: loss -5.21859 acc 0.65789 roc_auc 0.63077 prc_auc 0.84545[0m
[92maverage training of epoch 48: loss -5.26792 acc 0.66667 roc_auc 0.39980 prc_auc 0.62269[0m
[93maverage test of epoch 48: loss -5.27840 acc 0.65789 roc_auc 0.60769 prc_auc 0.82718[0m
[92maverage training of epoch 49: loss -5.32766 acc 0.66667 roc_auc 0.39820 prc_auc 0.62187[0m
[93maverage test of epoch 49: loss -5.33807 acc 0.65789 roc_auc 0.58769 prc_auc 0.81295[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.08132 acc 0.33775 roc_auc 0.32529 prc_auc 0.55511[0m
[93maverage test of epoch 0: loss -0.09821 acc 0.32432 roc_auc 0.10333 prc_auc 0.49908[0m
[92maverage training of epoch 1: loss -0.15069 acc 0.33775 roc_auc 0.33882 prc_auc 0.56729[0m
[93maverage test of epoch 1: loss -0.16808 acc 0.32432 roc_auc 0.10000 prc_auc 0.49817[0m
[92maverage training of epoch 2: loss -0.22221 acc 0.33775 roc_auc 0.35824 prc_auc 0.57513[0m
[93maverage test of epoch 2: loss -0.23999 acc 0.32432 roc_auc 0.09667 prc_auc 0.49593[0m
[92maverage training of epoch 3: loss -0.29557 acc 0.33775 roc_auc 0.38059 prc_auc 0.58743[0m
[93maverage test of epoch 3: loss -0.31356 acc 0.32432 roc_auc 0.16000 prc_auc 0.54921[0m
[92maverage training of epoch 4: loss -0.37037 acc 0.33775 roc_auc 0.41000 prc_auc 0.60655[0m
[93maverage test of epoch 4: loss -0.38828 acc 0.32432 roc_auc 0.20667 prc_auc 0.57861[0m
[92maverage training of epoch 5: loss -0.44610 acc 0.33775 roc_auc 0.44510 prc_auc 0.63368[0m
[93maverage test of epoch 5: loss -0.46366 acc 0.32432 roc_auc 0.22333 prc_auc 0.58620[0m
[92maverage training of epoch 6: loss -0.52231 acc 0.33775 roc_auc 0.48431 prc_auc 0.66329[0m
[93maverage test of epoch 6: loss -0.53924 acc 0.32432 roc_auc 0.27000 prc_auc 0.64020[0m
[92maverage training of epoch 7: loss -0.59865 acc 0.33775 roc_auc 0.52176 prc_auc 0.70254[0m
[93maverage test of epoch 7: loss -0.61473 acc 0.32432 roc_auc 0.35000 prc_auc 0.68268[0m
[92maverage training of epoch 8: loss -0.67492 acc 0.33775 roc_auc 0.55706 prc_auc 0.73701[0m
[93maverage test of epoch 8: loss -0.69002 acc 0.32432 roc_auc 0.41000 prc_auc 0.71370[0m
[92maverage training of epoch 9: loss -0.75105 acc 0.33775 roc_auc 0.58941 prc_auc 0.76601[0m
[93maverage test of epoch 9: loss -0.76514 acc 0.32432 roc_auc 0.58667 prc_auc 0.80689[0m
[92maverage training of epoch 10: loss -0.82712 acc 0.33775 roc_auc 0.60922 prc_auc 0.78453[0m
[93maverage test of epoch 10: loss -0.84024 acc 0.32432 roc_auc 0.62667 prc_auc 0.82273[0m
[92maverage training of epoch 11: loss -0.90327 acc 0.33775 roc_auc 0.62529 prc_auc 0.79598[0m
[93maverage test of epoch 11: loss -0.91554 acc 0.32432 roc_auc 0.66667 prc_auc 0.83666[0m
[92maverage training of epoch 12: loss -0.97969 acc 0.33775 roc_auc 0.63647 prc_auc 0.80382[0m
[93maverage test of epoch 12: loss -0.99129 acc 0.32432 roc_auc 0.75667 prc_auc 0.86704[0m
[92maverage training of epoch 13: loss -1.05666 acc 0.33775 roc_auc 0.65078 prc_auc 0.81327[0m
[93maverage test of epoch 13: loss -1.06779 acc 0.32432 roc_auc 0.81167 prc_auc 0.88720[0m
[92maverage training of epoch 14: loss -1.13453 acc 0.33775 roc_auc 0.66902 prc_auc 0.82603[0m
[93maverage test of epoch 14: loss -1.14543 acc 0.32432 roc_auc 0.82667 prc_auc 0.90541[0m
[92maverage training of epoch 15: loss -1.21379 acc 0.33775 roc_auc 0.68235 prc_auc 0.83543[0m
[93maverage test of epoch 15: loss -1.22479 acc 0.32432 roc_auc 0.85667 prc_auc 0.91428[0m
[92maverage training of epoch 16: loss -1.29512 acc 0.33775 roc_auc 0.70333 prc_auc 0.84952[0m
[93maverage test of epoch 16: loss -1.30670 acc 0.32432 roc_auc 0.85333 prc_auc 0.91330[0m
[92maverage training of epoch 17: loss -1.37946 acc 0.33775 roc_auc 0.73118 prc_auc 0.86398[0m
[93maverage test of epoch 17: loss -1.39223 acc 0.32432 roc_auc 0.84667 prc_auc 0.91092[0m
[92maverage training of epoch 18: loss -1.46779 acc 0.33775 roc_auc 0.75824 prc_auc 0.88157[0m
[93maverage test of epoch 18: loss -1.48212 acc 0.32432 roc_auc 0.84667 prc_auc 0.91092[0m
[92maverage training of epoch 19: loss -1.56020 acc 0.33775 roc_auc 0.77765 prc_auc 0.89409[0m
[93maverage test of epoch 19: loss -1.57566 acc 0.32432 roc_auc 0.84667 prc_auc 0.91092[0m
[92maverage training of epoch 20: loss -1.65510 acc 0.33775 roc_auc 0.79706 prc_auc 0.90475[0m
[93maverage test of epoch 20: loss -1.67048 acc 0.32432 roc_auc 0.84667 prc_auc 0.91099[0m
[92maverage training of epoch 21: loss -1.74992 acc 0.33775 roc_auc 0.81510 prc_auc 0.91506[0m
[93maverage test of epoch 21: loss -1.76404 acc 0.32432 roc_auc 0.84667 prc_auc 0.91099[0m
[92maverage training of epoch 22: loss -1.84259 acc 0.33775 roc_auc 0.82686 prc_auc 0.92088[0m
[93maverage test of epoch 22: loss -1.85488 acc 0.32432 roc_auc 0.84667 prc_auc 0.91099[0m
[92maverage training of epoch 23: loss -1.93216 acc 0.33775 roc_auc 0.84039 prc_auc 0.92745[0m
[93maverage test of epoch 23: loss -1.94248 acc 0.32432 roc_auc 0.84667 prc_auc 0.91099[0m
[92maverage training of epoch 24: loss -2.01837 acc 0.33775 roc_auc 0.85529 prc_auc 0.93430[0m
[93maverage test of epoch 24: loss -2.02680 acc 0.32432 roc_auc 0.84667 prc_auc 0.91099[0m
[92maverage training of epoch 25: loss -2.10130 acc 0.33775 roc_auc 0.86039 prc_auc 0.93689[0m
[93maverage test of epoch 25: loss -2.10801 acc 0.32432 roc_auc 0.84667 prc_auc 0.91099[0m
[92maverage training of epoch 26: loss -2.18118 acc 0.33775 roc_auc 0.85137 prc_auc 0.93300[0m
[93maverage test of epoch 26: loss -2.18638 acc 0.32432 roc_auc 0.84667 prc_auc 0.91099[0m
[92maverage training of epoch 27: loss -2.25834 acc 0.33775 roc_auc 0.84451 prc_auc 0.93005[0m
[93maverage test of epoch 27: loss -2.26227 acc 0.32432 roc_auc 0.84667 prc_auc 0.91099[0m
[92maverage training of epoch 28: loss -2.33316 acc 0.33775 roc_auc 0.83333 prc_auc 0.92481[0m
[93maverage test of epoch 28: loss -2.33601 acc 0.32432 roc_auc 0.84333 prc_auc 0.90851[0m
[92maverage training of epoch 29: loss -2.40602 acc 0.33775 roc_auc 0.82275 prc_auc 0.91980[0m
[93maverage test of epoch 29: loss -2.40795 acc 0.32432 roc_auc 0.84000 prc_auc 0.90760[0m
[92maverage training of epoch 30: loss -2.47730 acc 0.33775 roc_auc 0.81039 prc_auc 0.91422[0m
[93maverage test of epoch 30: loss -2.47838 acc 0.32432 roc_auc 0.84333 prc_auc 0.90844[0m
[92maverage training of epoch 31: loss -2.54730 acc 0.33775 roc_auc 0.78765 prc_auc 0.90373[0m
[93maverage test of epoch 31: loss -2.54756 acc 0.32432 roc_auc 0.84333 prc_auc 0.90844[0m
[92maverage training of epoch 32: loss -2.61623 acc 0.33775 roc_auc 0.75598 prc_auc 0.88906[0m
[93maverage test of epoch 32: loss -2.61571 acc 0.32432 roc_auc 0.84333 prc_auc 0.90844[0m
[92maverage training of epoch 33: loss -2.68414 acc 0.33775 roc_auc 0.72804 prc_auc 0.87437[0m
[93maverage test of epoch 33: loss -2.68293 acc 0.32432 roc_auc 0.84333 prc_auc 0.90844[0m
[92maverage training of epoch 34: loss -2.75101 acc 0.33775 roc_auc 0.70314 prc_auc 0.85983[0m
[93maverage test of epoch 34: loss -2.74926 acc 0.32432 roc_auc 0.84000 prc_auc 0.90760[0m
[92maverage training of epoch 35: loss -2.81689 acc 0.33775 roc_auc 0.66902 prc_auc 0.84055[0m
[93maverage test of epoch 35: loss -2.81471 acc 0.32432 roc_auc 0.83833 prc_auc 0.90697[0m
[92maverage training of epoch 36: loss -2.88186 acc 0.33775 roc_auc 0.64490 prc_auc 0.82634[0m
[93maverage test of epoch 36: loss -2.87933 acc 0.32432 roc_auc 0.84667 prc_auc 0.91007[0m
[92maverage training of epoch 37: loss -2.94600 acc 0.33775 roc_auc 0.61039 prc_auc 0.80511[0m
[93maverage test of epoch 37: loss -2.94319 acc 0.32432 roc_auc 0.84333 prc_auc 0.90876[0m
[92maverage training of epoch 38: loss -3.00940 acc 0.33775 roc_auc 0.57667 prc_auc 0.78273[0m
[93maverage test of epoch 38: loss -3.00636 acc 0.32432 roc_auc 0.81333 prc_auc 0.89382[0m
[92maverage training of epoch 39: loss -3.07211 acc 0.33775 roc_auc 0.54588 prc_auc 0.75905[0m
[93maverage test of epoch 39: loss -3.06889 acc 0.32432 roc_auc 0.79667 prc_auc 0.88811[0m
[92maverage training of epoch 40: loss -3.13422 acc 0.33775 roc_auc 0.50882 prc_auc 0.72866[0m
[93maverage test of epoch 40: loss -3.13085 acc 0.32432 roc_auc 0.77500 prc_auc 0.86648[0m
[92maverage training of epoch 41: loss -3.19577 acc 0.33775 roc_auc 0.48176 prc_auc 0.69883[0m
[93maverage test of epoch 41: loss -3.19229 acc 0.32432 roc_auc 0.77333 prc_auc 0.86648[0m
[92maverage training of epoch 42: loss -3.25682 acc 0.33775 roc_auc 0.45020 prc_auc 0.66385[0m
[93maverage test of epoch 42: loss -3.25325 acc 0.32432 roc_auc 0.76167 prc_auc 0.86025[0m
[92maverage training of epoch 43: loss -3.31741 acc 0.33775 roc_auc 0.43108 prc_auc 0.64746[0m
[93maverage test of epoch 43: loss -3.31379 acc 0.32432 roc_auc 0.73833 prc_auc 0.85148[0m
[92maverage training of epoch 44: loss -3.37759 acc 0.33775 roc_auc 0.41608 prc_auc 0.62930[0m
[93maverage test of epoch 44: loss -3.37394 acc 0.32432 roc_auc 0.70667 prc_auc 0.84220[0m
[92maverage training of epoch 45: loss -3.43739 acc 0.33775 roc_auc 0.40373 prc_auc 0.61525[0m
[93maverage test of epoch 45: loss -3.43373 acc 0.32432 roc_auc 0.69000 prc_auc 0.83690[0m
[92maverage training of epoch 46: loss -3.49685 acc 0.33775 roc_auc 0.39392 prc_auc 0.60741[0m
[93maverage test of epoch 46: loss -3.49320 acc 0.32432 roc_auc 0.65667 prc_auc 0.82175[0m
[92maverage training of epoch 47: loss -3.55599 acc 0.33775 roc_auc 0.38922 prc_auc 0.60000[0m
[93maverage test of epoch 47: loss -3.55237 acc 0.32432 roc_auc 0.65167 prc_auc 0.81887[0m
[92maverage training of epoch 48: loss -3.61484 acc 0.33775 roc_auc 0.38412 prc_auc 0.59479[0m
[93maverage test of epoch 48: loss -3.61127 acc 0.32432 roc_auc 0.62000 prc_auc 0.80880[0m
[92maverage training of epoch 49: loss -3.67343 acc 0.33775 roc_auc 0.38098 prc_auc 0.58911[0m
[93maverage test of epoch 49: loss -3.66993 acc 0.32432 roc_auc 0.60667 prc_auc 0.80120[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.01612 acc 0.66225 roc_auc 0.34980 prc_auc 0.57369[0m
[93maverage test of epoch 0: loss -0.11547 acc 0.67568 roc_auc 0.10667 prc_auc 0.55030[0m
[92maverage training of epoch 1: loss -0.14681 acc 0.66225 roc_auc 0.36039 prc_auc 0.58044[0m
[93maverage test of epoch 1: loss -0.26056 acc 0.67568 roc_auc 0.15000 prc_auc 0.53882[0m
[92maverage training of epoch 2: loss -0.30558 acc 0.66225 roc_auc 0.36431 prc_auc 0.58235[0m
[93maverage test of epoch 2: loss -0.43689 acc 0.67568 roc_auc 0.25000 prc_auc 0.58940[0m
[92maverage training of epoch 3: loss -0.49670 acc 0.66225 roc_auc 0.36980 prc_auc 0.59015[0m
[93maverage test of epoch 3: loss -0.64521 acc 0.67568 roc_auc 0.39000 prc_auc 0.68316[0m
[92maverage training of epoch 4: loss -0.71152 acc 0.66225 roc_auc 0.37706 prc_auc 0.59810[0m
[93maverage test of epoch 4: loss -0.86676 acc 0.67568 roc_auc 0.53667 prc_auc 0.77829[0m
[92maverage training of epoch 5: loss -0.92399 acc 0.66225 roc_auc 0.38392 prc_auc 0.60310[0m
[93maverage test of epoch 5: loss -1.07187 acc 0.67568 roc_auc 0.60000 prc_auc 0.82342[0m
[92maverage training of epoch 6: loss -1.11391 acc 0.66225 roc_auc 0.39216 prc_auc 0.60986[0m
[93maverage test of epoch 6: loss -1.24900 acc 0.67568 roc_auc 0.64333 prc_auc 0.84890[0m
[92maverage training of epoch 7: loss -1.27754 acc 0.66225 roc_auc 0.39784 prc_auc 0.61840[0mUsing backend: pytorch
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))

[93maverage test of epoch 7: loss -1.40064 acc 0.67568 roc_auc 0.66000 prc_auc 0.85585[0m
[92maverage training of epoch 8: loss -1.41951 acc 0.66225 roc_auc 0.40353 prc_auc 0.62259[0m
[93maverage test of epoch 8: loss -1.53373 acc 0.67568 roc_auc 0.67333 prc_auc 0.85992[0m
[92maverage training of epoch 9: loss -1.54675 acc 0.66225 roc_auc 0.40980 prc_auc 0.62669[0m
[93maverage test of epoch 9: loss -1.65569 acc 0.67568 roc_auc 0.70000 prc_auc 0.87360[0m
[92maverage training of epoch 10: loss -1.66604 acc 0.66225 roc_auc 0.42275 prc_auc 0.63440[0m
[93maverage test of epoch 10: loss -1.77284 acc 0.67568 roc_auc 0.73333 prc_auc 0.89355[0m
[92maverage training of epoch 11: loss -1.78264 acc 0.66225 roc_auc 0.44431 prc_auc 0.65891[0m
[93maverage test of epoch 11: loss -1.88943 acc 0.67568 roc_auc 0.76000 prc_auc 0.90500[0m
[92maverage training of epoch 12: loss -1.89966 acc 0.66225 roc_auc 0.45539 prc_auc 0.66387[0m
[93maverage test of epoch 12: loss -2.00739 acc 0.67568 roc_auc 0.78000 prc_auc 0.91421[0m
[92maverage training of epoch 13: loss -2.01809 acc 0.66225 roc_auc 0.45843 prc_auc 0.66913[0m
[93maverage test of epoch 13: loss -2.12691 acc 0.67568 roc_auc 0.82000 prc_auc 0.92565[0m
[92maverage training of epoch 14: loss -2.13753 acc 0.66225 roc_auc 0.45833 prc_auc 0.66875[0m
[93maverage test of epoch 14: loss -2.24699 acc 0.67568 roc_auc 0.84000 prc_auc 0.93466[0m
[92maverage training of epoch 15: loss -2.25671 acc 0.66225 roc_auc 0.45775 prc_auc 0.66781[0m
[93maverage test of epoch 15: loss -2.36611 acc 0.67568 roc_auc 0.84333 prc_auc 0.93616[0m
[92maverage training of epoch 16: loss -2.37406 acc 0.66225 roc_auc 0.45608 prc_auc 0.66586[0m
[93maverage test of epoch 16: loss -2.48265 acc 0.67568 roc_auc 0.84500 prc_auc 0.93616[0m
[92maverage training of epoch 17: loss -2.48809 acc 0.66225 roc_auc 0.45265 prc_auc 0.66457[0m
[93maverage test of epoch 17: loss -2.59526 acc 0.67568 roc_auc 0.85667 prc_auc 0.94176[0m
[92maverage training of epoch 18: loss -2.59772 acc 0.66225 roc_auc 0.44980 prc_auc 0.66076[0m
[93maverage test of epoch 18: loss -2.70310 acc 0.67568 roc_auc 0.86833 prc_auc 0.94625[0m
[92maverage training of epoch 19: loss -2.70237 acc 0.66225 roc_auc 0.44765 prc_auc 0.65757[0m
[93maverage test of epoch 19: loss -2.80584 acc 0.67568 roc_auc 0.90167 prc_auc 0.95947[0m
[92maverage training of epoch 20: loss -2.80194 acc 0.66225 roc_auc 0.44559 prc_auc 0.65575[0m
[93maverage test of epoch 20: loss -2.90356 acc 0.67568 roc_auc 0.91167 prc_auc 0.96155[0m
[92maverage training of epoch 21: loss -2.89665 acc 0.66225 roc_auc 0.44157 prc_auc 0.65248[0m
[93maverage test of epoch 21: loss -2.99663 acc 0.67568 roc_auc 0.92833 prc_auc 0.96923[0m
[92maverage training of epoch 22: loss -2.98695 acc 0.66225 roc_auc 0.43373 prc_auc 0.64587[0m
[93maverage test of epoch 22: loss -3.08555 acc 0.67568 roc_auc 0.92333 prc_auc 0.96609[0m
[92maverage training of epoch 23: loss -3.07336 acc 0.66225 roc_auc 0.42922 prc_auc 0.64235[0m
[93maverage test of epoch 23: loss -3.17085 acc 0.67568 roc_auc 0.91500 prc_auc 0.96114[0m
[92maverage training of epoch 24: loss -3.15640 acc 0.66225 roc_auc 0.42382 prc_auc 0.63852[0m
[93maverage test of epoch 24: loss -3.25302 acc 0.67568 roc_auc 0.91667 prc_auc 0.96267[0m
[92maverage training of epoch 25: loss -3.23653 acc 0.66225 roc_auc 0.41853 prc_auc 0.63405[0m
[93maverage test of epoch 25: loss -3.33250 acc 0.67568 roc_auc 0.91167 prc_auc 0.95958[0m
[92maverage training of epoch 26: loss -3.31417 acc 0.66225 roc_auc 0.41539 prc_auc 0.63168[0m
[93maverage test of epoch 26: loss -3.40964 acc 0.67568 roc_auc 0.91333 prc_auc 0.95875[0m
[92maverage training of epoch 27: loss -3.38964 acc 0.66225 roc_auc 0.41294 prc_auc 0.62910[0m
[93maverage test of epoch 27: loss -3.48476 acc 0.67568 roc_auc 0.90333 prc_auc 0.95441[0m
[92maverage training of epoch 28: loss -3.46324 acc 0.66225 roc_auc 0.41029 prc_auc 0.62685[0m
[93maverage test of epoch 28: loss -3.55811 acc 0.67568 roc_auc 0.90667 prc_auc 0.95353[0m
[92maverage training of epoch 29: loss -3.53518 acc 0.66225 roc_auc 0.40804 prc_auc 0.62335[0m
[93maverage test of epoch 29: loss -3.62990 acc 0.67568 roc_auc 0.90833 prc_auc 0.95231[0m
[92maverage training of epoch 30: loss -3.60567 acc 0.66225 roc_auc 0.40539 prc_auc 0.62063[0m
[93maverage test of epoch 30: loss -3.70030 acc 0.67568 roc_auc 0.91000 prc_auc 0.95201[0m
[92maverage training of epoch 31: loss -3.67487 acc 0.66225 roc_auc 0.40216 prc_auc 0.61822[0m
[93maverage test of epoch 31: loss -3.76946 acc 0.67568 roc_auc 0.91167 prc_auc 0.95375[0m
[92maverage training of epoch 32: loss -3.74291 acc 0.66225 roc_auc 0.39931 prc_auc 0.61570[0m
[93maverage test of epoch 32: loss -3.83751 acc 0.67568 roc_auc 0.90667 prc_auc 0.94925[0m
[92maverage training of epoch 33: loss -3.80992 acc 0.66225 roc_auc 0.39627 prc_auc 0.61316[0m
[93maverage test of epoch 33: loss -3.90457 acc 0.67568 roc_auc 0.87500 prc_auc 0.93278[0m
[92maverage training of epoch 34: loss -3.87600 acc 0.66225 roc_auc 0.39461 prc_auc 0.61017[0m
[93maverage test of epoch 34: loss -3.97073 acc 0.67568 roc_auc 0.88667 prc_auc 0.93478[0m
[92maverage training of epoch 35: loss -3.94124 acc 0.66225 roc_auc 0.39196 prc_auc 0.60794[0m
[93maverage test of epoch 35: loss -4.03606 acc 0.67568 roc_auc 0.88833 prc_auc 0.92963[0m
[92maverage training of epoch 36: loss -4.00572 acc 0.66225 roc_auc 0.38980 prc_auc 0.60629[0m
[93maverage test of epoch 36: loss -4.10066 acc 0.67568 roc_auc 0.88333 prc_auc 0.92418[0m
[92maverage training of epoch 37: loss -4.06949 acc 0.66225 roc_auc 0.38765 prc_auc 0.60442[0m
[93maverage test of epoch 37: loss -4.16457 acc 0.67568 roc_auc 0.86000 prc_auc 0.91223[0m
[92maverage training of epoch 38: loss -4.13263 acc 0.66225 roc_auc 0.38657 prc_auc 0.60366[0m
[93maverage test of epoch 38: loss -4.22785 acc 0.67568 roc_auc 0.86667 prc_auc 0.91001[0m
[92maverage training of epoch 39: loss -4.19518 acc 0.66225 roc_auc 0.38559 prc_auc 0.60312[0m
[93maverage test of epoch 39: loss -4.29057 acc 0.67568 roc_auc 0.88000 prc_auc 0.91552[0m
[92maverage training of epoch 40: loss -4.25720 acc 0.66225 roc_auc 0.38451 prc_auc 0.60152[0m
[93maverage test of epoch 40: loss -4.35276 acc 0.67568 roc_auc 0.82333 prc_auc 0.88642[0m
[92maverage training of epoch 41: loss -4.31873 acc 0.66225 roc_auc 0.38471 prc_auc 0.60234[0m
[93maverage test of epoch 41: loss -4.41447 acc 0.67568 roc_auc 0.84333 prc_auc 0.89303[0m
[92maverage training of epoch 42: loss -4.37981 acc 0.66225 roc_auc 0.38422 prc_auc 0.60137[0m
[93maverage test of epoch 42: loss -4.47573 acc 0.67568 roc_auc 0.78667 prc_auc 0.86651[0m
[92maverage training of epoch 43: loss -4.44046 acc 0.66225 roc_auc 0.38353 prc_auc 0.60156[0m
[93maverage test of epoch 43: loss -4.53658 acc 0.67568 roc_auc 0.84000 prc_auc 0.88364[0m
[92maverage training of epoch 44: loss -4.50073 acc 0.66225 roc_auc 0.38324 prc_auc 0.60123[0m
[93maverage test of epoch 44: loss -4.59704 acc 0.67568 roc_auc 0.70000 prc_auc 0.81124[0m
[92maverage training of epoch 45: loss -4.56065 acc 0.66225 roc_auc 0.38382 prc_auc 0.60168[0m
[93maverage test of epoch 45: loss -4.65716 acc 0.67568 roc_auc 0.78000 prc_auc 0.85333[0m
[92maverage training of epoch 46: loss -4.62023 acc 0.66225 roc_auc 0.38304 prc_auc 0.59996[0m
[93maverage test of epoch 46: loss -4.71695 acc 0.67568 roc_auc 0.73333 prc_auc 0.81514[0m
[92maverage training of epoch 47: loss -4.67951 acc 0.66225 roc_auc 0.38235 prc_auc 0.59646[0m
[93maverage test of epoch 47: loss -4.77643 acc 0.67568 roc_auc 0.72000 prc_auc 0.80439[0m
[92maverage training of epoch 48: loss -4.73851 acc 0.66225 roc_auc 0.38167 prc_auc 0.59466[0m
[93maverage test of epoch 48: loss -4.83564 acc 0.67568 roc_auc 0.74000 prc_auc 0.83135[0m
[92maverage training of epoch 49: loss -4.79724 acc 0.66225 roc_auc 0.38098 prc_auc 0.59317[0m
[93maverage test of epoch 49: loss -4.89459 acc 0.67568 roc_auc 0.62000 prc_auc 0.73708[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.0001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.53158 ROC_AUC (avg): 0.60964 PRC_AUC (avg): 0.79104 

Average forward propagation time taken(ms): 2.4676887076900687
Average backward propagation time taken(ms): 0.8739339008616493

