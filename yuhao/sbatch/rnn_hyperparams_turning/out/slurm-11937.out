# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-23-48-50/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-23-48-50/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 8,
 'epochs': 100,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 4,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.001,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 1,
 'num_workers': 8,
 'number_of_mlp_layer': 0,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-17-23-48-50',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 100, 'learning_rate': 0.001, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -0.48516 acc 0.34000 roc_auc 0.43960 prc_auc 0.66327[0m
[93maverage test of epoch 0: loss -1.06520 acc 0.39474 roc_auc 0.85846 prc_auc 0.93214[0m
[92maverage training of epoch 1: loss -1.52699 acc 0.57333 roc_auc 0.51780 prc_auc 0.73812[0m
[93maverage test of epoch 1: loss -2.00794 acc 0.65789 roc_auc 0.86462 prc_auc 0.93401[0m
[92maverage training of epoch 2: loss -2.44974 acc 0.66667 roc_auc 0.52320 prc_auc 0.71548[0m
[93maverage test of epoch 2: loss -2.90928 acc 0.65789 roc_auc 0.86462 prc_auc 0.93401[0m
[92maverage training of epoch 3: loss -3.38212 acc 0.66667 roc_auc 0.47340 prc_auc 0.66894[0m
[93maverage test of epoch 3: loss -3.80363 acc 0.65789 roc_auc 0.86462 prc_auc 0.93435[0m
[92maverage training of epoch 4: loss -4.20315 acc 0.66667 roc_auc 0.41960 prc_auc 0.62761[0m
[93maverage test of epoch 4: loss -4.55213 acc 0.65789 roc_auc 0.86462 prc_auc 0.93401[0m
[92maverage training of epoch 5: loss -4.91378 acc 0.66667 roc_auc 0.39840 prc_auc 0.61771[0m
[93maverage test of epoch 5: loss -5.22825 acc 0.65789 roc_auc 0.86462 prc_auc 0.93401[0m
[92maverage training of epoch 6: loss -5.57145 acc 0.66667 roc_auc 0.38660 prc_auc 0.60615[0m
[93maverage test of epoch 6: loss -5.86682 acc 0.65789 roc_auc 0.86462 prc_auc 0.93401[0m
[92maverage training of epoch 7: loss -6.19974 acc 0.66667 roc_auc 0.37680 prc_auc 0.59532[0m
[93maverage test of epoch 7: loss -6.48279 acc 0.65789 roc_auc 0.86462 prc_auc 0.93440[0m
[92maverage training of epoch 8: loss -6.80951 acc 0.66667 roc_auc 0.37260 prc_auc 0.59227[0m
[93maverage test of epoch 8: loss -7.08378 acc 0.65789 roc_auc 0.86462 prc_auc 0.93483[0m
[92maverage training of epoch 9: loss -7.40666 acc 0.66667 roc_auc 0.37000 prc_auc 0.59022[0m
[93maverage test of epoch 9: loss -7.67423 acc 0.65789 roc_auc 0.86769 prc_auc 0.93518[0m
[92maverage training of epoch 10: loss -7.99472 acc 0.66667 roc_auc 0.36520 prc_auc 0.56984[0m
[93maverage test of epoch 10: loss -8.25691 acc 0.65789 roc_auc 0.86615 prc_auc 0.93259[0m
[92maverage training of epoch 11: loss -8.57599 acc 0.66667 roc_auc 0.36190 prc_auc 0.56552[0m
[93maverage test of epoch 11: loss -8.83370 acc 0.65789 roc_auc 0.85077 prc_auc 0.90545[0m
[92maverage training of epoch 12: loss -9.15203 acc 0.66667 roc_auc 0.35980 prc_auc 0.56379[0m
[93maverage test of epoch 12: loss -9.40590 acc 0.65789 roc_auc 0.85077 prc_auc 0.90729[0m
[92maverage training of epoch 13: loss -9.72399 acc 0.66667 roc_auc 0.35920 prc_auc 0.56333[0m
[93maverage test of epoch 13: loss -9.97447 acc 0.65789 roc_auc 0.85385 prc_auc 0.91137[0m
[92maverage training of epoch 14: loss -10.29267 acc 0.66667 roc_auc 0.35860 prc_auc 0.56280[0m
[93maverage test of epoch 14: loss -10.54013 acc 0.65789 roc_auc 0.88000 prc_auc 0.93330[0m
[92maverage training of epoch 15: loss -10.85871 acc 0.66667 roc_auc 0.35850 prc_auc 0.56274[0m
[93maverage test of epoch 15: loss -11.10340 acc 0.65789 roc_auc 0.88154 prc_auc 0.91315[0m
[92maverage training of epoch 16: loss -11.42258 acc 0.66667 roc_auc 0.35810 prc_auc 0.56325[0m
[93maverage test of epoch 16: loss -11.66473 acc 0.65789 roc_auc 0.79077 prc_auc 0.82325[0m
[92maverage training of epoch 17: loss -11.98468 acc 0.66667 roc_auc 0.35790 prc_auc 0.56247[0m
[93maverage test of epoch 17: loss -12.22444 acc 0.65789 roc_auc 0.61231 prc_auc 0.71354[0m
[92maverage training of epoch 18: loss -12.54529 acc 0.66667 roc_auc 0.35760 prc_auc 0.56222[0m
[93maverage test of epoch 18: loss -12.78280 acc 0.65789 roc_auc 0.80462 prc_auc 0.84026[0m
[92maverage training of epoch 19: loss -13.10467 acc 0.66667 roc_auc 0.35750 prc_auc 0.56236[0m
[93maverage test of epoch 19: loss -13.34004 acc 0.65789 roc_auc 0.80462 prc_auc 0.84026[0m
[92maverage training of epoch 20: loss -13.66301 acc 0.66667 roc_auc 0.35730 prc_auc 0.56219[0m
[93maverage test of epoch 20: loss -13.89632 acc 0.65789 roc_auc 0.65385 prc_auc 0.73529[0m
[92maverage training of epoch 21: loss -14.22047 acc 0.66667 roc_auc 0.35700 prc_auc 0.56205[0m
[93maverage test of epoch 21: loss -14.45180 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -14.77719 acc 0.66667 roc_auc 0.35720 prc_auc 0.56197[0m
[93maverage test of epoch 22: loss -15.00661 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -15.33328 acc 0.66667 roc_auc 0.35720 prc_auc 0.56188[0m
[93maverage test of epoch 23: loss -15.56083 acc 0.65789 roc_auc 0.65385 prc_auc 0.73529[0m
[92maverage training of epoch 24: loss -15.88884 acc 0.66667 roc_auc 0.35700 prc_auc 0.56168[0m
[93maverage test of epoch 24: loss -16.11456 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -16.44394 acc 0.66667 roc_auc 0.35720 prc_auc 0.56172[0m
[93maverage test of epoch 25: loss -16.66788 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -16.99865 acc 0.66667 roc_auc 0.35720 prc_auc 0.56166[0m
[93maverage test of epoch 26: loss -17.22083 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -17.55302 acc 0.66667 roc_auc 0.35720 prc_auc 0.56162[0m
[93maverage test of epoch 27: loss -17.77347 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -18.10710 acc 0.66667 roc_auc 0.35720 prc_auc 0.56164[0m
[93maverage test of epoch 28: loss -18.32584 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -18.66094 acc 0.66667 roc_auc 0.35710 prc_auc 0.56192[0m
[93maverage test of epoch 29: loss -18.87800 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -19.21457 acc 0.66667 roc_auc 0.35740 prc_auc 0.56213[0m
[93maverage test of epoch 30: loss -19.42995 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -19.76802 acc 0.66667 roc_auc 0.35730 prc_auc 0.56311[0m
[93maverage test of epoch 31: loss -19.98174 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -20.32131 acc 0.66667 roc_auc 0.35770 prc_auc 0.56250[0m
[93maverage test of epoch 32: loss -20.53338 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -20.87447 acc 0.66667 roc_auc 0.35810 prc_auc 0.56292[0m
[93maverage test of epoch 33: loss -21.08490 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -21.42750 acc 0.66667 roc_auc 0.35820 prc_auc 0.56374[0m
[93maverage test of epoch 34: loss -21.63630 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -21.98044 acc 0.66667 roc_auc 0.35730 prc_auc 0.56244[0m
[93maverage test of epoch 35: loss -22.18762 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -22.53328 acc 0.66667 roc_auc 0.35790 prc_auc 0.56323[0m
[93maverage test of epoch 36: loss -22.73885 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -23.08605 acc 0.66667 roc_auc 0.35840 prc_auc 0.56478[0m
[93maverage test of epoch 37: loss -23.29000 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -23.63876 acc 0.66667 roc_auc 0.35750 prc_auc 0.56429[0m
[93maverage test of epoch 38: loss -23.84110 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -24.19141 acc 0.66667 roc_auc 0.35820 prc_auc 0.56390[0m
[93maverage test of epoch 39: loss -24.39215 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -24.74400 acc 0.66667 roc_auc 0.35910 prc_auc 0.56472[0m
[93maverage test of epoch 40: loss -24.94314 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -25.29655 acc 0.66667 roc_auc 0.36060 prc_auc 0.56588[0m
[93maverage test of epoch 41: loss -25.49410 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -25.84907 acc 0.66667 roc_auc 0.35880 prc_auc 0.56669[0m
[93maverage test of epoch 42: loss -26.04503 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -26.40156 acc 0.66667 roc_auc 0.35770 prc_auc 0.56595[0m
[93maverage test of epoch 43: loss -26.59592 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -26.95401 acc 0.66667 roc_auc 0.35900 prc_auc 0.56872[0m
[93maverage test of epoch 44: loss -27.14678 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -27.50643 acc 0.66667 roc_auc 0.35940 prc_auc 0.56759[0m
[93maverage test of epoch 45: loss -27.69762 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -28.05884 acc 0.66667 roc_auc 0.35890 prc_auc 0.57252[0m
[93maverage test of epoch 46: loss -28.24844 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -28.61122 acc 0.66667 roc_auc 0.36190 prc_auc 0.57058[0m
[93maverage test of epoch 47: loss -28.79924 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -29.16359 acc 0.66667 roc_auc 0.35770 prc_auc 0.56955[0m
[93maverage test of epoch 48: loss -29.35002 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -29.71594 acc 0.66667 roc_auc 0.36330 prc_auc 0.57566[0m
[93maverage test of epoch 49: loss -29.90079 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 50: loss -30.26828 acc 0.66667 roc_auc 0.35850 prc_auc 0.57360[0m
[93maverage test of epoch 50: loss -30.45155 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 51: loss -30.82061 acc 0.66667 roc_auc 0.36380 prc_auc 0.57973[0m
[93maverage test of epoch 51: loss -31.00230 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 52: loss -31.37294 acc 0.66667 roc_auc 0.36730 prc_auc 0.58233[0m
[93maverage test of epoch 52: loss -31.55304 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 53: loss -31.92525 acc 0.66667 roc_auc 0.36250 prc_auc 0.58259[0m
[93maverage test of epoch 53: loss -32.10378 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 54: loss -32.47755 acc 0.66667 roc_auc 0.36830 prc_auc 0.58978[0m
[93maverage test of epoch 54: loss -32.65450 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 55: loss -33.02984 acc 0.66667 roc_auc 0.36750 prc_auc 0.58973[0m
[93maverage test of epoch 55: loss -33.20521 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 56: loss -33.58213 acc 0.66667 roc_auc 0.35890 prc_auc 0.58995[0m
[93maverage test of epoch 56: loss -33.75592 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 57: loss -34.13441 acc 0.66667 roc_auc 0.37070 prc_auc 0.59565[0m
[93maverage test of epoch 57: loss -34.30662 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 58: loss -34.68669 acc 0.66667 roc_auc 0.40040 prc_auc 0.61538[0m
[93maverage test of epoch 58: loss -34.85732 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 59: loss -35.23895 acc 0.66667 roc_auc 0.37730 prc_auc 0.60603[0m
[93maverage test of epoch 59: loss -35.40801 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 60: loss -35.79122 acc 0.66667 roc_auc 0.39250 prc_auc 0.61186[0m
[93maverage test of epoch 60: loss -35.95870 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 61: loss -36.34348 acc 0.66667 roc_auc 0.42220 prc_auc 0.63010[0m
[93maverage test of epoch 61: loss -36.50938 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 62: loss -36.89574 acc 0.66667 roc_auc 0.41750 prc_auc 0.62668[0m
[93maverage test of epoch 62: loss -37.06007 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 63: loss -37.44800 acc 0.66667 roc_auc 0.42480 prc_auc 0.63285[0m
[93maverage test of epoch 63: loss -37.61075 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 64: loss -38.00026 acc 0.66667 roc_auc 0.42770 prc_auc 0.63386[0m
[93maverage test of epoch 64: loss -38.16142 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 65: loss -38.55250 acc 0.66667 roc_auc 0.43540 prc_auc 0.63751[0m
[93maverage test of epoch 65: loss -38.71209 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 66: loss -39.10475 acc 0.66667 roc_auc 0.43000 prc_auc 0.63755[0m
[93maverage test of epoch 66: loss -39.26277 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 67: loss -39.65700 acc 0.66667 roc_auc 0.44000 prc_auc 0.64127[0m
[93maverage test of epoch 67: loss -39.81343 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 68: loss -40.20924 acc 0.66667 roc_auc 0.45500 prc_auc 0.64736[0m
[93maverage test of epoch 68: loss -40.36410 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 69: loss -40.76148 acc 0.66667 roc_auc 0.46000 prc_auc 0.64946[0m
[93maverage test of epoch 69: loss -40.91476 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 70: loss -41.31372 acc 0.66667 roc_auc 0.44500 prc_auc 0.64375[0m
[93maverage test of epoch 70: loss -41.46542 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 71: loss -41.86595 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 71: loss -42.01608 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 72: loss -42.41818 acc 0.66667 roc_auc 0.43000 prc_auc 0.63767[0m
[93maverage test of epoch 72: loss -42.56673 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 73: loss -42.97041 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 73: loss -43.11738 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 74: loss -43.52264 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 74: loss -43.66803 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 75: loss -44.07486 acc 0.66667 roc_auc 0.44000 prc_auc 0.64144[0m
[93maverage test of epoch 75: loss -44.21868 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 76: loss -44.62708 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 76: loss -44.76932 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 77: loss -45.17930 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 77: loss -45.31997 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 78: loss -45.73152 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 78: loss -45.87061 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 79: loss -46.28374 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 79: loss -46.42125 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 80: loss -46.83595 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 80: loss -46.97188 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 81: loss -47.38817 acc 0.66667 roc_auc 0.42500 prc_auc 0.63571[0m
[93maverage test of epoch 81: loss -47.52252 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 82: loss -47.94038 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 82: loss -48.07315 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 83: loss -48.49258 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 83: loss -48.62378 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 84: loss -49.04479 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 84: loss -49.17441 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 85: loss -49.59699 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 85: loss -49.72503 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 86: loss -50.14919 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 86: loss -50.27566 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 87: loss -50.70139 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 87: loss -50.82628 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 88: loss -51.25359 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 88: loss -51.37690 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 89: loss -51.80578 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 89: loss -51.92752 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -52.35798 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 90: loss -52.47813 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 91: loss -52.91017 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 91: loss -53.02874 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 92: loss -53.46235 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 92: loss -53.57935 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 93: loss -54.01454 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 93: loss -54.12996 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 94: loss -54.56672 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 94: loss -54.68057 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 95: loss -55.11890 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 95: loss -55.23117 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 96: loss -55.67108 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 96: loss -55.78177 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 97: loss -56.22326 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 97: loss -56.33237 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 98: loss -56.77543 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 98: loss -56.88297 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -57.32761 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 99: loss -57.43356 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -0.07824 acc 0.33333 roc_auc 0.52760 prc_auc 0.67237[0m
[93maverage test of epoch 0: loss -0.68015 acc 0.34211 roc_auc 0.12000 prc_auc 0.48608[0m
[92maverage training of epoch 1: loss -1.51303 acc 0.33333 roc_auc 0.46300 prc_auc 0.63589[0m
[93maverage test of epoch 1: loss -2.19935 acc 0.34211 roc_auc 0.11385 prc_auc 0.48417[0m
[92maverage training of epoch 2: loss -2.60504 acc 0.33333 roc_auc 0.35640 prc_auc 0.57409[0m
[93maverage test of epoch 2: loss -3.03373 acc 0.34211 roc_auc 0.11385 prc_auc 0.48417[0m
[92maverage training of epoch 3: loss -3.33888 acc 0.33333 roc_auc 0.40020 prc_auc 0.58672[0m
[93maverage test of epoch 3: loss -3.68987 acc 0.34211 roc_auc 0.13231 prc_auc 0.48998[0m
[92maverage training of epoch 4: loss -3.95100 acc 0.33333 roc_auc 0.41220 prc_auc 0.59278[0m
[93maverage test of epoch 4: loss -4.26275 acc 0.34211 roc_auc 0.20615 prc_auc 0.56410[0m
[92maverage training of epoch 5: loss -4.50467 acc 0.33333 roc_auc 0.42460 prc_auc 0.61722[0m
[93maverage test of epoch 5: loss -4.79874 acc 0.34211 roc_auc 0.27231 prc_auc 0.60465[0m
[92maverage training of epoch 6: loss -5.04680 acc 0.33333 roc_auc 0.44440 prc_auc 0.63630[0m
[93maverage test of epoch 6: loss -5.37095 acc 0.34211 roc_auc 0.40769 prc_auc 0.70733[0m
[92maverage training of epoch 7: loss -5.79170 acc 0.33333 roc_auc 0.49040 prc_auc 0.68177[0m
[93maverage test of epoch 7: loss -6.28586 acc 0.34211 roc_auc 0.88923 prc_auc 0.93807[0m
[92maverage training of epoch 8: loss -6.64488 acc 0.33333 roc_auc 0.45520 prc_auc 0.63331[0m
[93maverage test of epoch 8: loss -7.01193 acc 0.34211 roc_auc 0.88923 prc_auc 0.93807[0m
[92maverage training of epoch 9: loss -7.33478 acc 0.33333 roc_auc 0.43360 prc_auc 0.61966[0m
[93maverage test of epoch 9: loss -7.66888 acc 0.34211 roc_auc 0.88615 prc_auc 0.93236[0m
[92maverage training of epoch 10: loss -7.97688 acc 0.33333 roc_auc 0.42600 prc_auc 0.61150[0m
[93maverage test of epoch 10: loss -8.29418 acc 0.34211 roc_auc 0.86308 prc_auc 0.90090[0m
[92maverage training of epoch 11: loss -8.59434 acc 0.58667 roc_auc 0.42380 prc_auc 0.61152[0m
[93maverage test of epoch 11: loss -8.90088 acc 0.65789 roc_auc 0.88000 prc_auc 0.92352[0m
[92maverage training of epoch 12: loss -9.19645 acc 0.66667 roc_auc 0.42300 prc_auc 0.61000[0m
[93maverage test of epoch 12: loss -9.49523 acc 0.65789 roc_auc 0.85231 prc_auc 0.87498[0m
[92maverage training of epoch 13: loss -9.78804 acc 0.66667 roc_auc 0.42160 prc_auc 0.60653[0m
[93maverage test of epoch 13: loss -10.08079 acc 0.65789 roc_auc 0.79385 prc_auc 0.84843[0m
[92maverage training of epoch 14: loss -10.37196 acc 0.66667 roc_auc 0.42100 prc_auc 0.60548[0m
[93maverage test of epoch 14: loss -10.65980 acc 0.65789 roc_auc 0.82769 prc_auc 0.85556[0m
[92maverage training of epoch 15: loss -10.95008 acc 0.66667 roc_auc 0.42080 prc_auc 0.60544[0m
[93maverage test of epoch 15: loss -11.23377 acc 0.65789 roc_auc 0.82462 prc_auc 0.85500[0m
[92maverage training of epoch 16: loss -11.52369 acc 0.66667 roc_auc 0.42080 prc_auc 0.60544[0m
[93maverage test of epoch 16: loss -11.80377 acc 0.65789 roc_auc 0.78769 prc_auc 0.83074[0m
[92maverage training of epoch 17: loss -12.09373 acc 0.66667 roc_auc 0.42040 prc_auc 0.60492[0m
[93maverage test of epoch 17: loss -12.37060 acc 0.65789 roc_auc 0.82462 prc_auc 0.84889[0m
[92maverage training of epoch 18: loss -12.66088 acc 0.66667 roc_auc 0.42020 prc_auc 0.60463[0m
[93maverage test of epoch 18: loss -12.93484 acc 0.65789 roc_auc 0.82000 prc_auc 0.84667[0m
[92maverage training of epoch 19: loss -13.22569 acc 0.66667 roc_auc 0.42020 prc_auc 0.60463[0m
[93maverage test of epoch 19: loss -13.49698 acc 0.65789 roc_auc 0.85538 prc_auc 0.87275[0m
[92maverage training of epoch 20: loss -13.78856 acc 0.66667 roc_auc 0.42000 prc_auc 0.60455[0m
[93maverage test of epoch 20: loss -14.05738 acc 0.65789 roc_auc 0.86154 prc_auc 0.88000[0m
[92maverage training of epoch 21: loss -14.34983 acc 0.66667 roc_auc 0.42020 prc_auc 0.60463[0m
[93maverage test of epoch 21: loss -14.61631 acc 0.65789 roc_auc 0.81538 prc_auc 0.84978[0m
[92maverage training of epoch 22: loss -14.90976 acc 0.66667 roc_auc 0.42010 prc_auc 0.60455[0m
[93maverage test of epoch 22: loss -15.17403 acc 0.65789 roc_auc 0.78462 prc_auc 0.83067[0m
[92maverage training of epoch 23: loss -15.46856 acc 0.66667 roc_auc 0.42010 prc_auc 0.60455[0m
[93maverage test of epoch 23: loss -15.73073 acc 0.65789 roc_auc 0.80000 prc_auc 0.83185[0m
[92maverage training of epoch 24: loss -16.02642 acc 0.66667 roc_auc 0.42020 prc_auc 0.60463[0m
[93maverage test of epoch 24: loss -16.28656 acc 0.65789 roc_auc 0.61077 prc_auc 0.71889[0m
[92maverage training of epoch 25: loss -16.58348 acc 0.66667 roc_auc 0.42010 prc_auc 0.60455[0m
[93maverage test of epoch 25: loss -16.84166 acc 0.65789 roc_auc 0.84000 prc_auc 0.86007[0m
[92maverage training of epoch 26: loss -17.13985 acc 0.66667 roc_auc 0.42010 prc_auc 0.60455[0m
[93maverage test of epoch 26: loss -17.39614 acc 0.65789 roc_auc 0.78000 prc_auc 0.82263[0m
[92maverage training of epoch 27: loss -17.69565 acc 0.66667 roc_auc 0.42010 prc_auc 0.60455[0m
[93maverage test of epoch 27: loss -17.95009 acc 0.65789 roc_auc 0.46923 prc_auc 0.68526[0m
[92maverage training of epoch 28: loss -18.25096 acc 0.66667 roc_auc 0.42000 prc_auc 0.60455[0m
[93maverage test of epoch 28: loss -18.50359 acc 0.65789 roc_auc 0.71538 prc_auc 0.78441[0m
[92maverage training of epoch 29: loss -18.80585 acc 0.66667 roc_auc 0.42000 prc_auc 0.60455[0m
[93maverage test of epoch 29: loss -19.05670 acc 0.65789 roc_auc 0.71231 prc_auc 0.77663[0m
[92maverage training of epoch 30: loss -19.36038 acc 0.66667 roc_auc 0.42020 prc_auc 0.60463[0m
[93maverage test of epoch 30: loss -19.60948 acc 0.65789 roc_auc 0.64615 prc_auc 0.73714[0m
[92maverage training of epoch 31: loss -19.91460 acc 0.66667 roc_auc 0.42010 prc_auc 0.60455[0m
[93maverage test of epoch 31: loss -20.16197 acc 0.65789 roc_auc 0.57077 prc_auc 0.70087[0m
[92maverage training of epoch 32: loss -20.46855 acc 0.66667 roc_auc 0.42010 prc_auc 0.60455[0m
[93maverage test of epoch 32: loss -20.71423 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 33: loss -21.02229 acc 0.66667 roc_auc 0.42010 prc_auc 0.60455[0m
[93maverage test of epoch 33: loss -21.26627 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 34: loss -21.57583 acc 0.66667 roc_auc 0.42010 prc_auc 0.60455[0m
[93maverage test of epoch 34: loss -21.81814 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 35: loss -22.12919 acc 0.66667 roc_auc 0.42010 prc_auc 0.60455[0m
[93maverage test of epoch 35: loss -22.36985 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 36: loss -22.68242 acc 0.66667 roc_auc 0.42010 prc_auc 0.60455[0m
[93maverage test of epoch 36: loss -22.92143 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 37: loss -23.23551 acc 0.66667 roc_auc 0.42010 prc_auc 0.60455[0m
[93maverage test of epoch 37: loss -23.47289 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 38: loss -23.78850 acc 0.66667 roc_auc 0.42020 prc_auc 0.60458[0m
[93maverage test of epoch 38: loss -24.02425 acc 0.65789 roc_auc 0.64615 prc_auc 0.73714[0m
[92maverage training of epoch 39: loss -24.34140 acc 0.66667 roc_auc 0.42020 prc_auc 0.60455[0m
[93maverage test of epoch 39: loss -24.57553 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 40: loss -24.89422 acc 0.66667 roc_auc 0.42020 prc_auc 0.60455[0m
[93maverage test of epoch 40: loss -25.12674 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 41: loss -25.44697 acc 0.66667 roc_auc 0.42030 prc_auc 0.60455[0m
[93maverage test of epoch 41: loss -25.67788 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 42: loss -25.99966 acc 0.66667 roc_auc 0.42020 prc_auc 0.60455[0m
[93maverage test of epoch 42: loss -26.22896 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 43: loss -26.55229 acc 0.66667 roc_auc 0.42030 prc_auc 0.60500[0m
[93maverage test of epoch 43: loss -26.77998 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 44: loss -27.10487 acc 0.66667 roc_auc 0.42030 prc_auc 0.60455[0m
[93maverage test of epoch 44: loss -27.33097 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 45: loss -27.65742 acc 0.66667 roc_auc 0.42030 prc_auc 0.60461[0m
[93maverage test of epoch 45: loss -27.88192 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 46: loss -28.20993 acc 0.66667 roc_auc 0.42020 prc_auc 0.60500[0m
[93maverage test of epoch 46: loss -28.43284 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 47: loss -28.76242 acc 0.66667 roc_auc 0.42010 prc_auc 0.60477[0m
[93maverage test of epoch 47: loss -28.98374 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 48: loss -29.31487 acc 0.66667 roc_auc 0.42020 prc_auc 0.60453[0m
[93maverage test of epoch 48: loss -29.53461 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -29.86731 acc 0.66667 roc_auc 0.42040 prc_auc 0.60486[0m
[93maverage test of epoch 49: loss -30.08546 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 50: loss -30.41973 acc 0.66667 roc_auc 0.42070 prc_auc 0.60512[0m
[93maverage test of epoch 50: loss -30.63630 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 51: loss -30.97213 acc 0.66667 roc_auc 0.42060 prc_auc 0.60492[0m
[93maverage test of epoch 51: loss -31.18711 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 52: loss -31.52452 acc 0.66667 roc_auc 0.42090 prc_auc 0.60498[0m
[93maverage test of epoch 52: loss -31.73792 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 53: loss -32.07689 acc 0.66667 roc_auc 0.42060 prc_auc 0.60530[0m
[93maverage test of epoch 53: loss -32.28870 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 54: loss -32.62925 acc 0.66667 roc_auc 0.42070 prc_auc 0.60568[0m
[93maverage test of epoch 54: loss -32.83948 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 55: loss -33.18160 acc 0.66667 roc_auc 0.42070 prc_auc 0.60462[0m
[93maverage test of epoch 55: loss -33.39025 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 56: loss -33.73393 acc 0.66667 roc_auc 0.42070 prc_auc 0.60558[0m
[93maverage test of epoch 56: loss -33.94100 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 57: loss -34.28626 acc 0.66667 roc_auc 0.42110 prc_auc 0.60567[0m
[93maverage test of epoch 57: loss -34.49175 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 58: loss -34.83858 acc 0.66667 roc_auc 0.42130 prc_auc 0.60388[0m
[93maverage test of epoch 58: loss -35.04248 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 59: loss -35.39089 acc 0.66667 roc_auc 0.42080 prc_auc 0.60240[0m
[93maverage test of epoch 59: loss -35.59322 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 60: loss -35.94319 acc 0.66667 roc_auc 0.42050 prc_auc 0.60425[0m
[93maverage test of epoch 60: loss -36.14394 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 61: loss -36.49548 acc 0.66667 roc_auc 0.41930 prc_auc 0.60234[0m
[93maverage test of epoch 61: loss -36.69465 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 62: loss -37.04777 acc 0.66667 roc_auc 0.41900 prc_auc 0.60037[0m
[93maverage test of epoch 62: loss -37.24536 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 63: loss -37.60005 acc 0.66667 roc_auc 0.41780 prc_auc 0.59959[0m
[93maverage test of epoch 63: loss -37.79606 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 64: loss -38.15232 acc 0.66667 roc_auc 0.42060 prc_auc 0.59941[0m
[93maverage test of epoch 64: loss -38.34675 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 65: loss -38.70459 acc 0.66667 roc_auc 0.42170 prc_auc 0.60244[0m
[93maverage test of epoch 65: loss -38.89744 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 66: loss -39.25685 acc 0.66667 roc_auc 0.41990 prc_auc 0.60146[0m
[93maverage test of epoch 66: loss -39.44813 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 67: loss -39.80911 acc 0.66667 roc_auc 0.41580 prc_auc 0.59742[0m
[93maverage test of epoch 67: loss -39.99881 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 68: loss -40.36137 acc 0.66667 roc_auc 0.42360 prc_auc 0.60577[0m
[93maverage test of epoch 68: loss -40.54948 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 69: loss -40.91362 acc 0.66667 roc_auc 0.42090 prc_auc 0.60251[0m
[93maverage test of epoch 69: loss -41.10016 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 70: loss -41.46587 acc 0.66667 roc_auc 0.42320 prc_auc 0.60629[0m
[93maverage test of epoch 70: loss -41.65083 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 71: loss -42.01812 acc 0.66667 roc_auc 0.42520 prc_auc 0.61049[0m
[93maverage test of epoch 71: loss -42.20150 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 72: loss -42.57036 acc 0.66667 roc_auc 0.42100 prc_auc 0.60405[0m
[93maverage test of epoch 72: loss -42.75217 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 73: loss -43.12260 acc 0.66667 roc_auc 0.42200 prc_auc 0.61006[0m
[93maverage test of epoch 73: loss -43.30283 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 74: loss -43.67484 acc 0.66667 roc_auc 0.43050 prc_auc 0.61345[0m
[93maverage test of epoch 74: loss -43.85349 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 75: loss -44.22707 acc 0.66667 roc_auc 0.42470 prc_auc 0.61608[0m
[93maverage test of epoch 75: loss -44.40414 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 76: loss -44.77930 acc 0.66667 roc_auc 0.41770 prc_auc 0.60686[0m
[93maverage test of epoch 76: loss -44.95480 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 77: loss -45.33153 acc 0.66667 roc_auc 0.43140 prc_auc 0.61960[0m
[93maverage test of epoch 77: loss -45.50545 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 78: loss -45.88375 acc 0.66667 roc_auc 0.43000 prc_auc 0.62000[0m
[93maverage test of epoch 78: loss -46.05609 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 79: loss -46.43596 acc 0.66667 roc_auc 0.42480 prc_auc 0.61811[0m
[93maverage test of epoch 79: loss -46.60673 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 80: loss -46.98818 acc 0.66667 roc_auc 0.45470 prc_auc 0.63645[0m
[93maverage test of epoch 80: loss -47.15737 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 81: loss -47.54039 acc 0.66667 roc_auc 0.43070 prc_auc 0.62256[0m
[93maverage test of epoch 81: loss -47.70800 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 82: loss -48.09260 acc 0.66667 roc_auc 0.42480 prc_auc 0.62214[0m
[93maverage test of epoch 82: loss -48.25863 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 83: loss -48.64481 acc 0.66667 roc_auc 0.44200 prc_auc 0.63285[0m
[93maverage test of epoch 83: loss -48.80926 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 84: loss -49.19701 acc 0.66667 roc_auc 0.43120 prc_auc 0.63113[0m
[93maverage test of epoch 84: loss -49.35989 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 85: loss -49.74922 acc 0.66667 roc_auc 0.43540 prc_auc 0.63325[0m
[93maverage test of epoch 85: loss -49.91052 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 86: loss -50.30142 acc 0.66667 roc_auc 0.41750 prc_auc 0.62790[0m
[93maverage test of epoch 86: loss -50.46114 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 87: loss -50.85362 acc 0.66667 roc_auc 0.47500 prc_auc 0.65587[0m
[93maverage test of epoch 87: loss -51.01177 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 88: loss -51.40582 acc 0.66667 roc_auc 0.49500 prc_auc 0.66445[0m
[93maverage test of epoch 88: loss -51.56239 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 89: loss -51.95801 acc 0.66667 roc_auc 0.46160 prc_auc 0.65224[0m
[93maverage test of epoch 89: loss -52.11301 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -52.51021 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 90: loss -52.66363 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 91: loss -53.06240 acc 0.66667 roc_auc 0.49500 prc_auc 0.66445[0m
[93maverage test of epoch 91: loss -53.21424 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 92: loss -53.61459 acc 0.66667 roc_auc 0.46000 prc_auc 0.64965[0m
[93maverage test of epoch 92: loss -53.76486 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 93: loss -54.16678 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 93: loss -54.31547 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 94: loss -54.71897 acc 0.66667 roc_auc 0.48000 prc_auc 0.65795[0m
[93maverage test of epoch 94: loss -54.86608 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 95: loss -55.27116 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 95: loss -55.41669 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 96: loss -55.82334 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 96: loss -55.96729 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 97: loss -56.37551 acc 0.66667 roc_auc 0.48000 prc_auc 0.65793[0m
[93maverage test of epoch 97: loss -56.51789 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 98: loss -56.92769 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 98: loss -57.06849 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -57.47986 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 99: loss -57.61909 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -1.21966 acc 0.42667 roc_auc 0.44560 prc_auc 0.65047[0m
[93maverage test of epoch 0: loss -1.86072 acc 0.65789 roc_auc 0.91385 prc_auc 0.96638[0m
[92maverage training of epoch 1: loss -2.71453 acc 0.66667 roc_auc 0.42760 prc_auc 0.63519[0m
[93maverage test of epoch 1: loss -3.39197 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 2: loss -3.82090 acc 0.66667 roc_auc 0.40960 prc_auc 0.62483[0m
[93maverage test of epoch 2: loss -4.18399 acc 0.65789 roc_auc 0.95692 prc_auc 0.98005[0m
[92maverage training of epoch 3: loss -4.53874 acc 0.66667 roc_auc 0.40660 prc_auc 0.62636[0m
[93maverage test of epoch 3: loss -4.85871 acc 0.65789 roc_auc 0.93538 prc_auc 0.96781[0m
[92maverage training of epoch 4: loss -5.20243 acc 0.66667 roc_auc 0.39820 prc_auc 0.62198[0m
[93maverage test of epoch 4: loss -5.51507 acc 0.65789 roc_auc 0.90462 prc_auc 0.95369[0m
[92maverage training of epoch 5: loss -5.85210 acc 0.66667 roc_auc 0.38880 prc_auc 0.60323[0m
[93maverage test of epoch 5: loss -6.15530 acc 0.65789 roc_auc 0.85846 prc_auc 0.93427[0m
[92maverage training of epoch 6: loss -6.48371 acc 0.66667 roc_auc 0.38400 prc_auc 0.59447[0m
[93maverage test of epoch 6: loss -6.77587 acc 0.65789 roc_auc 0.83846 prc_auc 0.92226[0m
[92maverage training of epoch 7: loss -7.09743 acc 0.66667 roc_auc 0.38240 prc_auc 0.59156[0m
[93maverage test of epoch 7: loss -7.38032 acc 0.65789 roc_auc 0.79538 prc_auc 0.89277[0m
[92maverage training of epoch 8: loss -7.69729 acc 0.66667 roc_auc 0.37950 prc_auc 0.57489[0m
[93maverage test of epoch 8: loss -7.97291 acc 0.65789 roc_auc 0.78769 prc_auc 0.86789[0m
[92maverage training of epoch 9: loss -8.28699 acc 0.66667 roc_auc 0.37900 prc_auc 0.57647[0m
[93maverage test of epoch 9: loss -8.55683 acc 0.65789 roc_auc 0.60769 prc_auc 0.74718[0m
[92maverage training of epoch 10: loss -8.86918 acc 0.66667 roc_auc 0.37780 prc_auc 0.57551[0m
[93maverage test of epoch 10: loss -9.13429 acc 0.65789 roc_auc 0.52000 prc_auc 0.67158[0m
[92maverage training of epoch 11: loss -9.44571 acc 0.66667 roc_auc 0.37780 prc_auc 0.57536[0m
[93maverage test of epoch 11: loss -9.70683 acc 0.65789 roc_auc 0.60308 prc_auc 0.71560[0m
[92maverage training of epoch 12: loss -10.01788 acc 0.66667 roc_auc 0.37720 prc_auc 0.57494[0m
[93maverage test of epoch 12: loss -10.27551 acc 0.65789 roc_auc 0.51692 prc_auc 0.66561[0m
[92maverage training of epoch 13: loss -10.58661 acc 0.66667 roc_auc 0.37690 prc_auc 0.57456[0m
[93maverage test of epoch 13: loss -10.84116 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 14: loss -11.15260 acc 0.66667 roc_auc 0.37690 prc_auc 0.57456[0m
[93maverage test of epoch 14: loss -11.40437 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 15: loss -11.71639 acc 0.66667 roc_auc 0.37690 prc_auc 0.57456[0m
[93maverage test of epoch 15: loss -11.96558 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 16: loss -12.27836 acc 0.66667 roc_auc 0.37690 prc_auc 0.57456[0m
[93maverage test of epoch 16: loss -12.52516 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 17: loss -12.83884 acc 0.66667 roc_auc 0.37690 prc_auc 0.57465[0m
[93maverage test of epoch 17: loss -13.08339 acc 0.65789 roc_auc 0.58462 prc_auc 0.70243[0m
[92maverage training of epoch 18: loss -13.39809 acc 0.66667 roc_auc 0.37680 prc_auc 0.57447[0m
[93maverage test of epoch 18: loss -13.64049 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -13.95630 acc 0.66667 roc_auc 0.37680 prc_auc 0.57450[0m
[93maverage test of epoch 19: loss -14.19666 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -14.51364 acc 0.66667 roc_auc 0.37680 prc_auc 0.57453[0m
[93maverage test of epoch 20: loss -14.75203 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -15.07025 acc 0.66667 roc_auc 0.37670 prc_auc 0.57453[0m
[93maverage test of epoch 21: loss -15.30672 acc 0.65789 roc_auc 0.47538 prc_auc 0.64707[0m
[92maverage training of epoch 22: loss -15.62624 acc 0.66667 roc_auc 0.37670 prc_auc 0.57442[0m
[93maverage test of epoch 22: loss -15.86085 acc 0.65789 roc_auc 0.72462 prc_auc 0.78853[0m
[92maverage training of epoch 23: loss -16.18170 acc 0.66667 roc_auc 0.37680 prc_auc 0.57453[0m
[93maverage test of epoch 23: loss -16.41449 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -16.73672 acc 0.66667 roc_auc 0.37660 prc_auc 0.57448[0m
[93maverage test of epoch 24: loss -16.96773 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -17.29135 acc 0.66667 roc_auc 0.37690 prc_auc 0.57442[0m
[93maverage test of epoch 25: loss -17.52060 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -17.84566 acc 0.66667 roc_auc 0.37650 prc_auc 0.57445[0m
[93maverage test of epoch 26: loss -18.07318 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -18.39968 acc 0.66667 roc_auc 0.37690 prc_auc 0.57498[0m
[93maverage test of epoch 27: loss -18.62550 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -18.95346 acc 0.66667 roc_auc 0.37690 prc_auc 0.57467[0m
[93maverage test of epoch 28: loss -19.17759 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -19.50704 acc 0.66667 roc_auc 0.37690 prc_auc 0.57500[0m
[93maverage test of epoch 29: loss -19.72950 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -20.06044 acc 0.66667 roc_auc 0.37660 prc_auc 0.57530[0m
[93maverage test of epoch 30: loss -20.28124 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -20.61368 acc 0.66667 roc_auc 0.37650 prc_auc 0.57514[0m
[93maverage test of epoch 31: loss -20.83284 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -21.16680 acc 0.66667 roc_auc 0.37690 prc_auc 0.57543[0m
[93maverage test of epoch 32: loss -21.38431 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -21.71979 acc 0.66667 roc_auc 0.37690 prc_auc 0.57623[0m
[93maverage test of epoch 33: loss -21.93568 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -22.27269 acc 0.66667 roc_auc 0.37660 prc_auc 0.57540[0m
[93maverage test of epoch 34: loss -22.48695 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -22.82550 acc 0.66667 roc_auc 0.37690 prc_auc 0.57732[0m
[93maverage test of epoch 35: loss -23.03815 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -23.37824 acc 0.66667 roc_auc 0.37700 prc_auc 0.57669[0m
[93maverage test of epoch 36: loss -23.58928 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -23.93092 acc 0.66667 roc_auc 0.37760 prc_auc 0.57612[0m
[93maverage test of epoch 37: loss -24.14035 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -24.48354 acc 0.66667 roc_auc 0.37700 prc_auc 0.57675[0m
[93maverage test of epoch 38: loss -24.69137 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -25.03611 acc 0.66667 roc_auc 0.37650 prc_auc 0.57557[0m
[93maverage test of epoch 39: loss -25.24235 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -25.58864 acc 0.66667 roc_auc 0.37840 prc_auc 0.57533[0m
[93maverage test of epoch 40: loss -25.79328 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -26.14113 acc 0.66667 roc_auc 0.37660 prc_auc 0.57981[0m
[93maverage test of epoch 41: loss -26.34418 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -26.69359 acc 0.66667 roc_auc 0.37760 prc_auc 0.57798[0m
[93maverage test of epoch 42: loss -26.89504 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -27.24602 acc 0.66667 roc_auc 0.37760 prc_auc 0.57851[0m
[93maverage test of epoch 43: loss -27.44588 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -27.79842 acc 0.66667 roc_auc 0.37830 prc_auc 0.57605[0m
[93maverage test of epoch 44: loss -27.99670 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -28.35080 acc 0.66667 roc_auc 0.37690 prc_auc 0.57717[0m
[93maverage test of epoch 45: loss -28.54749 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -28.90317 acc 0.66667 roc_auc 0.37790 prc_auc 0.57933[0m
[93maverage test of epoch 46: loss -29.09828 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -29.45552 acc 0.66667 roc_auc 0.37590 prc_auc 0.57899[0m
[93maverage test of epoch 47: loss -29.64904 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -30.00785 acc 0.66667 roc_auc 0.37430 prc_auc 0.58031[0m
[93maverage test of epoch 48: loss -30.19979 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -30.56016 acc 0.66667 roc_auc 0.37870 prc_auc 0.58229[0m
[93maverage test of epoch 49: loss -30.75052 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 50: loss -31.11246 acc 0.66667 roc_auc 0.37320 prc_auc 0.57971[0m
[93maverage test of epoch 50: loss -31.30124 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 51: loss -31.66475 acc 0.66667 roc_auc 0.37810 prc_auc 0.58216[0m
[93maverage test of epoch 51: loss -31.85194 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 52: loss -32.21703 acc 0.66667 roc_auc 0.38570 prc_auc 0.59123[0m
[93maverage test of epoch 52: loss -32.40264 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 53: loss -32.76930 acc 0.66667 roc_auc 0.38120 prc_auc 0.58563[0m
[93maverage test of epoch 53: loss -32.95333 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 54: loss -33.32156 acc 0.66667 roc_auc 0.37550 prc_auc 0.58247[0m
[93maverage test of epoch 54: loss -33.50401 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 55: loss -33.87382 acc 0.66667 roc_auc 0.38510 prc_auc 0.59167[0m
[93maverage test of epoch 55: loss -34.05468 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 56: loss -34.42606 acc 0.66667 roc_auc 0.38460 prc_auc 0.58806[0m
[93maverage test of epoch 56: loss -34.60535 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 57: loss -34.97830 acc 0.66667 roc_auc 0.37970 prc_auc 0.59029[0m
[93maverage test of epoch 57: loss -35.15601 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 58: loss -35.53054 acc 0.66667 roc_auc 0.37400 prc_auc 0.58701[0m
[93maverage test of epoch 58: loss -35.70667 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 59: loss -36.08277 acc 0.66667 roc_auc 0.39140 prc_auc 0.60247[0m
[93maverage test of epoch 59: loss -36.25732 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 60: loss -36.63499 acc 0.66667 roc_auc 0.39030 prc_auc 0.60511[0m
[93maverage test of epoch 60: loss -36.80797 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 61: loss -37.18721 acc 0.66667 roc_auc 0.38450 prc_auc 0.59893[0m
[93maverage test of epoch 61: loss -37.35861 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 62: loss -37.73943 acc 0.66667 roc_auc 0.38550 prc_auc 0.60422[0m
[93maverage test of epoch 62: loss -37.90924 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 63: loss -38.29164 acc 0.66667 roc_auc 0.41480 prc_auc 0.62041[0m
[93maverage test of epoch 63: loss -38.45988 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 64: loss -38.84384 acc 0.66667 roc_auc 0.39890 prc_auc 0.61169[0m
[93maverage test of epoch 64: loss -39.01050 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 65: loss -39.39604 acc 0.66667 roc_auc 0.43710 prc_auc 0.63420[0m
[93maverage test of epoch 65: loss -39.56112 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 66: loss -39.94823 acc 0.66667 roc_auc 0.39950 prc_auc 0.61617[0m
[93maverage test of epoch 66: loss -40.11174 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 67: loss -40.50043 acc 0.66667 roc_auc 0.44560 prc_auc 0.63914[0m
[93maverage test of epoch 67: loss -40.66236 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 68: loss -41.05261 acc 0.66667 roc_auc 0.40140 prc_auc 0.62143[0m
[93maverage test of epoch 68: loss -41.21296 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 69: loss -41.60480 acc 0.66667 roc_auc 0.45000 prc_auc 0.64551[0m
[93maverage test of epoch 69: loss -41.76357 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 70: loss -42.15698 acc 0.66667 roc_auc 0.39470 prc_auc 0.62423[0m
[93maverage test of epoch 70: loss -42.31417 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 71: loss -42.70915 acc 0.66667 roc_auc 0.39000 prc_auc 0.62792[0m
[93maverage test of epoch 71: loss -42.86477 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 72: loss -43.26132 acc 0.66667 roc_auc 0.43000 prc_auc 0.64333[0m
[93maverage test of epoch 72: loss -43.41536 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 73: loss -43.81349 acc 0.66667 roc_auc 0.49000 prc_auc 0.66225[0m
[93maverage test of epoch 73: loss -43.96595 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 74: loss -44.36566 acc 0.66667 roc_auc 0.47000 prc_auc 0.65370[0m
[93maverage test of epoch 74: loss -44.51654 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 75: loss -44.91782 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 75: loss -45.06713 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 76: loss -45.46998 acc 0.66667 roc_auc 0.48000 prc_auc 0.65793[0m
[93maverage test of epoch 76: loss -45.61771 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 77: loss -46.02214 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 77: loss -46.16829 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 78: loss -46.57430 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 78: loss -46.71887 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 79: loss -47.12645 acc 0.66667 roc_auc 0.49000 prc_auc 0.66226[0m
[93maverage test of epoch 79: loss -47.26945 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 80: loss -47.67861 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 80: loss -47.82003 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 81: loss -48.23076 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 81: loss -48.37060 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 82: loss -48.78291 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 82: loss -48.92118 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 83: loss -49.33505 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 83: loss -49.47174 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 84: loss -49.88720 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 84: loss -50.02231 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 85: loss -50.43935 acc 0.66667 roc_auc 0.47500 prc_auc 0.65579[0m
[93maverage test of epoch 85: loss -50.57288 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 86: loss -50.99149 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 86: loss -51.12345 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 87: loss -51.54363 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 87: loss -51.67401 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 88: loss -52.09576 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 88: loss -52.22457 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 89: loss -52.64790 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 89: loss -52.77513 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -53.20003 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 90: loss -53.32567 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 91: loss -53.75216 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 91: loss -53.87623 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 92: loss -54.30429 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 92: loss -54.42678 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 93: loss -54.85641 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 93: loss -54.97732 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 94: loss -55.40853 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 94: loss -55.52786 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 95: loss -55.96065 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 95: loss -56.07840 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 96: loss -56.51276 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 96: loss -56.62894 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 97: loss -57.06488 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 97: loss -57.17948 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 98: loss -57.61699 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 98: loss -57.73001 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -58.16910 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 99: loss -58.28054 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -0.39524 acc 0.33775 roc_auc 0.47725 prc_auc 0.63454[0m
[93maverage test of epoch 0: loss -0.74829 acc 0.32432 roc_auc 0.55000 prc_auc 0.78165[0m
[92maverage training of epoch 1: loss -1.16625 acc 0.33775 roc_auc 0.54961 prc_auc 0.69181[0m
[93maverage test of epoch 1: loss -1.56473 acc 0.32432 roc_auc 0.84667 prc_auc 0.91092[0m
[92maverage training of epoch 2: loss -2.08477 acc 0.33775 roc_auc 0.61863 prc_auc 0.79751[0m
[93maverage test of epoch 2: loss -2.52156 acc 0.32432 roc_auc 0.85000 prc_auc 0.91082[0m
[92maverage training of epoch 3: loss -2.94378 acc 0.33775 roc_auc 0.38078 prc_auc 0.58964[0m
[93maverage test of epoch 3: loss -3.28664 acc 0.32432 roc_auc 0.27000 prc_auc 0.61633[0m
[92maverage training of epoch 4: loss -3.65581 acc 0.33775 roc_auc 0.37333 prc_auc 0.57191[0m
[93maverage test of epoch 4: loss -3.96311 acc 0.32432 roc_auc 0.09333 prc_auc 0.49729[0m
[92maverage training of epoch 5: loss -4.30841 acc 0.33775 roc_auc 0.37196 prc_auc 0.56605[0m
[93maverage test of epoch 5: loss -4.60033 acc 0.32432 roc_auc 0.08333 prc_auc 0.49532[0m
[92maverage training of epoch 6: loss -4.93140 acc 0.33775 roc_auc 0.37333 prc_auc 0.56753[0m
[93maverage test of epoch 6: loss -5.21547 acc 0.32432 roc_auc 0.08667 prc_auc 0.50226[0m
[92maverage training of epoch 7: loss -5.53671 acc 0.33775 roc_auc 0.37431 prc_auc 0.56869[0m
[93maverage test of epoch 7: loss -5.81657 acc 0.32432 roc_auc 0.09167 prc_auc 0.49944[0m
[92maverage training of epoch 8: loss -6.13036 acc 0.33775 roc_auc 0.37529 prc_auc 0.56892[0m
[93maverage test of epoch 8: loss -6.40804 acc 0.32432 roc_auc 0.10667 prc_auc 0.50868[0m
[92maverage training of epoch 9: loss -6.71580 acc 0.33775 roc_auc 0.37569 prc_auc 0.56987[0m
[93maverage test of epoch 9: loss -6.99255 acc 0.32432 roc_auc 0.12167 prc_auc 0.51891[0m
[92maverage training of epoch 10: loss -7.29522 acc 0.33775 roc_auc 0.37569 prc_auc 0.56989[0m
[93maverage test of epoch 10: loss -7.57187 acc 0.32432 roc_auc 0.10000 prc_auc 0.51129[0m
[92maverage training of epoch 11: loss -7.87007 acc 0.33775 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 11: loss -8.14718 acc 0.32432 roc_auc 0.10333 prc_auc 0.51227[0m
[92maverage training of epoch 12: loss -8.44136 acc 0.33775 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 12: loss -8.71934 acc 0.32432 roc_auc 0.12833 prc_auc 0.52425[0m
[92maverage training of epoch 13: loss -9.00985 acc 0.33775 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 13: loss -9.28900 acc 0.32432 roc_auc 0.11000 prc_auc 0.54354[0m
[92maverage training of epoch 14: loss -9.57608 acc 0.33775 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 14: loss -9.85663 acc 0.32432 roc_auc 0.12667 prc_auc 0.57116[0m
[92maverage training of epoch 15: loss -10.14047 acc 0.33775 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 15: loss -10.42259 acc 0.32432 roc_auc 0.17000 prc_auc 0.57836[0m
[92maverage training of epoch 16: loss -10.70336 acc 0.33775 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 16: loss -10.98719 acc 0.32432 roc_auc 0.17167 prc_auc 0.55716[0m
[92maverage training of epoch 17: loss -11.26500 acc 0.33775 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 17: loss -11.55066 acc 0.32432 roc_auc 0.40333 prc_auc 0.65018[0m
[92maverage training of epoch 18: loss -11.82561 acc 0.52318 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 18: loss -12.11317 acc 0.67568 roc_auc 0.58000 prc_auc 0.71530[0m
[92maverage training of epoch 19: loss -12.38534 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 19: loss -12.67489 acc 0.67568 roc_auc 0.29500 prc_auc 0.62655[0m
[92maverage training of epoch 20: loss -12.94434 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 20: loss -13.23594 acc 0.67568 roc_auc 0.20667 prc_auc 0.58938[0m
[92maverage training of epoch 21: loss -13.50273 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 21: loss -13.79642 acc 0.67568 roc_auc 0.39167 prc_auc 0.63022[0m
[92maverage training of epoch 22: loss -14.06060 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 22: loss -14.35641 acc 0.67568 roc_auc 0.40000 prc_auc 0.63392[0m
[92maverage training of epoch 23: loss -14.61802 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 23: loss -14.91600 acc 0.67568 roc_auc 0.46000 prc_auc 0.65828[0m
[92maverage training of epoch 24: loss -15.17506 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 24: loss -15.47524 acc 0.67568 roc_auc 0.60000 prc_auc 0.73472[0m
[92maverage training of epoch 25: loss -15.73178 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 25: loss -16.03418 acc 0.67568 roc_auc 0.25667 prc_auc 0.60474[0m
[92maverage training of epoch 26: loss -16.28823 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 26: loss -16.59287 acc 0.67568 roc_auc 0.32000 prc_auc 0.64541[0m
[92maverage training of epoch 27: loss -16.84444 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 27: loss -17.15133 acc 0.67568 roc_auc 0.70000 prc_auc 0.79751[0m
[92maverage training of epoch 28: loss -17.40044 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 28: loss -17.70961 acc 0.67568 roc_auc 0.48000 prc_auc 0.68865[0m
[92maverage training of epoch 29: loss -17.95628 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 29: loss -18.26773 acc 0.67568 roc_auc 0.46000 prc_auc 0.66724[0m
[92maverage training of epoch 30: loss -18.51196 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 30: loss -18.82571 acc 0.67568 roc_auc 0.31333 prc_auc 0.63335[0m
[92maverage training of epoch 31: loss -19.06752 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 31: loss -19.38357 acc 0.67568 roc_auc 0.24333 prc_auc 0.63566[0m
[92maverage training of epoch 32: loss -19.62296 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 32: loss -19.94132 acc 0.67568 roc_auc 0.52167 prc_auc 0.76662[0m
[92maverage training of epoch 33: loss -20.17831 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 33: loss -20.49900 acc 0.67568 roc_auc 0.42000 prc_auc 0.65946[0m
[92maverage training of epoch 34: loss -20.73357 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 34: loss -21.05659 acc 0.67568 roc_auc 0.38000 prc_auc 0.64278[0m
[92maverage training of epoch 35: loss -21.28877 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 35: loss -21.61411 acc 0.67568 roc_auc 0.70000 prc_auc 0.79751[0m
[92maverage training of epoch 36: loss -21.84390 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 36: loss -22.17158 acc 0.67568 roc_auc 0.50167 prc_auc 0.77246[0m
[92maverage training of epoch 37: loss -22.39898 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0mUsing backend: pytorch
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))

[93maverage test of epoch 37: loss -22.72900 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 38: loss -22.95402 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 38: loss -23.28637 acc 0.67568 roc_auc 0.84000 prc_auc 0.87252[0m
[92maverage training of epoch 39: loss -23.50901 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 39: loss -23.84371 acc 0.67568 roc_auc 0.46000 prc_auc 0.66546[0m
[92maverage training of epoch 40: loss -24.06397 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 40: loss -24.40102 acc 0.67568 roc_auc 0.46000 prc_auc 0.66633[0m
[92maverage training of epoch 41: loss -24.61890 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 41: loss -24.95829 acc 0.67568 roc_auc 0.72000 prc_auc 0.80439[0m
[92maverage training of epoch 42: loss -25.17379 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 42: loss -25.51554 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 43: loss -25.72867 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 43: loss -26.07277 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 44: loss -26.28353 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 44: loss -26.62998 acc 0.67568 roc_auc 0.50000 prc_auc 0.68036[0m
[92maverage training of epoch 45: loss -26.83837 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 45: loss -27.18717 acc 0.67568 roc_auc 0.34000 prc_auc 0.67305[0m
[92maverage training of epoch 46: loss -27.39320 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 46: loss -27.74436 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 47: loss -27.94801 acc 0.66225 roc_auc 0.37578 prc_auc 0.56962[0m
[93maverage test of epoch 47: loss -28.30152 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 48: loss -28.50281 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 48: loss -28.85868 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 49: loss -29.05760 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 49: loss -29.41583 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 50: loss -29.61238 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 50: loss -29.97297 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 51: loss -30.16715 acc 0.66225 roc_auc 0.37578 prc_auc 0.56962[0m
[93maverage test of epoch 51: loss -30.53009 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 52: loss -30.72191 acc 0.66225 roc_auc 0.37588 prc_auc 0.56962[0m
[93maverage test of epoch 52: loss -31.08721 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 53: loss -31.27666 acc 0.66225 roc_auc 0.37578 prc_auc 0.56962[0m
[93maverage test of epoch 53: loss -31.64432 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 54: loss -31.83141 acc 0.66225 roc_auc 0.37588 prc_auc 0.56972[0m
[93maverage test of epoch 54: loss -32.20142 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 55: loss -32.38614 acc 0.66225 roc_auc 0.37549 prc_auc 0.56950[0m
[93maverage test of epoch 55: loss -32.75852 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 56: loss -32.94088 acc 0.66225 roc_auc 0.37588 prc_auc 0.57008[0m
[93maverage test of epoch 56: loss -33.31561 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 57: loss -33.49560 acc 0.66225 roc_auc 0.37569 prc_auc 0.56987[0m
[93maverage test of epoch 57: loss -33.87270 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 58: loss -34.05032 acc 0.66225 roc_auc 0.37588 prc_auc 0.56966[0m
[93maverage test of epoch 58: loss -34.42978 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 59: loss -34.60504 acc 0.66225 roc_auc 0.37588 prc_auc 0.56963[0m
[93maverage test of epoch 59: loss -34.98685 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 60: loss -35.15975 acc 0.66225 roc_auc 0.37588 prc_auc 0.57027[0m
[93maverage test of epoch 60: loss -35.54392 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 61: loss -35.71445 acc 0.66225 roc_auc 0.37618 prc_auc 0.57106[0m
[93maverage test of epoch 61: loss -36.10099 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 62: loss -36.26915 acc 0.66225 roc_auc 0.37529 prc_auc 0.57023[0m
[93maverage test of epoch 62: loss -36.65804 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 63: loss -36.82384 acc 0.66225 roc_auc 0.37588 prc_auc 0.57061[0m
[93maverage test of epoch 63: loss -37.21509 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 64: loss -37.37853 acc 0.66225 roc_auc 0.37578 prc_auc 0.57048[0m
[93maverage test of epoch 64: loss -37.77214 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 65: loss -37.93321 acc 0.66225 roc_auc 0.37598 prc_auc 0.57195[0m
[93maverage test of epoch 65: loss -38.32918 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 66: loss -38.48788 acc 0.66225 roc_auc 0.37529 prc_auc 0.57079[0m
[93maverage test of epoch 66: loss -38.88621 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 67: loss -39.04255 acc 0.66225 roc_auc 0.37529 prc_auc 0.57357[0m
[93maverage test of epoch 67: loss -39.44324 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 68: loss -39.59721 acc 0.66225 roc_auc 0.37549 prc_auc 0.57110[0m
[93maverage test of epoch 68: loss -40.00026 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 69: loss -40.15187 acc 0.66225 roc_auc 0.37608 prc_auc 0.57122[0m
[93maverage test of epoch 69: loss -40.55728 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 70: loss -40.70653 acc 0.66225 roc_auc 0.37510 prc_auc 0.57281[0m
[93maverage test of epoch 70: loss -41.11430 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 71: loss -41.26118 acc 0.66225 roc_auc 0.37618 prc_auc 0.57244[0m
[93maverage test of epoch 71: loss -41.67132 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 72: loss -41.81583 acc 0.66225 roc_auc 0.37657 prc_auc 0.57358[0m
[93maverage test of epoch 72: loss -42.22833 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 73: loss -42.37048 acc 0.66225 roc_auc 0.37686 prc_auc 0.57407[0m
[93maverage test of epoch 73: loss -42.78534 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 74: loss -42.92512 acc 0.66225 roc_auc 0.37529 prc_auc 0.57227[0m
[93maverage test of epoch 74: loss -43.34234 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 75: loss -43.47976 acc 0.66225 roc_auc 0.37569 prc_auc 0.57247[0m
[93maverage test of epoch 75: loss -43.89934 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 76: loss -44.03440 acc 0.66225 roc_auc 0.37225 prc_auc 0.57213[0m
[93maverage test of epoch 76: loss -44.45635 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 77: loss -44.58904 acc 0.66225 roc_auc 0.37137 prc_auc 0.57155[0m
[93maverage test of epoch 77: loss -45.01335 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 78: loss -45.14368 acc 0.66225 roc_auc 0.37539 prc_auc 0.57429[0m
[93maverage test of epoch 78: loss -45.57034 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 79: loss -45.69831 acc 0.66225 roc_auc 0.37539 prc_auc 0.57790[0m
[93maverage test of epoch 79: loss -46.12734 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 80: loss -46.25294 acc 0.66225 roc_auc 0.37255 prc_auc 0.57827[0m
[93maverage test of epoch 80: loss -46.68433 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 81: loss -46.80757 acc 0.66225 roc_auc 0.37186 prc_auc 0.57610[0m
[93maverage test of epoch 81: loss -47.24132 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 82: loss -47.36219 acc 0.66225 roc_auc 0.37196 prc_auc 0.57807[0m
[93maverage test of epoch 82: loss -47.79831 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 83: loss -47.91682 acc 0.66225 roc_auc 0.37716 prc_auc 0.58198[0m
[93maverage test of epoch 83: loss -48.35529 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 84: loss -48.47143 acc 0.66225 roc_auc 0.37451 prc_auc 0.58497[0m
[93maverage test of epoch 84: loss -48.91227 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 85: loss -49.02605 acc 0.66225 roc_auc 0.38363 prc_auc 0.58976[0m
[93maverage test of epoch 85: loss -49.46925 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 86: loss -49.58067 acc 0.66225 roc_auc 0.37912 prc_auc 0.58762[0m
[93maverage test of epoch 86: loss -50.02623 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 87: loss -50.13528 acc 0.66225 roc_auc 0.38539 prc_auc 0.59305[0m
[93maverage test of epoch 87: loss -50.58321 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 88: loss -50.68990 acc 0.66225 roc_auc 0.37627 prc_auc 0.59310[0m
[93maverage test of epoch 88: loss -51.14018 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 89: loss -51.24451 acc 0.66225 roc_auc 0.39755 prc_auc 0.60603[0m
[93maverage test of epoch 89: loss -51.69715 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 90: loss -51.79911 acc 0.66225 roc_auc 0.38441 prc_auc 0.60074[0m
[93maverage test of epoch 90: loss -52.25413 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 91: loss -52.35372 acc 0.66225 roc_auc 0.40863 prc_auc 0.61611[0m
[93maverage test of epoch 91: loss -52.81109 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 92: loss -52.90833 acc 0.66225 roc_auc 0.37814 prc_auc 0.60358[0m
[93maverage test of epoch 92: loss -53.36806 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 93: loss -53.46293 acc 0.66225 roc_auc 0.44422 prc_auc 0.63705[0m
[93maverage test of epoch 93: loss -53.92503 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 94: loss -54.01753 acc 0.66225 roc_auc 0.39618 prc_auc 0.61525[0m
[93maverage test of epoch 94: loss -54.48199 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 95: loss -54.57213 acc 0.66225 roc_auc 0.42686 prc_auc 0.62998[0m
[93maverage test of epoch 95: loss -55.03895 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 96: loss -55.12672 acc 0.66225 roc_auc 0.45196 prc_auc 0.63861[0m
[93maverage test of epoch 96: loss -55.59591 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 97: loss -55.68132 acc 0.66225 roc_auc 0.43284 prc_auc 0.63417[0m
[93maverage test of epoch 97: loss -56.15286 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 98: loss -56.23590 acc 0.66225 roc_auc 0.46784 prc_auc 0.64829[0m
[93maverage test of epoch 98: loss -56.70981 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 99: loss -56.79049 acc 0.66225 roc_auc 0.48284 prc_auc 0.65469[0m
[93maverage test of epoch 99: loss -57.26676 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -0.73089 acc 0.66225 roc_auc 0.41078 prc_auc 0.60651[0m
[93maverage test of epoch 0: loss -1.62705 acc 0.67568 roc_auc 0.69333 prc_auc 0.86826[0m
[92maverage training of epoch 1: loss -2.14871 acc 0.66225 roc_auc 0.41941 prc_auc 0.62187[0m
[93maverage test of epoch 1: loss -2.78731 acc 0.67568 roc_auc 0.93333 prc_auc 0.97438[0m
[92maverage training of epoch 2: loss -3.21393 acc 0.66225 roc_auc 0.39314 prc_auc 0.60336[0m
[93maverage test of epoch 2: loss -3.70954 acc 0.67568 roc_auc 0.90667 prc_auc 0.95653[0m
[92maverage training of epoch 3: loss -4.00806 acc 0.66225 roc_auc 0.37725 prc_auc 0.59034[0m
[93maverage test of epoch 3: loss -4.42664 acc 0.67568 roc_auc 0.90667 prc_auc 0.94712[0m
[92maverage training of epoch 4: loss -4.68440 acc 0.66225 roc_auc 0.37275 prc_auc 0.58227[0m
[93maverage test of epoch 4: loss -5.07893 acc 0.67568 roc_auc 0.83500 prc_auc 0.89339[0m
[92maverage training of epoch 5: loss -5.31681 acc 0.66225 roc_auc 0.37667 prc_auc 0.58747[0m
[93maverage test of epoch 5: loss -5.70084 acc 0.67568 roc_auc 0.79333 prc_auc 0.85211[0m
[92maverage training of epoch 6: loss -5.92639 acc 0.66225 roc_auc 0.37667 prc_auc 0.58950[0m
[93maverage test of epoch 6: loss -6.30522 acc 0.67568 roc_auc 0.58000 prc_auc 0.72757[0m
[92maverage training of epoch 7: loss -6.52205 acc 0.66225 roc_auc 0.37608 prc_auc 0.58203[0m
[93maverage test of epoch 7: loss -6.89832 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 8: loss -7.10842 acc 0.66225 roc_auc 0.37578 prc_auc 0.57428[0m
[93maverage test of epoch 8: loss -7.48362 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 9: loss -7.68821 acc 0.66225 roc_auc 0.37333 prc_auc 0.57151[0m
[93maverage test of epoch 9: loss -8.06326 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 10: loss -8.26315 acc 0.66225 roc_auc 0.37275 prc_auc 0.57108[0m
[93maverage test of epoch 10: loss -8.63867 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 11: loss -8.83439 acc 0.66225 roc_auc 0.37255 prc_auc 0.57054[0m
[93maverage test of epoch 11: loss -9.21081 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 12: loss -9.40275 acc 0.66225 roc_auc 0.37137 prc_auc 0.56893[0m
[93maverage test of epoch 12: loss -9.78038 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 13: loss -9.96882 acc 0.66225 roc_auc 0.37098 prc_auc 0.56877[0m
[93maverage test of epoch 13: loss -10.34789 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 14: loss -10.53306 acc 0.66225 roc_auc 0.37098 prc_auc 0.56914[0m
[93maverage test of epoch 14: loss -10.91373 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 15: loss -11.09580 acc 0.66225 roc_auc 0.37029 prc_auc 0.56851[0m
[93maverage test of epoch 15: loss -11.47822 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 16: loss -11.65731 acc 0.66225 roc_auc 0.37029 prc_auc 0.56818[0m
[93maverage test of epoch 16: loss -12.04158 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 17: loss -12.21779 acc 0.66225 roc_auc 0.37049 prc_auc 0.56965[0m
[93maverage test of epoch 17: loss -12.60400 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 18: loss -12.77743 acc 0.66225 roc_auc 0.37010 prc_auc 0.56958[0m
[93maverage test of epoch 18: loss -13.16565 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 19: loss -13.33636 acc 0.66225 roc_auc 0.37010 prc_auc 0.56838[0m
[93maverage test of epoch 19: loss -13.72663 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 20: loss -13.89468 acc 0.66225 roc_auc 0.36971 prc_auc 0.56934[0m
[93maverage test of epoch 20: loss -14.28707 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 21: loss -14.45250 acc 0.66225 roc_auc 0.37020 prc_auc 0.56925[0m
[93maverage test of epoch 21: loss -14.84704 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 22: loss -15.00989 acc 0.66225 roc_auc 0.36971 prc_auc 0.56957[0m
[93maverage test of epoch 22: loss -15.40660 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 23: loss -15.56691 acc 0.66225 roc_auc 0.36971 prc_auc 0.56914[0m
[93maverage test of epoch 23: loss -15.96583 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 24: loss -16.12362 acc 0.66225 roc_auc 0.37010 prc_auc 0.57103[0m
[93maverage test of epoch 24: loss -16.52477 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 25: loss -16.68006 acc 0.66225 roc_auc 0.36971 prc_auc 0.57063[0m
[93maverage test of epoch 25: loss -17.08345 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 26: loss -17.23627 acc 0.66225 roc_auc 0.36971 prc_auc 0.57169[0m
[93maverage test of epoch 26: loss -17.64193 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 27: loss -17.79229 acc 0.66225 roc_auc 0.37020 prc_auc 0.57270[0m
[93maverage test of epoch 27: loss -18.20023 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 28: loss -18.34813 acc 0.66225 roc_auc 0.36892 prc_auc 0.57016[0m
[93maverage test of epoch 28: loss -18.75836 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 29: loss -18.90384 acc 0.66225 roc_auc 0.36882 prc_auc 0.57066[0m
[93maverage test of epoch 29: loss -19.31636 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 30: loss -19.45942 acc 0.66225 roc_auc 0.36833 prc_auc 0.57035[0m
[93maverage test of epoch 30: loss -19.87425 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 31: loss -20.01489 acc 0.66225 roc_auc 0.36735 prc_auc 0.57128[0m
[93maverage test of epoch 31: loss -20.43203 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 32: loss -20.57026 acc 0.66225 roc_auc 0.36990 prc_auc 0.57229[0m
[93maverage test of epoch 32: loss -20.98973 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 33: loss -21.12556 acc 0.66225 roc_auc 0.36284 prc_auc 0.56719[0m
[93maverage test of epoch 33: loss -21.54735 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 34: loss -21.68078 acc 0.66225 roc_auc 0.36696 prc_auc 0.56876[0m
[93maverage test of epoch 34: loss -22.10491 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 35: loss -22.23595 acc 0.66225 roc_auc 0.36755 prc_auc 0.57042[0m
[93maverage test of epoch 35: loss -22.66241 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 36: loss -22.79106 acc 0.66225 roc_auc 0.36824 prc_auc 0.57315[0m
[93maverage test of epoch 36: loss -23.21985 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 37: loss -23.34612 acc 0.66225 roc_auc 0.37265 prc_auc 0.58006[0m
[93maverage test of epoch 37: loss -23.77727 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 38: loss -23.90115 acc 0.66225 roc_auc 0.36412 prc_auc 0.57256[0m
[93maverage test of epoch 38: loss -24.33464 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 39: loss -24.45615 acc 0.66225 roc_auc 0.36549 prc_auc 0.57521[0m
[93maverage test of epoch 39: loss -24.89198 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -25.01111 acc 0.66225 roc_auc 0.37127 prc_auc 0.57892[0m
[93maverage test of epoch 40: loss -25.44929 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -25.56605 acc 0.66225 roc_auc 0.37510 prc_auc 0.58309[0m
[93maverage test of epoch 41: loss -26.00658 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -26.12096 acc 0.66225 roc_auc 0.36784 prc_auc 0.57919[0m
[93maverage test of epoch 42: loss -26.56384 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -26.67586 acc 0.66225 roc_auc 0.37108 prc_auc 0.58553[0m
[93maverage test of epoch 43: loss -27.12109 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -27.23073 acc 0.66225 roc_auc 0.37245 prc_auc 0.58604[0m
[93maverage test of epoch 44: loss -27.67832 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -27.78560 acc 0.66225 roc_auc 0.37588 prc_auc 0.59144[0m
[93maverage test of epoch 45: loss -28.23554 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -28.34045 acc 0.66225 roc_auc 0.37941 prc_auc 0.59585[0m
[93maverage test of epoch 46: loss -28.79274 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -28.89528 acc 0.66225 roc_auc 0.37794 prc_auc 0.59628[0m
[93maverage test of epoch 47: loss -29.34993 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -29.45010 acc 0.66225 roc_auc 0.38833 prc_auc 0.60481[0m
[93maverage test of epoch 48: loss -29.90711 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -30.00491 acc 0.66225 roc_auc 0.38186 prc_auc 0.60362[0m
[93maverage test of epoch 49: loss -30.46427 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 50: loss -30.55971 acc 0.66225 roc_auc 0.44314 prc_auc 0.63502[0m
[93maverage test of epoch 50: loss -31.02142 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 51: loss -31.11450 acc 0.66225 roc_auc 0.39618 prc_auc 0.61242[0m
[93maverage test of epoch 51: loss -31.57857 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 52: loss -31.66927 acc 0.66225 roc_auc 0.44461 prc_auc 0.63663[0m
[93maverage test of epoch 52: loss -32.13570 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 53: loss -32.22404 acc 0.66225 roc_auc 0.42451 prc_auc 0.62731[0m
[93maverage test of epoch 53: loss -32.69282 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 54: loss -32.77880 acc 0.66225 roc_auc 0.44265 prc_auc 0.63804[0m
[93maverage test of epoch 54: loss -33.24994 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 55: loss -33.33355 acc 0.66225 roc_auc 0.45363 prc_auc 0.64232[0m
[93maverage test of epoch 55: loss -33.80705 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 56: loss -33.88830 acc 0.66225 roc_auc 0.44882 prc_auc 0.64033[0m
[93maverage test of epoch 56: loss -34.36416 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 57: loss -34.44305 acc 0.66225 roc_auc 0.45284 prc_auc 0.64209[0m
[93maverage test of epoch 57: loss -34.92127 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 58: loss -34.99780 acc 0.66225 roc_auc 0.41608 prc_auc 0.62899[0m
[93maverage test of epoch 58: loss -35.47838 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 59: loss -35.55254 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 59: loss -36.03548 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 60: loss -36.10729 acc 0.66225 roc_auc 0.43627 prc_auc 0.63600[0m
[93maverage test of epoch 60: loss -36.59259 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 61: loss -36.66203 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 61: loss -37.14970 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 62: loss -37.21677 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 62: loss -37.70679 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 63: loss -37.77151 acc 0.66225 roc_auc 0.44206 prc_auc 0.63794[0m
[93maverage test of epoch 63: loss -38.26389 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 64: loss -38.32624 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 64: loss -38.82099 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 65: loss -38.88098 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 65: loss -39.37808 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 66: loss -39.43571 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 66: loss -39.93517 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 67: loss -39.99044 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 67: loss -40.49226 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 68: loss -40.54516 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 68: loss -41.04935 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 69: loss -41.09989 acc 0.66225 roc_auc 0.41088 prc_auc 0.62749[0m
[93maverage test of epoch 69: loss -41.60644 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 70: loss -41.65462 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 70: loss -42.16352 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 71: loss -42.20934 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 71: loss -42.72061 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 72: loss -42.76406 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 72: loss -43.27769 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 73: loss -43.31878 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 73: loss -43.83477 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 74: loss -43.87350 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 74: loss -44.39185 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 75: loss -44.42822 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 75: loss -44.94893 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 76: loss -44.98293 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 76: loss -45.50600 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 77: loss -45.53764 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 77: loss -46.06308 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 78: loss -46.09235 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 78: loss -46.62014 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 79: loss -46.64706 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 79: loss -47.17721 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 80: loss -47.20176 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 80: loss -47.73428 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 81: loss -47.75646 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 81: loss -48.29134 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 82: loss -48.31117 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 82: loss -48.84840 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 83: loss -48.86587 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 83: loss -49.40547 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 84: loss -49.42056 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 84: loss -49.96252 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 85: loss -49.97526 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 85: loss -50.51958 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 86: loss -50.52994 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 86: loss -51.07662 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 87: loss -51.08463 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 87: loss -51.63367 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 88: loss -51.63931 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 88: loss -52.19071 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 89: loss -52.19399 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 89: loss -52.74775 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 90: loss -52.74866 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 90: loss -53.30478 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 91: loss -53.30333 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 91: loss -53.86181 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 92: loss -53.85800 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 92: loss -54.41885 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 93: loss -54.41267 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 93: loss -54.97587 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 94: loss -54.96733 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 94: loss -55.53289 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 95: loss -55.52199 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 95: loss -56.08991 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 96: loss -56.07664 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 96: loss -56.64692 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 97: loss -56.63129 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 97: loss -57.20393 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 98: loss -57.18593 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 98: loss -57.76094 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 99: loss -57.74058 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 99: loss -58.31794 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.66501 ROC_AUC (avg): 0.5 PRC_AUC (avg): 0.66501 

Average forward propagation time taken(ms): 2.463692719185142
Average backward propagation time taken(ms): 0.8669157303617262

