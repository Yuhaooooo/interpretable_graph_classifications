# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-18-17-49/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-18-17-49/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 16,
 'epochs': 50,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 4,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.003,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 1,
 'num_workers': 8,
 'number_of_mlp_layer': 0,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-17-18-17-49',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 50, 'learning_rate': 0.003, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.003
[92maverage training of epoch 0: loss -1.22927 acc 0.43333 roc_auc 0.35600 prc_auc 0.58629[0m
[93maverage test of epoch 0: loss -2.70392 acc 0.65789 roc_auc 0.86462 prc_auc 0.93807[0m
[92maverage training of epoch 1: loss -3.89528 acc 0.66667 roc_auc 0.37420 prc_auc 0.59414[0m
[93maverage test of epoch 1: loss -4.99303 acc 0.65789 roc_auc 0.86462 prc_auc 0.93807[0m
[92maverage training of epoch 2: loss -5.96960 acc 0.66667 roc_auc 0.36850 prc_auc 0.57732[0m
[93maverage test of epoch 2: loss -6.90717 acc 0.65789 roc_auc 0.86462 prc_auc 0.93807[0m
[92maverage training of epoch 3: loss -7.82480 acc 0.66667 roc_auc 0.36100 prc_auc 0.56719[0m
[93maverage test of epoch 3: loss -8.70893 acc 0.65789 roc_auc 0.86308 prc_auc 0.93673[0m
[92maverage training of epoch 4: loss -9.60455 acc 0.66667 roc_auc 0.35920 prc_auc 0.56375[0m
[93maverage test of epoch 4: loss -10.46128 acc 0.65789 roc_auc 0.86308 prc_auc 0.93166[0m
[92maverage training of epoch 5: loss -11.34706 acc 0.66667 roc_auc 0.35820 prc_auc 0.56266[0m
[93maverage test of epoch 5: loss -12.18598 acc 0.65789 roc_auc 0.85077 prc_auc 0.90104[0m
[92maverage training of epoch 6: loss -13.06738 acc 0.66667 roc_auc 0.35740 prc_auc 0.56219[0m
[93maverage test of epoch 6: loss -13.89311 acc 0.65789 roc_auc 0.84308 prc_auc 0.91709[0m
[92maverage training of epoch 7: loss -14.77308 acc 0.66667 roc_auc 0.35700 prc_auc 0.56179[0m
[93maverage test of epoch 7: loss -15.58819 acc 0.65789 roc_auc 0.68923 prc_auc 0.75860[0m
[92maverage training of epoch 8: loss -16.46846 acc 0.66667 roc_auc 0.35720 prc_auc 0.56202[0m
[93maverage test of epoch 8: loss -17.27455 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 9: loss -18.15625 acc 0.66667 roc_auc 0.35720 prc_auc 0.56189[0m
[93maverage test of epoch 9: loss -18.95438 acc 0.65789 roc_auc 0.65385 prc_auc 0.73529[0m
[92maverage training of epoch 10: loss -19.83829 acc 0.66667 roc_auc 0.35720 prc_auc 0.56212[0m
[93maverage test of epoch 10: loss -20.62917 acc 0.65789 roc_auc 0.72000 prc_auc 0.80842[0m
[92maverage training of epoch 11: loss -21.51583 acc 0.66667 roc_auc 0.35730 prc_auc 0.56188[0m
[93maverage test of epoch 11: loss -22.30000 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 12: loss -23.18982 acc 0.66667 roc_auc 0.35760 prc_auc 0.56296[0m
[93maverage test of epoch 12: loss -23.96768 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 13: loss -24.86094 acc 0.66667 roc_auc 0.35690 prc_auc 0.56296[0m
[93maverage test of epoch 13: loss -25.63277 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 14: loss -26.52973 acc 0.66667 roc_auc 0.35650 prc_auc 0.56206[0m
[93maverage test of epoch 14: loss -27.29577 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 15: loss -28.19660 acc 0.66667 roc_auc 0.35880 prc_auc 0.56512[0m
[93maverage test of epoch 15: loss -28.95703 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 16: loss -29.86188 acc 0.66667 roc_auc 0.35630 prc_auc 0.56459[0m
[93maverage test of epoch 16: loss -30.61685 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 17: loss -31.52583 acc 0.66667 roc_auc 0.35700 prc_auc 0.56751[0m
[93maverage test of epoch 17: loss -32.27546 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 18: loss -33.18866 acc 0.66667 roc_auc 0.36060 prc_auc 0.57540[0m
[93maverage test of epoch 18: loss -33.93305 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -34.85056 acc 0.66667 roc_auc 0.36640 prc_auc 0.57704[0m
[93maverage test of epoch 19: loss -35.58979 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -36.51165 acc 0.66667 roc_auc 0.37280 prc_auc 0.58682[0m
[93maverage test of epoch 20: loss -37.24578 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -38.17207 acc 0.66667 roc_auc 0.36820 prc_auc 0.59566[0m
[93maverage test of epoch 21: loss -38.90116 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -39.83192 acc 0.66667 roc_auc 0.36610 prc_auc 0.59907[0m
[93maverage test of epoch 22: loss -40.55601 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -41.49127 acc 0.66667 roc_auc 0.36060 prc_auc 0.60370[0m
[93maverage test of epoch 23: loss -42.21039 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -43.15019 acc 0.66667 roc_auc 0.42040 prc_auc 0.63037[0m
[93maverage test of epoch 24: loss -43.86438 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -44.80875 acc 0.66667 roc_auc 0.44500 prc_auc 0.64342[0m
[93maverage test of epoch 25: loss -45.51805 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -46.46699 acc 0.66667 roc_auc 0.46000 prc_auc 0.64951[0m
[93maverage test of epoch 26: loss -47.17140 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -48.12495 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 27: loss -48.82451 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -49.78268 acc 0.66667 roc_auc 0.44500 prc_auc 0.64342[0m
[93maverage test of epoch 28: loss -50.47741 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -51.44021 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 29: loss -52.13010 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -53.09755 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 30: loss -53.78263 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -54.75474 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 31: loss -55.43502 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -56.41178 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 32: loss -57.08726 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -58.06870 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 33: loss -58.73939 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -59.72551 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -60.39143 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -61.38223 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -62.04337 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -63.03887 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -63.69524 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -64.69543 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -65.34703 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -66.35191 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -66.99875 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -68.00834 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -68.65043 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -69.66472 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -70.30205 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -71.32104 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -71.95360 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -72.97729 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -73.60508 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -74.63347 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -75.25652 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -76.28961 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -76.90791 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -77.94572 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -78.55927 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -79.60180 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -80.21061 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -81.25786 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -81.86193 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -82.91389 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -83.51322 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -84.56990 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -85.16447 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.003
[92maverage training of epoch 0: loss -2.59207 acc 0.58000 roc_auc 0.42900 prc_auc 0.60063[0m
[93maverage test of epoch 0: loss -4.27569 acc 0.65789 roc_auc 0.79538 prc_auc 0.89566[0m
[92maverage training of epoch 1: loss -5.28924 acc 0.66667 roc_auc 0.41640 prc_auc 0.59616[0m
[93maverage test of epoch 1: loss -6.24600 acc 0.65789 roc_auc 0.79385 prc_auc 0.88533[0m
[92maverage training of epoch 2: loss -7.16487 acc 0.66667 roc_auc 0.42040 prc_auc 0.60512[0m
[93maverage test of epoch 2: loss -8.04604 acc 0.65789 roc_auc 0.88462 prc_auc 0.92169[0m
[92maverage training of epoch 3: loss -8.93729 acc 0.66667 roc_auc 0.42060 prc_auc 0.60505[0m
[93maverage test of epoch 3: loss -9.78733 acc 0.65789 roc_auc 0.86462 prc_auc 0.89079[0m
[92maverage training of epoch 4: loss -10.66848 acc 0.66667 roc_auc 0.42020 prc_auc 0.60463[0m
[93maverage test of epoch 4: loss -11.50057 acc 0.65789 roc_auc 0.82000 prc_auc 0.84667[0m
[92maverage training of epoch 5: loss -12.37804 acc 0.66667 roc_auc 0.42010 prc_auc 0.60455[0m
[93maverage test of epoch 5: loss -13.19754 acc 0.65789 roc_auc 0.71692 prc_auc 0.77697[0m
[92maverage training of epoch 6: loss -14.07436 acc 0.66667 roc_auc 0.42010 prc_auc 0.60455[0m
[93maverage test of epoch 6: loss -14.88396 acc 0.65789 roc_auc 0.79846 prc_auc 0.83587[0m
[92maverage training of epoch 7: loss -15.76181 acc 0.66667 roc_auc 0.42010 prc_auc 0.60455[0m
[93maverage test of epoch 7: loss -16.56303 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 8: loss -17.44292 acc 0.66667 roc_auc 0.42010 prc_auc 0.60455[0m
[93maverage test of epoch 8: loss -18.23675 acc 0.65789 roc_auc 0.82308 prc_auc 0.84667[0m
[92maverage training of epoch 9: loss -19.11935 acc 0.66667 roc_auc 0.42010 prc_auc 0.60497[0m
[93maverage test of epoch 9: loss -19.90642 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 10: loss -20.79219 acc 0.66667 roc_auc 0.42020 prc_auc 0.60497[0m
[93maverage test of epoch 10: loss -21.57296 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 11: loss -22.46222 acc 0.66667 roc_auc 0.42040 prc_auc 0.60509[0m
[93maverage test of epoch 11: loss -23.23700 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 12: loss -24.13001 acc 0.66667 roc_auc 0.42060 prc_auc 0.60532[0m
[93maverage test of epoch 12: loss -24.89906 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 13: loss -25.79599 acc 0.66667 roc_auc 0.42030 prc_auc 0.60438[0m
[93maverage test of epoch 13: loss -26.55949 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 14: loss -27.46049 acc 0.66667 roc_auc 0.42060 prc_auc 0.60523[0m
[93maverage test of epoch 14: loss -28.21859 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 15: loss -29.12378 acc 0.66667 roc_auc 0.42000 prc_auc 0.60464[0m
[93maverage test of epoch 15: loss -29.87658 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 16: loss -30.78604 acc 0.66667 roc_auc 0.42060 prc_auc 0.60466[0m
[93maverage test of epoch 16: loss -31.53364 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 17: loss -32.44745 acc 0.66667 roc_auc 0.42140 prc_auc 0.60611[0m
[93maverage test of epoch 17: loss -33.18994 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 18: loss -34.10816 acc 0.66667 roc_auc 0.42190 prc_auc 0.60641[0m
[93maverage test of epoch 18: loss -34.84558 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -35.76825 acc 0.66667 roc_auc 0.42650 prc_auc 0.60980[0m
[93maverage test of epoch 19: loss -36.50067 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -37.42783 acc 0.66667 roc_auc 0.42910 prc_auc 0.61742[0m
[93maverage test of epoch 20: loss -38.15528 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -39.08697 acc 0.66667 roc_auc 0.42990 prc_auc 0.62100[0m
[93maverage test of epoch 21: loss -39.80948 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -40.74574 acc 0.66667 roc_auc 0.45470 prc_auc 0.64146[0m
[93maverage test of epoch 22: loss -41.46334 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -42.40418 acc 0.66667 roc_auc 0.45660 prc_auc 0.64143[0m
[93maverage test of epoch 23: loss -43.11690 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -44.06234 acc 0.66667 roc_auc 0.44040 prc_auc 0.63796[0m
[93maverage test of epoch 24: loss -44.77020 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -45.72025 acc 0.66667 roc_auc 0.45000 prc_auc 0.64615[0m
[93maverage test of epoch 25: loss -46.42327 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -47.37795 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 26: loss -48.07614 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -49.03547 acc 0.66667 roc_auc 0.44500 prc_auc 0.64443[0m
[93maverage test of epoch 27: loss -49.72885 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -50.69283 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 28: loss -51.38141 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -52.35006 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 29: loss -53.03384 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -54.00716 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 30: loss -54.68616 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -55.66415 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 31: loss -56.33837 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -57.32105 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 32: loss -57.99049 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -58.97785 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 33: loss -59.64252 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -60.63458 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -61.29449 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -62.29124 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -62.94639 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -63.94784 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -64.59822 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -65.60437 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -66.25001 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -67.26086 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -67.90174 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -68.91730 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -69.55342 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -70.57369 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -71.20507 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -72.23005 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -72.85668 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -73.88636 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -74.50824 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -75.54264 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -76.15977 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -77.19887 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -77.81125 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -78.85508 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -79.46272 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -80.51126 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -81.11416 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -82.16740 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -82.76556 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -83.82352 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -84.41694 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -85.47961 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -86.06828 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.003
[92maverage training of epoch 0: loss -0.98324 acc 0.57333 roc_auc 0.43120 prc_auc 0.64113[0m
[93maverage test of epoch 0: loss -2.63973 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 1: loss -4.18387 acc 0.66667 roc_auc 0.39770 prc_auc 0.60718[0m
[93maverage test of epoch 1: loss -5.35458 acc 0.65789 roc_auc 0.95231 prc_auc 0.97791[0m
[92maverage training of epoch 2: loss -6.37616 acc 0.66667 roc_auc 0.38380 prc_auc 0.59336[0m
[93maverage test of epoch 2: loss -7.31232 acc 0.65789 roc_auc 0.95077 prc_auc 0.97663[0m
[92maverage training of epoch 3: loss -8.26408 acc 0.66667 roc_auc 0.37980 prc_auc 0.57757[0m
[93maverage test of epoch 3: loss -9.13935 acc 0.65789 roc_auc 0.93538 prc_auc 0.95662[0m
[92maverage training of epoch 4: loss -10.06464 acc 0.66667 roc_auc 0.37790 prc_auc 0.57529[0m
[93maverage test of epoch 4: loss -10.90879 acc 0.65789 roc_auc 0.86462 prc_auc 0.87965[0m
[92maverage training of epoch 5: loss -11.82174 acc 0.66667 roc_auc 0.37750 prc_auc 0.57480[0m
[93maverage test of epoch 5: loss -12.64588 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 6: loss -13.55289 acc 0.66667 roc_auc 0.37720 prc_auc 0.57449[0m
[93maverage test of epoch 6: loss -14.36238 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 7: loss -15.26689 acc 0.66667 roc_auc 0.37730 prc_auc 0.57487[0m
[93maverage test of epoch 7: loss -16.06476 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 8: loss -16.96880 acc 0.66667 roc_auc 0.37730 prc_auc 0.57547[0m
[93maverage test of epoch 8: loss -17.75692 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 9: loss -18.66183 acc 0.66667 roc_auc 0.37720 prc_auc 0.57741[0m
[93maverage test of epoch 9: loss -19.44142 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 10: loss -20.34811 acc 0.66667 roc_auc 0.37720 prc_auc 0.57674[0m
[93maverage test of epoch 10: loss -21.12004 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 11: loss -22.02913 acc 0.66667 roc_auc 0.37660 prc_auc 0.57928[0m
[93maverage test of epoch 11: loss -22.79401 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 12: loss -23.70599 acc 0.66667 roc_auc 0.37770 prc_auc 0.57468[0m
[93maverage test of epoch 12: loss -24.46428 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 13: loss -25.37950 acc 0.66667 roc_auc 0.37820 prc_auc 0.58000[0m
[93maverage test of epoch 13: loss -26.13155 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 14: loss -27.05028 acc 0.66667 roc_auc 0.37690 prc_auc 0.58124[0m
[93maverage test of epoch 14: loss -27.79636 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 15: loss -28.71881 acc 0.66667 roc_auc 0.38740 prc_auc 0.59286[0m
[93maverage test of epoch 15: loss -29.45914 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 16: loss -30.38549 acc 0.66667 roc_auc 0.38120 prc_auc 0.58924[0m
[93maverage test of epoch 16: loss -31.12023 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 17: loss -32.05061 acc 0.66667 roc_auc 0.39440 prc_auc 0.60082[0m
[93maverage test of epoch 17: loss -32.77992 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 18: loss -33.71444 acc 0.66667 roc_auc 0.38900 prc_auc 0.60504[0m
[93maverage test of epoch 18: loss -34.43841 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -35.37716 acc 0.66667 roc_auc 0.43280 prc_auc 0.63235[0m
[93maverage test of epoch 19: loss -36.09590 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -37.03897 acc 0.66667 roc_auc 0.44150 prc_auc 0.63849[0m
[93maverage test of epoch 20: loss -37.75255 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -38.69999 acc 0.66667 roc_auc 0.47000 prc_auc 0.65366[0m
[93maverage test of epoch 21: loss -39.40847 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -40.36033 acc 0.66667 roc_auc 0.48000 prc_auc 0.65792[0m
[93maverage test of epoch 22: loss -41.06377 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -42.02010 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 23: loss -42.71854 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -43.67937 acc 0.66667 roc_auc 0.47500 prc_auc 0.65578[0m
[93maverage test of epoch 24: loss -44.37286 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -45.33823 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 25: loss -46.02679 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -46.99672 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 26: loss -47.68037 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -48.65489 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 27: loss -49.33367 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -50.31279 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 28: loss -50.98671 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -51.97046 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 29: loss -52.63954 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -53.62791 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 30: loss -54.29216 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -55.28519 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 31: loss -55.94463 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -56.94230 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 32: loss -57.59693 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -58.59928 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 33: loss -59.24912 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -60.25613 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -60.90119 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -61.91288 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -62.55315 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -63.56953 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -64.20503 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -65.22610 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -65.85683 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -66.88259 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -67.50854 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -68.53900 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -69.16018 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -70.19535 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -70.81179 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -71.85166 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -72.46334 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -73.50792 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -74.11484 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -75.16412 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -75.76630 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -76.82028 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -77.41771 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -78.47641 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -79.06910 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -80.13250 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -80.72043 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -81.78855 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -82.37172 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -83.44456 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -84.02298 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -85.10052 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -85.67419 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.003
[92maverage training of epoch 0: loss -0.70025 acc 0.56954 roc_auc 0.55941 prc_auc 0.68778[0m
[93maverage test of epoch 0: loss -1.65381 acc 0.32432 roc_auc 0.86000 prc_auc 0.92243[0m
[92maverage training of epoch 1: loss -2.65908 acc 0.62252 roc_auc 0.80118 prc_auc 0.86845[0m
[93maverage test of epoch 1: loss -3.52432 acc 0.62162 roc_auc 0.85667 prc_auc 0.91780[0m
[92maverage training of epoch 2: loss -4.48588 acc 0.87417 roc_auc 0.83039 prc_auc 0.85254[0m
[93maverage test of epoch 2: loss -5.35988 acc 0.86486 roc_auc 0.83333 prc_auc 0.86831[0m
[92maverage training of epoch 3: loss -6.17071 acc 0.85430 roc_auc 0.82980 prc_auc 0.83940[0m
[93maverage test of epoch 3: loss -7.00294 acc 0.86486 roc_auc 0.81167 prc_auc 0.86344[0m
[92maverage training of epoch 4: loss -7.80537 acc 0.86755 roc_auc 0.83353 prc_auc 0.83988[0m
[93maverage test of epoch 4: loss -8.53831 acc 0.81081 roc_auc 0.80333 prc_auc 0.84300[0m
[92maverage training of epoch 5: loss -9.40348 acc 0.86755 roc_auc 0.83196 prc_auc 0.84098[0m
[93maverage test of epoch 5: loss -10.15943 acc 0.81081 roc_auc 0.82667 prc_auc 0.87133[0m
[92maverage training of epoch 6: loss -10.85848 acc 0.83444 roc_auc 0.83392 prc_auc 0.87003[0m
[93maverage test of epoch 6: loss -11.60576 acc 0.83784 roc_auc 0.84833 prc_auc 0.89353[0m
[92maverage training of epoch 7: loss -12.55078 acc 0.88079 roc_auc 0.83706 prc_auc 0.84265[0m
[93maverage test of epoch 7: loss -13.27426 acc 0.81081 roc_auc 0.85000 prc_auc 0.89209[0m
[92maverage training of epoch 8: loss -13.96223 acc 0.83444 roc_auc 0.84549 prc_auc 0.87492[0m
[93maverage test of epoch 8: loss -14.79486 acc 0.86486 roc_auc 0.85000 prc_auc 0.89845[0m
[92maverage training of epoch 9: loss -15.66978 acc 0.88742 roc_auc 0.83637 prc_auc 0.84329[0m
[93maverage test of epoch 9: loss -16.41145 acc 0.81081 roc_auc 0.85000 prc_auc 0.89209[0m
[92maverage training of epoch 10: loss -17.22743 acc 0.87417 roc_auc 0.83637 prc_auc 0.85209[0m
[93maverage test of epoch 10: loss -18.00424 acc 0.86486 roc_auc 0.85000 prc_auc 0.89392[0m
[92maverage training of epoch 11: loss -18.78952 acc 0.87417 roc_auc 0.83608 prc_auc 0.85262[0m
[93maverage test of epoch 11: loss -19.55480 acc 0.86486 roc_auc 0.85667 prc_auc 0.89811[0m
[92maverage training of epoch 12: loss -20.35211 acc 0.88742 roc_auc 0.83529 prc_auc 0.85231[0m
[93maverage test of epoch 12: loss -21.10292 acc 0.86486 roc_auc 0.85333 prc_auc 0.89266[0m
[92maverage training of epoch 13: loss -21.90669 acc 0.88742 roc_auc 0.83725 prc_auc 0.85669[0m
[93maverage test of epoch 13: loss -22.68354 acc 0.86486 roc_auc 0.86000 prc_auc 0.89895[0m
[92maverage training of epoch 14: loss -23.44768 acc 0.88742 roc_auc 0.84569 prc_auc 0.86867[0m
[93maverage test of epoch 14: loss -24.24380 acc 0.86486 roc_auc 0.82500 prc_auc 0.86718[0m
[92maverage training of epoch 15: loss -25.00516 acc 0.88742 roc_auc 0.84863 prc_auc 0.86934[0m
[93maverage test of epoch 15: loss -25.79081 acc 0.86486 roc_auc 0.86000 prc_auc 0.89914[0m
[92maverage training of epoch 16: loss -26.56682 acc 0.89404 roc_auc 0.85431 prc_auc 0.88154[0m
[93maverage test of epoch 16: loss -27.33830 acc 0.86486 roc_auc 0.82500 prc_auc 0.86718[0m
[92maverage training of epoch 17: loss -28.12791 acc 0.89404 roc_auc 0.85373 prc_auc 0.88520[0m
[93maverage test of epoch 17: loss -28.87830 acc 0.86486 roc_auc 0.82500 prc_auc 0.86718[0m
[92maverage training of epoch 18: loss -29.68123 acc 0.89404 roc_auc 0.88775 prc_auc 0.92252[0m
[93maverage test of epoch 18: loss -30.42035 acc 0.86486 roc_auc 0.86333 prc_auc 0.89914[0m
[92maverage training of epoch 19: loss -31.25310 acc 0.90066 roc_auc 0.88431 prc_auc 0.91932[0m
[93maverage test of epoch 19: loss -31.97873 acc 0.86486 roc_auc 0.83833 prc_auc 0.87636[0m
[92maverage training of epoch 20: loss -32.82040 acc 0.90066 roc_auc 0.88608 prc_auc 0.92105[0m
[93maverage test of epoch 20: loss -33.52506 acc 0.86486 roc_auc 0.83833 prc_auc 0.87636[0m
[92maverage training of epoch 21: loss -34.30893 acc 0.90066 roc_auc 0.87755 prc_auc 0.91211[0m
[93maverage test of epoch 21: loss -35.07125 acc 0.86486 roc_auc 0.83833 prc_auc 0.87636[0m
[92maverage training of epoch 22: loss -35.95279 acc 0.90066 roc_auc 0.87843 prc_auc 0.91284[0m
[93maverage test of epoch 22: loss -36.61984 acc 0.86486 roc_auc 0.83500 prc_auc 0.87526[0m
[92maverage training of epoch 23: loss -37.49818 acc 0.90066 roc_auc 0.87882 prc_auc 0.91300[0m
[93maverage test of epoch 23: loss -38.15978 acc 0.86486 roc_auc 0.83500 prc_auc 0.87526[0m
[92maverage training of epoch 24: loss -39.05226 acc 0.89404 roc_auc 0.87863 prc_auc 0.91292[0m
[93maverage test of epoch 24: loss -39.69115 acc 0.86486 roc_auc 0.83500 prc_auc 0.87526[0m
[92maverage training of epoch 25: loss -40.60349 acc 0.89404 roc_auc 0.87863 prc_auc 0.91293[0m
[93maverage test of epoch 25: loss -41.21281 acc 0.86486 roc_auc 0.83167 prc_auc 0.87442[0m
[92maverage training of epoch 26: loss -42.16980 acc 0.89404 roc_auc 0.87882 prc_auc 0.91297[0m
[93maverage test of epoch 26: loss -42.78224 acc 0.86486 roc_auc 0.83167 prc_auc 0.87442[0m
[92maverage training of epoch 27: loss -43.77228 acc 0.90728 roc_auc 0.87990 prc_auc 0.91378[0m
[93maverage test of epoch 27: loss -44.23040 acc 0.86486 roc_auc 0.83167 prc_auc 0.87442[0m
[92maverage training of epoch 28: loss -45.29171 acc 0.89404 roc_auc 0.88078 prc_auc 0.91443[0m
[93maverage test of epoch 28: loss -45.87930 acc 0.86486 roc_auc 0.83500 prc_auc 0.87526[0m
[92maverage training of epoch 29: loss -46.89392 acc 0.90728 roc_auc 0.88078 prc_auc 0.91448[0m
[93maverage test of epoch 29: loss -47.43189 acc 0.86486 roc_auc 0.83167 prc_auc 0.87442[0m
[92maverage training of epoch 30: loss -48.37026 acc 0.89404 roc_auc 0.87951 prc_auc 0.91402[0m
[93maverage test of epoch 30: loss -48.95510 acc 0.86486 roc_auc 0.83333 prc_auc 0.87442[0m
[92maverage training of epoch 31: loss -49.98609 acc 0.90066 roc_auc 0.88069 prc_auc 0.91447[0m
[93maverage test of epoch 31: loss -50.41768 acc 0.83784 roc_auc 0.82833 prc_auc 0.87326[0m
[92maverage training of epoch 32: loss -51.51948 acc 0.89404 roc_auc 0.87137 prc_auc 0.90583[0m
[93maverage test of epoch 32: loss -52.00290 acc 0.86486 roc_auc 0.83167 prc_auc 0.87423[0m
[92maverage training of epoch 33: loss -53.09830 acc 0.90066 roc_auc 0.88039 prc_auc 0.91434[0m
[93maverage test of epoch 33: loss -53.53946 acc 0.86486 roc_auc 0.82833 prc_auc 0.87339[0m
[92maverage training of epoch 34: loss -54.66785 acc 0.90066 roc_auc 0.88059 prc_auc 0.91443[0m
[93maverage test of epoch 34: loss -55.07757 acc 0.86486 roc_auc 0.82833 prc_auc 0.87339[0m
[92maverage training of epoch 35: loss -56.23519 acc 0.90066 roc_auc 0.88059 prc_auc 0.91443[0m
[93maverage test of epoch 35: loss -56.62654 acc 0.86486 roc_auc 0.82833 prc_auc 0.87339[0m
[92maverage training of epoch 36: loss -57.79610 acc 0.90066 roc_auc 0.88059 prc_auc 0.91443[0m
[93maverage test of epoch 36: loss -58.17793 acc 0.86486 roc_auc 0.82833 prc_auc 0.87326[0m
[92maverage training of epoch 37: loss -59.35033 acc 0.90066 roc_auc 0.88147 prc_auc 0.91516[0m
[93maverage test of epoch 37: loss -59.72601 acc 0.86486 roc_auc 0.82833 prc_auc 0.87326[0m
[92maverage training of epoch 38: loss -60.90586 acc 0.90066 roc_auc 0.88147 prc_auc 0.91516[0m
[93maverage test of epoch 38: loss -61.27236 acc 0.86486 roc_auc 0.83167 prc_auc 0.87415[0m
[92maverage training of epoch 39: loss -62.46242 acc 0.90066 roc_auc 0.88147 prc_auc 0.91516[0m
[93maverage test of epoch 39: loss -62.81495 acc 0.86486 roc_auc 0.83167 prc_auc 0.87415[0m
[92maverage training of epoch 40: loss -64.01105 acc 0.90066 roc_auc 0.88147 prc_auc 0.91516[0m
[93maverage test of epoch 40: loss -64.34243 acc 0.86486 roc_auc 0.83167 prc_auc 0.87415[0m
[92maverage training of epoch 41: loss -65.55767 acc 0.90066 roc_auc 0.88059 prc_auc 0.91443[0m
[93maverage test of epoch 41: loss -65.87517 acc 0.86486 roc_auc 0.83167 prc_auc 0.87423[0m
[92maverage training of epoch 42: loss -67.24995 acc 0.91391 roc_auc 0.89980 prc_auc 0.93245[0m
[93maverage test of epoch 42: loss -65.49770 acc 0.81081 roc_auc 0.80667 prc_auc 0.85513[0m
[92maverage training of epoch 43: loss -68.87197 acc 0.92053 roc_auc 0.90902 prc_auc 0.94141[0m
[93maverage test of epoch 43: loss -68.63688 acc 0.86486 roc_auc 0.83833 prc_auc 0.87473[0m
[92maverage training of epoch 44: loss -70.56612 acc 0.92715 roc_auc 0.90980 prc_auc 0.94192[0m
[93maverage test of epoch 44: loss -70.29332 acc 0.86486 roc_auc 0.83833 prc_auc 0.87526[0m
[92maverage training of epoch 45: loss -72.03190 acc 0.91391 roc_auc 0.90059 prc_auc 0.93279[0m
[93maverage test of epoch 45: loss -70.17786 acc 0.81081 roc_auc 0.82167 prc_auc 0.86101[0m
[92maverage training of epoch 46: loss -73.73719 acc 0.92715 roc_auc 0.91020 prc_auc 0.94207[0m
[93maverage test of epoch 46: loss -71.52607 acc 0.81081 roc_auc 0.82500 prc_auc 0.86212[0m
[92maverage training of epoch 47: loss -75.34921 acc 0.92715 roc_auc 0.91020 prc_auc 0.94213[0m
[93maverage test of epoch 47: loss -73.89425 acc 0.83784 roc_auc 0.83667 prc_auc 0.86994[0m
[92maverage training of epoch 48: loss -76.91556 acc 0.92715 roc_auc 0.91098 prc_auc 0.94240[0m
[93maverage test of epoch 48: loss -75.53886 acc 0.86486 roc_auc 0.83500 prc_auc 0.86899[0m
[92maverage training of epoch 49: loss -78.51436 acc 0.92715 roc_auc 0.91118 prc_auc 0.94271[0m
[93maverage test of epoch 49: loss -77.22881 acc 0.86486 roc_auc 0.83167 prc_auc 0.86899[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.003
[92maverage training of epoch 0: loss -1.55656 acc 0.66225 roc_auc 0.39961 prc_auc 0.60512[0m
[93maverage test of epoch 0: loss -2.68451 acc 0.67568 roc_auc 0.92667 prc_auc 0.97104[0m
[92maverage training of epoch 1: loss -3.64133 acc 0.66225 roc_auc 0.37667 prc_auc 0.57828[0m
[93maverage test of epoch 1: loss -4.65308 acc 0.67568 roc_auc 0.92500 prc_auc 0.96822[0m
[92maverage training of epoch 2: loss -5.49997 acc 0.66225 roc_auc 0.37216 prc_auc 0.56973[0m
[93maverage test of epoch 2: loss -6.45317 acc 0.67568 roc_auc 0.93333 prc_auc 0.96875[0m
[92maverage training of epoch 3: loss -7.26338 acc 0.66225 roc_auc 0.37098 prc_auc 0.56897[0m
[93maverage test of epoch 3: loss -8.20213 acc 0.67568 roc_auc 0.92667 prc_auc 0.95690[0m
[92maverage training of epoch 4: loss -8.99179 acc 0.66225 roc_auc 0.37039 prc_auc 0.56848[0m
[93maverage test of epoch 4: loss -9.92691 acc 0.67568 roc_auc 0.94667 prc_auc 0.96121[0mUsing backend: pytorch
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))

[92maverage training of epoch 5: loss -10.70177 acc 0.66225 roc_auc 0.37000 prc_auc 0.56830[0m
[93maverage test of epoch 5: loss -11.63759 acc 0.67568 roc_auc 0.79333 prc_auc 0.83776[0m
[92maverage training of epoch 6: loss -12.40039 acc 0.66225 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 6: loss -13.33907 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 7: loss -14.09132 acc 0.66225 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 7: loss -15.03411 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 8: loss -15.77676 acc 0.66225 roc_auc 0.36980 prc_auc 0.56863[0m
[93maverage test of epoch 8: loss -16.72445 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 9: loss -17.45812 acc 0.66225 roc_auc 0.36990 prc_auc 0.56829[0m
[93maverage test of epoch 9: loss -18.41122 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 10: loss -19.13634 acc 0.66225 roc_auc 0.36990 prc_auc 0.56873[0m
[93maverage test of epoch 10: loss -20.09523 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 11: loss -20.81210 acc 0.66225 roc_auc 0.36980 prc_auc 0.56880[0m
[93maverage test of epoch 11: loss -21.77705 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 12: loss -22.48589 acc 0.66225 roc_auc 0.36990 prc_auc 0.56946[0m
[93maverage test of epoch 12: loss -23.45710 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 13: loss -24.15810 acc 0.66225 roc_auc 0.37039 prc_auc 0.56987[0m
[93maverage test of epoch 13: loss -25.13572 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 14: loss -25.82902 acc 0.66225 roc_auc 0.36931 prc_auc 0.57178[0m
[93maverage test of epoch 14: loss -26.81316 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 15: loss -27.49885 acc 0.66225 roc_auc 0.36951 prc_auc 0.56918[0m
[93maverage test of epoch 15: loss -28.48962 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 16: loss -29.16780 acc 0.66225 roc_auc 0.36843 prc_auc 0.56973[0m
[93maverage test of epoch 16: loss -30.16527 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 17: loss -30.83601 acc 0.66225 roc_auc 0.36608 prc_auc 0.56769[0m
[93maverage test of epoch 17: loss -31.84023 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 18: loss -32.50358 acc 0.66225 roc_auc 0.36647 prc_auc 0.56974[0m
[93maverage test of epoch 18: loss -33.51461 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 19: loss -34.17062 acc 0.66225 roc_auc 0.37225 prc_auc 0.58566[0m
[93maverage test of epoch 19: loss -35.18851 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 20: loss -35.83721 acc 0.66225 roc_auc 0.36627 prc_auc 0.57790[0m
[93maverage test of epoch 20: loss -36.86199 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 21: loss -37.50341 acc 0.66225 roc_auc 0.38961 prc_auc 0.59747[0m
[93maverage test of epoch 21: loss -38.53511 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 22: loss -39.16929 acc 0.66225 roc_auc 0.38127 prc_auc 0.59914[0m
[93maverage test of epoch 22: loss -40.20792 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 23: loss -40.83487 acc 0.66225 roc_auc 0.43422 prc_auc 0.63221[0m
[93maverage test of epoch 23: loss -41.88045 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 24: loss -42.50021 acc 0.66225 roc_auc 0.41814 prc_auc 0.62455[0m
[93maverage test of epoch 24: loss -43.55277 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 25: loss -44.16534 acc 0.66225 roc_auc 0.43608 prc_auc 0.63602[0m
[93maverage test of epoch 25: loss -45.22490 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 26: loss -45.83028 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 26: loss -46.89684 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 27: loss -47.49506 acc 0.66225 roc_auc 0.41108 prc_auc 0.62735[0m
[93maverage test of epoch 27: loss -48.56863 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 28: loss -49.15970 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 28: loss -50.24029 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 29: loss -50.82421 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 29: loss -51.91183 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 30: loss -52.48860 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 30: loss -53.58326 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 31: loss -54.15291 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 31: loss -55.25460 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 32: loss -55.81711 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 32: loss -56.92587 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 33: loss -57.48125 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 33: loss -58.59705 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 34: loss -59.14532 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 34: loss -60.26817 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 35: loss -60.80932 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 35: loss -61.93924 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 36: loss -62.47327 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 36: loss -63.61024 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 37: loss -64.13717 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 37: loss -65.28120 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 38: loss -65.80102 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 38: loss -66.95212 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 39: loss -67.46482 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 39: loss -68.62299 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -69.12858 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 40: loss -70.29381 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -70.79229 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 41: loss -71.96459 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -72.45596 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 42: loss -73.63534 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -74.11960 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 43: loss -75.30605 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -75.78320 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 44: loss -76.97672 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -77.44677 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 45: loss -78.64736 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -79.11031 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 46: loss -80.31797 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -80.77382 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 47: loss -81.98854 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -82.43728 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 48: loss -83.65908 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -84.10072 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 49: loss -85.32960 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.70284 ROC_AUC (avg): 0.56633 PRC_AUC (avg): 0.70367 

Average forward propagation time taken(ms): 2.476802573071887
Average backward propagation time taken(ms): 0.871509992227978

