# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 1)
('lr', 0.0003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-03-01-20/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-03-01-20/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 16,
 'epochs': 100,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 4,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.0003,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 1,
 'num_workers': 8,
 'number_of_mlp_layer': 1,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-18-03-01-20',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 100, 'learning_rate': 0.0003, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.57079 acc 0.66667 roc_auc 0.43000 prc_auc 0.64159[0m
[93maverage test of epoch 0: loss -0.91760 acc 0.65789 roc_auc 0.77538 prc_auc 0.89964[0m
[92maverage training of epoch 1: loss -1.27511 acc 0.66667 roc_auc 0.44720 prc_auc 0.66793[0m
[93maverage test of epoch 1: loss -1.58955 acc 0.65789 roc_auc 0.89231 prc_auc 0.94250[0m
[92maverage training of epoch 2: loss -1.95925 acc 0.66667 roc_auc 0.47480 prc_auc 0.68877[0m
[93maverage test of epoch 2: loss -2.32380 acc 0.65789 roc_auc 0.86154 prc_auc 0.93235[0m
[92maverage training of epoch 3: loss -2.72191 acc 0.66667 roc_auc 0.47640 prc_auc 0.67853[0m
[93maverage test of epoch 3: loss -3.04916 acc 0.65789 roc_auc 0.85846 prc_auc 0.93142[0m
[92maverage training of epoch 4: loss -3.43982 acc 0.66667 roc_auc 0.44900 prc_auc 0.66137[0m
[93maverage test of epoch 4: loss -3.88895 acc 0.65789 roc_auc 0.85846 prc_auc 0.93153[0m
[92maverage training of epoch 5: loss -4.47068 acc 0.66667 roc_auc 0.43760 prc_auc 0.65186[0m
[93maverage test of epoch 5: loss -4.96344 acc 0.65789 roc_auc 0.85846 prc_auc 0.93142[0m
[92maverage training of epoch 6: loss -5.49702 acc 0.66667 roc_auc 0.43120 prc_auc 0.64414[0m
[93maverage test of epoch 6: loss -5.93834 acc 0.65789 roc_auc 0.85692 prc_auc 0.93097[0m
[92maverage training of epoch 7: loss -6.44179 acc 0.66667 roc_auc 0.42820 prc_auc 0.63913[0m
[93maverage test of epoch 7: loss -6.85544 acc 0.65789 roc_auc 0.86000 prc_auc 0.93165[0m
[92maverage training of epoch 8: loss -7.35028 acc 0.66667 roc_auc 0.42740 prc_auc 0.63879[0m
[93maverage test of epoch 8: loss -7.75377 acc 0.65789 roc_auc 0.86462 prc_auc 0.93299[0m
[92maverage training of epoch 9: loss -8.25072 acc 0.66667 roc_auc 0.42660 prc_auc 0.63800[0m
[93maverage test of epoch 9: loss -8.65303 acc 0.65789 roc_auc 0.86462 prc_auc 0.89714[0m
[92maverage training of epoch 10: loss -9.15801 acc 0.66667 roc_auc 0.42570 prc_auc 0.63678[0m
[93maverage test of epoch 10: loss -9.56404 acc 0.65789 roc_auc 0.85231 prc_auc 0.88546[0m
[92maverage training of epoch 11: loss -10.08055 acc 0.66667 roc_auc 0.42330 prc_auc 0.63494[0m
[93maverage test of epoch 11: loss -10.49314 acc 0.65789 roc_auc 0.76769 prc_auc 0.81510[0m
[92maverage training of epoch 12: loss -11.02307 acc 0.66667 roc_auc 0.42240 prc_auc 0.63459[0m
[93maverage test of epoch 12: loss -11.44281 acc 0.65789 roc_auc 0.61538 prc_auc 0.71429[0m
[92maverage training of epoch 13: loss -11.98486 acc 0.66667 roc_auc 0.42190 prc_auc 0.63434[0m
[93maverage test of epoch 13: loss -12.41100 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 14: loss -12.96653 acc 0.66667 roc_auc 0.42140 prc_auc 0.63403[0m
[93maverage test of epoch 14: loss -13.40050 acc 0.65789 roc_auc 0.72154 prc_auc 0.79865[0m
[92maverage training of epoch 15: loss -13.97074 acc 0.66667 roc_auc 0.42040 prc_auc 0.62787[0m
[93maverage test of epoch 15: loss -14.41316 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 16: loss -14.99823 acc 0.66667 roc_auc 0.41990 prc_auc 0.62754[0m
[93maverage test of epoch 16: loss -15.44896 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 17: loss -16.04963 acc 0.66667 roc_auc 0.42040 prc_auc 0.62457[0m
[93maverage test of epoch 17: loss -16.50932 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 18: loss -17.12630 acc 0.66667 roc_auc 0.41790 prc_auc 0.62224[0m
[93maverage test of epoch 18: loss -17.59545 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -18.22930 acc 0.66667 roc_auc 0.41780 prc_auc 0.62136[0m
[93maverage test of epoch 19: loss -18.70824 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -19.35943 acc 0.66667 roc_auc 0.41770 prc_auc 0.62105[0m
[93maverage test of epoch 20: loss -19.84842 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -20.51732 acc 0.66667 roc_auc 0.41720 prc_auc 0.61952[0m
[93maverage test of epoch 21: loss -21.01654 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -21.70347 acc 0.66667 roc_auc 0.41470 prc_auc 0.61753[0m
[93maverage test of epoch 22: loss -22.21305 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -22.91827 acc 0.66667 roc_auc 0.41050 prc_auc 0.61530[0m
[93maverage test of epoch 23: loss -23.43829 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -24.16204 acc 0.66667 roc_auc 0.42070 prc_auc 0.62582[0m
[93maverage test of epoch 24: loss -24.69254 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -25.43504 acc 0.66667 roc_auc 0.41120 prc_auc 0.62221[0m
[93maverage test of epoch 25: loss -25.97605 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -26.73747 acc 0.66667 roc_auc 0.42600 prc_auc 0.63980[0m
[93maverage test of epoch 26: loss -27.28899 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -28.06950 acc 0.66667 roc_auc 0.40740 prc_auc 0.62238[0m
[93maverage test of epoch 27: loss -28.63151 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -29.43124 acc 0.66667 roc_auc 0.48220 prc_auc 0.65986[0m
[93maverage test of epoch 28: loss -30.00367 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -30.82197 acc 0.66667 roc_auc 0.42500 prc_auc 0.63772[0m
[93maverage test of epoch 29: loss -31.40332 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -32.23961 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 30: loss -32.82958 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -33.68413 acc 0.66667 roc_auc 0.40000 prc_auc 0.62886[0m
[93maverage test of epoch 31: loss -34.28285 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -35.15592 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 32: loss -35.76351 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -36.65532 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 33: loss -37.27187 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -38.18263 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -38.80819 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -39.73810 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -40.37270 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -41.32194 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -41.96561 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -42.93434 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -43.58709 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -44.57546 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -45.23727 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -46.24583 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -46.92391 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -48.06613 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -48.89693 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -50.10589 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -50.95866 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -52.18923 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -53.05265 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -54.30790 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -55.18390 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -56.46514 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -57.35459 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -58.66270 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -59.56608 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -60.90170 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -61.81925 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -63.18271 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -64.11461 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -65.50620 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -66.45241 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -67.87255 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -68.83332 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 50: loss -70.28238 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 50: loss -71.25765 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 51: loss -72.73572 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 51: loss -73.72546 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 52: loss -75.23294 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 52: loss -76.23726 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 53: loss -77.77440 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 53: loss -78.79325 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 54: loss -80.36020 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 54: loss -81.39338 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 55: loss -82.99019 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 55: loss -84.03768 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 56: loss -85.66445 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 56: loss -86.72526 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 57: loss -88.37962 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 57: loss -89.45188 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 58: loss -91.13412 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 58: loss -92.21818 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 59: loss -93.92886 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 59: loss -95.02508 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 60: loss -96.76482 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 60: loss -97.87354 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 61: loss -99.64280 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 61: loss -100.76417 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 62: loss -102.56328 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 62: loss -103.69744 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 63: loss -105.52675 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 63: loss -106.67378 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 64: loss -108.53358 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 64: loss -109.69350 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 65: loss -111.58388 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 65: loss -112.75608 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 66: loss -114.67621 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 66: loss -115.85987 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 67: loss -117.81020 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 67: loss -119.00557 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 68: loss -120.98641 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 68: loss -122.19352 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 69: loss -124.20516 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 69: loss -125.42407 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 70: loss -127.46675 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 70: loss -128.69743 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 71: loss -130.77139 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 71: loss -132.01386 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 72: loss -134.11934 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 72: loss -135.37356 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 73: loss -137.51075 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 73: loss -138.77670 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 74: loss -140.94580 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 74: loss -142.22339 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 75: loss -144.42460 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 75: loss -145.71379 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 76: loss -147.94727 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 76: loss -149.24801 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 77: loss -151.51395 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 77: loss -152.82613 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 78: loss -155.12470 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 78: loss -156.44825 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 79: loss -158.77962 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 79: loss -160.11443 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 80: loss -162.47875 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 80: loss -163.82477 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 81: loss -166.22218 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 81: loss -167.57926 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 82: loss -170.00994 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 82: loss -171.37800 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 83: loss -173.84209 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 83: loss -175.22102 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 84: loss -177.71866 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 84: loss -179.10836 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 85: loss -181.63969 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 85: loss -183.04003 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 86: loss -185.60522 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 86: loss -187.01613 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 87: loss -189.61526 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 87: loss -191.03662 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 88: loss -193.66992 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 88: loss -195.10156 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 89: loss -197.76905 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 89: loss -199.21092 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -201.91286 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 90: loss -203.36487 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 91: loss -206.10124 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 91: loss -207.56309 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 92: loss -210.33417 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 92: loss -211.80592 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 93: loss -214.61183 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 93: loss -216.09338 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 94: loss -218.93426 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 94: loss -220.42543 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 95: loss -223.30120 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 95: loss -224.80171 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 96: loss -227.71271 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 96: loss -229.22261 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 97: loss -232.16896 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 97: loss -233.68810 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 98: loss -236.66994 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 98: loss -238.19817 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -241.21564 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 99: loss -242.75289 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.22384 acc 0.66667 roc_auc 0.45300 prc_auc 0.63494[0m
[93maverage test of epoch 0: loss -0.34524 acc 0.65789 roc_auc 0.14769 prc_auc 0.49538[0m
[92maverage training of epoch 1: loss -0.48679 acc 0.66667 roc_auc 0.46100 prc_auc 0.63999[0m
[93maverage test of epoch 1: loss -0.62221 acc 0.65789 roc_auc 0.63692 prc_auc 0.84605[0m
[92maverage training of epoch 2: loss -0.78107 acc 0.66667 roc_auc 0.46980 prc_auc 0.65651[0m
[93maverage test of epoch 2: loss -0.96616 acc 0.65789 roc_auc 0.89846 prc_auc 0.94428[0m
[92maverage training of epoch 3: loss -1.30355 acc 0.66667 roc_auc 0.47760 prc_auc 0.66123[0m
[93maverage test of epoch 3: loss -1.64888 acc 0.65789 roc_auc 0.90154 prc_auc 0.94336[0m
[92maverage training of epoch 4: loss -1.89007 acc 0.66667 roc_auc 0.47220 prc_auc 0.65266[0m
[93maverage test of epoch 4: loss -2.11263 acc 0.65789 roc_auc 0.90154 prc_auc 0.94607[0m
[92maverage training of epoch 5: loss -2.33086 acc 0.66667 roc_auc 0.46800 prc_auc 0.64900[0m
[93maverage test of epoch 5: loss -2.53944 acc 0.65789 roc_auc 0.89692 prc_auc 0.94035[0m
[92maverage training of epoch 6: loss -2.75541 acc 0.66667 roc_auc 0.46440 prc_auc 0.64627[0m
[93maverage test of epoch 6: loss -2.96213 acc 0.65789 roc_auc 0.89077 prc_auc 0.93598[0m
[92maverage training of epoch 7: loss -3.18059 acc 0.66667 roc_auc 0.46140 prc_auc 0.64388[0m
[93maverage test of epoch 7: loss -3.38880 acc 0.65789 roc_auc 0.89385 prc_auc 0.93645[0m
[92maverage training of epoch 8: loss -3.61181 acc 0.66667 roc_auc 0.46080 prc_auc 0.64329[0m
[93maverage test of epoch 8: loss -3.82319 acc 0.65789 roc_auc 0.88923 prc_auc 0.93543[0m
[92maverage training of epoch 9: loss -4.05184 acc 0.66667 roc_auc 0.45900 prc_auc 0.64199[0m
[93maverage test of epoch 9: loss -4.26665 acc 0.65789 roc_auc 0.89538 prc_auc 0.93407[0m
[92maverage training of epoch 10: loss -4.49956 acc 0.66667 roc_auc 0.45700 prc_auc 0.64015[0m
[93maverage test of epoch 10: loss -4.71661 acc 0.65789 roc_auc 0.89231 prc_auc 0.93175[0m
[92maverage training of epoch 11: loss -4.95447 acc 0.66667 roc_auc 0.45680 prc_auc 0.64001[0m
[93maverage test of epoch 11: loss -5.17484 acc 0.65789 roc_auc 0.88769 prc_auc 0.92627[0m
[92maverage training of epoch 12: loss -5.41867 acc 0.66667 roc_auc 0.45620 prc_auc 0.63974[0m
[93maverage test of epoch 12: loss -5.64323 acc 0.65789 roc_auc 0.88923 prc_auc 0.92303[0m
[92maverage training of epoch 13: loss -5.89376 acc 0.66667 roc_auc 0.45600 prc_auc 0.63851[0m
[93maverage test of epoch 13: loss -6.12310 acc 0.65789 roc_auc 0.88462 prc_auc 0.92089[0m
[92maverage training of epoch 14: loss -6.38083 acc 0.66667 roc_auc 0.45560 prc_auc 0.63832[0m
[93maverage test of epoch 14: loss -6.61536 acc 0.65789 roc_auc 0.87692 prc_auc 0.90380[0m
[92maverage training of epoch 15: loss -6.88068 acc 0.66667 roc_auc 0.45560 prc_auc 0.63832[0m
[93maverage test of epoch 15: loss -7.12068 acc 0.65789 roc_auc 0.89077 prc_auc 0.92425[0m
[92maverage training of epoch 16: loss -7.39383 acc 0.66667 roc_auc 0.45530 prc_auc 0.63720[0m
[93maverage test of epoch 16: loss -7.63925 acc 0.65789 roc_auc 0.88308 prc_auc 0.91520[0m
[92maverage training of epoch 17: loss -7.91961 acc 0.66667 roc_auc 0.45520 prc_auc 0.63732[0m
[93maverage test of epoch 17: loss -8.16969 acc 0.65789 roc_auc 0.88000 prc_auc 0.90094[0m
[92maverage training of epoch 18: loss -8.45731 acc 0.66667 roc_auc 0.45520 prc_auc 0.63732[0m
[93maverage test of epoch 18: loss -8.71223 acc 0.65789 roc_auc 0.86462 prc_auc 0.89079[0m
[92maverage training of epoch 19: loss -9.00738 acc 0.66667 roc_auc 0.45530 prc_auc 0.63732[0m
[93maverage test of epoch 19: loss -9.26733 acc 0.65789 roc_auc 0.86615 prc_auc 0.89070[0m
[92maverage training of epoch 20: loss -9.57022 acc 0.66667 roc_auc 0.45520 prc_auc 0.63746[0m
[93maverage test of epoch 20: loss -9.83534 acc 0.65789 roc_auc 0.82615 prc_auc 0.85333[0m
[92maverage training of epoch 21: loss -10.14615 acc 0.66667 roc_auc 0.45520 prc_auc 0.63746[0m
[93maverage test of epoch 21: loss -10.41654 acc 0.65789 roc_auc 0.82154 prc_auc 0.84961[0m
[92maverage training of epoch 22: loss -10.73543 acc 0.66667 roc_auc 0.45520 prc_auc 0.63748[0m
[93maverage test of epoch 22: loss -11.01118 acc 0.65789 roc_auc 0.75846 prc_auc 0.81158[0m
[92maverage training of epoch 23: loss -11.33829 acc 0.66667 roc_auc 0.45520 prc_auc 0.63746[0m
[93maverage test of epoch 23: loss -11.61944 acc 0.65789 roc_auc 0.75231 prc_auc 0.79875[0m
[92maverage training of epoch 24: loss -11.95490 acc 0.66667 roc_auc 0.45520 prc_auc 0.63746[0m
[93maverage test of epoch 24: loss -12.24151 acc 0.65789 roc_auc 0.70923 prc_auc 0.78947[0m
[92maverage training of epoch 25: loss -12.58543 acc 0.66667 roc_auc 0.45520 prc_auc 0.63746[0m
[93maverage test of epoch 25: loss -12.87752 acc 0.65789 roc_auc 0.69385 prc_auc 0.77649[0m
[92maverage training of epoch 26: loss -13.23000 acc 0.66667 roc_auc 0.45520 prc_auc 0.63746[0m
[93maverage test of epoch 26: loss -13.52759 acc 0.65789 roc_auc 0.73846 prc_auc 0.79963[0m
[92maverage training of epoch 27: loss -13.88872 acc 0.66667 roc_auc 0.45520 prc_auc 0.63746[0m
[93maverage test of epoch 27: loss -14.19183 acc 0.65789 roc_auc 0.76308 prc_auc 0.81080[0m
[92maverage training of epoch 28: loss -14.56169 acc 0.66667 roc_auc 0.45520 prc_auc 0.63746[0m
[93maverage test of epoch 28: loss -14.87032 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 29: loss -15.24900 acc 0.66667 roc_auc 0.45520 prc_auc 0.63748[0m
[93maverage test of epoch 29: loss -15.56314 acc 0.65789 roc_auc 0.65846 prc_auc 0.75368[0m
[92maverage training of epoch 30: loss -15.95071 acc 0.66667 roc_auc 0.45520 prc_auc 0.63746[0m
[93maverage test of epoch 30: loss -16.27036 acc 0.65789 roc_auc 0.47538 prc_auc 0.66158[0m
[92maverage training of epoch 31: loss -16.66689 acc 0.66667 roc_auc 0.45520 prc_auc 0.63748[0m
[93maverage test of epoch 31: loss -16.99203 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 32: loss -17.39759 acc 0.66667 roc_auc 0.45510 prc_auc 0.63728[0m
[93maverage test of epoch 32: loss -17.72822 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 33: loss -18.14287 acc 0.66667 roc_auc 0.45510 prc_auc 0.63728[0m
[93maverage test of epoch 33: loss -18.47896 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 34: loss -18.90275 acc 0.66667 roc_auc 0.45500 prc_auc 0.63710[0m
[93maverage test of epoch 34: loss -19.24429 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 35: loss -19.67729 acc 0.66667 roc_auc 0.45510 prc_auc 0.63728[0m
[93maverage test of epoch 35: loss -20.02423 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 36: loss -20.46651 acc 0.66667 roc_auc 0.45500 prc_auc 0.63708[0m
[93maverage test of epoch 36: loss -20.81884 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 37: loss -21.27043 acc 0.66667 roc_auc 0.45510 prc_auc 0.63738[0m
[93maverage test of epoch 37: loss -21.62811 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 38: loss -22.08909 acc 0.66667 roc_auc 0.45540 prc_auc 0.63745[0m
[93maverage test of epoch 38: loss -22.45212 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 39: loss -22.92250 acc 0.66667 roc_auc 0.45510 prc_auc 0.63710[0m
[93maverage test of epoch 39: loss -23.29080 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 40: loss -23.77069 acc 0.66667 roc_auc 0.45490 prc_auc 0.63696[0m
[93maverage test of epoch 40: loss -24.14429 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 41: loss -24.63370 acc 0.66667 roc_auc 0.45510 prc_auc 0.63714[0m
[93maverage test of epoch 41: loss -25.01249 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 42: loss -25.51146 acc 0.66667 roc_auc 0.45540 prc_auc 0.63720[0m
[93maverage test of epoch 42: loss -25.89546 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -26.40408 acc 0.66667 roc_auc 0.45510 prc_auc 0.63729[0m
[93maverage test of epoch 43: loss -26.79325 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 44: loss -27.31157 acc 0.66667 roc_auc 0.45550 prc_auc 0.63759[0m
[93maverage test of epoch 44: loss -27.70588 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -28.23390 acc 0.66667 roc_auc 0.45570 prc_auc 0.63780[0m
[93maverage test of epoch 45: loss -28.63324 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -29.17096 acc 0.66667 roc_auc 0.45640 prc_auc 0.63723[0m
[93maverage test of epoch 46: loss -29.57532 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -30.12288 acc 0.66667 roc_auc 0.45660 prc_auc 0.63679[0m
[93maverage test of epoch 47: loss -30.53227 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -31.08971 acc 0.66667 roc_auc 0.45700 prc_auc 0.63792[0m
[93maverage test of epoch 48: loss -31.50409 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -32.07146 acc 0.66667 roc_auc 0.45660 prc_auc 0.63597[0m
[93maverage test of epoch 49: loss -32.49079 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 50: loss -33.06813 acc 0.66667 roc_auc 0.45600 prc_auc 0.63500[0m
[93maverage test of epoch 50: loss -33.49236 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 51: loss -34.07971 acc 0.66667 roc_auc 0.45980 prc_auc 0.63795[0m
[93maverage test of epoch 51: loss -34.50881 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 52: loss -35.10621 acc 0.66667 roc_auc 0.45930 prc_auc 0.63362[0m
[93maverage test of epoch 52: loss -35.54012 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 53: loss -36.14762 acc 0.66667 roc_auc 0.45560 prc_auc 0.63219[0m
[93maverage test of epoch 53: loss -36.58632 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 54: loss -37.20395 acc 0.66667 roc_auc 0.45530 prc_auc 0.62795[0m
[93maverage test of epoch 54: loss -37.64736 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 55: loss -38.27513 acc 0.66667 roc_auc 0.45270 prc_auc 0.62976[0m
[93maverage test of epoch 55: loss -38.72321 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 56: loss -39.36114 acc 0.66667 roc_auc 0.44770 prc_auc 0.62371[0m
[93maverage test of epoch 56: loss -39.81377 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 57: loss -40.46185 acc 0.66667 roc_auc 0.45470 prc_auc 0.63186[0m
[93maverage test of epoch 57: loss -40.91900 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 58: loss -41.57739 acc 0.66667 roc_auc 0.45520 prc_auc 0.63197[0m
[93maverage test of epoch 58: loss -42.03910 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 59: loss -42.70783 acc 0.66667 roc_auc 0.45000 prc_auc 0.62930[0m
[93maverage test of epoch 59: loss -43.17407 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 60: loss -43.85318 acc 0.66667 roc_auc 0.45510 prc_auc 0.63261[0m
[93maverage test of epoch 60: loss -44.32389 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 61: loss -45.01344 acc 0.66667 roc_auc 0.44940 prc_auc 0.63054[0m
[93maverage test of epoch 61: loss -45.48859 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 62: loss -46.18861 acc 0.66667 roc_auc 0.45210 prc_auc 0.63987[0m
[93maverage test of epoch 62: loss -46.66815 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 63: loss -47.37869 acc 0.66667 roc_auc 0.48050 prc_auc 0.65622[0m
[93maverage test of epoch 63: loss -47.86259 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 64: loss -48.58368 acc 0.66667 roc_auc 0.47760 prc_auc 0.65641[0m
[93maverage test of epoch 64: loss -49.07189 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 65: loss -49.80358 acc 0.66667 roc_auc 0.45500 prc_auc 0.64803[0m
[93maverage test of epoch 65: loss -50.29606 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 66: loss -51.03840 acc 0.66667 roc_auc 0.48000 prc_auc 0.65801[0m
[93maverage test of epoch 66: loss -51.53509 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 67: loss -52.28812 acc 0.66667 roc_auc 0.50500 prc_auc 0.66896[0m
[93maverage test of epoch 67: loss -52.78900 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 68: loss -53.55275 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 68: loss -54.05777 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 69: loss -54.88513 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 69: loss -55.51153 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 70: loss -56.45068 acc 0.66667 roc_auc 0.46500 prc_auc 0.65168[0m
[93maverage test of epoch 70: loss -57.11908 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 71: loss -58.07187 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 71: loss -58.74638 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 72: loss -59.71540 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 72: loss -60.39782 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 73: loss -61.38415 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 73: loss -62.07522 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 74: loss -63.07943 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 74: loss -63.77953 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 75: loss -64.80202 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 75: loss -65.51136 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 76: loss -66.55243 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 76: loss -67.27114 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 77: loss -68.33105 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 77: loss -69.05922 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 78: loss -70.13821 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 78: loss -70.87590 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 79: loss -72.01705 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 79: loss -72.87318 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 80: loss -74.14479 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 80: loss -75.05718 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 81: loss -76.35105 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 81: loss -77.27492 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 82: loss -78.59380 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 82: loss -79.53116 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 83: loss -80.87628 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 83: loss -81.82792 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 84: loss -83.20001 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 84: loss -84.16634 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 85: loss -85.56590 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 85: loss -86.54714 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 86: loss -87.97376 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 86: loss -88.96823 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 87: loss -90.42008 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 87: loss -91.42696 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 88: loss -92.90488 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 88: loss -93.92478 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 89: loss -95.42952 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 89: loss -96.46290 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -97.99504 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 90: loss -99.04230 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 91: loss -100.60230 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 91: loss -101.66362 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 92: loss -103.25195 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 92: loss -104.32752 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 93: loss -105.94457 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 93: loss -107.03451 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 94: loss -108.68061 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 94: loss -109.78503 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 95: loss -111.47169 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 95: loss -112.64928 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 96: loss -114.50112 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 96: loss -115.78850 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 97: loss -117.67576 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 97: loss -118.97642 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 98: loss -120.89494 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 98: loss -122.21016 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -124.16184 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 99: loss -125.49311 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.27151 acc 0.33333 roc_auc 0.37920 prc_auc 0.58480[0m
[93maverage test of epoch 0: loss -0.31605 acc 0.34211 roc_auc 0.53231 prc_auc 0.77764[0m
[92maverage training of epoch 1: loss -0.33187 acc 0.33333 roc_auc 0.36980 prc_auc 0.57982[0m
[93maverage test of epoch 1: loss -0.36378 acc 0.34211 roc_auc 0.53385 prc_auc 0.78882[0m
[92maverage training of epoch 2: loss -0.38095 acc 0.33333 roc_auc 0.37300 prc_auc 0.57960[0m
[93maverage test of epoch 2: loss -0.40892 acc 0.34211 roc_auc 0.56769 prc_auc 0.81165[0m
[92maverage training of epoch 3: loss -0.42758 acc 0.33333 roc_auc 0.37360 prc_auc 0.57395[0m
[93maverage test of epoch 3: loss -0.45178 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 4: loss -0.46715 acc 0.33333 roc_auc 0.37140 prc_auc 0.57330[0m
[93maverage test of epoch 4: loss -0.48481 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 5: loss -0.50036 acc 0.33333 roc_auc 0.37700 prc_auc 0.57535[0m
[93maverage test of epoch 5: loss -0.51784 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 6: loss -0.53357 acc 0.33333 roc_auc 0.37660 prc_auc 0.57505[0m
[93maverage test of epoch 6: loss -0.55088 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 7: loss -0.56679 acc 0.33333 roc_auc 0.37640 prc_auc 0.57486[0m
[93maverage test of epoch 7: loss -0.58392 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 8: loss -0.59993 acc 0.33333 roc_auc 0.37800 prc_auc 0.57538[0m
[93maverage test of epoch 8: loss -0.61696 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 9: loss -0.63307 acc 0.33333 roc_auc 0.37740 prc_auc 0.57503[0m
[93maverage test of epoch 9: loss -0.65000 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 10: loss -0.66620 acc 0.32000 roc_auc 0.37740 prc_auc 0.57503[0m
[93maverage test of epoch 10: loss -0.68305 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 11: loss -0.69934 acc 0.66667 roc_auc 0.37720 prc_auc 0.57494[0m
[93maverage test of epoch 11: loss -0.71609 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 12: loss -0.73248 acc 0.66667 roc_auc 0.37700 prc_auc 0.57482[0m
[93maverage test of epoch 12: loss -0.74914 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 13: loss -0.76562 acc 0.66667 roc_auc 0.37690 prc_auc 0.57465[0m
[93maverage test of epoch 13: loss -0.78218 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 14: loss -0.79876 acc 0.66667 roc_auc 0.37690 prc_auc 0.57463[0m
[93maverage test of epoch 14: loss -0.81523 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 15: loss -0.83190 acc 0.66667 roc_auc 0.37690 prc_auc 0.57465[0m
[93maverage test of epoch 15: loss -0.84828 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 16: loss -0.86504 acc 0.66667 roc_auc 0.37680 prc_auc 0.57485[0m
[93maverage test of epoch 16: loss -0.88132 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 17: loss -0.89818 acc 0.66667 roc_auc 0.37680 prc_auc 0.57463[0m
[93maverage test of epoch 17: loss -0.91437 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 18: loss -0.93132 acc 0.66667 roc_auc 0.37680 prc_auc 0.57465[0m
[93maverage test of epoch 18: loss -0.94742 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -0.96447 acc 0.66667 roc_auc 0.37680 prc_auc 0.57460[0m
[93maverage test of epoch 19: loss -0.98046 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -0.99761 acc 0.66667 roc_auc 0.37670 prc_auc 0.57458[0m
[93maverage test of epoch 20: loss -1.01351 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -1.03075 acc 0.66667 roc_auc 0.37660 prc_auc 0.57442[0m
[93maverage test of epoch 21: loss -1.04656 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -1.06389 acc 0.66667 roc_auc 0.37650 prc_auc 0.57439[0m
[93maverage test of epoch 22: loss -1.07960 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -1.09703 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 23: loss -1.11265 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -1.13017 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 24: loss -1.14570 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -1.16331 acc 0.66667 roc_auc 0.37650 prc_auc 0.57439[0m
[93maverage test of epoch 25: loss -1.17874 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -1.19645 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 26: loss -1.21179 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -1.22960 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 27: loss -1.24484 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -1.26274 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 28: loss -1.27788 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -1.29588 acc 0.66667 roc_auc 0.37640 prc_auc 0.57442[0m
[93maverage test of epoch 29: loss -1.31093 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -1.32902 acc 0.66667 roc_auc 0.37650 prc_auc 0.57439[0m
[93maverage test of epoch 30: loss -1.34398 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -1.36216 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 31: loss -1.37703 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -1.39530 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 32: loss -1.41007 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -1.42844 acc 0.66667 roc_auc 0.37640 prc_auc 0.57442[0m
[93maverage test of epoch 33: loss -1.44312 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -1.46159 acc 0.66667 roc_auc 0.37640 prc_auc 0.57442[0m
[93maverage test of epoch 34: loss -1.47617 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -1.49473 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 35: loss -1.50921 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -1.52787 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 36: loss -1.54226 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -1.56101 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 37: loss -1.57531 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -1.59415 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 38: loss -1.60835 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -1.62729 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 39: loss -1.64140 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -1.66044 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 40: loss -1.67445 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -1.69358 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 41: loss -1.70750 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -1.72672 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 42: loss -1.74054 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -1.75986 acc 0.66667 roc_auc 0.37640 prc_auc 0.57445[0m
[93maverage test of epoch 43: loss -1.77359 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -1.79300 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 44: loss -1.80664 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -1.82613 acc 0.66667 roc_auc 0.37490 prc_auc 0.57400[0m
[93maverage test of epoch 45: loss -1.83968 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -1.85928 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 46: loss -1.87273 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -1.89242 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 47: loss -1.90578 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -1.92557 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 48: loss -1.93882 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -1.95871 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 49: loss -1.97187 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 50: loss -1.99185 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 50: loss -2.00492 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 51: loss -2.02499 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 51: loss -2.03796 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 52: loss -2.05813 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 52: loss -2.07101 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 53: loss -2.09127 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 53: loss -2.10405 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 54: loss -2.12441 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 54: loss -2.13710 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 55: loss -2.15755 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 55: loss -2.17015 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 56: loss -2.19069 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 56: loss -2.20319 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 57: loss -2.22383 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 57: loss -2.23624 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 58: loss -2.25697 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 58: loss -2.26929 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 59: loss -2.29011 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 59: loss -2.30233 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 60: loss -2.32326 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 60: loss -2.33538 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 61: loss -2.35640 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 61: loss -2.36842 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 62: loss -2.38954 acc 0.66667 roc_auc 0.37640 prc_auc 0.57445[0m
[93maverage test of epoch 62: loss -2.40147 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 63: loss -2.42268 acc 0.66667 roc_auc 0.37640 prc_auc 0.57442[0m
[93maverage test of epoch 63: loss -2.43451 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 64: loss -2.45582 acc 0.66667 roc_auc 0.37640 prc_auc 0.57442[0m
[93maverage test of epoch 64: loss -2.46756 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 65: loss -2.48896 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 65: loss -2.50061 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 66: loss -2.52210 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 66: loss -2.53365 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 67: loss -2.55524 acc 0.66667 roc_auc 0.37640 prc_auc 0.57442[0m
[93maverage test of epoch 67: loss -2.56670 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 68: loss -2.58838 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 68: loss -2.59974 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 69: loss -2.62152 acc 0.66667 roc_auc 0.37640 prc_auc 0.57442[0m
[93maverage test of epoch 69: loss -2.63279 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 70: loss -2.65466 acc 0.66667 roc_auc 0.37640 prc_auc 0.57442[0m
[93maverage test of epoch 70: loss -2.66583 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 71: loss -2.68780 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 71: loss -2.69888 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 72: loss -2.72094 acc 0.66667 roc_auc 0.37640 prc_auc 0.57445[0m
[93maverage test of epoch 72: loss -2.73193 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 73: loss -2.75408 acc 0.66667 roc_auc 0.37640 prc_auc 0.57445[0m
[93maverage test of epoch 73: loss -2.76497 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 74: loss -2.78722 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 74: loss -2.79802 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 75: loss -2.82036 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 75: loss -2.83106 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 76: loss -2.85350 acc 0.66667 roc_auc 0.37640 prc_auc 0.57442[0m
[93maverage test of epoch 76: loss -2.86411 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 77: loss -2.89674 acc 0.66667 roc_auc 0.40820 prc_auc 0.61550[0m
[93maverage test of epoch 77: loss -2.95500 acc 0.65789 roc_auc 0.86154 prc_auc 0.91070[0m
[92maverage training of epoch 78: loss -3.14578 acc 0.66667 roc_auc 0.42360 prc_auc 0.62476[0m
[93maverage test of epoch 78: loss -3.35040 acc 0.65789 roc_auc 0.95385 prc_auc 0.97791[0m
[92maverage training of epoch 79: loss -3.55909 acc 0.66667 roc_auc 0.41820 prc_auc 0.61835[0m
[93maverage test of epoch 79: loss -3.75207 acc 0.65789 roc_auc 0.93846 prc_auc 0.95764[0m
[92maverage training of epoch 80: loss -3.95407 acc 0.66667 roc_auc 0.41520 prc_auc 0.61690[0m
[93maverage test of epoch 80: loss -4.14223 acc 0.65789 roc_auc 0.91385 prc_auc 0.92556[0m
[92maverage training of epoch 81: loss -4.34584 acc 0.66667 roc_auc 0.41380 prc_auc 0.61493[0m
[93maverage test of epoch 81: loss -4.53483 acc 0.65789 roc_auc 0.86462 prc_auc 0.87965[0m
[92maverage training of epoch 82: loss -4.74288 acc 0.66667 roc_auc 0.41300 prc_auc 0.61454[0m
[93maverage test of epoch 82: loss -4.93481 acc 0.65789 roc_auc 0.76000 prc_auc 0.83579[0m
[92maverage training of epoch 83: loss -5.14863 acc 0.66667 roc_auc 0.41220 prc_auc 0.61376[0m
[93maverage test of epoch 83: loss -5.34452 acc 0.65789 roc_auc 0.66000 prc_auc 0.77550[0m
[92maverage training of epoch 84: loss -5.56488 acc 0.66667 roc_auc 0.41120 prc_auc 0.61307[0m
[93maverage test of epoch 84: loss -5.76533 acc 0.65789 roc_auc 0.62000 prc_auc 0.74000[0m
[92maverage training of epoch 85: loss -5.99272 acc 0.66667 roc_auc 0.41140 prc_auc 0.61323[0m
[93maverage test of epoch 85: loss -6.19812 acc 0.65789 roc_auc 0.64000 prc_auc 0.75368[0m
[92maverage training of epoch 86: loss -6.43291 acc 0.66667 roc_auc 0.41160 prc_auc 0.61340[0m
[93maverage test of epoch 86: loss -6.64352 acc 0.65789 roc_auc 0.52000 prc_auc 0.67158[0m
[92maverage training of epoch 87: loss -6.88602 acc 0.66667 roc_auc 0.41140 prc_auc 0.61331[0m
[93maverage test of epoch 87: loss -7.10203 acc 0.65789 roc_auc 0.46615 prc_auc 0.64400[0m
[92maverage training of epoch 88: loss -7.35245 acc 0.66667 roc_auc 0.41120 prc_auc 0.61326[0m
[93maverage test of epoch 88: loss -7.57402 acc 0.65789 roc_auc 0.86462 prc_auc 0.89657[0m
[92maverage training of epoch 89: loss -7.83256 acc 0.66667 roc_auc 0.41100 prc_auc 0.61322[0m
[93maverage test of epoch 89: loss -8.05980 acc 0.65789 roc_auc 0.74000 prc_auc 0.82211[0m
[92maverage training of epoch 90: loss -8.32664 acc 0.66667 roc_auc 0.41100 prc_auc 0.61322[0m
[93maverage test of epoch 90: loss -8.55963 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 91: loss -8.83493 acc 0.66667 roc_auc 0.41100 prc_auc 0.61322[0m
[93maverage test of epoch 91: loss -9.07374 acc 0.65789 roc_auc 0.74462 prc_auc 0.80135[0m
[92maverage training of epoch 92: loss -9.35762 acc 0.66667 roc_auc 0.41100 prc_auc 0.61322[0m
[93maverage test of epoch 92: loss -9.60230 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 93: loss -9.89490 acc 0.66667 roc_auc 0.41100 prc_auc 0.61322[0m
[93maverage test of epoch 93: loss -10.14545 acc 0.65789 roc_auc 0.52000 prc_auc 0.67158[0m
[92maverage training of epoch 94: loss -10.44536 acc 0.66667 roc_auc 0.41080 prc_auc 0.61306[0m
[93maverage test of epoch 94: loss -10.69941 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 95: loss -11.00531 acc 0.66667 roc_auc 0.40980 prc_auc 0.61265[0m
[93maverage test of epoch 95: loss -11.26271 acc 0.65789 roc_auc 0.64462 prc_auc 0.73829[0m
[92maverage training of epoch 96: loss -11.57526 acc 0.66667 roc_auc 0.40990 prc_auc 0.61273[0m
[93maverage test of epoch 96: loss -11.83656 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 97: loss -12.15624 acc 0.66667 roc_auc 0.41000 prc_auc 0.61282[0m
[93maverage test of epoch 97: loss -12.42185 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 98: loss -12.74907 acc 0.66667 roc_auc 0.41000 prc_auc 0.61282[0m
[93maverage test of epoch 98: loss -13.01930 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -13.35437 acc 0.66667 roc_auc 0.41000 prc_auc 0.61282[0m
[93maverage test of epoch 99: loss -13.62944 acc 0.65789 roc_auc 0.82000 prc_auc 0.87684[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss 0.47073 acc 0.33775 roc_auc 0.50353 prc_auc 0.64089[0m
[93maverage test of epoch 0: loss -0.00250 acc 0.32432 roc_auc 0.72500 prc_auc 0.85020[0m
[92maverage training of epoch 1: loss -0.18397 acc 0.33775 roc_auc 0.39784 prc_auc 0.62236[0m
[93maverage test of epoch 1: loss -0.21276 acc 0.35135 roc_auc 0.54000 prc_auc 0.70162[0m
[92maverage training of epoch 2: loss -0.23354 acc 0.35762 roc_auc 0.52686 prc_auc 0.71311[0m
[93maverage test of epoch 2: loss -0.27025 acc 0.37838 roc_auc 0.85000 prc_auc 0.91401[0m
[92maverage training of epoch 3: loss -0.38623 acc 0.56291 roc_auc 0.59686 prc_auc 0.78600[0m
[93maverage test of epoch 3: loss -0.51418 acc 0.67568 roc_auc 0.85667 prc_auc 0.91693[0m
[92maverage training of epoch 4: loss -0.67290 acc 0.66225 roc_auc 0.64000 prc_auc 0.78528[0m
[93maverage test of epoch 4: loss -0.88353 acc 0.67568 roc_auc 0.86000 prc_auc 0.92137[0m
[92maverage training of epoch 5: loss -1.11331 acc 0.66225 roc_auc 0.68961 prc_auc 0.80760[0m
[93maverage test of epoch 5: loss -1.35810 acc 0.67568 roc_auc 0.85667 prc_auc 0.92034[0m
[92maverage training of epoch 6: loss -1.49575 acc 0.66225 roc_auc 0.81020 prc_auc 0.85430[0m
[93maverage test of epoch 6: loss -1.69057 acc 0.67568 roc_auc 0.86000 prc_auc 0.92585[0m
[92maverage training of epoch 7: loss -1.80748 acc 0.66225 roc_auc 0.81922 prc_auc 0.85588[0m
[93maverage test of epoch 7: loss -2.00253 acc 0.67568 roc_auc 0.86000 prc_auc 0.92585[0m
[92maverage training of epoch 8: loss -2.11514 acc 0.66225 roc_auc 0.81784 prc_auc 0.85553[0m
[93maverage test of epoch 8: loss -2.31748 acc 0.67568 roc_auc 0.86333 prc_auc 0.92682[0m
[92maverage training of epoch 9: loss -2.42924 acc 0.66225 roc_auc 0.81961 prc_auc 0.85897[0m
[93maverage test of epoch 9: loss -2.64038 acc 0.67568 roc_auc 0.86000 prc_auc 0.92282[0m
[92maverage training of epoch 10: loss -2.75313 acc 0.66225 roc_auc 0.82647 prc_auc 0.86665[0m
[93maverage test of epoch 10: loss -2.97254 acc 0.67568 roc_auc 0.86000 prc_auc 0.92282[0m
[92maverage training of epoch 11: loss -3.09208 acc 0.66225 roc_auc 0.84216 prc_auc 0.87819[0m
[93maverage test of epoch 11: loss -3.31989 acc 0.67568 roc_auc 0.86000 prc_auc 0.92282[0m
[92maverage training of epoch 12: loss -3.45371 acc 0.66225 roc_auc 0.85706 prc_auc 0.88827[0m
[93maverage test of epoch 12: loss -3.69148 acc 0.67568 roc_auc 0.86000 prc_auc 0.92282[0m
[92maverage training of epoch 13: loss -3.84149 acc 0.66225 roc_auc 0.86373 prc_auc 0.89306[0m
[93maverage test of epoch 13: loss -4.09269 acc 0.67568 roc_auc 0.86000 prc_auc 0.92282[0m
[92maverage training of epoch 14: loss -4.25859 acc 0.66225 roc_auc 0.86431 prc_auc 0.89319[0m
[93maverage test of epoch 14: loss -4.52843 acc 0.67568 roc_auc 0.86000 prc_auc 0.92137[0m
[92maverage training of epoch 15: loss -4.71449 acc 0.66225 roc_auc 0.86157 prc_auc 0.88884[0m
[93maverage test of epoch 15: loss -5.00935 acc 0.67568 roc_auc 0.85667 prc_auc 0.92034[0m
[92maverage training of epoch 16: loss -5.21766 acc 0.66225 roc_auc 0.86235 prc_auc 0.88746[0m
[93maverage test of epoch 16: loss -5.53898 acc 0.67568 roc_auc 0.85333 prc_auc 0.91937[0m
[92maverage training of epoch 17: loss -5.75151 acc 0.66225 roc_auc 0.86196 prc_auc 0.88433[0m
[93maverage test of epoch 17: loss -6.09044 acc 0.67568 roc_auc 0.85333 prc_auc 0.91937[0m
[92maverage training of epoch 18: loss -6.30998 acc 0.66225 roc_auc 0.86333 prc_auc 0.88242[0m
[93maverage test of epoch 18: loss -6.66767 acc 0.67568 roc_auc 0.85333 prc_auc 0.91937[0m
[92maverage training of epoch 19: loss -6.89783 acc 0.66225 roc_auc 0.86157 prc_auc 0.87974[0m
[93maverage test of epoch 19: loss -7.27386 acc 0.67568 roc_auc 0.85333 prc_auc 0.91937[0m
[92maverage training of epoch 20: loss -7.51369 acc 0.66225 roc_auc 0.86039 prc_auc 0.87788[0m
[93maverage test of epoch 20: loss -7.90719 acc 0.67568 roc_auc 0.85667 prc_auc 0.92211[0m
[92maverage training of epoch 21: loss -8.15773 acc 0.66225 roc_auc 0.85843 prc_auc 0.87639[0m
[93maverage test of epoch 21: loss -8.56887 acc 0.67568 roc_auc 0.85667 prc_auc 0.92247[0m
[92maverage training of epoch 22: loss -8.83081 acc 0.66225 roc_auc 0.85422 prc_auc 0.87281[0m
[93maverage test of epoch 22: loss -9.25977 acc 0.67568 roc_auc 0.85833 prc_auc 0.91999[0m
[92maverage training of epoch 23: loss -9.53366 acc 0.66225 roc_auc 0.85098 prc_auc 0.86930[0m
[93maverage test of epoch 23: loss -9.98072 acc 0.67568 roc_auc 0.84833 prc_auc 0.89701[0m
[92maverage training of epoch 24: loss -10.26700 acc 0.66225 roc_auc 0.84814 prc_auc 0.86229[0m
[93maverage test of epoch 24: loss -10.73335 acc 0.67568 roc_auc 0.84667 prc_auc 0.89454[0m
[92maverage training of epoch 25: loss -11.03177 acc 0.66225 roc_auc 0.84392 prc_auc 0.85317[0m
[93maverage test of epoch 25: loss -11.52066 acc 0.67568 roc_auc 0.85000 prc_auc 0.90030[0m
[92maverage training of epoch 26: loss -11.83160 acc 0.66225 roc_auc 0.81833 prc_auc 0.83649[0m
[93maverage test of epoch 26: loss -12.34931 acc 0.67568 roc_auc 0.85000 prc_auc 0.90049[0m
[92maverage training of epoch 27: loss -12.68375 acc 0.66225 roc_auc 0.79382 prc_auc 0.81248[0m
[93maverage test of epoch 27: loss -13.24328 acc 0.67568 roc_auc 0.83500 prc_auc 0.87919[0m
[92maverage training of epoch 28: loss -13.61828 acc 0.66225 roc_auc 0.73549 prc_auc 0.77162[0m
[93maverage test of epoch 28: loss -14.21963 acc 0.67568 roc_auc 0.86333 prc_auc 0.90396[0m
[92maverage training of epoch 29: loss -14.59719 acc 0.66225 roc_auc 0.59618 prc_auc 0.69160[0m
[93maverage test of epoch 29: loss -15.21513 acc 0.67568 roc_auc 0.86500 prc_auc 0.90396[0m
[92maverage training of epoch 30: loss -15.60051 acc 0.66225 roc_auc 0.49990 prc_auc 0.65163[0m
[93maverage test of epoch 30: loss -16.23707 acc 0.67568 roc_auc 0.86667 prc_auc 0.90396[0m
[92maverage training of epoch 31: loss -16.63456 acc 0.66225 roc_auc 0.46196 prc_auc 0.62833[0m
[93maverage test of epoch 31: loss -17.29122 acc 0.67568 roc_auc 0.83500 prc_auc 0.87703[0m
[92maverage training of epoch 32: loss -17.70103 acc 0.66225 roc_auc 0.44961 prc_auc 0.62111[0m
[93maverage test of epoch 32: loss -18.37821 acc 0.67568 roc_auc 0.76167 prc_auc 0.82143[0m
[92maverage training of epoch 33: loss -18.80022 acc 0.66225 roc_auc 0.43392 prc_auc 0.61073[0m
[93maverage test of epoch 33: loss -19.49815 acc 0.67568 roc_auc 0.62167 prc_auc 0.73766[0m
[92maverage training of epoch 34: loss -19.93193 acc 0.66225 roc_auc 0.42588 prc_auc 0.60624[0m
[93maverage test of epoch 34: loss -20.64979 acc 0.67568 roc_auc 0.58333 prc_auc 0.71798[0m
[92maverage training of epoch 35: loss -21.09221 acc 0.66225 roc_auc 0.42275 prc_auc 0.60392[0mUsing backend: pytorch
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))

[93maverage test of epoch 35: loss -21.82793 acc 0.67568 roc_auc 0.62333 prc_auc 0.73766[0m
[92maverage training of epoch 36: loss -22.27872 acc 0.66225 roc_auc 0.41716 prc_auc 0.59755[0m
[93maverage test of epoch 36: loss -23.03292 acc 0.67568 roc_auc 0.60000 prc_auc 0.72571[0m
[92maverage training of epoch 37: loss -23.49235 acc 0.66225 roc_auc 0.42059 prc_auc 0.60195[0m
[93maverage test of epoch 37: loss -24.26565 acc 0.67568 roc_auc 0.60000 prc_auc 0.72571[0m
[92maverage training of epoch 38: loss -24.73387 acc 0.66225 roc_auc 0.42167 prc_auc 0.60237[0m
[93maverage test of epoch 38: loss -25.52676 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 39: loss -26.00387 acc 0.66225 roc_auc 0.41804 prc_auc 0.60036[0m
[93maverage test of epoch 39: loss -26.81680 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 40: loss -27.30284 acc 0.66225 roc_auc 0.42598 prc_auc 0.60961[0m
[93maverage test of epoch 40: loss -28.13618 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -28.63119 acc 0.66225 roc_auc 0.41363 prc_auc 0.60228[0m
[93maverage test of epoch 41: loss -29.48528 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -29.98923 acc 0.66225 roc_auc 0.41275 prc_auc 0.60652[0m
[93maverage test of epoch 42: loss -30.86436 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -31.37722 acc 0.66225 roc_auc 0.41382 prc_auc 0.61529[0m
[93maverage test of epoch 43: loss -32.27368 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -32.79538 acc 0.66225 roc_auc 0.44059 prc_auc 0.63048[0m
[93maverage test of epoch 44: loss -33.71342 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -34.24389 acc 0.66225 roc_auc 0.41706 prc_auc 0.61905[0m
[93maverage test of epoch 45: loss -35.18372 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -35.72287 acc 0.66225 roc_auc 0.41922 prc_auc 0.62292[0m
[93maverage test of epoch 46: loss -36.68469 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -37.23242 acc 0.66225 roc_auc 0.42745 prc_auc 0.63225[0m
[93maverage test of epoch 47: loss -38.21643 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -38.77262 acc 0.66225 roc_auc 0.42725 prc_auc 0.63225[0m
[93maverage test of epoch 48: loss -39.77900 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -40.34354 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 49: loss -41.37246 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 50: loss -41.94521 acc 0.66225 roc_auc 0.43069 prc_auc 0.63429[0m
[93maverage test of epoch 50: loss -42.99681 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 51: loss -43.57765 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 51: loss -44.65207 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 52: loss -45.24077 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 52: loss -46.33770 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 53: loss -46.93265 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 53: loss -48.05057 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 54: loss -48.65148 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 54: loss -49.79065 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 55: loss -50.39764 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 55: loss -51.55838 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 56: loss -52.17151 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 56: loss -53.35411 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 57: loss -53.97344 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 57: loss -55.17814 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 58: loss -55.80369 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 58: loss -57.03075 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 59: loss -57.66248 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 59: loss -58.91214 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 60: loss -59.55009 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 60: loss -60.82252 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 61: loss -61.46660 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 61: loss -62.76204 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 62: loss -63.41230 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 62: loss -64.73097 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 63: loss -65.38719 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 63: loss -66.72915 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 64: loss -67.39141 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 64: loss -68.75700 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 65: loss -69.42519 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 65: loss -70.81453 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 66: loss -71.48859 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 66: loss -72.90179 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 67: loss -73.58146 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 67: loss -75.01860 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 68: loss -75.70398 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 68: loss -77.16542 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 69: loss -77.90985 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 69: loss -79.51611 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 70: loss -80.36454 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 70: loss -82.03524 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 71: loss -82.88960 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 71: loss -84.58976 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 72: loss -85.45240 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 72: loss -87.18390 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 73: loss -88.05560 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 73: loss -89.81933 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 74: loss -90.70053 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 74: loss -92.49715 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 75: loss -93.38798 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 75: loss -95.21809 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 76: loss -96.11869 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 76: loss -97.98270 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 77: loss -98.89306 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 77: loss -100.79124 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 78: loss -101.71108 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 78: loss -103.64356 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 79: loss -104.57292 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 79: loss -106.54023 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 80: loss -107.47917 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 80: loss -109.48165 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 81: loss -110.43006 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 81: loss -112.46789 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 82: loss -113.42547 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 82: loss -115.49888 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 83: loss -116.46574 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 83: loss -118.57513 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 84: loss -119.55111 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 84: loss -121.69673 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 85: loss -122.68172 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 85: loss -124.86384 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 86: loss -125.85682 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 86: loss -128.07374 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 87: loss -129.07246 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 87: loss -131.32354 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 88: loss -132.32845 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 88: loss -134.61450 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 89: loss -135.62579 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 89: loss -137.94723 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 90: loss -138.96510 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 90: loss -141.32260 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 91: loss -142.34726 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 91: loss -144.74128 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 92: loss -145.77278 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 92: loss -148.20374 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 93: loss -149.24207 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 93: loss -151.71034 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 94: loss -152.75546 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 94: loss -155.26137 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 95: loss -156.31322 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 95: loss -158.85709 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 96: loss -159.91560 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 96: loss -162.49770 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 97: loss -163.56249 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 97: loss -166.18240 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 98: loss -167.25244 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 98: loss -169.90980 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 99: loss -170.98506 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 99: loss -173.68027 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss 0.45640 acc 0.33775 roc_auc 0.43078 prc_auc 0.63450[0m
[93maverage test of epoch 0: loss 0.23487 acc 0.32432 roc_auc 0.92667 prc_auc 0.97104[0m
[92maverage training of epoch 1: loss 0.05548 acc 0.33775 roc_auc 0.37922 prc_auc 0.57118[0m
[93maverage test of epoch 1: loss 0.00742 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 2: loss -0.01904 acc 0.33775 roc_auc 0.37059 prc_auc 0.56870[0m
[93maverage test of epoch 2: loss -0.02596 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 3: loss -0.05229 acc 0.33775 roc_auc 0.37039 prc_auc 0.56872[0m
[93maverage test of epoch 3: loss -0.05935 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 4: loss -0.08555 acc 0.33775 roc_auc 0.37000 prc_auc 0.56849[0m
[93maverage test of epoch 4: loss -0.09276 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 5: loss -0.11882 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 5: loss -0.12618 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 6: loss -0.15210 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 6: loss -0.15960 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 7: loss -0.18538 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 7: loss -0.19302 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 8: loss -0.21867 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 8: loss -0.22645 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 9: loss -0.25195 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 9: loss -0.25988 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 10: loss -0.28524 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 10: loss -0.29330 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 11: loss -0.31853 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 11: loss -0.32673 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 12: loss -0.35182 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 12: loss -0.36017 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 13: loss -0.38511 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 13: loss -0.39360 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 14: loss -0.41840 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 14: loss -0.42703 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 15: loss -0.45169 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 15: loss -0.46046 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 16: loss -0.48498 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 16: loss -0.49390 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 17: loss -0.51827 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 17: loss -0.52733 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 18: loss -0.55156 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 18: loss -0.56076 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 19: loss -0.58485 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 19: loss -0.59420 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 20: loss -0.61815 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 20: loss -0.62763 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 21: loss -0.65144 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 21: loss -0.66106 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 22: loss -0.68473 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 22: loss -0.69450 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 23: loss -0.71803 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 23: loss -0.72793 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 24: loss -0.75132 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 24: loss -0.76137 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 25: loss -0.78461 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 25: loss -0.79480 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 26: loss -0.81790 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 26: loss -0.82824 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 27: loss -0.85120 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 27: loss -0.86167 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 28: loss -0.88449 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 28: loss -0.89511 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 29: loss -0.91778 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 29: loss -0.92854 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 30: loss -0.95108 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 30: loss -0.96197 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 31: loss -0.98437 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 31: loss -0.99541 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 32: loss -1.01766 acc 0.33775 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 32: loss -1.02884 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 33: loss -1.05095 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 33: loss -1.06228 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 34: loss -1.08425 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 34: loss -1.09571 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 35: loss -1.11754 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 35: loss -1.12915 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 36: loss -1.15083 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 36: loss -1.16258 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 37: loss -1.18412 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 37: loss -1.19602 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 38: loss -1.21742 acc 0.33775 roc_auc 0.36971 prc_auc 0.56810[0m
[93maverage test of epoch 38: loss -1.22945 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 39: loss -1.25071 acc 0.33775 roc_auc 0.36971 prc_auc 0.56808[0m
[93maverage test of epoch 39: loss -1.26289 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -1.28400 acc 0.33775 roc_auc 0.36971 prc_auc 0.56808[0m
[93maverage test of epoch 40: loss -1.29632 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -1.31730 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 41: loss -1.32975 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -1.35059 acc 0.33775 roc_auc 0.37000 prc_auc 0.56825[0m
[93maverage test of epoch 42: loss -1.36319 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -1.38388 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 43: loss -1.39662 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -1.41718 acc 0.33775 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 44: loss -1.43006 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -1.45047 acc 0.33775 roc_auc 0.36971 prc_auc 0.56808[0m
[93maverage test of epoch 45: loss -1.46349 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -1.48376 acc 0.33775 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 46: loss -1.49693 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -1.51705 acc 0.33775 roc_auc 0.36971 prc_auc 0.56810[0m
[93maverage test of epoch 47: loss -1.53036 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -1.55035 acc 0.33775 roc_auc 0.36971 prc_auc 0.56808[0m
[93maverage test of epoch 48: loss -1.56380 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -1.58364 acc 0.33775 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 49: loss -1.59723 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 50: loss -1.61693 acc 0.33775 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 50: loss -1.63066 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 51: loss -1.65022 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 51: loss -1.66410 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 52: loss -1.68352 acc 0.33775 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 52: loss -1.69753 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 53: loss -1.71681 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 53: loss -1.73097 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 54: loss -1.75010 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 54: loss -1.76440 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 55: loss -1.78339 acc 0.33775 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 55: loss -1.79783 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 56: loss -1.81669 acc 0.33775 roc_auc 0.36971 prc_auc 0.56810[0m
[93maverage test of epoch 56: loss -1.83127 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 57: loss -1.84998 acc 0.33775 roc_auc 0.36971 prc_auc 0.56808[0m
[93maverage test of epoch 57: loss -1.86470 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 58: loss -1.88327 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 58: loss -1.89814 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 59: loss -1.91656 acc 0.33775 roc_auc 0.36961 prc_auc 0.56808[0m
[93maverage test of epoch 59: loss -1.93157 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 60: loss -1.94986 acc 0.33775 roc_auc 0.36961 prc_auc 0.56808[0m
[93maverage test of epoch 60: loss -1.96500 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 61: loss -1.98315 acc 0.33775 roc_auc 0.36961 prc_auc 0.56808[0m
[93maverage test of epoch 61: loss -1.99844 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 62: loss -2.01644 acc 0.33775 roc_auc 0.36961 prc_auc 0.56808[0m
[93maverage test of epoch 62: loss -2.03187 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 63: loss -2.04973 acc 0.33775 roc_auc 0.36961 prc_auc 0.56808[0m
[93maverage test of epoch 63: loss -2.06530 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 64: loss -2.08302 acc 0.33775 roc_auc 0.36961 prc_auc 0.56808[0m
[93maverage test of epoch 64: loss -2.09874 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 65: loss -2.11631 acc 0.33775 roc_auc 0.36961 prc_auc 0.56808[0m
[93maverage test of epoch 65: loss -2.13217 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 66: loss -2.14960 acc 0.33775 roc_auc 0.36961 prc_auc 0.56808[0m
[93maverage test of epoch 66: loss -2.16560 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 67: loss -2.18290 acc 0.33775 roc_auc 0.36961 prc_auc 0.56808[0m
[93maverage test of epoch 67: loss -2.19903 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 68: loss -2.21619 acc 0.33775 roc_auc 0.36961 prc_auc 0.56808[0m
[93maverage test of epoch 68: loss -2.23247 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 69: loss -2.24948 acc 0.33775 roc_auc 0.36961 prc_auc 0.56808[0m
[93maverage test of epoch 69: loss -2.26590 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 70: loss -2.28277 acc 0.33775 roc_auc 0.36961 prc_auc 0.56808[0m
[93maverage test of epoch 70: loss -2.29933 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 71: loss -2.31607 acc 0.33775 roc_auc 0.36961 prc_auc 0.56809[0m
[93maverage test of epoch 71: loss -2.33336 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 72: loss -2.41705 acc 0.47020 roc_auc 0.41255 prc_auc 0.60975[0m
[93maverage test of epoch 72: loss -2.59044 acc 0.67568 roc_auc 0.94000 prc_auc 0.97720[0m
[92maverage training of epoch 73: loss -2.81825 acc 0.66225 roc_auc 0.40039 prc_auc 0.59696[0m
[93maverage test of epoch 73: loss -3.04886 acc 0.67568 roc_auc 0.93500 prc_auc 0.97266[0m
[92maverage training of epoch 74: loss -3.25808 acc 0.66225 roc_auc 0.39216 prc_auc 0.59157[0m
[93maverage test of epoch 74: loss -3.47702 acc 0.67568 roc_auc 0.93333 prc_auc 0.96845[0m
[92maverage training of epoch 75: loss -3.67737 acc 0.66225 roc_auc 0.38745 prc_auc 0.58824[0m
[93maverage test of epoch 75: loss -3.89395 acc 0.67568 roc_auc 0.93833 prc_auc 0.96584[0m
[92maverage training of epoch 76: loss -4.09216 acc 0.66225 roc_auc 0.38706 prc_auc 0.58798[0m
[93maverage test of epoch 76: loss -4.31161 acc 0.67568 roc_auc 0.88000 prc_auc 0.93276[0m
[92maverage training of epoch 77: loss -4.51073 acc 0.66225 roc_auc 0.38627 prc_auc 0.58685[0m
[93maverage test of epoch 77: loss -4.73549 acc 0.67568 roc_auc 0.79833 prc_auc 0.85875[0m
[92maverage training of epoch 78: loss -4.93702 acc 0.66225 roc_auc 0.38667 prc_auc 0.58707[0m
[93maverage test of epoch 78: loss -5.16837 acc 0.67568 roc_auc 0.88000 prc_auc 0.92440[0m
[92maverage training of epoch 79: loss -5.44092 acc 0.66225 roc_auc 0.39500 prc_auc 0.59323[0m
[93maverage test of epoch 79: loss -5.80944 acc 0.67568 roc_auc 0.52167 prc_auc 0.68216[0m
[92maverage training of epoch 80: loss -6.16968 acc 0.66225 roc_auc 0.39373 prc_auc 0.59123[0m
[93maverage test of epoch 80: loss -6.57687 acc 0.67568 roc_auc 0.92000 prc_auc 0.94811[0m
[92maverage training of epoch 81: loss -6.94206 acc 0.66225 roc_auc 0.39078 prc_auc 0.58915[0m
[93maverage test of epoch 81: loss -7.36260 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 82: loss -7.73530 acc 0.66225 roc_auc 0.38980 prc_auc 0.58857[0m
[93maverage test of epoch 82: loss -8.17121 acc 0.67568 roc_auc 0.38000 prc_auc 0.62797[0m
[92maverage training of epoch 83: loss -8.55249 acc 0.66225 roc_auc 0.38902 prc_auc 0.58823[0m
[93maverage test of epoch 83: loss -9.00481 acc 0.67568 roc_auc 0.56000 prc_auc 0.71459[0m
[92maverage training of epoch 84: loss -9.39524 acc 0.66225 roc_auc 0.38843 prc_auc 0.58776[0m
[93maverage test of epoch 84: loss -9.86467 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 85: loss -10.26459 acc 0.66225 roc_auc 0.38765 prc_auc 0.58726[0m
[93maverage test of epoch 85: loss -10.75167 acc 0.67568 roc_auc 0.66667 prc_auc 0.75758[0m
[92maverage training of epoch 86: loss -11.16132 acc 0.66225 roc_auc 0.38686 prc_auc 0.58682[0m
[93maverage test of epoch 86: loss -11.66649 acc 0.67568 roc_auc 0.64667 prc_auc 0.74703[0m
[92maverage training of epoch 87: loss -12.08604 acc 0.66225 roc_auc 0.38686 prc_auc 0.58688[0m
[93maverage test of epoch 87: loss -12.60963 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 88: loss -13.03763 acc 0.66225 roc_auc 0.38686 prc_auc 0.58688[0m
[93maverage test of epoch 88: loss -13.57754 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 89: loss -14.01271 acc 0.66225 roc_auc 0.38637 prc_auc 0.58647[0m
[93maverage test of epoch 89: loss -14.56909 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 90: loss -15.01209 acc 0.66225 roc_auc 0.38647 prc_auc 0.58663[0m
[93maverage test of epoch 90: loss -15.58576 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 91: loss -16.03706 acc 0.66225 roc_auc 0.38647 prc_auc 0.58675[0m
[93maverage test of epoch 91: loss -16.62868 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 92: loss -17.08863 acc 0.66225 roc_auc 0.38578 prc_auc 0.58603[0m
[93maverage test of epoch 92: loss -17.69873 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 93: loss -18.16758 acc 0.66225 roc_auc 0.38569 prc_auc 0.58611[0m
[93maverage test of epoch 93: loss -18.79665 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 94: loss -19.27458 acc 0.66225 roc_auc 0.38549 prc_auc 0.58601[0m
[93maverage test of epoch 94: loss -19.92303 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 95: loss -20.41017 acc 0.66225 roc_auc 0.38559 prc_auc 0.58613[0m
[93maverage test of epoch 95: loss -21.07833 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 96: loss -21.57339 acc 0.66225 roc_auc 0.38588 prc_auc 0.58608[0m
[93maverage test of epoch 96: loss -22.25927 acc 0.67568 roc_auc 0.88000 prc_auc 0.92216[0m
[92maverage training of epoch 97: loss -22.76073 acc 0.66225 roc_auc 0.38618 prc_auc 0.58653[0m
[93maverage test of epoch 97: loss -23.46429 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 98: loss -23.97272 acc 0.66225 roc_auc 0.38627 prc_auc 0.58691[0m
[93maverage test of epoch 98: loss -24.69441 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 99: loss -25.20933 acc 0.66225 roc_auc 0.38647 prc_auc 0.58678[0m
[93maverage test of epoch 99: loss -25.94875 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 1)
('lr', 0.0003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.66501 ROC_AUC (avg): 0.564 PRC_AUC (avg): 0.7088 

Average forward propagation time taken(ms): 2.79581366097715
Average backward propagation time taken(ms): 0.9344380719757842

