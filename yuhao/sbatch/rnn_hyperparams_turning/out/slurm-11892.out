# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-20-45-44/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-20-45-44/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 8,
 'epochs': 50,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 8,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.001,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 2,
 'num_workers': 8,
 'number_of_mlp_layer': 0,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-17-20-45-44',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 50, 'learning_rate': 0.001, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -1.43317 acc 0.66667 roc_auc 0.37500 prc_auc 0.58774[0m
[93maverage test of epoch 0: loss -2.76935 acc 0.65789 roc_auc 0.41231 prc_auc 0.69329[0m
[92maverage training of epoch 1: loss -3.49243 acc 0.66667 roc_auc 0.37720 prc_auc 0.59121[0m
[93maverage test of epoch 1: loss -4.15240 acc 0.65789 roc_auc 0.66462 prc_auc 0.79689[0m
[92maverage training of epoch 2: loss -4.80459 acc 0.66667 roc_auc 0.42800 prc_auc 0.64680[0m
[93maverage test of epoch 2: loss -5.42714 acc 0.65789 roc_auc 0.51692 prc_auc 0.66658[0m
[92maverage training of epoch 3: loss -6.03926 acc 0.66667 roc_auc 0.38240 prc_auc 0.60914[0m
[93maverage test of epoch 3: loss -6.62399 acc 0.65789 roc_auc 0.38462 prc_auc 0.62076[0m
[92maverage training of epoch 4: loss -7.21506 acc 0.66667 roc_auc 0.35160 prc_auc 0.56265[0m
[93maverage test of epoch 4: loss -7.76186 acc 0.65789 roc_auc 0.56615 prc_auc 0.71871[0m
[92maverage training of epoch 5: loss -8.33706 acc 0.66667 roc_auc 0.34990 prc_auc 0.57018[0m
[93maverage test of epoch 5: loss -8.85215 acc 0.65789 roc_auc 0.63385 prc_auc 0.79663[0m
[92maverage training of epoch 6: loss -9.41801 acc 0.66667 roc_auc 0.36840 prc_auc 0.57805[0m
[93maverage test of epoch 6: loss -9.92142 acc 0.65789 roc_auc 0.56000 prc_auc 0.78214[0m
[92maverage training of epoch 7: loss -10.47754 acc 0.66667 roc_auc 0.35250 prc_auc 0.56459[0m
[93maverage test of epoch 7: loss -10.97003 acc 0.65789 roc_auc 0.46154 prc_auc 0.68283[0m
[92maverage training of epoch 8: loss -11.52513 acc 0.66667 roc_auc 0.36720 prc_auc 0.56944[0m
[93maverage test of epoch 8: loss -12.00510 acc 0.65789 roc_auc 0.64308 prc_auc 0.79431[0m
[92maverage training of epoch 9: loss -12.55982 acc 0.66667 roc_auc 0.35320 prc_auc 0.55932[0m
[93maverage test of epoch 9: loss -13.03371 acc 0.65789 roc_auc 0.60615 prc_auc 0.79711[0m
[92maverage training of epoch 10: loss -13.58701 acc 0.66667 roc_auc 0.35440 prc_auc 0.56133[0m
[93maverage test of epoch 10: loss -14.05288 acc 0.65789 roc_auc 0.44923 prc_auc 0.65927[0m
[92maverage training of epoch 11: loss -14.60836 acc 0.66667 roc_auc 0.35690 prc_auc 0.56120[0m
[93maverage test of epoch 11: loss -15.07096 acc 0.65789 roc_auc 0.54154 prc_auc 0.70336[0m
[92maverage training of epoch 12: loss -15.62555 acc 0.66667 roc_auc 0.35340 prc_auc 0.55957[0m
[93maverage test of epoch 12: loss -16.08186 acc 0.65789 roc_auc 0.41846 prc_auc 0.64737[0m
[92maverage training of epoch 13: loss -16.63777 acc 0.66667 roc_auc 0.36110 prc_auc 0.57415[0m
[93maverage test of epoch 13: loss -17.09070 acc 0.65789 roc_auc 0.56154 prc_auc 0.70973[0m
[92maverage training of epoch 14: loss -17.64800 acc 0.66667 roc_auc 0.36440 prc_auc 0.56700[0m
[93maverage test of epoch 14: loss -18.09684 acc 0.65789 roc_auc 0.55846 prc_auc 0.66990[0m
[92maverage training of epoch 15: loss -18.65528 acc 0.66667 roc_auc 0.36140 prc_auc 0.56841[0m
[93maverage test of epoch 15: loss -19.09973 acc 0.65789 roc_auc 0.52615 prc_auc 0.66863[0m
[92maverage training of epoch 16: loss -19.66094 acc 0.66667 roc_auc 0.35830 prc_auc 0.56241[0m
[93maverage test of epoch 16: loss -20.10103 acc 0.65789 roc_auc 0.56154 prc_auc 0.68301[0m
[92maverage training of epoch 17: loss -20.66360 acc 0.66667 roc_auc 0.35970 prc_auc 0.56513[0m
[93maverage test of epoch 17: loss -21.10088 acc 0.65789 roc_auc 0.47692 prc_auc 0.64193[0m
[92maverage training of epoch 18: loss -21.66685 acc 0.66667 roc_auc 0.36090 prc_auc 0.56629[0m
[93maverage test of epoch 18: loss -22.09998 acc 0.65789 roc_auc 0.42000 prc_auc 0.62992[0m
[92maverage training of epoch 19: loss -22.66797 acc 0.66667 roc_auc 0.36120 prc_auc 0.56590[0m
[93maverage test of epoch 19: loss -23.09756 acc 0.65789 roc_auc 0.41692 prc_auc 0.62009[0m
[92maverage training of epoch 20: loss -23.66743 acc 0.66667 roc_auc 0.36190 prc_auc 0.56861[0m
[93maverage test of epoch 20: loss -24.09355 acc 0.65789 roc_auc 0.48462 prc_auc 0.65075[0m
[92maverage training of epoch 21: loss -24.66693 acc 0.66667 roc_auc 0.35750 prc_auc 0.56376[0m
[93maverage test of epoch 21: loss -25.09031 acc 0.65789 roc_auc 0.54615 prc_auc 0.68185[0m
[92maverage training of epoch 22: loss -25.66495 acc 0.66667 roc_auc 0.36010 prc_auc 0.56600[0m
[93maverage test of epoch 22: loss -26.08566 acc 0.65789 roc_auc 0.48000 prc_auc 0.64902[0m
[92maverage training of epoch 23: loss -26.66346 acc 0.66667 roc_auc 0.35820 prc_auc 0.56727[0m
[93maverage test of epoch 23: loss -27.08040 acc 0.65789 roc_auc 0.48000 prc_auc 0.64902[0m
[92maverage training of epoch 24: loss -27.66054 acc 0.66667 roc_auc 0.35820 prc_auc 0.56574[0m
[93maverage test of epoch 24: loss -28.07402 acc 0.65789 roc_auc 0.55231 prc_auc 0.68267[0m
[92maverage training of epoch 25: loss -28.65760 acc 0.66667 roc_auc 0.35680 prc_auc 0.56879[0m
[93maverage test of epoch 25: loss -29.06866 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -29.65418 acc 0.66667 roc_auc 0.36380 prc_auc 0.57588[0m
[93maverage test of epoch 26: loss -30.06168 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -30.65010 acc 0.66667 roc_auc 0.36280 prc_auc 0.57713[0m
[93maverage test of epoch 27: loss -31.05524 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -31.64642 acc 0.66667 roc_auc 0.36430 prc_auc 0.57776[0m
[93maverage test of epoch 28: loss -32.04837 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -32.64216 acc 0.66667 roc_auc 0.36490 prc_auc 0.58510[0m
[93maverage test of epoch 29: loss -33.04104 acc 0.65789 roc_auc 0.42000 prc_auc 0.62409[0m
[92maverage training of epoch 30: loss -33.63761 acc 0.66667 roc_auc 0.36310 prc_auc 0.58745[0m
[93maverage test of epoch 30: loss -34.03386 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -34.63288 acc 0.66667 roc_auc 0.36770 prc_auc 0.59299[0m
[93maverage test of epoch 31: loss -35.02630 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -35.62810 acc 0.66667 roc_auc 0.39090 prc_auc 0.61135[0m
[93maverage test of epoch 32: loss -36.01812 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -36.62310 acc 0.66667 roc_auc 0.41540 prc_auc 0.62654[0m
[93maverage test of epoch 33: loss -37.01049 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -37.61801 acc 0.66667 roc_auc 0.43170 prc_auc 0.63323[0m
[93maverage test of epoch 34: loss -38.00197 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -38.61280 acc 0.66667 roc_auc 0.43360 prc_auc 0.63643[0m
[93maverage test of epoch 35: loss -38.99408 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -39.60747 acc 0.66667 roc_auc 0.43480 prc_auc 0.63811[0m
[93maverage test of epoch 36: loss -39.98623 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -40.60204 acc 0.66667 roc_auc 0.43500 prc_auc 0.63948[0m
[93maverage test of epoch 37: loss -40.97780 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -41.59660 acc 0.66667 roc_auc 0.44000 prc_auc 0.64148[0m
[93maverage test of epoch 38: loss -41.96958 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -42.59101 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -42.96096 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -43.58550 acc 0.66667 roc_auc 0.49000 prc_auc 0.66225[0m
[93maverage test of epoch 40: loss -43.95275 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -44.58003 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -44.94433 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -45.57441 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -45.93564 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -46.56863 acc 0.66667 roc_auc 0.43000 prc_auc 0.63755[0m
[93maverage test of epoch 43: loss -46.92705 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -47.56300 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -47.91857 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -48.55731 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -48.91014 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -49.55156 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -49.90140 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -50.54567 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -50.89284 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -51.54003 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -51.88424 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -52.53418 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -52.87550 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -1.84061 acc 0.64000 roc_auc 0.47300 prc_auc 0.65191[0m
[93maverage test of epoch 0: loss -3.48075 acc 0.65789 roc_auc 0.47385 prc_auc 0.65045[0m
[92maverage training of epoch 1: loss -4.51641 acc 0.66667 roc_auc 0.46840 prc_auc 0.64466[0m
[93maverage test of epoch 1: loss -5.43927 acc 0.65789 roc_auc 0.60615 prc_auc 0.77059[0m
[92maverage training of epoch 2: loss -6.13217 acc 0.66667 roc_auc 0.42600 prc_auc 0.60783[0m
[93maverage test of epoch 2: loss -6.72068 acc 0.65789 roc_auc 0.58462 prc_auc 0.71927[0m
[92maverage training of epoch 3: loss -7.33162 acc 0.66667 roc_auc 0.42280 prc_auc 0.59890[0m
[93maverage test of epoch 3: loss -7.85426 acc 0.65789 roc_auc 0.52615 prc_auc 0.68749[0m
[92maverage training of epoch 4: loss -8.43677 acc 0.66667 roc_auc 0.43720 prc_auc 0.62066[0m
[93maverage test of epoch 4: loss -8.93649 acc 0.65789 roc_auc 0.49538 prc_auc 0.71734[0m
[92maverage training of epoch 5: loss -9.50794 acc 0.66667 roc_auc 0.42660 prc_auc 0.60372[0m
[93maverage test of epoch 5: loss -9.99220 acc 0.65789 roc_auc 0.55538 prc_auc 0.75133[0m
[92maverage training of epoch 6: loss -10.55769 acc 0.66667 roc_auc 0.42200 prc_auc 0.60562[0m
[93maverage test of epoch 6: loss -11.02956 acc 0.65789 roc_auc 0.49846 prc_auc 0.67836[0m
[92maverage training of epoch 7: loss -11.59272 acc 0.66667 roc_auc 0.41380 prc_auc 0.59144[0m
[93maverage test of epoch 7: loss -12.06141 acc 0.65789 roc_auc 0.71538 prc_auc 0.80829[0m
[92maverage training of epoch 8: loss -12.62206 acc 0.66667 roc_auc 0.41940 prc_auc 0.59980[0m
[93maverage test of epoch 8: loss -13.08054 acc 0.65789 roc_auc 0.36615 prc_auc 0.58131[0m
[92maverage training of epoch 9: loss -13.64395 acc 0.66667 roc_auc 0.42430 prc_auc 0.61211[0m
[93maverage test of epoch 9: loss -14.09757 acc 0.65789 roc_auc 0.48154 prc_auc 0.64333[0m
[92maverage training of epoch 10: loss -14.66034 acc 0.66667 roc_auc 0.42130 prc_auc 0.61001[0m
[93maverage test of epoch 10: loss -15.10798 acc 0.65789 roc_auc 0.40462 prc_auc 0.60913[0m
[92maverage training of epoch 11: loss -15.67328 acc 0.66667 roc_auc 0.42850 prc_auc 0.60949[0m
[93maverage test of epoch 11: loss -16.11719 acc 0.65789 roc_auc 0.56769 prc_auc 0.71452[0m
[92maverage training of epoch 12: loss -16.68262 acc 0.66667 roc_auc 0.42290 prc_auc 0.60153[0m
[93maverage test of epoch 12: loss -17.12280 acc 0.65789 roc_auc 0.55077 prc_auc 0.70371[0m
[92maverage training of epoch 13: loss -17.68949 acc 0.66667 roc_auc 0.41740 prc_auc 0.59881[0m
[93maverage test of epoch 13: loss -18.12550 acc 0.65789 roc_auc 0.36000 prc_auc 0.59391[0m
[92maverage training of epoch 14: loss -18.69483 acc 0.66667 roc_auc 0.42390 prc_auc 0.60513[0m
[93maverage test of epoch 14: loss -19.12640 acc 0.65789 roc_auc 0.46000 prc_auc 0.66613[0m
[92maverage training of epoch 15: loss -19.69761 acc 0.66667 roc_auc 0.41540 prc_auc 0.60103[0m
[93maverage test of epoch 15: loss -20.12660 acc 0.65789 roc_auc 0.44154 prc_auc 0.67055[0m
[92maverage training of epoch 16: loss -20.70008 acc 0.66667 roc_auc 0.41950 prc_auc 0.59992[0m
[93maverage test of epoch 16: loss -21.12456 acc 0.65789 roc_auc 0.68462 prc_auc 0.76658[0m
[92maverage training of epoch 17: loss -21.70072 acc 0.66667 roc_auc 0.42270 prc_auc 0.60284[0m
[93maverage test of epoch 17: loss -22.12213 acc 0.65789 roc_auc 0.44308 prc_auc 0.63381[0m
[92maverage training of epoch 18: loss -22.70065 acc 0.66667 roc_auc 0.42330 prc_auc 0.60462[0m
[93maverage test of epoch 18: loss -23.11818 acc 0.65789 roc_auc 0.51231 prc_auc 0.66617[0m
[92maverage training of epoch 19: loss -23.69937 acc 0.66667 roc_auc 0.42220 prc_auc 0.60296[0m
[93maverage test of epoch 19: loss -24.11521 acc 0.65789 roc_auc 0.51692 prc_auc 0.66561[0m
[92maverage training of epoch 20: loss -24.69782 acc 0.66667 roc_auc 0.42060 prc_auc 0.59879[0m
[93maverage test of epoch 20: loss -25.10890 acc 0.65789 roc_auc 0.47692 prc_auc 0.64771[0m
[92maverage training of epoch 21: loss -25.69534 acc 0.66667 roc_auc 0.42840 prc_auc 0.60803[0m
[93maverage test of epoch 21: loss -26.10463 acc 0.65789 roc_auc 0.53692 prc_auc 0.67498[0m
[92maverage training of epoch 22: loss -26.69279 acc 0.66667 roc_auc 0.42260 prc_auc 0.60228[0m
[93maverage test of epoch 22: loss -27.09882 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -27.68929 acc 0.66667 roc_auc 0.41880 prc_auc 0.60182[0m
[93maverage test of epoch 23: loss -28.09239 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -28.68644 acc 0.66667 roc_auc 0.42560 prc_auc 0.60869[0m
[93maverage test of epoch 24: loss -29.08629 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -29.68264 acc 0.66667 roc_auc 0.42380 prc_auc 0.61186[0m
[93maverage test of epoch 25: loss -30.07897 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -30.67856 acc 0.66667 roc_auc 0.41900 prc_auc 0.61171[0m
[93maverage test of epoch 26: loss -31.07172 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -31.67443 acc 0.66667 roc_auc 0.43180 prc_auc 0.62133[0m
[93maverage test of epoch 27: loss -32.06467 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -32.66984 acc 0.66667 roc_auc 0.44720 prc_auc 0.63169[0m
[93maverage test of epoch 28: loss -33.05766 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -33.66533 acc 0.66667 roc_auc 0.44120 prc_auc 0.63084[0m
[93maverage test of epoch 29: loss -34.04994 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -34.66044 acc 0.66667 roc_auc 0.41700 prc_auc 0.62272[0m
[93maverage test of epoch 30: loss -35.04230 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -35.65537 acc 0.66667 roc_auc 0.44320 prc_auc 0.63608[0m
[93maverage test of epoch 31: loss -36.03453 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -36.65041 acc 0.66667 roc_auc 0.46000 prc_auc 0.64965[0m
[93maverage test of epoch 32: loss -37.02662 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -37.64499 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 33: loss -38.01851 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -38.63978 acc 0.66667 roc_auc 0.48500 prc_auc 0.66010[0m
[93maverage test of epoch 34: loss -39.01056 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -39.63458 acc 0.66667 roc_auc 0.42500 prc_auc 0.63772[0m
[93maverage test of epoch 35: loss -40.00226 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -40.62919 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -40.99406 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -41.62381 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -41.98541 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -42.61831 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -42.97744 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -43.61277 acc 0.66667 roc_auc 0.49000 prc_auc 0.66226[0m
[93maverage test of epoch 39: loss -43.96885 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -44.60715 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -44.96040 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -45.60154 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -45.95210 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -46.59601 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -46.94369 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -47.59038 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -47.93512 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -48.58463 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -48.92663 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -49.57894 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -49.91799 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -50.57326 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -50.90929 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -51.56758 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -51.90059 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -52.56166 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -52.89219 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -53.55597 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -53.88373 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -0.96849 acc 0.61333 roc_auc 0.41340 prc_auc 0.60331[0m
[93maverage test of epoch 0: loss -2.63711 acc 0.65789 roc_auc 0.42154 prc_auc 0.64336[0m
[92maverage training of epoch 1: loss -3.78040 acc 0.66667 roc_auc 0.39880 prc_auc 0.58909[0m
[93maverage test of epoch 1: loss -4.56983 acc 0.65789 roc_auc 0.45846 prc_auc 0.67181[0m
[92maverage training of epoch 2: loss -5.29480 acc 0.66667 roc_auc 0.45240 prc_auc 0.65837[0m
[93maverage test of epoch 2: loss -6.13728 acc 0.65789 roc_auc 0.59077 prc_auc 0.72984[0m
[92maverage training of epoch 3: loss -6.82093 acc 0.66667 roc_auc 0.40160 prc_auc 0.61387[0m
[93maverage test of epoch 3: loss -7.41636 acc 0.65789 roc_auc 0.47385 prc_auc 0.65484[0m
[92maverage training of epoch 4: loss -8.01204 acc 0.66667 roc_auc 0.45230 prc_auc 0.62667[0m
[93maverage test of epoch 4: loss -8.56779 acc 0.65789 roc_auc 0.66154 prc_auc 0.74523[0m
[92maverage training of epoch 5: loss -9.17823 acc 0.66667 roc_auc 0.32560 prc_auc 0.57173[0m
[93maverage test of epoch 5: loss -9.75404 acc 0.65789 roc_auc 0.46462 prc_auc 0.68263[0m
[92maverage training of epoch 6: loss -10.34654 acc 0.66667 roc_auc 0.37940 prc_auc 0.59633[0m
[93maverage test of epoch 6: loss -10.88421 acc 0.65789 roc_auc 0.55077 prc_auc 0.69232[0m
[92maverage training of epoch 7: loss -11.46553 acc 0.66667 roc_auc 0.37780 prc_auc 0.57197[0m
[93maverage test of epoch 7: loss -11.97643 acc 0.65789 roc_auc 0.57846 prc_auc 0.76739[0m
[92maverage training of epoch 8: loss -12.54814 acc 0.66667 roc_auc 0.38240 prc_auc 0.58756[0m
[93maverage test of epoch 8: loss -13.05227 acc 0.65789 roc_auc 0.68769 prc_auc 0.84481[0m
[92maverage training of epoch 9: loss -13.61464 acc 0.66667 roc_auc 0.37300 prc_auc 0.57885[0m
[93maverage test of epoch 9: loss -14.10290 acc 0.65789 roc_auc 0.29538 prc_auc 0.54809[0m
[92maverage training of epoch 10: loss -14.66363 acc 0.66667 roc_auc 0.38420 prc_auc 0.58083[0m
[93maverage test of epoch 10: loss -15.14122 acc 0.65789 roc_auc 0.56923 prc_auc 0.77352[0m
[92maverage training of epoch 11: loss -15.70150 acc 0.66667 roc_auc 0.38310 prc_auc 0.58205[0m
[93maverage test of epoch 11: loss -16.17435 acc 0.65789 roc_auc 0.44615 prc_auc 0.65236[0m
[92maverage training of epoch 12: loss -16.73097 acc 0.66667 roc_auc 0.37690 prc_auc 0.57610[0m
[93maverage test of epoch 12: loss -17.19641 acc 0.65789 roc_auc 0.39077 prc_auc 0.65827[0m
[92maverage training of epoch 13: loss -17.75422 acc 0.66667 roc_auc 0.37570 prc_auc 0.57769[0m
[93maverage test of epoch 13: loss -18.21504 acc 0.65789 roc_auc 0.44000 prc_auc 0.66924[0m
[92maverage training of epoch 14: loss -18.77286 acc 0.66667 roc_auc 0.37510 prc_auc 0.57173[0m
[93maverage test of epoch 14: loss -19.22936 acc 0.65789 roc_auc 0.51692 prc_auc 0.68365[0m
[92maverage training of epoch 15: loss -19.78877 acc 0.66667 roc_auc 0.37960 prc_auc 0.57679[0m
[93maverage test of epoch 15: loss -20.23947 acc 0.65789 roc_auc 0.66462 prc_auc 0.76224[0m
[92maverage training of epoch 16: loss -20.79949 acc 0.66667 roc_auc 0.37720 prc_auc 0.58145[0m
[93maverage test of epoch 16: loss -21.24672 acc 0.65789 roc_auc 0.54769 prc_auc 0.68456[0m
[92maverage training of epoch 17: loss -21.80890 acc 0.66667 roc_auc 0.37820 prc_auc 0.57725[0m
[93maverage test of epoch 17: loss -22.25187 acc 0.65789 roc_auc 0.36462 prc_auc 0.59177[0m
[92maverage training of epoch 18: loss -22.81483 acc 0.66667 roc_auc 0.37800 prc_auc 0.57597[0m
[93maverage test of epoch 18: loss -23.25325 acc 0.65789 roc_auc 0.43538 prc_auc 0.63121[0m
[92maverage training of epoch 19: loss -23.82028 acc 0.66667 roc_auc 0.37850 prc_auc 0.57768[0m
[93maverage test of epoch 19: loss -24.25617 acc 0.65789 roc_auc 0.40154 prc_auc 0.61421[0m
[92maverage training of epoch 20: loss -24.82297 acc 0.66667 roc_auc 0.37600 prc_auc 0.57645[0m
[93maverage test of epoch 20: loss -25.25417 acc 0.65789 roc_auc 0.63538 prc_auc 0.72788[0m
[92maverage training of epoch 21: loss -25.82485 acc 0.66667 roc_auc 0.37760 prc_auc 0.57700[0m
[93maverage test of epoch 21: loss -26.25348 acc 0.65789 roc_auc 0.53077 prc_auc 0.67319[0m
[92maverage training of epoch 22: loss -26.82555 acc 0.66667 roc_auc 0.37950 prc_auc 0.57793[0m
[93maverage test of epoch 22: loss -27.24994 acc 0.65789 roc_auc 0.39077 prc_auc 0.61041[0m
[92maverage training of epoch 23: loss -27.82564 acc 0.66667 roc_auc 0.37800 prc_auc 0.57705[0m
[93maverage test of epoch 23: loss -28.24675 acc 0.65789 roc_auc 0.57385 prc_auc 0.69419[0m
[92maverage training of epoch 24: loss -28.82373 acc 0.66667 roc_auc 0.37290 prc_auc 0.57249[0m
[93maverage test of epoch 24: loss -29.24330 acc 0.65789 roc_auc 0.51846 prc_auc 0.66632[0m
[92maverage training of epoch 25: loss -29.82333 acc 0.66667 roc_auc 0.38120 prc_auc 0.58095[0m
[93maverage test of epoch 25: loss -30.23799 acc 0.65789 roc_auc 0.53846 prc_auc 0.67568[0m
[92maverage training of epoch 26: loss -30.82091 acc 0.66667 roc_auc 0.37870 prc_auc 0.58100[0m
[93maverage test of epoch 26: loss -31.23265 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -31.81795 acc 0.66667 roc_auc 0.37670 prc_auc 0.58002[0m
[93maverage test of epoch 27: loss -32.22723 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -32.81495 acc 0.66667 roc_auc 0.37400 prc_auc 0.58223[0m
[93maverage test of epoch 28: loss -33.22106 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -33.81153 acc 0.66667 roc_auc 0.37630 prc_auc 0.58359[0m
[93maverage test of epoch 29: loss -34.21389 acc 0.65789 roc_auc 0.48000 prc_auc 0.64902[0m
[92maverage training of epoch 30: loss -34.80786 acc 0.66667 roc_auc 0.38360 prc_auc 0.58794[0m
[93maverage test of epoch 30: loss -35.20803 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -35.80359 acc 0.66667 roc_auc 0.39340 prc_auc 0.59998[0m
[93maverage test of epoch 31: loss -36.20077 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -36.79897 acc 0.66667 roc_auc 0.39680 prc_auc 0.60284[0m
[93maverage test of epoch 32: loss -37.19329 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -37.79458 acc 0.66667 roc_auc 0.38720 prc_auc 0.60060[0m
[93maverage test of epoch 33: loss -38.18540 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -38.78965 acc 0.66667 roc_auc 0.40640 prc_auc 0.61566[0m
[93maverage test of epoch 34: loss -39.17808 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -39.78475 acc 0.66667 roc_auc 0.39110 prc_auc 0.61138[0m
[93maverage test of epoch 35: loss -40.16957 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -40.77973 acc 0.66667 roc_auc 0.40710 prc_auc 0.62916[0m
[93maverage test of epoch 36: loss -41.16202 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -41.77457 acc 0.66667 roc_auc 0.44440 prc_auc 0.64154[0m
[93maverage test of epoch 37: loss -42.15427 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -42.76961 acc 0.66667 roc_auc 0.39520 prc_auc 0.62360[0m
[93maverage test of epoch 38: loss -43.14602 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -43.76414 acc 0.66667 roc_auc 0.39500 prc_auc 0.63485[0m
[93maverage test of epoch 39: loss -44.13778 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -44.75855 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -45.12977 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -45.75315 acc 0.66667 roc_auc 0.43500 prc_auc 0.63969[0m
[93maverage test of epoch 41: loss -46.12124 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -46.74769 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -47.11283 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -47.74193 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -48.10433 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -48.73622 acc 0.66667 roc_auc 0.39500 prc_auc 0.63256[0m
[93maverage test of epoch 44: loss -49.09581 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -49.73062 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -50.08752 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -50.72503 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -51.07890 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -51.71928 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -52.07018 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -52.71358 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -53.06138 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -53.70765 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -54.05311 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -0.58207 acc 0.50993 roc_auc 0.38000 prc_auc 0.58022[0m
[93maverage test of epoch 0: loss -1.28559 acc 0.67568 roc_auc 0.40667 prc_auc 0.66709[0m
[92maverage training of epoch 1: loss -2.04318 acc 0.66225 roc_auc 0.39353 prc_auc 0.58331[0m
[93maverage test of epoch 1: loss -2.93054 acc 0.67568 roc_auc 0.52667 prc_auc 0.71277[0m
[92maverage training of epoch 2: loss -3.61711 acc 0.66225 roc_auc 0.40725 prc_auc 0.60255[0m
[93maverage test of epoch 2: loss -4.62802 acc 0.67568 roc_auc 0.51667 prc_auc 0.67875[0m
[92maverage training of epoch 3: loss -5.26714 acc 0.66225 roc_auc 0.36922 prc_auc 0.57006[0m
[93maverage test of epoch 3: loss -6.07145 acc 0.67568 roc_auc 0.45833 prc_auc 0.69634[0m
[92maverage training of epoch 4: loss -6.58560 acc 0.66225 roc_auc 0.41196 prc_auc 0.59391[0m
[93maverage test of epoch 4: loss -7.30461 acc 0.67568 roc_auc 0.44833 prc_auc 0.69888[0m
[92maverage training of epoch 5: loss -7.76599 acc 0.66225 roc_auc 0.39147 prc_auc 0.58859[0m
[93maverage test of epoch 5: loss -8.46313 acc 0.67568 roc_auc 0.40667 prc_auc 0.62051[0m
[92maverage training of epoch 6: loss -8.89741 acc 0.66225 roc_auc 0.37941 prc_auc 0.58141[0m
[93maverage test of epoch 6: loss -9.57142 acc 0.67568 roc_auc 0.30833 prc_auc 0.57816[0m
[92maverage training of epoch 7: loss -9.98847 acc 0.66225 roc_auc 0.37069 prc_auc 0.57453[0m
[93maverage test of epoch 7: loss -10.66336 acc 0.67568 roc_auc 0.60833 prc_auc 0.78847[0m
[92maverage training of epoch 8: loss -11.06084 acc 0.66225 roc_auc 0.38363 prc_auc 0.57559[0m
[93maverage test of epoch 8: loss -11.72988 acc 0.67568 roc_auc 0.62833 prc_auc 0.78002[0m
[92maverage training of epoch 9: loss -12.11967 acc 0.66225 roc_auc 0.37784 prc_auc 0.57340[0m
[93maverage test of epoch 9: loss -12.78511 acc 0.67568 roc_auc 0.52333 prc_auc 0.70095[0m
[92maverage training of epoch 10: loss -13.16364 acc 0.66225 roc_auc 0.37294 prc_auc 0.56815[0m
[93maverage test of epoch 10: loss -13.82942 acc 0.67568 roc_auc 0.56667 prc_auc 0.71390[0m
[92maverage training of epoch 11: loss -14.20117 acc 0.66225 roc_auc 0.38480 prc_auc 0.57959[0m
[93maverage test of epoch 11: loss -14.86585 acc 0.67568 roc_auc 0.38000 prc_auc 0.62315[0m
[92maverage training of epoch 12: loss -15.23104 acc 0.66225 roc_auc 0.38235 prc_auc 0.57867[0m
[93maverage test of epoch 12: loss -15.89632 acc 0.67568 roc_auc 0.33333 prc_auc 0.60199[0m
[92maverage training of epoch 13: loss -16.25411 acc 0.66225 roc_auc 0.37637 prc_auc 0.57395[0m
[93maverage test of epoch 13: loss -16.92273 acc 0.67568 roc_auc 0.51000 prc_auc 0.68157[0m
[92maverage training of epoch 14: loss -17.27562 acc 0.66225 roc_auc 0.37157 prc_auc 0.57315[0m
[93maverage test of epoch 14: loss -17.94754 acc 0.67568 roc_auc 0.52000 prc_auc 0.68542[0m
[92maverage training of epoch 15: loss -18.29218 acc 0.66225 roc_auc 0.37265 prc_auc 0.57598[0m
[93maverage test of epoch 15: loss -18.96696 acc 0.67568 roc_auc 0.61500 prc_auc 0.73535[0m
[92maverage training of epoch 16: loss -19.30668 acc 0.66225 roc_auc 0.37304 prc_auc 0.57719[0m
[93maverage test of epoch 16: loss -19.98286 acc 0.67568 roc_auc 0.48000 prc_auc 0.66703[0m
[92maverage training of epoch 17: loss -20.31862 acc 0.66225 roc_auc 0.38461 prc_auc 0.58664[0m
[93maverage test of epoch 17: loss -20.99895 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 18: loss -21.32825 acc 0.66225 roc_auc 0.38490 prc_auc 0.59265[0m
[93maverage test of epoch 18: loss -22.01207 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 19: loss -22.33604 acc 0.66225 roc_auc 0.38480 prc_auc 0.59172[0m
[93maverage test of epoch 19: loss -23.02331 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 20: loss -23.34310 acc 0.66225 roc_auc 0.38098 prc_auc 0.59458[0m
[93maverage test of epoch 20: loss -24.03442 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 21: loss -24.34812 acc 0.66225 roc_auc 0.37029 prc_auc 0.59822[0m
[93maverage test of epoch 21: loss -25.04420 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 22: loss -25.35318 acc 0.66225 roc_auc 0.37127 prc_auc 0.59955[0m
[93maverage test of epoch 22: loss -26.05063 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 23: loss -26.35697 acc 0.66225 roc_auc 0.43618 prc_auc 0.63126[0m
[93maverage test of epoch 23: loss -27.05963 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 24: loss -27.35982 acc 0.66225 roc_auc 0.38078 prc_auc 0.61129[0m
[93maverage test of epoch 24: loss -28.06631 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 25: loss -28.36231 acc 0.66225 roc_auc 0.43206 prc_auc 0.63412[0m
[93maverage test of epoch 25: loss -29.07304 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 26: loss -29.36393 acc 0.66225 roc_auc 0.45088 prc_auc 0.64167[0m
[93maverage test of epoch 26: loss -30.07876 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 27: loss -30.36550 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 27: loss -31.08410 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 28: loss -31.36651 acc 0.66225 roc_auc 0.44784 prc_auc 0.64007[0m
[93maverage test of epoch 28: loss -32.08930 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 29: loss -32.36722 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 29: loss -33.09389 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 30: loss -33.36741 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 30: loss -34.09802 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 31: loss -34.36765 acc 0.66225 roc_auc 0.39549 prc_auc 0.62354[0m
[93maverage test of epoch 31: loss -35.10218 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 32: loss -35.36749 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 32: loss -36.10644 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 33: loss -36.36719 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 33: loss -37.11008 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 34: loss -37.36698 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 34: loss -38.11453 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 35: loss -38.36643 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 35: loss -39.11792 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 36: loss -39.36559 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 36: loss -40.12117 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 37: loss -40.36489 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 37: loss -41.12511 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 38: loss -41.36400 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 38: loss -42.12822 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 39: loss -42.36307 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 39: loss -43.13117 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -43.36216 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 40: loss -44.13494 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -44.36109 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 41: loss -45.13788 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -45.35991 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 42: loss -46.14112 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -46.35871 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 43: loss -47.14415 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -47.35751 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 44: loss -48.14688 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -48.35608 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 45: loss -49.15016 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -49.35499 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 46: loss -50.15295 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -50.35374 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 47: loss -51.15591 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -51.35231 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 48: loss -52.15894 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -52.35100 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 49: loss -53.16165 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -1.05557 acc 0.63576 roc_auc 0.40706 prc_auc 0.60101[0m
[93maverage test of epoch 0: loss -2.18968 acc 0.67568 roc_auc 0.39000 prc_auc 0.65827[0m
[92maverage training of epoch 1: loss -2.97333 acc 0.66225 roc_auc 0.38706 prc_auc 0.58400[0m
[93maverage test of epoch 1: loss -3.80300 acc 0.67568 roc_auc 0.36333 prc_auc 0.59055[0m
[92maverage training of epoch 2: loss -4.44130 acc 0.66225 roc_auc 0.40725 prc_auc 0.58601[0m
[93maverage test of epoch 2: loss -5.20282 acc 0.67568 roc_auc 0.25667 prc_auc 0.62192[0m
[92maverage training of epoch 3: loss -5.77291 acc 0.66225 roc_auc 0.41765 prc_auc 0.61547[0m
[93maverage test of epoch 3: loss -6.55590 acc 0.67568 roc_auc 0.62667 prc_auc 0.79953[0m
[92maverage training of epoch 4: loss -7.14544 acc 0.66225 roc_auc 0.37333 prc_auc 0.57341[0m
[93maverage test of epoch 4: loss -7.85915 acc 0.67568 roc_auc 0.52167 prc_auc 0.67017[0mUsing backend: pytorch

[92maverage training of epoch 5: loss -8.37265 acc 0.66225 roc_auc 0.37784 prc_auc 0.58232[0m
[93maverage test of epoch 5: loss -9.02434 acc 0.67568 roc_auc 0.43667 prc_auc 0.67805[0m
[92maverage training of epoch 6: loss -9.51345 acc 0.66225 roc_auc 0.37441 prc_auc 0.57660[0m
[93maverage test of epoch 6: loss -10.15517 acc 0.67568 roc_auc 0.55833 prc_auc 0.72426[0m
[92maverage training of epoch 7: loss -10.61039 acc 0.66225 roc_auc 0.37167 prc_auc 0.57074[0m
[93maverage test of epoch 7: loss -11.23666 acc 0.67568 roc_auc 0.42667 prc_auc 0.66957[0m
[92maverage training of epoch 8: loss -11.68918 acc 0.66225 roc_auc 0.36686 prc_auc 0.56643[0m
[93maverage test of epoch 8: loss -12.31266 acc 0.67568 roc_auc 0.43833 prc_auc 0.68259[0m
[92maverage training of epoch 9: loss -12.74603 acc 0.66225 roc_auc 0.36853 prc_auc 0.57146[0m
[93maverage test of epoch 9: loss -13.36638 acc 0.67568 roc_auc 0.29000 prc_auc 0.56134[0m
[92maverage training of epoch 10: loss -13.79325 acc 0.66225 roc_auc 0.37098 prc_auc 0.57197[0m
[93maverage test of epoch 10: loss -14.41276 acc 0.67568 roc_auc 0.49000 prc_auc 0.68673[0m
[92maverage training of epoch 11: loss -14.82942 acc 0.66225 roc_auc 0.36853 prc_auc 0.56702[0m
[93maverage test of epoch 11: loss -15.45086 acc 0.67568 roc_auc 0.41000 prc_auc 0.66742[0m
[92maverage training of epoch 12: loss -15.86109 acc 0.66225 roc_auc 0.36941 prc_auc 0.56953[0m
[93maverage test of epoch 12: loss -16.48073 acc 0.67568 roc_auc 0.38167 prc_auc 0.60101[0m
[92maverage training of epoch 13: loss -16.88537 acc 0.66225 roc_auc 0.36853 prc_auc 0.56972[0m
[93maverage test of epoch 13: loss -17.50872 acc 0.67568 roc_auc 0.40333 prc_auc 0.63962[0m
[92maverage training of epoch 14: loss -17.90585 acc 0.66225 roc_auc 0.37108 prc_auc 0.56854[0m
[93maverage test of epoch 14: loss -18.53368 acc 0.67568 roc_auc 0.61667 prc_auc 0.79723[0m
[92maverage training of epoch 15: loss -18.92338 acc 0.66225 roc_auc 0.37010 prc_auc 0.57114[0m
[93maverage test of epoch 15: loss -19.55497 acc 0.67568 roc_auc 0.58167 prc_auc 0.71815[0m
[92maverage training of epoch 16: loss -19.93754 acc 0.66225 roc_auc 0.37088 prc_auc 0.57009[0m
[93maverage test of epoch 16: loss -20.57134 acc 0.67568 roc_auc 0.43667 prc_auc 0.66517[0m
[92maverage training of epoch 17: loss -20.94951 acc 0.66225 roc_auc 0.36706 prc_auc 0.56850[0m
[93maverage test of epoch 17: loss -21.58568 acc 0.67568 roc_auc 0.49833 prc_auc 0.68596[0m
[92maverage training of epoch 18: loss -21.95839 acc 0.66225 roc_auc 0.36873 prc_auc 0.56757[0m
[93maverage test of epoch 18: loss -22.59932 acc 0.67568 roc_auc 0.32500 prc_auc 0.60357[0m
[92maverage training of epoch 19: loss -22.96801 acc 0.66225 roc_auc 0.37000 prc_auc 0.56863[0m
[93maverage test of epoch 19: loss -23.61088 acc 0.67568 roc_auc 0.53167 prc_auc 0.69344[0m
[92maverage training of epoch 20: loss -23.97447 acc 0.66225 roc_auc 0.37088 prc_auc 0.57256[0m
[93maverage test of epoch 20: loss -24.62065 acc 0.67568 roc_auc 0.53000 prc_auc 0.68900[0m
[92maverage training of epoch 21: loss -24.98010 acc 0.66225 roc_auc 0.36833 prc_auc 0.56739[0m
[93maverage test of epoch 21: loss -25.62884 acc 0.67568 roc_auc 0.40000 prc_auc 0.63456[0m
[92maverage training of epoch 22: loss -25.98449 acc 0.66225 roc_auc 0.36657 prc_auc 0.56912[0m
[93maverage test of epoch 22: loss -26.63892 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 23: loss -26.98860 acc 0.66225 roc_auc 0.36637 prc_auc 0.56859[0m
[93maverage test of epoch 23: loss -27.64675 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 24: loss -27.99151 acc 0.66225 roc_auc 0.36824 prc_auc 0.57347[0m
[93maverage test of epoch 24: loss -28.65352 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 25: loss -28.99346 acc 0.66225 roc_auc 0.36745 prc_auc 0.57165[0m
[93maverage test of epoch 25: loss -29.66019 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 26: loss -29.99595 acc 0.66225 roc_auc 0.36824 prc_auc 0.57767[0m
[93maverage test of epoch 26: loss -30.66576 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 27: loss -30.99747 acc 0.66225 roc_auc 0.37020 prc_auc 0.57966[0m
[93maverage test of epoch 27: loss -31.67180 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 28: loss -31.99860 acc 0.66225 roc_auc 0.36951 prc_auc 0.58021[0m
[93maverage test of epoch 28: loss -32.67632 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 29: loss -32.99925 acc 0.66225 roc_auc 0.37510 prc_auc 0.58819[0m
[93maverage test of epoch 29: loss -33.68138 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 30: loss -33.99965 acc 0.66225 roc_auc 0.39265 prc_auc 0.60089[0m
[93maverage test of epoch 30: loss -34.68606 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 31: loss -34.99993 acc 0.66225 roc_auc 0.38990 prc_auc 0.60085[0m
[93maverage test of epoch 31: loss -35.69062 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 32: loss -35.99996 acc 0.66225 roc_auc 0.41039 prc_auc 0.61783[0m
[93maverage test of epoch 32: loss -36.69433 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 33: loss -36.99949 acc 0.66225 roc_auc 0.35784 prc_auc 0.59730[0m
[93maverage test of epoch 33: loss -37.69875 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 34: loss -37.99918 acc 0.66225 roc_auc 0.43265 prc_auc 0.63415[0m
[93maverage test of epoch 34: loss -38.70256 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 35: loss -38.99890 acc 0.66225 roc_auc 0.36235 prc_auc 0.60809[0m
[93maverage test of epoch 35: loss -39.70558 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 36: loss -39.99839 acc 0.66225 roc_auc 0.35931 prc_auc 0.62372[0m
[93maverage test of epoch 36: loss -40.70956 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 37: loss -40.99758 acc 0.66225 roc_auc 0.48980 prc_auc 0.65772[0m
[93maverage test of epoch 37: loss -41.71340 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 38: loss -41.99689 acc 0.66225 roc_auc 0.44206 prc_auc 0.63794[0m
[93maverage test of epoch 38: loss -42.71612 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 39: loss -42.99582 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 39: loss -43.71989 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -43.99467 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 40: loss -44.72305 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -44.99385 acc 0.66225 roc_auc 0.44637 prc_auc 0.65138[0m
[93maverage test of epoch 41: loss -45.72618 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -45.99286 acc 0.66225 roc_auc 0.48382 prc_auc 0.65511[0m
[93maverage test of epoch 42: loss -46.72903 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -46.99170 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 43: loss -47.73248 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -47.99055 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 44: loss -48.73556 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -48.98936 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 45: loss -49.73870 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -49.98807 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 46: loss -50.74175 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -50.98682 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 47: loss -51.74465 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -51.98552 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 48: loss -52.74765 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -52.98438 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 49: loss -53.75049 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.66501 ROC_AUC (avg): 0.5 PRC_AUC (avg): 0.66501 

Average forward propagation time taken(ms): 3.9584830897003727
Average backward propagation time taken(ms): 1.5089190935337744

