# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 1)
('lr', 0.0001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-00-04-37/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-00-04-37/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 8,
 'epochs': 100,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 4,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.0001,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 1,
 'num_workers': 8,
 'number_of_mlp_layer': 1,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-18-00-04-37',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 100, 'learning_rate': 0.0001, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss 0.25479 acc 0.33333 roc_auc 0.57700 prc_auc 0.73097[0m
[93maverage test of epoch 0: loss 0.22593 acc 0.34211 roc_auc 0.26615 prc_auc 0.62352[0m
[92maverage training of epoch 1: loss 0.14527 acc 0.33333 roc_auc 0.54760 prc_auc 0.71848[0m
[93maverage test of epoch 1: loss -0.11152 acc 0.34211 roc_auc 0.80923 prc_auc 0.91291[0m
[92maverage training of epoch 2: loss -0.41480 acc 0.33333 roc_auc 0.57680 prc_auc 0.72633[0m
[93maverage test of epoch 2: loss -0.69539 acc 0.34211 roc_auc 0.52308 prc_auc 0.79152[0m
[92maverage training of epoch 3: loss -0.93966 acc 0.33333 roc_auc 0.58160 prc_auc 0.73303[0m
[93maverage test of epoch 3: loss -1.18831 acc 0.34211 roc_auc 0.48000 prc_auc 0.76943[0m
[92maverage training of epoch 4: loss -1.41349 acc 0.33333 roc_auc 0.58480 prc_auc 0.73421[0m
[93maverage test of epoch 4: loss -1.65152 acc 0.34211 roc_auc 0.40154 prc_auc 0.71838[0m
[92maverage training of epoch 5: loss -1.84305 acc 0.33333 roc_auc 0.59600 prc_auc 0.74240[0m
[93maverage test of epoch 5: loss -2.04838 acc 0.34211 roc_auc 0.48308 prc_auc 0.77129[0m
[92maverage training of epoch 6: loss -2.23693 acc 0.33333 roc_auc 0.59400 prc_auc 0.74460[0m
[93maverage test of epoch 6: loss -2.44993 acc 0.34211 roc_auc 0.80154 prc_auc 0.90634[0m
[92maverage training of epoch 7: loss -2.65411 acc 0.33333 roc_auc 0.58840 prc_auc 0.74125[0m
[93maverage test of epoch 7: loss -2.89074 acc 0.34211 roc_auc 0.69077 prc_auc 0.87243[0m
[92maverage training of epoch 8: loss -3.13056 acc 0.33333 roc_auc 0.58620 prc_auc 0.73551[0m
[93maverage test of epoch 8: loss -3.41352 acc 0.34211 roc_auc 0.52923 prc_auc 0.79973[0m
[92maverage training of epoch 9: loss -3.71383 acc 0.33333 roc_auc 0.58760 prc_auc 0.73595[0m
[93maverage test of epoch 9: loss -4.07068 acc 0.34211 roc_auc 0.21385 prc_auc 0.56965[0m
[92maverage training of epoch 10: loss -4.45295 acc 0.33333 roc_auc 0.58960 prc_auc 0.73738[0m
[93maverage test of epoch 10: loss -4.89984 acc 0.34211 roc_auc 0.47385 prc_auc 0.76671[0m
[92maverage training of epoch 11: loss -5.35071 acc 0.33333 roc_auc 0.59580 prc_auc 0.74400[0m
[93maverage test of epoch 11: loss -5.85087 acc 0.34211 roc_auc 0.69846 prc_auc 0.86127[0m
[92maverage training of epoch 12: loss -6.29763 acc 0.33333 roc_auc 0.60820 prc_auc 0.75724[0m
[93maverage test of epoch 12: loss -6.76828 acc 0.34211 roc_auc 0.84308 prc_auc 0.91506[0m
[92maverage training of epoch 13: loss -7.15928 acc 0.33333 roc_auc 0.61760 prc_auc 0.76920[0m
[93maverage test of epoch 13: loss -7.56709 acc 0.34211 roc_auc 0.85846 prc_auc 0.92975[0m
[92maverage training of epoch 14: loss -7.89948 acc 0.33333 roc_auc 0.62040 prc_auc 0.77657[0m
[93maverage test of epoch 14: loss -8.24732 acc 0.34211 roc_auc 0.85846 prc_auc 0.92975[0m
[92maverage training of epoch 15: loss -8.53003 acc 0.33333 roc_auc 0.61870 prc_auc 0.77614[0m
[93maverage test of epoch 15: loss -8.83065 acc 0.34211 roc_auc 0.86154 prc_auc 0.93308[0m
[92maverage training of epoch 16: loss -9.07781 acc 0.33333 roc_auc 0.60780 prc_auc 0.76826[0m
[93maverage test of epoch 16: loss -9.34621 acc 0.34211 roc_auc 0.86154 prc_auc 0.93308[0m
[92maverage training of epoch 17: loss -9.56958 acc 0.33333 roc_auc 0.59100 prc_auc 0.76018[0m
[93maverage test of epoch 17: loss -9.81684 acc 0.34211 roc_auc 0.82923 prc_auc 0.92102[0m
[92maverage training of epoch 18: loss -10.02445 acc 0.33333 roc_auc 0.55730 prc_auc 0.72848[0m
[93maverage test of epoch 18: loss -10.25782 acc 0.34211 roc_auc 0.83385 prc_auc 0.92488[0m
[92maverage training of epoch 19: loss -10.45465 acc 0.33333 roc_auc 0.49570 prc_auc 0.67830[0m
[93maverage test of epoch 19: loss -10.67853 acc 0.34211 roc_auc 0.83077 prc_auc 0.92180[0m
[92maverage training of epoch 20: loss -10.86769 acc 0.33333 roc_auc 0.47140 prc_auc 0.64919[0m
[93maverage test of epoch 20: loss -11.08489 acc 0.34211 roc_auc 0.83077 prc_auc 0.92443[0m
[92maverage training of epoch 21: loss -11.26842 acc 0.33333 roc_auc 0.45330 prc_auc 0.61791[0m
[93maverage test of epoch 21: loss -11.48078 acc 0.34211 roc_auc 0.80154 prc_auc 0.91576[0m
[92maverage training of epoch 22: loss -11.66007 acc 0.33333 roc_auc 0.43780 prc_auc 0.61076[0m
[93maverage test of epoch 22: loss -11.86888 acc 0.34211 roc_auc 0.80769 prc_auc 0.92093[0m
[92maverage training of epoch 23: loss -12.04488 acc 0.33333 roc_auc 0.42500 prc_auc 0.60408[0m
[93maverage test of epoch 23: loss -12.25106 acc 0.34211 roc_auc 0.66462 prc_auc 0.84016[0m
[92maverage training of epoch 24: loss -12.42450 acc 0.33333 roc_auc 0.41580 prc_auc 0.60030[0m
[93maverage test of epoch 24: loss -12.62873 acc 0.34211 roc_auc 0.40154 prc_auc 0.69309[0m
[92maverage training of epoch 25: loss -12.80015 acc 0.33333 roc_auc 0.40920 prc_auc 0.59726[0m
[93maverage test of epoch 25: loss -13.00293 acc 0.34211 roc_auc 0.29538 prc_auc 0.58665[0m
[92maverage training of epoch 26: loss -13.17275 acc 0.33333 roc_auc 0.40490 prc_auc 0.59640[0m
[93maverage test of epoch 26: loss -13.37450 acc 0.34211 roc_auc 0.18154 prc_auc 0.53283[0m
[92maverage training of epoch 27: loss -13.54310 acc 0.33333 roc_auc 0.39860 prc_auc 0.59499[0m
[93maverage test of epoch 27: loss -13.74418 acc 0.34211 roc_auc 0.14615 prc_auc 0.49667[0m
[92maverage training of epoch 28: loss -13.91189 acc 0.33333 roc_auc 0.39340 prc_auc 0.59212[0m
[93maverage test of epoch 28: loss -14.11262 acc 0.34211 roc_auc 0.07385 prc_auc 0.48015[0m
[92maverage training of epoch 29: loss -14.27972 acc 0.33333 roc_auc 0.37910 prc_auc 0.58692[0m
[93maverage test of epoch 29: loss -14.48035 acc 0.34211 roc_auc 0.07692 prc_auc 0.47133[0m
[92maverage training of epoch 30: loss -14.64707 acc 0.33333 roc_auc 0.37320 prc_auc 0.58526[0m
[93maverage test of epoch 30: loss -14.84781 acc 0.34211 roc_auc 0.08923 prc_auc 0.47823[0m
[92maverage training of epoch 31: loss -15.01437 acc 0.33333 roc_auc 0.37320 prc_auc 0.58526[0m
[93maverage test of epoch 31: loss -15.21540 acc 0.34211 roc_auc 0.08154 prc_auc 0.47195[0m
[92maverage training of epoch 32: loss -15.38198 acc 0.33333 roc_auc 0.37620 prc_auc 0.58611[0m
[93maverage test of epoch 32: loss -15.58344 acc 0.34211 roc_auc 0.10154 prc_auc 0.47925[0m
[92maverage training of epoch 33: loss -15.75020 acc 0.33333 roc_auc 0.37520 prc_auc 0.58511[0m
[93maverage test of epoch 33: loss -15.95224 acc 0.34211 roc_auc 0.09692 prc_auc 0.48243[0m
[92maverage training of epoch 34: loss -16.11933 acc 0.33333 roc_auc 0.37080 prc_auc 0.58362[0m
[93maverage test of epoch 34: loss -16.32206 acc 0.34211 roc_auc 0.12769 prc_auc 0.48867[0m
[92maverage training of epoch 35: loss -16.48961 acc 0.33333 roc_auc 0.36900 prc_auc 0.58244[0m
[93maverage test of epoch 35: loss -16.69311 acc 0.34211 roc_auc 0.12462 prc_auc 0.49211[0m
[92maverage training of epoch 36: loss -16.86125 acc 0.33333 roc_auc 0.36600 prc_auc 0.58171[0m
[93maverage test of epoch 36: loss -17.06560 acc 0.34211 roc_auc 0.10615 prc_auc 0.48099[0m
[92maverage training of epoch 37: loss -17.23444 acc 0.33333 roc_auc 0.36470 prc_auc 0.58116[0m
[93maverage test of epoch 37: loss -17.43973 acc 0.34211 roc_auc 0.12000 prc_auc 0.49633[0m
[92maverage training of epoch 38: loss -17.60936 acc 0.33333 roc_auc 0.36660 prc_auc 0.58123[0m
[93maverage test of epoch 38: loss -17.81564 acc 0.34211 roc_auc 0.12462 prc_auc 0.50223[0m
[92maverage training of epoch 39: loss -17.98615 acc 0.33333 roc_auc 0.36760 prc_auc 0.58066[0m
[93maverage test of epoch 39: loss -18.19348 acc 0.34211 roc_auc 0.09385 prc_auc 0.48468[0m
[92maverage training of epoch 40: loss -18.36498 acc 0.33333 roc_auc 0.36770 prc_auc 0.58006[0m
[93maverage test of epoch 40: loss -18.57340 acc 0.34211 roc_auc 0.15231 prc_auc 0.51483[0m
[92maverage training of epoch 41: loss -18.74595 acc 0.33333 roc_auc 0.36840 prc_auc 0.57945[0m
[93maverage test of epoch 41: loss -18.95551 acc 0.34211 roc_auc 0.15692 prc_auc 0.50727[0m
[92maverage training of epoch 42: loss -19.12917 acc 0.33333 roc_auc 0.36650 prc_auc 0.57853[0m
[93maverage test of epoch 42: loss -19.33990 acc 0.34211 roc_auc 0.14308 prc_auc 0.50353[0m
[92maverage training of epoch 43: loss -19.51476 acc 0.33333 roc_auc 0.36600 prc_auc 0.57798[0m
[93maverage test of epoch 43: loss -19.72666 acc 0.34211 roc_auc 0.14000 prc_auc 0.49653[0m
[92maverage training of epoch 44: loss -19.90276 acc 0.33333 roc_auc 0.36560 prc_auc 0.57783[0m
[93maverage test of epoch 44: loss -20.11590 acc 0.34211 roc_auc 0.17538 prc_auc 0.52864[0m
[92maverage training of epoch 45: loss -20.29332 acc 0.33333 roc_auc 0.36560 prc_auc 0.57750[0m
[93maverage test of epoch 45: loss -20.50769 acc 0.34211 roc_auc 0.11538 prc_auc 0.48472[0m
[92maverage training of epoch 46: loss -20.68647 acc 0.33333 roc_auc 0.36380 prc_auc 0.57647[0m
[93maverage test of epoch 46: loss -20.90210 acc 0.34211 roc_auc 0.04615 prc_auc 0.49807[0m
[92maverage training of epoch 47: loss -21.08229 acc 0.33333 roc_auc 0.36480 prc_auc 0.57656[0m
[93maverage test of epoch 47: loss -21.29919 acc 0.34211 roc_auc 0.13077 prc_auc 0.49097[0m
[92maverage training of epoch 48: loss -21.48082 acc 0.33333 roc_auc 0.36400 prc_auc 0.57576[0m
[93maverage test of epoch 48: loss -21.69899 acc 0.34211 roc_auc 0.10615 prc_auc 0.50713[0m
[92maverage training of epoch 49: loss -21.88211 acc 0.33333 roc_auc 0.36160 prc_auc 0.57444[0m
[93maverage test of epoch 49: loss -22.10156 acc 0.34211 roc_auc 0.05231 prc_auc 0.49526[0m
[92maverage training of epoch 50: loss -22.28621 acc 0.33333 roc_auc 0.36130 prc_auc 0.57414[0m
[93maverage test of epoch 50: loss -22.50696 acc 0.34211 roc_auc 0.10923 prc_auc 0.49561[0m
[92maverage training of epoch 51: loss -22.69318 acc 0.33333 roc_auc 0.35900 prc_auc 0.57285[0m
[93maverage test of epoch 51: loss -22.91523 acc 0.34211 roc_auc 0.18000 prc_auc 0.51466[0m
[92maverage training of epoch 52: loss -23.10306 acc 0.33333 roc_auc 0.35760 prc_auc 0.57169[0m
[93maverage test of epoch 52: loss -23.32638 acc 0.34211 roc_auc 0.12769 prc_auc 0.50651[0m
[92maverage training of epoch 53: loss -23.51560 acc 0.33333 roc_auc 0.35700 prc_auc 0.57092[0m
[93maverage test of epoch 53: loss -23.73991 acc 0.34211 roc_auc 0.23846 prc_auc 0.54364[0m
[92maverage training of epoch 54: loss -23.93044 acc 0.33333 roc_auc 0.35740 prc_auc 0.57044[0m
[93maverage test of epoch 54: loss -24.15575 acc 0.34211 roc_auc 0.15385 prc_auc 0.52303[0m
[92maverage training of epoch 55: loss -24.34765 acc 0.33333 roc_auc 0.35880 prc_auc 0.57056[0m
[93maverage test of epoch 55: loss -24.57399 acc 0.34211 roc_auc 0.15692 prc_auc 0.53887[0m
[92maverage training of epoch 56: loss -24.76736 acc 0.33333 roc_auc 0.35700 prc_auc 0.56970[0m
[93maverage test of epoch 56: loss -24.99477 acc 0.34211 roc_auc 0.15846 prc_auc 0.53878[0m
[92maverage training of epoch 57: loss -25.18968 acc 0.33333 roc_auc 0.35760 prc_auc 0.56961[0m
[93maverage test of epoch 57: loss -25.41822 acc 0.34211 roc_auc 0.20462 prc_auc 0.56835[0m
[92maverage training of epoch 58: loss -25.61473 acc 0.33333 roc_auc 0.35780 prc_auc 0.56945[0m
[93maverage test of epoch 58: loss -25.84439 acc 0.34211 roc_auc 0.25077 prc_auc 0.56021[0m
[92maverage training of epoch 59: loss -26.04253 acc 0.33333 roc_auc 0.35920 prc_auc 0.56978[0m
[93maverage test of epoch 59: loss -26.27330 acc 0.34211 roc_auc 0.21077 prc_auc 0.54285[0m
[92maverage training of epoch 60: loss -26.47310 acc 0.33333 roc_auc 0.35930 prc_auc 0.56941[0m
[93maverage test of epoch 60: loss -26.70502 acc 0.34211 roc_auc 0.23538 prc_auc 0.59937[0m
[92maverage training of epoch 61: loss -26.90653 acc 0.33333 roc_auc 0.35960 prc_auc 0.56960[0m
[93maverage test of epoch 61: loss -27.13962 acc 0.34211 roc_auc 0.28615 prc_auc 0.57781[0m
[92maverage training of epoch 62: loss -27.34288 acc 0.33333 roc_auc 0.36120 prc_auc 0.56994[0m
[93maverage test of epoch 62: loss -27.57711 acc 0.34211 roc_auc 0.15077 prc_auc 0.56706[0m
[92maverage training of epoch 63: loss -27.78214 acc 0.33333 roc_auc 0.36080 prc_auc 0.56933[0m
[93maverage test of epoch 63: loss -28.01755 acc 0.34211 roc_auc 0.35077 prc_auc 0.59623[0m
[92maverage training of epoch 64: loss -28.22440 acc 0.33333 roc_auc 0.36060 prc_auc 0.56896[0m
[93maverage test of epoch 64: loss -28.46100 acc 0.34211 roc_auc 0.25692 prc_auc 0.57405[0m
[92maverage training of epoch 65: loss -28.66968 acc 0.33333 roc_auc 0.36160 prc_auc 0.56924[0m
[93maverage test of epoch 65: loss -28.90744 acc 0.34211 roc_auc 0.16769 prc_auc 0.55811[0m
[92maverage training of epoch 66: loss -29.11798 acc 0.33333 roc_auc 0.36260 prc_auc 0.56969[0m
[93maverage test of epoch 66: loss -29.35693 acc 0.34211 roc_auc 0.59231 prc_auc 0.72783[0m
[92maverage training of epoch 67: loss -29.56938 acc 0.33333 roc_auc 0.36270 prc_auc 0.56952[0m
[93maverage test of epoch 67: loss -29.80952 acc 0.34211 roc_auc 0.21077 prc_auc 0.55362[0m
[92maverage training of epoch 68: loss -30.02389 acc 0.33333 roc_auc 0.36200 prc_auc 0.56898[0m
[93maverage test of epoch 68: loss -30.26521 acc 0.34211 roc_auc 0.14154 prc_auc 0.60151[0m
[92maverage training of epoch 69: loss -30.48152 acc 0.33333 roc_auc 0.36200 prc_auc 0.56863[0m
[93maverage test of epoch 69: loss -30.72401 acc 0.34211 roc_auc 0.78154 prc_auc 0.83920[0m
[92maverage training of epoch 70: loss -30.94230 acc 0.33333 roc_auc 0.36320 prc_auc 0.56941[0m
[93maverage test of epoch 70: loss -31.18599 acc 0.34211 roc_auc 0.39846 prc_auc 0.61819[0m
[92maverage training of epoch 71: loss -31.40626 acc 0.33333 roc_auc 0.36250 prc_auc 0.56881[0m
[93maverage test of epoch 71: loss -31.65112 acc 0.34211 roc_auc 0.51385 prc_auc 0.65660[0m
[92maverage training of epoch 72: loss -31.87339 acc 0.33333 roc_auc 0.36180 prc_auc 0.56803[0m
[93maverage test of epoch 72: loss -32.11942 acc 0.34211 roc_auc 0.40615 prc_auc 0.63209[0m
[92maverage training of epoch 73: loss -32.34370 acc 0.33333 roc_auc 0.36180 prc_auc 0.56817[0m
[93maverage test of epoch 73: loss -32.59091 acc 0.34211 roc_auc 0.76154 prc_auc 0.82566[0m
[92maverage training of epoch 74: loss -32.81722 acc 0.33333 roc_auc 0.36150 prc_auc 0.56806[0m
[93maverage test of epoch 74: loss -33.06557 acc 0.34211 roc_auc 0.35846 prc_auc 0.61596[0m
[92maverage training of epoch 75: loss -33.29393 acc 0.33333 roc_auc 0.36120 prc_auc 0.56805[0m
[93maverage test of epoch 75: loss -33.54343 acc 0.34211 roc_auc 0.35846 prc_auc 0.60256[0m
[92maverage training of epoch 76: loss -33.77386 acc 0.33333 roc_auc 0.36170 prc_auc 0.56788[0m
[93maverage test of epoch 76: loss -34.02453 acc 0.34211 roc_auc 0.32000 prc_auc 0.58995[0m
[92maverage training of epoch 77: loss -34.25705 acc 0.33333 roc_auc 0.36180 prc_auc 0.56778[0m
[93maverage test of epoch 77: loss -34.50888 acc 0.34211 roc_auc 0.64769 prc_auc 0.73495[0m
[92maverage training of epoch 78: loss -34.74350 acc 0.33333 roc_auc 0.36200 prc_auc 0.56811[0m
[93maverage test of epoch 78: loss -34.99647 acc 0.34211 roc_auc 0.30000 prc_auc 0.58459[0m
[92maverage training of epoch 79: loss -35.23321 acc 0.33333 roc_auc 0.36320 prc_auc 0.56868[0m
[93maverage test of epoch 79: loss -35.48731 acc 0.34211 roc_auc 0.35846 prc_auc 0.60256[0m
[92maverage training of epoch 80: loss -35.72617 acc 0.33333 roc_auc 0.36280 prc_auc 0.56846[0m
[93maverage test of epoch 80: loss -35.98139 acc 0.34211 roc_auc 0.49846 prc_auc 0.65720[0m
[92maverage training of epoch 81: loss -36.22238 acc 0.33333 roc_auc 0.36230 prc_auc 0.56783[0m
[93maverage test of epoch 81: loss -36.47872 acc 0.34211 roc_auc 0.80462 prc_auc 0.84026[0m
[92maverage training of epoch 82: loss -36.72187 acc 0.33333 roc_auc 0.36260 prc_auc 0.56785[0m
[93maverage test of epoch 82: loss -36.97932 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 83: loss -37.22464 acc 0.33333 roc_auc 0.36320 prc_auc 0.56810[0m
[93maverage test of epoch 83: loss -37.48319 acc 0.34211 roc_auc 0.43538 prc_auc 0.63069[0m
[92maverage training of epoch 84: loss -37.73067 acc 0.33333 roc_auc 0.36340 prc_auc 0.56801[0m
[93maverage test of epoch 84: loss -37.99032 acc 0.34211 roc_auc 0.19846 prc_auc 0.59000[0m
[92maverage training of epoch 85: loss -38.23999 acc 0.33333 roc_auc 0.36350 prc_auc 0.56820[0m
[93maverage test of epoch 85: loss -38.50072 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 86: loss -38.75259 acc 0.33333 roc_auc 0.36280 prc_auc 0.56772[0m
[93maverage test of epoch 86: loss -39.01440 acc 0.34211 roc_auc 0.64000 prc_auc 0.75368[0m
[92maverage training of epoch 87: loss -39.26848 acc 0.33333 roc_auc 0.36280 prc_auc 0.56777[0m
[93maverage test of epoch 87: loss -39.53136 acc 0.34211 roc_auc 0.78154 prc_auc 0.83920[0m
[92maverage training of epoch 88: loss -39.78766 acc 0.33333 roc_auc 0.36290 prc_auc 0.56782[0m
[93maverage test of epoch 88: loss -40.05160 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 89: loss -40.31014 acc 0.49333 roc_auc 0.36200 prc_auc 0.56666[0m
[93maverage test of epoch 89: loss -40.57513 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -40.83587 acc 0.66667 roc_auc 0.36160 prc_auc 0.56648[0m
[93maverage test of epoch 90: loss -41.10184 acc 0.65789 roc_auc 0.52000 prc_auc 0.67158[0m
[92maverage training of epoch 91: loss -41.36478 acc 0.66667 roc_auc 0.36060 prc_auc 0.56563[0m
[93maverage test of epoch 91: loss -41.63176 acc 0.65789 roc_auc 0.60154 prc_auc 0.71868[0m
[92maverage training of epoch 92: loss -41.89696 acc 0.66667 roc_auc 0.36000 prc_auc 0.56450[0m
[93maverage test of epoch 92: loss -42.16495 acc 0.65789 roc_auc 0.21846 prc_auc 0.57534[0m
[92maverage training of epoch 93: loss -42.43243 acc 0.66667 roc_auc 0.35950 prc_auc 0.56397[0m
[93maverage test of epoch 93: loss -42.70144 acc 0.65789 roc_auc 0.50154 prc_auc 0.65860[0m
[92maverage training of epoch 94: loss -42.97120 acc 0.66667 roc_auc 0.35850 prc_auc 0.56306[0m
[93maverage test of epoch 94: loss -43.24121 acc 0.65789 roc_auc 0.31846 prc_auc 0.59101[0m
[92maverage training of epoch 95: loss -43.51326 acc 0.66667 roc_auc 0.35800 prc_auc 0.56282[0m
[93maverage test of epoch 95: loss -43.78426 acc 0.65789 roc_auc 0.44000 prc_auc 0.63209[0m
[92maverage training of epoch 96: loss -44.05860 acc 0.66667 roc_auc 0.35730 prc_auc 0.56201[0m
[93maverage test of epoch 96: loss -44.33057 acc 0.65789 roc_auc 0.46000 prc_auc 0.64041[0m
[92maverage training of epoch 97: loss -44.60722 acc 0.66667 roc_auc 0.35720 prc_auc 0.56211[0m
[93maverage test of epoch 97: loss -44.88017 acc 0.65789 roc_auc 0.72000 prc_auc 0.80842[0m
[92maverage training of epoch 98: loss -45.15915 acc 0.66667 roc_auc 0.35720 prc_auc 0.56193[0m
[93maverage test of epoch 98: loss -45.43306 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -45.71438 acc 0.66667 roc_auc 0.35720 prc_auc 0.56214[0m
[93maverage test of epoch 99: loss -45.98925 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss 0.12442 acc 0.66667 roc_auc 0.32220 prc_auc 0.55290[0m
[93maverage test of epoch 0: loss 0.07425 acc 0.65789 roc_auc 0.19385 prc_auc 0.52436[0m
[92maverage training of epoch 1: loss 0.01368 acc 0.66667 roc_auc 0.28180 prc_auc 0.54537[0m
[93maverage test of epoch 1: loss -0.03147 acc 0.65789 roc_auc 0.22154 prc_auc 0.60785[0m
[92maverage training of epoch 2: loss -0.08556 acc 0.66667 roc_auc 0.26460 prc_auc 0.53679[0m
[93maverage test of epoch 2: loss -0.12503 acc 0.65789 roc_auc 0.34462 prc_auc 0.70390[0m
[92maverage training of epoch 3: loss -0.17406 acc 0.66667 roc_auc 0.26920 prc_auc 0.54097[0m
[93maverage test of epoch 3: loss -0.20928 acc 0.65789 roc_auc 0.37231 prc_auc 0.72390[0m
[92maverage training of epoch 4: loss -0.25553 acc 0.66667 roc_auc 0.30200 prc_auc 0.54887[0m
[93maverage test of epoch 4: loss -0.28800 acc 0.65789 roc_auc 0.36000 prc_auc 0.70936[0m
[92maverage training of epoch 5: loss -0.33363 acc 0.66667 roc_auc 0.35680 prc_auc 0.58203[0m
[93maverage test of epoch 5: loss -0.36511 acc 0.65789 roc_auc 0.39692 prc_auc 0.62476[0m
[92maverage training of epoch 6: loss -0.41123 acc 0.66667 roc_auc 0.42820 prc_auc 0.63826[0m
[93maverage test of epoch 6: loss -0.44313 acc 0.65789 roc_auc 0.48000 prc_auc 0.65535[0m
[92maverage training of epoch 7: loss -0.49053 acc 0.66667 roc_auc 0.46480 prc_auc 0.67170[0m
[93maverage test of epoch 7: loss -0.52421 acc 0.65789 roc_auc 0.54462 prc_auc 0.70858[0m
[92maverage training of epoch 8: loss -0.57393 acc 0.66667 roc_auc 0.51700 prc_auc 0.71523[0m
[93maverage test of epoch 8: loss -0.61099 acc 0.65789 roc_auc 0.71692 prc_auc 0.76393[0m
[92maverage training of epoch 9: loss -0.66469 acc 0.66667 roc_auc 0.57120 prc_auc 0.74864[0m
[93maverage test of epoch 9: loss -0.70699 acc 0.65789 roc_auc 0.76308 prc_auc 0.81169[0m
[92maverage training of epoch 10: loss -0.76877 acc 0.66667 roc_auc 0.62860 prc_auc 0.78277[0m
[93maverage test of epoch 10: loss -0.82073 acc 0.65789 roc_auc 0.84000 prc_auc 0.90247[0m
[92maverage training of epoch 11: loss -0.89889 acc 0.66667 roc_auc 0.67960 prc_auc 0.81144[0m
[93maverage test of epoch 11: loss -0.96921 acc 0.65789 roc_auc 0.84308 prc_auc 0.90723[0m
[92maverage training of epoch 12: loss -1.16367 acc 0.66667 roc_auc 0.56520 prc_auc 0.72076[0m
[93maverage test of epoch 12: loss -1.44443 acc 0.65789 roc_auc 0.76615 prc_auc 0.86905[0m
[92maverage training of epoch 13: loss -1.71960 acc 0.66667 roc_auc 0.62260 prc_auc 0.77333[0m
[93maverage test of epoch 13: loss -1.93281 acc 0.65789 roc_auc 0.80308 prc_auc 0.88761[0m
[92maverage training of epoch 14: loss -2.14252 acc 0.66667 roc_auc 0.64640 prc_auc 0.77897[0m
[93maverage test of epoch 14: loss -2.31349 acc 0.65789 roc_auc 0.83385 prc_auc 0.89707[0m
[92maverage training of epoch 15: loss -2.49907 acc 0.66667 roc_auc 0.62760 prc_auc 0.76083[0m
[93maverage test of epoch 15: loss -2.64944 acc 0.65789 roc_auc 0.83077 prc_auc 0.89478[0m
[92maverage training of epoch 16: loss -2.82421 acc 0.66667 roc_auc 0.61020 prc_auc 0.75357[0m
[93maverage test of epoch 16: loss -2.96214 acc 0.65789 roc_auc 0.85538 prc_auc 0.91504[0m
[92maverage training of epoch 17: loss -3.13104 acc 0.66667 roc_auc 0.58570 prc_auc 0.73763[0m
[93maverage test of epoch 17: loss -3.26013 acc 0.65789 roc_auc 0.85846 prc_auc 0.91736[0m
[92maverage training of epoch 18: loss -3.42483 acc 0.66667 roc_auc 0.55500 prc_auc 0.71937[0m
[93maverage test of epoch 18: loss -3.54710 acc 0.65789 roc_auc 0.85846 prc_auc 0.91710[0m
[92maverage training of epoch 19: loss -3.70910 acc 0.66667 roc_auc 0.53280 prc_auc 0.70654[0m
[93maverage test of epoch 19: loss -3.82619 acc 0.65789 roc_auc 0.85846 prc_auc 0.91710[0m
[92maverage training of epoch 20: loss -3.98629 acc 0.66667 roc_auc 0.51740 prc_auc 0.69527[0m
[93maverage test of epoch 20: loss -4.09892 acc 0.65789 roc_auc 0.85538 prc_auc 0.91404[0m
[92maverage training of epoch 21: loss -4.25791 acc 0.66667 roc_auc 0.50500 prc_auc 0.68421[0m
[93maverage test of epoch 21: loss -4.36704 acc 0.65789 roc_auc 0.85692 prc_auc 0.91809[0m
[92maverage training of epoch 22: loss -4.52543 acc 0.66667 roc_auc 0.49560 prc_auc 0.67522[0m
[93maverage test of epoch 22: loss -4.63149 acc 0.65789 roc_auc 0.85385 prc_auc 0.91500[0m
[92maverage training of epoch 23: loss -4.79012 acc 0.66667 roc_auc 0.48340 prc_auc 0.66307[0m
[93maverage test of epoch 23: loss -4.89399 acc 0.65789 roc_auc 0.85692 prc_auc 0.91862[0m
[92maverage training of epoch 24: loss -5.05313 acc 0.66667 roc_auc 0.47880 prc_auc 0.66116[0m
[93maverage test of epoch 24: loss -5.15488 acc 0.65789 roc_auc 0.85846 prc_auc 0.91777[0m
[92maverage training of epoch 25: loss -5.31503 acc 0.66667 roc_auc 0.47540 prc_auc 0.65900[0m
[93maverage test of epoch 25: loss -5.41515 acc 0.65789 roc_auc 0.85692 prc_auc 0.91753[0m
[92maverage training of epoch 26: loss -5.57716 acc 0.66667 roc_auc 0.47340 prc_auc 0.65769[0m
[93maverage test of epoch 26: loss -5.67672 acc 0.65789 roc_auc 0.85692 prc_auc 0.91408[0m
[92maverage training of epoch 27: loss -5.84221 acc 0.66667 roc_auc 0.47220 prc_auc 0.65758[0m
[93maverage test of epoch 27: loss -5.94344 acc 0.65789 roc_auc 0.85692 prc_auc 0.91155[0m
[92maverage training of epoch 28: loss -6.11610 acc 0.66667 roc_auc 0.47100 prc_auc 0.65637[0m
[93maverage test of epoch 28: loss -6.22456 acc 0.65789 roc_auc 0.86154 prc_auc 0.91581[0m
[92maverage training of epoch 29: loss -6.41380 acc 0.66667 roc_auc 0.47100 prc_auc 0.65629[0m
[93maverage test of epoch 29: loss -6.54506 acc 0.65789 roc_auc 0.85692 prc_auc 0.91511[0m
[92maverage training of epoch 30: loss -6.77602 acc 0.66667 roc_auc 0.47420 prc_auc 0.66098[0m
[93maverage test of epoch 30: loss -6.97243 acc 0.65789 roc_auc 0.86923 prc_auc 0.92350[0m
[92maverage training of epoch 31: loss -7.28664 acc 0.66667 roc_auc 0.50010 prc_auc 0.68771[0m
[93maverage test of epoch 31: loss -7.57305 acc 0.65789 roc_auc 0.87692 prc_auc 0.92890[0m
[92maverage training of epoch 32: loss -7.88906 acc 0.66667 roc_auc 0.54980 prc_auc 0.72324[0m
[93maverage test of epoch 32: loss -8.12414 acc 0.65789 roc_auc 0.87692 prc_auc 0.92890[0m
[92maverage training of epoch 33: loss -8.38541 acc 0.66667 roc_auc 0.54850 prc_auc 0.71810[0m
[93maverage test of epoch 33: loss -8.56243 acc 0.65789 roc_auc 0.87692 prc_auc 0.92915[0m
[92maverage training of epoch 34: loss -8.80291 acc 0.66667 roc_auc 0.53040 prc_auc 0.70353[0m
[93maverage test of epoch 34: loss -8.95491 acc 0.65789 roc_auc 0.87846 prc_auc 0.92937[0m
[92maverage training of epoch 35: loss -9.18713 acc 0.66667 roc_auc 0.51630 prc_auc 0.69146[0m
[93maverage test of epoch 35: loss -9.32583 acc 0.65789 roc_auc 0.87692 prc_auc 0.92737[0m
[92maverage training of epoch 36: loss -9.55442 acc 0.66667 roc_auc 0.50380 prc_auc 0.68257[0m
[93maverage test of epoch 36: loss -9.68474 acc 0.65789 roc_auc 0.87538 prc_auc 0.92381[0m
[92maverage training of epoch 37: loss -9.91186 acc 0.66667 roc_auc 0.49470 prc_auc 0.67713[0m
[93maverage test of epoch 37: loss -10.03628 acc 0.65789 roc_auc 0.87846 prc_auc 0.92810[0m
[92maverage training of epoch 38: loss -10.26320 acc 0.66667 roc_auc 0.48990 prc_auc 0.67460[0m
[93maverage test of epoch 38: loss -10.38320 acc 0.65789 roc_auc 0.88154 prc_auc 0.92732[0m
[92maverage training of epoch 39: loss -10.61075 acc 0.66667 roc_auc 0.48630 prc_auc 0.67084[0m
[93maverage test of epoch 39: loss -10.72736 acc 0.65789 roc_auc 0.86615 prc_auc 0.91316[0m
[92maverage training of epoch 40: loss -10.95620 acc 0.66667 roc_auc 0.48220 prc_auc 0.66638[0m
[93maverage test of epoch 40: loss -11.07018 acc 0.65789 roc_auc 0.85692 prc_auc 0.89185[0m
[92maverage training of epoch 41: loss -11.29992 acc 0.66667 roc_auc 0.47900 prc_auc 0.66040[0m
[93maverage test of epoch 41: loss -11.40685 acc 0.65789 roc_auc 0.87077 prc_auc 0.89689[0m
[92maverage training of epoch 42: loss -11.63000 acc 0.66667 roc_auc 0.47590 prc_auc 0.65899[0m
[93maverage test of epoch 42: loss -11.73039 acc 0.65789 roc_auc 0.86462 prc_auc 0.89079[0m
[92maverage training of epoch 43: loss -11.95573 acc 0.66667 roc_auc 0.47410 prc_auc 0.65752[0m
[93maverage test of epoch 43: loss -12.05436 acc 0.65789 roc_auc 0.85077 prc_auc 0.87024[0m
[92maverage training of epoch 44: loss -12.28212 acc 0.66667 roc_auc 0.47270 prc_auc 0.65691[0m
[93maverage test of epoch 44: loss -12.37930 acc 0.65789 roc_auc 0.84308 prc_auc 0.86222[0m
[92maverage training of epoch 45: loss -12.60963 acc 0.66667 roc_auc 0.47210 prc_auc 0.65693[0m
[93maverage test of epoch 45: loss -12.70559 acc 0.65789 roc_auc 0.82000 prc_auc 0.84667[0m
[92maverage training of epoch 46: loss -12.93864 acc 0.66667 roc_auc 0.47100 prc_auc 0.65672[0m
[93maverage test of epoch 46: loss -13.03356 acc 0.65789 roc_auc 0.81846 prc_auc 0.84819[0m
[92maverage training of epoch 47: loss -13.26941 acc 0.66667 roc_auc 0.47120 prc_auc 0.65626[0m
[93maverage test of epoch 47: loss -13.36343 acc 0.65789 roc_auc 0.82308 prc_auc 0.84667[0m
[92maverage training of epoch 48: loss -13.60219 acc 0.66667 roc_auc 0.47050 prc_auc 0.65617[0m
[93maverage test of epoch 48: loss -13.69542 acc 0.65789 roc_auc 0.71692 prc_auc 0.77697[0m
[92maverage training of epoch 49: loss -13.93714 acc 0.66667 roc_auc 0.47070 prc_auc 0.65657[0m
[93maverage test of epoch 49: loss -14.02969 acc 0.65789 roc_auc 0.82308 prc_auc 0.84667[0m
[92maverage training of epoch 50: loss -14.27444 acc 0.66667 roc_auc 0.47070 prc_auc 0.65642[0m
[93maverage test of epoch 50: loss -14.36638 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 51: loss -14.61420 acc 0.66667 roc_auc 0.46970 prc_auc 0.65562[0m
[93maverage test of epoch 51: loss -14.70561 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 52: loss -14.95653 acc 0.66667 roc_auc 0.46940 prc_auc 0.65771[0m
[93maverage test of epoch 52: loss -15.04746 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 53: loss -15.30152 acc 0.66667 roc_auc 0.46940 prc_auc 0.65458[0m
[93maverage test of epoch 53: loss -15.39203 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 54: loss -15.64926 acc 0.66667 roc_auc 0.46920 prc_auc 0.65356[0m
[93maverage test of epoch 54: loss -15.73939 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 55: loss -15.99981 acc 0.66667 roc_auc 0.46800 prc_auc 0.64914[0m
[93maverage test of epoch 55: loss -16.08961 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 56: loss -16.35324 acc 0.66667 roc_auc 0.46740 prc_auc 0.65146[0m
[93maverage test of epoch 56: loss -16.44274 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 57: loss -16.70960 acc 0.66667 roc_auc 0.46270 prc_auc 0.64522[0m
[93maverage test of epoch 57: loss -16.79883 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 58: loss -17.06894 acc 0.66667 roc_auc 0.46950 prc_auc 0.64901[0m
[93maverage test of epoch 58: loss -17.15793 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 59: loss -17.43129 acc 0.66667 roc_auc 0.46870 prc_auc 0.64981[0m
[93maverage test of epoch 59: loss -17.52006 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 60: loss -17.79670 acc 0.66667 roc_auc 0.46830 prc_auc 0.65146[0m
[93maverage test of epoch 60: loss -17.88524 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 61: loss -18.16518 acc 0.66667 roc_auc 0.46230 prc_auc 0.64821[0m
[93maverage test of epoch 61: loss -18.25353 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 62: loss -18.53678 acc 0.66667 roc_auc 0.47190 prc_auc 0.65073[0m
[93maverage test of epoch 62: loss -18.62495 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 63: loss -18.91152 acc 0.66667 roc_auc 0.45680 prc_auc 0.64075[0m
[93maverage test of epoch 63: loss -18.99951 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 64: loss -19.28941 acc 0.66667 roc_auc 0.46110 prc_auc 0.64456[0m
[93maverage test of epoch 64: loss -19.37724 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 65: loss -19.67049 acc 0.66667 roc_auc 0.45330 prc_auc 0.63275[0m
[93maverage test of epoch 65: loss -19.75816 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 66: loss -20.05476 acc 0.66667 roc_auc 0.46090 prc_auc 0.64543[0m
[93maverage test of epoch 66: loss -20.14229 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 67: loss -20.44225 acc 0.66667 roc_auc 0.44570 prc_auc 0.63481[0m
[93maverage test of epoch 67: loss -20.52964 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 68: loss -20.83296 acc 0.66667 roc_auc 0.46490 prc_auc 0.65310[0m
[93maverage test of epoch 68: loss -20.92022 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 69: loss -21.22692 acc 0.66667 roc_auc 0.47180 prc_auc 0.65309[0m
[93maverage test of epoch 69: loss -21.31404 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 70: loss -21.62413 acc 0.66667 roc_auc 0.47860 prc_auc 0.66017[0m
[93maverage test of epoch 70: loss -21.71110 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 71: loss -22.02448 acc 0.66667 roc_auc 0.45250 prc_auc 0.64299[0m
[93maverage test of epoch 71: loss -22.11119 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 72: loss -22.42783 acc 0.66667 roc_auc 0.49350 prc_auc 0.66583[0m
[93maverage test of epoch 72: loss -22.51427 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 73: loss -22.83421 acc 0.66667 roc_auc 0.45830 prc_auc 0.64923[0m
[93maverage test of epoch 73: loss -22.92039 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 74: loss -23.24364 acc 0.66667 roc_auc 0.48280 prc_auc 0.65860[0m
[93maverage test of epoch 74: loss -23.32959 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 75: loss -23.65616 acc 0.66667 roc_auc 0.44500 prc_auc 0.64514[0m
[93maverage test of epoch 75: loss -23.74189 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 76: loss -24.07181 acc 0.66667 roc_auc 0.44000 prc_auc 0.64356[0m
[93maverage test of epoch 76: loss -24.15732 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 77: loss -24.49061 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 77: loss -24.57591 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 78: loss -24.91258 acc 0.66667 roc_auc 0.52000 prc_auc 0.67568[0m
[93maverage test of epoch 78: loss -24.99767 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 79: loss -25.33773 acc 0.66667 roc_auc 0.42500 prc_auc 0.63772[0m
[93maverage test of epoch 79: loss -25.42264 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 80: loss -25.76609 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 80: loss -25.85078 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 81: loss -26.19767 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 81: loss -26.28219 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 82: loss -26.63251 acc 0.66667 roc_auc 0.47500 prc_auc 0.65579[0m
[93maverage test of epoch 82: loss -26.71682 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 83: loss -27.07059 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 83: loss -27.15469 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 84: loss -27.51190 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 84: loss -27.59580 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 85: loss -27.95642 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 85: loss -28.03997 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 86: loss -28.40389 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 86: loss -28.48706 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 87: loss -28.85432 acc 0.66667 roc_auc 0.47000 prc_auc 0.65379[0m
[93maverage test of epoch 87: loss -28.93715 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 88: loss -29.30778 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 88: loss -29.39029 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 89: loss -29.76432 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 89: loss -29.84649 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -30.22396 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 90: loss -30.30583 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 91: loss -30.68673 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 91: loss -30.76826 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 92: loss -31.15260 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 92: loss -31.23384 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 93: loss -31.62164 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 93: loss -31.70254 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 94: loss -32.09384 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 94: loss -32.17442 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 95: loss -32.56922 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 95: loss -32.64953 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 96: loss -33.04788 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 96: loss -33.12788 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 97: loss -33.52974 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 97: loss -33.60944 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 98: loss -34.01483 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 98: loss -34.09422 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -34.50320 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 99: loss -34.58227 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.36970 acc 0.34000 roc_auc 0.52260 prc_auc 0.73570[0m
[93maverage test of epoch 0: loss -0.38470 acc 0.34211 roc_auc 0.80308 prc_auc 0.92598[0m
[92maverage training of epoch 1: loss -0.39754 acc 0.34667 roc_auc 0.54060 prc_auc 0.74900[0m
[93maverage test of epoch 1: loss -0.41001 acc 0.34211 roc_auc 0.72000 prc_auc 0.89070[0m
[92maverage training of epoch 2: loss -0.42234 acc 0.37333 roc_auc 0.53750 prc_auc 0.74697[0m
[93maverage test of epoch 2: loss -0.43363 acc 0.36842 roc_auc 0.54769 prc_auc 0.80699[0m
[92maverage training of epoch 3: loss -0.44544 acc 0.52667 roc_auc 0.53620 prc_auc 0.74969[0m
[93maverage test of epoch 3: loss -0.45435 acc 0.65789 roc_auc 0.52923 prc_auc 0.80185[0m
[92maverage training of epoch 4: loss -0.46512 acc 0.66667 roc_auc 0.47940 prc_auc 0.67129[0m
[93maverage test of epoch 4: loss -0.46877 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 5: loss -0.47881 acc 0.66667 roc_auc 0.40300 prc_auc 0.61950[0m
[93maverage test of epoch 5: loss -0.47978 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 6: loss -0.49062 acc 0.66667 roc_auc 0.40250 prc_auc 0.61864[0m
[93maverage test of epoch 6: loss -0.49079 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 7: loss -0.50240 acc 0.66667 roc_auc 0.40250 prc_auc 0.61864[0m
[93maverage test of epoch 7: loss -0.50181 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 8: loss -0.51413 acc 0.66667 roc_auc 0.40250 prc_auc 0.61879[0m
[93maverage test of epoch 8: loss -0.51282 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 9: loss -0.52588 acc 0.66667 roc_auc 0.40210 prc_auc 0.61846[0m
[93maverage test of epoch 9: loss -0.52384 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 10: loss -0.53787 acc 0.66667 roc_auc 0.40200 prc_auc 0.61836[0m
[93maverage test of epoch 10: loss -0.53485 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 11: loss -0.54999 acc 0.66667 roc_auc 0.40170 prc_auc 0.61805[0m
[93maverage test of epoch 11: loss -0.54586 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 12: loss -0.56214 acc 0.66667 roc_auc 0.40150 prc_auc 0.61805[0m
[93maverage test of epoch 12: loss -0.55688 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 13: loss -0.57488 acc 0.66667 roc_auc 0.42290 prc_auc 0.64564[0m
[93maverage test of epoch 13: loss -0.56856 acc 0.65789 roc_auc 0.52000 prc_auc 0.67158[0m
[92maverage training of epoch 14: loss -0.58864 acc 0.66667 roc_auc 0.42290 prc_auc 0.64564[0m
[93maverage test of epoch 14: loss -0.58094 acc 0.65789 roc_auc 0.52000 prc_auc 0.67158[0m
[92maverage training of epoch 15: loss -0.60327 acc 0.66667 roc_auc 0.44360 prc_auc 0.67397[0m
[93maverage test of epoch 15: loss -0.59571 acc 0.65789 roc_auc 0.62000 prc_auc 0.74000[0m
[92maverage training of epoch 16: loss -0.71881 acc 0.66667 roc_auc 0.48000 prc_auc 0.68429[0m
[93maverage test of epoch 16: loss -0.82160 acc 0.65789 roc_auc 0.28615 prc_auc 0.66116[0m
[92maverage training of epoch 17: loss -0.94067 acc 0.66667 roc_auc 0.47420 prc_auc 0.68016[0m
[93maverage test of epoch 17: loss -1.02800 acc 0.65789 roc_auc 0.46923 prc_auc 0.76910[0m
[92maverage training of epoch 18: loss -1.16108 acc 0.66667 roc_auc 0.48480 prc_auc 0.69002[0m
[93maverage test of epoch 18: loss -1.26421 acc 0.65789 roc_auc 0.93538 prc_auc 0.97317[0m
[92maverage training of epoch 19: loss -1.41531 acc 0.66667 roc_auc 0.49760 prc_auc 0.69883[0m
[93maverage test of epoch 19: loss -1.53061 acc 0.65789 roc_auc 0.94462 prc_auc 0.97555[0m
[92maverage training of epoch 20: loss -1.68637 acc 0.66667 roc_auc 0.52040 prc_auc 0.71476[0m
[93maverage test of epoch 20: loss -1.79909 acc 0.65789 roc_auc 0.94769 prc_auc 0.97702[0m
[92maverage training of epoch 21: loss -1.94517 acc 0.66667 roc_auc 0.54540 prc_auc 0.73991[0m
[93maverage test of epoch 21: loss -2.04549 acc 0.65789 roc_auc 0.95231 prc_auc 0.97791[0m
[92maverage training of epoch 22: loss -2.17763 acc 0.66667 roc_auc 0.58060 prc_auc 0.77508[0m
[93maverage test of epoch 22: loss -2.26486 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 23: loss -2.38975 acc 0.66667 roc_auc 0.60060 prc_auc 0.79022[0m
[93maverage test of epoch 23: loss -2.47200 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 24: loss -2.59925 acc 0.66667 roc_auc 0.61140 prc_auc 0.79860[0m
[93maverage test of epoch 24: loss -2.68428 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 25: loss -2.81787 acc 0.66667 roc_auc 0.61140 prc_auc 0.79464[0m
[93maverage test of epoch 25: loss -2.90631 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 26: loss -3.04133 acc 0.66667 roc_auc 0.60800 prc_auc 0.78792[0m
[93maverage test of epoch 26: loss -3.12582 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 27: loss -3.25537 acc 0.66667 roc_auc 0.60000 prc_auc 0.78107[0m
[93maverage test of epoch 27: loss -3.33006 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 28: loss -3.45209 acc 0.66667 roc_auc 0.59120 prc_auc 0.77457[0m
[93maverage test of epoch 28: loss -3.51676 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 29: loss -3.63330 acc 0.66667 roc_auc 0.58620 prc_auc 0.77204[0m
[93maverage test of epoch 29: loss -3.69056 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 30: loss -3.80387 acc 0.66667 roc_auc 0.57960 prc_auc 0.76701[0m
[93maverage test of epoch 30: loss -3.85610 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 31: loss -3.96779 acc 0.66667 roc_auc 0.57560 prc_auc 0.76256[0m
[93maverage test of epoch 31: loss -4.01659 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 32: loss -4.12761 acc 0.66667 roc_auc 0.56810 prc_auc 0.75645[0m
[93maverage test of epoch 32: loss -4.17387 acc 0.65789 roc_auc 0.95231 prc_auc 0.97791[0m
[92maverage training of epoch 33: loss -4.28474 acc 0.66667 roc_auc 0.55830 prc_auc 0.74710[0m
[93maverage test of epoch 33: loss -4.32904 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 34: loss -4.44020 acc 0.66667 roc_auc 0.54510 prc_auc 0.73092[0m
[93maverage test of epoch 34: loss -4.48296 acc 0.65789 roc_auc 0.95231 prc_auc 0.97791[0m
[92maverage training of epoch 35: loss -4.59474 acc 0.66667 roc_auc 0.53280 prc_auc 0.72203[0m
[93maverage test of epoch 35: loss -4.63630 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 36: loss -4.74896 acc 0.66667 roc_auc 0.51700 prc_auc 0.70653[0m
[93maverage test of epoch 36: loss -4.78958 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 37: loss -4.90332 acc 0.66667 roc_auc 0.50920 prc_auc 0.70195[0m
[93maverage test of epoch 37: loss -4.94324 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 38: loss -5.05821 acc 0.66667 roc_auc 0.50060 prc_auc 0.69465[0m
[93maverage test of epoch 38: loss -5.09762 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 39: loss -5.21394 acc 0.66667 roc_auc 0.49300 prc_auc 0.68905[0m
[93maverage test of epoch 39: loss -5.25299 acc 0.65789 roc_auc 0.95231 prc_auc 0.97791[0m
[92maverage training of epoch 40: loss -5.37073 acc 0.66667 roc_auc 0.48500 prc_auc 0.68292[0m
[93maverage test of epoch 40: loss -5.40955 acc 0.65789 roc_auc 0.95231 prc_auc 0.97791[0m
[92maverage training of epoch 41: loss -5.52879 acc 0.66667 roc_auc 0.47580 prc_auc 0.67619[0m
[93maverage test of epoch 41: loss -5.56751 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 42: loss -5.68833 acc 0.66667 roc_auc 0.46770 prc_auc 0.66676[0m
[93maverage test of epoch 42: loss -5.72704 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 43: loss -5.84951 acc 0.66667 roc_auc 0.46000 prc_auc 0.66085[0m
[93maverage test of epoch 43: loss -5.88831 acc 0.65789 roc_auc 0.95231 prc_auc 0.97791[0m
[92maverage training of epoch 44: loss -6.01248 acc 0.66667 roc_auc 0.45120 prc_auc 0.65367[0m
[93maverage test of epoch 44: loss -6.05144 acc 0.65789 roc_auc 0.95231 prc_auc 0.97791[0m
[92maverage training of epoch 45: loss -6.17737 acc 0.66667 roc_auc 0.44460 prc_auc 0.64789[0m
[93maverage test of epoch 45: loss -6.21657 acc 0.65789 roc_auc 0.95231 prc_auc 0.97791[0m
[92maverage training of epoch 46: loss -6.34430 acc 0.66667 roc_auc 0.43770 prc_auc 0.64310[0m
[93maverage test of epoch 46: loss -6.38380 acc 0.65789 roc_auc 0.95231 prc_auc 0.97791[0m
[92maverage training of epoch 47: loss -6.51339 acc 0.66667 roc_auc 0.43280 prc_auc 0.63843[0m
[93maverage test of epoch 47: loss -6.55325 acc 0.65789 roc_auc 0.95385 prc_auc 0.97808[0m
[92maverage training of epoch 48: loss -6.68472 acc 0.66667 roc_auc 0.42910 prc_auc 0.63639[0m
[93maverage test of epoch 48: loss -6.72499 acc 0.65789 roc_auc 0.95538 prc_auc 0.97946[0m
[92maverage training of epoch 49: loss -6.85840 acc 0.66667 roc_auc 0.42430 prc_auc 0.63187[0m
[93maverage test of epoch 49: loss -6.89913 acc 0.65789 roc_auc 0.95231 prc_auc 0.97697[0m
[92maverage training of epoch 50: loss -7.03451 acc 0.66667 roc_auc 0.42230 prc_auc 0.63036[0m
[93maverage test of epoch 50: loss -7.07574 acc 0.65789 roc_auc 0.95385 prc_auc 0.97808[0m
[92maverage training of epoch 51: loss -7.21313 acc 0.66667 roc_auc 0.42030 prc_auc 0.62933[0m
[93maverage test of epoch 51: loss -7.25491 acc 0.65789 roc_auc 0.95077 prc_auc 0.97663[0m
[92maverage training of epoch 52: loss -7.39436 acc 0.66667 roc_auc 0.41830 prc_auc 0.62775[0m
[93maverage test of epoch 52: loss -7.43672 acc 0.65789 roc_auc 0.95231 prc_auc 0.97697[0m
[92maverage training of epoch 53: loss -7.57825 acc 0.66667 roc_auc 0.41690 prc_auc 0.62724[0m
[93maverage test of epoch 53: loss -7.62125 acc 0.65789 roc_auc 0.95231 prc_auc 0.97697[0m
[92maverage training of epoch 54: loss -7.76489 acc 0.66667 roc_auc 0.41500 prc_auc 0.62620[0m
[93maverage test of epoch 54: loss -7.80855 acc 0.65789 roc_auc 0.93846 prc_auc 0.96603[0m
[92maverage training of epoch 55: loss -7.95434 acc 0.66667 roc_auc 0.41340 prc_auc 0.62552[0m
[93maverage test of epoch 55: loss -7.99869 acc 0.65789 roc_auc 0.93231 prc_auc 0.95907[0m
[92maverage training of epoch 56: loss -8.14667 acc 0.66667 roc_auc 0.41220 prc_auc 0.62478[0m
[93maverage test of epoch 56: loss -8.19175 acc 0.65789 roc_auc 0.92769 prc_auc 0.95211[0m
[92maverage training of epoch 57: loss -8.34194 acc 0.66667 roc_auc 0.41060 prc_auc 0.62396[0m
[93maverage test of epoch 57: loss -8.38778 acc 0.65789 roc_auc 0.94000 prc_auc 0.95965[0m
[92maverage training of epoch 58: loss -8.54020 acc 0.66667 roc_auc 0.40970 prc_auc 0.62296[0m
[93maverage test of epoch 58: loss -8.58683 acc 0.65789 roc_auc 0.86923 prc_auc 0.88927[0m
[92maverage training of epoch 59: loss -8.74153 acc 0.66667 roc_auc 0.40930 prc_auc 0.62269[0m
[93maverage test of epoch 59: loss -8.78897 acc 0.65789 roc_auc 0.86462 prc_auc 0.87965[0m
[92maverage training of epoch 60: loss -8.94597 acc 0.66667 roc_auc 0.40920 prc_auc 0.62270[0m
[93maverage test of epoch 60: loss -8.99426 acc 0.65789 roc_auc 0.90154 prc_auc 0.92242[0m
[92maverage training of epoch 61: loss -9.15358 acc 0.66667 roc_auc 0.40840 prc_auc 0.62204[0m
[93maverage test of epoch 61: loss -9.20273 acc 0.65789 roc_auc 0.84000 prc_auc 0.89053[0m
[92maverage training of epoch 62: loss -9.36440 acc 0.66667 roc_auc 0.40800 prc_auc 0.62260[0m
[93maverage test of epoch 62: loss -9.41443 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 63: loss -9.57848 acc 0.66667 roc_auc 0.40750 prc_auc 0.62211[0m
[93maverage test of epoch 63: loss -9.62943 acc 0.65789 roc_auc 0.86000 prc_auc 0.90421[0m
[92maverage training of epoch 64: loss -9.79587 acc 0.66667 roc_auc 0.40670 prc_auc 0.61699[0m
[93maverage test of epoch 64: loss -9.84775 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 65: loss -10.01661 acc 0.66667 roc_auc 0.40680 prc_auc 0.61751[0m
[93maverage test of epoch 65: loss -10.06944 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 66: loss -10.24075 acc 0.66667 roc_auc 0.40550 prc_auc 0.61586[0m
[93maverage test of epoch 66: loss -10.29454 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 67: loss -10.46831 acc 0.66667 roc_auc 0.40490 prc_auc 0.61511[0m
[93maverage test of epoch 67: loss -10.52309 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 68: loss -10.69933 acc 0.66667 roc_auc 0.40460 prc_auc 0.61478[0m
[93maverage test of epoch 68: loss -10.75511 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 69: loss -10.93386 acc 0.66667 roc_auc 0.40530 prc_auc 0.61519[0m
[93maverage test of epoch 69: loss -10.99064 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 70: loss -11.17191 acc 0.66667 roc_auc 0.40440 prc_auc 0.61428[0m
[93maverage test of epoch 70: loss -11.22971 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 71: loss -11.41352 acc 0.66667 roc_auc 0.40370 prc_auc 0.61402[0m
[93maverage test of epoch 71: loss -11.47236 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 72: loss -11.65871 acc 0.66667 roc_auc 0.40380 prc_auc 0.61363[0m
[93maverage test of epoch 72: loss -11.71860 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 73: loss -11.90752 acc 0.66667 roc_auc 0.40320 prc_auc 0.61232[0m
[93maverage test of epoch 73: loss -11.96846 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 74: loss -12.15996 acc 0.66667 roc_auc 0.40310 prc_auc 0.61249[0m
[93maverage test of epoch 74: loss -12.22197 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 75: loss -12.41606 acc 0.66667 roc_auc 0.40280 prc_auc 0.60900[0m
[93maverage test of epoch 75: loss -12.47913 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 76: loss -12.67584 acc 0.66667 roc_auc 0.40340 prc_auc 0.61402[0m
[93maverage test of epoch 76: loss -12.73998 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 77: loss -12.93931 acc 0.66667 roc_auc 0.40420 prc_auc 0.61353[0m
[93maverage test of epoch 77: loss -13.00454 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 78: loss -13.20651 acc 0.66667 roc_auc 0.40150 prc_auc 0.61090[0m
[93maverage test of epoch 78: loss -13.27282 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 79: loss -13.47743 acc 0.66667 roc_auc 0.40220 prc_auc 0.60854[0m
[93maverage test of epoch 79: loss -13.54483 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 80: loss -13.75210 acc 0.66667 roc_auc 0.40210 prc_auc 0.61139[0m
[93maverage test of epoch 80: loss -13.82058 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 81: loss -14.03052 acc 0.66667 roc_auc 0.40130 prc_auc 0.61039[0m
[93maverage test of epoch 81: loss -14.10008 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 82: loss -14.31271 acc 0.66667 roc_auc 0.40160 prc_auc 0.61149[0m
[93maverage test of epoch 82: loss -14.38336 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 83: loss -14.59867 acc 0.66667 roc_auc 0.40080 prc_auc 0.60635[0m
[93maverage test of epoch 83: loss -14.67040 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 84: loss -14.88842 acc 0.66667 roc_auc 0.40200 prc_auc 0.60392[0m
[93maverage test of epoch 84: loss -14.96124 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 85: loss -15.18197 acc 0.66667 roc_auc 0.40320 prc_auc 0.60225[0m
[93maverage test of epoch 85: loss -15.25586 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 86: loss -15.47931 acc 0.66667 roc_auc 0.40070 prc_auc 0.60094[0m
[93maverage test of epoch 86: loss -15.55428 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 87: loss -15.78046 acc 0.66667 roc_auc 0.40260 prc_auc 0.59887[0m
[93maverage test of epoch 87: loss -15.85650 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 88: loss -16.08542 acc 0.66667 roc_auc 0.40190 prc_auc 0.60122[0m
[93maverage test of epoch 88: loss -16.16252 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 89: loss -16.39418 acc 0.66667 roc_auc 0.40260 prc_auc 0.60805[0m
[93maverage test of epoch 89: loss -16.47234 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -16.70676 acc 0.66667 roc_auc 0.40260 prc_auc 0.60302[0m
[93maverage test of epoch 90: loss -16.78598 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 91: loss -17.02316 acc 0.66667 roc_auc 0.40470 prc_auc 0.60375[0m
[93maverage test of epoch 91: loss -17.10342 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 92: loss -17.34337 acc 0.66667 roc_auc 0.40380 prc_auc 0.60251[0m
[93maverage test of epoch 92: loss -17.42468 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 93: loss -17.66741 acc 0.66667 roc_auc 0.40690 prc_auc 0.60577[0m
[93maverage test of epoch 93: loss -17.74973 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 94: loss -17.99525 acc 0.66667 roc_auc 0.40150 prc_auc 0.60415[0m
[93maverage test of epoch 94: loss -18.07860 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 95: loss -18.32691 acc 0.66667 roc_auc 0.40210 prc_auc 0.60084[0m
[93maverage test of epoch 95: loss -18.41128 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 96: loss -18.66239 acc 0.66667 roc_auc 0.40430 prc_auc 0.60294[0m
[93maverage test of epoch 96: loss -18.74775 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 97: loss -19.00167 acc 0.66667 roc_auc 0.40570 prc_auc 0.60426[0m
[93maverage test of epoch 97: loss -19.08803 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 98: loss -19.34477 acc 0.66667 roc_auc 0.40620 prc_auc 0.60382[0m
[93maverage test of epoch 98: loss -19.43211 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -19.69167 acc 0.66667 roc_auc 0.40480 prc_auc 0.60084[0m
[93maverage test of epoch 99: loss -19.77997 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.04946 acc 0.33775 roc_auc 0.50098 prc_auc 0.71982[0m
[93maverage test of epoch 0: loss -0.08274 acc 0.32432 roc_auc 0.79667 prc_auc 0.88906[0m
[92maverage training of epoch 1: loss -0.12435 acc 0.34437 roc_auc 0.51216 prc_auc 0.73228[0m
[93maverage test of epoch 1: loss -0.15988 acc 0.35135 roc_auc 0.83000 prc_auc 0.89963[0m
[92maverage training of epoch 2: loss -0.20319 acc 0.35099 roc_auc 0.52784 prc_auc 0.74461[0m
[93maverage test of epoch 2: loss -0.24137 acc 0.35135 roc_auc 0.84000 prc_auc 0.90374[0m
[92maverage training of epoch 3: loss -0.28659 acc 0.35099 roc_auc 0.54549 prc_auc 0.75928[0m
[93maverage test of epoch 3: loss -0.32762 acc 0.35135 roc_auc 0.84333 prc_auc 0.90873[0m
[92maverage training of epoch 4: loss -0.39533 acc 0.35099 roc_auc 0.51039 prc_auc 0.71710[0m
[93maverage test of epoch 4: loss -0.46951 acc 0.35135 roc_auc 0.67667 prc_auc 0.87432[0m
[92maverage training of epoch 5: loss -0.54809 acc 0.35099 roc_auc 0.51490 prc_auc 0.73089[0m
[93maverage test of epoch 5: loss -0.61835 acc 0.35135 roc_auc 0.79000 prc_auc 0.90470[0m
[92maverage training of epoch 6: loss -0.69276 acc 0.35099 roc_auc 0.52039 prc_auc 0.73762[0m
[93maverage test of epoch 6: loss -0.75906 acc 0.35135 roc_auc 0.85667 prc_auc 0.92909[0m
[92maverage training of epoch 7: loss -0.85542 acc 0.35099 roc_auc 0.55039 prc_auc 0.76840[0m
[93maverage test of epoch 7: loss -0.94726 acc 0.35135 roc_auc 0.82167 prc_auc 0.91317[0m
[92maverage training of epoch 8: loss -1.03923 acc 0.35099 roc_auc 0.50784 prc_auc 0.74418[0m
[93maverage test of epoch 8: loss -1.12528 acc 0.35135 roc_auc 0.70000 prc_auc 0.86883[0m
[92maverage training of epoch 9: loss -1.21627 acc 0.35762 roc_auc 0.51882 prc_auc 0.74868[0m
[93maverage test of epoch 9: loss -1.30571 acc 0.35135 roc_auc 0.67500 prc_auc 0.86283[0m
[92maverage training of epoch 10: loss -1.40157 acc 0.37086 roc_auc 0.52961 prc_auc 0.75357[0m
[93maverage test of epoch 10: loss -1.50087 acc 0.37838 roc_auc 0.65667 prc_auc 0.85645[0m
[92maverage training of epoch 11: loss -1.60844 acc 0.38411 roc_auc 0.53667 prc_auc 0.75822[0m
[93maverage test of epoch 11: loss -1.72585 acc 0.37838 roc_auc 0.50000 prc_auc 0.78077[0m
[92maverage training of epoch 12: loss -1.85276 acc 0.45695 roc_auc 0.53373 prc_auc 0.75662[0m
[93maverage test of epoch 12: loss -1.99644 acc 0.37838 roc_auc 0.41333 prc_auc 0.74012[0m
[92maverage training of epoch 13: loss -2.14434 acc 0.56954 roc_auc 0.51667 prc_auc 0.74360[0m
[93maverage test of epoch 13: loss -2.31249 acc 0.67568 roc_auc 0.34667 prc_auc 0.69795[0m
[92maverage training of epoch 14: loss -2.46960 acc 0.66225 roc_auc 0.51059 prc_auc 0.74529[0m
[93maverage test of epoch 14: loss -2.64529 acc 0.67568 roc_auc 0.37000 prc_auc 0.70983[0m
[92maverage training of epoch 15: loss -2.79937 acc 0.66225 roc_auc 0.57333 prc_auc 0.79209[0m
[93maverage test of epoch 15: loss -2.96868 acc 0.67568 roc_auc 0.53000 prc_auc 0.79830[0m
[92maverage training of epoch 16: loss -3.11883 acc 0.66225 roc_auc 0.63059 prc_auc 0.82619[0m
[93maverage test of epoch 16: loss -3.27854 acc 0.67568 roc_auc 0.84333 prc_auc 0.91568[0m
[92maverage training of epoch 17: loss -3.42460 acc 0.66225 roc_auc 0.66353 prc_auc 0.83708[0m
[93maverage test of epoch 17: loss -3.57669 acc 0.67568 roc_auc 0.86333 prc_auc 0.92385[0m
[92maverage training of epoch 18: loss -3.71666 acc 0.66225 roc_auc 0.66196 prc_auc 0.83428[0m
[93maverage test of epoch 18: loss -3.86396 acc 0.67568 roc_auc 0.86333 prc_auc 0.92385[0m
[92maverage training of epoch 19: loss -3.99958 acc 0.66225 roc_auc 0.65471 prc_auc 0.82843[0m
[93maverage test of epoch 19: loss -4.14658 acc 0.67568 roc_auc 0.87000 prc_auc 0.92729[0m
[92maverage training of epoch 20: loss -4.28096 acc 0.66225 roc_auc 0.64490 prc_auc 0.82228[0m
[93maverage test of epoch 20: loss -4.43160 acc 0.67568 roc_auc 0.87000 prc_auc 0.92729[0m
[92maverage training of epoch 21: loss -4.56755 acc 0.66225 roc_auc 0.63627 prc_auc 0.81821[0m
[93maverage test of epoch 21: loss -4.72537 acc 0.67568 roc_auc 0.87000 prc_auc 0.92729[0m
[92maverage training of epoch 22: loss -4.86538 acc 0.66225 roc_auc 0.62745 prc_auc 0.81235[0m
[93maverage test of epoch 22: loss -5.03374 acc 0.67568 roc_auc 0.87000 prc_auc 0.92729[0m
[92maverage training of epoch 23: loss -5.17940 acc 0.66225 roc_auc 0.61784 prc_auc 0.80729[0m
[93maverage test of epoch 23: loss -5.36028 acc 0.67568 roc_auc 0.87000 prc_auc 0.92729[0m
[92maverage training of epoch 24: loss -5.51129 acc 0.66225 roc_auc 0.60471 prc_auc 0.79602[0m
[93maverage test of epoch 24: loss -5.70420 acc 0.67568 roc_auc 0.87000 prc_auc 0.92729[0m
[92maverage training of epoch 25: loss -5.85873 acc 0.66225 roc_auc 0.58941 prc_auc 0.77959[0m
[93maverage test of epoch 25: loss -6.06131 acc 0.67568 roc_auc 0.87000 prc_auc 0.92729[0m
[92maverage training of epoch 26: loss -6.21601 acc 0.66225 roc_auc 0.57549 prc_auc 0.76289[0m
[93maverage test of epoch 26: loss -6.42383 acc 0.67568 roc_auc 0.87000 prc_auc 0.92661[0m
[92maverage training of epoch 27: loss -6.57602 acc 0.66225 roc_auc 0.56020 prc_auc 0.75124[0m
[93maverage test of epoch 27: loss -6.78588 acc 0.67568 roc_auc 0.87333 prc_auc 0.92668[0m
[92maverage training of epoch 28: loss -6.93465 acc 0.66225 roc_auc 0.55000 prc_auc 0.74418[0m
[93maverage test of epoch 28: loss -7.14532 acc 0.67568 roc_auc 0.86667 prc_auc 0.92514[0m
[92maverage training of epoch 29: loss -7.29083 acc 0.66225 roc_auc 0.54618 prc_auc 0.74290[0m
[93maverage test of epoch 29: loss -7.50206 acc 0.67568 roc_auc 0.87000 prc_auc 0.92661[0m
[92maverage training of epoch 30: loss -7.64480 acc 0.66225 roc_auc 0.53922 prc_auc 0.73700[0m
[93maverage test of epoch 30: loss -7.85669 acc 0.67568 roc_auc 0.86667 prc_auc 0.92586[0m
[92maverage training of epoch 31: loss -7.99723 acc 0.66225 roc_auc 0.53059 prc_auc 0.72899[0m
[93maverage test of epoch 31: loss -8.21015 acc 0.67568 roc_auc 0.87000 prc_auc 0.92614[0m
[92maverage training of epoch 32: loss -8.34909 acc 0.66225 roc_auc 0.52294 prc_auc 0.72141[0m
[93maverage test of epoch 32: loss -8.56345 acc 0.67568 roc_auc 0.87000 prc_auc 0.92614[0m
[92maverage training of epoch 33: loss -8.70130 acc 0.66225 roc_auc 0.51255 prc_auc 0.71254[0m
[93maverage test of epoch 33: loss -8.91746 acc 0.67568 roc_auc 0.87000 prc_auc 0.92729[0m
[92maverage training of epoch 34: loss -9.05461 acc 0.66225 roc_auc 0.50196 prc_auc 0.70130[0m
[93maverage test of epoch 34: loss -9.27286 acc 0.67568 roc_auc 0.87000 prc_auc 0.92729[0m
[92maverage training of epoch 35: loss -9.40964 acc 0.66225 roc_auc 0.49078 prc_auc 0.68659[0m
[93maverage test of epoch 35: loss -9.63019 acc 0.67568 roc_auc 0.87000 prc_auc 0.92729[0mUsing backend: pytorch
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))

[92maverage training of epoch 36: loss -9.76683 acc 0.66225 roc_auc 0.47824 prc_auc 0.67521[0m
[93maverage test of epoch 36: loss -9.98982 acc 0.67568 roc_auc 0.87000 prc_auc 0.92729[0m
[92maverage training of epoch 37: loss -10.12657 acc 0.66225 roc_auc 0.46716 prc_auc 0.66334[0m
[93maverage test of epoch 37: loss -10.35217 acc 0.67568 roc_auc 0.87000 prc_auc 0.92729[0m
[92maverage training of epoch 38: loss -10.48921 acc 0.66225 roc_auc 0.45647 prc_auc 0.65390[0m
[93maverage test of epoch 38: loss -10.71755 acc 0.67568 roc_auc 0.87000 prc_auc 0.92729[0m
[92maverage training of epoch 39: loss -10.85504 acc 0.66225 roc_auc 0.44569 prc_auc 0.63927[0m
[93maverage test of epoch 39: loss -11.08620 acc 0.67568 roc_auc 0.87000 prc_auc 0.92729[0m
[92maverage training of epoch 40: loss -11.22428 acc 0.66225 roc_auc 0.43784 prc_auc 0.63201[0m
[93maverage test of epoch 40: loss -11.45837 acc 0.67568 roc_auc 0.87000 prc_auc 0.92752[0m
[92maverage training of epoch 41: loss -11.59713 acc 0.66225 roc_auc 0.42941 prc_auc 0.62401[0m
[93maverage test of epoch 41: loss -11.83420 acc 0.67568 roc_auc 0.87000 prc_auc 0.92729[0m
[92maverage training of epoch 42: loss -11.97375 acc 0.66225 roc_auc 0.42549 prc_auc 0.62140[0m
[93maverage test of epoch 42: loss -12.21387 acc 0.67568 roc_auc 0.87000 prc_auc 0.92729[0m
[92maverage training of epoch 43: loss -12.35426 acc 0.66225 roc_auc 0.42127 prc_auc 0.61617[0m
[93maverage test of epoch 43: loss -12.59749 acc 0.67568 roc_auc 0.87000 prc_auc 0.92729[0m
[92maverage training of epoch 44: loss -12.73879 acc 0.66225 roc_auc 0.41745 prc_auc 0.61396[0m
[93maverage test of epoch 44: loss -12.98519 acc 0.67568 roc_auc 0.86833 prc_auc 0.92618[0m
[92maverage training of epoch 45: loss -13.12744 acc 0.66225 roc_auc 0.41451 prc_auc 0.60727[0m
[93maverage test of epoch 45: loss -13.37707 acc 0.67568 roc_auc 0.86833 prc_auc 0.92495[0m
[92maverage training of epoch 46: loss -13.52030 acc 0.66225 roc_auc 0.41088 prc_auc 0.60380[0m
[93maverage test of epoch 46: loss -13.77321 acc 0.67568 roc_auc 0.86667 prc_auc 0.92385[0m
[92maverage training of epoch 47: loss -13.91746 acc 0.66225 roc_auc 0.40784 prc_auc 0.60044[0m
[93maverage test of epoch 47: loss -14.17369 acc 0.67568 roc_auc 0.86667 prc_auc 0.92401[0m
[92maverage training of epoch 48: loss -14.31899 acc 0.66225 roc_auc 0.40569 prc_auc 0.59889[0m
[93maverage test of epoch 48: loss -14.57860 acc 0.67568 roc_auc 0.86667 prc_auc 0.92401[0m
[92maverage training of epoch 49: loss -14.72495 acc 0.66225 roc_auc 0.40373 prc_auc 0.59758[0m
[93maverage test of epoch 49: loss -14.98799 acc 0.67568 roc_auc 0.86667 prc_auc 0.92401[0m
[92maverage training of epoch 50: loss -15.13541 acc 0.66225 roc_auc 0.40196 prc_auc 0.59490[0m
[93maverage test of epoch 50: loss -15.40192 acc 0.67568 roc_auc 0.86500 prc_auc 0.92243[0m
[92maverage training of epoch 51: loss -15.55042 acc 0.66225 roc_auc 0.39912 prc_auc 0.59284[0m
[93maverage test of epoch 51: loss -15.82046 acc 0.67568 roc_auc 0.86500 prc_auc 0.92280[0m
[92maverage training of epoch 52: loss -15.97004 acc 0.66225 roc_auc 0.39784 prc_auc 0.59216[0m
[93maverage test of epoch 52: loss -16.24365 acc 0.67568 roc_auc 0.86667 prc_auc 0.92535[0m
[92maverage training of epoch 53: loss -16.39431 acc 0.66225 roc_auc 0.39696 prc_auc 0.59172[0m
[93maverage test of epoch 53: loss -16.67154 acc 0.67568 roc_auc 0.86500 prc_auc 0.92339[0m
[92maverage training of epoch 54: loss -16.82328 acc 0.66225 roc_auc 0.39745 prc_auc 0.59237[0m
[93maverage test of epoch 54: loss -17.10416 acc 0.67568 roc_auc 0.86500 prc_auc 0.92394[0m
[92maverage training of epoch 55: loss -17.25699 acc 0.66225 roc_auc 0.39667 prc_auc 0.59255[0m
[93maverage test of epoch 55: loss -17.54157 acc 0.67568 roc_auc 0.86500 prc_auc 0.92383[0m
[92maverage training of epoch 56: loss -17.69546 acc 0.66225 roc_auc 0.39676 prc_auc 0.59269[0m
[93maverage test of epoch 56: loss -17.98379 acc 0.67568 roc_auc 0.86333 prc_auc 0.92387[0m
[92maverage training of epoch 57: loss -18.13875 acc 0.66225 roc_auc 0.39627 prc_auc 0.59252[0m
[93maverage test of epoch 57: loss -18.43086 acc 0.67568 roc_auc 0.85833 prc_auc 0.91487[0m
[92maverage training of epoch 58: loss -18.58685 acc 0.66225 roc_auc 0.39627 prc_auc 0.59259[0m
[93maverage test of epoch 58: loss -18.88272 acc 0.67568 roc_auc 0.87000 prc_auc 0.92394[0m
[92maverage training of epoch 59: loss -19.03950 acc 0.66225 roc_auc 0.39608 prc_auc 0.58593[0m
[93maverage test of epoch 59: loss -19.33897 acc 0.67568 roc_auc 0.86000 prc_auc 0.91417[0m
[92maverage training of epoch 60: loss -19.49647 acc 0.66225 roc_auc 0.39608 prc_auc 0.58570[0m
[93maverage test of epoch 60: loss -19.79958 acc 0.67568 roc_auc 0.87000 prc_auc 0.91961[0m
[92maverage training of epoch 61: loss -19.95781 acc 0.66225 roc_auc 0.39686 prc_auc 0.58630[0m
[93maverage test of epoch 61: loss -20.26463 acc 0.67568 roc_auc 0.87000 prc_auc 0.92242[0m
[92maverage training of epoch 62: loss -20.42362 acc 0.66225 roc_auc 0.39657 prc_auc 0.58558[0m
[93maverage test of epoch 62: loss -20.73422 acc 0.67568 roc_auc 0.86333 prc_auc 0.90396[0m
[92maverage training of epoch 63: loss -20.89397 acc 0.66225 roc_auc 0.39667 prc_auc 0.58569[0m
[93maverage test of epoch 63: loss -21.20842 acc 0.67568 roc_auc 0.86667 prc_auc 0.89417[0m
[92maverage training of epoch 64: loss -21.36892 acc 0.66225 roc_auc 0.39627 prc_auc 0.58543[0m
[93maverage test of epoch 64: loss -21.68722 acc 0.67568 roc_auc 0.83167 prc_auc 0.86752[0m
[92maverage training of epoch 65: loss -21.84822 acc 0.66225 roc_auc 0.39637 prc_auc 0.58583[0m
[93maverage test of epoch 65: loss -22.17019 acc 0.67568 roc_auc 0.86500 prc_auc 0.89559[0m
[92maverage training of epoch 66: loss -22.33162 acc 0.66225 roc_auc 0.39725 prc_auc 0.58627[0m
[93maverage test of epoch 66: loss -22.65733 acc 0.67568 roc_auc 0.72500 prc_auc 0.81200[0m
[92maverage training of epoch 67: loss -22.81923 acc 0.66225 roc_auc 0.39725 prc_auc 0.58677[0m
[93maverage test of epoch 67: loss -23.14878 acc 0.67568 roc_auc 0.86000 prc_auc 0.89108[0m
[92maverage training of epoch 68: loss -23.31117 acc 0.66225 roc_auc 0.39725 prc_auc 0.58624[0m
[93maverage test of epoch 68: loss -23.64465 acc 0.67568 roc_auc 0.76000 prc_auc 0.81691[0m
[92maverage training of epoch 69: loss -23.80756 acc 0.66225 roc_auc 0.39745 prc_auc 0.58690[0m
[93maverage test of epoch 69: loss -24.14504 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 70: loss -24.30849 acc 0.66225 roc_auc 0.39696 prc_auc 0.58651[0m
[93maverage test of epoch 70: loss -24.65005 acc 0.67568 roc_auc 0.70000 prc_auc 0.79751[0m
[92maverage training of epoch 71: loss -24.81404 acc 0.66225 roc_auc 0.39765 prc_auc 0.58622[0m
[93maverage test of epoch 71: loss -25.15975 acc 0.67568 roc_auc 0.70000 prc_auc 0.79751[0m
[92maverage training of epoch 72: loss -25.32428 acc 0.66225 roc_auc 0.39814 prc_auc 0.58607[0m
[93maverage test of epoch 72: loss -25.67420 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 73: loss -25.83927 acc 0.66225 roc_auc 0.39882 prc_auc 0.58675[0m
[93maverage test of epoch 73: loss -26.19344 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 74: loss -26.35907 acc 0.66225 roc_auc 0.39892 prc_auc 0.58721[0m
[93maverage test of epoch 74: loss -26.71758 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 75: loss -26.88372 acc 0.66225 roc_auc 0.39892 prc_auc 0.58668[0m
[93maverage test of epoch 75: loss -27.24660 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 76: loss -27.41329 acc 0.66225 roc_auc 0.39931 prc_auc 0.58700[0m
[93maverage test of epoch 76: loss -27.78058 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 77: loss -27.94777 acc 0.66225 roc_auc 0.39931 prc_auc 0.58741[0m
[93maverage test of epoch 77: loss -28.31952 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 78: loss -28.48723 acc 0.66225 roc_auc 0.40039 prc_auc 0.58757[0m
[93maverage test of epoch 78: loss -28.86351 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 79: loss -29.03170 acc 0.66225 roc_auc 0.40118 prc_auc 0.58789[0m
[93maverage test of epoch 79: loss -29.41252 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 80: loss -29.58119 acc 0.66225 roc_auc 0.40088 prc_auc 0.58818[0m
[93maverage test of epoch 80: loss -29.96658 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 81: loss -30.13570 acc 0.66225 roc_auc 0.40088 prc_auc 0.58889[0m
[93maverage test of epoch 81: loss -30.52573 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 82: loss -30.69530 acc 0.66225 roc_auc 0.40118 prc_auc 0.58844[0m
[93maverage test of epoch 82: loss -31.08999 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 83: loss -31.25997 acc 0.66225 roc_auc 0.40147 prc_auc 0.58869[0m
[93maverage test of epoch 83: loss -31.65937 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 84: loss -31.82977 acc 0.66225 roc_auc 0.40245 prc_auc 0.58880[0m
[93maverage test of epoch 84: loss -32.23392 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 85: loss -32.40472 acc 0.66225 roc_auc 0.40294 prc_auc 0.59044[0m
[93maverage test of epoch 85: loss -32.81364 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 86: loss -32.98474 acc 0.66225 roc_auc 0.40392 prc_auc 0.59007[0m
[93maverage test of epoch 86: loss -33.39842 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 87: loss -33.56987 acc 0.66225 roc_auc 0.40578 prc_auc 0.59140[0m
[93maverage test of epoch 87: loss -33.98839 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 88: loss -34.16015 acc 0.66225 roc_auc 0.40392 prc_auc 0.58884[0m
[93maverage test of epoch 88: loss -34.58355 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 89: loss -34.75562 acc 0.66225 roc_auc 0.40686 prc_auc 0.59055[0m
[93maverage test of epoch 89: loss -35.18392 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 90: loss -35.35627 acc 0.66225 roc_auc 0.40539 prc_auc 0.58922[0m
[93maverage test of epoch 90: loss -35.78952 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 91: loss -35.96213 acc 0.66225 roc_auc 0.40510 prc_auc 0.59066[0m
[93maverage test of epoch 91: loss -36.40034 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 92: loss -36.57316 acc 0.66225 roc_auc 0.40824 prc_auc 0.59082[0m
[93maverage test of epoch 92: loss -37.01634 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 93: loss -37.18937 acc 0.66225 roc_auc 0.40373 prc_auc 0.58955[0m
[93maverage test of epoch 93: loss -37.63758 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 94: loss -37.81081 acc 0.66225 roc_auc 0.40657 prc_auc 0.59096[0m
[93maverage test of epoch 94: loss -38.26408 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 95: loss -38.43747 acc 0.66225 roc_auc 0.40245 prc_auc 0.59093[0m
[93maverage test of epoch 95: loss -38.89583 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 96: loss -39.06932 acc 0.66225 roc_auc 0.41069 prc_auc 0.59467[0m
[93maverage test of epoch 96: loss -39.53275 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 97: loss -39.70636 acc 0.66225 roc_auc 0.40912 prc_auc 0.59724[0m
[93maverage test of epoch 97: loss -40.17493 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 98: loss -40.34861 acc 0.66225 roc_auc 0.41098 prc_auc 0.59651[0m
[93maverage test of epoch 98: loss -40.82234 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 99: loss -40.99610 acc 0.66225 roc_auc 0.40392 prc_auc 0.59436[0m
[93maverage test of epoch 99: loss -41.47502 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss 0.38857 acc 0.33775 roc_auc 0.20373 prc_auc 0.51893[0m
[93maverage test of epoch 0: loss 0.35255 acc 0.32432 roc_auc 0.06667 prc_auc 0.48823[0m
[92maverage training of epoch 1: loss 0.25508 acc 0.33775 roc_auc 0.20275 prc_auc 0.51815[0m
[93maverage test of epoch 1: loss 0.21947 acc 0.32432 roc_auc 0.06667 prc_auc 0.48823[0m
[92maverage training of epoch 2: loss 0.12157 acc 0.33775 roc_auc 0.20098 prc_auc 0.51754[0m
[93maverage test of epoch 2: loss 0.08594 acc 0.32432 roc_auc 0.06667 prc_auc 0.48823[0m
[92maverage training of epoch 3: loss -0.01318 acc 0.33775 roc_auc 0.19725 prc_auc 0.51745[0m
[93maverage test of epoch 3: loss -0.04923 acc 0.32432 roc_auc 0.06667 prc_auc 0.48823[0m
[92maverage training of epoch 4: loss -0.14909 acc 0.33775 roc_auc 0.19686 prc_auc 0.52631[0m
[93maverage test of epoch 4: loss -0.18566 acc 0.32432 roc_auc 0.06667 prc_auc 0.48823[0m
[92maverage training of epoch 5: loss -0.28492 acc 0.33775 roc_auc 0.19412 prc_auc 0.52650[0m
[93maverage test of epoch 5: loss -0.32159 acc 0.32432 roc_auc 0.06667 prc_auc 0.48823[0m
[92maverage training of epoch 6: loss -0.42011 acc 0.33775 roc_auc 0.18843 prc_auc 0.52565[0m
[93maverage test of epoch 6: loss -0.45697 acc 0.32432 roc_auc 0.06667 prc_auc 0.48823[0m
[92maverage training of epoch 7: loss -0.55563 acc 0.33775 roc_auc 0.17961 prc_auc 0.52258[0m
[93maverage test of epoch 7: loss -0.59363 acc 0.32432 roc_auc 0.06667 prc_auc 0.48823[0m
[92maverage training of epoch 8: loss -0.69574 acc 0.33775 roc_auc 0.16392 prc_auc 0.51673[0m
[93maverage test of epoch 8: loss -0.73899 acc 0.32432 roc_auc 0.07000 prc_auc 0.48890[0m
[92maverage training of epoch 9: loss -0.85105 acc 0.33775 roc_auc 0.22294 prc_auc 0.56226[0m
[93maverage test of epoch 9: loss -0.90506 acc 0.32432 roc_auc 0.07000 prc_auc 0.48890[0m
[92maverage training of epoch 10: loss -1.06259 acc 0.33775 roc_auc 0.48510 prc_auc 0.75224[0m
[93maverage test of epoch 10: loss -1.17777 acc 0.32432 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 11: loss -1.45237 acc 0.33775 roc_auc 0.65941 prc_auc 0.81336[0m
[93maverage test of epoch 11: loss -1.73757 acc 0.32432 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 12: loss -1.93520 acc 0.33775 roc_auc 0.84039 prc_auc 0.91660[0m
[93maverage test of epoch 12: loss -2.07493 acc 0.32432 roc_auc 0.92667 prc_auc 0.97104[0m
[92maverage training of epoch 13: loss -2.21303 acc 0.33775 roc_auc 0.87765 prc_auc 0.93799[0m
[93maverage test of epoch 13: loss -2.31795 acc 0.32432 roc_auc 0.92333 prc_auc 0.96958[0m
[92maverage training of epoch 14: loss -2.43146 acc 0.33775 roc_auc 0.87451 prc_auc 0.93371[0m
[93maverage test of epoch 14: loss -2.51482 acc 0.32432 roc_auc 0.92333 prc_auc 0.96958[0m
[92maverage training of epoch 15: loss -2.61438 acc 0.33775 roc_auc 0.87392 prc_auc 0.93033[0m
[93maverage test of epoch 15: loss -2.68569 acc 0.32432 roc_auc 0.92333 prc_auc 0.96958[0m
[92maverage training of epoch 16: loss -2.77779 acc 0.33775 roc_auc 0.87353 prc_auc 0.92797[0m
[93maverage test of epoch 16: loss -2.84214 acc 0.32432 roc_auc 0.92333 prc_auc 0.96958[0m
[92maverage training of epoch 17: loss -2.93038 acc 0.33775 roc_auc 0.87098 prc_auc 0.92390[0m
[93maverage test of epoch 17: loss -2.99075 acc 0.32432 roc_auc 0.92333 prc_auc 0.96958[0m
[92maverage training of epoch 18: loss -3.07709 acc 0.33775 roc_auc 0.87098 prc_auc 0.92316[0m
[93maverage test of epoch 18: loss -3.13485 acc 0.32432 roc_auc 0.92333 prc_auc 0.96958[0m
[92maverage training of epoch 19: loss -3.22067 acc 0.33775 roc_auc 0.87196 prc_auc 0.92403[0m
[93maverage test of epoch 19: loss -3.27723 acc 0.32432 roc_auc 0.92333 prc_auc 0.96958[0m
[92maverage training of epoch 20: loss -3.36320 acc 0.33775 roc_auc 0.86961 prc_auc 0.92126[0m
[93maverage test of epoch 20: loss -3.41959 acc 0.32432 roc_auc 0.92333 prc_auc 0.96958[0m
[92maverage training of epoch 21: loss -3.50631 acc 0.33775 roc_auc 0.87118 prc_auc 0.92131[0m
[93maverage test of epoch 21: loss -3.56241 acc 0.32432 roc_auc 0.92333 prc_auc 0.96958[0m
[92maverage training of epoch 22: loss -3.65082 acc 0.33775 roc_auc 0.87392 prc_auc 0.92293[0m
[93maverage test of epoch 22: loss -3.70640 acc 0.32432 roc_auc 0.92333 prc_auc 0.96958[0m
[92maverage training of epoch 23: loss -3.79679 acc 0.33775 roc_auc 0.87412 prc_auc 0.92159[0m
[93maverage test of epoch 23: loss -3.85317 acc 0.32432 roc_auc 0.92333 prc_auc 0.96958[0m
[92maverage training of epoch 24: loss -3.94577 acc 0.33775 roc_auc 0.87608 prc_auc 0.92200[0m
[93maverage test of epoch 24: loss -4.00201 acc 0.32432 roc_auc 0.92333 prc_auc 0.96958[0m
[92maverage training of epoch 25: loss -4.09734 acc 0.33775 roc_auc 0.87765 prc_auc 0.92270[0m
[93maverage test of epoch 25: loss -4.15392 acc 0.32432 roc_auc 0.92333 prc_auc 0.96958[0m
[92maverage training of epoch 26: loss -4.25184 acc 0.33775 roc_auc 0.87745 prc_auc 0.92190[0m
[93maverage test of epoch 26: loss -4.30983 acc 0.32432 roc_auc 0.92333 prc_auc 0.96958[0m
[92maverage training of epoch 27: loss -4.40964 acc 0.33775 roc_auc 0.87725 prc_auc 0.92132[0m
[93maverage test of epoch 27: loss -4.46821 acc 0.32432 roc_auc 0.92667 prc_auc 0.97104[0m
[92maverage training of epoch 28: loss -4.57067 acc 0.33775 roc_auc 0.87647 prc_auc 0.91923[0m
[93maverage test of epoch 28: loss -4.62932 acc 0.32432 roc_auc 0.92667 prc_auc 0.97104[0m
[92maverage training of epoch 29: loss -4.73441 acc 0.33775 roc_auc 0.87647 prc_auc 0.91466[0m
[93maverage test of epoch 29: loss -4.79448 acc 0.32432 roc_auc 0.92667 prc_auc 0.97104[0m
[92maverage training of epoch 30: loss -4.90204 acc 0.33775 roc_auc 0.86647 prc_auc 0.89039[0m
[93maverage test of epoch 30: loss -4.96382 acc 0.32432 roc_auc 0.92667 prc_auc 0.97104[0m
[92maverage training of epoch 31: loss -5.07266 acc 0.33775 roc_auc 0.86333 prc_auc 0.87291[0m
[93maverage test of epoch 31: loss -5.13342 acc 0.32432 roc_auc 0.92667 prc_auc 0.97104[0m
[92maverage training of epoch 32: loss -5.24495 acc 0.33775 roc_auc 0.86196 prc_auc 0.87074[0m
[93maverage test of epoch 32: loss -5.30630 acc 0.32432 roc_auc 0.92667 prc_auc 0.97104[0m
[92maverage training of epoch 33: loss -5.42000 acc 0.33775 roc_auc 0.86039 prc_auc 0.86425[0m
[93maverage test of epoch 33: loss -5.48042 acc 0.32432 roc_auc 0.92667 prc_auc 0.97104[0m
[92maverage training of epoch 34: loss -5.59634 acc 0.33775 roc_auc 0.85667 prc_auc 0.86184[0m
[93maverage test of epoch 34: loss -5.65586 acc 0.32432 roc_auc 0.92667 prc_auc 0.97104[0m
[92maverage training of epoch 35: loss -5.77365 acc 0.33775 roc_auc 0.84765 prc_auc 0.85086[0m
[93maverage test of epoch 35: loss -5.83205 acc 0.32432 roc_auc 0.92667 prc_auc 0.97104[0m
[92maverage training of epoch 36: loss -5.95142 acc 0.33775 roc_auc 0.84059 prc_auc 0.83542[0m
[93maverage test of epoch 36: loss -6.00762 acc 0.32432 roc_auc 0.92667 prc_auc 0.97104[0m
[92maverage training of epoch 37: loss -6.12866 acc 0.33775 roc_auc 0.83902 prc_auc 0.83297[0m
[93maverage test of epoch 37: loss -6.18197 acc 0.32432 roc_auc 0.92667 prc_auc 0.97104[0m
[92maverage training of epoch 38: loss -6.30422 acc 0.33775 roc_auc 0.83804 prc_auc 0.82995[0m
[93maverage test of epoch 38: loss -6.35450 acc 0.32432 roc_auc 0.92667 prc_auc 0.97104[0m
[92maverage training of epoch 39: loss -6.47750 acc 0.33775 roc_auc 0.83686 prc_auc 0.82806[0m
[93maverage test of epoch 39: loss -6.52507 acc 0.32432 roc_auc 0.92667 prc_auc 0.97104[0m
[92maverage training of epoch 40: loss -6.64860 acc 0.33775 roc_auc 0.83608 prc_auc 0.82590[0m
[93maverage test of epoch 40: loss -6.69431 acc 0.32432 roc_auc 0.92667 prc_auc 0.97104[0m
[92maverage training of epoch 41: loss -6.81856 acc 0.33775 roc_auc 0.83431 prc_auc 0.82351[0m
[93maverage test of epoch 41: loss -6.86246 acc 0.32432 roc_auc 0.92667 prc_auc 0.97104[0m
[92maverage training of epoch 42: loss -6.98760 acc 0.33775 roc_auc 0.83451 prc_auc 0.82333[0m
[93maverage test of epoch 42: loss -7.03004 acc 0.32432 roc_auc 0.92667 prc_auc 0.97104[0m
[92maverage training of epoch 43: loss -7.15616 acc 0.33775 roc_auc 0.83392 prc_auc 0.82301[0m
[93maverage test of epoch 43: loss -7.19742 acc 0.32432 roc_auc 0.93000 prc_auc 0.97235[0m
[92maverage training of epoch 44: loss -7.32440 acc 0.33775 roc_auc 0.83471 prc_auc 0.82353[0m
[93maverage test of epoch 44: loss -7.36491 acc 0.32432 roc_auc 0.93000 prc_auc 0.97235[0m
[92maverage training of epoch 45: loss -7.49304 acc 0.33775 roc_auc 0.83412 prc_auc 0.82290[0m
[93maverage test of epoch 45: loss -7.53260 acc 0.32432 roc_auc 0.93000 prc_auc 0.97235[0m
[92maverage training of epoch 46: loss -7.66206 acc 0.33775 roc_auc 0.83412 prc_auc 0.82282[0m
[93maverage test of epoch 46: loss -7.70072 acc 0.32432 roc_auc 0.93000 prc_auc 0.97235[0m
[92maverage training of epoch 47: loss -7.83147 acc 0.33775 roc_auc 0.83373 prc_auc 0.82223[0m
[93maverage test of epoch 47: loss -7.86962 acc 0.32432 roc_auc 0.93000 prc_auc 0.97235[0m
[92maverage training of epoch 48: loss -8.00169 acc 0.33775 roc_auc 0.83392 prc_auc 0.82337[0m
[93maverage test of epoch 48: loss -8.03923 acc 0.32432 roc_auc 0.93000 prc_auc 0.97235[0m
[92maverage training of epoch 49: loss -8.17255 acc 0.33775 roc_auc 0.83314 prc_auc 0.82218[0m
[93maverage test of epoch 49: loss -8.20988 acc 0.32432 roc_auc 0.93000 prc_auc 0.97235[0m
[92maverage training of epoch 50: loss -8.34437 acc 0.33775 roc_auc 0.83373 prc_auc 0.82311[0m
[93maverage test of epoch 50: loss -8.38147 acc 0.32432 roc_auc 0.93000 prc_auc 0.97235[0m
[92maverage training of epoch 51: loss -8.51729 acc 0.33775 roc_auc 0.83314 prc_auc 0.82208[0m
[93maverage test of epoch 51: loss -8.55404 acc 0.32432 roc_auc 0.93000 prc_auc 0.97235[0m
[92maverage training of epoch 52: loss -8.69126 acc 0.33775 roc_auc 0.83275 prc_auc 0.82121[0m
[93maverage test of epoch 52: loss -8.72772 acc 0.32432 roc_auc 0.93000 prc_auc 0.97235[0m
[92maverage training of epoch 53: loss -8.86637 acc 0.33775 roc_auc 0.83235 prc_auc 0.82098[0m
[93maverage test of epoch 53: loss -8.90257 acc 0.32432 roc_auc 0.93000 prc_auc 0.97235[0m
[92maverage training of epoch 54: loss -9.04264 acc 0.33775 roc_auc 0.83235 prc_auc 0.82079[0m
[93maverage test of epoch 54: loss -9.07860 acc 0.32432 roc_auc 0.93000 prc_auc 0.97235[0m
[92maverage training of epoch 55: loss -9.22010 acc 0.33775 roc_auc 0.83275 prc_auc 0.82202[0m
[93maverage test of epoch 55: loss -9.25587 acc 0.32432 roc_auc 0.93000 prc_auc 0.97235[0m
[92maverage training of epoch 56: loss -9.39881 acc 0.33775 roc_auc 0.83294 prc_auc 0.82255[0m
[93maverage test of epoch 56: loss -9.43444 acc 0.32432 roc_auc 0.93000 prc_auc 0.97235[0m
[92maverage training of epoch 57: loss -9.57880 acc 0.33775 roc_auc 0.83275 prc_auc 0.82225[0m
[93maverage test of epoch 57: loss -9.61431 acc 0.32432 roc_auc 0.93000 prc_auc 0.97235[0m
[92maverage training of epoch 58: loss -9.76009 acc 0.33775 roc_auc 0.83363 prc_auc 0.82306[0m
[93maverage test of epoch 58: loss -9.79553 acc 0.32432 roc_auc 0.93000 prc_auc 0.97235[0m
[92maverage training of epoch 59: loss -9.94272 acc 0.33775 roc_auc 0.83333 prc_auc 0.82278[0m
[93maverage test of epoch 59: loss -9.97788 acc 0.32432 roc_auc 0.93000 prc_auc 0.97235[0m
[92maverage training of epoch 60: loss -10.12659 acc 0.33775 roc_auc 0.83314 prc_auc 0.82247[0m
[93maverage test of epoch 60: loss -10.16166 acc 0.32432 roc_auc 0.93000 prc_auc 0.97235[0m
[92maverage training of epoch 61: loss -10.31180 acc 0.33775 roc_auc 0.83294 prc_auc 0.82183[0m
[93maverage test of epoch 61: loss -10.34686 acc 0.32432 roc_auc 0.93000 prc_auc 0.97235[0m
[92maverage training of epoch 62: loss -10.49857 acc 0.33775 roc_auc 0.83235 prc_auc 0.82141[0m
[93maverage test of epoch 62: loss -10.53322 acc 0.32432 roc_auc 0.93000 prc_auc 0.97235[0m
[92maverage training of epoch 63: loss -10.68645 acc 0.33775 roc_auc 0.83255 prc_auc 0.82171[0m
[93maverage test of epoch 63: loss -10.72113 acc 0.32432 roc_auc 0.93000 prc_auc 0.97235[0m
[92maverage training of epoch 64: loss -10.87575 acc 0.33775 roc_auc 0.83255 prc_auc 0.82149[0m
[93maverage test of epoch 64: loss -10.91053 acc 0.32432 roc_auc 0.93000 prc_auc 0.97235[0m
[92maverage training of epoch 65: loss -11.06647 acc 0.33775 roc_auc 0.83255 prc_auc 0.82149[0m
[93maverage test of epoch 65: loss -11.10139 acc 0.32432 roc_auc 0.93000 prc_auc 0.97235[0m
[92maverage training of epoch 66: loss -11.25854 acc 0.33775 roc_auc 0.83235 prc_auc 0.82119[0m
[93maverage test of epoch 66: loss -11.29350 acc 0.32432 roc_auc 0.93000 prc_auc 0.97235[0m
[92maverage training of epoch 67: loss -11.45202 acc 0.33775 roc_auc 0.83255 prc_auc 0.82125[0m
[93maverage test of epoch 67: loss -11.48719 acc 0.32432 roc_auc 0.93000 prc_auc 0.97235[0m
[92maverage training of epoch 68: loss -11.64688 acc 0.33775 roc_auc 0.83235 prc_auc 0.82093[0m
[93maverage test of epoch 68: loss -11.68214 acc 0.32432 roc_auc 0.93000 prc_auc 0.97235[0m
[92maverage training of epoch 69: loss -11.84302 acc 0.33775 roc_auc 0.83235 prc_auc 0.82093[0m
[93maverage test of epoch 69: loss -11.87848 acc 0.32432 roc_auc 0.93000 prc_auc 0.97235[0m
[92maverage training of epoch 70: loss -12.04054 acc 0.33775 roc_auc 0.83216 prc_auc 0.82061[0m
[93maverage test of epoch 70: loss -12.07619 acc 0.32432 roc_auc 0.93000 prc_auc 0.97235[0m
[92maverage training of epoch 71: loss -12.23937 acc 0.33775 roc_auc 0.83216 prc_auc 0.82061[0m
[93maverage test of epoch 71: loss -12.27511 acc 0.32432 roc_auc 0.93000 prc_auc 0.97235[0m
[92maverage training of epoch 72: loss -12.43965 acc 0.33775 roc_auc 0.83196 prc_auc 0.82019[0m
[93maverage test of epoch 72: loss -12.47553 acc 0.32432 roc_auc 0.93000 prc_auc 0.97235[0m
[92maverage training of epoch 73: loss -12.64120 acc 0.33775 roc_auc 0.83196 prc_auc 0.82045[0m
[93maverage test of epoch 73: loss -12.67740 acc 0.32432 roc_auc 0.93000 prc_auc 0.97235[0m
[92maverage training of epoch 74: loss -12.84421 acc 0.33775 roc_auc 0.83216 prc_auc 0.82051[0m
[93maverage test of epoch 74: loss -12.88090 acc 0.32432 roc_auc 0.93000 prc_auc 0.97235[0m
[92maverage training of epoch 75: loss -13.04880 acc 0.33775 roc_auc 0.83216 prc_auc 0.82051[0m
[93maverage test of epoch 75: loss -13.08591 acc 0.32432 roc_auc 0.93000 prc_auc 0.97235[0m
[92maverage training of epoch 76: loss -13.25492 acc 0.33775 roc_auc 0.83235 prc_auc 0.82058[0m
[93maverage test of epoch 76: loss -13.29246 acc 0.32432 roc_auc 0.93000 prc_auc 0.97235[0m
[92maverage training of epoch 77: loss -13.46255 acc 0.33775 roc_auc 0.83235 prc_auc 0.82059[0m
[93maverage test of epoch 77: loss -13.50055 acc 0.32432 roc_auc 0.93000 prc_auc 0.97235[0m
[92maverage training of epoch 78: loss -13.67169 acc 0.33775 roc_auc 0.83275 prc_auc 0.82073[0m
[93maverage test of epoch 78: loss -13.71018 acc 0.32432 roc_auc 0.93000 prc_auc 0.97235[0m
[92maverage training of epoch 79: loss -13.88235 acc 0.33775 roc_auc 0.83255 prc_auc 0.82032[0m
[93maverage test of epoch 79: loss -13.92136 acc 0.32432 roc_auc 0.93000 prc_auc 0.97235[0m
[92maverage training of epoch 80: loss -14.09454 acc 0.33775 roc_auc 0.83255 prc_auc 0.82033[0m
[93maverage test of epoch 80: loss -14.13410 acc 0.32432 roc_auc 0.93000 prc_auc 0.97235[0m
[92maverage training of epoch 81: loss -14.30834 acc 0.33775 roc_auc 0.83431 prc_auc 0.83043[0m
[93maverage test of epoch 81: loss -14.34849 acc 0.32432 roc_auc 0.93333 prc_auc 0.97332[0m
[92maverage training of epoch 82: loss -14.52384 acc 0.33775 roc_auc 0.84059 prc_auc 0.83886[0m
[93maverage test of epoch 82: loss -14.56433 acc 0.32432 roc_auc 0.93333 prc_auc 0.97332[0m
[92maverage training of epoch 83: loss -14.74073 acc 0.33775 roc_auc 0.84294 prc_auc 0.83943[0m
[93maverage test of epoch 83: loss -14.78148 acc 0.32432 roc_auc 0.93333 prc_auc 0.97332[0m
[92maverage training of epoch 84: loss -14.95881 acc 0.33775 roc_auc 0.84529 prc_auc 0.85206[0m
[93maverage test of epoch 84: loss -14.99972 acc 0.32432 roc_auc 0.93333 prc_auc 0.97332[0m
[92maverage training of epoch 85: loss -15.17821 acc 0.33775 roc_auc 0.85000 prc_auc 0.85873[0m
[93maverage test of epoch 85: loss -15.21939 acc 0.32432 roc_auc 0.93333 prc_auc 0.97332[0m
[92maverage training of epoch 86: loss -15.39888 acc 0.33775 roc_auc 0.85588 prc_auc 0.87306[0m
[93maverage test of epoch 86: loss -15.44024 acc 0.32432 roc_auc 0.93667 prc_auc 0.97435[0m
[92maverage training of epoch 87: loss -15.62077 acc 0.33775 roc_auc 0.86078 prc_auc 0.88353[0m
[93maverage test of epoch 87: loss -15.66240 acc 0.32432 roc_auc 0.93667 prc_auc 0.97435[0m
[92maverage training of epoch 88: loss -15.84395 acc 0.33775 roc_auc 0.86078 prc_auc 0.88428[0m
[93maverage test of epoch 88: loss -15.88598 acc 0.32432 roc_auc 0.93667 prc_auc 0.97435[0m
[92maverage training of epoch 89: loss -16.06867 acc 0.33775 roc_auc 0.86157 prc_auc 0.88853[0m
[93maverage test of epoch 89: loss -16.11096 acc 0.32432 roc_auc 0.93667 prc_auc 0.97435[0m
[92maverage training of epoch 90: loss -16.29481 acc 0.33775 roc_auc 0.86265 prc_auc 0.89086[0m
[93maverage test of epoch 90: loss -16.33739 acc 0.32432 roc_auc 0.93667 prc_auc 0.97435[0m
[92maverage training of epoch 91: loss -16.52237 acc 0.33775 roc_auc 0.86196 prc_auc 0.89018[0m
[93maverage test of epoch 91: loss -16.56529 acc 0.32432 roc_auc 0.94000 prc_auc 0.97546[0m
[92maverage training of epoch 92: loss -16.75134 acc 0.33775 roc_auc 0.86235 prc_auc 0.89100[0m
[93maverage test of epoch 92: loss -16.79464 acc 0.32432 roc_auc 0.94000 prc_auc 0.97546[0m
[92maverage training of epoch 93: loss -16.98174 acc 0.33775 roc_auc 0.86216 prc_auc 0.89100[0m
[93maverage test of epoch 93: loss -17.02545 acc 0.32432 roc_auc 0.94000 prc_auc 0.97546[0m
[92maverage training of epoch 94: loss -17.21356 acc 0.53642 roc_auc 0.86216 prc_auc 0.89161[0m
[93maverage test of epoch 94: loss -17.25773 acc 0.64865 roc_auc 0.94000 prc_auc 0.97546[0m
[92maverage training of epoch 95: loss -17.44679 acc 0.70861 roc_auc 0.86255 prc_auc 0.89235[0m
[93maverage test of epoch 95: loss -17.49149 acc 0.75676 roc_auc 0.94000 prc_auc 0.97546[0m
[92maverage training of epoch 96: loss -17.68143 acc 0.72848 roc_auc 0.86255 prc_auc 0.89225[0m
[93maverage test of epoch 96: loss -17.72678 acc 0.78378 roc_auc 0.94000 prc_auc 0.97546[0m
[92maverage training of epoch 97: loss -17.91751 acc 0.72848 roc_auc 0.86137 prc_auc 0.89117[0m
[93maverage test of epoch 97: loss -17.96360 acc 0.83784 roc_auc 0.94000 prc_auc 0.97546[0m
[92maverage training of epoch 98: loss -18.15506 acc 0.76159 roc_auc 0.86176 prc_auc 0.89018[0m
[93maverage test of epoch 98: loss -18.20195 acc 0.83784 roc_auc 0.94000 prc_auc 0.97546[0m
[92maverage training of epoch 99: loss -18.39403 acc 0.82119 roc_auc 0.86235 prc_auc 0.89153[0m
[93maverage test of epoch 99: loss -18.44190 acc 0.83784 roc_auc 0.94000 prc_auc 0.97546[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 1)
('lr', 0.0001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.69744 ROC_AUC (avg): 0.592 PRC_AUC (avg): 0.72756 

Average forward propagation time taken(ms): 2.805494178877053
Average backward propagation time taken(ms): 0.9387540205204187

