# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 1)
('lr', 0.001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-17-44-50/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-17-44-50/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 8,
 'epochs': 50,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 8,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.001,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 1,
 'num_workers': 8,
 'number_of_mlp_layer': 1,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-17-17-44-50',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 50, 'learning_rate': 0.001, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -1.48589 acc 0.66667 roc_auc 0.35100 prc_auc 0.56167[0m
[93maverage test of epoch 0: loss -3.38044 acc 0.65789 roc_auc 0.10462 prc_auc 0.47806[0m
[92maverage training of epoch 1: loss -5.50300 acc 0.66667 roc_auc 0.40880 prc_auc 0.61595[0m
[93maverage test of epoch 1: loss -7.77627 acc 0.65789 roc_auc 0.17846 prc_auc 0.50710[0m
[92maverage training of epoch 2: loss -10.08403 acc 0.66667 roc_auc 0.39500 prc_auc 0.60106[0m
[93maverage test of epoch 2: loss -12.44530 acc 0.65789 roc_auc 0.52000 prc_auc 0.70056[0m
[92maverage training of epoch 3: loss -15.10033 acc 0.66667 roc_auc 0.37750 prc_auc 0.58695[0m
[93maverage test of epoch 3: loss -17.83596 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 4: loss -20.92474 acc 0.66667 roc_auc 0.36650 prc_auc 0.57560[0m
[93maverage test of epoch 4: loss -24.08289 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 5: loss -27.65294 acc 0.66667 roc_auc 0.36080 prc_auc 0.57114[0m
[93maverage test of epoch 5: loss -31.29375 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 6: loss -35.39217 acc 0.66667 roc_auc 0.36190 prc_auc 0.58247[0m
[93maverage test of epoch 6: loss -39.55772 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 7: loss -44.21387 acc 0.66667 roc_auc 0.36310 prc_auc 0.60270[0m
[93maverage test of epoch 7: loss -48.92943 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 8: loss -54.15527 acc 0.66667 roc_auc 0.43000 prc_auc 0.63767[0m
[93maverage test of epoch 8: loss -59.41862 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 9: loss -65.19979 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 9: loss -70.99652 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 10: loss -77.33202 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 10: loss -83.65107 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 11: loss -90.51241 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 11: loss -97.31206 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 12: loss -104.63418 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 12: loss -111.83657 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 13: loss -119.58294 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 13: loss -127.17831 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 14: loss -135.36024 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 14: loss -143.35152 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 15: loss -151.97755 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 15: loss -160.36609 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 16: loss -169.44297 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 16: loss -178.22895 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 17: loss -187.76252 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 17: loss -196.94572 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 18: loss -206.94110 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 18: loss -216.52074 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -226.98255 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 19: loss -236.95771 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -247.89031 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 20: loss -258.25973 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -269.66720 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 21: loss -280.42950 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -292.31580 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 22: loss -303.46958 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -315.83835 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 23: loss -327.38208 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -340.23688 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 24: loss -352.16885 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -365.51322 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 25: loss -377.83173 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -391.66904 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 26: loss -404.37221 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -418.70575 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 27: loss -431.79184 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -446.62487 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 28: loss -460.09185 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -475.42763 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 29: loss -489.27357 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -505.11511 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 30: loss -519.33794 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -535.68822 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 31: loss -550.28582 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -567.14779 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 32: loss -582.11832 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -599.49492 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 33: loss -614.83586 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -632.73344 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -648.53297 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -668.74162 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -687.34601 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -710.75577 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -732.11629 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -758.39584 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -782.78282 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -811.82037 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -839.12619 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -870.52090 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -899.12650 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -931.63025 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -960.99208 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -994.41684 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -1024.37270 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -1058.69680 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -1089.26740 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -1124.54574 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -1155.75869 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -1192.01177 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -1223.88069 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -1261.14912 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -1293.70334 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -1332.02037 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -1365.28207 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -1404.67397 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -1438.65801 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -1479.14513 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -1513.86033 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -1555.46164 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -1590.91804 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -4.03073 acc 0.66667 roc_auc 0.46460 prc_auc 0.64758[0m
[93maverage test of epoch 0: loss -6.28854 acc 0.65789 roc_auc 0.94154 prc_auc 0.96800[0m
[92maverage training of epoch 1: loss -9.03685 acc 0.66667 roc_auc 0.46960 prc_auc 0.65097[0m
[93maverage test of epoch 1: loss -11.68400 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 2: loss -14.34293 acc 0.66667 roc_auc 0.46840 prc_auc 0.64848[0m
[93maverage test of epoch 2: loss -16.92613 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 3: loss -19.83588 acc 0.66667 roc_auc 0.45630 prc_auc 0.64002[0m
[93maverage test of epoch 3: loss -22.65951 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 4: loss -25.95229 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 4: loss -29.10478 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 5: loss -32.82905 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 5: loss -36.34630 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 6: loss -40.53197 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 6: loss -44.43593 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 7: loss -49.10661 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 7: loss -53.41376 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 8: loss -58.59000 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 8: loss -63.31371 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 9: loss -69.01393 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 9: loss -74.16526 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 10: loss -80.40592 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 10: loss -85.99379 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 11: loss -92.78939 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 11: loss -98.82059 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 12: loss -106.18365 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 12: loss -112.66291 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 13: loss -120.60377 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 13: loss -127.53359 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 14: loss -136.06046 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 14: loss -143.44129 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 15: loss -152.56034 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 15: loss -160.39057 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 16: loss -170.10591 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 16: loss -178.38209 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 17: loss -188.69563 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 17: loss -197.40906 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 18: loss -208.29372 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 18: loss -217.39744 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -228.83171 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 19: loss -238.29769 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -250.24299 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 20: loss -260.03474 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -272.49119 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 21: loss -282.61031 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -295.58354 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 22: loss -306.03177 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -319.52661 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 23: loss -330.30446 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -344.32587 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 24: loss -355.43405 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -369.98626 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 25: loss -381.42424 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -396.51107 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 26: loss -408.27857 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -423.90411 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 27: loss -436.00044 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -452.16855 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 28: loss -464.59262 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -481.30666 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 29: loss -494.05727 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -511.32071 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 30: loss -524.39676 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -542.21309 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 31: loss -555.61296 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -573.98573 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 32: loss -587.70809 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -606.64022 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 33: loss -620.68312 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -640.27140 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -655.56623 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -679.82534 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -699.23022 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -724.99764 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -745.31915 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -772.32849 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -794.35089 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -824.15735 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -848.20747 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -881.09060 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -907.88341 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -942.26208 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -969.89656 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -1005.33063 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -1033.60389 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -1070.02033 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -1098.86496 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -1136.28378 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -1165.72568 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -1204.17473 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -1234.21667 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -1273.71888 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -1304.38966 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -1344.98242 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -1376.30421 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -1418.01525 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -1450.00622 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -1492.86019 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -1525.53155 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -1569.54778 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -1602.91045 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -1.07291 acc 0.49333 roc_auc 0.40820 prc_auc 0.63430[0m
[93maverage test of epoch 0: loss -2.44685 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 1: loss -4.20332 acc 0.66667 roc_auc 0.40460 prc_auc 0.61907[0m
[93maverage test of epoch 1: loss -6.23249 acc 0.65789 roc_auc 0.94923 prc_auc 0.97661[0m
[92maverage training of epoch 2: loss -8.54903 acc 0.66667 roc_auc 0.38960 prc_auc 0.59515[0m
[93maverage test of epoch 2: loss -10.97339 acc 0.65789 roc_auc 0.94923 prc_auc 0.97661[0m
[92maverage training of epoch 3: loss -13.65285 acc 0.66667 roc_auc 0.40200 prc_auc 0.60761[0m
[93maverage test of epoch 3: loss -16.50995 acc 0.65789 roc_auc 0.93231 prc_auc 0.95823[0m
[92maverage training of epoch 4: loss -19.70861 acc 0.66667 roc_auc 0.41200 prc_auc 0.61511[0m
[93maverage test of epoch 4: loss -23.08073 acc 0.65789 roc_auc 0.80308 prc_auc 0.84551[0m
[92maverage training of epoch 5: loss -26.81733 acc 0.66667 roc_auc 0.41830 prc_auc 0.61808[0m
[93maverage test of epoch 5: loss -30.67743 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 6: loss -34.89837 acc 0.66667 roc_auc 0.41810 prc_auc 0.61256[0m
[93maverage test of epoch 6: loss -39.19705 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 7: loss -43.89472 acc 0.66667 roc_auc 0.43410 prc_auc 0.62940[0m
[93maverage test of epoch 7: loss -48.61007 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 8: loss -53.74079 acc 0.66667 roc_auc 0.47500 prc_auc 0.65578[0m
[93maverage test of epoch 8: loss -58.83875 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 9: loss -64.41258 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 9: loss -69.90396 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 10: loss -75.93844 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 10: loss -81.83400 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 11: loss -88.34273 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 11: loss -94.64988 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 12: loss -101.64407 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 12: loss -108.36807 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 13: loss -115.85726 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 13: loss -123.00171 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 14: loss -130.99402 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 14: loss -138.56122 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 15: loss -147.06351 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 15: loss -155.05448 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 16: loss -164.07254 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 16: loss -172.48718 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 17: loss -182.02570 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 17: loss -190.86284 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 18: loss -200.92732 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 18: loss -210.24577 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -222.50406 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 19: loss -234.29195 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -247.77500 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 20: loss -260.31815 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -274.53083 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 21: loss -287.61937 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -302.43219 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 22: loss -315.93756 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -331.33981 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 23: loss -345.28977 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -361.30505 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 24: loss -375.69326 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -392.30772 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 25: loss -407.12429 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -424.35583 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 26: loss -439.61232 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -457.47469 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 27: loss -473.17811 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -491.68203 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 28: loss -507.83667 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -526.99126 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 29: loss -543.59966 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -563.41305 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 30: loss -580.47712 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -600.95638 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 31: loss -618.47690 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -639.62894 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 32: loss -657.60623 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -680.34653 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 33: loss -700.63440 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -726.30508 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -749.48339 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -777.74207 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -802.35190 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -831.72267 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -857.06249 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -887.35678 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -913.28385 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -944.45908 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -970.97359 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -1003.05160 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -1030.14534 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -1063.12778 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -1090.79993 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -1124.71679 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -1152.98851 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -1187.86433 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -1216.74983 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -1252.60283 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -1282.11108 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -1318.95862 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -1349.09688 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -1386.95300 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -1417.72580 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -1456.60240 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -1488.01292 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -1527.92225 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -1559.97151 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -1600.92361 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -1633.61344 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -1675.61897 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -1708.94868 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -1.27842 acc 0.58278 roc_auc 0.52863 prc_auc 0.66447[0m
[93maverage test of epoch 0: loss -3.59974 acc 0.32432 roc_auc 0.83333 prc_auc 0.91313[0m
[92maverage training of epoch 1: loss -6.28307 acc 0.33775 roc_auc 0.53078 prc_auc 0.67571[0m
[93maverage test of epoch 1: loss -9.04315 acc 0.32432 roc_auc 0.52667 prc_auc 0.77722[0m
[92maverage training of epoch 2: loss -12.02454 acc 0.33775 roc_auc 0.47490 prc_auc 0.63790[0m
[93maverage test of epoch 2: loss -15.13827 acc 0.32432 roc_auc 0.20167 prc_auc 0.56149[0m
[92maverage training of epoch 3: loss -18.55266 acc 0.33775 roc_auc 0.42255 prc_auc 0.60111[0m
[93maverage test of epoch 3: loss -22.13460 acc 0.32432 roc_auc 0.23667 prc_auc 0.57039[0m
[92maverage training of epoch 4: loss -26.06587 acc 0.33775 roc_auc 0.36882 prc_auc 0.58906[0m
[93maverage test of epoch 4: loss -30.17061 acc 0.32432 roc_auc 0.29333 prc_auc 0.61322[0m
[92maverage training of epoch 5: loss -34.57645 acc 0.33775 roc_auc 0.37314 prc_auc 0.58551[0m
[93maverage test of epoch 5: loss -39.16244 acc 0.32432 roc_auc 0.35333 prc_auc 0.61632[0m
[92maverage training of epoch 6: loss -44.03848 acc 0.33775 roc_auc 0.36196 prc_auc 0.57815[0m
[93maverage test of epoch 6: loss -49.12334 acc 0.32432 roc_auc 0.60000 prc_auc 0.74945[0m
[92maverage training of epoch 7: loss -54.47463 acc 0.33775 roc_auc 0.36549 prc_auc 0.57500[0m
[93maverage test of epoch 7: loss -60.06721 acc 0.32432 roc_auc 0.22000 prc_auc 0.58413[0m
[92maverage training of epoch 8: loss -65.85135 acc 0.32450 roc_auc 0.37255 prc_auc 0.57320[0m
[93maverage test of epoch 8: loss -71.89750 acc 0.32432 roc_auc 0.64167 prc_auc 0.76763[0m
[92maverage training of epoch 9: loss -78.07387 acc 0.59603 roc_auc 0.37314 prc_auc 0.56748[0m
[93maverage test of epoch 9: loss -84.57086 acc 0.67568 roc_auc 0.40000 prc_auc 0.64345[0m
[92maverage training of epoch 10: loss -91.14341 acc 0.66225 roc_auc 0.37627 prc_auc 0.57062[0m
[93maverage test of epoch 10: loss -98.10252 acc 0.67568 roc_auc 0.62000 prc_auc 0.74835[0m
[92maverage training of epoch 11: loss -105.07203 acc 0.66225 roc_auc 0.37784 prc_auc 0.57051[0m
[93maverage test of epoch 11: loss -112.50182 acc 0.67568 roc_auc 0.50000 prc_auc 0.68685[0m
[92maverage training of epoch 12: loss -119.86748 acc 0.66225 roc_auc 0.38098 prc_auc 0.57288[0m
[93maverage test of epoch 12: loss -127.77498 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 13: loss -135.53510 acc 0.66225 roc_auc 0.38206 prc_auc 0.57407[0m
[93maverage test of epoch 13: loss -143.92654 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 14: loss -152.07898 acc 0.66225 roc_auc 0.38608 prc_auc 0.58383[0m
[93maverage test of epoch 14: loss -160.96003 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 15: loss -169.50225 acc 0.66225 roc_auc 0.42559 prc_auc 0.62079[0m
[93maverage test of epoch 15: loss -178.87824 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 16: loss -187.80757 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 16: loss -197.68363 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 17: loss -206.99720 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 17: loss -217.37821 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 18: loss -227.07307 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 18: loss -237.96389 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 19: loss -248.03698 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 19: loss -259.44224 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 20: loss -269.89047 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 20: loss -281.81481 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 21: loss -292.63486 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 21: loss -305.08272 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 22: loss -316.27154 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 22: loss -329.24750 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 23: loss -340.80162 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 23: loss -354.30997 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 24: loss -366.22617 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 24: loss -380.27131 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 25: loss -392.54634 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 25: loss -407.13263 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 26: loss -419.76280 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 26: loss -434.89456 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 27: loss -447.87645 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 27: loss -463.55770 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 28: loss -476.88812 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 28: loss -493.12311 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 29: loss -506.79810 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 29: loss -523.59115 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 30: loss -537.60760 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 30: loss -554.96319 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 31: loss -569.31682 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 31: loss -587.23759 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 32: loss -601.92554 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 32: loss -620.41751 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 33: loss -635.43637 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 33: loss -654.50264 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 34: loss -669.84761 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 34: loss -689.49146 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 35: loss -705.15962 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 35: loss -725.38656 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 36: loss -741.37416 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 36: loss -762.18793 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 37: loss -778.93268 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 37: loss -801.79671 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 38: loss -820.75923 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 38: loss -845.33607 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 39: loss -864.88398 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 39: loss -890.33110 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -910.32418 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 40: loss -936.51141 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -956.82784 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 41: loss -983.71403 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -1004.38012 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 42: loss -1031.97729 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -1052.97438 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 43: loss -1081.28270 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -1102.62499 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 44: loss -1131.66685 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -1153.36105 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 45: loss -1183.15213 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -1205.20349 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 46: loss -1235.75695 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -1258.16711 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 47: loss -1289.49367 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -1312.26212 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 48: loss -1344.37154 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -1367.49809 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 49: loss -1400.39945 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -0.24169 acc 0.43046 roc_auc 0.45980 prc_auc 0.64751[0m
[93maverage test of epoch 0: loss -1.26983 acc 0.32432 roc_auc 0.21000 prc_auc 0.61072[0m
[92maverage training of epoch 1: loss -2.94507 acc 0.63576 roc_auc 0.39784 prc_auc 0.59685[0m
[93maverage test of epoch 1: loss -4.72104 acc 0.67568 roc_auc 0.33667 prc_auc 0.70375[0mUsing backend: pytorch
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))

[92maverage training of epoch 2: loss -7.00229 acc 0.66225 roc_auc 0.41314 prc_auc 0.60919[0m
[93maverage test of epoch 2: loss -9.90383 acc 0.67568 roc_auc 0.92500 prc_auc 0.96923[0m
[92maverage training of epoch 3: loss -12.92905 acc 0.66225 roc_auc 0.40098 prc_auc 0.59731[0m
[93maverage test of epoch 3: loss -16.33842 acc 0.67568 roc_auc 0.92667 prc_auc 0.95690[0m
[92maverage training of epoch 4: loss -19.85008 acc 0.66225 roc_auc 0.39814 prc_auc 0.59457[0m
[93maverage test of epoch 4: loss -23.85204 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 5: loss -27.88787 acc 0.66225 roc_auc 0.39627 prc_auc 0.59240[0m
[93maverage test of epoch 5: loss -32.50466 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 6: loss -37.04992 acc 0.66225 roc_auc 0.40569 prc_auc 0.59629[0m
[93maverage test of epoch 6: loss -42.26192 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 7: loss -47.26049 acc 0.66225 roc_auc 0.38598 prc_auc 0.60082[0m
[93maverage test of epoch 7: loss -53.02286 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 8: loss -58.42986 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 8: loss -64.71144 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 9: loss -70.51460 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 9: loss -77.32959 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 10: loss -83.53537 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 10: loss -90.89165 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 11: loss -97.47595 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 11: loss -105.34121 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 12: loss -112.27236 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 12: loss -120.62831 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 13: loss -127.90480 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 13: loss -136.76049 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 14: loss -144.38356 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 14: loss -153.74699 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 15: loss -161.71656 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 15: loss -171.59468 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 16: loss -179.90987 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 16: loss -190.30901 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 17: loss -198.96844 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 17: loss -209.89445 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 18: loss -218.89637 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 18: loss -230.35481 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 19: loss -239.69727 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 19: loss -251.69356 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 20: loss -261.37420 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 20: loss -273.91351 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 21: loss -283.92991 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 21: loss -297.01718 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 22: loss -307.36683 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 22: loss -321.00707 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 23: loss -331.68731 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 23: loss -345.88535 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 24: loss -356.89334 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 24: loss -371.65387 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 25: loss -382.98672 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 25: loss -398.31438 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 26: loss -409.96911 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 26: loss -425.86844 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 27: loss -437.84213 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 27: loss -454.31775 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 28: loss -466.60712 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 28: loss -483.66344 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 29: loss -496.26532 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 29: loss -513.90675 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 30: loss -526.81790 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 30: loss -545.04903 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 31: loss -558.26611 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 31: loss -577.09109 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 32: loss -590.61073 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 32: loss -610.03359 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 33: loss -623.85262 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 33: loss -643.87797 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 34: loss -657.99249 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 34: loss -678.62427 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 35: loss -693.03113 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 35: loss -714.27353 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 36: loss -728.96916 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 36: loss -750.82630 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 37: loss -765.80717 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 37: loss -788.28282 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 38: loss -803.54529 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 38: loss -826.64476 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 39: loss -842.18503 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 39: loss -865.91096 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -881.72519 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 40: loss -906.08157 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -922.16683 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 41: loss -947.15945 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -963.51279 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 42: loss -989.14428 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -1005.75892 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 43: loss -1032.03151 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -1048.90559 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 44: loss -1075.82567 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -1092.95637 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 45: loss -1120.52846 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -1137.91104 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 46: loss -1166.13743 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -1183.76851 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 47: loss -1212.65445 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -1230.53072 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 48: loss -1260.07981 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -1278.19758 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 49: loss -1308.41395 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 1)
('lr', 0.001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.66501 ROC_AUC (avg): 0.5 PRC_AUC (avg): 0.66501 

Average forward propagation time taken(ms): 2.7920961359020717
Average backward propagation time taken(ms): 0.9355048964216187

