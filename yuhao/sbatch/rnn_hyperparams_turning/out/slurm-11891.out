# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.0003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-20-42-00/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-20-42-00/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 8,
 'epochs': 50,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 8,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.0003,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 2,
 'num_workers': 8,
 'number_of_mlp_layer': 0,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-17-20-42-00',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 50, 'learning_rate': 0.0003, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.42151 acc 0.66667 roc_auc 0.43840 prc_auc 0.63045[0m
[93maverage test of epoch 0: loss -0.87386 acc 0.65789 roc_auc 0.61231 prc_auc 0.69349[0m
[92maverage training of epoch 1: loss -1.37927 acc 0.66667 roc_auc 0.43300 prc_auc 0.62682[0m
[93maverage test of epoch 1: loss -1.93580 acc 0.65789 roc_auc 0.69231 prc_auc 0.81562[0m
[92maverage training of epoch 2: loss -2.32973 acc 0.66667 roc_auc 0.47360 prc_auc 0.66214[0m
[93maverage test of epoch 2: loss -2.65246 acc 0.65789 roc_auc 0.47692 prc_auc 0.73185[0m
[92maverage training of epoch 3: loss -2.90989 acc 0.66667 roc_auc 0.39940 prc_auc 0.62550[0m
[93maverage test of epoch 3: loss -3.13849 acc 0.65789 roc_auc 0.35385 prc_auc 0.56985[0m
[92maverage training of epoch 4: loss -3.35368 acc 0.66667 roc_auc 0.38340 prc_auc 0.60801[0m
[93maverage test of epoch 4: loss -3.53372 acc 0.65789 roc_auc 0.57538 prc_auc 0.70979[0m
[92maverage training of epoch 5: loss -3.73254 acc 0.66667 roc_auc 0.41360 prc_auc 0.62100[0m
[93maverage test of epoch 5: loss -3.90492 acc 0.65789 roc_auc 0.71385 prc_auc 0.82632[0m
[92maverage training of epoch 6: loss -4.11539 acc 0.66667 roc_auc 0.40660 prc_auc 0.61580[0m
[93maverage test of epoch 6: loss -4.30770 acc 0.65789 roc_auc 0.39385 prc_auc 0.66078[0m
[92maverage training of epoch 7: loss -4.50815 acc 0.66667 roc_auc 0.34430 prc_auc 0.58286[0m
[93maverage test of epoch 7: loss -4.69589 acc 0.65789 roc_auc 0.52923 prc_auc 0.67111[0m
[92maverage training of epoch 8: loss -4.89847 acc 0.66667 roc_auc 0.45300 prc_auc 0.61990[0m
[93maverage test of epoch 8: loss -5.06500 acc 0.65789 roc_auc 0.67692 prc_auc 0.76906[0m
[92maverage training of epoch 9: loss -5.26269 acc 0.66667 roc_auc 0.41320 prc_auc 0.64164[0m
[93maverage test of epoch 9: loss -5.41935 acc 0.65789 roc_auc 0.48923 prc_auc 0.65929[0m
[92maverage training of epoch 10: loss -5.61620 acc 0.66667 roc_auc 0.38100 prc_auc 0.58843[0m
[93maverage test of epoch 10: loss -5.76172 acc 0.65789 roc_auc 0.39692 prc_auc 0.62716[0m
[92maverage training of epoch 11: loss -5.96730 acc 0.66667 roc_auc 0.40140 prc_auc 0.58982[0m
[93maverage test of epoch 11: loss -6.11654 acc 0.65789 roc_auc 0.55692 prc_auc 0.73683[0m
[92maverage training of epoch 12: loss -6.30929 acc 0.66667 roc_auc 0.38840 prc_auc 0.60414[0m
[93maverage test of epoch 12: loss -6.44904 acc 0.65789 roc_auc 0.40000 prc_auc 0.61544[0m
[92maverage training of epoch 13: loss -6.64445 acc 0.66667 roc_auc 0.43020 prc_auc 0.62432[0m
[93maverage test of epoch 13: loss -6.78507 acc 0.65789 roc_auc 0.56000 prc_auc 0.67846[0m
[92maverage training of epoch 14: loss -6.97473 acc 0.66667 roc_auc 0.38580 prc_auc 0.58723[0m
[93maverage test of epoch 14: loss -7.11313 acc 0.65789 roc_auc 0.64308 prc_auc 0.83547[0m
[92maverage training of epoch 15: loss -7.29759 acc 0.66667 roc_auc 0.41140 prc_auc 0.62088[0m
[93maverage test of epoch 15: loss -7.43100 acc 0.65789 roc_auc 0.58462 prc_auc 0.75748[0m
[92maverage training of epoch 16: loss -7.62151 acc 0.66667 roc_auc 0.41520 prc_auc 0.59326[0m
[93maverage test of epoch 16: loss -7.74582 acc 0.65789 roc_auc 0.58154 prc_auc 0.76296[0m
[92maverage training of epoch 17: loss -7.93436 acc 0.66667 roc_auc 0.36580 prc_auc 0.57170[0m
[93maverage test of epoch 17: loss -8.06175 acc 0.65789 roc_auc 0.54769 prc_auc 0.75044[0m
[92maverage training of epoch 18: loss -8.25372 acc 0.66667 roc_auc 0.38260 prc_auc 0.58442[0m
[93maverage test of epoch 18: loss -8.37593 acc 0.65789 roc_auc 0.47231 prc_auc 0.63842[0m
[92maverage training of epoch 19: loss -8.56648 acc 0.66667 roc_auc 0.38900 prc_auc 0.59391[0m
[93maverage test of epoch 19: loss -8.68477 acc 0.65789 roc_auc 0.36923 prc_auc 0.63284[0m
[92maverage training of epoch 20: loss -8.87532 acc 0.66667 roc_auc 0.42080 prc_auc 0.60026[0m
[93maverage test of epoch 20: loss -8.98849 acc 0.65789 roc_auc 0.49846 prc_auc 0.67567[0m
[92maverage training of epoch 21: loss -9.18451 acc 0.66667 roc_auc 0.38980 prc_auc 0.59457[0m
[93maverage test of epoch 21: loss -9.30185 acc 0.65789 roc_auc 0.66769 prc_auc 0.83704[0m
[92maverage training of epoch 22: loss -9.49011 acc 0.66667 roc_auc 0.38680 prc_auc 0.57828[0m
[93maverage test of epoch 22: loss -9.60876 acc 0.65789 roc_auc 0.67538 prc_auc 0.79813[0m
[92maverage training of epoch 23: loss -9.79873 acc 0.66667 roc_auc 0.38750 prc_auc 0.59461[0m
[93maverage test of epoch 23: loss -9.91312 acc 0.65789 roc_auc 0.52308 prc_auc 0.74468[0m
[92maverage training of epoch 24: loss -10.10247 acc 0.66667 roc_auc 0.35680 prc_auc 0.57120[0m
[93maverage test of epoch 24: loss -10.21270 acc 0.65789 roc_auc 0.54923 prc_auc 0.70497[0m
[92maverage training of epoch 25: loss -10.40687 acc 0.66667 roc_auc 0.35560 prc_auc 0.56772[0m
[93maverage test of epoch 25: loss -10.51885 acc 0.65789 roc_auc 0.58923 prc_auc 0.79638[0m
[92maverage training of epoch 26: loss -10.71107 acc 0.66667 roc_auc 0.38630 prc_auc 0.60155[0m
[93maverage test of epoch 26: loss -10.81946 acc 0.65789 roc_auc 0.52462 prc_auc 0.75798[0m
[92maverage training of epoch 27: loss -11.01251 acc 0.66667 roc_auc 0.36180 prc_auc 0.57471[0m
[93maverage test of epoch 27: loss -11.12274 acc 0.65789 roc_auc 0.44615 prc_auc 0.68933[0m
[92maverage training of epoch 28: loss -11.31680 acc 0.66667 roc_auc 0.36800 prc_auc 0.57134[0m
[93maverage test of epoch 28: loss -11.42466 acc 0.65789 roc_auc 0.67231 prc_auc 0.77166[0m
[92maverage training of epoch 29: loss -11.61832 acc 0.66667 roc_auc 0.37180 prc_auc 0.57158[0m
[93maverage test of epoch 29: loss -11.72497 acc 0.65789 roc_auc 0.46000 prc_auc 0.67037[0m
[92maverage training of epoch 30: loss -11.91972 acc 0.66667 roc_auc 0.36540 prc_auc 0.57673[0m
[93maverage test of epoch 30: loss -12.02607 acc 0.65789 roc_auc 0.33231 prc_auc 0.61041[0m
[92maverage training of epoch 31: loss -12.22075 acc 0.66667 roc_auc 0.38160 prc_auc 0.59045[0m
[93maverage test of epoch 31: loss -12.32684 acc 0.65789 roc_auc 0.50000 prc_auc 0.71830[0m
[92maverage training of epoch 32: loss -12.52156 acc 0.66667 roc_auc 0.37430 prc_auc 0.58326[0m
[93maverage test of epoch 32: loss -12.62417 acc 0.65789 roc_auc 0.49846 prc_auc 0.64444[0m
[92maverage training of epoch 33: loss -12.82156 acc 0.66667 roc_auc 0.36030 prc_auc 0.58024[0m
[93maverage test of epoch 33: loss -12.92470 acc 0.65789 roc_auc 0.52154 prc_auc 0.66997[0m
[92maverage training of epoch 34: loss -13.12204 acc 0.66667 roc_auc 0.35920 prc_auc 0.57473[0m
[93maverage test of epoch 34: loss -13.22205 acc 0.65789 roc_auc 0.50308 prc_auc 0.74287[0m
[92maverage training of epoch 35: loss -13.42192 acc 0.66667 roc_auc 0.36640 prc_auc 0.57195[0m
[93maverage test of epoch 35: loss -13.52251 acc 0.65789 roc_auc 0.50154 prc_auc 0.66046[0m
[92maverage training of epoch 36: loss -13.72158 acc 0.66667 roc_auc 0.37210 prc_auc 0.58197[0m
[93maverage test of epoch 36: loss -13.82180 acc 0.65789 roc_auc 0.39538 prc_auc 0.61089[0m
[92maverage training of epoch 37: loss -14.02088 acc 0.66667 roc_auc 0.36450 prc_auc 0.57240[0m
[93maverage test of epoch 37: loss -14.11977 acc 0.65789 roc_auc 0.50923 prc_auc 0.71300[0m
[92maverage training of epoch 38: loss -14.32050 acc 0.66667 roc_auc 0.35600 prc_auc 0.56525[0m
[93maverage test of epoch 38: loss -14.41882 acc 0.65789 roc_auc 0.73692 prc_auc 0.83854[0m
[92maverage training of epoch 39: loss -14.61932 acc 0.66667 roc_auc 0.36290 prc_auc 0.57068[0m
[93maverage test of epoch 39: loss -14.71580 acc 0.65789 roc_auc 0.44154 prc_auc 0.63659[0m
[92maverage training of epoch 40: loss -14.91857 acc 0.66667 roc_auc 0.35070 prc_auc 0.55912[0m
[93maverage test of epoch 40: loss -15.01489 acc 0.65789 roc_auc 0.62615 prc_auc 0.76990[0m
[92maverage training of epoch 41: loss -15.21806 acc 0.66667 roc_auc 0.35580 prc_auc 0.56239[0m
[93maverage test of epoch 41: loss -15.31339 acc 0.65789 roc_auc 0.49231 prc_auc 0.66153[0m
[92maverage training of epoch 42: loss -15.51721 acc 0.66667 roc_auc 0.35710 prc_auc 0.56290[0m
[93maverage test of epoch 42: loss -15.61053 acc 0.65789 roc_auc 0.41846 prc_auc 0.61895[0m
[92maverage training of epoch 43: loss -15.81567 acc 0.66667 roc_auc 0.36310 prc_auc 0.57211[0m
[93maverage test of epoch 43: loss -15.90839 acc 0.65789 roc_auc 0.47077 prc_auc 0.65173[0m
[92maverage training of epoch 44: loss -16.11474 acc 0.66667 roc_auc 0.35900 prc_auc 0.56955[0m
[93maverage test of epoch 44: loss -16.20683 acc 0.65789 roc_auc 0.53538 prc_auc 0.67339[0m
[92maverage training of epoch 45: loss -16.41369 acc 0.66667 roc_auc 0.35790 prc_auc 0.56481[0m
[93maverage test of epoch 45: loss -16.50521 acc 0.65789 roc_auc 0.67385 prc_auc 0.77249[0m
[92maverage training of epoch 46: loss -16.71265 acc 0.66667 roc_auc 0.36180 prc_auc 0.56736[0m
[93maverage test of epoch 46: loss -16.80256 acc 0.65789 roc_auc 0.49231 prc_auc 0.63931[0m
[92maverage training of epoch 47: loss -17.01083 acc 0.66667 roc_auc 0.36110 prc_auc 0.56644[0m
[93maverage test of epoch 47: loss -17.10041 acc 0.65789 roc_auc 0.52615 prc_auc 0.68842[0m
[92maverage training of epoch 48: loss -17.31001 acc 0.66667 roc_auc 0.35570 prc_auc 0.56131[0m
[93maverage test of epoch 48: loss -17.39857 acc 0.65789 roc_auc 0.58000 prc_auc 0.71318[0m
[92maverage training of epoch 49: loss -17.60850 acc 0.66667 roc_auc 0.35360 prc_auc 0.56094[0m
[93maverage test of epoch 49: loss -17.69574 acc 0.65789 roc_auc 0.48769 prc_auc 0.64333[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.67214 acc 0.58000 roc_auc 0.51500 prc_auc 0.69089[0m
[93maverage test of epoch 0: loss -1.18727 acc 0.65789 roc_auc 0.53231 prc_auc 0.72272[0m
[92maverage training of epoch 1: loss -1.76906 acc 0.66667 roc_auc 0.46540 prc_auc 0.66589[0m
[93maverage test of epoch 1: loss -2.42086 acc 0.65789 roc_auc 0.46154 prc_auc 0.64049[0m
[92maverage training of epoch 2: loss -2.98130 acc 0.66667 roc_auc 0.44870 prc_auc 0.64048[0m
[93maverage test of epoch 2: loss -3.42379 acc 0.65789 roc_auc 0.32615 prc_auc 0.59091[0m
[92maverage training of epoch 3: loss -3.78890 acc 0.66667 roc_auc 0.46320 prc_auc 0.63701[0m
[93maverage test of epoch 3: loss -4.06555 acc 0.65789 roc_auc 0.53231 prc_auc 0.68378[0m
[92maverage training of epoch 4: loss -4.38330 acc 0.66667 roc_auc 0.46560 prc_auc 0.65318[0m
[93maverage test of epoch 4: loss -4.66059 acc 0.65789 roc_auc 0.50769 prc_auc 0.72269[0m
[92maverage training of epoch 5: loss -4.98734 acc 0.66667 roc_auc 0.46490 prc_auc 0.64034[0m
[93maverage test of epoch 5: loss -5.21998 acc 0.65789 roc_auc 0.49538 prc_auc 0.70010[0m
[92maverage training of epoch 6: loss -5.47231 acc 0.66667 roc_auc 0.44220 prc_auc 0.63534[0m
[93maverage test of epoch 6: loss -5.63836 acc 0.65789 roc_auc 0.45385 prc_auc 0.64857[0m
[92maverage training of epoch 7: loss -5.86632 acc 0.66667 roc_auc 0.44420 prc_auc 0.63127[0m
[93maverage test of epoch 7: loss -6.02471 acc 0.65789 roc_auc 0.64000 prc_auc 0.74716[0m
[92maverage training of epoch 8: loss -6.23542 acc 0.66667 roc_auc 0.44930 prc_auc 0.62486[0m
[93maverage test of epoch 8: loss -6.37209 acc 0.65789 roc_auc 0.42154 prc_auc 0.60210[0m
[92maverage training of epoch 9: loss -6.58766 acc 0.66667 roc_auc 0.46260 prc_auc 0.65346[0m
[93maverage test of epoch 9: loss -6.71807 acc 0.65789 roc_auc 0.44615 prc_auc 0.64584[0m
[92maverage training of epoch 10: loss -6.92395 acc 0.66667 roc_auc 0.43800 prc_auc 0.63225[0m
[93maverage test of epoch 10: loss -7.04768 acc 0.65789 roc_auc 0.39077 prc_auc 0.63689[0m
[92maverage training of epoch 11: loss -7.25532 acc 0.66667 roc_auc 0.45980 prc_auc 0.63221[0m
[93maverage test of epoch 11: loss -7.37782 acc 0.65789 roc_auc 0.49077 prc_auc 0.71858[0m
[92maverage training of epoch 12: loss -7.57924 acc 0.66667 roc_auc 0.45250 prc_auc 0.62468[0m
[93maverage test of epoch 12: loss -7.69880 acc 0.65789 roc_auc 0.53846 prc_auc 0.72005[0m
[92maverage training of epoch 13: loss -7.89741 acc 0.66667 roc_auc 0.44090 prc_auc 0.63196[0m
[93maverage test of epoch 13: loss -8.01306 acc 0.65789 roc_auc 0.41231 prc_auc 0.65080[0m
[92maverage training of epoch 14: loss -8.21496 acc 0.66667 roc_auc 0.46270 prc_auc 0.64827[0m
[93maverage test of epoch 14: loss -8.32602 acc 0.65789 roc_auc 0.48154 prc_auc 0.62135[0m
[92maverage training of epoch 15: loss -8.52571 acc 0.66667 roc_auc 0.41490 prc_auc 0.61963[0m
[93maverage test of epoch 15: loss -8.63826 acc 0.65789 roc_auc 0.47231 prc_auc 0.73532[0m
[92maverage training of epoch 16: loss -8.83764 acc 0.66667 roc_auc 0.41000 prc_auc 0.59170[0m
[93maverage test of epoch 16: loss -8.94611 acc 0.65789 roc_auc 0.68462 prc_auc 0.78501[0m
[92maverage training of epoch 17: loss -9.14607 acc 0.66667 roc_auc 0.43600 prc_auc 0.60969[0m
[93maverage test of epoch 17: loss -9.25315 acc 0.65789 roc_auc 0.55538 prc_auc 0.69473[0m
[92maverage training of epoch 18: loss -9.45430 acc 0.66667 roc_auc 0.43370 prc_auc 0.60654[0m
[93maverage test of epoch 18: loss -9.55711 acc 0.65789 roc_auc 0.54615 prc_auc 0.70570[0m
[92maverage training of epoch 19: loss -9.75928 acc 0.66667 roc_auc 0.43840 prc_auc 0.62517[0m
[93maverage test of epoch 19: loss -9.86657 acc 0.65789 roc_auc 0.47077 prc_auc 0.66323[0m
[92maverage training of epoch 20: loss -10.06446 acc 0.66667 roc_auc 0.41760 prc_auc 0.59861[0m
[93maverage test of epoch 20: loss -10.16510 acc 0.65789 roc_auc 0.44769 prc_auc 0.60554[0m
[92maverage training of epoch 21: loss -10.36780 acc 0.66667 roc_auc 0.44260 prc_auc 0.61248[0m
[93maverage test of epoch 21: loss -10.47099 acc 0.65789 roc_auc 0.56154 prc_auc 0.71842[0m
[92maverage training of epoch 22: loss -10.67155 acc 0.66667 roc_auc 0.42850 prc_auc 0.60753[0m
[93maverage test of epoch 22: loss -10.77313 acc 0.65789 roc_auc 0.46462 prc_auc 0.64241[0m
[92maverage training of epoch 23: loss -10.97342 acc 0.66667 roc_auc 0.41740 prc_auc 0.60192[0m
[93maverage test of epoch 23: loss -11.07397 acc 0.65789 roc_auc 0.42154 prc_auc 0.63697[0m
[92maverage training of epoch 24: loss -11.27734 acc 0.66667 roc_auc 0.42720 prc_auc 0.60710[0m
[93maverage test of epoch 24: loss -11.37678 acc 0.65789 roc_auc 0.61385 prc_auc 0.72972[0m
[92maverage training of epoch 25: loss -11.57948 acc 0.66667 roc_auc 0.42170 prc_auc 0.59649[0m
[93maverage test of epoch 25: loss -11.67490 acc 0.65789 roc_auc 0.55077 prc_auc 0.73101[0m
[92maverage training of epoch 26: loss -11.88070 acc 0.66667 roc_auc 0.44110 prc_auc 0.63684[0m
[93maverage test of epoch 26: loss -11.97459 acc 0.65789 roc_auc 0.65231 prc_auc 0.76299[0m
[92maverage training of epoch 27: loss -12.18221 acc 0.66667 roc_auc 0.41530 prc_auc 0.60920[0m
[93maverage test of epoch 27: loss -12.27548 acc 0.65789 roc_auc 0.29231 prc_auc 0.59723[0m
[92maverage training of epoch 28: loss -12.48268 acc 0.66667 roc_auc 0.43330 prc_auc 0.62108[0m
[93maverage test of epoch 28: loss -12.57666 acc 0.65789 roc_auc 0.66154 prc_auc 0.74479[0m
[92maverage training of epoch 29: loss -12.78367 acc 0.66667 roc_auc 0.42560 prc_auc 0.60910[0m
[93maverage test of epoch 29: loss -12.87557 acc 0.65789 roc_auc 0.43692 prc_auc 0.62821[0m
[92maverage training of epoch 30: loss -13.08359 acc 0.66667 roc_auc 0.42810 prc_auc 0.61019[0m
[93maverage test of epoch 30: loss -13.17540 acc 0.65789 roc_auc 0.61231 prc_auc 0.72138[0m
[92maverage training of epoch 31: loss -13.38302 acc 0.66667 roc_auc 0.41660 prc_auc 0.60025[0m
[93maverage test of epoch 31: loss -13.47428 acc 0.65789 roc_auc 0.37692 prc_auc 0.58734[0m
[92maverage training of epoch 32: loss -13.68325 acc 0.66667 roc_auc 0.42490 prc_auc 0.60963[0m
[93maverage test of epoch 32: loss -13.77303 acc 0.65789 roc_auc 0.39538 prc_auc 0.59632[0m
[92maverage training of epoch 33: loss -13.98185 acc 0.66667 roc_auc 0.42620 prc_auc 0.60628[0m
[93maverage test of epoch 33: loss -14.07188 acc 0.65789 roc_auc 0.47846 prc_auc 0.62531[0m
[92maverage training of epoch 34: loss -14.28127 acc 0.66667 roc_auc 0.42190 prc_auc 0.60260[0m
[93maverage test of epoch 34: loss -14.37102 acc 0.65789 roc_auc 0.45077 prc_auc 0.62741[0m
[92maverage training of epoch 35: loss -14.58110 acc 0.66667 roc_auc 0.41390 prc_auc 0.59734[0m
[93maverage test of epoch 35: loss -14.66877 acc 0.65789 roc_auc 0.36154 prc_auc 0.62028[0m
[92maverage training of epoch 36: loss -14.88038 acc 0.66667 roc_auc 0.42300 prc_auc 0.61062[0m
[93maverage test of epoch 36: loss -14.96742 acc 0.65789 roc_auc 0.48615 prc_auc 0.65231[0m
[92maverage training of epoch 37: loss -15.17973 acc 0.66667 roc_auc 0.41750 prc_auc 0.59911[0m
[93maverage test of epoch 37: loss -15.26430 acc 0.65789 roc_auc 0.67077 prc_auc 0.73518[0m
[92maverage training of epoch 38: loss -15.47872 acc 0.66667 roc_auc 0.42400 prc_auc 0.60164[0m
[93maverage test of epoch 38: loss -15.56374 acc 0.65789 roc_auc 0.54615 prc_auc 0.67611[0m
[92maverage training of epoch 39: loss -15.77754 acc 0.66667 roc_auc 0.41980 prc_auc 0.60505[0m
[93maverage test of epoch 39: loss -15.86109 acc 0.65789 roc_auc 0.48769 prc_auc 0.66585[0m
[92maverage training of epoch 40: loss -16.07629 acc 0.66667 roc_auc 0.41590 prc_auc 0.60665[0m
[93maverage test of epoch 40: loss -16.15903 acc 0.65789 roc_auc 0.49538 prc_auc 0.65887[0m
[92maverage training of epoch 41: loss -16.37508 acc 0.66667 roc_auc 0.41740 prc_auc 0.60232[0m
[93maverage test of epoch 41: loss -16.45743 acc 0.65789 roc_auc 0.60769 prc_auc 0.74461[0m
[92maverage training of epoch 42: loss -16.67420 acc 0.66667 roc_auc 0.42570 prc_auc 0.60572[0m
[93maverage test of epoch 42: loss -16.75555 acc 0.65789 roc_auc 0.56000 prc_auc 0.70462[0m
[92maverage training of epoch 43: loss -16.97302 acc 0.66667 roc_auc 0.42470 prc_auc 0.60895[0m
[93maverage test of epoch 43: loss -17.05323 acc 0.65789 roc_auc 0.49077 prc_auc 0.66997[0m
[92maverage training of epoch 44: loss -17.27141 acc 0.66667 roc_auc 0.42080 prc_auc 0.59986[0m
[93maverage test of epoch 44: loss -17.35120 acc 0.65789 roc_auc 0.39077 prc_auc 0.60309[0m
[92maverage training of epoch 45: loss -17.57013 acc 0.66667 roc_auc 0.41720 prc_auc 0.59697[0m
[93maverage test of epoch 45: loss -17.64846 acc 0.65789 roc_auc 0.33846 prc_auc 0.58376[0m
[92maverage training of epoch 46: loss -17.86881 acc 0.66667 roc_auc 0.42100 prc_auc 0.60373[0m
[93maverage test of epoch 46: loss -17.94599 acc 0.65789 roc_auc 0.64000 prc_auc 0.75062[0m
[92maverage training of epoch 47: loss -18.16757 acc 0.66667 roc_auc 0.41570 prc_auc 0.60170[0m
[93maverage test of epoch 47: loss -18.24348 acc 0.65789 roc_auc 0.47538 prc_auc 0.64736[0m
[92maverage training of epoch 48: loss -18.46567 acc 0.66667 roc_auc 0.42380 prc_auc 0.60669[0m
[93maverage test of epoch 48: loss -18.54157 acc 0.65789 roc_auc 0.52308 prc_auc 0.66768[0m
[92maverage training of epoch 49: loss -18.76432 acc 0.66667 roc_auc 0.42170 prc_auc 0.60630[0m
[93maverage test of epoch 49: loss -18.83963 acc 0.65789 roc_auc 0.42615 prc_auc 0.62501[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss 0.16311 acc 0.51333 roc_auc 0.44920 prc_auc 0.65901[0m
[93maverage test of epoch 0: loss -0.48203 acc 0.65789 roc_auc 0.72308 prc_auc 0.85328[0m
[92maverage training of epoch 1: loss -1.05310 acc 0.66667 roc_auc 0.44660 prc_auc 0.62976[0m
[93maverage test of epoch 1: loss -1.60403 acc 0.65789 roc_auc 0.64923 prc_auc 0.77743[0m
[92maverage training of epoch 2: loss -2.20441 acc 0.66667 roc_auc 0.46240 prc_auc 0.67198[0m
[93maverage test of epoch 2: loss -2.81189 acc 0.65789 roc_auc 0.68308 prc_auc 0.84648[0m
[92maverage training of epoch 3: loss -3.22128 acc 0.66667 roc_auc 0.39000 prc_auc 0.60102[0m
[93maverage test of epoch 3: loss -3.58040 acc 0.65789 roc_auc 0.41231 prc_auc 0.62575[0m
[92maverage training of epoch 4: loss -3.85484 acc 0.66667 roc_auc 0.45080 prc_auc 0.61510[0m
[93maverage test of epoch 4: loss -4.06532 acc 0.65789 roc_auc 0.57231 prc_auc 0.70073[0m
[92maverage training of epoch 5: loss -4.27735 acc 0.66667 roc_auc 0.34080 prc_auc 0.57696[0m
[93maverage test of epoch 5: loss -4.46903 acc 0.65789 roc_auc 0.48615 prc_auc 0.64421[0m
[92maverage training of epoch 6: loss -4.69768 acc 0.66667 roc_auc 0.45640 prc_auc 0.63717[0m
[93maverage test of epoch 6: loss -4.89406 acc 0.65789 roc_auc 0.48000 prc_auc 0.62414[0m
[92maverage training of epoch 7: loss -5.19034 acc 0.66667 roc_auc 0.48440 prc_auc 0.67437[0m
[93maverage test of epoch 7: loss -5.42907 acc 0.65789 roc_auc 0.62462 prc_auc 0.71319[0m
[92maverage training of epoch 8: loss -5.72492 acc 0.66667 roc_auc 0.51840 prc_auc 0.68337[0m
[93maverage test of epoch 8: loss -5.93601 acc 0.65789 roc_auc 0.52923 prc_auc 0.73826[0m
[92maverage training of epoch 9: loss -6.17086 acc 0.66667 roc_auc 0.39760 prc_auc 0.62580[0m
[93maverage test of epoch 9: loss -6.33100 acc 0.65789 roc_auc 0.40000 prc_auc 0.62036[0m
[92maverage training of epoch 10: loss -6.54783 acc 0.66667 roc_auc 0.51460 prc_auc 0.64734[0m
[93maverage test of epoch 10: loss -6.68233 acc 0.65789 roc_auc 0.54769 prc_auc 0.76334[0m
[92maverage training of epoch 11: loss -6.88724 acc 0.66667 roc_auc 0.50080 prc_auc 0.67553[0m
[93maverage test of epoch 11: loss -7.01547 acc 0.65789 roc_auc 0.53538 prc_auc 0.72758[0m
[92maverage training of epoch 12: loss -7.20501 acc 0.66667 roc_auc 0.50240 prc_auc 0.64797[0m
[93maverage test of epoch 12: loss -7.32264 acc 0.65789 roc_auc 0.40923 prc_auc 0.66332[0m
[92maverage training of epoch 13: loss -7.51518 acc 0.66667 roc_auc 0.47000 prc_auc 0.64928[0m
[93maverage test of epoch 13: loss -7.64260 acc 0.65789 roc_auc 0.51385 prc_auc 0.72649[0m
[92maverage training of epoch 14: loss -7.82337 acc 0.66667 roc_auc 0.36120 prc_auc 0.57495[0m
[93maverage test of epoch 14: loss -7.95705 acc 0.65789 roc_auc 0.52000 prc_auc 0.69315[0m
[92maverage training of epoch 15: loss -8.15317 acc 0.66667 roc_auc 0.51720 prc_auc 0.69820[0m
[93maverage test of epoch 15: loss -8.28503 acc 0.65789 roc_auc 0.56615 prc_auc 0.72609[0m
[92maverage training of epoch 16: loss -8.46959 acc 0.66667 roc_auc 0.40580 prc_auc 0.63126[0m
[93maverage test of epoch 16: loss -8.59900 acc 0.65789 roc_auc 0.46462 prc_auc 0.61155[0m
[92maverage training of epoch 17: loss -8.80758 acc 0.66667 roc_auc 0.48860 prc_auc 0.68595[0m
[93maverage test of epoch 17: loss -8.93178 acc 0.65789 roc_auc 0.31077 prc_auc 0.55383[0m
[92maverage training of epoch 18: loss -9.14088 acc 0.66667 roc_auc 0.48740 prc_auc 0.67910[0m
[93maverage test of epoch 18: loss -9.27619 acc 0.65789 roc_auc 0.52308 prc_auc 0.73517[0m
[92maverage training of epoch 19: loss -9.47626 acc 0.66667 roc_auc 0.43760 prc_auc 0.65182[0m
[93maverage test of epoch 19: loss -9.61542 acc 0.65789 roc_auc 0.61846 prc_auc 0.73893[0m
[92maverage training of epoch 20: loss -9.80704 acc 0.66667 roc_auc 0.44240 prc_auc 0.66889[0m
[93maverage test of epoch 20: loss -9.94092 acc 0.65789 roc_auc 0.76000 prc_auc 0.87881[0m
[92maverage training of epoch 21: loss -10.13430 acc 0.66667 roc_auc 0.41370 prc_auc 0.60427[0m
[93maverage test of epoch 21: loss -10.26437 acc 0.65789 roc_auc 0.48000 prc_auc 0.65223[0m
[92maverage training of epoch 22: loss -10.45810 acc 0.66667 roc_auc 0.37760 prc_auc 0.57753[0m
[93maverage test of epoch 22: loss -10.58308 acc 0.65789 roc_auc 0.42769 prc_auc 0.65505[0m
[92maverage training of epoch 23: loss -10.77972 acc 0.66667 roc_auc 0.43560 prc_auc 0.64925[0m
[93maverage test of epoch 23: loss -10.89854 acc 0.65789 roc_auc 0.30308 prc_auc 0.58557[0m
[92maverage training of epoch 24: loss -11.09336 acc 0.66667 roc_auc 0.41520 prc_auc 0.61579[0m
[93maverage test of epoch 24: loss -11.21867 acc 0.65789 roc_auc 0.49846 prc_auc 0.67440[0m
[92maverage training of epoch 25: loss -11.41072 acc 0.66667 roc_auc 0.37820 prc_auc 0.58999[0m
[93maverage test of epoch 25: loss -11.52824 acc 0.65789 roc_auc 0.56615 prc_auc 0.67670[0m
[92maverage training of epoch 26: loss -11.72048 acc 0.66667 roc_auc 0.36320 prc_auc 0.56769[0m
[93maverage test of epoch 26: loss -11.83920 acc 0.65789 roc_auc 0.53692 prc_auc 0.65174[0m
[92maverage training of epoch 27: loss -12.03111 acc 0.66667 roc_auc 0.39880 prc_auc 0.61886[0m
[93maverage test of epoch 27: loss -12.14714 acc 0.65789 roc_auc 0.34769 prc_auc 0.59845[0m
[92maverage training of epoch 28: loss -12.33955 acc 0.66667 roc_auc 0.39670 prc_auc 0.58476[0m
[93maverage test of epoch 28: loss -12.45368 acc 0.65789 roc_auc 0.42462 prc_auc 0.65448[0m
[92maverage training of epoch 29: loss -12.64676 acc 0.66667 roc_auc 0.37410 prc_auc 0.57565[0m
[93maverage test of epoch 29: loss -12.75824 acc 0.65789 roc_auc 0.55538 prc_auc 0.74040[0m
[92maverage training of epoch 30: loss -12.95288 acc 0.66667 roc_auc 0.37810 prc_auc 0.58350[0m
[93maverage test of epoch 30: loss -13.06484 acc 0.65789 roc_auc 0.33692 prc_auc 0.62084[0m
[92maverage training of epoch 31: loss -13.25761 acc 0.66667 roc_auc 0.38020 prc_auc 0.59197[0m
[93maverage test of epoch 31: loss -13.36753 acc 0.65789 roc_auc 0.41385 prc_auc 0.65236[0m
[92maverage training of epoch 32: loss -13.56047 acc 0.66667 roc_auc 0.38390 prc_auc 0.59170[0m
[93maverage test of epoch 32: loss -13.66989 acc 0.65789 roc_auc 0.48769 prc_auc 0.68279[0m
[92maverage training of epoch 33: loss -13.86391 acc 0.66667 roc_auc 0.38230 prc_auc 0.58468[0m
[93maverage test of epoch 33: loss -13.97024 acc 0.65789 roc_auc 0.60000 prc_auc 0.70833[0m
[92maverage training of epoch 34: loss -14.16571 acc 0.66667 roc_auc 0.38000 prc_auc 0.58950[0m
[93maverage test of epoch 34: loss -14.27174 acc 0.65789 roc_auc 0.35846 prc_auc 0.60665[0m
[92maverage training of epoch 35: loss -14.46718 acc 0.66667 roc_auc 0.38530 prc_auc 0.58795[0m
[93maverage test of epoch 35: loss -14.57106 acc 0.65789 roc_auc 0.52615 prc_auc 0.73977[0m
[92maverage training of epoch 36: loss -14.76909 acc 0.66667 roc_auc 0.37830 prc_auc 0.58655[0m
[93maverage test of epoch 36: loss -14.87351 acc 0.65789 roc_auc 0.45231 prc_auc 0.64000[0m
[92maverage training of epoch 37: loss -15.07037 acc 0.66667 roc_auc 0.38900 prc_auc 0.58287[0m
[93maverage test of epoch 37: loss -15.17428 acc 0.65789 roc_auc 0.59385 prc_auc 0.71206[0m
[92maverage training of epoch 38: loss -15.37239 acc 0.66667 roc_auc 0.37380 prc_auc 0.57387[0m
[93maverage test of epoch 38: loss -15.47288 acc 0.65789 roc_auc 0.36154 prc_auc 0.60187[0m
[92maverage training of epoch 39: loss -15.67205 acc 0.66667 roc_auc 0.38170 prc_auc 0.58743[0m
[93maverage test of epoch 39: loss -15.77298 acc 0.65789 roc_auc 0.49692 prc_auc 0.67643[0m
[92maverage training of epoch 40: loss -15.97187 acc 0.66667 roc_auc 0.37350 prc_auc 0.57397[0m
[93maverage test of epoch 40: loss -16.07361 acc 0.65789 roc_auc 0.58462 prc_auc 0.75082[0m
[92maverage training of epoch 41: loss -16.27245 acc 0.66667 roc_auc 0.38560 prc_auc 0.59073[0m
[93maverage test of epoch 41: loss -16.37188 acc 0.65789 roc_auc 0.63385 prc_auc 0.78849[0m
[92maverage training of epoch 42: loss -16.57253 acc 0.66667 roc_auc 0.37390 prc_auc 0.57170[0m
[93maverage test of epoch 42: loss -16.67085 acc 0.65789 roc_auc 0.46000 prc_auc 0.68769[0m
[92maverage training of epoch 43: loss -16.87162 acc 0.66667 roc_auc 0.37690 prc_auc 0.57259[0m
[93maverage test of epoch 43: loss -16.96964 acc 0.65789 roc_auc 0.62154 prc_auc 0.71468[0m
[92maverage training of epoch 44: loss -17.17088 acc 0.66667 roc_auc 0.38050 prc_auc 0.57916[0m
[93maverage test of epoch 44: loss -17.26843 acc 0.65789 roc_auc 0.58462 prc_auc 0.75238[0m
[92maverage training of epoch 45: loss -17.47055 acc 0.66667 roc_auc 0.38150 prc_auc 0.58274[0m
[93maverage test of epoch 45: loss -17.56752 acc 0.65789 roc_auc 0.58154 prc_auc 0.72241[0m
[92maverage training of epoch 46: loss -17.77010 acc 0.66667 roc_auc 0.37470 prc_auc 0.56975[0m
[93maverage test of epoch 46: loss -17.86583 acc 0.65789 roc_auc 0.36154 prc_auc 0.64045[0m
[92maverage training of epoch 47: loss -18.06940 acc 0.66667 roc_auc 0.38050 prc_auc 0.58691[0m
[93maverage test of epoch 47: loss -18.16361 acc 0.65789 roc_auc 0.47231 prc_auc 0.68588[0m
[92maverage training of epoch 48: loss -18.36885 acc 0.66667 roc_auc 0.38140 prc_auc 0.58633[0m
[93maverage test of epoch 48: loss -18.46116 acc 0.65789 roc_auc 0.58769 prc_auc 0.72389[0m
[92maverage training of epoch 49: loss -18.66723 acc 0.66667 roc_auc 0.38110 prc_auc 0.57830[0m
[93maverage test of epoch 49: loss -18.76081 acc 0.65789 roc_auc 0.64000 prc_auc 0.71884[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.20454 acc 0.33775 roc_auc 0.39137 prc_auc 0.59472[0m
[93maverage test of epoch 0: loss -0.43653 acc 0.35135 roc_auc 0.36000 prc_auc 0.66666[0m
[92maverage training of epoch 1: loss -0.61365 acc 0.49669 roc_auc 0.41569 prc_auc 0.60480[0m
[93maverage test of epoch 1: loss -0.80635 acc 0.64865 roc_auc 0.50667 prc_auc 0.72789[0m
[92maverage training of epoch 2: loss -0.98121 acc 0.66225 roc_auc 0.41196 prc_auc 0.61800[0m
[93maverage test of epoch 2: loss -1.28043 acc 0.67568 roc_auc 0.59000 prc_auc 0.74096[0m
[92maverage training of epoch 3: loss -1.48838 acc 0.66225 roc_auc 0.44824 prc_auc 0.62729[0m
[93maverage test of epoch 3: loss -1.78708 acc 0.67568 roc_auc 0.51333 prc_auc 0.66418[0m
[92maverage training of epoch 4: loss -2.01586 acc 0.66225 roc_auc 0.52392 prc_auc 0.66298[0m
[93maverage test of epoch 4: loss -2.29402 acc 0.67568 roc_auc 0.54667 prc_auc 0.77577[0m
[92maverage training of epoch 5: loss -2.44443 acc 0.66225 roc_auc 0.44431 prc_auc 0.64060[0m
[93maverage test of epoch 5: loss -2.72779 acc 0.67568 roc_auc 0.36333 prc_auc 0.60843[0m
[92maverage training of epoch 6: loss -2.90240 acc 0.66225 roc_auc 0.47725 prc_auc 0.63945[0m
[93maverage test of epoch 6: loss -3.17443 acc 0.67568 roc_auc 0.45000 prc_auc 0.66100[0m
[92maverage training of epoch 7: loss -3.36397 acc 0.66225 roc_auc 0.44294 prc_auc 0.63788[0m
[93maverage test of epoch 7: loss -3.75191 acc 0.67568 roc_auc 0.62000 prc_auc 0.79896[0m
[92maverage training of epoch 8: loss -3.92478 acc 0.66225 roc_auc 0.52392 prc_auc 0.69094[0m
[93maverage test of epoch 8: loss -4.27148 acc 0.67568 roc_auc 0.64333 prc_auc 0.82897[0m
[92maverage training of epoch 9: loss -4.42503 acc 0.66225 roc_auc 0.56451 prc_auc 0.70877[0m
[93maverage test of epoch 9: loss -4.73413 acc 0.67568 roc_auc 0.72667 prc_auc 0.85552[0m
[92maverage training of epoch 10: loss -4.83880 acc 0.66225 roc_auc 0.57412 prc_auc 0.72511[0m
[93maverage test of epoch 10: loss -5.14641 acc 0.67568 roc_auc 0.70667 prc_auc 0.85753[0m
[92maverage training of epoch 11: loss -5.24216 acc 0.66225 roc_auc 0.57490 prc_auc 0.70950[0m
[93maverage test of epoch 11: loss -5.52829 acc 0.67568 roc_auc 0.49333 prc_auc 0.64526[0m
[92maverage training of epoch 12: loss -5.61090 acc 0.66225 roc_auc 0.61059 prc_auc 0.75004[0m
[93maverage test of epoch 12: loss -5.86844 acc 0.67568 roc_auc 0.39500 prc_auc 0.65073[0m
[92maverage training of epoch 13: loss -5.95159 acc 0.66225 roc_auc 0.56980 prc_auc 0.71359[0m
[93maverage test of epoch 13: loss -6.23450 acc 0.67568 roc_auc 0.65667 prc_auc 0.79805[0m
[92maverage training of epoch 14: loss -6.30529 acc 0.66225 roc_auc 0.63245 prc_auc 0.74351[0m
[93maverage test of epoch 14: loss -6.58092 acc 0.67568 roc_auc 0.83167 prc_auc 0.92482[0m
[92maverage training of epoch 15: loss -6.61878 acc 0.66225 roc_auc 0.71186 prc_auc 0.80933[0m
[93maverage test of epoch 15: loss -6.90561 acc 0.67568 roc_auc 0.77667 prc_auc 0.89172[0m
[92maverage training of epoch 16: loss -6.95506 acc 0.66225 roc_auc 0.86588 prc_auc 0.92782[0m
[93maverage test of epoch 16: loss -7.22448 acc 0.67568 roc_auc 0.90167 prc_auc 0.95617[0m
[92maverage training of epoch 17: loss -7.32944 acc 0.66225 roc_auc 0.88922 prc_auc 0.93443[0m
[93maverage test of epoch 17: loss -7.52441 acc 0.67568 roc_auc 0.84333 prc_auc 0.91889[0m
[92maverage training of epoch 18: loss -7.58210 acc 0.66225 roc_auc 0.82520 prc_auc 0.86546[0m
[93maverage test of epoch 18: loss -7.91767 acc 0.67568 roc_auc 0.88000 prc_auc 0.92427[0m
[92maverage training of epoch 19: loss -7.94931 acc 0.66225 roc_auc 0.88343 prc_auc 0.91969[0m
[93maverage test of epoch 19: loss -8.19860 acc 0.67568 roc_auc 0.90000 prc_auc 0.94822[0m
[92maverage training of epoch 20: loss -8.23728 acc 0.66225 roc_auc 0.87304 prc_auc 0.92026[0m
[93maverage test of epoch 20: loss -8.48406 acc 0.67568 roc_auc 0.83167 prc_auc 0.90906[0m
[92maverage training of epoch 21: loss -8.57735 acc 0.70861 roc_auc 0.89402 prc_auc 0.92523[0m
[93maverage test of epoch 21: loss -8.82664 acc 0.70270 roc_auc 0.86667 prc_auc 0.93172[0m
[92maverage training of epoch 22: loss -8.87183 acc 0.77483 roc_auc 0.91451 prc_auc 0.95726[0m
[93maverage test of epoch 22: loss -9.16205 acc 0.72973 roc_auc 0.81333 prc_auc 0.87934[0m
[92maverage training of epoch 23: loss -9.23625 acc 0.78146 roc_auc 0.91000 prc_auc 0.94912[0m
[93maverage test of epoch 23: loss -9.26668 acc 0.72973 roc_auc 0.83500 prc_auc 0.89772[0m
[92maverage training of epoch 24: loss -9.42593 acc 0.79470 roc_auc 0.90343 prc_auc 0.93746[0m
[93maverage test of epoch 24: loss -9.66987 acc 0.78378 roc_auc 0.90000 prc_auc 0.95382[0m
[92maverage training of epoch 25: loss -9.72565 acc 0.79470 roc_auc 0.88941 prc_auc 0.91069[0m
[93maverage test of epoch 25: loss -9.87764 acc 0.70270 roc_auc 0.84167 prc_auc 0.90118[0m
[92maverage training of epoch 26: loss -9.99442 acc 0.77483 roc_auc 0.88637 prc_auc 0.92414[0m
[93maverage test of epoch 26: loss -10.27115 acc 0.75676 roc_auc 0.89000 prc_auc 0.94767[0m
[92maverage training of epoch 27: loss -10.30346 acc 0.78146 roc_auc 0.89245 prc_auc 0.93434[0m
[93maverage test of epoch 27: loss -10.48335 acc 0.75676 roc_auc 0.90000 prc_auc 0.95381[0m
[92maverage training of epoch 28: loss -10.60651 acc 0.80132 roc_auc 0.90343 prc_auc 0.93731[0m
[93maverage test of epoch 28: loss -10.75841 acc 0.75676 roc_auc 0.86500 prc_auc 0.92388[0m
[92maverage training of epoch 29: loss -10.83371 acc 0.78808 roc_auc 0.88157 prc_auc 0.92486[0m
[93maverage test of epoch 29: loss -11.05742 acc 0.75676 roc_auc 0.85333 prc_auc 0.91590[0m
[92maverage training of epoch 30: loss -11.16850 acc 0.80795 roc_auc 0.90049 prc_auc 0.94102[0m
[93maverage test of epoch 30: loss -11.26847 acc 0.75676 roc_auc 0.81167 prc_auc 0.87453[0m
[92maverage training of epoch 31: loss -11.37975 acc 0.81457 roc_auc 0.89980 prc_auc 0.94317[0m
[93maverage test of epoch 31: loss -11.64544 acc 0.75676 roc_auc 0.83333 prc_auc 0.86222[0m
[92maverage training of epoch 32: loss -11.67370 acc 0.80132 roc_auc 0.89520 prc_auc 0.93781[0m
[93maverage test of epoch 32: loss -11.82428 acc 0.75676 roc_auc 0.83333 prc_auc 0.88993[0m
[92maverage training of epoch 33: loss -11.93857 acc 0.83444 roc_auc 0.91363 prc_auc 0.95454[0m
[93maverage test of epoch 33: loss -12.02160 acc 0.75676 roc_auc 0.83167 prc_auc 0.89887[0m
[92maverage training of epoch 34: loss -12.21304 acc 0.82119 roc_auc 0.90794 prc_auc 0.94909[0m
[93maverage test of epoch 34: loss -12.31947 acc 0.75676 roc_auc 0.85333 prc_auc 0.92061[0m
[92maverage training of epoch 35: loss -12.50442 acc 0.84106 roc_auc 0.92108 prc_auc 0.96031[0m
[93maverage test of epoch 35: loss -12.73915 acc 0.75676 roc_auc 0.81000 prc_auc 0.85093[0m
[92maverage training of epoch 36: loss -12.70141 acc 0.84768 roc_auc 0.93941 prc_auc 0.97358[0m
[93maverage test of epoch 36: loss -12.95944 acc 0.75676 roc_auc 0.81833 prc_auc 0.86819[0m
[92maverage training of epoch 37: loss -12.97583 acc 0.84768 roc_auc 0.91971 prc_auc 0.96262[0m
[93maverage test of epoch 37: loss -13.21711 acc 0.72973 roc_auc 0.73500 prc_auc 0.78398[0m
[92maverage training of epoch 38: loss -13.32260 acc 0.84106 roc_auc 0.93000 prc_auc 0.96680[0m
[93maverage test of epoch 38: loss -13.44239 acc 0.75676 roc_auc 0.85333 prc_auc 0.91033[0m
[92maverage training of epoch 39: loss -13.62555 acc 0.85430 roc_auc 0.90108 prc_auc 0.93362[0m
[93maverage test of epoch 39: loss -13.74340 acc 0.75676 roc_auc 0.89000 prc_auc 0.93440[0m
[92maverage training of epoch 40: loss -13.88575 acc 0.85430 roc_auc 0.92480 prc_auc 0.96123[0m
[93maverage test of epoch 40: loss -13.94969 acc 0.75676 roc_auc 0.82000 prc_auc 0.87586[0m
[92maverage training of epoch 41: loss -14.10507 acc 0.86093 roc_auc 0.92098 prc_auc 0.96469[0m
[93maverage test of epoch 41: loss -14.33622 acc 0.83784 roc_auc 0.88500 prc_auc 0.93583[0m
[92maverage training of epoch 42: loss -14.51959 acc 0.86755 roc_auc 0.90990 prc_auc 0.95362[0m
[93maverage test of epoch 42: loss -14.59175 acc 0.78378 roc_auc 0.80167 prc_auc 0.85325[0m
[92maverage training of epoch 43: loss -14.73031 acc 0.86093 roc_auc 0.89961 prc_auc 0.94053[0m
[93maverage test of epoch 43: loss -14.85704 acc 0.81081 roc_auc 0.87667 prc_auc 0.92646[0m
[92maverage training of epoch 44: loss -14.97998 acc 0.85430 roc_auc 0.95118 prc_auc 0.97761[0m
[93maverage test of epoch 44: loss -15.10059 acc 0.75676 roc_auc 0.84167 prc_auc 0.89042[0m
[92maverage training of epoch 45: loss -15.27322 acc 0.85430 roc_auc 0.91176 prc_auc 0.94646[0m
[93maverage test of epoch 45: loss -15.43373 acc 0.83784 roc_auc 0.79000 prc_auc 0.83973[0m
[92maverage training of epoch 46: loss -15.55838 acc 0.85430 roc_auc 0.93765 prc_auc 0.96453[0m
[93maverage test of epoch 46: loss -15.66995 acc 0.78378 roc_auc 0.79333 prc_auc 0.84960[0m
[92maverage training of epoch 47: loss -15.87349 acc 0.86093 roc_auc 0.91118 prc_auc 0.93389[0m
[93maverage test of epoch 47: loss -15.99160 acc 0.81081 roc_auc 0.88667 prc_auc 0.92645[0m
[92maverage training of epoch 48: loss -16.23854 acc 0.86755 roc_auc 0.89353 prc_auc 0.92340[0m
[93maverage test of epoch 48: loss -16.12943 acc 0.75676 roc_auc 0.77667 prc_auc 0.83361[0m
[92maverage training of epoch 49: loss -16.49813 acc 0.87417 roc_auc 0.93794 prc_auc 0.95678[0m
[93maverage test of epoch 49: loss -16.56786 acc 0.81081 roc_auc 0.83000 prc_auc 0.87739[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.09555 acc 0.58940 roc_auc 0.42137 prc_auc 0.61137[0m
[93maverage test of epoch 0: loss -0.79888 acc 0.67568 roc_auc 0.38667 prc_auc 0.65075[0m
[92maverage training of epoch 1: loss -1.19188 acc 0.66225 roc_auc 0.40588 prc_auc 0.61466[0m
[93maverage test of epoch 1: loss -1.55976 acc 0.67568 roc_auc 0.26667 prc_auc 0.56342[0m
[92maverage training of epoch 2: loss -1.81032 acc 0.66225 roc_auc 0.46882 prc_auc 0.63537[0m
[93maverage test of epoch 2: loss -2.12434 acc 0.67568 roc_auc 0.30000 prc_auc 0.61711[0m
[92maverage training of epoch 3: loss -2.36269 acc 0.66225 roc_auc 0.37843 prc_auc 0.59608[0m
[93maverage test of epoch 3: loss -2.71156 acc 0.67568 roc_auc 0.65000 prc_auc 0.78378[0m
[92maverage training of epoch 4: loss -2.90460 acc 0.66225 roc_auc 0.40941 prc_auc 0.58534[0m
[93maverage test of epoch 4: loss -3.23562 acc 0.67568 roc_auc 0.58667 prc_auc 0.75309[0m
[92maverage training of epoch 5: loss -3.43032 acc 0.66225 roc_auc 0.49569 prc_auc 0.65629[0m
[93maverage test of epoch 5: loss -3.71867 acc 0.67568 roc_auc 0.47000 prc_auc 0.68010[0m
[92maverage training of epoch 6: loss -3.96189 acc 0.66225 roc_auc 0.41961 prc_auc 0.61523[0m
[93maverage test of epoch 6: loss -4.29962 acc 0.67568 roc_auc 0.60667 prc_auc 0.74353[0mUsing backend: pytorch

[92maverage training of epoch 7: loss -4.46458 acc 0.66225 roc_auc 0.48098 prc_auc 0.63723[0m
[93maverage test of epoch 7: loss -4.74634 acc 0.67568 roc_auc 0.42000 prc_auc 0.61875[0m
[92maverage training of epoch 8: loss -4.93216 acc 0.66225 roc_auc 0.42353 prc_auc 0.62329[0m
[93maverage test of epoch 8: loss -5.20094 acc 0.67568 roc_auc 0.45000 prc_auc 0.67780[0m
[92maverage training of epoch 9: loss -5.33946 acc 0.66225 roc_auc 0.43314 prc_auc 0.62301[0m
[93maverage test of epoch 9: loss -5.58955 acc 0.67568 roc_auc 0.29000 prc_auc 0.56232[0m
[92maverage training of epoch 10: loss -5.72888 acc 0.66225 roc_auc 0.44216 prc_auc 0.62813[0m
[93maverage test of epoch 10: loss -5.96908 acc 0.67568 roc_auc 0.47333 prc_auc 0.70971[0m
[92maverage training of epoch 11: loss -6.08976 acc 0.66225 roc_auc 0.38353 prc_auc 0.58456[0m
[93maverage test of epoch 11: loss -6.32673 acc 0.67568 roc_auc 0.37000 prc_auc 0.63699[0m
[92maverage training of epoch 12: loss -6.44725 acc 0.66225 roc_auc 0.44118 prc_auc 0.62738[0m
[93maverage test of epoch 12: loss -6.66931 acc 0.67568 roc_auc 0.41000 prc_auc 0.69692[0m
[92maverage training of epoch 13: loss -6.78328 acc 0.66225 roc_auc 0.37186 prc_auc 0.57505[0m
[93maverage test of epoch 13: loss -7.01059 acc 0.67568 roc_auc 0.39000 prc_auc 0.64052[0m
[92maverage training of epoch 14: loss -7.11878 acc 0.66225 roc_auc 0.38235 prc_auc 0.58094[0m
[93maverage test of epoch 14: loss -7.35266 acc 0.67568 roc_auc 0.72833 prc_auc 0.88165[0m
[92maverage training of epoch 15: loss -7.44921 acc 0.66225 roc_auc 0.38892 prc_auc 0.58486[0m
[93maverage test of epoch 15: loss -7.68564 acc 0.67568 roc_auc 0.65833 prc_auc 0.80161[0m
[92maverage training of epoch 16: loss -7.77196 acc 0.66225 roc_auc 0.38353 prc_auc 0.58142[0m
[93maverage test of epoch 16: loss -8.00326 acc 0.67568 roc_auc 0.44333 prc_auc 0.68925[0m
[92maverage training of epoch 17: loss -8.09209 acc 0.66225 roc_auc 0.36461 prc_auc 0.56780[0m
[93maverage test of epoch 17: loss -8.32003 acc 0.67568 roc_auc 0.46167 prc_auc 0.65742[0m
[92maverage training of epoch 18: loss -8.40562 acc 0.66225 roc_auc 0.37382 prc_auc 0.56711[0m
[93maverage test of epoch 18: loss -8.63847 acc 0.67568 roc_auc 0.43500 prc_auc 0.66130[0m
[92maverage training of epoch 19: loss -8.72596 acc 0.66225 roc_auc 0.36696 prc_auc 0.56815[0m
[93maverage test of epoch 19: loss -8.95321 acc 0.67568 roc_auc 0.53667 prc_auc 0.71933[0m
[92maverage training of epoch 20: loss -9.03631 acc 0.66225 roc_auc 0.38971 prc_auc 0.58485[0m
[93maverage test of epoch 20: loss -9.26321 acc 0.67568 roc_auc 0.52833 prc_auc 0.73002[0m
[92maverage training of epoch 21: loss -9.34714 acc 0.66225 roc_auc 0.37902 prc_auc 0.57347[0m
[93maverage test of epoch 21: loss -9.56943 acc 0.67568 roc_auc 0.47000 prc_auc 0.70015[0m
[92maverage training of epoch 22: loss -9.65507 acc 0.66225 roc_auc 0.37980 prc_auc 0.57483[0m
[93maverage test of epoch 22: loss -9.88557 acc 0.67568 roc_auc 0.48833 prc_auc 0.72315[0m
[92maverage training of epoch 23: loss -9.96466 acc 0.66225 roc_auc 0.37275 prc_auc 0.57610[0m
[93maverage test of epoch 23: loss -10.19480 acc 0.67568 roc_auc 0.53333 prc_auc 0.70152[0m
[92maverage training of epoch 24: loss -10.27022 acc 0.66225 roc_auc 0.35912 prc_auc 0.56306[0m
[93maverage test of epoch 24: loss -10.50166 acc 0.67568 roc_auc 0.47833 prc_auc 0.71120[0m
[92maverage training of epoch 25: loss -10.57452 acc 0.66225 roc_auc 0.34784 prc_auc 0.55545[0m
[93maverage test of epoch 25: loss -10.80919 acc 0.67568 roc_auc 0.41333 prc_auc 0.70350[0m
[92maverage training of epoch 26: loss -10.88199 acc 0.66225 roc_auc 0.37451 prc_auc 0.57048[0m
[93maverage test of epoch 26: loss -11.11409 acc 0.67568 roc_auc 0.61667 prc_auc 0.77701[0m
[92maverage training of epoch 27: loss -11.18624 acc 0.66225 roc_auc 0.36745 prc_auc 0.57019[0m
[93maverage test of epoch 27: loss -11.42181 acc 0.67568 roc_auc 0.63667 prc_auc 0.78928[0m
[92maverage training of epoch 28: loss -11.49062 acc 0.66225 roc_auc 0.38010 prc_auc 0.57750[0m
[93maverage test of epoch 28: loss -11.72353 acc 0.67568 roc_auc 0.60333 prc_auc 0.70003[0m
[92maverage training of epoch 29: loss -11.79331 acc 0.66225 roc_auc 0.37353 prc_auc 0.56714[0m
[93maverage test of epoch 29: loss -12.02881 acc 0.67568 roc_auc 0.68333 prc_auc 0.81512[0m
[92maverage training of epoch 30: loss -12.09595 acc 0.66225 roc_auc 0.36167 prc_auc 0.56770[0m
[93maverage test of epoch 30: loss -12.33279 acc 0.67568 roc_auc 0.47500 prc_auc 0.71290[0m
[92maverage training of epoch 31: loss -12.39891 acc 0.66225 roc_auc 0.37951 prc_auc 0.58129[0m
[93maverage test of epoch 31: loss -12.63767 acc 0.67568 roc_auc 0.67500 prc_auc 0.78635[0m
[92maverage training of epoch 32: loss -12.70125 acc 0.66225 roc_auc 0.37598 prc_auc 0.57637[0m
[93maverage test of epoch 32: loss -12.93860 acc 0.67568 roc_auc 0.45000 prc_auc 0.69837[0m
[92maverage training of epoch 33: loss -13.00199 acc 0.66225 roc_auc 0.36294 prc_auc 0.56982[0m
[93maverage test of epoch 33: loss -13.24387 acc 0.67568 roc_auc 0.70500 prc_auc 0.83508[0m
[92maverage training of epoch 34: loss -13.30356 acc 0.66225 roc_auc 0.36235 prc_auc 0.57020[0m
[93maverage test of epoch 34: loss -13.54654 acc 0.67568 roc_auc 0.70000 prc_auc 0.87299[0m
[92maverage training of epoch 35: loss -13.60584 acc 0.66225 roc_auc 0.37520 prc_auc 0.57777[0m
[93maverage test of epoch 35: loss -13.84611 acc 0.67568 roc_auc 0.40500 prc_auc 0.62917[0m
[92maverage training of epoch 36: loss -13.90755 acc 0.66225 roc_auc 0.37147 prc_auc 0.56955[0m
[93maverage test of epoch 36: loss -14.15011 acc 0.67568 roc_auc 0.46833 prc_auc 0.69975[0m
[92maverage training of epoch 37: loss -14.20819 acc 0.66225 roc_auc 0.37088 prc_auc 0.57124[0m
[93maverage test of epoch 37: loss -14.45406 acc 0.67568 roc_auc 0.41833 prc_auc 0.65037[0m
[92maverage training of epoch 38: loss -14.50948 acc 0.66225 roc_auc 0.37667 prc_auc 0.57812[0m
[93maverage test of epoch 38: loss -14.75295 acc 0.67568 roc_auc 0.24500 prc_auc 0.55618[0m
[92maverage training of epoch 39: loss -14.80954 acc 0.66225 roc_auc 0.37794 prc_auc 0.57728[0m
[93maverage test of epoch 39: loss -15.05692 acc 0.67568 roc_auc 0.57667 prc_auc 0.74177[0m
[92maverage training of epoch 40: loss -15.10937 acc 0.66225 roc_auc 0.37196 prc_auc 0.57062[0m
[93maverage test of epoch 40: loss -15.35831 acc 0.67568 roc_auc 0.45000 prc_auc 0.63882[0m
[92maverage training of epoch 41: loss -15.41041 acc 0.66225 roc_auc 0.37049 prc_auc 0.57159[0m
[93maverage test of epoch 41: loss -15.65953 acc 0.67568 roc_auc 0.61500 prc_auc 0.77991[0m
[92maverage training of epoch 42: loss -15.71126 acc 0.66225 roc_auc 0.37892 prc_auc 0.58314[0m
[93maverage test of epoch 42: loss -15.96030 acc 0.67568 roc_auc 0.37500 prc_auc 0.59504[0m
[92maverage training of epoch 43: loss -16.01136 acc 0.66225 roc_auc 0.37363 prc_auc 0.57034[0m
[93maverage test of epoch 43: loss -16.26302 acc 0.67568 roc_auc 0.54500 prc_auc 0.69350[0m
[92maverage training of epoch 44: loss -16.31158 acc 0.66225 roc_auc 0.36588 prc_auc 0.56671[0m
[93maverage test of epoch 44: loss -16.56441 acc 0.67568 roc_auc 0.57667 prc_auc 0.73771[0m
[92maverage training of epoch 45: loss -16.61175 acc 0.66225 roc_auc 0.36373 prc_auc 0.56510[0m
[93maverage test of epoch 45: loss -16.86641 acc 0.67568 roc_auc 0.35500 prc_auc 0.60575[0m
[92maverage training of epoch 46: loss -16.91179 acc 0.66225 roc_auc 0.36755 prc_auc 0.56712[0m
[93maverage test of epoch 46: loss -17.16782 acc 0.67568 roc_auc 0.41000 prc_auc 0.65277[0m
[92maverage training of epoch 47: loss -17.21173 acc 0.66225 roc_auc 0.36843 prc_auc 0.57206[0m
[93maverage test of epoch 47: loss -17.46883 acc 0.67568 roc_auc 0.45500 prc_auc 0.65262[0m
[92maverage training of epoch 48: loss -17.51179 acc 0.66225 roc_auc 0.37176 prc_auc 0.57551[0m
[93maverage test of epoch 48: loss -17.77027 acc 0.67568 roc_auc 0.49000 prc_auc 0.69917[0m
[92maverage training of epoch 49: loss -17.81237 acc 0.66225 roc_auc 0.36637 prc_auc 0.56783[0m
[93maverage test of epoch 49: loss -18.07127 acc 0.67568 roc_auc 0.55667 prc_auc 0.70218[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.0003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.69203 ROC_AUC (avg): 0.5881 PRC_AUC (avg): 0.71335 

Average forward propagation time taken(ms): 3.963014847264845
Average backward propagation time taken(ms): 1.51045790375603

