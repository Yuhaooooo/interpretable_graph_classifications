# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 1)
('lr', 0.0003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-21-01-01/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-21-01-01/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 8,
 'epochs': 50,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 8,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.0003,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 2,
 'num_workers': 8,
 'number_of_mlp_layer': 1,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-17-21-01-01',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 50, 'learning_rate': 0.0003, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.82131 acc 0.32667 roc_auc 0.37320 prc_auc 0.58534[0m
[93maverage test of epoch 0: loss -1.49159 acc 0.36842 roc_auc 0.42462 prc_auc 0.65189[0m
[92maverage training of epoch 1: loss -2.16659 acc 0.50667 roc_auc 0.36500 prc_auc 0.60318[0m
[93maverage test of epoch 1: loss -2.88476 acc 0.63158 roc_auc 0.43077 prc_auc 0.66625[0m
[92maverage training of epoch 2: loss -3.66568 acc 0.66000 roc_auc 0.40200 prc_auc 0.61856[0m
[93maverage test of epoch 2: loss -4.69492 acc 0.65789 roc_auc 0.46154 prc_auc 0.66959[0m
[92maverage training of epoch 3: loss -5.95271 acc 0.66667 roc_auc 0.40580 prc_auc 0.63901[0m
[93maverage test of epoch 3: loss -7.21502 acc 0.65789 roc_auc 0.50154 prc_auc 0.68983[0m
[92maverage training of epoch 4: loss -8.37756 acc 0.66667 roc_auc 0.39420 prc_auc 0.60904[0m
[93maverage test of epoch 4: loss -9.48721 acc 0.65789 roc_auc 0.52615 prc_auc 0.72860[0m
[92maverage training of epoch 5: loss -10.59916 acc 0.66667 roc_auc 0.40660 prc_auc 0.61236[0m
[93maverage test of epoch 5: loss -11.64463 acc 0.65789 roc_auc 0.26462 prc_auc 0.52778[0m
[92maverage training of epoch 6: loss -12.74452 acc 0.66667 roc_auc 0.42040 prc_auc 0.64192[0m
[93maverage test of epoch 6: loss -13.79593 acc 0.65789 roc_auc 0.60615 prc_auc 0.78362[0m
[92maverage training of epoch 7: loss -14.94069 acc 0.66667 roc_auc 0.41180 prc_auc 0.62200[0m
[93maverage test of epoch 7: loss -16.01801 acc 0.65789 roc_auc 0.58308 prc_auc 0.74743[0m
[92maverage training of epoch 8: loss -17.21315 acc 0.66667 roc_auc 0.39910 prc_auc 0.60961[0m
[93maverage test of epoch 8: loss -18.31511 acc 0.65789 roc_auc 0.58462 prc_auc 0.70252[0m
[92maverage training of epoch 9: loss -19.58373 acc 0.66667 roc_auc 0.40450 prc_auc 0.61749[0m
[93maverage test of epoch 9: loss -20.75281 acc 0.65789 roc_auc 0.46000 prc_auc 0.64616[0m
[92maverage training of epoch 10: loss -22.07052 acc 0.66667 roc_auc 0.40290 prc_auc 0.61025[0m
[93maverage test of epoch 10: loss -23.29148 acc 0.65789 roc_auc 0.63846 prc_auc 0.75109[0m
[92maverage training of epoch 11: loss -24.69682 acc 0.66667 roc_auc 0.40870 prc_auc 0.61890[0m
[93maverage test of epoch 11: loss -25.95675 acc 0.65789 roc_auc 0.54615 prc_auc 0.67962[0m
[92maverage training of epoch 12: loss -27.43415 acc 0.66667 roc_auc 0.40790 prc_auc 0.61463[0m
[93maverage test of epoch 12: loss -28.74866 acc 0.65789 roc_auc 0.50769 prc_auc 0.66199[0m
[92maverage training of epoch 13: loss -30.31255 acc 0.66667 roc_auc 0.43020 prc_auc 0.63709[0m
[93maverage test of epoch 13: loss -31.67316 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 14: loss -33.30310 acc 0.66667 roc_auc 0.43660 prc_auc 0.64099[0m
[93maverage test of epoch 14: loss -34.72890 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 15: loss -36.42419 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 15: loss -37.89043 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 16: loss -39.66306 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 16: loss -41.16930 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 17: loss -43.02025 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 17: loss -44.58366 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 18: loss -46.49603 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 18: loss -48.10306 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -50.09564 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 19: loss -51.74056 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -53.81849 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 20: loss -55.51467 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -57.65512 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 21: loss -59.39045 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -61.60904 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 22: loss -63.39155 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -65.68328 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 23: loss -67.51941 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -69.88585 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 24: loss -71.76945 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -74.21045 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 25: loss -76.13903 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -78.66814 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 26: loss -80.64500 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -83.25025 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 27: loss -85.27462 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -87.96897 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 28: loss -90.03774 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -92.81475 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 29: loss -94.94236 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -97.80000 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 30: loss -99.97363 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -102.91695 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 31: loss -105.13617 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -108.17259 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 32: loss -110.44247 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -113.56463 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 33: loss -115.88240 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -119.09268 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -121.45372 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -124.75983 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -127.17335 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -130.56482 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -133.03362 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -136.51213 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -139.02434 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -142.59844 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -145.15541 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -148.82285 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -151.43077 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -155.18870 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -157.83666 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -161.68853 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -164.38307 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -168.32283 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -171.06386 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -175.09654 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -177.88231 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -182.00778 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -184.83752 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -189.05539 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -191.92912 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -196.24299 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -199.16107 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -203.56980 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -206.52768 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -211.03511 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -214.03849 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -218.63945 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -221.68606 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -1.36039 acc 0.34667 roc_auc 0.52580 prc_auc 0.71307[0m
[93maverage test of epoch 0: loss -2.27480 acc 0.34211 roc_auc 0.37231 prc_auc 0.64076[0m
[92maverage training of epoch 1: loss -3.16236 acc 0.33333 roc_auc 0.36920 prc_auc 0.58281[0m
[93maverage test of epoch 1: loss -4.02623 acc 0.34211 roc_auc 0.61538 prc_auc 0.77205[0m
[92maverage training of epoch 2: loss -4.83972 acc 0.33333 roc_auc 0.51640 prc_auc 0.67298[0m
[93maverage test of epoch 2: loss -5.67967 acc 0.34211 roc_auc 0.56000 prc_auc 0.76317[0m
[92maverage training of epoch 3: loss -6.77383 acc 0.40000 roc_auc 0.44120 prc_auc 0.64123[0m
[93maverage test of epoch 3: loss -8.17120 acc 0.65789 roc_auc 0.40923 prc_auc 0.60105[0m
[92maverage training of epoch 4: loss -9.52763 acc 0.66667 roc_auc 0.44720 prc_auc 0.62747[0m
[93maverage test of epoch 4: loss -10.76833 acc 0.65789 roc_auc 0.34769 prc_auc 0.63042[0m
[92maverage training of epoch 5: loss -11.89812 acc 0.66667 roc_auc 0.45500 prc_auc 0.63552[0m
[93maverage test of epoch 5: loss -12.97178 acc 0.65789 roc_auc 0.60308 prc_auc 0.75316[0m
[92maverage training of epoch 6: loss -14.04208 acc 0.66667 roc_auc 0.45340 prc_auc 0.62959[0m
[93maverage test of epoch 6: loss -15.11744 acc 0.65789 roc_auc 0.53538 prc_auc 0.73719[0m
[92maverage training of epoch 7: loss -16.19035 acc 0.66667 roc_auc 0.46820 prc_auc 0.64564[0m
[93maverage test of epoch 7: loss -17.31646 acc 0.65789 roc_auc 0.45538 prc_auc 0.63766[0m
[92maverage training of epoch 8: loss -18.43754 acc 0.66667 roc_auc 0.44760 prc_auc 0.63823[0m
[93maverage test of epoch 8: loss -19.56415 acc 0.65789 roc_auc 0.64615 prc_auc 0.81318[0m
[92maverage training of epoch 9: loss -20.74729 acc 0.66667 roc_auc 0.46000 prc_auc 0.63586[0m
[93maverage test of epoch 9: loss -21.93463 acc 0.65789 roc_auc 0.36615 prc_auc 0.59417[0m
[92maverage training of epoch 10: loss -23.17386 acc 0.66667 roc_auc 0.45880 prc_auc 0.64277[0m
[93maverage test of epoch 10: loss -24.40289 acc 0.65789 roc_auc 0.45846 prc_auc 0.69763[0m
[92maverage training of epoch 11: loss -25.70881 acc 0.66667 roc_auc 0.45370 prc_auc 0.63148[0m
[93maverage test of epoch 11: loss -26.98951 acc 0.65789 roc_auc 0.46154 prc_auc 0.63866[0m
[92maverage training of epoch 12: loss -28.34881 acc 0.66667 roc_auc 0.45880 prc_auc 0.63763[0m
[93maverage test of epoch 12: loss -29.68619 acc 0.65789 roc_auc 0.54000 prc_auc 0.72713[0m
[92maverage training of epoch 13: loss -31.10340 acc 0.66667 roc_auc 0.46120 prc_auc 0.63836[0m
[93maverage test of epoch 13: loss -32.48346 acc 0.65789 roc_auc 0.31077 prc_auc 0.56971[0m
[92maverage training of epoch 14: loss -33.96175 acc 0.66667 roc_auc 0.46030 prc_auc 0.63437[0m
[93maverage test of epoch 14: loss -35.38779 acc 0.65789 roc_auc 0.46923 prc_auc 0.62718[0m
[92maverage training of epoch 15: loss -36.93482 acc 0.66667 roc_auc 0.45820 prc_auc 0.63864[0m
[93maverage test of epoch 15: loss -38.41279 acc 0.65789 roc_auc 0.44308 prc_auc 0.63651[0m
[92maverage training of epoch 16: loss -40.01362 acc 0.66667 roc_auc 0.45850 prc_auc 0.63764[0m
[93maverage test of epoch 16: loss -41.52827 acc 0.65789 roc_auc 0.46462 prc_auc 0.63509[0m
[92maverage training of epoch 17: loss -43.19554 acc 0.66667 roc_auc 0.45730 prc_auc 0.63725[0m
[93maverage test of epoch 17: loss -44.78038 acc 0.65789 roc_auc 0.62615 prc_auc 0.73311[0m
[92maverage training of epoch 18: loss -46.67228 acc 0.66667 roc_auc 0.46600 prc_auc 0.65348[0m
[93maverage test of epoch 18: loss -48.48334 acc 0.65789 roc_auc 0.55846 prc_auc 0.70415[0m
[92maverage training of epoch 19: loss -50.48944 acc 0.66667 roc_auc 0.46630 prc_auc 0.64871[0m
[93maverage test of epoch 19: loss -52.36325 acc 0.65789 roc_auc 0.45846 prc_auc 0.63981[0m
[92maverage training of epoch 20: loss -54.45016 acc 0.66667 roc_auc 0.46080 prc_auc 0.63608[0m
[93maverage test of epoch 20: loss -56.37060 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -58.52857 acc 0.66667 roc_auc 0.45500 prc_auc 0.63503[0m
[93maverage test of epoch 21: loss -60.50274 acc 0.65789 roc_auc 0.45692 prc_auc 0.63923[0m
[92maverage training of epoch 22: loss -62.72699 acc 0.66667 roc_auc 0.46500 prc_auc 0.65167[0m
[93maverage test of epoch 22: loss -64.75342 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -67.05052 acc 0.66667 roc_auc 0.49000 prc_auc 0.66226[0m
[93maverage test of epoch 23: loss -69.12141 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -71.49710 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 24: loss -73.61733 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -76.06961 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 25: loss -78.24394 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -80.76984 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 26: loss -82.99341 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -85.60525 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 27: loss -87.87757 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -90.56901 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 28: loss -92.90169 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -95.66647 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 29: loss -98.04813 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -100.89284 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 30: loss -103.32498 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -106.25054 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 31: loss -108.73207 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -111.73434 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 32: loss -114.26699 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -117.34348 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 33: loss -119.92307 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -123.08448 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -125.71165 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -128.95517 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -131.63439 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -134.95856 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -137.69122 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -141.09460 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -143.87298 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -147.35875 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -150.18430 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -153.75615 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -156.63384 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -160.28465 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -163.20992 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -166.94525 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -169.91908 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -173.74069 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -176.76162 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -180.66833 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -183.73518 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -187.72542 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -190.83825 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -194.91185 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -198.07158 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -202.22964 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -205.43356 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -209.67722 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -212.92794 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -217.25815 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -220.55473 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -224.97135 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -228.31043 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.65174 acc 0.66667 roc_auc 0.51120 prc_auc 0.69428[0m
[93maverage test of epoch 0: loss -2.03121 acc 0.65789 roc_auc 0.67077 prc_auc 0.75707[0m
[92maverage training of epoch 1: loss -3.11650 acc 0.66667 roc_auc 0.40080 prc_auc 0.60650[0m
[93maverage test of epoch 1: loss -4.36940 acc 0.65789 roc_auc 0.71077 prc_auc 0.83794[0m
[92maverage training of epoch 2: loss -5.80297 acc 0.66667 roc_auc 0.41180 prc_auc 0.63045[0m
[93maverage test of epoch 2: loss -7.53160 acc 0.65789 roc_auc 0.55385 prc_auc 0.66388[0m
[92maverage training of epoch 3: loss -9.04008 acc 0.66667 roc_auc 0.43040 prc_auc 0.62160[0m
[93maverage test of epoch 3: loss -10.38480 acc 0.65789 roc_auc 0.72923 prc_auc 0.84915[0m
[92maverage training of epoch 4: loss -11.58287 acc 0.66667 roc_auc 0.41140 prc_auc 0.61647[0m
[93maverage test of epoch 4: loss -12.72159 acc 0.65789 roc_auc 0.49846 prc_auc 0.65706[0m
[92maverage training of epoch 5: loss -13.90655 acc 0.66667 roc_auc 0.40600 prc_auc 0.60014[0m
[93maverage test of epoch 5: loss -15.03568 acc 0.65789 roc_auc 0.49231 prc_auc 0.69338[0m
[92maverage training of epoch 6: loss -16.20091 acc 0.66667 roc_auc 0.41340 prc_auc 0.62733[0m
[93maverage test of epoch 6: loss -17.34921 acc 0.65789 roc_auc 0.46462 prc_auc 0.65097[0m
[92maverage training of epoch 7: loss -18.53728 acc 0.66667 roc_auc 0.42240 prc_auc 0.62239[0m
[93maverage test of epoch 7: loss -19.71191 acc 0.65789 roc_auc 0.64769 prc_auc 0.82919[0m
[92maverage training of epoch 8: loss -20.93403 acc 0.66667 roc_auc 0.44960 prc_auc 0.64270[0m
[93maverage test of epoch 8: loss -22.11301 acc 0.65789 roc_auc 0.63231 prc_auc 0.80641[0m
[92maverage training of epoch 9: loss -23.37516 acc 0.66667 roc_auc 0.43290 prc_auc 0.63872[0m
[93maverage test of epoch 9: loss -24.55312 acc 0.65789 roc_auc 0.63846 prc_auc 0.73758[0m
[92maverage training of epoch 10: loss -25.87554 acc 0.66667 roc_auc 0.43210 prc_auc 0.63743[0m
[93maverage test of epoch 10: loss -27.08559 acc 0.65789 roc_auc 0.31231 prc_auc 0.55520[0m
[92maverage training of epoch 11: loss -28.46014 acc 0.66667 roc_auc 0.43310 prc_auc 0.62740[0m
[93maverage test of epoch 11: loss -29.70332 acc 0.65789 roc_auc 0.62462 prc_auc 0.72294[0m
[92maverage training of epoch 12: loss -31.11182 acc 0.66667 roc_auc 0.43280 prc_auc 0.63318[0m
[93maverage test of epoch 12: loss -32.40441 acc 0.65789 roc_auc 0.57846 prc_auc 0.73394[0m
[92maverage training of epoch 13: loss -33.86189 acc 0.66667 roc_auc 0.44110 prc_auc 0.63284[0m
[93maverage test of epoch 13: loss -35.18577 acc 0.65789 roc_auc 0.56000 prc_auc 0.69067[0m
[92maverage training of epoch 14: loss -36.70794 acc 0.66667 roc_auc 0.43150 prc_auc 0.62317[0m
[93maverage test of epoch 14: loss -38.06336 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 15: loss -39.63725 acc 0.66667 roc_auc 0.43330 prc_auc 0.62808[0m
[93maverage test of epoch 15: loss -41.02300 acc 0.65789 roc_auc 0.53385 prc_auc 0.67361[0m
[92maverage training of epoch 16: loss -42.65933 acc 0.66667 roc_auc 0.42740 prc_auc 0.63049[0m
[93maverage test of epoch 16: loss -44.08330 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 17: loss -45.78635 acc 0.66667 roc_auc 0.45000 prc_auc 0.64569[0m
[93maverage test of epoch 17: loss -47.25558 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 18: loss -48.99437 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 18: loss -50.50823 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -52.31621 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 19: loss -53.85454 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -55.73197 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 20: loss -57.31686 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -59.23891 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 21: loss -60.85977 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -62.85310 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 22: loss -64.50322 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -66.55830 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 23: loss -68.24457 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -70.36966 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 24: loss -72.08938 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -74.27514 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 25: loss -76.03165 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -78.27969 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 26: loss -80.07999 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -82.39119 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 27: loss -84.22685 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -86.60826 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 28: loss -88.48153 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -90.92460 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 29: loss -92.83367 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -95.34607 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 30: loss -97.29246 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -99.87445 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 31: loss -101.85796 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -104.50931 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 32: loss -106.52499 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -109.24812 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 33: loss -111.30804 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -114.09634 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -116.19183 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -119.05241 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -121.18010 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -124.11679 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -126.28213 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -129.28963 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -131.49285 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -134.57337 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -136.81461 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -139.96651 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -142.24152 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -145.46841 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -147.78284 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -151.08202 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -153.43134 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -156.80719 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -159.18922 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -162.64269 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -165.06042 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -168.58932 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -171.04124 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -174.64741 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -177.13377 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -180.81720 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -183.34029 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -187.09916 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -189.65722 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -193.49251 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -196.08244 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -199.99844 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -202.62379 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.09945 acc 0.66225 roc_auc 0.47020 prc_auc 0.64546[0m
[93maverage test of epoch 0: loss -0.42343 acc 0.67568 roc_auc 0.59000 prc_auc 0.78094[0m
[92maverage training of epoch 1: loss -0.58652 acc 0.66225 roc_auc 0.40373 prc_auc 0.58732[0m
[93maverage test of epoch 1: loss -0.84440 acc 0.67568 roc_auc 0.54000 prc_auc 0.74944[0m
[92maverage training of epoch 2: loss -1.04065 acc 0.66225 roc_auc 0.42118 prc_auc 0.60970[0m
[93maverage test of epoch 2: loss -1.30945 acc 0.67568 roc_auc 0.26000 prc_auc 0.57241[0m
[92maverage training of epoch 3: loss -1.55434 acc 0.66225 roc_auc 0.41980 prc_auc 0.61787[0m
[93maverage test of epoch 3: loss -1.88046 acc 0.67568 roc_auc 0.48667 prc_auc 0.70715[0m
[92maverage training of epoch 4: loss -2.13412 acc 0.66225 roc_auc 0.40765 prc_auc 0.60368[0m
[93maverage test of epoch 4: loss -2.52839 acc 0.67568 roc_auc 0.52333 prc_auc 0.69564[0m
[92maverage training of epoch 5: loss -2.83735 acc 0.66225 roc_auc 0.40647 prc_auc 0.61555[0m
[93maverage test of epoch 5: loss -3.35535 acc 0.67568 roc_auc 0.49000 prc_auc 0.69757[0m
[92maverage training of epoch 6: loss -3.78420 acc 0.66225 roc_auc 0.42275 prc_auc 0.61778[0m
[93maverage test of epoch 6: loss -4.38287 acc 0.67568 roc_auc 0.40000 prc_auc 0.71302[0m
[92maverage training of epoch 7: loss -4.82800 acc 0.66225 roc_auc 0.41431 prc_auc 0.60285[0m
[93maverage test of epoch 7: loss -5.42444 acc 0.67568 roc_auc 0.34333 prc_auc 0.62049[0m
[92maverage training of epoch 8: loss -5.80547 acc 0.66225 roc_auc 0.44078 prc_auc 0.62924[0m
[93maverage test of epoch 8: loss -6.40177 acc 0.67568 roc_auc 0.58833 prc_auc 0.73218[0m
[92maverage training of epoch 9: loss -6.76651 acc 0.66225 roc_auc 0.42529 prc_auc 0.61903[0m
[93maverage test of epoch 9: loss -7.38068 acc 0.67568 roc_auc 0.37500 prc_auc 0.60073[0m
[92maverage training of epoch 10: loss -7.74634 acc 0.66225 roc_auc 0.40431 prc_auc 0.59977[0m
[93maverage test of epoch 10: loss -8.38666 acc 0.67568 roc_auc 0.51667 prc_auc 0.75567[0m
[92maverage training of epoch 11: loss -8.76850 acc 0.66225 roc_auc 0.44588 prc_auc 0.62278[0m
[93maverage test of epoch 11: loss -9.43137 acc 0.67568 roc_auc 0.40333 prc_auc 0.62193[0m
[92maverage training of epoch 12: loss -9.81969 acc 0.66225 roc_auc 0.40873 prc_auc 0.60474[0m
[93maverage test of epoch 12: loss -10.52468 acc 0.67568 roc_auc 0.63667 prc_auc 0.78262[0m
[92maverage training of epoch 13: loss -10.91634 acc 0.66225 roc_auc 0.43539 prc_auc 0.62226[0m
[93maverage test of epoch 13: loss -11.64608 acc 0.67568 roc_auc 0.52000 prc_auc 0.67239[0m
[92maverage training of epoch 14: loss -12.05448 acc 0.66225 roc_auc 0.44559 prc_auc 0.63837[0m
[93maverage test of epoch 14: loss -12.81526 acc 0.67568 roc_auc 0.60833 prc_auc 0.72628[0m
[92maverage training of epoch 15: loss -13.23498 acc 0.66225 roc_auc 0.43578 prc_auc 0.62459[0m
[93maverage test of epoch 15: loss -14.03761 acc 0.67568 roc_auc 0.58667 prc_auc 0.71638[0m
[92maverage training of epoch 16: loss -14.46049 acc 0.66225 roc_auc 0.41892 prc_auc 0.61415[0m
[93maverage test of epoch 16: loss -15.29736 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 17: loss -15.73786 acc 0.66225 roc_auc 0.44784 prc_auc 0.63687[0m
[93maverage test of epoch 17: loss -16.59564 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 18: loss -17.04753 acc 0.66225 roc_auc 0.47304 prc_auc 0.65052[0m
[93maverage test of epoch 18: loss -17.94204 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 19: loss -18.40349 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 19: loss -19.33160 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 20: loss -19.79867 acc 0.66225 roc_auc 0.49343 prc_auc 0.65933[0m
[93maverage test of epoch 20: loss -20.75567 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 21: loss -21.24522 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 21: loss -22.24339 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 22: loss -22.73780 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 22: loss -23.77488 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 23: loss -24.27646 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 23: loss -25.34578 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 24: loss -25.86602 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 24: loss -26.97894 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 25: loss -27.50730 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 25: loss -28.66094 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 26: loss -29.19630 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 26: loss -30.38719 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 27: loss -30.92940 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 27: loss -32.16188 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 28: loss -32.72002 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 28: loss -33.98933 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 29: loss -34.55381 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 29: loss -35.87046 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 30: loss -36.44561 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 30: loss -37.79594 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 31: loss -38.38748 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 31: loss -39.77780 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 32: loss -40.38194 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 32: loss -41.81959 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 33: loss -42.42999 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 33: loss -43.91430 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 34: loss -44.53593 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 34: loss -46.05898 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 35: loss -46.69356 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 35: loss -48.26540 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 36: loss -48.90789 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 36: loss -50.52354 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 37: loss -51.17828 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 37: loss -52.84093 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 38: loss -53.50494 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 38: loss -55.21631 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 39: loss -55.89143 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 39: loss -57.64739 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -58.33305 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 40: loss -60.13533 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -60.83277 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 41: loss -62.68666 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -63.39016 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 42: loss -65.29322 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -66.00785 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 43: loss -67.95884 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -68.68126 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 44: loss -70.68435 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -71.41503 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 45: loss -73.46558 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -74.20677 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 46: loss -76.30942 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -77.05831 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 47: loss -79.21073 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -79.96735 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 48: loss -82.17142 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -82.93710 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 49: loss -85.19371 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.65587 acc 0.49669 roc_auc 0.55843 prc_auc 0.68230[0m
[93maverage test of epoch 0: loss -1.14662 acc 0.32432 roc_auc 0.42667 prc_auc 0.67205[0m
[92maverage training of epoch 1: loss -2.08120 acc 0.37748 roc_auc 0.42490 prc_auc 0.63060[0m
[93maverage test of epoch 1: loss -3.96640 acc 0.67568 roc_auc 0.51000 prc_auc 0.70294[0m
[92maverage training of epoch 2: loss -6.15206 acc 0.66225 roc_auc 0.46167 prc_auc 0.65514[0mUsing backend: pytorch

[93maverage test of epoch 2: loss -8.00930 acc 0.67568 roc_auc 0.51667 prc_auc 0.72575[0m
[92maverage training of epoch 3: loss -9.43332 acc 0.66225 roc_auc 0.49412 prc_auc 0.67082[0m
[93maverage test of epoch 3: loss -10.78132 acc 0.67568 roc_auc 0.33333 prc_auc 0.62382[0m
[92maverage training of epoch 4: loss -11.97884 acc 0.64901 roc_auc 0.45020 prc_auc 0.61699[0m
[93maverage test of epoch 4: loss -13.17219 acc 0.43243 roc_auc 0.43333 prc_auc 0.73765[0m
[92maverage training of epoch 5: loss -14.34312 acc 0.45033 roc_auc 0.48020 prc_auc 0.63331[0m
[93maverage test of epoch 5: loss -15.50284 acc 0.32432 roc_auc 0.51333 prc_auc 0.67016[0m
[92maverage training of epoch 6: loss -16.67133 acc 0.33775 roc_auc 0.44078 prc_auc 0.62103[0m
[93maverage test of epoch 6: loss -17.87253 acc 0.32432 roc_auc 0.57667 prc_auc 0.73210[0m
[92maverage training of epoch 7: loss -19.07144 acc 0.33775 roc_auc 0.40775 prc_auc 0.59948[0m
[93maverage test of epoch 7: loss -20.32566 acc 0.32432 roc_auc 0.63000 prc_auc 0.76320[0m
[92maverage training of epoch 8: loss -21.55977 acc 0.33775 roc_auc 0.39647 prc_auc 0.59569[0m
[93maverage test of epoch 8: loss -22.85556 acc 0.32432 roc_auc 0.34167 prc_auc 0.66597[0m
[92maverage training of epoch 9: loss -24.15966 acc 0.33775 roc_auc 0.39176 prc_auc 0.59366[0m
[93maverage test of epoch 9: loss -25.51826 acc 0.32432 roc_auc 0.62667 prc_auc 0.79375[0m
[92maverage training of epoch 10: loss -26.86685 acc 0.33775 roc_auc 0.39471 prc_auc 0.59349[0m
[93maverage test of epoch 10: loss -28.25998 acc 0.32432 roc_auc 0.43333 prc_auc 0.65339[0m
[92maverage training of epoch 11: loss -29.68868 acc 0.32450 roc_auc 0.39157 prc_auc 0.59103[0m
[93maverage test of epoch 11: loss -31.13895 acc 0.32432 roc_auc 0.54333 prc_auc 0.79306[0m
[92maverage training of epoch 12: loss -32.62500 acc 0.43709 roc_auc 0.39510 prc_auc 0.59165[0m
[93maverage test of epoch 12: loss -34.15301 acc 0.67568 roc_auc 0.47833 prc_auc 0.67156[0m
[92maverage training of epoch 13: loss -35.68356 acc 0.59603 roc_auc 0.38157 prc_auc 0.58354[0m
[93maverage test of epoch 13: loss -37.27176 acc 0.67568 roc_auc 0.36833 prc_auc 0.59246[0m
[92maverage training of epoch 14: loss -38.87788 acc 0.66225 roc_auc 0.37647 prc_auc 0.58064[0m
[93maverage test of epoch 14: loss -40.54419 acc 0.67568 roc_auc 0.43667 prc_auc 0.63651[0m
[92maverage training of epoch 15: loss -42.20259 acc 0.66225 roc_auc 0.37824 prc_auc 0.57927[0m
[93maverage test of epoch 15: loss -43.92876 acc 0.67568 roc_auc 0.54833 prc_auc 0.74397[0m
[92maverage training of epoch 16: loss -45.64760 acc 0.66225 roc_auc 0.37706 prc_auc 0.57673[0m
[93maverage test of epoch 16: loss -47.43184 acc 0.67568 roc_auc 0.40333 prc_auc 0.61349[0m
[92maverage training of epoch 17: loss -49.23163 acc 0.66225 roc_auc 0.37686 prc_auc 0.57699[0m
[93maverage test of epoch 17: loss -51.09912 acc 0.67568 roc_auc 0.58167 prc_auc 0.71301[0m
[92maverage training of epoch 18: loss -52.94507 acc 0.66225 roc_auc 0.37647 prc_auc 0.57770[0m
[93maverage test of epoch 18: loss -54.90064 acc 0.67568 roc_auc 0.42667 prc_auc 0.63661[0m
[92maverage training of epoch 19: loss -56.80009 acc 0.66225 roc_auc 0.37490 prc_auc 0.57278[0m
[93maverage test of epoch 19: loss -58.82393 acc 0.67568 roc_auc 0.60333 prc_auc 0.76083[0m
[92maverage training of epoch 20: loss -60.78613 acc 0.66225 roc_auc 0.37078 prc_auc 0.57051[0m
[93maverage test of epoch 20: loss -62.87438 acc 0.67568 roc_auc 0.28167 prc_auc 0.55956[0m
[92maverage training of epoch 21: loss -64.91059 acc 0.66225 roc_auc 0.36882 prc_auc 0.56817[0m
[93maverage test of epoch 21: loss -67.08012 acc 0.67568 roc_auc 0.61000 prc_auc 0.78880[0m
[92maverage training of epoch 22: loss -69.16598 acc 0.66225 roc_auc 0.36961 prc_auc 0.56972[0m
[93maverage test of epoch 22: loss -71.40923 acc 0.67568 roc_auc 0.50500 prc_auc 0.69852[0m
[92maverage training of epoch 23: loss -73.54944 acc 0.66225 roc_auc 0.36863 prc_auc 0.56775[0m
[93maverage test of epoch 23: loss -75.86598 acc 0.67568 roc_auc 0.72167 prc_auc 0.83153[0m
[92maverage training of epoch 24: loss -78.05974 acc 0.66225 roc_auc 0.36725 prc_auc 0.56596[0m
[93maverage test of epoch 24: loss -80.45012 acc 0.67568 roc_auc 0.72000 prc_auc 0.83085[0m
[92maverage training of epoch 25: loss -82.69854 acc 0.66225 roc_auc 0.36951 prc_auc 0.56769[0m
[93maverage test of epoch 25: loss -85.16515 acc 0.67568 roc_auc 0.44000 prc_auc 0.65410[0m
[92maverage training of epoch 26: loss -87.47090 acc 0.66225 roc_auc 0.36559 prc_auc 0.56471[0m
[93maverage test of epoch 26: loss -90.00780 acc 0.67568 roc_auc 0.57000 prc_auc 0.70781[0m
[92maverage training of epoch 27: loss -92.36826 acc 0.66225 roc_auc 0.36294 prc_auc 0.56040[0m
[93maverage test of epoch 27: loss -94.98554 acc 0.67568 roc_auc 0.47333 prc_auc 0.65025[0m
[92maverage training of epoch 28: loss -97.40049 acc 0.66225 roc_auc 0.36618 prc_auc 0.56577[0m
[93maverage test of epoch 28: loss -100.10477 acc 0.67568 roc_auc 0.43000 prc_auc 0.64109[0m
[92maverage training of epoch 29: loss -102.56500 acc 0.66225 roc_auc 0.36696 prc_auc 0.56690[0m
[93maverage test of epoch 29: loss -105.34743 acc 0.67568 roc_auc 0.31333 prc_auc 0.60100[0m
[92maverage training of epoch 30: loss -107.85735 acc 0.66225 roc_auc 0.36765 prc_auc 0.56776[0m
[93maverage test of epoch 30: loss -110.70805 acc 0.67568 roc_auc 0.54167 prc_auc 0.69674[0m
[92maverage training of epoch 31: loss -113.26739 acc 0.66225 roc_auc 0.36618 prc_auc 0.56901[0m
[93maverage test of epoch 31: loss -116.19969 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 32: loss -118.80639 acc 0.66225 roc_auc 0.36706 prc_auc 0.56929[0m
[93maverage test of epoch 32: loss -121.81872 acc 0.67568 roc_auc 0.46167 prc_auc 0.65936[0m
[92maverage training of epoch 33: loss -124.47369 acc 0.66225 roc_auc 0.37333 prc_auc 0.57952[0m
[93maverage test of epoch 33: loss -127.56443 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 34: loss -130.26427 acc 0.66225 roc_auc 0.38627 prc_auc 0.59410[0m
[93maverage test of epoch 34: loss -133.44046 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 35: loss -136.19308 acc 0.66225 roc_auc 0.39118 prc_auc 0.60801[0m
[93maverage test of epoch 35: loss -139.45322 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 36: loss -142.24782 acc 0.66225 roc_auc 0.43108 prc_auc 0.63420[0m
[93maverage test of epoch 36: loss -145.59349 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 37: loss -148.43715 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 37: loss -151.86952 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 38: loss -154.76076 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 38: loss -158.27971 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 39: loss -161.21870 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 39: loss -164.82154 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -167.80946 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 40: loss -171.50496 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -174.54000 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 41: loss -178.32483 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -181.40146 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 42: loss -185.28259 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -188.40504 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 43: loss -192.37954 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -195.54571 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 44: loss -199.61352 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -202.82407 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 45: loss -206.98552 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -210.23973 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 46: loss -214.49709 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -217.79534 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 47: loss -222.14845 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -225.48783 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 48: loss -229.93807 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -233.32076 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 49: loss -237.86944 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 1)
('lr', 0.0003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.66501 ROC_AUC (avg): 0.5 PRC_AUC (avg): 0.66501 

Average forward propagation time taken(ms): 4.2762612469310115
Average backward propagation time taken(ms): 1.5730620342865578

