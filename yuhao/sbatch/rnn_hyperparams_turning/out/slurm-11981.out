# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.0003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-04-00-24/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-04-00-24/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 16,
 'epochs': 100,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 8,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.0003,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 1,
 'num_workers': 8,
 'number_of_mlp_layer': 0,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-18-04-00-24',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 100, 'learning_rate': 0.0003, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.49520 acc 0.33333 roc_auc 0.42940 prc_auc 0.64570[0m
[93maverage test of epoch 0: loss -0.87571 acc 0.34211 roc_auc 0.20923 prc_auc 0.57119[0m
[92maverage training of epoch 1: loss -1.18115 acc 0.40667 roc_auc 0.43200 prc_auc 0.64755[0m
[93maverage test of epoch 1: loss -1.47495 acc 0.65789 roc_auc 0.22154 prc_auc 0.58214[0m
[92maverage training of epoch 2: loss -1.75409 acc 0.66667 roc_auc 0.43780 prc_auc 0.65726[0m
[93maverage test of epoch 2: loss -2.03690 acc 0.65789 roc_auc 0.44615 prc_auc 0.73768[0m
[92maverage training of epoch 3: loss -2.38653 acc 0.66667 roc_auc 0.43340 prc_auc 0.64935[0m
[93maverage test of epoch 3: loss -2.71993 acc 0.65789 roc_auc 0.87385 prc_auc 0.92052[0m
[92maverage training of epoch 4: loss -3.10665 acc 0.66667 roc_auc 0.43420 prc_auc 0.64935[0m
[93maverage test of epoch 4: loss -3.47239 acc 0.65789 roc_auc 0.87385 prc_auc 0.93448[0m
[92maverage training of epoch 5: loss -3.82743 acc 0.66667 roc_auc 0.41880 prc_auc 0.64028[0m
[93maverage test of epoch 5: loss -4.10682 acc 0.65789 roc_auc 0.87538 prc_auc 0.93448[0m
[92maverage training of epoch 6: loss -4.38619 acc 0.66667 roc_auc 0.40020 prc_auc 0.62842[0m
[93maverage test of epoch 6: loss -4.59034 acc 0.65789 roc_auc 0.87692 prc_auc 0.93781[0m
[92maverage training of epoch 7: loss -4.82671 acc 0.66667 roc_auc 0.40320 prc_auc 0.62483[0m
[93maverage test of epoch 7: loss -4.99418 acc 0.65789 roc_auc 0.87692 prc_auc 0.93811[0m
[92maverage training of epoch 8: loss -5.21036 acc 0.66667 roc_auc 0.40820 prc_auc 0.63317[0m
[93maverage test of epoch 8: loss -5.35962 acc 0.65789 roc_auc 0.87692 prc_auc 0.93811[0m
[92maverage training of epoch 9: loss -5.56540 acc 0.66667 roc_auc 0.42140 prc_auc 0.64186[0m
[93maverage test of epoch 9: loss -5.70485 acc 0.65789 roc_auc 0.87385 prc_auc 0.93633[0m
[92maverage training of epoch 10: loss -5.90522 acc 0.66667 roc_auc 0.43380 prc_auc 0.65125[0m
[93maverage test of epoch 10: loss -6.03947 acc 0.65789 roc_auc 0.86923 prc_auc 0.93534[0m
[92maverage training of epoch 11: loss -6.23733 acc 0.66667 roc_auc 0.43460 prc_auc 0.65546[0m
[93maverage test of epoch 11: loss -6.36923 acc 0.65789 roc_auc 0.86308 prc_auc 0.93340[0m
[92maverage training of epoch 12: loss -6.56628 acc 0.66667 roc_auc 0.45000 prc_auc 0.66208[0m
[93maverage test of epoch 12: loss -6.69767 acc 0.65789 roc_auc 0.86000 prc_auc 0.93174[0m
[92maverage training of epoch 13: loss -6.89486 acc 0.66667 roc_auc 0.45460 prc_auc 0.66469[0m
[93maverage test of epoch 13: loss -7.02680 acc 0.65789 roc_auc 0.86769 prc_auc 0.93768[0m
[92maverage training of epoch 14: loss -7.22447 acc 0.66667 roc_auc 0.45180 prc_auc 0.65982[0m
[93maverage test of epoch 14: loss -7.35733 acc 0.65789 roc_auc 0.86615 prc_auc 0.93768[0m
[92maverage training of epoch 15: loss -7.55529 acc 0.66667 roc_auc 0.44060 prc_auc 0.65372[0m
[93maverage test of epoch 15: loss -7.68875 acc 0.65789 roc_auc 0.86769 prc_auc 0.93768[0m
[92maverage training of epoch 16: loss -7.88649 acc 0.66667 roc_auc 0.42680 prc_auc 0.64414[0m
[93maverage test of epoch 16: loss -8.01985 acc 0.65789 roc_auc 0.86923 prc_auc 0.93768[0m
[92maverage training of epoch 17: loss -8.21679 acc 0.66667 roc_auc 0.41580 prc_auc 0.63448[0m
[93maverage test of epoch 17: loss -8.34924 acc 0.65789 roc_auc 0.87385 prc_auc 0.94200[0m
[92maverage training of epoch 18: loss -8.54503 acc 0.66667 roc_auc 0.40060 prc_auc 0.62424[0m
[93maverage test of epoch 18: loss -8.67593 acc 0.65789 roc_auc 0.87385 prc_auc 0.94034[0m
[92maverage training of epoch 19: loss -8.87046 acc 0.66667 roc_auc 0.38910 prc_auc 0.61649[0m
[93maverage test of epoch 19: loss -8.99943 acc 0.65789 roc_auc 0.87385 prc_auc 0.94114[0m
[92maverage training of epoch 20: loss -9.19280 acc 0.66667 roc_auc 0.38800 prc_auc 0.61404[0m
[93maverage test of epoch 20: loss -9.31967 acc 0.65789 roc_auc 0.87077 prc_auc 0.93849[0m
[92maverage training of epoch 21: loss -9.51208 acc 0.66667 roc_auc 0.38580 prc_auc 0.60952[0m
[93maverage test of epoch 21: loss -9.63687 acc 0.65789 roc_auc 0.87231 prc_auc 0.94021[0m
[92maverage training of epoch 22: loss -9.82855 acc 0.66667 roc_auc 0.38120 prc_auc 0.60006[0m
[93maverage test of epoch 22: loss -9.95133 acc 0.65789 roc_auc 0.89385 prc_auc 0.94201[0m
[92maverage training of epoch 23: loss -10.14252 acc 0.66667 roc_auc 0.37510 prc_auc 0.59259[0m
[93maverage test of epoch 23: loss -10.26339 acc 0.65789 roc_auc 0.88923 prc_auc 0.93711[0m
[92maverage training of epoch 24: loss -10.45430 acc 0.66667 roc_auc 0.37280 prc_auc 0.59160[0m
[93maverage test of epoch 24: loss -10.57340 acc 0.65789 roc_auc 0.89077 prc_auc 0.93958[0m
[92maverage training of epoch 25: loss -10.76420 acc 0.66667 roc_auc 0.37220 prc_auc 0.59098[0m
[93maverage test of epoch 25: loss -10.88165 acc 0.65789 roc_auc 0.85692 prc_auc 0.91376[0m
[92maverage training of epoch 26: loss -11.07249 acc 0.66667 roc_auc 0.37110 prc_auc 0.59001[0m
[93maverage test of epoch 26: loss -11.18840 acc 0.65789 roc_auc 0.90154 prc_auc 0.92847[0m
[92maverage training of epoch 27: loss -11.37941 acc 0.66667 roc_auc 0.36950 prc_auc 0.58918[0m
[93maverage test of epoch 27: loss -11.49387 acc 0.65789 roc_auc 0.84308 prc_auc 0.89911[0m
[92maverage training of epoch 28: loss -11.68514 acc 0.66667 roc_auc 0.36660 prc_auc 0.57861[0m
[93maverage test of epoch 28: loss -11.79824 acc 0.65789 roc_auc 0.84000 prc_auc 0.88766[0m
[92maverage training of epoch 29: loss -11.98988 acc 0.66667 roc_auc 0.36310 prc_auc 0.56711[0m
[93maverage test of epoch 29: loss -12.10169 acc 0.65789 roc_auc 0.81231 prc_auc 0.86834[0m
[92maverage training of epoch 30: loss -12.29375 acc 0.66667 roc_auc 0.36080 prc_auc 0.56522[0m
[93maverage test of epoch 30: loss -12.40433 acc 0.65789 roc_auc 0.72000 prc_auc 0.80842[0m
[92maverage training of epoch 31: loss -12.59688 acc 0.66667 roc_auc 0.35960 prc_auc 0.56455[0m
[93maverage test of epoch 31: loss -12.70629 acc 0.65789 roc_auc 0.72000 prc_auc 0.80842[0m
[92maverage training of epoch 32: loss -12.89938 acc 0.66667 roc_auc 0.35870 prc_auc 0.56315[0m
[93maverage test of epoch 32: loss -13.00766 acc 0.65789 roc_auc 0.81846 prc_auc 0.86456[0m
[92maverage training of epoch 33: loss -13.20134 acc 0.66667 roc_auc 0.35790 prc_auc 0.56307[0m
[93maverage test of epoch 33: loss -13.30853 acc 0.65789 roc_auc 0.72000 prc_auc 0.80842[0m
[92maverage training of epoch 34: loss -13.50282 acc 0.66667 roc_auc 0.35790 prc_auc 0.56312[0m
[93maverage test of epoch 34: loss -13.60895 acc 0.65789 roc_auc 0.64000 prc_auc 0.75368[0m
[92maverage training of epoch 35: loss -13.80389 acc 0.66667 roc_auc 0.35780 prc_auc 0.56252[0m
[93maverage test of epoch 35: loss -13.90899 acc 0.65789 roc_auc 0.52000 prc_auc 0.67158[0m
[92maverage training of epoch 36: loss -14.10462 acc 0.66667 roc_auc 0.35770 prc_auc 0.56229[0m
[93maverage test of epoch 36: loss -14.20871 acc 0.65789 roc_auc 0.52000 prc_auc 0.67158[0m
[92maverage training of epoch 37: loss -14.40503 acc 0.66667 roc_auc 0.35760 prc_auc 0.56242[0m
[93maverage test of epoch 37: loss -14.50814 acc 0.65789 roc_auc 0.52000 prc_auc 0.67158[0m
[92maverage training of epoch 38: loss -14.70518 acc 0.66667 roc_auc 0.35780 prc_auc 0.56242[0m
[93maverage test of epoch 38: loss -14.80732 acc 0.65789 roc_auc 0.76154 prc_auc 0.82566[0m
[92maverage training of epoch 39: loss -15.00510 acc 0.66667 roc_auc 0.35750 prc_auc 0.56199[0m
[93maverage test of epoch 39: loss -15.10628 acc 0.65789 roc_auc 0.52000 prc_auc 0.67158[0m
[92maverage training of epoch 40: loss -15.30482 acc 0.66667 roc_auc 0.35760 prc_auc 0.56201[0m
[93maverage test of epoch 40: loss -15.40506 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -15.60436 acc 0.66667 roc_auc 0.35730 prc_auc 0.56193[0m
[93maverage test of epoch 41: loss -15.70368 acc 0.65789 roc_auc 0.52000 prc_auc 0.67158[0m
[92maverage training of epoch 42: loss -15.90375 acc 0.66667 roc_auc 0.35740 prc_auc 0.56214[0m
[93maverage test of epoch 42: loss -16.00215 acc 0.65789 roc_auc 0.65385 prc_auc 0.73529[0m
[92maverage training of epoch 43: loss -16.20300 acc 0.66667 roc_auc 0.35720 prc_auc 0.56224[0m
[93maverage test of epoch 43: loss -16.30049 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -16.50214 acc 0.66667 roc_auc 0.35740 prc_auc 0.56225[0m
[93maverage test of epoch 44: loss -16.59873 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -16.80118 acc 0.66667 roc_auc 0.35740 prc_auc 0.56216[0m
[93maverage test of epoch 45: loss -16.89687 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -17.10012 acc 0.66667 roc_auc 0.35730 prc_auc 0.56191[0m
[93maverage test of epoch 46: loss -17.19492 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -17.39899 acc 0.66667 roc_auc 0.35730 prc_auc 0.56206[0m
[93maverage test of epoch 47: loss -17.49291 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -17.69779 acc 0.66667 roc_auc 0.35770 prc_auc 0.56200[0m
[93maverage test of epoch 48: loss -17.79083 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -17.99652 acc 0.66667 roc_auc 0.35760 prc_auc 0.56217[0m
[93maverage test of epoch 49: loss -18.08869 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 50: loss -18.29521 acc 0.66667 roc_auc 0.35740 prc_auc 0.56189[0m
[93maverage test of epoch 50: loss -18.38650 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 51: loss -18.59385 acc 0.66667 roc_auc 0.35770 prc_auc 0.56284[0m
[93maverage test of epoch 51: loss -18.68427 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 52: loss -18.89244 acc 0.66667 roc_auc 0.35760 prc_auc 0.56232[0m
[93maverage test of epoch 52: loss -18.98199 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 53: loss -19.19100 acc 0.66667 roc_auc 0.35780 prc_auc 0.56267[0m
[93maverage test of epoch 53: loss -19.27969 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 54: loss -19.48953 acc 0.66667 roc_auc 0.35750 prc_auc 0.56248[0m
[93maverage test of epoch 54: loss -19.57735 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 55: loss -19.78803 acc 0.66667 roc_auc 0.35830 prc_auc 0.56219[0m
[93maverage test of epoch 55: loss -19.87499 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 56: loss -20.08650 acc 0.66667 roc_auc 0.35800 prc_auc 0.56330[0m
[93maverage test of epoch 56: loss -20.17260 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 57: loss -20.38495 acc 0.66667 roc_auc 0.35800 prc_auc 0.56308[0m
[93maverage test of epoch 57: loss -20.47019 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 58: loss -20.68339 acc 0.66667 roc_auc 0.35760 prc_auc 0.56275[0m
[93maverage test of epoch 58: loss -20.76776 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 59: loss -20.98180 acc 0.66667 roc_auc 0.35800 prc_auc 0.56351[0m
[93maverage test of epoch 59: loss -21.06532 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 60: loss -21.28020 acc 0.66667 roc_auc 0.35790 prc_auc 0.56465[0m
[93maverage test of epoch 60: loss -21.36286 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 61: loss -21.57858 acc 0.66667 roc_auc 0.35840 prc_auc 0.56435[0m
[93maverage test of epoch 61: loss -21.66039 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 62: loss -21.87696 acc 0.66667 roc_auc 0.35840 prc_auc 0.56453[0m
[93maverage test of epoch 62: loss -21.95791 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 63: loss -22.17532 acc 0.66667 roc_auc 0.35900 prc_auc 0.56353[0m
[93maverage test of epoch 63: loss -22.25541 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 64: loss -22.47367 acc 0.66667 roc_auc 0.35790 prc_auc 0.56423[0m
[93maverage test of epoch 64: loss -22.55291 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 65: loss -22.77201 acc 0.66667 roc_auc 0.35800 prc_auc 0.56278[0m
[93maverage test of epoch 65: loss -22.85040 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 66: loss -23.07035 acc 0.66667 roc_auc 0.35950 prc_auc 0.56407[0m
[93maverage test of epoch 66: loss -23.14788 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 67: loss -23.36867 acc 0.66667 roc_auc 0.35770 prc_auc 0.56484[0m
[93maverage test of epoch 67: loss -23.44535 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 68: loss -23.66700 acc 0.66667 roc_auc 0.35930 prc_auc 0.56557[0m
[93maverage test of epoch 68: loss -23.74282 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 69: loss -23.96531 acc 0.66667 roc_auc 0.36010 prc_auc 0.56618[0m
[93maverage test of epoch 69: loss -24.04028 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 70: loss -24.26362 acc 0.66667 roc_auc 0.35680 prc_auc 0.56462[0m
[93maverage test of epoch 70: loss -24.33774 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 71: loss -24.56193 acc 0.66667 roc_auc 0.36060 prc_auc 0.56621[0m
[93maverage test of epoch 71: loss -24.63519 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 72: loss -24.86023 acc 0.66667 roc_auc 0.36070 prc_auc 0.56633[0m
[93maverage test of epoch 72: loss -24.93264 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 73: loss -25.15853 acc 0.66667 roc_auc 0.35990 prc_auc 0.56605[0m
[93maverage test of epoch 73: loss -25.23009 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 74: loss -25.45682 acc 0.66667 roc_auc 0.35990 prc_auc 0.56753[0m
[93maverage test of epoch 74: loss -25.52753 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 75: loss -25.75512 acc 0.66667 roc_auc 0.35830 prc_auc 0.56656[0m
[93maverage test of epoch 75: loss -25.82497 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 76: loss -26.05340 acc 0.66667 roc_auc 0.35930 prc_auc 0.56855[0m
[93maverage test of epoch 76: loss -26.12241 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 77: loss -26.35169 acc 0.66667 roc_auc 0.36200 prc_auc 0.56911[0m
[93maverage test of epoch 77: loss -26.41984 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 78: loss -26.64997 acc 0.66667 roc_auc 0.36120 prc_auc 0.56998[0m
[93maverage test of epoch 78: loss -26.71727 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 79: loss -26.94826 acc 0.66667 roc_auc 0.36190 prc_auc 0.57325[0m
[93maverage test of epoch 79: loss -27.01471 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 80: loss -27.24654 acc 0.66667 roc_auc 0.35800 prc_auc 0.57292[0m
[93maverage test of epoch 80: loss -27.31214 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 81: loss -27.54482 acc 0.66667 roc_auc 0.36170 prc_auc 0.57331[0m
[93maverage test of epoch 81: loss -27.60957 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 82: loss -27.84310 acc 0.66667 roc_auc 0.36590 prc_auc 0.57442[0m
[93maverage test of epoch 82: loss -27.90699 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 83: loss -28.14137 acc 0.66667 roc_auc 0.35960 prc_auc 0.57079[0m
[93maverage test of epoch 83: loss -28.20442 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 84: loss -28.43965 acc 0.66667 roc_auc 0.36260 prc_auc 0.57333[0m
[93maverage test of epoch 84: loss -28.50184 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 85: loss -28.73792 acc 0.66667 roc_auc 0.36190 prc_auc 0.57755[0m
[93maverage test of epoch 85: loss -28.79927 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 86: loss -29.03620 acc 0.66667 roc_auc 0.36710 prc_auc 0.57867[0m
[93maverage test of epoch 86: loss -29.09669 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 87: loss -29.33447 acc 0.66667 roc_auc 0.35610 prc_auc 0.57728[0m
[93maverage test of epoch 87: loss -29.39411 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 88: loss -29.63275 acc 0.66667 roc_auc 0.36210 prc_auc 0.57685[0m
[93maverage test of epoch 88: loss -29.69154 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 89: loss -29.93102 acc 0.66667 roc_auc 0.36870 prc_auc 0.58148[0m
[93maverage test of epoch 89: loss -29.98896 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -30.22929 acc 0.66667 roc_auc 0.36790 prc_auc 0.58646[0m
[93maverage test of epoch 90: loss -30.28638 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 91: loss -30.52756 acc 0.66667 roc_auc 0.37120 prc_auc 0.58552[0m
[93maverage test of epoch 91: loss -30.58380 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 92: loss -30.82583 acc 0.66667 roc_auc 0.36190 prc_auc 0.57999[0m
[93maverage test of epoch 92: loss -30.88121 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 93: loss -31.12410 acc 0.66667 roc_auc 0.36120 prc_auc 0.58219[0m
[93maverage test of epoch 93: loss -31.17863 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 94: loss -31.42237 acc 0.66667 roc_auc 0.35690 prc_auc 0.58243[0m
[93maverage test of epoch 94: loss -31.47605 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 95: loss -31.72063 acc 0.66667 roc_auc 0.36540 prc_auc 0.58842[0m
[93maverage test of epoch 95: loss -31.77347 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 96: loss -32.01890 acc 0.66667 roc_auc 0.36960 prc_auc 0.59044[0m
[93maverage test of epoch 96: loss -32.07089 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 97: loss -32.31717 acc 0.66667 roc_auc 0.37320 prc_auc 0.59257[0m
[93maverage test of epoch 97: loss -32.36830 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 98: loss -32.61544 acc 0.66667 roc_auc 0.36050 prc_auc 0.58900[0m
[93maverage test of epoch 98: loss -32.66572 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -32.91370 acc 0.66667 roc_auc 0.37920 prc_auc 0.60194[0m
[93maverage test of epoch 99: loss -32.96314 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.06695 acc 0.66667 roc_auc 0.46460 prc_auc 0.65895[0m
[93maverage test of epoch 0: loss -0.52892 acc 0.65789 roc_auc 0.80308 prc_auc 0.89292[0m
[92maverage training of epoch 1: loss -1.20099 acc 0.66667 roc_auc 0.47900 prc_auc 0.66081[0m
[93maverage test of epoch 1: loss -1.85957 acc 0.65789 roc_auc 0.76000 prc_auc 0.84619[0m
[92maverage training of epoch 2: loss -2.36193 acc 0.66667 roc_auc 0.47480 prc_auc 0.65975[0m
[93maverage test of epoch 2: loss -2.87421 acc 0.65789 roc_auc 0.61231 prc_auc 0.76662[0m
[92maverage training of epoch 3: loss -3.43856 acc 0.66667 roc_auc 0.47420 prc_auc 0.65981[0m
[93maverage test of epoch 3: loss -4.01289 acc 0.65789 roc_auc 0.81846 prc_auc 0.87198[0m
[92maverage training of epoch 4: loss -4.44388 acc 0.66667 roc_auc 0.45260 prc_auc 0.63544[0m
[93maverage test of epoch 4: loss -4.76711 acc 0.65789 roc_auc 0.74462 prc_auc 0.85127[0m
[92maverage training of epoch 5: loss -5.02891 acc 0.66667 roc_auc 0.43100 prc_auc 0.61896[0m
[93maverage test of epoch 5: loss -5.24476 acc 0.65789 roc_auc 0.72308 prc_auc 0.85111[0m
[92maverage training of epoch 6: loss -5.46170 acc 0.66667 roc_auc 0.42380 prc_auc 0.60979[0m
[93maverage test of epoch 6: loss -5.63926 acc 0.65789 roc_auc 0.72000 prc_auc 0.84723[0m
[92maverage training of epoch 7: loss -5.83557 acc 0.66667 roc_auc 0.42170 prc_auc 0.60891[0m
[93maverage test of epoch 7: loss -5.99317 acc 0.65789 roc_auc 0.72923 prc_auc 0.85424[0m
[92maverage training of epoch 8: loss -6.17819 acc 0.66667 roc_auc 0.42180 prc_auc 0.60957[0m
[93maverage test of epoch 8: loss -6.32390 acc 0.65789 roc_auc 0.72462 prc_auc 0.84926[0m
[92maverage training of epoch 9: loss -6.50256 acc 0.66667 roc_auc 0.42620 prc_auc 0.61420[0m
[93maverage test of epoch 9: loss -6.64139 acc 0.65789 roc_auc 0.72923 prc_auc 0.85171[0m
[92maverage training of epoch 10: loss -6.81832 acc 0.66667 roc_auc 0.43440 prc_auc 0.63302[0m
[93maverage test of epoch 10: loss -6.95678 acc 0.65789 roc_auc 0.60769 prc_auc 0.80450[0m
[92maverage training of epoch 11: loss -7.14428 acc 0.66667 roc_auc 0.44940 prc_auc 0.65206[0m
[93maverage test of epoch 11: loss -7.30078 acc 0.65789 roc_auc 0.42462 prc_auc 0.72866[0m
[92maverage training of epoch 12: loss -7.51334 acc 0.66667 roc_auc 0.35890 prc_auc 0.59229[0m
[93maverage test of epoch 12: loss -7.68568 acc 0.65789 roc_auc 0.18462 prc_auc 0.57163[0m
[92maverage training of epoch 13: loss -7.89432 acc 0.66667 roc_auc 0.39800 prc_auc 0.59977[0m
[93maverage test of epoch 13: loss -8.05790 acc 0.65789 roc_auc 0.14462 prc_auc 0.54494[0m
[92maverage training of epoch 14: loss -8.25782 acc 0.66667 roc_auc 0.40860 prc_auc 0.60131[0m
[93maverage test of epoch 14: loss -8.41173 acc 0.65789 roc_auc 0.16308 prc_auc 0.55116[0m
[92maverage training of epoch 15: loss -8.60515 acc 0.66667 roc_auc 0.41300 prc_auc 0.60172[0m
[93maverage test of epoch 15: loss -8.75165 acc 0.65789 roc_auc 0.16769 prc_auc 0.55057[0m
[92maverage training of epoch 16: loss -8.94087 acc 0.66667 roc_auc 0.41700 prc_auc 0.60420[0m
[93maverage test of epoch 16: loss -9.08190 acc 0.65789 roc_auc 0.16923 prc_auc 0.55751[0m
[92maverage training of epoch 17: loss -9.26847 acc 0.66667 roc_auc 0.41860 prc_auc 0.60821[0m
[93maverage test of epoch 17: loss -9.40534 acc 0.65789 roc_auc 0.16000 prc_auc 0.55589[0m
[92maverage training of epoch 18: loss -9.59023 acc 0.66667 roc_auc 0.41940 prc_auc 0.60997[0m
[93maverage test of epoch 18: loss -9.72379 acc 0.65789 roc_auc 0.16000 prc_auc 0.55980[0m
[92maverage training of epoch 19: loss -9.90764 acc 0.66667 roc_auc 0.42040 prc_auc 0.60799[0m
[93maverage test of epoch 19: loss -10.03846 acc 0.65789 roc_auc 0.16000 prc_auc 0.57742[0m
[92maverage training of epoch 20: loss -10.22171 acc 0.66667 roc_auc 0.42050 prc_auc 0.60802[0m
[93maverage test of epoch 20: loss -10.35019 acc 0.65789 roc_auc 0.15846 prc_auc 0.58415[0m
[92maverage training of epoch 21: loss -10.53315 acc 0.66667 roc_auc 0.42130 prc_auc 0.60933[0m
[93maverage test of epoch 21: loss -10.65959 acc 0.65789 roc_auc 0.21077 prc_auc 0.61552[0m
[92maverage training of epoch 22: loss -10.84249 acc 0.66667 roc_auc 0.42140 prc_auc 0.60976[0m
[93maverage test of epoch 22: loss -10.96712 acc 0.65789 roc_auc 0.21538 prc_auc 0.67713[0m
[92maverage training of epoch 23: loss -11.15013 acc 0.66667 roc_auc 0.42120 prc_auc 0.60908[0m
[93maverage test of epoch 23: loss -11.27310 acc 0.65789 roc_auc 0.31692 prc_auc 0.67713[0m
[92maverage training of epoch 24: loss -11.45636 acc 0.66667 roc_auc 0.42100 prc_auc 0.60758[0m
[93maverage test of epoch 24: loss -11.57782 acc 0.65789 roc_auc 0.38000 prc_auc 0.63053[0m
[92maverage training of epoch 25: loss -11.76142 acc 0.66667 roc_auc 0.42090 prc_auc 0.60663[0m
[93maverage test of epoch 25: loss -11.88148 acc 0.65789 roc_auc 0.36308 prc_auc 0.68526[0m
[92maverage training of epoch 26: loss -12.06552 acc 0.66667 roc_auc 0.42070 prc_auc 0.60595[0m
[93maverage test of epoch 26: loss -12.18425 acc 0.65789 roc_auc 0.35538 prc_auc 0.62794[0m
[92maverage training of epoch 27: loss -12.36879 acc 0.66667 roc_auc 0.42060 prc_auc 0.60551[0m
[93maverage test of epoch 27: loss -12.48628 acc 0.65789 roc_auc 0.41692 prc_auc 0.65251[0m
[92maverage training of epoch 28: loss -12.67137 acc 0.66667 roc_auc 0.42050 prc_auc 0.60510[0m
[93maverage test of epoch 28: loss -12.78767 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 29: loss -12.97336 acc 0.66667 roc_auc 0.42050 prc_auc 0.60507[0m
[93maverage test of epoch 29: loss -13.08852 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 30: loss -13.27485 acc 0.66667 roc_auc 0.42040 prc_auc 0.60491[0m
[93maverage test of epoch 30: loss -13.38891 acc 0.65789 roc_auc 0.46923 prc_auc 0.68526[0m
[92maverage training of epoch 31: loss -13.57591 acc 0.66667 roc_auc 0.42060 prc_auc 0.60502[0m
[93maverage test of epoch 31: loss -13.68891 acc 0.65789 roc_auc 0.54462 prc_auc 0.69663[0m
[92maverage training of epoch 32: loss -13.87661 acc 0.66667 roc_auc 0.42040 prc_auc 0.60495[0m
[93maverage test of epoch 32: loss -13.98857 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 33: loss -14.17699 acc 0.66667 roc_auc 0.42060 prc_auc 0.60507[0m
[93maverage test of epoch 33: loss -14.28794 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 34: loss -14.47709 acc 0.66667 roc_auc 0.42050 prc_auc 0.60507[0m
[93maverage test of epoch 34: loss -14.58706 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 35: loss -14.77697 acc 0.66667 roc_auc 0.42020 prc_auc 0.60455[0m
[93maverage test of epoch 35: loss -14.88596 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 36: loss -15.07664 acc 0.66667 roc_auc 0.42030 prc_auc 0.60455[0m
[93maverage test of epoch 36: loss -15.18468 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 37: loss -15.37613 acc 0.66667 roc_auc 0.42020 prc_auc 0.60455[0m
[93maverage test of epoch 37: loss -15.48323 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 38: loss -15.67547 acc 0.66667 roc_auc 0.42030 prc_auc 0.60458[0m
[93maverage test of epoch 38: loss -15.78164 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 39: loss -15.97468 acc 0.66667 roc_auc 0.42030 prc_auc 0.60458[0m
[93maverage test of epoch 39: loss -16.07994 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 40: loss -16.27378 acc 0.66667 roc_auc 0.42030 prc_auc 0.60458[0m
[93maverage test of epoch 40: loss -16.37812 acc 0.65789 roc_auc 0.61077 prc_auc 0.71889[0m
[92maverage training of epoch 41: loss -16.57278 acc 0.66667 roc_auc 0.42020 prc_auc 0.60497[0m
[93maverage test of epoch 41: loss -16.67622 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 42: loss -16.87169 acc 0.66667 roc_auc 0.42030 prc_auc 0.60500[0m
[93maverage test of epoch 42: loss -16.97423 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 43: loss -17.17053 acc 0.66667 roc_auc 0.42030 prc_auc 0.60500[0m
[93maverage test of epoch 43: loss -17.27218 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 44: loss -17.46929 acc 0.66667 roc_auc 0.42030 prc_auc 0.60461[0m
[93maverage test of epoch 44: loss -17.57006 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 45: loss -17.76801 acc 0.66667 roc_auc 0.42030 prc_auc 0.60458[0m
[93maverage test of epoch 45: loss -17.86789 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 46: loss -18.06667 acc 0.66667 roc_auc 0.42030 prc_auc 0.60500[0m
[93maverage test of epoch 46: loss -18.16568 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 47: loss -18.36529 acc 0.66667 roc_auc 0.42010 prc_auc 0.60499[0m
[93maverage test of epoch 47: loss -18.46342 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 48: loss -18.66387 acc 0.66667 roc_auc 0.42030 prc_auc 0.60492[0m
[93maverage test of epoch 48: loss -18.76113 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 49: loss -18.96241 acc 0.66667 roc_auc 0.42030 prc_auc 0.60494[0m
[93maverage test of epoch 49: loss -19.05881 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 50: loss -19.26093 acc 0.66667 roc_auc 0.42020 prc_auc 0.60550[0m
[93maverage test of epoch 50: loss -19.35646 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 51: loss -19.55942 acc 0.66667 roc_auc 0.42040 prc_auc 0.60497[0m
[93maverage test of epoch 51: loss -19.65408 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 52: loss -19.85789 acc 0.66667 roc_auc 0.42040 prc_auc 0.60544[0m
[93maverage test of epoch 52: loss -19.95169 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 53: loss -20.15634 acc 0.66667 roc_auc 0.42090 prc_auc 0.60555[0m
[93maverage test of epoch 53: loss -20.24928 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 54: loss -20.45477 acc 0.66667 roc_auc 0.42040 prc_auc 0.60561[0m
[93maverage test of epoch 54: loss -20.54685 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 55: loss -20.75319 acc 0.66667 roc_auc 0.42080 prc_auc 0.60549[0m
[93maverage test of epoch 55: loss -20.84440 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 56: loss -21.05159 acc 0.66667 roc_auc 0.42080 prc_auc 0.60590[0m
[93maverage test of epoch 56: loss -21.14195 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 57: loss -21.34998 acc 0.66667 roc_auc 0.42070 prc_auc 0.60520[0m
[93maverage test of epoch 57: loss -21.43948 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 58: loss -21.64836 acc 0.66667 roc_auc 0.42030 prc_auc 0.60426[0m
[93maverage test of epoch 58: loss -21.73700 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 59: loss -21.94673 acc 0.66667 roc_auc 0.42080 prc_auc 0.60587[0m
[93maverage test of epoch 59: loss -22.03452 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 60: loss -22.24509 acc 0.66667 roc_auc 0.42030 prc_auc 0.60540[0m
[93maverage test of epoch 60: loss -22.33202 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 61: loss -22.54344 acc 0.66667 roc_auc 0.42100 prc_auc 0.60602[0m
[93maverage test of epoch 61: loss -22.62952 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 62: loss -22.84179 acc 0.66667 roc_auc 0.42000 prc_auc 0.60534[0m
[93maverage test of epoch 62: loss -22.92701 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 63: loss -23.14012 acc 0.66667 roc_auc 0.42040 prc_auc 0.60567[0m
[93maverage test of epoch 63: loss -23.22449 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 64: loss -23.43846 acc 0.66667 roc_auc 0.42040 prc_auc 0.60580[0m
[93maverage test of epoch 64: loss -23.52197 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 65: loss -23.73679 acc 0.66667 roc_auc 0.42070 prc_auc 0.60383[0m
[93maverage test of epoch 65: loss -23.81944 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 66: loss -24.03511 acc 0.66667 roc_auc 0.42030 prc_auc 0.60593[0m
[93maverage test of epoch 66: loss -24.11692 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 67: loss -24.33343 acc 0.66667 roc_auc 0.42060 prc_auc 0.60390[0m
[93maverage test of epoch 67: loss -24.41438 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 68: loss -24.63175 acc 0.66667 roc_auc 0.42070 prc_auc 0.60420[0m
[93maverage test of epoch 68: loss -24.71185 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 69: loss -24.93006 acc 0.66667 roc_auc 0.42010 prc_auc 0.60434[0m
[93maverage test of epoch 69: loss -25.00931 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 70: loss -25.22837 acc 0.66667 roc_auc 0.42200 prc_auc 0.60439[0m
[93maverage test of epoch 70: loss -25.30677 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 71: loss -25.52668 acc 0.66667 roc_auc 0.41990 prc_auc 0.60447[0m
[93maverage test of epoch 71: loss -25.60422 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 72: loss -25.82499 acc 0.66667 roc_auc 0.42000 prc_auc 0.60325[0m
[93maverage test of epoch 72: loss -25.90168 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 73: loss -26.12329 acc 0.66667 roc_auc 0.42160 prc_auc 0.60627[0m
[93maverage test of epoch 73: loss -26.19913 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 74: loss -26.42159 acc 0.66667 roc_auc 0.42220 prc_auc 0.60554[0m
[93maverage test of epoch 74: loss -26.49658 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 75: loss -26.71989 acc 0.66667 roc_auc 0.42110 prc_auc 0.60341[0m
[93maverage test of epoch 75: loss -26.79403 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 76: loss -27.01819 acc 0.66667 roc_auc 0.41930 prc_auc 0.60369[0m
[93maverage test of epoch 76: loss -27.09147 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 77: loss -27.31649 acc 0.66667 roc_auc 0.42030 prc_auc 0.60011[0m
[93maverage test of epoch 77: loss -27.38892 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 78: loss -27.61478 acc 0.66667 roc_auc 0.42080 prc_auc 0.60433[0m
[93maverage test of epoch 78: loss -27.68637 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 79: loss -27.91308 acc 0.66667 roc_auc 0.42100 prc_auc 0.60473[0m
[93maverage test of epoch 79: loss -27.98381 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 80: loss -28.21137 acc 0.66667 roc_auc 0.41950 prc_auc 0.60015[0m
[93maverage test of epoch 80: loss -28.28125 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 81: loss -28.50966 acc 0.66667 roc_auc 0.42070 prc_auc 0.60614[0m
[93maverage test of epoch 81: loss -28.57869 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 82: loss -28.80795 acc 0.66667 roc_auc 0.42440 prc_auc 0.60674[0m
[93maverage test of epoch 82: loss -28.87613 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 83: loss -29.10624 acc 0.66667 roc_auc 0.42060 prc_auc 0.60256[0m
[93maverage test of epoch 83: loss -29.17357 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 84: loss -29.40453 acc 0.66667 roc_auc 0.42110 prc_auc 0.59955[0m
[93maverage test of epoch 84: loss -29.47101 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 85: loss -29.70282 acc 0.66667 roc_auc 0.41890 prc_auc 0.60131[0m
[93maverage test of epoch 85: loss -29.76845 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 86: loss -30.00111 acc 0.66667 roc_auc 0.41570 prc_auc 0.59607[0m
[93maverage test of epoch 86: loss -30.06589 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 87: loss -30.29940 acc 0.66667 roc_auc 0.41730 prc_auc 0.59808[0m
[93maverage test of epoch 87: loss -30.36332 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 88: loss -30.59769 acc 0.66667 roc_auc 0.42100 prc_auc 0.60434[0m
[93maverage test of epoch 88: loss -30.66076 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 89: loss -30.89598 acc 0.66667 roc_auc 0.42370 prc_auc 0.60755[0m
[93maverage test of epoch 89: loss -30.95821 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -31.19427 acc 0.66667 roc_auc 0.42110 prc_auc 0.60492[0m
[93maverage test of epoch 90: loss -31.25565 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 91: loss -31.49257 acc 0.66667 roc_auc 0.42660 prc_auc 0.60970[0m
[93maverage test of epoch 91: loss -31.55309 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 92: loss -31.79086 acc 0.66667 roc_auc 0.42430 prc_auc 0.60696[0m
[93maverage test of epoch 92: loss -31.85053 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 93: loss -32.08915 acc 0.66667 roc_auc 0.42310 prc_auc 0.60500[0m
[93maverage test of epoch 93: loss -32.14797 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 94: loss -32.38744 acc 0.66667 roc_auc 0.42810 prc_auc 0.61581[0m
[93maverage test of epoch 94: loss -32.44542 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 95: loss -32.68573 acc 0.66667 roc_auc 0.42360 prc_auc 0.60913[0m
[93maverage test of epoch 95: loss -32.74286 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 96: loss -32.98402 acc 0.66667 roc_auc 0.42540 prc_auc 0.61130[0m
[93maverage test of epoch 96: loss -33.04029 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 97: loss -33.28231 acc 0.66667 roc_auc 0.42370 prc_auc 0.60938[0m
[93maverage test of epoch 97: loss -33.33773 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 98: loss -33.58060 acc 0.66667 roc_auc 0.41870 prc_auc 0.60601[0m
[93maverage test of epoch 98: loss -33.63518 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -33.87889 acc 0.66667 roc_auc 0.42860 prc_auc 0.61563[0m
[93maverage test of epoch 99: loss -33.93261 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.65440 acc 0.66667 roc_auc 0.40820 prc_auc 0.61875[0m
[93maverage test of epoch 0: loss -0.98147 acc 0.65789 roc_auc 0.34769 prc_auc 0.67595[0m
[92maverage training of epoch 1: loss -1.36441 acc 0.66667 roc_auc 0.45960 prc_auc 0.66364[0m
[93maverage test of epoch 1: loss -1.69960 acc 0.65789 roc_auc 0.93538 prc_auc 0.97301[0m
[92maverage training of epoch 2: loss -2.01477 acc 0.66667 roc_auc 0.49500 prc_auc 0.69328[0m
[93maverage test of epoch 2: loss -2.24183 acc 0.65789 roc_auc 0.95385 prc_auc 0.97886[0m
[92maverage training of epoch 3: loss -2.52552 acc 0.66667 roc_auc 0.49300 prc_auc 0.69129[0m
[93maverage test of epoch 3: loss -2.73126 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 4: loss -3.06462 acc 0.66667 roc_auc 0.47600 prc_auc 0.67872[0m
[93maverage test of epoch 4: loss -3.33138 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 5: loss -3.69794 acc 0.66667 roc_auc 0.46730 prc_auc 0.67452[0m
[93maverage test of epoch 5: loss -3.94363 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 6: loss -4.26125 acc 0.66667 roc_auc 0.47030 prc_auc 0.67636[0m
[93maverage test of epoch 6: loss -4.45120 acc 0.65789 roc_auc 0.94923 prc_auc 0.97644[0m
[92maverage training of epoch 7: loss -4.73814 acc 0.66667 roc_auc 0.47230 prc_auc 0.67461[0m
[93maverage test of epoch 7: loss -4.90051 acc 0.65789 roc_auc 0.94769 prc_auc 0.97555[0m
[92maverage training of epoch 8: loss -5.18222 acc 0.66667 roc_auc 0.44890 prc_auc 0.65447[0m
[93maverage test of epoch 8: loss -5.34080 acc 0.65789 roc_auc 0.94308 prc_auc 0.97317[0m
[92maverage training of epoch 9: loss -5.61752 acc 0.66667 roc_auc 0.43710 prc_auc 0.64666[0m
[93maverage test of epoch 9: loss -5.76380 acc 0.65789 roc_auc 0.94923 prc_auc 0.97574[0m
[92maverage training of epoch 10: loss -6.02670 acc 0.66667 roc_auc 0.42860 prc_auc 0.63709[0m
[93maverage test of epoch 10: loss -6.15725 acc 0.65789 roc_auc 0.94308 prc_auc 0.97246[0m
[92maverage training of epoch 11: loss -6.40928 acc 0.66667 roc_auc 0.42030 prc_auc 0.62719[0m
[93maverage test of epoch 11: loss -6.52811 acc 0.65789 roc_auc 0.94615 prc_auc 0.97264[0m
[92maverage training of epoch 12: loss -6.77286 acc 0.66667 roc_auc 0.41030 prc_auc 0.61937[0m
[93maverage test of epoch 12: loss -6.88327 acc 0.65789 roc_auc 0.94462 prc_auc 0.96900[0m
[92maverage training of epoch 13: loss -7.12306 acc 0.66667 roc_auc 0.40490 prc_auc 0.61629[0m
[93maverage test of epoch 13: loss -7.22713 acc 0.65789 roc_auc 0.94462 prc_auc 0.96571[0m
[92maverage training of epoch 14: loss -7.46345 acc 0.66667 roc_auc 0.39890 prc_auc 0.61153[0m
[93maverage test of epoch 14: loss -7.56256 acc 0.65789 roc_auc 0.92308 prc_auc 0.94862[0m
[92maverage training of epoch 15: loss -7.79640 acc 0.66667 roc_auc 0.39600 prc_auc 0.61009[0m
[93maverage test of epoch 15: loss -7.89147 acc 0.65789 roc_auc 0.94308 prc_auc 0.95520[0m
[92maverage training of epoch 16: loss -8.12354 acc 0.66667 roc_auc 0.39360 prc_auc 0.60930[0m
[93maverage test of epoch 16: loss -8.21524 acc 0.65789 roc_auc 0.91538 prc_auc 0.92854[0m
[92maverage training of epoch 17: loss -8.44604 acc 0.66667 roc_auc 0.39400 prc_auc 0.60891[0m
[93maverage test of epoch 17: loss -8.53487 acc 0.65789 roc_auc 0.90000 prc_auc 0.93158[0m
[92maverage training of epoch 18: loss -8.76480 acc 0.66667 roc_auc 0.39000 prc_auc 0.60614[0m
[93maverage test of epoch 18: loss -8.85112 acc 0.65789 roc_auc 0.74923 prc_auc 0.79432[0m
[92maverage training of epoch 19: loss -9.08048 acc 0.66667 roc_auc 0.39040 prc_auc 0.60632[0m
[93maverage test of epoch 19: loss -9.16459 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -9.39361 acc 0.66667 roc_auc 0.38880 prc_auc 0.60317[0m
[93maverage test of epoch 20: loss -9.47573 acc 0.65789 roc_auc 0.86462 prc_auc 0.87965[0m
[92maverage training of epoch 21: loss -9.70461 acc 0.66667 roc_auc 0.38860 prc_auc 0.60522[0m
[93maverage test of epoch 21: loss -9.78493 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -10.01383 acc 0.66667 roc_auc 0.38780 prc_auc 0.60030[0m
[93maverage test of epoch 22: loss -10.09249 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -10.32153 acc 0.66667 roc_auc 0.38530 prc_auc 0.59908[0m
[93maverage test of epoch 23: loss -10.39866 acc 0.65789 roc_auc 0.58000 prc_auc 0.71263[0m
[92maverage training of epoch 24: loss -10.62794 acc 0.66667 roc_auc 0.38530 prc_auc 0.59911[0m
[93maverage test of epoch 24: loss -10.70365 acc 0.65789 roc_auc 0.84308 prc_auc 0.87222[0m
[92maverage training of epoch 25: loss -10.93326 acc 0.66667 roc_auc 0.38760 prc_auc 0.60200[0m
[93maverage test of epoch 25: loss -11.00763 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -11.23764 acc 0.66667 roc_auc 0.38760 prc_auc 0.59973[0m
[93maverage test of epoch 26: loss -11.31074 acc 0.65789 roc_auc 0.80000 prc_auc 0.86316[0m
[92maverage training of epoch 27: loss -11.54122 acc 0.66667 roc_auc 0.38210 prc_auc 0.59670[0m
[93maverage test of epoch 27: loss -11.61310 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -11.84410 acc 0.66667 roc_auc 0.38370 prc_auc 0.59793[0m
[93maverage test of epoch 28: loss -11.91482 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -12.14638 acc 0.66667 roc_auc 0.38530 prc_auc 0.60105[0m
[93maverage test of epoch 29: loss -12.21599 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -12.44816 acc 0.66667 roc_auc 0.38710 prc_auc 0.60132[0m
[93maverage test of epoch 30: loss -12.51668 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -12.74948 acc 0.66667 roc_auc 0.38400 prc_auc 0.59102[0m
[93maverage test of epoch 31: loss -12.81696 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -13.05042 acc 0.66667 roc_auc 0.39030 prc_auc 0.59789[0m
[93maverage test of epoch 32: loss -13.11687 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -13.35102 acc 0.66667 roc_auc 0.38750 prc_auc 0.59399[0m
[93maverage test of epoch 33: loss -13.41647 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -13.65133 acc 0.66667 roc_auc 0.38210 prc_auc 0.58995[0m
[93maverage test of epoch 34: loss -13.71580 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -13.95139 acc 0.66667 roc_auc 0.38780 prc_auc 0.59167[0m
[93maverage test of epoch 35: loss -14.01490 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -14.25123 acc 0.66667 roc_auc 0.38230 prc_auc 0.58814[0m
[93maverage test of epoch 36: loss -14.31379 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -14.55088 acc 0.66667 roc_auc 0.38100 prc_auc 0.58371[0m
[93maverage test of epoch 37: loss -14.61250 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -14.85035 acc 0.66667 roc_auc 0.38450 prc_auc 0.58966[0m
[93maverage test of epoch 38: loss -14.91105 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -15.14968 acc 0.66667 roc_auc 0.38300 prc_auc 0.58701[0m
[93maverage test of epoch 39: loss -15.20947 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -15.44889 acc 0.66667 roc_auc 0.37860 prc_auc 0.58720[0m
[93maverage test of epoch 40: loss -15.50777 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -15.74798 acc 0.66667 roc_auc 0.38320 prc_auc 0.58792[0m
[93maverage test of epoch 41: loss -15.80595 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -16.04697 acc 0.66667 roc_auc 0.38970 prc_auc 0.59720[0m
[93maverage test of epoch 42: loss -16.10406 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -16.34588 acc 0.66667 roc_auc 0.38550 prc_auc 0.59283[0m
[93maverage test of epoch 43: loss -16.40207 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -16.64471 acc 0.66667 roc_auc 0.38820 prc_auc 0.59474[0m
[93maverage test of epoch 44: loss -16.70002 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -16.94347 acc 0.66667 roc_auc 0.38730 prc_auc 0.59384[0m
[93maverage test of epoch 45: loss -16.99791 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -17.24218 acc 0.66667 roc_auc 0.39320 prc_auc 0.60018[0m
[93maverage test of epoch 46: loss -17.29574 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -17.54084 acc 0.66667 roc_auc 0.38750 prc_auc 0.59627[0m
[93maverage test of epoch 47: loss -17.59352 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -17.83945 acc 0.66667 roc_auc 0.38140 prc_auc 0.59165[0m
[93maverage test of epoch 48: loss -17.89126 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -18.13802 acc 0.66667 roc_auc 0.38650 prc_auc 0.59792[0m
[93maverage test of epoch 49: loss -18.18897 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 50: loss -18.43656 acc 0.66667 roc_auc 0.39220 prc_auc 0.60080[0m
[93maverage test of epoch 50: loss -18.48664 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 51: loss -18.73507 acc 0.66667 roc_auc 0.39040 prc_auc 0.60534[0m
[93maverage test of epoch 51: loss -18.78428 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 52: loss -19.03355 acc 0.66667 roc_auc 0.39070 prc_auc 0.60515[0m
[93maverage test of epoch 52: loss -19.08190 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 53: loss -19.33200 acc 0.66667 roc_auc 0.39730 prc_auc 0.60890[0m
[93maverage test of epoch 53: loss -19.37950 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 54: loss -19.63043 acc 0.66667 roc_auc 0.40520 prc_auc 0.61393[0m
[93maverage test of epoch 54: loss -19.67707 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 55: loss -19.92885 acc 0.66667 roc_auc 0.40900 prc_auc 0.61599[0m
[93maverage test of epoch 55: loss -19.97462 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 56: loss -20.22724 acc 0.66667 roc_auc 0.41480 prc_auc 0.61938[0m
[93maverage test of epoch 56: loss -20.27216 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 57: loss -20.52563 acc 0.66667 roc_auc 0.39750 prc_auc 0.61252[0m
[93maverage test of epoch 57: loss -20.56969 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 58: loss -20.82399 acc 0.66667 roc_auc 0.40580 prc_auc 0.61711[0m
[93maverage test of epoch 58: loss -20.86720 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 59: loss -21.12235 acc 0.66667 roc_auc 0.40670 prc_auc 0.61827[0m
[93maverage test of epoch 59: loss -21.16470 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 60: loss -21.42070 acc 0.66667 roc_auc 0.40290 prc_auc 0.61877[0m
[93maverage test of epoch 60: loss -21.46219 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 61: loss -21.71903 acc 0.66667 roc_auc 0.43200 prc_auc 0.63294[0m
[93maverage test of epoch 61: loss -21.75967 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 62: loss -22.01736 acc 0.66667 roc_auc 0.38240 prc_auc 0.61004[0m
[93maverage test of epoch 62: loss -22.05715 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 63: loss -22.31568 acc 0.66667 roc_auc 0.42290 prc_auc 0.62897[0m
[93maverage test of epoch 63: loss -22.35461 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 64: loss -22.61400 acc 0.66667 roc_auc 0.43950 prc_auc 0.63701[0m
[93maverage test of epoch 64: loss -22.65208 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 65: loss -22.91230 acc 0.66667 roc_auc 0.41180 prc_auc 0.62511[0m
[93maverage test of epoch 65: loss -22.94953 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 66: loss -23.21061 acc 0.66667 roc_auc 0.42520 prc_auc 0.63296[0m
[93maverage test of epoch 66: loss -23.24698 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 67: loss -23.50890 acc 0.66667 roc_auc 0.42720 prc_auc 0.63607[0m
[93maverage test of epoch 67: loss -23.54443 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 68: loss -23.80720 acc 0.66667 roc_auc 0.47500 prc_auc 0.65580[0m
[93maverage test of epoch 68: loss -23.84187 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 69: loss -24.10549 acc 0.66667 roc_auc 0.40970 prc_auc 0.62860[0m
[93maverage test of epoch 69: loss -24.13931 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 70: loss -24.40377 acc 0.66667 roc_auc 0.43500 prc_auc 0.63996[0m
[93maverage test of epoch 70: loss -24.43674 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 71: loss -24.70206 acc 0.66667 roc_auc 0.44000 prc_auc 0.64172[0m
[93maverage test of epoch 71: loss -24.73417 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 72: loss -25.00034 acc 0.66667 roc_auc 0.44500 prc_auc 0.64375[0m
[93maverage test of epoch 72: loss -25.03160 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 73: loss -25.29862 acc 0.66667 roc_auc 0.38000 prc_auc 0.62349[0m
[93maverage test of epoch 73: loss -25.32903 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 74: loss -25.59689 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 74: loss -25.62645 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 75: loss -25.89517 acc 0.66667 roc_auc 0.48500 prc_auc 0.66008[0m
[93maverage test of epoch 75: loss -25.92388 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 76: loss -26.19344 acc 0.66667 roc_auc 0.43000 prc_auc 0.63780[0m
[93maverage test of epoch 76: loss -26.22130 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 77: loss -26.49171 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 77: loss -26.51872 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 78: loss -26.78998 acc 0.66667 roc_auc 0.47500 prc_auc 0.65580[0m
[93maverage test of epoch 78: loss -26.81614 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 79: loss -27.08825 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 79: loss -27.11355 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 80: loss -27.38652 acc 0.66667 roc_auc 0.47000 prc_auc 0.65370[0m
[93maverage test of epoch 80: loss -27.41097 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 81: loss -27.68479 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 81: loss -27.70839 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 82: loss -27.98305 acc 0.66667 roc_auc 0.40000 prc_auc 0.63656[0m
[93maverage test of epoch 82: loss -28.00580 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 83: loss -28.28131 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 83: loss -28.30321 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 84: loss -28.57958 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 84: loss -28.60062 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 85: loss -28.87784 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 85: loss -28.89803 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 86: loss -29.17610 acc 0.66667 roc_auc 0.45000 prc_auc 0.64551[0m
[93maverage test of epoch 86: loss -29.19545 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 87: loss -29.47436 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 87: loss -29.49285 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 88: loss -29.77262 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 88: loss -29.79026 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 89: loss -30.07088 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 89: loss -30.08767 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -30.36913 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 90: loss -30.38507 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 91: loss -30.66739 acc 0.66667 roc_auc 0.43000 prc_auc 0.63812[0m
[93maverage test of epoch 91: loss -30.68248 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 92: loss -30.96565 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 92: loss -30.97989 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 93: loss -31.26390 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 93: loss -31.27729 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 94: loss -31.56216 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 94: loss -31.57469 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 95: loss -31.86041 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 95: loss -31.87210 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 96: loss -32.15867 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 96: loss -32.16950 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 97: loss -32.45692 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 97: loss -32.46691 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 98: loss -32.75518 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 98: loss -32.76431 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -33.05343 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 99: loss -33.06171 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.64653 acc 0.66225 roc_auc 0.43118 prc_auc 0.62663[0m
[93maverage test of epoch 0: loss -1.08938 acc 0.67568 roc_auc 0.66333 prc_auc 0.85671[0m
[92maverage training of epoch 1: loss -1.46217 acc 0.66225 roc_auc 0.43706 prc_auc 0.62413[0m
[93maverage test of epoch 1: loss -1.84194 acc 0.67568 roc_auc 0.79667 prc_auc 0.90655[0m
[92maverage training of epoch 2: loss -2.10419 acc 0.66225 roc_auc 0.42863 prc_auc 0.62295[0m
[93maverage test of epoch 2: loss -2.42127 acc 0.67568 roc_auc 0.82333 prc_auc 0.91585[0m
[92maverage training of epoch 3: loss -2.69124 acc 0.66225 roc_auc 0.44235 prc_auc 0.63723[0m
[93maverage test of epoch 3: loss -3.05843 acc 0.67568 roc_auc 0.83667 prc_auc 0.91945[0m
[92maverage training of epoch 4: loss -3.38559 acc 0.66225 roc_auc 0.44294 prc_auc 0.63072[0m
[93maverage test of epoch 4: loss -3.79624 acc 0.67568 roc_auc 0.86000 prc_auc 0.93121[0m
[92maverage training of epoch 5: loss -4.05710 acc 0.66225 roc_auc 0.43588 prc_auc 0.62341[0m
[93maverage test of epoch 5: loss -4.40587 acc 0.67568 roc_auc 0.86500 prc_auc 0.93477[0m
[92maverage training of epoch 6: loss -4.65630 acc 0.66225 roc_auc 0.45000 prc_auc 0.64599[0m
[93maverage test of epoch 6: loss -5.00944 acc 0.67568 roc_auc 0.84000 prc_auc 0.91674[0m
[92maverage training of epoch 7: loss -5.19554 acc 0.66225 roc_auc 0.43745 prc_auc 0.62393[0m
[93maverage test of epoch 7: loss -5.49018 acc 0.67568 roc_auc 0.85000 prc_auc 0.92059[0m
[92maverage training of epoch 8: loss -5.64257 acc 0.66225 roc_auc 0.42324 prc_auc 0.61045[0m
[93maverage test of epoch 8: loss -5.91447 acc 0.67568 roc_auc 0.85667 prc_auc 0.92327[0m
[92maverage training of epoch 9: loss -6.04756 acc 0.66225 roc_auc 0.41167 prc_auc 0.60105[0m
[93maverage test of epoch 9: loss -6.30657 acc 0.67568 roc_auc 0.85833 prc_auc 0.92372[0m
[92maverage training of epoch 10: loss -6.42676 acc 0.66225 roc_auc 0.40225 prc_auc 0.59374[0m
[93maverage test of epoch 10: loss -6.67766 acc 0.67568 roc_auc 0.85833 prc_auc 0.92367[0m
[92maverage training of epoch 11: loss -6.78850 acc 0.66225 roc_auc 0.39686 prc_auc 0.59136[0m
[93maverage test of epoch 11: loss -7.03402 acc 0.67568 roc_auc 0.86167 prc_auc 0.92445[0m
[92maverage training of epoch 12: loss -7.13771 acc 0.66225 roc_auc 0.39520 prc_auc 0.59000[0m
[93maverage test of epoch 12: loss -7.37958 acc 0.67568 roc_auc 0.86167 prc_auc 0.92414[0m
[92maverage training of epoch 13: loss -7.47755 acc 0.66225 roc_auc 0.39235 prc_auc 0.58871[0m
[93maverage test of epoch 13: loss -7.71694 acc 0.67568 roc_auc 0.86000 prc_auc 0.92230[0m
[92maverage training of epoch 14: loss -7.81020 acc 0.66225 roc_auc 0.38971 prc_auc 0.58711[0m
[93maverage test of epoch 14: loss -8.04793 acc 0.67568 roc_auc 0.86000 prc_auc 0.92091[0m
[92maverage training of epoch 15: loss -8.13721 acc 0.66225 roc_auc 0.38696 prc_auc 0.58504[0m
[93maverage test of epoch 15: loss -8.37388 acc 0.67568 roc_auc 0.86167 prc_auc 0.91904[0m
[92maverage training of epoch 16: loss -8.45972 acc 0.66225 roc_auc 0.38627 prc_auc 0.58454[0m
[93maverage test of epoch 16: loss -8.69579 acc 0.67568 roc_auc 0.83333 prc_auc 0.88691[0m
[92maverage training of epoch 17: loss -8.77859 acc 0.66225 roc_auc 0.38520 prc_auc 0.58431[0m
[93maverage test of epoch 17: loss -9.01440 acc 0.67568 roc_auc 0.85667 prc_auc 0.89111[0m
[92maverage training of epoch 18: loss -9.09449 acc 0.66225 roc_auc 0.38520 prc_auc 0.58440[0m
[93maverage test of epoch 18: loss -9.33031 acc 0.67568 roc_auc 0.83667 prc_auc 0.87836[0m
[92maverage training of epoch 19: loss -9.40794 acc 0.66225 roc_auc 0.38412 prc_auc 0.58365[0m
[93maverage test of epoch 19: loss -9.64399 acc 0.67568 roc_auc 0.79667 prc_auc 0.84946[0m
[92maverage training of epoch 20: loss -9.71935 acc 0.66225 roc_auc 0.38402 prc_auc 0.58357[0m
[93maverage test of epoch 20: loss -9.95579 acc 0.67568 roc_auc 0.86000 prc_auc 0.89108[0m
[92maverage training of epoch 21: loss -10.02905 acc 0.66225 roc_auc 0.38382 prc_auc 0.58358[0m
[93maverage test of epoch 21: loss -10.26603 acc 0.67568 roc_auc 0.84000 prc_auc 0.87252[0m
[92maverage training of epoch 22: loss -10.33732 acc 0.66225 roc_auc 0.38343 prc_auc 0.58403[0m
[93maverage test of epoch 22: loss -10.57496 acc 0.67568 roc_auc 0.84000 prc_auc 0.87252[0m
[92maverage training of epoch 23: loss -10.64437 acc 0.66225 roc_auc 0.38206 prc_auc 0.58329[0m
[93maverage test of epoch 23: loss -10.88276 acc 0.67568 roc_auc 0.80000 prc_auc 0.84368[0m
[92maverage training of epoch 24: loss -10.95040 acc 0.66225 roc_auc 0.38196 prc_auc 0.58270[0m
[93maverage test of epoch 24: loss -11.18961 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 25: loss -11.25556 acc 0.66225 roc_auc 0.38147 prc_auc 0.57593[0m
[93maverage test of epoch 25: loss -11.49566 acc 0.67568 roc_auc 0.64000 prc_auc 0.76649[0m
[92maverage training of epoch 26: loss -11.55996 acc 0.66225 roc_auc 0.38137 prc_auc 0.57619[0m
[93maverage test of epoch 26: loss -11.80101 acc 0.67568 roc_auc 0.82000 prc_auc 0.86604[0m
[92maverage training of epoch 27: loss -11.86372 acc 0.66225 roc_auc 0.38059 prc_auc 0.57355[0m
[93maverage test of epoch 27: loss -12.10576 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 28: loss -12.16694 acc 0.66225 roc_auc 0.37951 prc_auc 0.57214[0m
[93maverage test of epoch 28: loss -12.41000 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 29: loss -12.46967 acc 0.66225 roc_auc 0.37941 prc_auc 0.57208[0m
[93maverage test of epoch 29: loss -12.71381 acc 0.67568 roc_auc 0.60000 prc_auc 0.72571[0m
[92maverage training of epoch 30: loss -12.77200 acc 0.66225 roc_auc 0.37873 prc_auc 0.57171[0m
[93maverage test of epoch 30: loss -13.01723 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 31: loss -13.07398 acc 0.66225 roc_auc 0.37804 prc_auc 0.57114[0m
[93maverage test of epoch 31: loss -13.32033 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 32: loss -13.37566 acc 0.66225 roc_auc 0.37814 prc_auc 0.57132[0m
[93maverage test of epoch 32: loss -13.62314 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 33: loss -13.67707 acc 0.66225 roc_auc 0.37824 prc_auc 0.57112[0m
[93maverage test of epoch 33: loss -13.92571 acc 0.67568 roc_auc 0.86000 prc_auc 0.89108[0m
[92maverage training of epoch 34: loss -13.97825 acc 0.66225 roc_auc 0.37735 prc_auc 0.57008[0m
[93maverage test of epoch 34: loss -14.22806 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 35: loss -14.27923 acc 0.66225 roc_auc 0.37755 prc_auc 0.57100[0m
[93maverage test of epoch 35: loss -14.53023 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 36: loss -14.58004 acc 0.66225 roc_auc 0.37676 prc_auc 0.57131[0m
[93maverage test of epoch 36: loss -14.83224 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 37: loss -14.88070 acc 0.66225 roc_auc 0.37696 prc_auc 0.57135[0mUsing backend: pytorch
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))

[93maverage test of epoch 37: loss -15.13411 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 38: loss -15.18124 acc 0.66225 roc_auc 0.37676 prc_auc 0.57155[0m
[93maverage test of epoch 38: loss -15.43586 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 39: loss -15.48165 acc 0.66225 roc_auc 0.37647 prc_auc 0.57054[0m
[93maverage test of epoch 39: loss -15.73750 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 40: loss -15.78197 acc 0.66225 roc_auc 0.37588 prc_auc 0.57054[0m
[93maverage test of epoch 40: loss -16.03904 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 41: loss -16.08220 acc 0.66225 roc_auc 0.37608 prc_auc 0.57015[0m
[93maverage test of epoch 41: loss -16.34051 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 42: loss -16.38236 acc 0.66225 roc_auc 0.37627 prc_auc 0.57162[0m
[93maverage test of epoch 42: loss -16.64191 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 43: loss -16.68245 acc 0.66225 roc_auc 0.37598 prc_auc 0.57126[0m
[93maverage test of epoch 43: loss -16.94325 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 44: loss -16.98248 acc 0.66225 roc_auc 0.37578 prc_auc 0.57205[0m
[93maverage test of epoch 44: loss -17.24453 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 45: loss -17.28246 acc 0.66225 roc_auc 0.37520 prc_auc 0.57365[0m
[93maverage test of epoch 45: loss -17.54576 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 46: loss -17.58240 acc 0.66225 roc_auc 0.37480 prc_auc 0.57176[0m
[93maverage test of epoch 46: loss -17.84695 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 47: loss -17.88230 acc 0.66225 roc_auc 0.37637 prc_auc 0.57198[0m
[93maverage test of epoch 47: loss -18.14810 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 48: loss -18.18216 acc 0.66225 roc_auc 0.37539 prc_auc 0.57029[0m
[93maverage test of epoch 48: loss -18.44923 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 49: loss -18.48200 acc 0.66225 roc_auc 0.37480 prc_auc 0.57066[0m
[93maverage test of epoch 49: loss -18.75032 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 50: loss -18.78180 acc 0.66225 roc_auc 0.37578 prc_auc 0.57191[0m
[93maverage test of epoch 50: loss -19.05139 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 51: loss -19.08159 acc 0.66225 roc_auc 0.37373 prc_auc 0.57049[0m
[93maverage test of epoch 51: loss -19.35244 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 52: loss -19.38135 acc 0.66225 roc_auc 0.37471 prc_auc 0.57115[0m
[93maverage test of epoch 52: loss -19.65347 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 53: loss -19.68109 acc 0.66225 roc_auc 0.37618 prc_auc 0.57163[0m
[93maverage test of epoch 53: loss -19.95448 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 54: loss -19.98082 acc 0.66225 roc_auc 0.37510 prc_auc 0.57127[0m
[93maverage test of epoch 54: loss -20.25548 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 55: loss -20.28054 acc 0.66225 roc_auc 0.37588 prc_auc 0.57154[0m
[93maverage test of epoch 55: loss -20.55646 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 56: loss -20.58024 acc 0.66225 roc_auc 0.37529 prc_auc 0.57233[0m
[93maverage test of epoch 56: loss -20.85743 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 57: loss -20.87993 acc 0.66225 roc_auc 0.37667 prc_auc 0.57554[0m
[93maverage test of epoch 57: loss -21.15839 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 58: loss -21.17961 acc 0.66225 roc_auc 0.37451 prc_auc 0.57253[0m
[93maverage test of epoch 58: loss -21.45934 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 59: loss -21.47929 acc 0.66225 roc_auc 0.37608 prc_auc 0.57452[0m
[93maverage test of epoch 59: loss -21.76029 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 60: loss -21.77895 acc 0.66225 roc_auc 0.37676 prc_auc 0.57577[0m
[93maverage test of epoch 60: loss -22.06122 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 61: loss -22.07861 acc 0.66225 roc_auc 0.37539 prc_auc 0.57485[0m
[93maverage test of epoch 61: loss -22.36215 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 62: loss -22.37826 acc 0.66225 roc_auc 0.37431 prc_auc 0.57299[0m
[93maverage test of epoch 62: loss -22.66307 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 63: loss -22.67790 acc 0.66225 roc_auc 0.37510 prc_auc 0.57367[0m
[93maverage test of epoch 63: loss -22.96399 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 64: loss -22.97754 acc 0.66225 roc_auc 0.37343 prc_auc 0.57429[0m
[93maverage test of epoch 64: loss -23.26490 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 65: loss -23.27717 acc 0.66225 roc_auc 0.37647 prc_auc 0.57785[0m
[93maverage test of epoch 65: loss -23.56580 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 66: loss -23.57680 acc 0.66225 roc_auc 0.37500 prc_auc 0.57504[0m
[93maverage test of epoch 66: loss -23.86671 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 67: loss -23.87643 acc 0.66225 roc_auc 0.37441 prc_auc 0.57692[0m
[93maverage test of epoch 67: loss -24.16761 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 68: loss -24.17605 acc 0.66225 roc_auc 0.38216 prc_auc 0.58135[0m
[93maverage test of epoch 68: loss -24.46850 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 69: loss -24.47567 acc 0.66225 roc_auc 0.37863 prc_auc 0.58176[0m
[93maverage test of epoch 69: loss -24.76940 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 70: loss -24.77529 acc 0.66225 roc_auc 0.37333 prc_auc 0.57999[0m
[93maverage test of epoch 70: loss -25.07029 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 71: loss -25.07490 acc 0.66225 roc_auc 0.37941 prc_auc 0.57885[0m
[93maverage test of epoch 71: loss -25.37117 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 72: loss -25.37451 acc 0.66225 roc_auc 0.38324 prc_auc 0.58429[0m
[93maverage test of epoch 72: loss -25.67206 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 73: loss -25.67412 acc 0.66225 roc_auc 0.38078 prc_auc 0.58345[0m
[93maverage test of epoch 73: loss -25.97294 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 74: loss -25.97373 acc 0.66225 roc_auc 0.37706 prc_auc 0.58092[0m
[93maverage test of epoch 74: loss -26.27382 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 75: loss -26.27334 acc 0.66225 roc_auc 0.37941 prc_auc 0.58772[0m
[93maverage test of epoch 75: loss -26.57471 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 76: loss -26.57295 acc 0.66225 roc_auc 0.38078 prc_auc 0.58794[0m
[93maverage test of epoch 76: loss -26.87559 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 77: loss -26.87255 acc 0.66225 roc_auc 0.38735 prc_auc 0.59230[0m
[93maverage test of epoch 77: loss -27.17647 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 78: loss -27.17216 acc 0.66225 roc_auc 0.39255 prc_auc 0.59373[0m
[93maverage test of epoch 78: loss -27.47735 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 79: loss -27.47176 acc 0.66225 roc_auc 0.37608 prc_auc 0.58573[0m
[93maverage test of epoch 79: loss -27.77823 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 80: loss -27.77137 acc 0.66225 roc_auc 0.36755 prc_auc 0.58766[0m
[93maverage test of epoch 80: loss -28.07911 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 81: loss -28.07097 acc 0.66225 roc_auc 0.38824 prc_auc 0.59431[0m
[93maverage test of epoch 81: loss -28.37999 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 82: loss -28.37057 acc 0.66225 roc_auc 0.39196 prc_auc 0.59795[0m
[93maverage test of epoch 82: loss -28.68087 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 83: loss -28.67018 acc 0.66225 roc_auc 0.38059 prc_auc 0.59240[0m
[93maverage test of epoch 83: loss -28.98175 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 84: loss -28.96978 acc 0.66225 roc_auc 0.39216 prc_auc 0.60119[0m
[93maverage test of epoch 84: loss -29.28263 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 85: loss -29.26939 acc 0.66225 roc_auc 0.37980 prc_auc 0.59468[0m
[93maverage test of epoch 85: loss -29.58351 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 86: loss -29.56899 acc 0.66225 roc_auc 0.39176 prc_auc 0.60425[0m
[93maverage test of epoch 86: loss -29.88439 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 87: loss -29.86860 acc 0.66225 roc_auc 0.40167 prc_auc 0.61007[0m
[93maverage test of epoch 87: loss -30.18527 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 88: loss -30.16820 acc 0.66225 roc_auc 0.40510 prc_auc 0.61257[0m
[93maverage test of epoch 88: loss -30.48615 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 89: loss -30.46780 acc 0.66225 roc_auc 0.36951 prc_auc 0.59863[0m
[93maverage test of epoch 89: loss -30.78703 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 90: loss -30.76741 acc 0.66225 roc_auc 0.38931 prc_auc 0.60512[0m
[93maverage test of epoch 90: loss -31.08790 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 91: loss -31.06701 acc 0.66225 roc_auc 0.38902 prc_auc 0.60534[0m
[93maverage test of epoch 91: loss -31.38878 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 92: loss -31.36661 acc 0.66225 roc_auc 0.39431 prc_auc 0.61077[0m
[93maverage test of epoch 92: loss -31.68966 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 93: loss -31.66622 acc 0.66225 roc_auc 0.38863 prc_auc 0.60950[0m
[93maverage test of epoch 93: loss -31.99054 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 94: loss -31.96582 acc 0.66225 roc_auc 0.43804 prc_auc 0.63174[0m
[93maverage test of epoch 94: loss -32.29141 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 95: loss -32.26542 acc 0.66225 roc_auc 0.45147 prc_auc 0.63747[0m
[93maverage test of epoch 95: loss -32.59229 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 96: loss -32.56502 acc 0.66225 roc_auc 0.43275 prc_auc 0.62854[0m
[93maverage test of epoch 96: loss -32.89316 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 97: loss -32.86462 acc 0.66225 roc_auc 0.39529 prc_auc 0.61703[0m
[93maverage test of epoch 97: loss -33.19404 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 98: loss -33.16422 acc 0.66225 roc_auc 0.42314 prc_auc 0.62958[0m
[93maverage test of epoch 98: loss -33.49492 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 99: loss -33.46382 acc 0.66225 roc_auc 0.44784 prc_auc 0.64007[0m
[93maverage test of epoch 99: loss -33.79580 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.11934 acc 0.64901 roc_auc 0.40451 prc_auc 0.63673[0m
[93maverage test of epoch 0: loss -0.35631 acc 0.67568 roc_auc 0.84333 prc_auc 0.93739[0m
[92maverage training of epoch 1: loss -0.54159 acc 0.66225 roc_auc 0.57412 prc_auc 0.76821[0m
[93maverage test of epoch 1: loss -0.77118 acc 0.67568 roc_auc 0.92667 prc_auc 0.97247[0m
[92maverage training of epoch 2: loss -0.96460 acc 0.66225 roc_auc 0.76373 prc_auc 0.87289[0m
[93maverage test of epoch 2: loss -1.22384 acc 0.67568 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 3: loss -1.44102 acc 0.66225 roc_auc 0.83196 prc_auc 0.90129[0m
[93maverage test of epoch 3: loss -1.76368 acc 0.67568 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 4: loss -2.01558 acc 0.66225 roc_auc 0.85824 prc_auc 0.92083[0m
[93maverage test of epoch 4: loss -2.40676 acc 0.67568 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 5: loss -2.66273 acc 0.81457 roc_auc 0.86549 prc_auc 0.92340[0m
[93maverage test of epoch 5: loss -3.00129 acc 0.81081 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 6: loss -3.19171 acc 0.83444 roc_auc 0.83667 prc_auc 0.89616[0m
[93maverage test of epoch 6: loss -3.37840 acc 0.81081 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 7: loss -3.55924 acc 0.82781 roc_auc 0.82686 prc_auc 0.88224[0m
[93maverage test of epoch 7: loss -3.74764 acc 0.83784 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 8: loss -3.90353 acc 0.82781 roc_auc 0.81608 prc_auc 0.86922[0m
[93maverage test of epoch 8: loss -4.09866 acc 0.83784 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 9: loss -4.21820 acc 0.82781 roc_auc 0.81196 prc_auc 0.85997[0m
[93maverage test of epoch 9: loss -4.42390 acc 0.83784 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 10: loss -4.50785 acc 0.82119 roc_auc 0.82098 prc_auc 0.86429[0m
[93maverage test of epoch 10: loss -4.73822 acc 0.83784 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 11: loss -4.84622 acc 0.83444 roc_auc 0.80402 prc_auc 0.84603[0m
[93maverage test of epoch 11: loss -5.04492 acc 0.83784 roc_auc 0.93667 prc_auc 0.97575[0m
[92maverage training of epoch 12: loss -5.14729 acc 0.83444 roc_auc 0.78667 prc_auc 0.83531[0m
[93maverage test of epoch 12: loss -5.35490 acc 0.83784 roc_auc 0.94000 prc_auc 0.97693[0m
[92maverage training of epoch 13: loss -5.44790 acc 0.83444 roc_auc 0.77980 prc_auc 0.82952[0m
[93maverage test of epoch 13: loss -5.65927 acc 0.83784 roc_auc 0.94000 prc_auc 0.97693[0m
[92maverage training of epoch 14: loss -5.74205 acc 0.83444 roc_auc 0.77961 prc_auc 0.82838[0m
[93maverage test of epoch 14: loss -5.95956 acc 0.83784 roc_auc 0.94000 prc_auc 0.97693[0m
[92maverage training of epoch 15: loss -6.01056 acc 0.83444 roc_auc 0.79255 prc_auc 0.83094[0m
[93maverage test of epoch 15: loss -6.24921 acc 0.83784 roc_auc 0.94333 prc_auc 0.97777[0m
[92maverage training of epoch 16: loss -6.29401 acc 0.83444 roc_auc 0.80235 prc_auc 0.83991[0m
[93maverage test of epoch 16: loss -6.53425 acc 0.83784 roc_auc 0.93667 prc_auc 0.97575[0m
[92maverage training of epoch 17: loss -6.62843 acc 0.84106 roc_auc 0.76137 prc_auc 0.81265[0m
[93maverage test of epoch 17: loss -6.82540 acc 0.83784 roc_auc 0.94333 prc_auc 0.97777[0m
[92maverage training of epoch 18: loss -6.88330 acc 0.84106 roc_auc 0.76000 prc_auc 0.81144[0m
[93maverage test of epoch 18: loss -7.10935 acc 0.83784 roc_auc 0.94000 prc_auc 0.97693[0m
[92maverage training of epoch 19: loss -7.12022 acc 0.83444 roc_auc 0.79431 prc_auc 0.83431[0m
[93maverage test of epoch 19: loss -7.21836 acc 0.81081 roc_auc 0.93333 prc_auc 0.97496[0m
[92maverage training of epoch 20: loss -7.10026 acc 0.80132 roc_auc 0.78402 prc_auc 0.83431[0m
[93maverage test of epoch 20: loss -7.41137 acc 0.81081 roc_auc 0.93333 prc_auc 0.97496[0m
[92maverage training of epoch 21: loss -7.38361 acc 0.80795 roc_auc 0.78735 prc_auc 0.83525[0m
[93maverage test of epoch 21: loss -7.81506 acc 0.83784 roc_auc 0.93333 prc_auc 0.97496[0m
[92maverage training of epoch 22: loss -7.92276 acc 0.85430 roc_auc 0.81069 prc_auc 0.84043[0m
[93maverage test of epoch 22: loss -8.15831 acc 0.83784 roc_auc 0.93667 prc_auc 0.97575[0m
[92maverage training of epoch 23: loss -8.22229 acc 0.84106 roc_auc 0.75637 prc_auc 0.80765[0m
[93maverage test of epoch 23: loss -8.43201 acc 0.83784 roc_auc 0.94000 prc_auc 0.97693[0m
[92maverage training of epoch 24: loss -8.48978 acc 0.84106 roc_auc 0.75804 prc_auc 0.80922[0m
[93maverage test of epoch 24: loss -8.70310 acc 0.83784 roc_auc 0.93667 prc_auc 0.97614[0m
[92maverage training of epoch 25: loss -8.75524 acc 0.84106 roc_auc 0.75578 prc_auc 0.80557[0m
[93maverage test of epoch 25: loss -8.97276 acc 0.83784 roc_auc 0.93500 prc_auc 0.97440[0m
[92maverage training of epoch 26: loss -9.01932 acc 0.84106 roc_auc 0.75520 prc_auc 0.80548[0m
[93maverage test of epoch 26: loss -9.24100 acc 0.83784 roc_auc 0.93667 prc_auc 0.97635[0m
[92maverage training of epoch 27: loss -9.28207 acc 0.84106 roc_auc 0.75451 prc_auc 0.80279[0m
[93maverage test of epoch 27: loss -9.50793 acc 0.83784 roc_auc 0.94667 prc_auc 0.97635[0m
[92maverage training of epoch 28: loss -9.46223 acc 0.83444 roc_auc 0.77147 prc_auc 0.81900[0m
[93maverage test of epoch 28: loss -9.66530 acc 0.83784 roc_auc 0.94000 prc_auc 0.97659[0m
[92maverage training of epoch 29: loss -9.65631 acc 0.82781 roc_auc 0.77039 prc_auc 0.82006[0m
[93maverage test of epoch 29: loss -9.78416 acc 0.81081 roc_auc 0.94000 prc_auc 0.97659[0m
[92maverage training of epoch 30: loss -9.95549 acc 0.82781 roc_auc 0.76363 prc_auc 0.81955[0m
[93maverage test of epoch 30: loss -10.17726 acc 0.83784 roc_auc 0.93833 prc_auc 0.97485[0m
[92maverage training of epoch 31: loss -10.29361 acc 0.85430 roc_auc 0.78853 prc_auc 0.81989[0m
[93maverage test of epoch 31: loss -10.54579 acc 0.83784 roc_auc 0.94333 prc_auc 0.96608[0m
[92maverage training of epoch 32: loss -10.57149 acc 0.84106 roc_auc 0.77235 prc_auc 0.82034[0m
[93maverage test of epoch 32: loss -10.77656 acc 0.83784 roc_auc 0.93667 prc_auc 0.97133[0m
[92maverage training of epoch 33: loss -10.81620 acc 0.84106 roc_auc 0.75569 prc_auc 0.79653[0m
[93maverage test of epoch 33: loss -11.06430 acc 0.83784 roc_auc 0.90000 prc_auc 0.92745[0m
[92maverage training of epoch 34: loss -11.06994 acc 0.84106 roc_auc 0.75480 prc_auc 0.79631[0m
[93maverage test of epoch 34: loss -11.32236 acc 0.83784 roc_auc 0.84000 prc_auc 0.87996[0m
[92maverage training of epoch 35: loss -11.32307 acc 0.84106 roc_auc 0.75343 prc_auc 0.80087[0m
[93maverage test of epoch 35: loss -11.57992 acc 0.83784 roc_auc 0.95667 prc_auc 0.97651[0m
[92maverage training of epoch 36: loss -11.57588 acc 0.84106 roc_auc 0.75176 prc_auc 0.79382[0m
[93maverage test of epoch 36: loss -11.83706 acc 0.83784 roc_auc 0.77333 prc_auc 0.82479[0m
[92maverage training of epoch 37: loss -11.82820 acc 0.84106 roc_auc 0.75216 prc_auc 0.79373[0m
[93maverage test of epoch 37: loss -12.09376 acc 0.83784 roc_auc 0.77333 prc_auc 0.82479[0m
[92maverage training of epoch 38: loss -12.08009 acc 0.84106 roc_auc 0.75127 prc_auc 0.79810[0m
[93maverage test of epoch 38: loss -12.35004 acc 0.83784 roc_auc 0.95667 prc_auc 0.97651[0m
[92maverage training of epoch 39: loss -11.93864 acc 0.78146 roc_auc 0.66559 prc_auc 0.75800[0m
[93maverage test of epoch 39: loss -12.43659 acc 0.83784 roc_auc 0.93833 prc_auc 0.97268[0m
[92maverage training of epoch 40: loss -12.49081 acc 0.85430 roc_auc 0.79431 prc_auc 0.82986[0m
[93maverage test of epoch 40: loss -12.85084 acc 0.83784 roc_auc 0.94833 prc_auc 0.96961[0m
[92maverage training of epoch 41: loss -12.65073 acc 0.82781 roc_auc 0.74657 prc_auc 0.80487[0m
[93maverage test of epoch 41: loss -13.10045 acc 0.83784 roc_auc 0.77333 prc_auc 0.82479[0m
[92maverage training of epoch 42: loss -13.10840 acc 0.84768 roc_auc 0.77578 prc_auc 0.82017[0m
[93maverage test of epoch 42: loss -13.00974 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 43: loss -13.31729 acc 0.84106 roc_auc 0.74500 prc_auc 0.79368[0m
[93maverage test of epoch 43: loss -13.60834 acc 0.83784 roc_auc 0.77333 prc_auc 0.82479[0m
[92maverage training of epoch 44: loss -13.60807 acc 0.84768 roc_auc 0.76598 prc_auc 0.81265[0m
[93maverage test of epoch 44: loss -13.66945 acc 0.83784 roc_auc 0.80333 prc_auc 0.84711[0m
[92maverage training of epoch 45: loss -13.66243 acc 0.85430 roc_auc 0.81402 prc_auc 0.85323[0m
[93maverage test of epoch 45: loss -13.91243 acc 0.83784 roc_auc 0.88333 prc_auc 0.92242[0m
[92maverage training of epoch 46: loss -13.57246 acc 0.82781 roc_auc 0.82961 prc_auc 0.87234[0m
[93maverage test of epoch 46: loss -14.16142 acc 0.81081 roc_auc 0.93667 prc_auc 0.97549[0m
[92maverage training of epoch 47: loss -14.00173 acc 0.84106 roc_auc 0.83373 prc_auc 0.86867[0m
[93maverage test of epoch 47: loss -14.20649 acc 0.81081 roc_auc 0.86167 prc_auc 0.90041[0m
[92maverage training of epoch 48: loss -14.50061 acc 0.86755 roc_auc 0.83971 prc_auc 0.87436[0m
[93maverage test of epoch 48: loss -14.83089 acc 0.83784 roc_auc 0.76167 prc_auc 0.81823[0m
[92maverage training of epoch 49: loss -14.79829 acc 0.86755 roc_auc 0.84451 prc_auc 0.88135[0m
[93maverage test of epoch 49: loss -15.05483 acc 0.83784 roc_auc 0.75833 prc_auc 0.81739[0m
[92maverage training of epoch 50: loss -14.94790 acc 0.86093 roc_auc 0.85275 prc_auc 0.88631[0m
[93maverage test of epoch 50: loss -14.93287 acc 0.81081 roc_auc 0.76167 prc_auc 0.81823[0m
[92maverage training of epoch 51: loss -15.34063 acc 0.87417 roc_auc 0.83598 prc_auc 0.87157[0m
[93maverage test of epoch 51: loss -15.57328 acc 0.83784 roc_auc 0.76333 prc_auc 0.82226[0m
[92maverage training of epoch 52: loss -15.45508 acc 0.84106 roc_auc 0.79696 prc_auc 0.83805[0m
[93maverage test of epoch 52: loss -15.82327 acc 0.83784 roc_auc 0.76333 prc_auc 0.82226[0m
[92maverage training of epoch 53: loss -15.69968 acc 0.84106 roc_auc 0.77451 prc_auc 0.82158[0m
[93maverage test of epoch 53: loss -16.06984 acc 0.83784 roc_auc 0.75500 prc_auc 0.81660[0m
[92maverage training of epoch 54: loss -15.56739 acc 0.82119 roc_auc 0.78608 prc_auc 0.83470[0m
[93maverage test of epoch 54: loss -16.31606 acc 0.83784 roc_auc 0.76667 prc_auc 0.82305[0m
[92maverage training of epoch 55: loss -16.18580 acc 0.84106 roc_auc 0.80412 prc_auc 0.84468[0m
[93maverage test of epoch 55: loss -16.56588 acc 0.83784 roc_auc 0.76333 prc_auc 0.82226[0m
[92maverage training of epoch 56: loss -16.53428 acc 0.84768 roc_auc 0.80039 prc_auc 0.84000[0m
[93maverage test of epoch 56: loss -16.81736 acc 0.83784 roc_auc 0.76333 prc_auc 0.82226[0m
[92maverage training of epoch 57: loss -16.75291 acc 0.84768 roc_auc 0.81480 prc_auc 0.85249[0m
[93maverage test of epoch 57: loss -17.06678 acc 0.83784 roc_auc 0.76333 prc_auc 0.82226[0m
[92maverage training of epoch 58: loss -16.91677 acc 0.84106 roc_auc 0.77510 prc_auc 0.82219[0m
[93maverage test of epoch 58: loss -17.31540 acc 0.83784 roc_auc 0.76333 prc_auc 0.82226[0m
[92maverage training of epoch 59: loss -17.21199 acc 0.84768 roc_auc 0.80510 prc_auc 0.84498[0m
[93maverage test of epoch 59: loss -17.56599 acc 0.83784 roc_auc 0.76333 prc_auc 0.82226[0m
[92maverage training of epoch 60: loss -17.40528 acc 0.84106 roc_auc 0.79657 prc_auc 0.83792[0m
[93maverage test of epoch 60: loss -17.81540 acc 0.83784 roc_auc 0.76333 prc_auc 0.82226[0m
[92maverage training of epoch 61: loss -17.23483 acc 0.82119 roc_auc 0.78725 prc_auc 0.83587[0m
[93maverage test of epoch 61: loss -18.05712 acc 0.83784 roc_auc 0.76667 prc_auc 0.82305[0m
[92maverage training of epoch 62: loss -17.93947 acc 0.84768 roc_auc 0.80510 prc_auc 0.84498[0m
[93maverage test of epoch 62: loss -18.30709 acc 0.83784 roc_auc 0.76333 prc_auc 0.82226[0m
[92maverage training of epoch 63: loss -17.89022 acc 0.82781 roc_auc 0.78892 prc_auc 0.83385[0m
[93maverage test of epoch 63: loss -18.55290 acc 0.83784 roc_auc 0.76333 prc_auc 0.82226[0m
[92maverage training of epoch 64: loss -18.22466 acc 0.84768 roc_auc 0.82353 prc_auc 0.86234[0m
[93maverage test of epoch 64: loss -18.30158 acc 0.81081 roc_auc 0.75833 prc_auc 0.81739[0m
[92maverage training of epoch 65: loss -18.86899 acc 0.88079 roc_auc 0.85863 prc_auc 0.89006[0m
[93maverage test of epoch 65: loss -18.54288 acc 0.81081 roc_auc 0.75833 prc_auc 0.81739[0m
[92maverage training of epoch 66: loss -18.91262 acc 0.84768 roc_auc 0.80608 prc_auc 0.84524[0m
[93maverage test of epoch 66: loss -18.78515 acc 0.81081 roc_auc 0.75833 prc_auc 0.81739[0m
[92maverage training of epoch 67: loss -19.15740 acc 0.84768 roc_auc 0.80598 prc_auc 0.84518[0m
[93maverage test of epoch 67: loss -19.02762 acc 0.81081 roc_auc 0.75833 prc_auc 0.81739[0m
[92maverage training of epoch 68: loss -19.40223 acc 0.84768 roc_auc 0.80608 prc_auc 0.84524[0m
[93maverage test of epoch 68: loss -19.26980 acc 0.81081 roc_auc 0.75833 prc_auc 0.81739[0m
[92maverage training of epoch 69: loss -19.64701 acc 0.84768 roc_auc 0.80608 prc_auc 0.84524[0m
[93maverage test of epoch 69: loss -19.51210 acc 0.81081 roc_auc 0.75833 prc_auc 0.81739[0m
[92maverage training of epoch 70: loss -19.89177 acc 0.84768 roc_auc 0.80608 prc_auc 0.84524[0m
[93maverage test of epoch 70: loss -19.75456 acc 0.81081 roc_auc 0.75833 prc_auc 0.81739[0m
[92maverage training of epoch 71: loss -20.13651 acc 0.84768 roc_auc 0.80608 prc_auc 0.84524[0m
[93maverage test of epoch 71: loss -19.99747 acc 0.81081 roc_auc 0.75833 prc_auc 0.81739[0m
[92maverage training of epoch 72: loss -20.38121 acc 0.84768 roc_auc 0.80608 prc_auc 0.84524[0m
[93maverage test of epoch 72: loss -20.24192 acc 0.81081 roc_auc 0.75833 prc_auc 0.81739[0m
[92maverage training of epoch 73: loss -20.62589 acc 0.84768 roc_auc 0.80608 prc_auc 0.84524[0m
[93maverage test of epoch 73: loss -21.00074 acc 0.83784 roc_auc 0.76667 prc_auc 0.82305[0m
[92maverage training of epoch 74: loss -20.87052 acc 0.84768 roc_auc 0.80608 prc_auc 0.84524[0m
[93maverage test of epoch 74: loss -21.29004 acc 0.83784 roc_auc 0.76667 prc_auc 0.82305[0m
[92maverage training of epoch 75: loss -21.05373 acc 0.84106 roc_auc 0.79735 prc_auc 0.83813[0m
[93maverage test of epoch 75: loss -21.53831 acc 0.83784 roc_auc 0.76667 prc_auc 0.82305[0m
[92maverage training of epoch 76: loss -21.29808 acc 0.84106 roc_auc 0.79500 prc_auc 0.83745[0m
[93maverage test of epoch 76: loss -21.78770 acc 0.83784 roc_auc 0.76333 prc_auc 0.82226[0m
[92maverage training of epoch 77: loss -21.67089 acc 0.85430 roc_auc 0.81480 prc_auc 0.85245[0m
[93maverage test of epoch 77: loss -21.44750 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 78: loss -21.94188 acc 0.84768 roc_auc 0.80922 prc_auc 0.84712[0m
[93maverage test of epoch 78: loss -21.69177 acc 0.81081 roc_auc 0.74500 prc_auc 0.81349[0m
[92maverage training of epoch 79: loss -22.23120 acc 0.88079 roc_auc 0.86461 prc_auc 0.89660[0m
[93maverage test of epoch 79: loss -22.53186 acc 0.83784 roc_auc 0.76333 prc_auc 0.82226[0m
[92maverage training of epoch 80: loss -22.39764 acc 0.85430 roc_auc 0.81500 prc_auc 0.85254[0m
[93maverage test of epoch 80: loss -22.17769 acc 0.81081 roc_auc 0.75500 prc_auc 0.81660[0m
[92maverage training of epoch 81: loss -22.58038 acc 0.84768 roc_auc 0.80627 prc_auc 0.84529[0m
[93maverage test of epoch 81: loss -23.02921 acc 0.83784 roc_auc 0.76333 prc_auc 0.82226[0m
[92maverage training of epoch 82: loss -22.76070 acc 0.84106 roc_auc 0.79618 prc_auc 0.83780[0m
[93maverage test of epoch 82: loss -22.65544 acc 0.81081 roc_auc 0.75500 prc_auc 0.81660[0m
[92maverage training of epoch 83: loss -23.08116 acc 0.86755 roc_auc 0.84578 prc_auc 0.88005[0m
[93maverage test of epoch 83: loss -23.52370 acc 0.83784 roc_auc 0.76333 prc_auc 0.82226[0m
[92maverage training of epoch 84: loss -23.24602 acc 0.84106 roc_auc 0.79637 prc_auc 0.83790[0m
[93maverage test of epoch 84: loss -23.77252 acc 0.83784 roc_auc 0.76333 prc_auc 0.82226[0m
[92maverage training of epoch 85: loss -23.66288 acc 0.86755 roc_auc 0.83882 prc_auc 0.87352[0m
[93maverage test of epoch 85: loss -24.01116 acc 0.83784 roc_auc 0.76333 prc_auc 0.82226[0m
[92maverage training of epoch 86: loss -23.79887 acc 0.84768 roc_auc 0.80627 prc_auc 0.84531[0m
[93maverage test of epoch 86: loss -23.88543 acc 0.83784 roc_auc 0.75500 prc_auc 0.81660[0m
[92maverage training of epoch 87: loss -24.04301 acc 0.84768 roc_auc 0.80627 prc_auc 0.84531[0m
[93maverage test of epoch 87: loss -23.86104 acc 0.81081 roc_auc 0.75500 prc_auc 0.81660[0m
[92maverage training of epoch 88: loss -24.21795 acc 0.84106 roc_auc 0.79637 prc_auc 0.83786[0m
[93maverage test of epoch 88: loss -24.10491 acc 0.81081 roc_auc 0.76167 prc_auc 0.81823[0m
[92maverage training of epoch 89: loss -24.52116 acc 0.86755 roc_auc 0.84696 prc_auc 0.88049[0m
[93maverage test of epoch 89: loss -24.34059 acc 0.81081 roc_auc 0.75500 prc_auc 0.81660[0m
[92maverage training of epoch 90: loss -24.90280 acc 0.86755 roc_auc 0.84745 prc_auc 0.88134[0m
[93maverage test of epoch 90: loss -25.25816 acc 0.83784 roc_auc 0.76333 prc_auc 0.82226[0m
[92maverage training of epoch 91: loss -25.01742 acc 0.84768 roc_auc 0.80588 prc_auc 0.84518[0m
[93maverage test of epoch 91: loss -25.50568 acc 0.83784 roc_auc 0.76333 prc_auc 0.82226[0m
[92maverage training of epoch 92: loss -25.26159 acc 0.84768 roc_auc 0.80667 prc_auc 0.84543[0m
[93maverage test of epoch 92: loss -25.75530 acc 0.83784 roc_auc 0.76333 prc_auc 0.82226[0m
[92maverage training of epoch 93: loss -25.54066 acc 0.86093 roc_auc 0.83922 prc_auc 0.87361[0m
[93maverage test of epoch 93: loss -25.30463 acc 0.81081 roc_auc 0.75833 prc_auc 0.81739[0m
[92maverage training of epoch 94: loss -25.59910 acc 0.86093 roc_auc 0.84686 prc_auc 0.87985[0m
[93maverage test of epoch 94: loss -26.24583 acc 0.83784 roc_auc 0.76333 prc_auc 0.82226[0m
[92maverage training of epoch 95: loss -25.99034 acc 0.84768 roc_auc 0.80627 prc_auc 0.84531[0m
[93maverage test of epoch 95: loss -26.49447 acc 0.83784 roc_auc 0.76333 prc_auc 0.82226[0m
[92maverage training of epoch 96: loss -26.16271 acc 0.84106 roc_auc 0.79892 prc_auc 0.83870[0m
[93maverage test of epoch 96: loss -26.74088 acc 0.83784 roc_auc 0.77000 prc_auc 0.82389[0m
[92maverage training of epoch 97: loss -26.47801 acc 0.84768 roc_auc 0.80647 prc_auc 0.84535[0m
[93maverage test of epoch 97: loss -26.26664 acc 0.81081 roc_auc 0.76167 prc_auc 0.81823[0m
[92maverage training of epoch 98: loss -26.81730 acc 0.85430 roc_auc 0.81775 prc_auc 0.85352[0m
[93maverage test of epoch 98: loss -26.50873 acc 0.81081 roc_auc 0.75833 prc_auc 0.81739[0m
[92maverage training of epoch 99: loss -27.29154 acc 0.86755 roc_auc 0.82980 prc_auc 0.86264[0m
[93maverage test of epoch 99: loss -27.49166 acc 0.83784 roc_auc 0.77333 prc_auc 0.82479[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.0003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.69744 ROC_AUC (avg): 0.55467 PRC_AUC (avg): 0.69483 

Average forward propagation time taken(ms): 2.468286796052002
Average backward propagation time taken(ms): 0.873318581046541

