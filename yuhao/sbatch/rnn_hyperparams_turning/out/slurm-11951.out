# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.0003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-01-08-52/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-01-08-52/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 8,
 'epochs': 100,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 8,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.0003,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 1,
 'num_workers': 8,
 'number_of_mlp_layer': 0,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-18-01-08-52',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 100, 'learning_rate': 0.0003, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss 0.12610 acc 0.45333 roc_auc 0.46560 prc_auc 0.68889[0m
[93maverage test of epoch 0: loss -0.07634 acc 0.65789 roc_auc 0.87077 prc_auc 0.93994[0m
[92maverage training of epoch 1: loss -0.27744 acc 0.66000 roc_auc 0.47020 prc_auc 0.69270[0m
[93maverage test of epoch 1: loss -0.50806 acc 0.65789 roc_auc 0.87077 prc_auc 0.93581[0m
[92maverage training of epoch 2: loss -0.83101 acc 0.66667 roc_auc 0.40300 prc_auc 0.60615[0m
[93maverage test of epoch 2: loss -1.22823 acc 0.65789 roc_auc 0.25538 prc_auc 0.60226[0m
[92maverage training of epoch 3: loss -1.57646 acc 0.66667 roc_auc 0.40020 prc_auc 0.60199[0m
[93maverage test of epoch 3: loss -1.85892 acc 0.65789 roc_auc 0.24308 prc_auc 0.60347[0m
[92maverage training of epoch 4: loss -2.06831 acc 0.66667 roc_auc 0.46300 prc_auc 0.64730[0m
[93maverage test of epoch 4: loss -2.27454 acc 0.65789 roc_auc 0.70769 prc_auc 0.85835[0m
[92maverage training of epoch 5: loss -2.46716 acc 0.60000 roc_auc 0.50900 prc_auc 0.70205[0m
[93maverage test of epoch 5: loss -2.66528 acc 0.42105 roc_auc 0.85846 prc_auc 0.92042[0m
[92maverage training of epoch 6: loss -2.84970 acc 0.41333 roc_auc 0.52080 prc_auc 0.72163[0m
[93maverage test of epoch 6: loss -3.04016 acc 0.34211 roc_auc 0.84923 prc_auc 0.91705[0m
[92maverage training of epoch 7: loss -3.21476 acc 0.33333 roc_auc 0.51400 prc_auc 0.71554[0m
[93maverage test of epoch 7: loss -3.39854 acc 0.34211 roc_auc 0.84923 prc_auc 0.91719[0m
[92maverage training of epoch 8: loss -3.56848 acc 0.33333 roc_auc 0.52480 prc_auc 0.72429[0m
[93maverage test of epoch 8: loss -3.75221 acc 0.34211 roc_auc 0.87385 prc_auc 0.93725[0m
[92maverage training of epoch 9: loss -3.92506 acc 0.33333 roc_auc 0.55540 prc_auc 0.73902[0m
[93maverage test of epoch 9: loss -4.11810 acc 0.34211 roc_auc 0.88000 prc_auc 0.93878[0m
[92maverage training of epoch 10: loss -4.30435 acc 0.33333 roc_auc 0.59960 prc_auc 0.76904[0m
[93maverage test of epoch 10: loss -4.52006 acc 0.34211 roc_auc 0.88308 prc_auc 0.93915[0m
[92maverage training of epoch 11: loss -4.72795 acc 0.33333 roc_auc 0.64080 prc_auc 0.80733[0m
[93maverage test of epoch 11: loss -4.96441 acc 0.34211 roc_auc 0.87692 prc_auc 0.93688[0m
[92maverage training of epoch 12: loss -5.16229 acc 0.33333 roc_auc 0.67960 prc_auc 0.84862[0m
[93maverage test of epoch 12: loss -5.38614 acc 0.34211 roc_auc 0.85846 prc_auc 0.93689[0m
[92maverage training of epoch 13: loss -5.56879 acc 0.33333 roc_auc 0.55860 prc_auc 0.76231[0m
[93maverage test of epoch 13: loss -5.78079 acc 0.34211 roc_auc 0.83385 prc_auc 0.92837[0m
[92maverage training of epoch 14: loss -5.95306 acc 0.33333 roc_auc 0.43080 prc_auc 0.65575[0m
[93maverage test of epoch 14: loss -6.15533 acc 0.34211 roc_auc 0.65846 prc_auc 0.84303[0m
[92maverage training of epoch 15: loss -6.31985 acc 0.33333 roc_auc 0.36080 prc_auc 0.57162[0m
[93maverage test of epoch 15: loss -6.51406 acc 0.34211 roc_auc 0.27385 prc_auc 0.59274[0m
[92maverage training of epoch 16: loss -6.67297 acc 0.33333 roc_auc 0.35360 prc_auc 0.56543[0m
[93maverage test of epoch 16: loss -6.86077 acc 0.34211 roc_auc 0.14769 prc_auc 0.49418[0m
[92maverage training of epoch 17: loss -7.01569 acc 0.33333 roc_auc 0.35240 prc_auc 0.56345[0m
[93maverage test of epoch 17: loss -7.19838 acc 0.34211 roc_auc 0.13846 prc_auc 0.49188[0m
[92maverage training of epoch 18: loss -7.35043 acc 0.33333 roc_auc 0.35360 prc_auc 0.56341[0m
[93maverage test of epoch 18: loss -7.52896 acc 0.34211 roc_auc 0.13538 prc_auc 0.49155[0m
[92maverage training of epoch 19: loss -7.67896 acc 0.33333 roc_auc 0.35460 prc_auc 0.56396[0m
[93maverage test of epoch 19: loss -7.85400 acc 0.34211 roc_auc 0.13538 prc_auc 0.49161[0m
[92maverage training of epoch 20: loss -8.00254 acc 0.33333 roc_auc 0.35700 prc_auc 0.56491[0m
[93maverage test of epoch 20: loss -8.17462 acc 0.34211 roc_auc 0.13846 prc_auc 0.49518[0m
[92maverage training of epoch 21: loss -8.32215 acc 0.33333 roc_auc 0.35760 prc_auc 0.56509[0m
[93maverage test of epoch 21: loss -8.49166 acc 0.34211 roc_auc 0.13385 prc_auc 0.49248[0m
[92maverage training of epoch 22: loss -8.63851 acc 0.33333 roc_auc 0.35720 prc_auc 0.56413[0m
[93maverage test of epoch 22: loss -8.80575 acc 0.34211 roc_auc 0.13231 prc_auc 0.49574[0m
[92maverage training of epoch 23: loss -8.95220 acc 0.33333 roc_auc 0.35780 prc_auc 0.56431[0m
[93maverage test of epoch 23: loss -9.11742 acc 0.34211 roc_auc 0.13385 prc_auc 0.49312[0m
[92maverage training of epoch 24: loss -9.26366 acc 0.33333 roc_auc 0.35680 prc_auc 0.56258[0m
[93maverage test of epoch 24: loss -9.42704 acc 0.34211 roc_auc 0.13385 prc_auc 0.49974[0m
[92maverage training of epoch 25: loss -9.57326 acc 0.33333 roc_auc 0.35740 prc_auc 0.56274[0m
[93maverage test of epoch 25: loss -9.73496 acc 0.34211 roc_auc 0.13692 prc_auc 0.50232[0m
[92maverage training of epoch 26: loss -9.88128 acc 0.33333 roc_auc 0.35700 prc_auc 0.56268[0m
[93maverage test of epoch 26: loss -10.04144 acc 0.34211 roc_auc 0.13692 prc_auc 0.50514[0m
[92maverage training of epoch 27: loss -10.18798 acc 0.33333 roc_auc 0.35640 prc_auc 0.56176[0m
[93maverage test of epoch 27: loss -10.34669 acc 0.34211 roc_auc 0.12308 prc_auc 0.50166[0m
[92maverage training of epoch 28: loss -10.49354 acc 0.33333 roc_auc 0.35640 prc_auc 0.56171[0m
[93maverage test of epoch 28: loss -10.65089 acc 0.34211 roc_auc 0.12154 prc_auc 0.50067[0m
[92maverage training of epoch 29: loss -10.79813 acc 0.33333 roc_auc 0.35620 prc_auc 0.56166[0m
[93maverage test of epoch 29: loss -10.95420 acc 0.34211 roc_auc 0.13538 prc_auc 0.50733[0m
[92maverage training of epoch 30: loss -11.10189 acc 0.33333 roc_auc 0.35620 prc_auc 0.56162[0m
[93maverage test of epoch 30: loss -11.25674 acc 0.34211 roc_auc 0.10154 prc_auc 0.49025[0m
[92maverage training of epoch 31: loss -11.40494 acc 0.44667 roc_auc 0.35620 prc_auc 0.56142[0m
[93maverage test of epoch 31: loss -11.55862 acc 0.65789 roc_auc 0.15692 prc_auc 0.51798[0m
[92maverage training of epoch 32: loss -11.70738 acc 0.66667 roc_auc 0.35640 prc_auc 0.56151[0m
[93maverage test of epoch 32: loss -11.85993 acc 0.65789 roc_auc 0.16000 prc_auc 0.52532[0m
[92maverage training of epoch 33: loss -12.00928 acc 0.66667 roc_auc 0.35640 prc_auc 0.56151[0m
[93maverage test of epoch 33: loss -12.16075 acc 0.65789 roc_auc 0.14000 prc_auc 0.52147[0m
[92maverage training of epoch 34: loss -12.31072 acc 0.66667 roc_auc 0.35660 prc_auc 0.56164[0m
[93maverage test of epoch 34: loss -12.46113 acc 0.65789 roc_auc 0.17231 prc_auc 0.54729[0m
[92maverage training of epoch 35: loss -12.61177 acc 0.66667 roc_auc 0.35640 prc_auc 0.56146[0m
[93maverage test of epoch 35: loss -12.76115 acc 0.65789 roc_auc 0.16923 prc_auc 0.58752[0m
[92maverage training of epoch 36: loss -12.91247 acc 0.66667 roc_auc 0.35640 prc_auc 0.56146[0m
[93maverage test of epoch 36: loss -13.06085 acc 0.65789 roc_auc 0.10923 prc_auc 0.55506[0m
[92maverage training of epoch 37: loss -13.21287 acc 0.66667 roc_auc 0.35620 prc_auc 0.56137[0m
[93maverage test of epoch 37: loss -13.36026 acc 0.65789 roc_auc 0.32462 prc_auc 0.58629[0m
[92maverage training of epoch 38: loss -13.51301 acc 0.66667 roc_auc 0.35660 prc_auc 0.56162[0m
[93maverage test of epoch 38: loss -13.65944 acc 0.65789 roc_auc 0.29692 prc_auc 0.58249[0m
[92maverage training of epoch 39: loss -13.81292 acc 0.66667 roc_auc 0.35700 prc_auc 0.56196[0m
[93maverage test of epoch 39: loss -13.95840 acc 0.65789 roc_auc 0.27231 prc_auc 0.57947[0m
[92maverage training of epoch 40: loss -14.11263 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 40: loss -14.25717 acc 0.65789 roc_auc 0.54615 prc_auc 0.69946[0m
[92maverage training of epoch 41: loss -14.41217 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 41: loss -14.55578 acc 0.65789 roc_auc 0.11846 prc_auc 0.56708[0m
[92maverage training of epoch 42: loss -14.71156 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 42: loss -14.85425 acc 0.65789 roc_auc 0.44923 prc_auc 0.63152[0m
[92maverage training of epoch 43: loss -15.01082 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 43: loss -15.15260 acc 0.65789 roc_auc 0.58462 prc_auc 0.71122[0m
[92maverage training of epoch 44: loss -15.30995 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 44: loss -15.45084 acc 0.65789 roc_auc 0.54923 prc_auc 0.68301[0m
[92maverage training of epoch 45: loss -15.60899 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 45: loss -15.74898 acc 0.65789 roc_auc 0.56308 prc_auc 0.69271[0m
[92maverage training of epoch 46: loss -15.90794 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 46: loss -16.04704 acc 0.65789 roc_auc 0.60000 prc_auc 0.73334[0m
[92maverage training of epoch 47: loss -16.20681 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 47: loss -16.34502 acc 0.65789 roc_auc 0.30615 prc_auc 0.57664[0m
[92maverage training of epoch 48: loss -16.50561 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 48: loss -16.64294 acc 0.65789 roc_auc 0.18000 prc_auc 0.56278[0m
[92maverage training of epoch 49: loss -16.80435 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 49: loss -16.94081 acc 0.65789 roc_auc 0.31385 prc_auc 0.57182[0m
[92maverage training of epoch 50: loss -17.10304 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 50: loss -17.23862 acc 0.65789 roc_auc 0.37077 prc_auc 0.61368[0m
[92maverage training of epoch 51: loss -17.40167 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 51: loss -17.53639 acc 0.65789 roc_auc 0.67385 prc_auc 0.76871[0m
[92maverage training of epoch 52: loss -17.70028 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 52: loss -17.83412 acc 0.65789 roc_auc 0.31385 prc_auc 0.59796[0m
[92maverage training of epoch 53: loss -17.99884 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 53: loss -18.13182 acc 0.65789 roc_auc 0.84000 prc_auc 0.89053[0m
[92maverage training of epoch 54: loss -18.29737 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 54: loss -18.42948 acc 0.65789 roc_auc 0.78923 prc_auc 0.85096[0m
[92maverage training of epoch 55: loss -18.59587 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 55: loss -18.72712 acc 0.65789 roc_auc 0.52000 prc_auc 0.67158[0m
[92maverage training of epoch 56: loss -18.89435 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 56: loss -19.02474 acc 0.65789 roc_auc 0.50308 prc_auc 0.66118[0m
[92maverage training of epoch 57: loss -19.19280 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 57: loss -19.32233 acc 0.65789 roc_auc 0.76154 prc_auc 0.82566[0m
[92maverage training of epoch 58: loss -19.49123 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 58: loss -19.61991 acc 0.65789 roc_auc 0.40462 prc_auc 0.64158[0m
[92maverage training of epoch 59: loss -19.78965 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 59: loss -19.91746 acc 0.65789 roc_auc 0.58462 prc_auc 0.73589[0m
[92maverage training of epoch 60: loss -20.08805 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 60: loss -20.21501 acc 0.65789 roc_auc 0.69692 prc_auc 0.76091[0m
[92maverage training of epoch 61: loss -20.38644 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 61: loss -20.51254 acc 0.65789 roc_auc 0.82308 prc_auc 0.86026[0m
[92maverage training of epoch 62: loss -20.68481 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 62: loss -20.81006 acc 0.65789 roc_auc 0.70000 prc_auc 0.79474[0m
[92maverage training of epoch 63: loss -20.98318 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 63: loss -21.10757 acc 0.65789 roc_auc 0.53692 prc_auc 0.67498[0m
[92maverage training of epoch 64: loss -21.28153 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 64: loss -21.40506 acc 0.65789 roc_auc 0.61385 prc_auc 0.71388[0m
[92maverage training of epoch 65: loss -21.57988 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 65: loss -21.70256 acc 0.65789 roc_auc 0.72154 prc_auc 0.79865[0m
[92maverage training of epoch 66: loss -21.87821 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 66: loss -22.00004 acc 0.65789 roc_auc 0.58154 prc_auc 0.70571[0m
[92maverage training of epoch 67: loss -22.17654 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 67: loss -22.29752 acc 0.65789 roc_auc 0.58000 prc_auc 0.71263[0m
[92maverage training of epoch 68: loss -22.47487 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 68: loss -22.59499 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 69: loss -22.77318 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 69: loss -22.89245 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 70: loss -23.07150 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 70: loss -23.18991 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 71: loss -23.36980 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 71: loss -23.48737 acc 0.65789 roc_auc 0.56154 prc_auc 0.69298[0m
[92maverage training of epoch 72: loss -23.66811 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 72: loss -23.78482 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 73: loss -23.96641 acc 0.66667 roc_auc 0.35710 prc_auc 0.56188[0m
[93maverage test of epoch 73: loss -24.08227 acc 0.65789 roc_auc 0.84308 prc_auc 0.87222[0m
[92maverage training of epoch 74: loss -24.26471 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 74: loss -24.37971 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 75: loss -24.56300 acc 0.66667 roc_auc 0.35710 prc_auc 0.56188[0m
[93maverage test of epoch 75: loss -24.67715 acc 0.65789 roc_auc 0.51538 prc_auc 0.66491[0m
[92maverage training of epoch 76: loss -24.86129 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 76: loss -24.97459 acc 0.65789 roc_auc 0.53846 prc_auc 0.67568[0m
[92maverage training of epoch 77: loss -25.15958 acc 0.66667 roc_auc 0.35720 prc_auc 0.56188[0m
[93maverage test of epoch 77: loss -25.27202 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 78: loss -25.45786 acc 0.66667 roc_auc 0.35710 prc_auc 0.56188[0m
[93maverage test of epoch 78: loss -25.56946 acc 0.65789 roc_auc 0.43231 prc_auc 0.63011[0m
[92maverage training of epoch 79: loss -25.75615 acc 0.66667 roc_auc 0.35700 prc_auc 0.56172[0m
[93maverage test of epoch 79: loss -25.86689 acc 0.65789 roc_auc 0.15846 prc_auc 0.58000[0m
[92maverage training of epoch 80: loss -26.05443 acc 0.66667 roc_auc 0.35700 prc_auc 0.56174[0m
[93maverage test of epoch 80: loss -26.16432 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 81: loss -26.35271 acc 0.66667 roc_auc 0.35710 prc_auc 0.56190[0m
[93maverage test of epoch 81: loss -26.46175 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 82: loss -26.65099 acc 0.66667 roc_auc 0.35730 prc_auc 0.56188[0m
[93maverage test of epoch 82: loss -26.75918 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 83: loss -26.94926 acc 0.66667 roc_auc 0.35700 prc_auc 0.56172[0m
[93maverage test of epoch 83: loss -27.05660 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 84: loss -27.24754 acc 0.66667 roc_auc 0.35710 prc_auc 0.56174[0m
[93maverage test of epoch 84: loss -27.35402 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 85: loss -27.54581 acc 0.66667 roc_auc 0.35710 prc_auc 0.56176[0m
[93maverage test of epoch 85: loss -27.65145 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 86: loss -27.84408 acc 0.66667 roc_auc 0.35720 prc_auc 0.56193[0m
[93maverage test of epoch 86: loss -27.94887 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 87: loss -28.14236 acc 0.66667 roc_auc 0.35720 prc_auc 0.56172[0m
[93maverage test of epoch 87: loss -28.24629 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 88: loss -28.44063 acc 0.66667 roc_auc 0.35730 prc_auc 0.56188[0m
[93maverage test of epoch 88: loss -28.54371 acc 0.65789 roc_auc 0.44000 prc_auc 0.63209[0m
[92maverage training of epoch 89: loss -28.73890 acc 0.66667 roc_auc 0.35690 prc_auc 0.56160[0m
[93maverage test of epoch 89: loss -28.84113 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -29.03717 acc 0.66667 roc_auc 0.35700 prc_auc 0.56174[0m
[93maverage test of epoch 90: loss -29.13855 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 91: loss -29.33544 acc 0.66667 roc_auc 0.35700 prc_auc 0.56158[0m
[93maverage test of epoch 91: loss -29.43597 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 92: loss -29.63371 acc 0.66667 roc_auc 0.35700 prc_auc 0.56152[0m
[93maverage test of epoch 92: loss -29.73339 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 93: loss -29.93198 acc 0.66667 roc_auc 0.35710 prc_auc 0.56170[0m
[93maverage test of epoch 93: loss -30.03080 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 94: loss -30.23024 acc 0.66667 roc_auc 0.35720 prc_auc 0.56168[0m
[93maverage test of epoch 94: loss -30.32822 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 95: loss -30.52851 acc 0.66667 roc_auc 0.35720 prc_auc 0.56166[0m
[93maverage test of epoch 95: loss -30.62564 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 96: loss -30.82678 acc 0.66667 roc_auc 0.35700 prc_auc 0.56150[0m
[93maverage test of epoch 96: loss -30.92305 acc 0.65789 roc_auc 0.48308 prc_auc 0.65095[0m
[92maverage training of epoch 97: loss -31.12504 acc 0.66667 roc_auc 0.35720 prc_auc 0.56178[0m
[93maverage test of epoch 97: loss -31.22047 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 98: loss -31.42331 acc 0.66667 roc_auc 0.35740 prc_auc 0.56195[0m
[93maverage test of epoch 98: loss -31.51788 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -31.72157 acc 0.66667 roc_auc 0.35740 prc_auc 0.56202[0m
[93maverage test of epoch 99: loss -31.81529 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.41255 acc 0.66667 roc_auc 0.37340 prc_auc 0.57976[0m
[93maverage test of epoch 0: loss -0.80164 acc 0.65789 roc_auc 0.15385 prc_auc 0.49597[0m
[92maverage training of epoch 1: loss -1.14402 acc 0.66667 roc_auc 0.36340 prc_auc 0.56835[0m
[93maverage test of epoch 1: loss -1.47047 acc 0.65789 roc_auc 0.15077 prc_auc 0.49502[0m
[92maverage training of epoch 2: loss -1.88567 acc 0.66667 roc_auc 0.34240 prc_auc 0.55660[0m
[93maverage test of epoch 2: loss -2.36954 acc 0.65789 roc_auc 0.12923 prc_auc 0.48869[0m
[92maverage training of epoch 3: loss -2.81016 acc 0.66667 roc_auc 0.41680 prc_auc 0.60583[0m
[93maverage test of epoch 3: loss -3.23144 acc 0.65789 roc_auc 0.20308 prc_auc 0.53775[0m
[92maverage training of epoch 4: loss -3.57902 acc 0.66667 roc_auc 0.42460 prc_auc 0.61532[0m
[93maverage test of epoch 4: loss -3.88818 acc 0.65789 roc_auc 0.22462 prc_auc 0.56821[0m
[92maverage training of epoch 5: loss -4.15818 acc 0.66667 roc_auc 0.42480 prc_auc 0.61543[0m
[93maverage test of epoch 5: loss -4.40398 acc 0.65789 roc_auc 0.29846 prc_auc 0.63441[0m
[92maverage training of epoch 6: loss -4.63746 acc 0.66667 roc_auc 0.41860 prc_auc 0.60435[0m
[93maverage test of epoch 6: loss -4.84491 acc 0.65789 roc_auc 0.42769 prc_auc 0.72351[0m
[92maverage training of epoch 7: loss -5.05755 acc 0.66667 roc_auc 0.42080 prc_auc 0.60818[0m
[93maverage test of epoch 7: loss -5.24092 acc 0.65789 roc_auc 0.76923 prc_auc 0.90248[0m
[92maverage training of epoch 8: loss -5.44206 acc 0.66667 roc_auc 0.42750 prc_auc 0.61471[0m
[93maverage test of epoch 8: loss -5.61073 acc 0.65789 roc_auc 0.91231 prc_auc 0.95144[0m
[92maverage training of epoch 9: loss -5.80625 acc 0.66667 roc_auc 0.43080 prc_auc 0.62547[0m
[93maverage test of epoch 9: loss -5.96628 acc 0.65789 roc_auc 0.90462 prc_auc 0.94549[0m
[92maverage training of epoch 10: loss -6.15984 acc 0.66667 roc_auc 0.43560 prc_auc 0.63299[0m
[93maverage test of epoch 10: loss -6.31502 acc 0.65789 roc_auc 0.90462 prc_auc 0.94573[0m
[92maverage training of epoch 11: loss -6.50882 acc 0.66667 roc_auc 0.43530 prc_auc 0.63357[0m
[93maverage test of epoch 11: loss -6.66158 acc 0.65789 roc_auc 0.90769 prc_auc 0.94743[0m
[92maverage training of epoch 12: loss -6.85679 acc 0.66667 roc_auc 0.42980 prc_auc 0.62475[0m
[93maverage test of epoch 12: loss -7.00855 acc 0.65789 roc_auc 0.90769 prc_auc 0.94708[0m
[92maverage training of epoch 13: loss -7.20521 acc 0.66667 roc_auc 0.42230 prc_auc 0.60426[0m
[93maverage test of epoch 13: loss -7.35614 acc 0.65789 roc_auc 0.91385 prc_auc 0.94584[0m
[92maverage training of epoch 14: loss -7.55325 acc 0.66667 roc_auc 0.41500 prc_auc 0.59859[0m
[93maverage test of epoch 14: loss -7.70250 acc 0.65789 roc_auc 0.84154 prc_auc 0.92488[0m
[92maverage training of epoch 15: loss -7.89878 acc 0.66667 roc_auc 0.41320 prc_auc 0.59588[0m
[93maverage test of epoch 15: loss -8.04521 acc 0.65789 roc_auc 0.80154 prc_auc 0.90321[0m
[92maverage training of epoch 16: loss -8.23981 acc 0.66667 roc_auc 0.41200 prc_auc 0.59414[0m
[93maverage test of epoch 16: loss -8.38273 acc 0.65789 roc_auc 0.67077 prc_auc 0.83413[0m
[92maverage training of epoch 17: loss -8.57545 acc 0.66667 roc_auc 0.41320 prc_auc 0.59493[0m
[93maverage test of epoch 17: loss -8.71470 acc 0.65789 roc_auc 0.47692 prc_auc 0.73906[0m
[92maverage training of epoch 18: loss -8.90572 acc 0.66667 roc_auc 0.41220 prc_auc 0.59260[0m
[93maverage test of epoch 18: loss -9.04150 acc 0.65789 roc_auc 0.38615 prc_auc 0.68606[0m
[92maverage training of epoch 19: loss -9.23118 acc 0.66667 roc_auc 0.41450 prc_auc 0.59395[0m
[93maverage test of epoch 19: loss -9.36380 acc 0.65789 roc_auc 0.36615 prc_auc 0.66089[0m
[92maverage training of epoch 20: loss -9.55250 acc 0.66667 roc_auc 0.41470 prc_auc 0.59387[0m
[93maverage test of epoch 20: loss -9.68228 acc 0.65789 roc_auc 0.27231 prc_auc 0.55020[0m
[92maverage training of epoch 21: loss -9.87034 acc 0.66667 roc_auc 0.41540 prc_auc 0.59437[0m
[93maverage test of epoch 21: loss -9.99760 acc 0.65789 roc_auc 0.22000 prc_auc 0.55497[0m
[92maverage training of epoch 22: loss -10.18528 acc 0.66667 roc_auc 0.41680 prc_auc 0.59753[0m
[93maverage test of epoch 22: loss -10.31027 acc 0.65789 roc_auc 0.22000 prc_auc 0.55650[0m
[92maverage training of epoch 23: loss -10.49779 acc 0.66667 roc_auc 0.41720 prc_auc 0.59917[0m
[93maverage test of epoch 23: loss -10.62073 acc 0.65789 roc_auc 0.24308 prc_auc 0.54440[0m
[92maverage training of epoch 24: loss -10.80827 acc 0.66667 roc_auc 0.41800 prc_auc 0.60047[0m
[93maverage test of epoch 24: loss -10.92934 acc 0.65789 roc_auc 0.27538 prc_auc 0.56020[0m
[92maverage training of epoch 25: loss -11.11704 acc 0.66667 roc_auc 0.41950 prc_auc 0.60358[0m
[93maverage test of epoch 25: loss -11.23640 acc 0.65789 roc_auc 0.27385 prc_auc 0.55932[0m
[92maverage training of epoch 26: loss -11.42437 acc 0.66667 roc_auc 0.41940 prc_auc 0.60346[0m
[93maverage test of epoch 26: loss -11.54214 acc 0.65789 roc_auc 0.36154 prc_auc 0.62357[0m
[92maverage training of epoch 27: loss -11.73048 acc 0.66667 roc_auc 0.41940 prc_auc 0.60346[0m
[93maverage test of epoch 27: loss -11.84676 acc 0.65789 roc_auc 0.37385 prc_auc 0.62872[0m
[92maverage training of epoch 28: loss -12.03554 acc 0.66667 roc_auc 0.42020 prc_auc 0.60518[0m
[93maverage test of epoch 28: loss -12.15043 acc 0.65789 roc_auc 0.39077 prc_auc 0.63827[0m
[92maverage training of epoch 29: loss -12.33971 acc 0.66667 roc_auc 0.42040 prc_auc 0.60559[0m
[93maverage test of epoch 29: loss -12.45328 acc 0.65789 roc_auc 0.46000 prc_auc 0.65467[0m
[92maverage training of epoch 30: loss -12.64312 acc 0.66667 roc_auc 0.42050 prc_auc 0.60521[0m
[93maverage test of epoch 30: loss -12.75543 acc 0.65789 roc_auc 0.48000 prc_auc 0.66180[0m
[92maverage training of epoch 31: loss -12.94587 acc 0.66667 roc_auc 0.42030 prc_auc 0.60491[0m
[93maverage test of epoch 31: loss -13.05698 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 32: loss -13.24806 acc 0.66667 roc_auc 0.42040 prc_auc 0.60530[0m
[93maverage test of epoch 32: loss -13.35800 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 33: loss -13.54975 acc 0.66667 roc_auc 0.42040 prc_auc 0.60495[0m
[93maverage test of epoch 33: loss -13.65858 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 34: loss -13.85102 acc 0.66667 roc_auc 0.42020 prc_auc 0.60491[0m
[93maverage test of epoch 34: loss -13.95877 acc 0.65789 roc_auc 0.56000 prc_auc 0.69895[0m
[92maverage training of epoch 35: loss -14.15193 acc 0.66667 roc_auc 0.42030 prc_auc 0.60495[0m
[93maverage test of epoch 35: loss -14.25862 acc 0.65789 roc_auc 0.37231 prc_auc 0.65385[0m
[92maverage training of epoch 36: loss -14.45251 acc 0.66667 roc_auc 0.42040 prc_auc 0.60491[0m
[93maverage test of epoch 36: loss -14.55817 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 37: loss -14.75281 acc 0.66667 roc_auc 0.42040 prc_auc 0.60491[0m
[93maverage test of epoch 37: loss -14.85747 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 38: loss -15.05288 acc 0.66667 roc_auc 0.42040 prc_auc 0.60491[0m
[93maverage test of epoch 38: loss -15.15654 acc 0.65789 roc_auc 0.39231 prc_auc 0.65368[0m
[92maverage training of epoch 39: loss -15.35273 acc 0.66667 roc_auc 0.42050 prc_auc 0.60495[0m
[93maverage test of epoch 39: loss -15.45542 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 40: loss -15.65239 acc 0.66667 roc_auc 0.42030 prc_auc 0.60491[0m
[93maverage test of epoch 40: loss -15.75413 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 41: loss -15.95189 acc 0.66667 roc_auc 0.42050 prc_auc 0.60536[0m
[93maverage test of epoch 41: loss -16.05268 acc 0.65789 roc_auc 0.25692 prc_auc 0.68526[0m
[92maverage training of epoch 42: loss -16.25125 acc 0.66667 roc_auc 0.42040 prc_auc 0.60495[0m
[93maverage test of epoch 42: loss -16.35111 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 43: loss -16.55049 acc 0.66667 roc_auc 0.42040 prc_auc 0.60454[0m
[93maverage test of epoch 43: loss -16.64942 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 44: loss -16.84961 acc 0.66667 roc_auc 0.42040 prc_auc 0.60500[0m
[93maverage test of epoch 44: loss -16.94763 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 45: loss -17.14864 acc 0.66667 roc_auc 0.42050 prc_auc 0.60492[0m
[93maverage test of epoch 45: loss -17.24575 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 46: loss -17.44759 acc 0.66667 roc_auc 0.42040 prc_auc 0.60478[0m
[93maverage test of epoch 46: loss -17.54380 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 47: loss -17.74646 acc 0.66667 roc_auc 0.42050 prc_auc 0.60456[0m
[93maverage test of epoch 47: loss -17.84177 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 48: loss -18.04527 acc 0.66667 roc_auc 0.42040 prc_auc 0.60486[0m
[93maverage test of epoch 48: loss -18.13969 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 49: loss -18.34401 acc 0.66667 roc_auc 0.42070 prc_auc 0.60459[0m
[93maverage test of epoch 49: loss -18.43755 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 50: loss -18.64271 acc 0.66667 roc_auc 0.42050 prc_auc 0.60477[0m
[93maverage test of epoch 50: loss -18.73537 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 51: loss -18.94137 acc 0.66667 roc_auc 0.42040 prc_auc 0.60471[0m
[93maverage test of epoch 51: loss -19.03314 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 52: loss -19.23998 acc 0.66667 roc_auc 0.42030 prc_auc 0.60502[0m
[93maverage test of epoch 52: loss -19.33088 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 53: loss -19.53856 acc 0.66667 roc_auc 0.42050 prc_auc 0.60486[0m
[93maverage test of epoch 53: loss -19.62859 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 54: loss -19.83711 acc 0.66667 roc_auc 0.42050 prc_auc 0.60503[0m
[93maverage test of epoch 54: loss -19.92627 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 55: loss -20.13563 acc 0.66667 roc_auc 0.42060 prc_auc 0.60526[0m
[93maverage test of epoch 55: loss -20.22392 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 56: loss -20.43412 acc 0.66667 roc_auc 0.42050 prc_auc 0.60519[0m
[93maverage test of epoch 56: loss -20.52155 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 57: loss -20.73260 acc 0.66667 roc_auc 0.42020 prc_auc 0.60572[0m
[93maverage test of epoch 57: loss -20.81916 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 58: loss -21.03105 acc 0.66667 roc_auc 0.42060 prc_auc 0.60470[0m
[93maverage test of epoch 58: loss -21.11675 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 59: loss -21.32949 acc 0.66667 roc_auc 0.42090 prc_auc 0.60406[0m
[93maverage test of epoch 59: loss -21.41432 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 60: loss -21.62791 acc 0.66667 roc_auc 0.42070 prc_auc 0.60567[0m
[93maverage test of epoch 60: loss -21.71189 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 61: loss -21.92632 acc 0.66667 roc_auc 0.42030 prc_auc 0.60528[0m
[93maverage test of epoch 61: loss -22.00943 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 62: loss -22.22472 acc 0.66667 roc_auc 0.42040 prc_auc 0.60546[0m
[93maverage test of epoch 62: loss -22.30697 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 63: loss -22.52310 acc 0.66667 roc_auc 0.42030 prc_auc 0.60527[0m
[93maverage test of epoch 63: loss -22.60450 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 64: loss -22.82147 acc 0.66667 roc_auc 0.42100 prc_auc 0.60429[0m
[93maverage test of epoch 64: loss -22.90201 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 65: loss -23.11984 acc 0.66667 roc_auc 0.42060 prc_auc 0.60487[0m
[93maverage test of epoch 65: loss -23.19952 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 66: loss -23.41820 acc 0.66667 roc_auc 0.42060 prc_auc 0.60494[0m
[93maverage test of epoch 66: loss -23.49702 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 67: loss -23.71655 acc 0.66667 roc_auc 0.42070 prc_auc 0.60382[0m
[93maverage test of epoch 67: loss -23.79452 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 68: loss -24.01489 acc 0.66667 roc_auc 0.42060 prc_auc 0.60492[0m
[93maverage test of epoch 68: loss -24.09200 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 69: loss -24.31323 acc 0.66667 roc_auc 0.42090 prc_auc 0.60290[0m
[93maverage test of epoch 69: loss -24.38949 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 70: loss -24.61156 acc 0.66667 roc_auc 0.42090 prc_auc 0.60342[0m
[93maverage test of epoch 70: loss -24.68696 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 71: loss -24.90989 acc 0.66667 roc_auc 0.42020 prc_auc 0.60064[0m
[93maverage test of epoch 71: loss -24.98444 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 72: loss -25.20821 acc 0.66667 roc_auc 0.42100 prc_auc 0.60181[0m
[93maverage test of epoch 72: loss -25.28191 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 73: loss -25.50653 acc 0.66667 roc_auc 0.42120 prc_auc 0.60396[0m
[93maverage test of epoch 73: loss -25.57938 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 74: loss -25.80485 acc 0.66667 roc_auc 0.42000 prc_auc 0.60433[0m
[93maverage test of epoch 74: loss -25.87684 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 75: loss -26.10316 acc 0.66667 roc_auc 0.42140 prc_auc 0.60194[0m
[93maverage test of epoch 75: loss -26.17430 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 76: loss -26.40147 acc 0.66667 roc_auc 0.42000 prc_auc 0.60311[0m
[93maverage test of epoch 76: loss -26.47176 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 77: loss -26.69978 acc 0.66667 roc_auc 0.42070 prc_auc 0.60322[0m
[93maverage test of epoch 77: loss -26.76921 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 78: loss -26.99808 acc 0.66667 roc_auc 0.41970 prc_auc 0.60052[0m
[93maverage test of epoch 78: loss -27.06667 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 79: loss -27.29639 acc 0.66667 roc_auc 0.42220 prc_auc 0.60662[0m
[93maverage test of epoch 79: loss -27.36412 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 80: loss -27.59469 acc 0.66667 roc_auc 0.42040 prc_auc 0.60155[0m
[93maverage test of epoch 80: loss -27.66157 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 81: loss -27.89299 acc 0.66667 roc_auc 0.41980 prc_auc 0.59867[0m
[93maverage test of epoch 81: loss -27.95902 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 82: loss -28.19129 acc 0.66667 roc_auc 0.41840 prc_auc 0.59915[0m
[93maverage test of epoch 82: loss -28.25646 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 83: loss -28.48959 acc 0.66667 roc_auc 0.42640 prc_auc 0.60807[0m
[93maverage test of epoch 83: loss -28.55391 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 84: loss -28.78788 acc 0.66667 roc_auc 0.42140 prc_auc 0.60065[0m
[93maverage test of epoch 84: loss -28.85135 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 85: loss -29.08618 acc 0.66667 roc_auc 0.41910 prc_auc 0.60400[0m
[93maverage test of epoch 85: loss -29.14880 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 86: loss -29.38447 acc 0.66667 roc_auc 0.41950 prc_auc 0.60288[0m
[93maverage test of epoch 86: loss -29.44624 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 87: loss -29.68276 acc 0.66667 roc_auc 0.42300 prc_auc 0.60613[0m
[93maverage test of epoch 87: loss -29.74368 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 88: loss -29.98106 acc 0.66667 roc_auc 0.42080 prc_auc 0.60613[0m
[93maverage test of epoch 88: loss -30.04112 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 89: loss -30.27935 acc 0.66667 roc_auc 0.42670 prc_auc 0.61107[0m
[93maverage test of epoch 89: loss -30.33857 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -30.57764 acc 0.66667 roc_auc 0.41890 prc_auc 0.60259[0m
[93maverage test of epoch 90: loss -30.63601 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 91: loss -30.87594 acc 0.66667 roc_auc 0.41930 prc_auc 0.60407[0m
[93maverage test of epoch 91: loss -30.93346 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 92: loss -31.17423 acc 0.66667 roc_auc 0.42810 prc_auc 0.61114[0m
[93maverage test of epoch 92: loss -31.23090 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 93: loss -31.47252 acc 0.66667 roc_auc 0.42820 prc_auc 0.61036[0m
[93maverage test of epoch 93: loss -31.52834 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 94: loss -31.77082 acc 0.66667 roc_auc 0.42720 prc_auc 0.61326[0m
[93maverage test of epoch 94: loss -31.82578 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 95: loss -32.06911 acc 0.66667 roc_auc 0.42430 prc_auc 0.61132[0m
[93maverage test of epoch 95: loss -32.12323 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 96: loss -32.36740 acc 0.66667 roc_auc 0.41650 prc_auc 0.60717[0m
[93maverage test of epoch 96: loss -32.42067 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 97: loss -32.66570 acc 0.66667 roc_auc 0.41520 prc_auc 0.60625[0m
[93maverage test of epoch 97: loss -32.71811 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 98: loss -32.96399 acc 0.66667 roc_auc 0.42680 prc_auc 0.61657[0m
[93maverage test of epoch 98: loss -33.01555 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -33.26228 acc 0.66667 roc_auc 0.43720 prc_auc 0.62406[0m
[93maverage test of epoch 99: loss -33.31300 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.55397 acc 0.66667 roc_auc 0.43320 prc_auc 0.63537[0m
[93maverage test of epoch 0: loss -1.06440 acc 0.65789 roc_auc 0.46769 prc_auc 0.74855[0m
[92maverage training of epoch 1: loss -1.51775 acc 0.66667 roc_auc 0.42600 prc_auc 0.63077[0m
[93maverage test of epoch 1: loss -1.94717 acc 0.65789 roc_auc 0.86462 prc_auc 0.94578[0m
[92maverage training of epoch 2: loss -2.42141 acc 0.66667 roc_auc 0.43360 prc_auc 0.63665[0m
[93maverage test of epoch 2: loss -2.95069 acc 0.65789 roc_auc 0.95692 prc_auc 0.98124[0m
[92maverage training of epoch 3: loss -3.62598 acc 0.66667 roc_auc 0.44680 prc_auc 0.64967[0m
[93maverage test of epoch 3: loss -4.33644 acc 0.65789 roc_auc 0.95077 prc_auc 0.97751[0m
[92maverage training of epoch 4: loss -4.92609 acc 0.66667 roc_auc 0.43740 prc_auc 0.63649[0m
[93maverage test of epoch 4: loss -5.36830 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 5: loss -5.69559 acc 0.66667 roc_auc 0.40880 prc_auc 0.60954[0m
[93maverage test of epoch 5: loss -5.95315 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 6: loss -6.20948 acc 0.66667 roc_auc 0.40280 prc_auc 0.60805[0m
[93maverage test of epoch 6: loss -6.41370 acc 0.65789 roc_auc 0.95538 prc_auc 0.97946[0m
[92maverage training of epoch 7: loss -6.64168 acc 0.66667 roc_auc 0.39700 prc_auc 0.60293[0m
[93maverage test of epoch 7: loss -6.82080 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 8: loss -7.03371 acc 0.66667 roc_auc 0.39160 prc_auc 0.60164[0m
[93maverage test of epoch 8: loss -7.19806 acc 0.65789 roc_auc 0.95231 prc_auc 0.97791[0m
[92maverage training of epoch 9: loss -7.40188 acc 0.66667 roc_auc 0.38930 prc_auc 0.60056[0m
[93maverage test of epoch 9: loss -7.55642 acc 0.65789 roc_auc 0.94923 prc_auc 0.97661[0m
[92maverage training of epoch 10: loss -7.75435 acc 0.66667 roc_auc 0.38780 prc_auc 0.60312[0m
[93maverage test of epoch 10: loss -7.90184 acc 0.65789 roc_auc 0.95385 prc_auc 0.97808[0m
[92maverage training of epoch 11: loss -8.09579 acc 0.66667 roc_auc 0.38680 prc_auc 0.60277[0m
[93maverage test of epoch 11: loss -8.23793 acc 0.65789 roc_auc 0.95231 prc_auc 0.97697[0m
[92maverage training of epoch 12: loss -8.42911 acc 0.66667 roc_auc 0.38640 prc_auc 0.60237[0m
[93maverage test of epoch 12: loss -8.56701 acc 0.65789 roc_auc 0.95231 prc_auc 0.97697[0m
[92maverage training of epoch 13: loss -8.75626 acc 0.66667 roc_auc 0.38560 prc_auc 0.60203[0m
[93maverage test of epoch 13: loss -8.89069 acc 0.65789 roc_auc 0.95231 prc_auc 0.97697[0m
[92maverage training of epoch 14: loss -9.07859 acc 0.66667 roc_auc 0.38540 prc_auc 0.60088[0m
[93maverage test of epoch 14: loss -9.21009 acc 0.65789 roc_auc 0.95077 prc_auc 0.97369[0m
[92maverage training of epoch 15: loss -9.39708 acc 0.66667 roc_auc 0.38520 prc_auc 0.60023[0m
[93maverage test of epoch 15: loss -9.52606 acc 0.65789 roc_auc 0.94923 prc_auc 0.97298[0m
[92maverage training of epoch 16: loss -9.71246 acc 0.66667 roc_auc 0.38440 prc_auc 0.59407[0m
[93maverage test of epoch 16: loss -9.83924 acc 0.65789 roc_auc 0.94923 prc_auc 0.97298[0m
[92maverage training of epoch 17: loss -10.02530 acc 0.66667 roc_auc 0.38380 prc_auc 0.59177[0m
[93maverage test of epoch 17: loss -10.15011 acc 0.65789 roc_auc 0.95538 prc_auc 0.97298[0m
[92maverage training of epoch 18: loss -10.33604 acc 0.66667 roc_auc 0.38350 prc_auc 0.59000[0m
[93maverage test of epoch 18: loss -10.45906 acc 0.65789 roc_auc 0.96769 prc_auc 0.97697[0m
[92maverage training of epoch 19: loss -10.64501 acc 0.66667 roc_auc 0.38330 prc_auc 0.58956[0m
[93maverage test of epoch 19: loss -10.76641 acc 0.65789 roc_auc 0.95385 prc_auc 0.97298[0m
[92maverage training of epoch 20: loss -10.95251 acc 0.66667 roc_auc 0.38300 prc_auc 0.58879[0m
[93maverage test of epoch 20: loss -11.07240 acc 0.65789 roc_auc 0.96154 prc_auc 0.97298[0m
[92maverage training of epoch 21: loss -11.25875 acc 0.66667 roc_auc 0.38140 prc_auc 0.58706[0m
[93maverage test of epoch 21: loss -11.37724 acc 0.65789 roc_auc 0.93692 prc_auc 0.95922[0m
[92maverage training of epoch 22: loss -11.56394 acc 0.66667 roc_auc 0.38080 prc_auc 0.58671[0m
[93maverage test of epoch 22: loss -11.68110 acc 0.65789 roc_auc 0.90769 prc_auc 0.93514[0m
[92maverage training of epoch 23: loss -11.86821 acc 0.66667 roc_auc 0.38070 prc_auc 0.58628[0m
[93maverage test of epoch 23: loss -11.98412 acc 0.65789 roc_auc 0.86000 prc_auc 0.90421[0m
[92maverage training of epoch 24: loss -12.17171 acc 0.66667 roc_auc 0.38040 prc_auc 0.58650[0m
[93maverage test of epoch 24: loss -12.28642 acc 0.65789 roc_auc 0.83077 prc_auc 0.87778[0m
[92maverage training of epoch 25: loss -12.47453 acc 0.66667 roc_auc 0.38050 prc_auc 0.58161[0m
[93maverage test of epoch 25: loss -12.58810 acc 0.65789 roc_auc 0.86000 prc_auc 0.90421[0m
[92maverage training of epoch 26: loss -12.77678 acc 0.66667 roc_auc 0.38050 prc_auc 0.58161[0m
[93maverage test of epoch 26: loss -12.88925 acc 0.65789 roc_auc 0.65385 prc_auc 0.73529[0m
[92maverage training of epoch 27: loss -13.07853 acc 0.66667 roc_auc 0.37950 prc_auc 0.57763[0m
[93maverage test of epoch 27: loss -13.18993 acc 0.65789 roc_auc 0.66000 prc_auc 0.76737[0m
[92maverage training of epoch 28: loss -13.37985 acc 0.66667 roc_auc 0.37900 prc_auc 0.57696[0m
[93maverage test of epoch 28: loss -13.49020 acc 0.65789 roc_auc 0.82615 prc_auc 0.84917[0m
[92maverage training of epoch 29: loss -13.68080 acc 0.66667 roc_auc 0.37900 prc_auc 0.57727[0m
[93maverage test of epoch 29: loss -13.79013 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -13.98142 acc 0.66667 roc_auc 0.37870 prc_auc 0.57646[0m
[93maverage test of epoch 30: loss -14.08976 acc 0.65789 roc_auc 0.74000 prc_auc 0.82211[0m
[92maverage training of epoch 31: loss -14.28175 acc 0.66667 roc_auc 0.37860 prc_auc 0.57646[0m
[93maverage test of epoch 31: loss -14.38912 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -14.58184 acc 0.66667 roc_auc 0.37840 prc_auc 0.57642[0m
[93maverage test of epoch 32: loss -14.68824 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -14.88171 acc 0.66667 roc_auc 0.37820 prc_auc 0.57603[0m
[93maverage test of epoch 33: loss -14.98717 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -15.18138 acc 0.66667 roc_auc 0.37810 prc_auc 0.57568[0m
[93maverage test of epoch 34: loss -15.28591 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -15.48090 acc 0.66667 roc_auc 0.37750 prc_auc 0.57508[0m
[93maverage test of epoch 35: loss -15.58450 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -15.78026 acc 0.66667 roc_auc 0.37730 prc_auc 0.57519[0m
[93maverage test of epoch 36: loss -15.88296 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -16.07951 acc 0.66667 roc_auc 0.37720 prc_auc 0.57475[0m
[93maverage test of epoch 37: loss -16.18129 acc 0.65789 roc_auc 0.52000 prc_auc 0.67158[0m
[92maverage training of epoch 38: loss -16.37863 acc 0.66667 roc_auc 0.37710 prc_auc 0.57495[0m
[93maverage test of epoch 38: loss -16.47952 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -16.67766 acc 0.66667 roc_auc 0.37670 prc_auc 0.57459[0m
[93maverage test of epoch 39: loss -16.77765 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -16.97660 acc 0.66667 roc_auc 0.37700 prc_auc 0.57450[0m
[93maverage test of epoch 40: loss -17.07571 acc 0.65789 roc_auc 0.66769 prc_auc 0.74769[0m
[92maverage training of epoch 41: loss -17.27547 acc 0.66667 roc_auc 0.37680 prc_auc 0.57509[0m
[93maverage test of epoch 41: loss -17.37369 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -17.57427 acc 0.66667 roc_auc 0.37680 prc_auc 0.57516[0m
[93maverage test of epoch 42: loss -17.67161 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -17.87301 acc 0.66667 roc_auc 0.37680 prc_auc 0.57472[0m
[93maverage test of epoch 43: loss -17.96948 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -18.17169 acc 0.66667 roc_auc 0.37710 prc_auc 0.57503[0m
[93maverage test of epoch 44: loss -18.26729 acc 0.65789 roc_auc 0.38000 prc_auc 0.60914[0m
[92maverage training of epoch 45: loss -18.47034 acc 0.66667 roc_auc 0.37660 prc_auc 0.57502[0m
[93maverage test of epoch 45: loss -18.56506 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -18.76894 acc 0.66667 roc_auc 0.37660 prc_auc 0.57568[0m
[93maverage test of epoch 46: loss -18.86279 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -19.06750 acc 0.66667 roc_auc 0.37700 prc_auc 0.57536[0m
[93maverage test of epoch 47: loss -19.16049 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -19.36603 acc 0.66667 roc_auc 0.37700 prc_auc 0.57501[0m
[93maverage test of epoch 48: loss -19.45816 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -19.66454 acc 0.66667 roc_auc 0.37670 prc_auc 0.57557[0m
[93maverage test of epoch 49: loss -19.75580 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 50: loss -19.96301 acc 0.66667 roc_auc 0.37710 prc_auc 0.57563[0m
[93maverage test of epoch 50: loss -20.05341 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 51: loss -20.26147 acc 0.66667 roc_auc 0.37700 prc_auc 0.57542[0m
[93maverage test of epoch 51: loss -20.35101 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 52: loss -20.55990 acc 0.66667 roc_auc 0.37700 prc_auc 0.57557[0m
[93maverage test of epoch 52: loss -20.64858 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 53: loss -20.85831 acc 0.66667 roc_auc 0.37710 prc_auc 0.57596[0m
[93maverage test of epoch 53: loss -20.94614 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 54: loss -21.15671 acc 0.66667 roc_auc 0.37720 prc_auc 0.57616[0m
[93maverage test of epoch 54: loss -21.24368 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 55: loss -21.45510 acc 0.66667 roc_auc 0.37720 prc_auc 0.57679[0m
[93maverage test of epoch 55: loss -21.54121 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 56: loss -21.75347 acc 0.66667 roc_auc 0.37750 prc_auc 0.57770[0m
[93maverage test of epoch 56: loss -21.83872 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 57: loss -22.05183 acc 0.66667 roc_auc 0.37700 prc_auc 0.57882[0m
[93maverage test of epoch 57: loss -22.13623 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 58: loss -22.35018 acc 0.66667 roc_auc 0.37700 prc_auc 0.57704[0m
[93maverage test of epoch 58: loss -22.43372 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 59: loss -22.64852 acc 0.66667 roc_auc 0.37790 prc_auc 0.57761[0m
[93maverage test of epoch 59: loss -22.73121 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 60: loss -22.94685 acc 0.66667 roc_auc 0.37680 prc_auc 0.57712[0m
[93maverage test of epoch 60: loss -23.02869 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 61: loss -23.24517 acc 0.66667 roc_auc 0.37740 prc_auc 0.57946[0m
[93maverage test of epoch 61: loss -23.32616 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 62: loss -23.54349 acc 0.66667 roc_auc 0.37710 prc_auc 0.57565[0m
[93maverage test of epoch 62: loss -23.62362 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 63: loss -23.84180 acc 0.66667 roc_auc 0.37600 prc_auc 0.57595[0m
[93maverage test of epoch 63: loss -23.92108 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 64: loss -24.14010 acc 0.66667 roc_auc 0.37890 prc_auc 0.57846[0m
[93maverage test of epoch 64: loss -24.21853 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 65: loss -24.43840 acc 0.66667 roc_auc 0.37770 prc_auc 0.57801[0m
[93maverage test of epoch 65: loss -24.51598 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 66: loss -24.73670 acc 0.66667 roc_auc 0.37720 prc_auc 0.57918[0m
[93maverage test of epoch 66: loss -24.81342 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 67: loss -25.03499 acc 0.66667 roc_auc 0.37900 prc_auc 0.57924[0m
[93maverage test of epoch 67: loss -25.11086 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 68: loss -25.33328 acc 0.66667 roc_auc 0.37740 prc_auc 0.57706[0m
[93maverage test of epoch 68: loss -25.40829 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 69: loss -25.63156 acc 0.66667 roc_auc 0.37720 prc_auc 0.57537[0m
[93maverage test of epoch 69: loss -25.70572 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 70: loss -25.92984 acc 0.66667 roc_auc 0.37850 prc_auc 0.57752[0m
[93maverage test of epoch 70: loss -26.00315 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 71: loss -26.22812 acc 0.66667 roc_auc 0.37780 prc_auc 0.58052[0m
[93maverage test of epoch 71: loss -26.30058 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 72: loss -26.52639 acc 0.66667 roc_auc 0.37540 prc_auc 0.57918[0m
[93maverage test of epoch 72: loss -26.59800 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 73: loss -26.82466 acc 0.66667 roc_auc 0.37500 prc_auc 0.57673[0m
[93maverage test of epoch 73: loss -26.89542 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 74: loss -27.12293 acc 0.66667 roc_auc 0.38070 prc_auc 0.58007[0m
[93maverage test of epoch 74: loss -27.19284 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 75: loss -27.42120 acc 0.66667 roc_auc 0.37790 prc_auc 0.57941[0m
[93maverage test of epoch 75: loss -27.49026 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 76: loss -27.71947 acc 0.66667 roc_auc 0.37960 prc_auc 0.57969[0m
[93maverage test of epoch 76: loss -27.78767 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 77: loss -28.01773 acc 0.66667 roc_auc 0.37920 prc_auc 0.58297[0m
[93maverage test of epoch 77: loss -28.08508 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 78: loss -28.31600 acc 0.66667 roc_auc 0.38030 prc_auc 0.58168[0m
[93maverage test of epoch 78: loss -28.38250 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 79: loss -28.61426 acc 0.66667 roc_auc 0.37680 prc_auc 0.58078[0m
[93maverage test of epoch 79: loss -28.67991 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 80: loss -28.91252 acc 0.66667 roc_auc 0.38390 prc_auc 0.58436[0m
[93maverage test of epoch 80: loss -28.97732 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 81: loss -29.21078 acc 0.66667 roc_auc 0.38200 prc_auc 0.58377[0m
[93maverage test of epoch 81: loss -29.27473 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 82: loss -29.50904 acc 0.66667 roc_auc 0.38180 prc_auc 0.58939[0m
[93maverage test of epoch 82: loss -29.57214 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 83: loss -29.80730 acc 0.66667 roc_auc 0.38350 prc_auc 0.59042[0m
[93maverage test of epoch 83: loss -29.86954 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 84: loss -30.10556 acc 0.66667 roc_auc 0.38290 prc_auc 0.58824[0m
[93maverage test of epoch 84: loss -30.16695 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 85: loss -30.40381 acc 0.66667 roc_auc 0.37710 prc_auc 0.58211[0m
[93maverage test of epoch 85: loss -30.46435 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 86: loss -30.70207 acc 0.66667 roc_auc 0.37670 prc_auc 0.58092[0m
[93maverage test of epoch 86: loss -30.76176 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 87: loss -31.00033 acc 0.66667 roc_auc 0.37590 prc_auc 0.58481[0m
[93maverage test of epoch 87: loss -31.05916 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 88: loss -31.29858 acc 0.66667 roc_auc 0.38370 prc_auc 0.59083[0m
[93maverage test of epoch 88: loss -31.35657 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 89: loss -31.59683 acc 0.66667 roc_auc 0.38110 prc_auc 0.58768[0m
[93maverage test of epoch 89: loss -31.65397 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -31.89508 acc 0.66667 roc_auc 0.37810 prc_auc 0.58805[0m
[93maverage test of epoch 90: loss -31.95137 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 91: loss -32.19334 acc 0.66667 roc_auc 0.38250 prc_auc 0.59170[0m
[93maverage test of epoch 91: loss -32.24877 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 92: loss -32.49159 acc 0.66667 roc_auc 0.38620 prc_auc 0.59291[0m
[93maverage test of epoch 92: loss -32.54617 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 93: loss -32.78984 acc 0.66667 roc_auc 0.37360 prc_auc 0.58766[0m
[93maverage test of epoch 93: loss -32.84358 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 94: loss -33.08810 acc 0.66667 roc_auc 0.38960 prc_auc 0.59830[0m
[93maverage test of epoch 94: loss -33.14098 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 95: loss -33.38635 acc 0.66667 roc_auc 0.39080 prc_auc 0.60004[0m
[93maverage test of epoch 95: loss -33.43837 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 96: loss -33.68460 acc 0.66667 roc_auc 0.38580 prc_auc 0.59651[0m
[93maverage test of epoch 96: loss -33.73577 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 97: loss -33.98285 acc 0.66667 roc_auc 0.38390 prc_auc 0.59728[0m
[93maverage test of epoch 97: loss -34.03317 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 98: loss -34.28110 acc 0.66667 roc_auc 0.37320 prc_auc 0.59644[0m
[93maverage test of epoch 98: loss -34.33058 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -34.57935 acc 0.66667 roc_auc 0.38770 prc_auc 0.60339[0m
[93maverage test of epoch 99: loss -34.62797 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.44623 acc 0.66225 roc_auc 0.42137 prc_auc 0.61139[0m
[93maverage test of epoch 0: loss -0.98321 acc 0.67568 roc_auc 0.49333 prc_auc 0.78338[0m
[92maverage training of epoch 1: loss -1.49600 acc 0.66225 roc_auc 0.41000 prc_auc 0.61669[0m
[93maverage test of epoch 1: loss -1.95574 acc 0.67568 roc_auc 0.83333 prc_auc 0.91580[0m
[92maverage training of epoch 2: loss -2.20691 acc 0.66225 roc_auc 0.40451 prc_auc 0.60051[0m
[93maverage test of epoch 2: loss -2.51610 acc 0.67568 roc_auc 0.83333 prc_auc 0.91580[0m
[92maverage training of epoch 3: loss -2.70428 acc 0.66225 roc_auc 0.42216 prc_auc 0.60809[0m
[93maverage test of epoch 3: loss -2.97580 acc 0.67568 roc_auc 0.87000 prc_auc 0.93133[0m
[92maverage training of epoch 4: loss -3.13735 acc 0.66225 roc_auc 0.42814 prc_auc 0.62048[0m
[93maverage test of epoch 4: loss -3.39687 acc 0.67568 roc_auc 0.86833 prc_auc 0.92994[0m
[92maverage training of epoch 5: loss -3.54440 acc 0.66225 roc_auc 0.43275 prc_auc 0.62193[0m
[93maverage test of epoch 5: loss -3.80001 acc 0.67568 roc_auc 0.86833 prc_auc 0.93137[0m
[92maverage training of epoch 6: loss -3.93794 acc 0.66225 roc_auc 0.43020 prc_auc 0.61808[0m
[93maverage test of epoch 6: loss -4.19174 acc 0.67568 roc_auc 0.86667 prc_auc 0.92904[0m
[92maverage training of epoch 7: loss -4.32173 acc 0.66225 roc_auc 0.42765 prc_auc 0.61632[0m
[93maverage test of epoch 7: loss -4.57387 acc 0.67568 roc_auc 0.86500 prc_auc 0.92939[0m
[92maverage training of epoch 8: loss -4.69665 acc 0.66225 roc_auc 0.42059 prc_auc 0.61096[0m
[93maverage test of epoch 8: loss -4.94681 acc 0.67568 roc_auc 0.86667 prc_auc 0.92965[0m
[92maverage training of epoch 9: loss -5.06288 acc 0.66225 roc_auc 0.41627 prc_auc 0.60770[0m
[93maverage test of epoch 9: loss -5.31082 acc 0.67568 roc_auc 0.86667 prc_auc 0.92991[0m
[92maverage training of epoch 10: loss -5.42069 acc 0.66225 roc_auc 0.40863 prc_auc 0.60077[0m
[93maverage test of epoch 10: loss -5.66643 acc 0.67568 roc_auc 0.86833 prc_auc 0.93054[0m
[92maverage training of epoch 11: loss -5.77064 acc 0.66225 roc_auc 0.40402 prc_auc 0.59629[0m
[93maverage test of epoch 11: loss -6.01441 acc 0.67568 roc_auc 0.86667 prc_auc 0.93154[0m
[92maverage training of epoch 12: loss -6.11355 acc 0.66225 roc_auc 0.39882 prc_auc 0.59207[0m
[93maverage test of epoch 12: loss -6.35566 acc 0.67568 roc_auc 0.86833 prc_auc 0.92821[0m
[92maverage training of epoch 13: loss -6.45028 acc 0.66225 roc_auc 0.39667 prc_auc 0.59100[0m
[93maverage test of epoch 13: loss -6.69111 acc 0.67568 roc_auc 0.86000 prc_auc 0.92570[0m
[92maverage training of epoch 14: loss -6.78170 acc 0.66225 roc_auc 0.39373 prc_auc 0.58865[0m
[93maverage test of epoch 14: loss -7.02159 acc 0.67568 roc_auc 0.86500 prc_auc 0.92376[0m
[92maverage training of epoch 15: loss -7.10859 acc 0.66225 roc_auc 0.39245 prc_auc 0.58835[0m
[93maverage test of epoch 15: loss -7.34785 acc 0.67568 roc_auc 0.85833 prc_auc 0.91941[0m
[92maverage training of epoch 16: loss -7.43162 acc 0.66225 roc_auc 0.38980 prc_auc 0.58657[0m
[93maverage test of epoch 16: loss -7.67054 acc 0.67568 roc_auc 0.86000 prc_auc 0.91777[0m
[92maverage training of epoch 17: loss -7.75138 acc 0.66225 roc_auc 0.38706 prc_auc 0.58548[0m
[93maverage test of epoch 17: loss -7.99019 acc 0.67568 roc_auc 0.87167 prc_auc 0.91867[0m
[92maverage training of epoch 18: loss -8.06836 acc 0.66225 roc_auc 0.38647 prc_auc 0.58527[0m
[93maverage test of epoch 18: loss -8.30726 acc 0.67568 roc_auc 0.86833 prc_auc 0.92296[0m
[92maverage training of epoch 19: loss -8.38297 acc 0.66225 roc_auc 0.38520 prc_auc 0.58387[0m
[93maverage test of epoch 19: loss -8.62213 acc 0.67568 roc_auc 0.84667 prc_auc 0.89590[0m
[92maverage training of epoch 20: loss -8.69556 acc 0.66225 roc_auc 0.38529 prc_auc 0.58403[0m
[93maverage test of epoch 20: loss -8.93512 acc 0.67568 roc_auc 0.82500 prc_auc 0.87120[0m
[92maverage training of epoch 21: loss -9.00642 acc 0.66225 roc_auc 0.38480 prc_auc 0.58400[0m
[93maverage test of epoch 21: loss -9.24652 acc 0.67568 roc_auc 0.87000 prc_auc 0.90108[0m
[92maverage training of epoch 22: loss -9.31580 acc 0.66225 roc_auc 0.38412 prc_auc 0.58385[0m
[93maverage test of epoch 22: loss -9.55653 acc 0.67568 roc_auc 0.66000 prc_auc 0.77268[0m
[92maverage training of epoch 23: loss -9.62391 acc 0.66225 roc_auc 0.38363 prc_auc 0.58357[0m
[93maverage test of epoch 23: loss -9.86536 acc 0.67568 roc_auc 0.84000 prc_auc 0.87252[0m
[92maverage training of epoch 24: loss -9.93092 acc 0.66225 roc_auc 0.38363 prc_auc 0.58337[0m
[93maverage test of epoch 24: loss -10.17317 acc 0.67568 roc_auc 0.70000 prc_auc 0.79751[0m
[92maverage training of epoch 25: loss -10.23699 acc 0.66225 roc_auc 0.38343 prc_auc 0.58361[0m
[93maverage test of epoch 25: loss -10.48009 acc 0.67568 roc_auc 0.68000 prc_auc 0.78032[0m
[92maverage training of epoch 26: loss -10.54224 acc 0.66225 roc_auc 0.38294 prc_auc 0.58257[0m
[93maverage test of epoch 26: loss -10.78625 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 27: loss -10.84678 acc 0.66225 roc_auc 0.38235 prc_auc 0.58319[0m
[93maverage test of epoch 27: loss -11.09175 acc 0.67568 roc_auc 0.60000 prc_auc 0.74054[0m
[92maverage training of epoch 28: loss -11.15070 acc 0.66225 roc_auc 0.38206 prc_auc 0.58315[0m
[93maverage test of epoch 28: loss -11.39668 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 29: loss -11.45409 acc 0.66225 roc_auc 0.38235 prc_auc 0.58384[0m
[93maverage test of epoch 29: loss -11.70110 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 30: loss -11.75701 acc 0.66225 roc_auc 0.38147 prc_auc 0.57530[0m
[93maverage test of epoch 30: loss -12.00509 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 31: loss -12.05953 acc 0.66225 roc_auc 0.38176 prc_auc 0.57627[0m
[93maverage test of epoch 31: loss -12.30870 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 32: loss -12.36169 acc 0.66225 roc_auc 0.38078 prc_auc 0.57393[0m
[93maverage test of epoch 32: loss -12.61198 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 33: loss -12.66354 acc 0.66225 roc_auc 0.37990 prc_auc 0.57196[0m
[93maverage test of epoch 33: loss -12.91497 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 34: loss -12.96513 acc 0.66225 roc_auc 0.37922 prc_auc 0.57232[0m
[93maverage test of epoch 34: loss -13.21771 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 35: loss -13.26648 acc 0.66225 roc_auc 0.37892 prc_auc 0.57197[0m
[93maverage test of epoch 35: loss -13.52023 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 36: loss -13.56762 acc 0.66225 roc_auc 0.37892 prc_auc 0.57225[0m
[93maverage test of epoch 36: loss -13.82255 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 37: loss -13.86858 acc 0.66225 roc_auc 0.37794 prc_auc 0.57117[0mUsing backend: pytorch
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))

[93maverage test of epoch 37: loss -14.12470 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 38: loss -14.16938 acc 0.66225 roc_auc 0.37784 prc_auc 0.57132[0m
[93maverage test of epoch 38: loss -14.42670 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 39: loss -14.47004 acc 0.66225 roc_auc 0.37784 prc_auc 0.57198[0m
[93maverage test of epoch 39: loss -14.72857 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 40: loss -14.77057 acc 0.66225 roc_auc 0.37686 prc_auc 0.57151[0m
[93maverage test of epoch 40: loss -15.03033 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 41: loss -15.07100 acc 0.66225 roc_auc 0.37706 prc_auc 0.57270[0m
[93maverage test of epoch 41: loss -15.33199 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 42: loss -15.37134 acc 0.66225 roc_auc 0.37637 prc_auc 0.57124[0m
[93maverage test of epoch 42: loss -15.63355 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 43: loss -15.67159 acc 0.66225 roc_auc 0.37578 prc_auc 0.57066[0m
[93maverage test of epoch 43: loss -15.93504 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 44: loss -15.97177 acc 0.66225 roc_auc 0.37608 prc_auc 0.57052[0m
[93maverage test of epoch 44: loss -16.23646 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 45: loss -16.27188 acc 0.66225 roc_auc 0.37608 prc_auc 0.57309[0m
[93maverage test of epoch 45: loss -16.53782 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 46: loss -16.57194 acc 0.66225 roc_auc 0.37608 prc_auc 0.57106[0m
[93maverage test of epoch 46: loss -16.83912 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 47: loss -16.87194 acc 0.66225 roc_auc 0.37578 prc_auc 0.57029[0m
[93maverage test of epoch 47: loss -17.14037 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 48: loss -17.17190 acc 0.66225 roc_auc 0.37578 prc_auc 0.57292[0m
[93maverage test of epoch 48: loss -17.44159 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 49: loss -17.47182 acc 0.66225 roc_auc 0.37549 prc_auc 0.57015[0m
[93maverage test of epoch 49: loss -17.74277 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 50: loss -17.77171 acc 0.66225 roc_auc 0.37422 prc_auc 0.57121[0m
[93maverage test of epoch 50: loss -18.04391 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 51: loss -18.07156 acc 0.66225 roc_auc 0.37422 prc_auc 0.57139[0m
[93maverage test of epoch 51: loss -18.34502 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 52: loss -18.37139 acc 0.66225 roc_auc 0.37598 prc_auc 0.57176[0m
[93maverage test of epoch 52: loss -18.64611 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 53: loss -18.67119 acc 0.66225 roc_auc 0.37382 prc_auc 0.56989[0m
[93maverage test of epoch 53: loss -18.94718 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 54: loss -18.97097 acc 0.66225 roc_auc 0.37461 prc_auc 0.57242[0m
[93maverage test of epoch 54: loss -19.24822 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 55: loss -19.27073 acc 0.66225 roc_auc 0.37588 prc_auc 0.57544[0m
[93maverage test of epoch 55: loss -19.54925 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 56: loss -19.57048 acc 0.66225 roc_auc 0.37500 prc_auc 0.57260[0m
[93maverage test of epoch 56: loss -19.85026 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 57: loss -19.87021 acc 0.66225 roc_auc 0.37598 prc_auc 0.57546[0m
[93maverage test of epoch 57: loss -20.15126 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 58: loss -20.16992 acc 0.66225 roc_auc 0.37529 prc_auc 0.57365[0m
[93maverage test of epoch 58: loss -20.45224 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 59: loss -20.46962 acc 0.66225 roc_auc 0.37637 prc_auc 0.57517[0m
[93maverage test of epoch 59: loss -20.75321 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 60: loss -20.76931 acc 0.66225 roc_auc 0.37588 prc_auc 0.57293[0m
[93maverage test of epoch 60: loss -21.05417 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 61: loss -21.06899 acc 0.66225 roc_auc 0.37539 prc_auc 0.57599[0m
[93maverage test of epoch 61: loss -21.35512 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 62: loss -21.36867 acc 0.66225 roc_auc 0.37520 prc_auc 0.57515[0m
[93maverage test of epoch 62: loss -21.65607 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 63: loss -21.66833 acc 0.66225 roc_auc 0.37510 prc_auc 0.57627[0m
[93maverage test of epoch 63: loss -21.95701 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 64: loss -21.96799 acc 0.66225 roc_auc 0.37431 prc_auc 0.57450[0m
[93maverage test of epoch 64: loss -22.25794 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 65: loss -22.26764 acc 0.66225 roc_auc 0.37147 prc_auc 0.57363[0m
[93maverage test of epoch 65: loss -22.55886 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 66: loss -22.56729 acc 0.66225 roc_auc 0.37461 prc_auc 0.57899[0m
[93maverage test of epoch 66: loss -22.85978 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 67: loss -22.86693 acc 0.66225 roc_auc 0.37578 prc_auc 0.57900[0m
[93maverage test of epoch 67: loss -23.16069 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 68: loss -23.16657 acc 0.66225 roc_auc 0.38098 prc_auc 0.58078[0m
[93maverage test of epoch 68: loss -23.46160 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 69: loss -23.46620 acc 0.66225 roc_auc 0.37314 prc_auc 0.57834[0m
[93maverage test of epoch 69: loss -23.76250 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 70: loss -23.76583 acc 0.66225 roc_auc 0.37627 prc_auc 0.58025[0m
[93maverage test of epoch 70: loss -24.06341 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 71: loss -24.06545 acc 0.66225 roc_auc 0.37667 prc_auc 0.58112[0m
[93maverage test of epoch 71: loss -24.36431 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 72: loss -24.36508 acc 0.66225 roc_auc 0.38353 prc_auc 0.59185[0m
[93maverage test of epoch 72: loss -24.66520 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 73: loss -24.66470 acc 0.66225 roc_auc 0.37559 prc_auc 0.58111[0m
[93maverage test of epoch 73: loss -24.96609 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 74: loss -24.96431 acc 0.66225 roc_auc 0.37696 prc_auc 0.58348[0m
[93maverage test of epoch 74: loss -25.26699 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 75: loss -25.26393 acc 0.66225 roc_auc 0.37618 prc_auc 0.58640[0m
[93maverage test of epoch 75: loss -25.56788 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 76: loss -25.56354 acc 0.66225 roc_auc 0.37941 prc_auc 0.58797[0m
[93maverage test of epoch 76: loss -25.86877 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 77: loss -25.86316 acc 0.66225 roc_auc 0.37794 prc_auc 0.58898[0m
[93maverage test of epoch 77: loss -26.16965 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 78: loss -26.16277 acc 0.66225 roc_auc 0.37922 prc_auc 0.59154[0m
[93maverage test of epoch 78: loss -26.47054 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 79: loss -26.46238 acc 0.66225 roc_auc 0.38775 prc_auc 0.59287[0m
[93maverage test of epoch 79: loss -26.77143 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 80: loss -26.76199 acc 0.66225 roc_auc 0.39039 prc_auc 0.59641[0m
[93maverage test of epoch 80: loss -27.07231 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 81: loss -27.06160 acc 0.66225 roc_auc 0.37627 prc_auc 0.59298[0m
[93maverage test of epoch 81: loss -27.37320 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 82: loss -27.36121 acc 0.66225 roc_auc 0.38392 prc_auc 0.59600[0m
[93maverage test of epoch 82: loss -27.67409 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 83: loss -27.66082 acc 0.66225 roc_auc 0.39304 prc_auc 0.60207[0m
[93maverage test of epoch 83: loss -27.97497 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 84: loss -27.96043 acc 0.66225 roc_auc 0.38853 prc_auc 0.60199[0m
[93maverage test of epoch 84: loss -28.27585 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 85: loss -28.26004 acc 0.66225 roc_auc 0.39559 prc_auc 0.60753[0m
[93maverage test of epoch 85: loss -28.57673 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 86: loss -28.55965 acc 0.66225 roc_auc 0.40833 prc_auc 0.62196[0m
[93maverage test of epoch 86: loss -28.87762 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 87: loss -28.85925 acc 0.66225 roc_auc 0.36706 prc_auc 0.59616[0m
[93maverage test of epoch 87: loss -29.17850 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 88: loss -29.15886 acc 0.66225 roc_auc 0.39725 prc_auc 0.60836[0m
[93maverage test of epoch 88: loss -29.47938 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 89: loss -29.45846 acc 0.66225 roc_auc 0.40167 prc_auc 0.61014[0m
[93maverage test of epoch 89: loss -29.78026 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 90: loss -29.75807 acc 0.66225 roc_auc 0.39765 prc_auc 0.61117[0m
[93maverage test of epoch 90: loss -30.08114 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 91: loss -30.05767 acc 0.66225 roc_auc 0.39225 prc_auc 0.61163[0m
[93maverage test of epoch 91: loss -30.38202 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 92: loss -30.35728 acc 0.66225 roc_auc 0.44775 prc_auc 0.63638[0m
[93maverage test of epoch 92: loss -30.68289 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 93: loss -30.65688 acc 0.66225 roc_auc 0.45373 prc_auc 0.63825[0m
[93maverage test of epoch 93: loss -30.98377 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 94: loss -30.95648 acc 0.66225 roc_auc 0.44265 prc_auc 0.63311[0m
[93maverage test of epoch 94: loss -31.28465 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 95: loss -31.25608 acc 0.66225 roc_auc 0.38667 prc_auc 0.61381[0m
[93maverage test of epoch 95: loss -31.58553 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 96: loss -31.55568 acc 0.66225 roc_auc 0.43225 prc_auc 0.63413[0m
[93maverage test of epoch 96: loss -31.88640 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 97: loss -31.85528 acc 0.66225 roc_auc 0.45284 prc_auc 0.64209[0m
[93maverage test of epoch 97: loss -32.18728 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 98: loss -32.15489 acc 0.66225 roc_auc 0.37461 prc_auc 0.61522[0m
[93maverage test of epoch 98: loss -32.48815 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 99: loss -32.45449 acc 0.66225 roc_auc 0.43088 prc_auc 0.63424[0m
[93maverage test of epoch 99: loss -32.78903 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.84013 acc 0.33113 roc_auc 0.37353 prc_auc 0.57907[0m
[93maverage test of epoch 0: loss -1.19592 acc 0.67568 roc_auc 0.56667 prc_auc 0.82206[0m
[92maverage training of epoch 1: loss -1.59353 acc 0.65563 roc_auc 0.42490 prc_auc 0.62996[0m
[93maverage test of epoch 1: loss -2.12334 acc 0.67568 roc_auc 0.93000 prc_auc 0.97316[0m
[92maverage training of epoch 2: loss -2.70960 acc 0.66225 roc_auc 0.43588 prc_auc 0.64110[0m
[93maverage test of epoch 2: loss -3.28193 acc 0.67568 roc_auc 0.94333 prc_auc 0.97669[0m
[92maverage training of epoch 3: loss -3.58994 acc 0.66225 roc_auc 0.44392 prc_auc 0.64852[0m
[93maverage test of epoch 3: loss -3.93309 acc 0.67568 roc_auc 0.95000 prc_auc 0.97877[0m
[92maverage training of epoch 4: loss -4.14030 acc 0.66225 roc_auc 0.44765 prc_auc 0.65417[0m
[93maverage test of epoch 4: loss -4.42504 acc 0.67568 roc_auc 0.95000 prc_auc 0.97888[0m
[92maverage training of epoch 5: loss -4.62112 acc 0.66225 roc_auc 0.44451 prc_auc 0.65330[0m
[93maverage test of epoch 5: loss -4.93033 acc 0.67568 roc_auc 0.95000 prc_auc 0.97888[0m
[92maverage training of epoch 6: loss -5.12944 acc 0.66225 roc_auc 0.45725 prc_auc 0.66094[0m
[93maverage test of epoch 6: loss -5.42351 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 7: loss -5.58332 acc 0.66225 roc_auc 0.43765 prc_auc 0.64187[0m
[93maverage test of epoch 7: loss -5.85188 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 8: loss -5.99058 acc 0.66225 roc_auc 0.41853 prc_auc 0.62417[0m
[93maverage test of epoch 8: loss -6.24597 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 9: loss -6.37075 acc 0.66225 roc_auc 0.40284 prc_auc 0.61254[0m
[93maverage test of epoch 9: loss -6.61819 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 10: loss -6.73297 acc 0.66225 roc_auc 0.39245 prc_auc 0.60752[0m
[93maverage test of epoch 10: loss -6.97534 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 11: loss -7.08249 acc 0.66225 roc_auc 0.38961 prc_auc 0.60662[0m
[93maverage test of epoch 11: loss -7.32157 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 12: loss -7.42265 acc 0.66225 roc_auc 0.38490 prc_auc 0.60060[0m
[93maverage test of epoch 12: loss -7.65958 acc 0.67568 roc_auc 0.92500 prc_auc 0.96822[0m
[92maverage training of epoch 13: loss -7.75566 acc 0.66225 roc_auc 0.38108 prc_auc 0.59405[0m
[93maverage test of epoch 13: loss -7.99123 acc 0.67568 roc_auc 0.93000 prc_auc 0.97294[0m
[92maverage training of epoch 14: loss -8.08309 acc 0.66225 roc_auc 0.38069 prc_auc 0.59378[0m
[93maverage test of epoch 14: loss -8.31786 acc 0.67568 roc_auc 0.92667 prc_auc 0.96988[0m
[92maverage training of epoch 15: loss -8.40606 acc 0.66225 roc_auc 0.37980 prc_auc 0.59121[0m
[93maverage test of epoch 15: loss -8.64045 acc 0.67568 roc_auc 0.92500 prc_auc 0.96853[0m
[92maverage training of epoch 16: loss -8.72543 acc 0.66225 roc_auc 0.37961 prc_auc 0.59063[0m
[93maverage test of epoch 16: loss -8.95975 acc 0.67568 roc_auc 0.93333 prc_auc 0.97135[0m
[92maverage training of epoch 17: loss -9.04184 acc 0.66225 roc_auc 0.37922 prc_auc 0.59228[0m
[93maverage test of epoch 17: loss -9.27633 acc 0.67568 roc_auc 0.93000 prc_auc 0.96875[0m
[92maverage training of epoch 18: loss -9.35582 acc 0.66225 roc_auc 0.37961 prc_auc 0.59193[0m
[93maverage test of epoch 18: loss -9.59066 acc 0.67568 roc_auc 0.93000 prc_auc 0.96801[0m
[92maverage training of epoch 19: loss -9.66775 acc 0.66225 roc_auc 0.37902 prc_auc 0.59119[0m
[93maverage test of epoch 19: loss -9.90310 acc 0.67568 roc_auc 0.92000 prc_auc 0.96028[0m
[92maverage training of epoch 20: loss -9.97796 acc 0.66225 roc_auc 0.37892 prc_auc 0.59099[0m
[93maverage test of epoch 20: loss -10.21395 acc 0.67568 roc_auc 0.92333 prc_auc 0.95098[0m
[92maverage training of epoch 21: loss -10.28673 acc 0.66225 roc_auc 0.37882 prc_auc 0.59080[0m
[93maverage test of epoch 21: loss -10.52345 acc 0.67568 roc_auc 0.94000 prc_auc 0.96632[0m
[92maverage training of epoch 22: loss -10.59426 acc 0.66225 roc_auc 0.37863 prc_auc 0.59085[0m
[93maverage test of epoch 22: loss -10.83180 acc 0.67568 roc_auc 0.82667 prc_auc 0.87924[0m
[92maverage training of epoch 23: loss -10.90075 acc 0.66225 roc_auc 0.37863 prc_auc 0.59087[0m
[93maverage test of epoch 23: loss -11.13916 acc 0.67568 roc_auc 0.80667 prc_auc 0.84431[0m
[92maverage training of epoch 24: loss -11.20633 acc 0.66225 roc_auc 0.37745 prc_auc 0.58463[0m
[93maverage test of epoch 24: loss -11.44568 acc 0.67568 roc_auc 0.79667 prc_auc 0.83926[0m
[92maverage training of epoch 25: loss -11.51114 acc 0.66225 roc_auc 0.37657 prc_auc 0.58242[0m
[93maverage test of epoch 25: loss -11.75148 acc 0.67568 roc_auc 0.92000 prc_auc 0.94811[0m
[92maverage training of epoch 26: loss -11.81529 acc 0.66225 roc_auc 0.37627 prc_auc 0.58248[0m
[93maverage test of epoch 26: loss -12.05665 acc 0.67568 roc_auc 0.66833 prc_auc 0.75939[0m
[92maverage training of epoch 27: loss -12.11885 acc 0.66225 roc_auc 0.37549 prc_auc 0.57400[0m
[93maverage test of epoch 27: loss -12.36128 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 28: loss -12.42193 acc 0.66225 roc_auc 0.37480 prc_auc 0.57280[0m
[93maverage test of epoch 28: loss -12.66544 acc 0.67568 roc_auc 0.75167 prc_auc 0.80977[0m
[92maverage training of epoch 29: loss -12.72457 acc 0.66225 roc_auc 0.37363 prc_auc 0.57210[0m
[93maverage test of epoch 29: loss -12.96920 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 30: loss -13.02683 acc 0.66225 roc_auc 0.37333 prc_auc 0.57106[0m
[93maverage test of epoch 30: loss -13.27260 acc 0.67568 roc_auc 0.79333 prc_auc 0.83776[0m
[92maverage training of epoch 31: loss -13.32877 acc 0.66225 roc_auc 0.37314 prc_auc 0.57136[0m
[93maverage test of epoch 31: loss -13.57570 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 32: loss -13.63043 acc 0.66225 roc_auc 0.37294 prc_auc 0.57119[0m
[93maverage test of epoch 32: loss -13.87853 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 33: loss -13.93184 acc 0.66225 roc_auc 0.37245 prc_auc 0.57052[0m
[93maverage test of epoch 33: loss -14.18112 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 34: loss -14.23304 acc 0.66225 roc_auc 0.37235 prc_auc 0.57005[0m
[93maverage test of epoch 34: loss -14.48352 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 35: loss -14.53405 acc 0.66225 roc_auc 0.37216 prc_auc 0.57142[0m
[93maverage test of epoch 35: loss -14.78573 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 36: loss -14.83489 acc 0.66225 roc_auc 0.37108 prc_auc 0.56899[0m
[93maverage test of epoch 36: loss -15.08779 acc 0.67568 roc_auc 0.71000 prc_auc 0.78371[0m
[92maverage training of epoch 37: loss -15.13559 acc 0.66225 roc_auc 0.37098 prc_auc 0.56945[0m
[93maverage test of epoch 37: loss -15.38971 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 38: loss -15.43616 acc 0.66225 roc_auc 0.37088 prc_auc 0.57073[0m
[93maverage test of epoch 38: loss -15.69151 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 39: loss -15.73662 acc 0.66225 roc_auc 0.37118 prc_auc 0.56995[0m
[93maverage test of epoch 39: loss -15.99321 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -16.03699 acc 0.66225 roc_auc 0.37059 prc_auc 0.57071[0m
[93maverage test of epoch 40: loss -16.29481 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -16.33726 acc 0.66225 roc_auc 0.36990 prc_auc 0.56980[0m
[93maverage test of epoch 41: loss -16.59633 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -16.63747 acc 0.66225 roc_auc 0.37069 prc_auc 0.57022[0m
[93maverage test of epoch 42: loss -16.89778 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -16.93760 acc 0.66225 roc_auc 0.37029 prc_auc 0.56974[0m
[93maverage test of epoch 43: loss -17.19918 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -17.23769 acc 0.66225 roc_auc 0.37029 prc_auc 0.57005[0m
[93maverage test of epoch 44: loss -17.50051 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -17.53771 acc 0.66225 roc_auc 0.37029 prc_auc 0.57165[0m
[93maverage test of epoch 45: loss -17.80180 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -17.83770 acc 0.66225 roc_auc 0.37000 prc_auc 0.56940[0m
[93maverage test of epoch 46: loss -18.10304 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -18.13764 acc 0.66225 roc_auc 0.36902 prc_auc 0.56969[0m
[93maverage test of epoch 47: loss -18.40424 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -18.43755 acc 0.66225 roc_auc 0.36922 prc_auc 0.57091[0m
[93maverage test of epoch 48: loss -18.70541 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -18.73742 acc 0.66225 roc_auc 0.37039 prc_auc 0.57170[0m
[93maverage test of epoch 49: loss -19.00655 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 50: loss -19.03727 acc 0.66225 roc_auc 0.36980 prc_auc 0.57152[0m
[93maverage test of epoch 50: loss -19.30767 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 51: loss -19.33710 acc 0.66225 roc_auc 0.36931 prc_auc 0.57075[0m
[93maverage test of epoch 51: loss -19.60876 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 52: loss -19.63690 acc 0.66225 roc_auc 0.36824 prc_auc 0.57077[0m
[93maverage test of epoch 52: loss -19.90983 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 53: loss -19.93668 acc 0.66225 roc_auc 0.36882 prc_auc 0.57111[0m
[93maverage test of epoch 53: loss -20.21088 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 54: loss -20.23645 acc 0.66225 roc_auc 0.37059 prc_auc 0.57202[0m
[93maverage test of epoch 54: loss -20.51191 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 55: loss -20.53620 acc 0.66225 roc_auc 0.36980 prc_auc 0.57001[0m
[93maverage test of epoch 55: loss -20.81293 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 56: loss -20.83593 acc 0.66225 roc_auc 0.36784 prc_auc 0.56937[0m
[93maverage test of epoch 56: loss -21.11394 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 57: loss -21.13565 acc 0.66225 roc_auc 0.36931 prc_auc 0.57161[0m
[93maverage test of epoch 57: loss -21.41492 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 58: loss -21.43536 acc 0.66225 roc_auc 0.36784 prc_auc 0.56971[0m
[93maverage test of epoch 58: loss -21.71590 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 59: loss -21.73506 acc 0.66225 roc_auc 0.37039 prc_auc 0.57196[0m
[93maverage test of epoch 59: loss -22.01687 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 60: loss -22.03474 acc 0.66225 roc_auc 0.37118 prc_auc 0.57284[0m
[93maverage test of epoch 60: loss -22.31783 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 61: loss -22.33442 acc 0.66225 roc_auc 0.36902 prc_auc 0.57108[0m
[93maverage test of epoch 61: loss -22.61878 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 62: loss -22.63409 acc 0.66225 roc_auc 0.36755 prc_auc 0.57210[0m
[93maverage test of epoch 62: loss -22.91972 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 63: loss -22.93375 acc 0.66225 roc_auc 0.36480 prc_auc 0.56872[0m
[93maverage test of epoch 63: loss -23.22066 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 64: loss -23.23341 acc 0.66225 roc_auc 0.36990 prc_auc 0.57390[0m
[93maverage test of epoch 64: loss -23.52159 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 65: loss -23.53307 acc 0.66225 roc_auc 0.37098 prc_auc 0.57766[0m
[93maverage test of epoch 65: loss -23.82251 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 66: loss -23.83271 acc 0.66225 roc_auc 0.36559 prc_auc 0.56971[0m
[93maverage test of epoch 66: loss -24.12344 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 67: loss -24.13236 acc 0.66225 roc_auc 0.36775 prc_auc 0.57348[0m
[93maverage test of epoch 67: loss -24.42435 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 68: loss -24.43200 acc 0.66225 roc_auc 0.36402 prc_auc 0.56960[0m
[93maverage test of epoch 68: loss -24.72527 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 69: loss -24.73164 acc 0.66225 roc_auc 0.37147 prc_auc 0.57695[0m
[93maverage test of epoch 69: loss -25.02618 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 70: loss -25.03127 acc 0.66225 roc_auc 0.37010 prc_auc 0.57644[0m
[93maverage test of epoch 70: loss -25.32709 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 71: loss -25.33090 acc 0.66225 roc_auc 0.37108 prc_auc 0.58129[0m
[93maverage test of epoch 71: loss -25.62799 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 72: loss -25.63053 acc 0.66225 roc_auc 0.36598 prc_auc 0.57380[0m
[93maverage test of epoch 72: loss -25.92890 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 73: loss -25.93016 acc 0.66225 roc_auc 0.37353 prc_auc 0.58473[0m
[93maverage test of epoch 73: loss -26.22980 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 74: loss -26.22979 acc 0.66225 roc_auc 0.36775 prc_auc 0.57619[0m
[93maverage test of epoch 74: loss -26.53070 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 75: loss -26.52941 acc 0.66225 roc_auc 0.36892 prc_auc 0.57945[0m
[93maverage test of epoch 75: loss -26.83159 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 76: loss -26.82903 acc 0.66225 roc_auc 0.37765 prc_auc 0.59085[0m
[93maverage test of epoch 76: loss -27.13249 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 77: loss -27.12865 acc 0.66225 roc_auc 0.37441 prc_auc 0.58427[0m
[93maverage test of epoch 77: loss -27.43338 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 78: loss -27.42827 acc 0.66225 roc_auc 0.37010 prc_auc 0.58149[0m
[93maverage test of epoch 78: loss -27.73428 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 79: loss -27.72789 acc 0.66225 roc_auc 0.37069 prc_auc 0.59053[0m
[93maverage test of epoch 79: loss -28.03517 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 80: loss -28.02751 acc 0.66225 roc_auc 0.37225 prc_auc 0.58608[0m
[93maverage test of epoch 80: loss -28.33606 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 81: loss -28.32712 acc 0.66225 roc_auc 0.37863 prc_auc 0.59062[0m
[93maverage test of epoch 81: loss -28.63695 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 82: loss -28.62674 acc 0.66225 roc_auc 0.37049 prc_auc 0.58926[0m
[93maverage test of epoch 82: loss -28.93784 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 83: loss -28.92635 acc 0.66225 roc_auc 0.38775 prc_auc 0.59858[0m
[93maverage test of epoch 83: loss -29.23873 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 84: loss -29.22597 acc 0.66225 roc_auc 0.36755 prc_auc 0.59009[0m
[93maverage test of epoch 84: loss -29.53962 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 85: loss -29.52559 acc 0.66225 roc_auc 0.38118 prc_auc 0.59929[0m
[93maverage test of epoch 85: loss -29.84051 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 86: loss -29.82520 acc 0.66225 roc_auc 0.37657 prc_auc 0.59618[0m
[93maverage test of epoch 86: loss -30.14141 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 87: loss -30.12482 acc 0.66225 roc_auc 0.37902 prc_auc 0.60055[0m
[93maverage test of epoch 87: loss -30.44229 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 88: loss -30.42443 acc 0.66225 roc_auc 0.39961 prc_auc 0.61449[0m
[93maverage test of epoch 88: loss -30.74318 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 89: loss -30.72405 acc 0.66225 roc_auc 0.41137 prc_auc 0.61533[0m
[93maverage test of epoch 89: loss -31.04407 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 90: loss -31.02366 acc 0.66225 roc_auc 0.42412 prc_auc 0.62195[0m
[93maverage test of epoch 90: loss -31.34496 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 91: loss -31.32328 acc 0.66225 roc_auc 0.41716 prc_auc 0.62006[0m
[93maverage test of epoch 91: loss -31.64585 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 92: loss -31.62289 acc 0.66225 roc_auc 0.36961 prc_auc 0.60214[0m
[93maverage test of epoch 92: loss -31.94674 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 93: loss -31.92250 acc 0.66225 roc_auc 0.37627 prc_auc 0.60341[0m
[93maverage test of epoch 93: loss -32.24763 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 94: loss -32.22211 acc 0.66225 roc_auc 0.38392 prc_auc 0.60794[0m
[93maverage test of epoch 94: loss -32.54852 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 95: loss -32.52173 acc 0.66225 roc_auc 0.35971 prc_auc 0.60306[0m
[93maverage test of epoch 95: loss -32.84940 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 96: loss -32.82134 acc 0.66225 roc_auc 0.43745 prc_auc 0.63606[0m
[93maverage test of epoch 96: loss -33.15029 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 97: loss -33.12095 acc 0.66225 roc_auc 0.41324 prc_auc 0.62254[0m
[93maverage test of epoch 97: loss -33.45118 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 98: loss -33.42056 acc 0.66225 roc_auc 0.42765 prc_auc 0.63225[0m
[93maverage test of epoch 98: loss -33.75206 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 99: loss -33.72017 acc 0.66225 roc_auc 0.42990 prc_auc 0.64165[0m
[93maverage test of epoch 99: loss -34.05295 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.0003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.66501 ROC_AUC (avg): 0.5 PRC_AUC (avg): 0.66501 

Average forward propagation time taken(ms): 2.4673485124197945
Average backward propagation time taken(ms): 0.8686449240521419

