# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 2)
('lr', 0.0001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-03-24-12/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-03-24-12/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 16,
 'epochs': 100,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 4,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.0001,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 1,
 'num_workers': 8,
 'number_of_mlp_layer': 2,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-18-03-24-12',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 100, 'learning_rate': 0.0001, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=4, bias=True)
    (ReLU1): ReLU()
    (Linear2): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.08068 acc 0.33333 roc_auc 0.36460 prc_auc 0.59698[0m
[93maverage test of epoch 0: loss -0.18369 acc 0.34211 roc_auc 0.29538 prc_auc 0.63862[0m
[92maverage training of epoch 1: loss -0.26995 acc 0.33333 roc_auc 0.39140 prc_auc 0.59264[0m
[93maverage test of epoch 1: loss -0.37357 acc 0.34211 roc_auc 0.26462 prc_auc 0.60933[0m
[92maverage training of epoch 2: loss -0.43582 acc 0.33333 roc_auc 0.52880 prc_auc 0.69662[0m
[93maverage test of epoch 2: loss -0.52477 acc 0.34211 roc_auc 0.26462 prc_auc 0.60931[0m
[92maverage training of epoch 3: loss -0.60092 acc 0.33333 roc_auc 0.53800 prc_auc 0.70254[0m
[93maverage test of epoch 3: loss -0.70744 acc 0.34211 roc_auc 0.28923 prc_auc 0.63378[0m
[92maverage training of epoch 4: loss -0.79847 acc 0.33333 roc_auc 0.54180 prc_auc 0.70587[0m
[93maverage test of epoch 4: loss -0.92307 acc 0.34211 roc_auc 0.27385 prc_auc 0.63004[0m
[92maverage training of epoch 5: loss -1.02981 acc 0.33333 roc_auc 0.53760 prc_auc 0.70331[0m
[93maverage test of epoch 5: loss -1.17389 acc 0.34211 roc_auc 0.26462 prc_auc 0.62040[0m
[92maverage training of epoch 6: loss -1.29721 acc 0.33333 roc_auc 0.52240 prc_auc 0.69310[0m
[93maverage test of epoch 6: loss -1.46201 acc 0.34211 roc_auc 0.16923 prc_auc 0.53651[0m
[92maverage training of epoch 7: loss -1.60351 acc 0.33333 roc_auc 0.49000 prc_auc 0.67514[0m
[93maverage test of epoch 7: loss -1.79111 acc 0.34211 roc_auc 0.12615 prc_auc 0.48627[0m
[92maverage training of epoch 8: loss -1.94636 acc 0.33333 roc_auc 0.43240 prc_auc 0.63872[0m
[93maverage test of epoch 8: loss -2.14633 acc 0.34211 roc_auc 0.12923 prc_auc 0.48907[0m
[92maverage training of epoch 9: loss -2.29589 acc 0.33333 roc_auc 0.35200 prc_auc 0.58336[0m
[93maverage test of epoch 9: loss -2.48750 acc 0.34211 roc_auc 0.12923 prc_auc 0.48907[0m
[92maverage training of epoch 10: loss -2.62528 acc 0.33333 roc_auc 0.26520 prc_auc 0.52966[0m
[93maverage test of epoch 10: loss -2.80843 acc 0.34211 roc_auc 0.13231 prc_auc 0.49041[0m
[92maverage training of epoch 11: loss -2.94141 acc 0.33333 roc_auc 0.18700 prc_auc 0.49944[0m
[93maverage test of epoch 11: loss -3.12267 acc 0.34211 roc_auc 0.13231 prc_auc 0.49041[0m
[92maverage training of epoch 12: loss -3.24990 acc 0.33333 roc_auc 0.18200 prc_auc 0.49715[0m
[93maverage test of epoch 12: loss -3.42407 acc 0.34211 roc_auc 0.13538 prc_auc 0.49118[0m
[92maverage training of epoch 13: loss -3.55182 acc 0.33333 roc_auc 0.17260 prc_auc 0.49510[0m
[93maverage test of epoch 13: loss -3.73019 acc 0.34211 roc_auc 0.13538 prc_auc 0.49118[0m
[92maverage training of epoch 14: loss -3.86486 acc 0.33333 roc_auc 0.18900 prc_auc 0.50167[0m
[93maverage test of epoch 14: loss -4.05170 acc 0.34211 roc_auc 0.13538 prc_auc 0.49118[0m
[92maverage training of epoch 15: loss -4.19949 acc 0.33333 roc_auc 0.24060 prc_auc 0.51875[0m
[93maverage test of epoch 15: loss -4.40221 acc 0.34211 roc_auc 0.14154 prc_auc 0.49269[0m
[92maverage training of epoch 16: loss -4.57119 acc 0.33333 roc_auc 0.29300 prc_auc 0.53564[0m
[93maverage test of epoch 16: loss -4.79632 acc 0.34211 roc_auc 0.13846 prc_auc 0.49190[0m
[92maverage training of epoch 17: loss -4.98167 acc 0.33333 roc_auc 0.23360 prc_auc 0.51411[0m
[93maverage test of epoch 17: loss -5.22191 acc 0.34211 roc_auc 0.13538 prc_auc 0.49114[0m
[92maverage training of epoch 18: loss -5.42048 acc 0.33333 roc_auc 0.31920 prc_auc 0.55064[0m
[93maverage test of epoch 18: loss -5.66822 acc 0.34211 roc_auc 0.13846 prc_auc 0.49475[0m
[92maverage training of epoch 19: loss -5.86386 acc 0.33333 roc_auc 0.33900 prc_auc 0.56530[0m
[93maverage test of epoch 19: loss -6.10695 acc 0.34211 roc_auc 0.14154 prc_auc 0.49523[0m
[92maverage training of epoch 20: loss -6.30206 acc 0.33333 roc_auc 0.36040 prc_auc 0.57888[0m
[93maverage test of epoch 20: loss -6.54275 acc 0.34211 roc_auc 0.13846 prc_auc 0.49235[0m
[92maverage training of epoch 21: loss -6.73962 acc 0.33333 roc_auc 0.37800 prc_auc 0.58924[0m
[93maverage test of epoch 21: loss -6.97975 acc 0.34211 roc_auc 0.13846 prc_auc 0.49446[0m
[92maverage training of epoch 22: loss -7.17971 acc 0.33333 roc_auc 0.38900 prc_auc 0.59888[0m
[93maverage test of epoch 22: loss -7.42000 acc 0.34211 roc_auc 0.13846 prc_auc 0.49446[0m
[92maverage training of epoch 23: loss -7.62307 acc 0.33333 roc_auc 0.39820 prc_auc 0.60713[0m
[93maverage test of epoch 23: loss -7.86320 acc 0.34211 roc_auc 0.13385 prc_auc 0.49084[0m
[92maverage training of epoch 24: loss -8.06970 acc 0.33333 roc_auc 0.40790 prc_auc 0.61555[0m
[93maverage test of epoch 24: loss -8.31022 acc 0.34211 roc_auc 0.13231 prc_auc 0.49858[0m
[92maverage training of epoch 25: loss -8.52057 acc 0.33333 roc_auc 0.41120 prc_auc 0.61855[0m
[93maverage test of epoch 25: loss -8.76152 acc 0.34211 roc_auc 0.13846 prc_auc 0.50634[0m
[92maverage training of epoch 26: loss -8.97620 acc 0.33333 roc_auc 0.41380 prc_auc 0.62046[0m
[93maverage test of epoch 26: loss -9.21804 acc 0.34211 roc_auc 0.16462 prc_auc 0.50545[0m
[92maverage training of epoch 27: loss -9.43784 acc 0.33333 roc_auc 0.41520 prc_auc 0.62144[0m
[93maverage test of epoch 27: loss -9.68116 acc 0.34211 roc_auc 0.16615 prc_auc 0.51301[0m
[92maverage training of epoch 28: loss -9.90666 acc 0.33333 roc_auc 0.41700 prc_auc 0.62269[0m
[93maverage test of epoch 28: loss -10.15199 acc 0.34211 roc_auc 0.17538 prc_auc 0.50711[0m
[92maverage training of epoch 29: loss -10.38369 acc 0.33333 roc_auc 0.41820 prc_auc 0.62380[0m
[93maverage test of epoch 29: loss -10.63130 acc 0.34211 roc_auc 0.70769 prc_auc 0.86611[0m
[92maverage training of epoch 30: loss -10.86956 acc 0.45333 roc_auc 0.41940 prc_auc 0.62513[0m
[93maverage test of epoch 30: loss -11.11949 acc 0.65789 roc_auc 0.85846 prc_auc 0.93318[0m
[92maverage training of epoch 31: loss -11.36469 acc 0.66667 roc_auc 0.41940 prc_auc 0.62513[0m
[93maverage test of epoch 31: loss -11.61687 acc 0.65789 roc_auc 0.86615 prc_auc 0.93301[0m
[92maverage training of epoch 32: loss -11.86935 acc 0.66667 roc_auc 0.41980 prc_auc 0.62604[0m
[93maverage test of epoch 32: loss -12.12432 acc 0.65789 roc_auc 0.86154 prc_auc 0.93301[0m
[92maverage training of epoch 33: loss -12.38402 acc 0.66667 roc_auc 0.42000 prc_auc 0.62613[0m
[93maverage test of epoch 33: loss -12.64135 acc 0.65789 roc_auc 0.86308 prc_auc 0.93352[0m
[92maverage training of epoch 34: loss -12.90835 acc 0.66667 roc_auc 0.42020 prc_auc 0.62629[0m
[93maverage test of epoch 34: loss -13.16774 acc 0.65789 roc_auc 0.86000 prc_auc 0.93114[0m
[92maverage training of epoch 35: loss -13.44212 acc 0.66667 roc_auc 0.42020 prc_auc 0.62629[0m
[93maverage test of epoch 35: loss -13.70411 acc 0.65789 roc_auc 0.85846 prc_auc 0.93146[0m
[92maverage training of epoch 36: loss -13.98650 acc 0.66667 roc_auc 0.42060 prc_auc 0.62654[0m
[93maverage test of epoch 36: loss -14.25102 acc 0.65789 roc_auc 0.86000 prc_auc 0.93164[0m
[92maverage training of epoch 37: loss -14.54125 acc 0.66667 roc_auc 0.42060 prc_auc 0.62654[0m
[93maverage test of epoch 37: loss -14.80822 acc 0.65789 roc_auc 0.85692 prc_auc 0.93120[0m
[92maverage training of epoch 38: loss -15.10660 acc 0.66667 roc_auc 0.42100 prc_auc 0.62689[0m
[93maverage test of epoch 38: loss -15.37573 acc 0.65789 roc_auc 0.86154 prc_auc 0.93462[0m
[92maverage training of epoch 39: loss -15.68230 acc 0.66667 roc_auc 0.42100 prc_auc 0.62689[0m
[93maverage test of epoch 39: loss -15.95365 acc 0.65789 roc_auc 0.86308 prc_auc 0.90692[0m
[92maverage training of epoch 40: loss -16.26856 acc 0.66667 roc_auc 0.42100 prc_auc 0.62689[0m
[93maverage test of epoch 40: loss -16.54249 acc 0.65789 roc_auc 0.85077 prc_auc 0.90783[0m
[92maverage training of epoch 41: loss -16.86646 acc 0.66667 roc_auc 0.42100 prc_auc 0.62689[0m
[93maverage test of epoch 41: loss -17.14302 acc 0.65789 roc_auc 0.88462 prc_auc 0.93679[0m
[92maverage training of epoch 42: loss -17.47610 acc 0.66667 roc_auc 0.42100 prc_auc 0.62689[0m
[93maverage test of epoch 42: loss -17.75518 acc 0.65789 roc_auc 0.90154 prc_auc 0.93165[0m
[92maverage training of epoch 43: loss -18.09700 acc 0.66667 roc_auc 0.42080 prc_auc 0.62680[0m
[93maverage test of epoch 43: loss -18.37834 acc 0.65789 roc_auc 0.82615 prc_auc 0.86936[0m
[92maverage training of epoch 44: loss -18.72973 acc 0.66667 roc_auc 0.42090 prc_auc 0.62680[0m
[93maverage test of epoch 44: loss -19.01417 acc 0.65789 roc_auc 0.72000 prc_auc 0.80842[0m
[92maverage training of epoch 45: loss -19.37491 acc 0.66667 roc_auc 0.42100 prc_auc 0.62697[0m
[93maverage test of epoch 45: loss -19.66179 acc 0.65789 roc_auc 0.80462 prc_auc 0.84026[0m
[92maverage training of epoch 46: loss -20.03245 acc 0.66667 roc_auc 0.42100 prc_auc 0.62697[0m
[93maverage test of epoch 46: loss -20.32215 acc 0.65789 roc_auc 0.80462 prc_auc 0.84026[0m
[92maverage training of epoch 47: loss -20.70274 acc 0.66667 roc_auc 0.42100 prc_auc 0.62697[0m
[93maverage test of epoch 47: loss -20.99513 acc 0.65789 roc_auc 0.78154 prc_auc 0.83920[0m
[92maverage training of epoch 48: loss -21.38591 acc 0.66667 roc_auc 0.42110 prc_auc 0.62697[0m
[93maverage test of epoch 48: loss -21.68099 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -22.08214 acc 0.66667 roc_auc 0.42100 prc_auc 0.62697[0m
[93maverage test of epoch 49: loss -22.37978 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 50: loss -22.79125 acc 0.66667 roc_auc 0.42090 prc_auc 0.62680[0m
[93maverage test of epoch 50: loss -23.09143 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 51: loss -23.51383 acc 0.66667 roc_auc 0.42110 prc_auc 0.62697[0m
[93maverage test of epoch 51: loss -23.81721 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 52: loss -24.25038 acc 0.66667 roc_auc 0.42080 prc_auc 0.62665[0m
[93maverage test of epoch 52: loss -24.55637 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 53: loss -25.00101 acc 0.66667 roc_auc 0.42030 prc_auc 0.62524[0m
[93maverage test of epoch 53: loss -25.31054 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 54: loss -25.76660 acc 0.66667 roc_auc 0.42050 prc_auc 0.62533[0m
[93maverage test of epoch 54: loss -26.07912 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 55: loss -26.54675 acc 0.66667 roc_auc 0.42040 prc_auc 0.62486[0m
[93maverage test of epoch 55: loss -26.86230 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 56: loss -27.34162 acc 0.66667 roc_auc 0.41970 prc_auc 0.62252[0m
[93maverage test of epoch 56: loss -27.66004 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 57: loss -28.15145 acc 0.66667 roc_auc 0.41870 prc_auc 0.62377[0m
[93maverage test of epoch 57: loss -28.47329 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 58: loss -28.97695 acc 0.66667 roc_auc 0.41500 prc_auc 0.62016[0m
[93maverage test of epoch 58: loss -29.30205 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 59: loss -29.81787 acc 0.66667 roc_auc 0.41780 prc_auc 0.62377[0m
[93maverage test of epoch 59: loss -30.14629 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 60: loss -30.67488 acc 0.66667 roc_auc 0.40790 prc_auc 0.62069[0m
[93maverage test of epoch 60: loss -31.00634 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 61: loss -31.54800 acc 0.66667 roc_auc 0.41920 prc_auc 0.62300[0m
[93maverage test of epoch 61: loss -31.88307 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 62: loss -32.43818 acc 0.66667 roc_auc 0.37910 prc_auc 0.61024[0m
[93maverage test of epoch 62: loss -32.77766 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 63: loss -33.34759 acc 0.66667 roc_auc 0.44000 prc_auc 0.64167[0m
[93maverage test of epoch 63: loss -33.69223 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 64: loss -34.27773 acc 0.66667 roc_auc 0.48530 prc_auc 0.66083[0m
[93maverage test of epoch 64: loss -34.62775 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 65: loss -35.22928 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 65: loss -35.58562 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 66: loss -36.20365 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 66: loss -36.56682 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 67: loss -37.20190 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 67: loss -37.57232 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 68: loss -38.22471 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 68: loss -38.60305 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 69: loss -39.27383 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 69: loss -39.66127 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 70: loss -40.35037 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 70: loss -40.74695 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 71: loss -41.45596 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 71: loss -41.86360 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 72: loss -42.59277 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 72: loss -43.01183 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 73: loss -43.76213 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 73: loss -44.19382 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 74: loss -44.96600 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 74: loss -45.41165 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 75: loss -46.20629 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 75: loss -46.66655 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 76: loss -47.48439 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 76: loss -47.96056 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 77: loss -48.80189 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 77: loss -49.29455 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 78: loss -50.15922 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 78: loss -50.66853 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 79: loss -51.55689 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 79: loss -52.08367 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 80: loss -52.99511 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 80: loss -53.53963 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 81: loss -54.47382 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 81: loss -55.03568 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 82: loss -55.99123 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 82: loss -56.56851 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 83: loss -57.54010 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 83: loss -58.12887 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 84: loss -59.11586 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 84: loss -59.71626 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 85: loss -60.71919 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 85: loss -61.33170 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 86: loss -62.35101 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 86: loss -62.97591 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 87: loss -64.01198 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 87: loss -64.64954 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 88: loss -65.70255 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 88: loss -66.35259 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 89: loss -67.42123 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 89: loss -68.08270 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -69.16705 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 90: loss -69.84023 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 91: loss -70.94088 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 91: loss -71.62610 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 92: loss -72.74347 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 92: loss -73.44099 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 93: loss -74.57558 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 93: loss -75.28568 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 94: loss -76.43787 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 94: loss -77.16073 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 95: loss -78.33090 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 95: loss -79.06680 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 96: loss -80.25521 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 96: loss -81.00427 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 97: loss -82.21128 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 97: loss -82.97371 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 98: loss -84.19959 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 98: loss -84.97555 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -86.22057 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 99: loss -87.01023 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=4, bias=True)
    (ReLU1): ReLU()
    (Linear2): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.01522 acc 0.38667 roc_auc 0.46940 prc_auc 0.65566[0m
[93maverage test of epoch 0: loss -0.14286 acc 0.65789 roc_auc 0.59692 prc_auc 0.80720[0m
[92maverage training of epoch 1: loss -0.18582 acc 0.66667 roc_auc 0.47620 prc_auc 0.65786[0m
[93maverage test of epoch 1: loss -0.32393 acc 0.65789 roc_auc 0.54462 prc_auc 0.79781[0m
[92maverage training of epoch 2: loss -0.39266 acc 0.66667 roc_auc 0.47460 prc_auc 0.65548[0m
[93maverage test of epoch 2: loss -0.55366 acc 0.65789 roc_auc 0.56308 prc_auc 0.81597[0m
[92maverage training of epoch 3: loss -0.65512 acc 0.66667 roc_auc 0.47400 prc_auc 0.66016[0m
[93maverage test of epoch 3: loss -0.83620 acc 0.65789 roc_auc 0.63692 prc_auc 0.84004[0m
[92maverage training of epoch 4: loss -0.96022 acc 0.66667 roc_auc 0.47560 prc_auc 0.66471[0m
[93maverage test of epoch 4: loss -1.14731 acc 0.65789 roc_auc 0.70462 prc_auc 0.87175[0m
[92maverage training of epoch 5: loss -1.28354 acc 0.66667 roc_auc 0.48020 prc_auc 0.66631[0m
[93maverage test of epoch 5: loss -1.46865 acc 0.65789 roc_auc 0.68308 prc_auc 0.86501[0m
[92maverage training of epoch 6: loss -1.61169 acc 0.66667 roc_auc 0.48800 prc_auc 0.67192[0m
[93maverage test of epoch 6: loss -1.79126 acc 0.65789 roc_auc 0.76154 prc_auc 0.88627[0m
[92maverage training of epoch 7: loss -1.94182 acc 0.66667 roc_auc 0.49300 prc_auc 0.67444[0m
[93maverage test of epoch 7: loss -2.11480 acc 0.65789 roc_auc 0.86769 prc_auc 0.92382[0m
[92maverage training of epoch 8: loss -2.27485 acc 0.66667 roc_auc 0.49400 prc_auc 0.67691[0m
[93maverage test of epoch 8: loss -2.44280 acc 0.65789 roc_auc 0.86615 prc_auc 0.92241[0m
[92maverage training of epoch 9: loss -2.61303 acc 0.66667 roc_auc 0.49240 prc_auc 0.67500[0m
[93maverage test of epoch 9: loss -2.77850 acc 0.65789 roc_auc 0.86462 prc_auc 0.92428[0m
[92maverage training of epoch 10: loss -2.96149 acc 0.66667 roc_auc 0.49080 prc_auc 0.67406[0m
[93maverage test of epoch 10: loss -3.12838 acc 0.65789 roc_auc 0.86769 prc_auc 0.92607[0m
[92maverage training of epoch 11: loss -3.32948 acc 0.66667 roc_auc 0.49010 prc_auc 0.67164[0m
[93maverage test of epoch 11: loss -3.50358 acc 0.65789 roc_auc 0.86615 prc_auc 0.92355[0m
[92maverage training of epoch 12: loss -3.73059 acc 0.66667 roc_auc 0.49060 prc_auc 0.67189[0m
[93maverage test of epoch 12: loss -3.91904 acc 0.65789 roc_auc 0.86000 prc_auc 0.91782[0m
[92maverage training of epoch 13: loss -4.18068 acc 0.66667 roc_auc 0.49580 prc_auc 0.67761[0m
[93maverage test of epoch 13: loss -4.39012 acc 0.65789 roc_auc 0.85846 prc_auc 0.91915[0m
[92maverage training of epoch 14: loss -4.69264 acc 0.66667 roc_auc 0.51780 prc_auc 0.69910[0m
[93maverage test of epoch 14: loss -4.92904 acc 0.65789 roc_auc 0.85846 prc_auc 0.91976[0m
[92maverage training of epoch 15: loss -5.27224 acc 0.66667 roc_auc 0.56700 prc_auc 0.74984[0m
[93maverage test of epoch 15: loss -5.52622 acc 0.65789 roc_auc 0.86308 prc_auc 0.91770[0m
[92maverage training of epoch 16: loss -5.87692 acc 0.66667 roc_auc 0.61870 prc_auc 0.78413[0m
[93maverage test of epoch 16: loss -6.08864 acc 0.65789 roc_auc 0.88154 prc_auc 0.92833[0m
[92maverage training of epoch 17: loss -6.42435 acc 0.66667 roc_auc 0.64470 prc_auc 0.78483[0m
[93maverage test of epoch 17: loss -6.58629 acc 0.65789 roc_auc 0.86615 prc_auc 0.90675[0m
[92maverage training of epoch 18: loss -6.92231 acc 0.66667 roc_auc 0.62620 prc_auc 0.75736[0m
[93maverage test of epoch 18: loss -7.06213 acc 0.65789 roc_auc 0.80769 prc_auc 0.83333[0m
[92maverage training of epoch 19: loss -7.40630 acc 0.66667 roc_auc 0.58020 prc_auc 0.72079[0m
[93maverage test of epoch 19: loss -7.53638 acc 0.65789 roc_auc 0.80769 prc_auc 0.83333[0m
[92maverage training of epoch 20: loss -7.89099 acc 0.66667 roc_auc 0.56230 prc_auc 0.69584[0m
[93maverage test of epoch 20: loss -8.01627 acc 0.65789 roc_auc 0.74615 prc_auc 0.79825[0m
[92maverage training of epoch 21: loss -8.38198 acc 0.66667 roc_auc 0.56500 prc_auc 0.69691[0m
[93maverage test of epoch 21: loss -8.50419 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -8.88100 acc 0.66667 roc_auc 0.50500 prc_auc 0.66890[0m
[93maverage test of epoch 22: loss -9.00071 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -9.38861 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 23: loss -9.50608 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -9.90506 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 24: loss -10.02042 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -10.43082 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 25: loss -10.54442 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -10.96664 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 26: loss -11.07872 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -11.51314 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 27: loss -11.62392 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -12.07092 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 28: loss -12.18062 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -12.64063 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 29: loss -12.74946 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -13.22297 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 30: loss -13.33123 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -13.81830 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 31: loss -13.92364 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -14.41999 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 32: loss -14.52172 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -15.03162 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 33: loss -15.13225 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -15.65628 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -15.75614 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -16.29481 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -16.39417 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -16.94799 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -17.04706 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -17.61652 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -17.71551 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -18.30108 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -18.40016 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -19.00231 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -19.10167 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -19.72087 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -19.82066 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -20.45738 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -20.55776 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -21.21247 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -21.31358 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -21.98676 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -22.08876 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -22.78088 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -22.88389 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -23.59543 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -23.69959 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -24.43102 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -24.53645 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -25.28827 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -25.39508 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -26.16777 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -26.27606 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -27.07010 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -27.17997 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 50: loss -27.99585 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 50: loss -28.10738 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 51: loss -28.94558 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 51: loss -29.05885 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 52: loss -29.91984 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 52: loss -30.03493 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 53: loss -30.91949 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 53: loss -31.03697 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 54: loss -31.94599 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 54: loss -32.06614 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 55: loss -33.00023 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 55: loss -33.12315 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 56: loss -34.08292 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 56: loss -34.20873 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 57: loss -35.19478 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 57: loss -35.32358 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 58: loss -36.33652 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 58: loss -36.46841 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 59: loss -37.50886 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 59: loss -37.64394 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 60: loss -38.71227 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 60: loss -38.84985 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 61: loss -39.94573 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 61: loss -40.08538 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 62: loss -41.20954 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 62: loss -41.35144 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 63: loss -42.50931 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 63: loss -42.66972 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 64: loss -43.88156 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 64: loss -44.05858 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 65: loss -45.30781 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 65: loss -45.49535 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 66: loss -46.78292 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 66: loss -46.98106 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 67: loss -48.30748 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 67: loss -48.51561 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 68: loss -49.88140 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 68: loss -50.09947 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 69: loss -51.50558 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 69: loss -51.73372 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 70: loss -53.18103 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 70: loss -53.41907 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 71: loss -54.90795 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 71: loss -55.15547 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 72: loss -56.68677 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 72: loss -56.94388 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 73: loss -58.51853 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 73: loss -58.78531 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 74: loss -60.40426 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 74: loss -60.68077 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 75: loss -62.34490 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 75: loss -62.63117 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 76: loss -64.34137 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 76: loss -64.63741 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 77: loss -66.39456 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 77: loss -66.70032 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 78: loss -68.50526 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 78: loss -68.82066 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 79: loss -70.67418 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 79: loss -70.99918 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 80: loss -72.90199 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 80: loss -73.23633 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 81: loss -75.18927 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 81: loss -75.53283 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 82: loss -77.53652 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 82: loss -77.88897 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 83: loss -79.94409 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 83: loss -80.30526 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 84: loss -82.41237 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 84: loss -82.78193 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 85: loss -84.94162 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 85: loss -85.31904 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 86: loss -87.53078 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 86: loss -87.91388 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 87: loss -90.17590 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 87: loss -90.56184 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 88: loss -92.87329 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 88: loss -93.26139 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 89: loss -95.62314 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 89: loss -96.01376 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -98.42666 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 90: loss -98.81982 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 91: loss -101.28431 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 91: loss -101.67913 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 92: loss -104.19445 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 92: loss -104.58993 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 93: loss -107.15618 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 93: loss -107.55138 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 94: loss -110.16766 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 94: loss -110.56078 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 95: loss -113.22698 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 95: loss -113.61803 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 96: loss -116.33513 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 96: loss -116.72460 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 97: loss -119.49341 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 97: loss -119.88155 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 98: loss -122.70295 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 98: loss -123.09002 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -125.96477 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 99: loss -126.35095 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=4, bias=True)
    (ReLU1): ReLU()
    (Linear2): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -1.01326 acc 0.33333 roc_auc 0.31380 prc_auc 0.55185[0m
[93maverage test of epoch 0: loss -1.19369 acc 0.34211 roc_auc 0.06154 prc_auc 0.46892[0m
[92maverage training of epoch 1: loss -1.32963 acc 0.33333 roc_auc 0.30660 prc_auc 0.54241[0m
[93maverage test of epoch 1: loss -1.50568 acc 0.34211 roc_auc 0.07077 prc_auc 0.47025[0m
[92maverage training of epoch 2: loss -1.64787 acc 0.33333 roc_auc 0.29800 prc_auc 0.54107[0m
[93maverage test of epoch 2: loss -1.83290 acc 0.34211 roc_auc 0.06462 prc_auc 0.46814[0m
[92maverage training of epoch 3: loss -1.99362 acc 0.33333 roc_auc 0.29620 prc_auc 0.54680[0m
[93maverage test of epoch 3: loss -2.20082 acc 0.34211 roc_auc 0.06769 prc_auc 0.47081[0m
[92maverage training of epoch 4: loss -2.39185 acc 0.33333 roc_auc 0.31240 prc_auc 0.55589[0m
[93maverage test of epoch 4: loss -2.63034 acc 0.34211 roc_auc 0.07692 prc_auc 0.47492[0m
[92maverage training of epoch 5: loss -2.85270 acc 0.33333 roc_auc 0.32560 prc_auc 0.55923[0m
[93maverage test of epoch 5: loss -3.11843 acc 0.34211 roc_auc 0.37385 prc_auc 0.71460[0m
[92maverage training of epoch 6: loss -3.35790 acc 0.33333 roc_auc 0.37380 prc_auc 0.59521[0m
[93maverage test of epoch 6: loss -3.63295 acc 0.34211 roc_auc 0.55385 prc_auc 0.80663[0m
[92maverage training of epoch 7: loss -3.87398 acc 0.33333 roc_auc 0.38440 prc_auc 0.60226[0m
[93maverage test of epoch 7: loss -4.13997 acc 0.34211 roc_auc 0.23077 prc_auc 0.57699[0m
[92maverage training of epoch 8: loss -4.36071 acc 0.33333 roc_auc 0.37860 prc_auc 0.59661[0m
[93maverage test of epoch 8: loss -4.60503 acc 0.34211 roc_auc 0.08000 prc_auc 0.50100[0m
[92maverage training of epoch 9: loss -4.81619 acc 0.33333 roc_auc 0.38250 prc_auc 0.59636[0m
[93maverage test of epoch 9: loss -5.05092 acc 0.34211 roc_auc 0.12308 prc_auc 0.53888[0m
[92maverage training of epoch 10: loss -5.25828 acc 0.33333 roc_auc 0.38380 prc_auc 0.59239[0m
[93maverage test of epoch 10: loss -5.48858 acc 0.34211 roc_auc 0.09385 prc_auc 0.48045[0m
[92maverage training of epoch 11: loss -5.69613 acc 0.33333 roc_auc 0.38360 prc_auc 0.59212[0m
[93maverage test of epoch 11: loss -5.92461 acc 0.34211 roc_auc 0.47077 prc_auc 0.75540[0m
[92maverage training of epoch 12: loss -6.13416 acc 0.33333 roc_auc 0.38600 prc_auc 0.59485[0m
[93maverage test of epoch 12: loss -6.36244 acc 0.34211 roc_auc 0.60769 prc_auc 0.82404[0m
[92maverage training of epoch 13: loss -6.57490 acc 0.33333 roc_auc 0.38720 prc_auc 0.59540[0m
[93maverage test of epoch 13: loss -6.80392 acc 0.34211 roc_auc 0.59692 prc_auc 0.81555[0m
[92maverage training of epoch 14: loss -7.02003 acc 0.33333 roc_auc 0.38940 prc_auc 0.59133[0m
[93maverage test of epoch 14: loss -7.25033 acc 0.34211 roc_auc 0.16923 prc_auc 0.52242[0m
[92maverage training of epoch 15: loss -7.47071 acc 0.33333 roc_auc 0.38940 prc_auc 0.59684[0m
[93maverage test of epoch 15: loss -7.70313 acc 0.34211 roc_auc 0.72923 prc_auc 0.88097[0m
[92maverage training of epoch 16: loss -7.92785 acc 0.33333 roc_auc 0.38980 prc_auc 0.59760[0m
[93maverage test of epoch 16: loss -8.16271 acc 0.34211 roc_auc 0.52615 prc_auc 0.77629[0m
[92maverage training of epoch 17: loss -8.39233 acc 0.33333 roc_auc 0.39140 prc_auc 0.59897[0m
[93maverage test of epoch 17: loss -8.62998 acc 0.34211 roc_auc 0.61538 prc_auc 0.82806[0m
[92maverage training of epoch 18: loss -8.86462 acc 0.58000 roc_auc 0.39200 prc_auc 0.59926[0m
[93maverage test of epoch 18: loss -9.10539 acc 0.65789 roc_auc 0.52923 prc_auc 0.78766[0m
[92maverage training of epoch 19: loss -9.34539 acc 0.66667 roc_auc 0.39280 prc_auc 0.60047[0m
[93maverage test of epoch 19: loss -9.58972 acc 0.65789 roc_auc 0.68462 prc_auc 0.85732[0m
[92maverage training of epoch 20: loss -9.83536 acc 0.66667 roc_auc 0.39280 prc_auc 0.60058[0m
[93maverage test of epoch 20: loss -10.08342 acc 0.65789 roc_auc 0.61692 prc_auc 0.81846[0m
[92maverage training of epoch 21: loss -10.33488 acc 0.66667 roc_auc 0.39300 prc_auc 0.60055[0m
[93maverage test of epoch 21: loss -10.58702 acc 0.65789 roc_auc 0.52000 prc_auc 0.76828[0m
[92maverage training of epoch 22: loss -10.84464 acc 0.66667 roc_auc 0.39340 prc_auc 0.60101[0m
[93maverage test of epoch 22: loss -11.10112 acc 0.65789 roc_auc 0.85846 prc_auc 0.93074[0m
[92maverage training of epoch 23: loss -11.36508 acc 0.66667 roc_auc 0.39500 prc_auc 0.60359[0m
[93maverage test of epoch 23: loss -11.62626 acc 0.65789 roc_auc 0.90769 prc_auc 0.95576[0m
[92maverage training of epoch 24: loss -11.89686 acc 0.66667 roc_auc 0.39520 prc_auc 0.60288[0m
[93maverage test of epoch 24: loss -12.16299 acc 0.65789 roc_auc 0.81846 prc_auc 0.91253[0m
[92maverage training of epoch 25: loss -12.44051 acc 0.66667 roc_auc 0.39600 prc_auc 0.60346[0m
[93maverage test of epoch 25: loss -12.71174 acc 0.65789 roc_auc 0.88923 prc_auc 0.93189[0m
[92maverage training of epoch 26: loss -12.99654 acc 0.66667 roc_auc 0.39720 prc_auc 0.60403[0m
[93maverage test of epoch 26: loss -13.27326 acc 0.65789 roc_auc 0.52154 prc_auc 0.75222[0m
[92maverage training of epoch 27: loss -13.56551 acc 0.66667 roc_auc 0.39760 prc_auc 0.60440[0m
[93maverage test of epoch 27: loss -13.84788 acc 0.65789 roc_auc 0.49692 prc_auc 0.70840[0m
[92maverage training of epoch 28: loss -14.14792 acc 0.66667 roc_auc 0.39780 prc_auc 0.60492[0m
[93maverage test of epoch 28: loss -14.43631 acc 0.65789 roc_auc 0.86615 prc_auc 0.90976[0m
[92maverage training of epoch 29: loss -14.74456 acc 0.66667 roc_auc 0.39900 prc_auc 0.60620[0m
[93maverage test of epoch 29: loss -15.03917 acc 0.65789 roc_auc 0.70769 prc_auc 0.79859[0m
[92maverage training of epoch 30: loss -15.35577 acc 0.66667 roc_auc 0.39940 prc_auc 0.60701[0m
[93maverage test of epoch 30: loss -15.65695 acc 0.65789 roc_auc 0.77538 prc_auc 0.84748[0m
[92maverage training of epoch 31: loss -15.98235 acc 0.66667 roc_auc 0.40140 prc_auc 0.60829[0m
[93maverage test of epoch 31: loss -16.29036 acc 0.65789 roc_auc 0.51538 prc_auc 0.66589[0m
[92maverage training of epoch 32: loss -16.62497 acc 0.66667 roc_auc 0.40220 prc_auc 0.60880[0m
[93maverage test of epoch 32: loss -16.94012 acc 0.65789 roc_auc 0.44000 prc_auc 0.66155[0m
[92maverage training of epoch 33: loss -17.28450 acc 0.66667 roc_auc 0.40320 prc_auc 0.61018[0m
[93maverage test of epoch 33: loss -17.60750 acc 0.65789 roc_auc 0.22769 prc_auc 0.56568[0m
[92maverage training of epoch 34: loss -17.96257 acc 0.66667 roc_auc 0.40420 prc_auc 0.60940[0m
[93maverage test of epoch 34: loss -18.29459 acc 0.65789 roc_auc 0.38462 prc_auc 0.61224[0m
[92maverage training of epoch 35: loss -18.66188 acc 0.66667 roc_auc 0.40760 prc_auc 0.61191[0m
[93maverage test of epoch 35: loss -19.00444 acc 0.65789 roc_auc 0.40154 prc_auc 0.63140[0m
[92maverage training of epoch 36: loss -19.38564 acc 0.66667 roc_auc 0.41000 prc_auc 0.61381[0m
[93maverage test of epoch 36: loss -19.74031 acc 0.65789 roc_auc 0.24000 prc_auc 0.55793[0m
[92maverage training of epoch 37: loss -20.13676 acc 0.66667 roc_auc 0.41290 prc_auc 0.61589[0m
[93maverage test of epoch 37: loss -20.50424 acc 0.65789 roc_auc 0.24000 prc_auc 0.55311[0m
[92maverage training of epoch 38: loss -20.91554 acc 0.66667 roc_auc 0.41740 prc_auc 0.61817[0m
[93maverage test of epoch 38: loss -21.29500 acc 0.65789 roc_auc 0.20154 prc_auc 0.58073[0m
[92maverage training of epoch 39: loss -21.72023 acc 0.66667 roc_auc 0.42000 prc_auc 0.62152[0m
[93maverage test of epoch 39: loss -22.11029 acc 0.65789 roc_auc 0.15538 prc_auc 0.57186[0m
[92maverage training of epoch 40: loss -22.54815 acc 0.66667 roc_auc 0.42160 prc_auc 0.62323[0m
[93maverage test of epoch 40: loss -22.94746 acc 0.65789 roc_auc 0.14923 prc_auc 0.56716[0m
[92maverage training of epoch 41: loss -23.39720 acc 0.66667 roc_auc 0.42420 prc_auc 0.62530[0m
[93maverage test of epoch 41: loss -23.80506 acc 0.65789 roc_auc 0.44000 prc_auc 0.72500[0m
[92maverage training of epoch 42: loss -24.26645 acc 0.66667 roc_auc 0.42580 prc_auc 0.62680[0m
[93maverage test of epoch 42: loss -24.68270 acc 0.65789 roc_auc 0.71231 prc_auc 0.86056[0m
[92maverage training of epoch 43: loss -25.15590 acc 0.66667 roc_auc 0.42720 prc_auc 0.62832[0m
[93maverage test of epoch 43: loss -25.58061 acc 0.65789 roc_auc 0.78462 prc_auc 0.86918[0m
[92maverage training of epoch 44: loss -26.06588 acc 0.66667 roc_auc 0.42820 prc_auc 0.62949[0m
[93maverage test of epoch 44: loss -26.49916 acc 0.65789 roc_auc 0.84000 prc_auc 0.89053[0m
[92maverage training of epoch 45: loss -26.99675 acc 0.66667 roc_auc 0.42900 prc_auc 0.62907[0m
[93maverage test of epoch 45: loss -27.43878 acc 0.65789 roc_auc 0.87077 prc_auc 0.90919[0m
[92maverage training of epoch 46: loss -27.94903 acc 0.66667 roc_auc 0.43020 prc_auc 0.63057[0m
[93maverage test of epoch 46: loss -28.39995 acc 0.65789 roc_auc 0.86000 prc_auc 0.90421[0m
[92maverage training of epoch 47: loss -28.92316 acc 0.66667 roc_auc 0.43100 prc_auc 0.63182[0m
[93maverage test of epoch 47: loss -29.38313 acc 0.65789 roc_auc 0.86000 prc_auc 0.90421[0m
[92maverage training of epoch 48: loss -29.91958 acc 0.66667 roc_auc 0.43100 prc_auc 0.63172[0m
[93maverage test of epoch 48: loss -30.38872 acc 0.65789 roc_auc 0.78000 prc_auc 0.84947[0m
[92maverage training of epoch 49: loss -30.93870 acc 0.66667 roc_auc 0.43150 prc_auc 0.63201[0m
[93maverage test of epoch 49: loss -31.41711 acc 0.65789 roc_auc 0.68615 prc_auc 0.77946[0m
[92maverage training of epoch 50: loss -31.98090 acc 0.66667 roc_auc 0.43380 prc_auc 0.63411[0m
[93maverage test of epoch 50: loss -32.46868 acc 0.65789 roc_auc 0.80000 prc_auc 0.86316[0m
[92maverage training of epoch 51: loss -33.04653 acc 0.66667 roc_auc 0.43530 prc_auc 0.63519[0m
[93maverage test of epoch 51: loss -33.54375 acc 0.65789 roc_auc 0.52000 prc_auc 0.67158[0m
[92maverage training of epoch 52: loss -34.13590 acc 0.66667 roc_auc 0.43720 prc_auc 0.63716[0m
[93maverage test of epoch 52: loss -34.64261 acc 0.65789 roc_auc 0.80000 prc_auc 0.86316[0m
[92maverage training of epoch 53: loss -35.24929 acc 0.66667 roc_auc 0.43860 prc_auc 0.63816[0m
[93maverage test of epoch 53: loss -35.76554 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 54: loss -36.38691 acc 0.66667 roc_auc 0.43950 prc_auc 0.63888[0m
[93maverage test of epoch 54: loss -36.91269 acc 0.65789 roc_auc 0.74000 prc_auc 0.82211[0m
[92maverage training of epoch 55: loss -37.54901 acc 0.66667 roc_auc 0.44030 prc_auc 0.63944[0m
[93maverage test of epoch 55: loss -38.08438 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 56: loss -38.73582 acc 0.66667 roc_auc 0.44130 prc_auc 0.64054[0m
[93maverage test of epoch 56: loss -39.28078 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 57: loss -39.94751 acc 0.66667 roc_auc 0.44210 prc_auc 0.64015[0m
[93maverage test of epoch 57: loss -40.50206 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 58: loss -41.18424 acc 0.66667 roc_auc 0.44210 prc_auc 0.64036[0m
[93maverage test of epoch 58: loss -41.74824 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 59: loss -42.44516 acc 0.66667 roc_auc 0.44210 prc_auc 0.64037[0m
[93maverage test of epoch 59: loss -43.01724 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 60: loss -43.72862 acc 0.66667 roc_auc 0.44150 prc_auc 0.63965[0m
[93maverage test of epoch 60: loss -44.30880 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 61: loss -45.03493 acc 0.66667 roc_auc 0.44240 prc_auc 0.64004[0m
[93maverage test of epoch 61: loss -45.62341 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 62: loss -46.36453 acc 0.66667 roc_auc 0.44340 prc_auc 0.63981[0m
[93maverage test of epoch 62: loss -46.96141 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 63: loss -47.71783 acc 0.66667 roc_auc 0.44370 prc_auc 0.63361[0m
[93maverage test of epoch 63: loss -48.32329 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 64: loss -49.09521 acc 0.66667 roc_auc 0.44510 prc_auc 0.63899[0m
[93maverage test of epoch 64: loss -49.70931 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 65: loss -50.49699 acc 0.66667 roc_auc 0.44180 prc_auc 0.63045[0m
[93maverage test of epoch 65: loss -51.11988 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 66: loss -51.93094 acc 0.66667 roc_auc 0.44260 prc_auc 0.63092[0m
[93maverage test of epoch 66: loss -52.58181 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 67: loss -53.43113 acc 0.66667 roc_auc 0.43950 prc_auc 0.62904[0m
[93maverage test of epoch 67: loss -54.10374 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 68: loss -54.97356 acc 0.66667 roc_auc 0.43440 prc_auc 0.62624[0m
[93maverage test of epoch 68: loss -55.65690 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 69: loss -56.54356 acc 0.66667 roc_auc 0.43690 prc_auc 0.62790[0m
[93maverage test of epoch 69: loss -57.23576 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 70: loss -58.13930 acc 0.66667 roc_auc 0.43640 prc_auc 0.63301[0m
[93maverage test of epoch 70: loss -58.84059 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 71: loss -59.76196 acc 0.66667 roc_auc 0.42100 prc_auc 0.62298[0m
[93maverage test of epoch 71: loss -60.47316 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 72: loss -61.41302 acc 0.66667 roc_auc 0.42140 prc_auc 0.62685[0m
[93maverage test of epoch 72: loss -62.13435 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 73: loss -63.09288 acc 0.66667 roc_auc 0.41000 prc_auc 0.62538[0m
[93maverage test of epoch 73: loss -63.82442 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 74: loss -64.80204 acc 0.66667 roc_auc 0.47000 prc_auc 0.65370[0m
[93maverage test of epoch 74: loss -65.54401 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 75: loss -66.54099 acc 0.66667 roc_auc 0.47500 prc_auc 0.65580[0m
[93maverage test of epoch 75: loss -67.29353 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 76: loss -68.31031 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 76: loss -69.07370 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 77: loss -70.11059 acc 0.66667 roc_auc 0.47500 prc_auc 0.65580[0m
[93maverage test of epoch 77: loss -70.88491 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 78: loss -71.94227 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 78: loss -72.72765 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 79: loss -73.80570 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 79: loss -74.60229 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 80: loss -75.70138 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 80: loss -76.50923 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 81: loss -77.62955 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 81: loss -78.44875 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 82: loss -79.59067 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 82: loss -80.42135 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 83: loss -81.58499 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 83: loss -82.42706 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 84: loss -83.61269 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 84: loss -84.46632 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 85: loss -85.67433 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 85: loss -86.53965 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 86: loss -87.77031 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 86: loss -88.64739 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 87: loss -89.90096 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 87: loss -90.78986 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 88: loss -92.06661 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 88: loss -92.96740 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 89: loss -94.26758 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 89: loss -95.18027 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -96.50403 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 90: loss -97.42859 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 91: loss -98.77630 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 91: loss -99.71291 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 92: loss -101.08483 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 92: loss -102.03354 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 93: loss -103.42993 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 93: loss -104.39079 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 94: loss -105.81193 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 94: loss -106.78499 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 95: loss -108.23113 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 95: loss -109.21644 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 96: loss -110.68783 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 96: loss -111.68542 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 97: loss -113.18235 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 97: loss -114.19226 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 98: loss -115.71498 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 98: loss -116.73727 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -118.28604 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 99: loss -119.32073 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=4, bias=True)
    (ReLU1): ReLU()
    (Linear2): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.60806 acc 0.66225 roc_auc 0.39373 prc_auc 0.57764[0m
[93maverage test of epoch 0: loss -0.66078 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 1: loss -0.67567 acc 0.66225 roc_auc 0.38510 prc_auc 0.57569[0m
[93maverage test of epoch 1: loss -0.72693 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 2: loss -0.74207 acc 0.66225 roc_auc 0.38529 prc_auc 0.57613[0m
[93maverage test of epoch 2: loss -0.79401 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 3: loss -0.80942 acc 0.66225 roc_auc 0.38490 prc_auc 0.57636[0m
[93maverage test of epoch 3: loss -0.86205 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 4: loss -0.87771 acc 0.66225 roc_auc 0.38549 prc_auc 0.57722[0m
[93maverage test of epoch 4: loss -0.93104 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 5: loss -0.94696 acc 0.66225 roc_auc 0.38569 prc_auc 0.57724[0m
[93maverage test of epoch 5: loss -1.00101 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 6: loss -1.01719 acc 0.66225 roc_auc 0.38520 prc_auc 0.57694[0m
[93maverage test of epoch 6: loss -1.07196 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 7: loss -1.08840 acc 0.66225 roc_auc 0.38647 prc_auc 0.57807[0m
[93maverage test of epoch 7: loss -1.14391 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 8: loss -1.16061 acc 0.66225 roc_auc 0.38755 prc_auc 0.57904[0m
[93maverage test of epoch 8: loss -1.21687 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 9: loss -1.23382 acc 0.66225 roc_auc 0.38843 prc_auc 0.57998[0m
[93maverage test of epoch 9: loss -1.29084 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 10: loss -1.30804 acc 0.66225 roc_auc 0.38912 prc_auc 0.58063[0m
[93maverage test of epoch 10: loss -1.36582 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 11: loss -1.38327 acc 0.66225 roc_auc 0.38922 prc_auc 0.58088[0m
[93maverage test of epoch 11: loss -1.44182 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 12: loss -1.45952 acc 0.66225 roc_auc 0.39000 prc_auc 0.58146[0m
[93maverage test of epoch 12: loss -1.51884 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 13: loss -1.53678 acc 0.66225 roc_auc 0.39039 prc_auc 0.58236[0m
[93maverage test of epoch 13: loss -1.59688 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 14: loss -1.61506 acc 0.66225 roc_auc 0.39108 prc_auc 0.58239[0m
[93maverage test of epoch 14: loss -1.67595 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 15: loss -1.69435 acc 0.66225 roc_auc 0.39176 prc_auc 0.58313[0m
[93maverage test of epoch 15: loss -1.75604 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 16: loss -1.77468 acc 0.66225 roc_auc 0.39235 prc_auc 0.58375[0m
[93maverage test of epoch 16: loss -1.83717 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 17: loss -1.85603 acc 0.66225 roc_auc 0.39373 prc_auc 0.58467[0m
[93maverage test of epoch 17: loss -1.91933 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 18: loss -1.93841 acc 0.66225 roc_auc 0.39431 prc_auc 0.58467[0m
[93maverage test of epoch 18: loss -2.00253 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 19: loss -2.02183 acc 0.66225 roc_auc 0.39480 prc_auc 0.58514[0m
[93maverage test of epoch 19: loss -2.08679 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 20: loss -2.10631 acc 0.66225 roc_auc 0.39549 prc_auc 0.58583[0m
[93maverage test of epoch 20: loss -2.17210 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 21: loss -2.19185 acc 0.66225 roc_auc 0.39618 prc_auc 0.58615[0m
[93maverage test of epoch 21: loss -2.25850 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 22: loss -2.27848 acc 0.66225 roc_auc 0.39657 prc_auc 0.58604[0m
[93maverage test of epoch 22: loss -2.34600 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 23: loss -2.37151 acc 0.66225 roc_auc 0.40333 prc_auc 0.59341[0m
[93maverage test of epoch 23: loss -2.58713 acc 0.67568 roc_auc 0.86333 prc_auc 0.92515[0m
[92maverage training of epoch 24: loss -3.25281 acc 0.66225 roc_auc 0.44961 prc_auc 0.63073[0m
[93maverage test of epoch 24: loss -3.78598 acc 0.67568 roc_auc 0.86333 prc_auc 0.92301[0m
[92maverage training of epoch 25: loss -4.13847 acc 0.66225 roc_auc 0.45784 prc_auc 0.64291[0m
[93maverage test of epoch 25: loss -4.54852 acc 0.67568 roc_auc 0.85833 prc_auc 0.92140[0m
[92maverage training of epoch 26: loss -4.93519 acc 0.66225 roc_auc 0.45951 prc_auc 0.64332[0m
[93maverage test of epoch 26: loss -5.43752 acc 0.67568 roc_auc 0.86000 prc_auc 0.92243[0m
[92maverage training of epoch 27: loss -5.87487 acc 0.66225 roc_auc 0.45765 prc_auc 0.63799[0m
[93maverage test of epoch 27: loss -6.39547 acc 0.67568 roc_auc 0.86000 prc_auc 0.92261[0m
[92maverage training of epoch 28: loss -6.81189 acc 0.66225 roc_auc 0.45196 prc_auc 0.63043[0m
[93maverage test of epoch 28: loss -7.33576 acc 0.67568 roc_auc 0.86000 prc_auc 0.92286[0m
[92maverage training of epoch 29: loss -7.75338 acc 0.66225 roc_auc 0.44882 prc_auc 0.62935[0m
[93maverage test of epoch 29: loss -8.30220 acc 0.67568 roc_auc 0.85667 prc_auc 0.91696[0m
[92maverage training of epoch 30: loss -8.75084 acc 0.66225 roc_auc 0.44627 prc_auc 0.62737[0m
[93maverage test of epoch 30: loss -9.34346 acc 0.67568 roc_auc 0.81333 prc_auc 0.90157[0m
[92maverage training of epoch 31: loss -9.79253 acc 0.66225 roc_auc 0.44490 prc_auc 0.62682[0m
[93maverage test of epoch 31: loss -10.38490 acc 0.67568 roc_auc 0.81000 prc_auc 0.89162[0m
[92maverage training of epoch 32: loss -10.81388 acc 0.66225 roc_auc 0.44529 prc_auc 0.62693[0m
[93maverage test of epoch 32: loss -11.39997 acc 0.67568 roc_auc 0.81333 prc_auc 0.89198[0m
[92maverage training of epoch 33: loss -11.81510 acc 0.66225 roc_auc 0.44588 prc_auc 0.62751[0mUsing backend: pytorch
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))

[93maverage test of epoch 33: loss -12.40000 acc 0.67568 roc_auc 0.85167 prc_auc 0.91049[0m
[92maverage training of epoch 34: loss -12.80543 acc 0.66225 roc_auc 0.44588 prc_auc 0.62751[0m
[93maverage test of epoch 34: loss -13.39245 acc 0.67568 roc_auc 0.86000 prc_auc 0.91827[0m
[92maverage training of epoch 35: loss -13.79136 acc 0.66225 roc_auc 0.44549 prc_auc 0.62699[0m
[93maverage test of epoch 35: loss -14.38351 acc 0.67568 roc_auc 0.85500 prc_auc 0.91098[0m
[92maverage training of epoch 36: loss -14.77874 acc 0.66225 roc_auc 0.44529 prc_auc 0.62693[0m
[93maverage test of epoch 36: loss -15.37854 acc 0.67568 roc_auc 0.88000 prc_auc 0.92024[0m
[92maverage training of epoch 37: loss -15.77219 acc 0.66225 roc_auc 0.44529 prc_auc 0.62693[0m
[93maverage test of epoch 37: loss -16.38178 acc 0.67568 roc_auc 0.87000 prc_auc 0.90108[0m
[92maverage training of epoch 38: loss -16.77585 acc 0.66225 roc_auc 0.44510 prc_auc 0.62687[0m
[93maverage test of epoch 38: loss -17.39727 acc 0.67568 roc_auc 0.84000 prc_auc 0.87252[0m
[92maverage training of epoch 39: loss -17.79339 acc 0.66225 roc_auc 0.44490 prc_auc 0.62681[0m
[93maverage test of epoch 39: loss -18.42839 acc 0.67568 roc_auc 0.58000 prc_auc 0.71644[0m
[92maverage training of epoch 40: loss -18.82788 acc 0.66225 roc_auc 0.44451 prc_auc 0.62623[0m
[93maverage test of epoch 40: loss -19.47790 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 41: loss -19.88160 acc 0.66225 roc_auc 0.44441 prc_auc 0.62599[0m
[93maverage test of epoch 41: loss -20.54761 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 42: loss -20.95633 acc 0.66225 roc_auc 0.44412 prc_auc 0.62586[0m
[93maverage test of epoch 42: loss -21.63948 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 43: loss -22.05398 acc 0.66225 roc_auc 0.44353 prc_auc 0.62507[0m
[93maverage test of epoch 43: loss -22.75528 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 44: loss -23.17622 acc 0.66225 roc_auc 0.44235 prc_auc 0.62400[0m
[93maverage test of epoch 44: loss -23.89661 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 45: loss -24.32452 acc 0.66225 roc_auc 0.44196 prc_auc 0.62548[0m
[93maverage test of epoch 45: loss -25.06482 acc 0.67568 roc_auc 0.84000 prc_auc 0.87854[0m
[92maverage training of epoch 46: loss -25.50016 acc 0.66225 roc_auc 0.44147 prc_auc 0.62331[0m
[93maverage test of epoch 46: loss -26.26116 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 47: loss -26.70435 acc 0.66225 roc_auc 0.44176 prc_auc 0.62693[0m
[93maverage test of epoch 47: loss -27.48676 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 48: loss -27.93812 acc 0.66225 roc_auc 0.44000 prc_auc 0.62761[0m
[93maverage test of epoch 48: loss -28.74262 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 49: loss -29.20247 acc 0.66225 roc_auc 0.44059 prc_auc 0.62880[0m
[93maverage test of epoch 49: loss -30.02972 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 50: loss -30.49828 acc 0.66225 roc_auc 0.43069 prc_auc 0.62865[0m
[93maverage test of epoch 50: loss -31.34888 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 51: loss -31.82642 acc 0.66225 roc_auc 0.42784 prc_auc 0.62210[0m
[93maverage test of epoch 51: loss -32.70097 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 52: loss -33.18768 acc 0.66225 roc_auc 0.45716 prc_auc 0.63692[0m
[93maverage test of epoch 52: loss -34.08674 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 53: loss -34.58281 acc 0.66225 roc_auc 0.43961 prc_auc 0.63443[0m
[93maverage test of epoch 53: loss -35.50692 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 54: loss -36.01250 acc 0.66225 roc_auc 0.48863 prc_auc 0.65721[0m
[93maverage test of epoch 54: loss -36.96220 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 55: loss -37.47744 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 55: loss -38.45328 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 56: loss -38.97829 acc 0.66225 roc_auc 0.50657 prc_auc 0.66527[0m
[93maverage test of epoch 56: loss -39.98077 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 57: loss -40.51568 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 57: loss -41.54530 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 58: loss -42.09023 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 58: loss -43.14753 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 59: loss -43.70252 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 59: loss -44.78789 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 60: loss -45.35304 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 60: loss -46.46707 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 61: loss -47.04253 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 61: loss -48.18569 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 62: loss -48.77142 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 62: loss -49.94413 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 63: loss -50.54017 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 63: loss -51.74295 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 64: loss -52.34944 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 64: loss -53.58272 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 65: loss -54.19967 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 65: loss -55.46400 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 66: loss -56.09153 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 66: loss -57.38746 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 67: loss -58.02561 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 67: loss -59.35352 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 68: loss -60.00223 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 68: loss -61.36254 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 69: loss -62.02173 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 69: loss -63.41484 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 70: loss -64.08462 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 70: loss -65.51101 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 71: loss -66.19135 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 71: loss -67.65153 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 72: loss -68.34251 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 72: loss -69.83701 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 73: loss -70.53868 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 73: loss -72.06798 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 74: loss -72.78036 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 74: loss -74.34493 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 75: loss -75.06803 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 75: loss -76.66835 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 76: loss -77.40214 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 76: loss -79.03865 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 77: loss -79.78312 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 77: loss -81.45629 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 78: loss -82.21147 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 78: loss -83.92181 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 79: loss -84.68770 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 79: loss -86.43568 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 80: loss -87.21226 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 80: loss -88.99837 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 81: loss -89.78562 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 81: loss -91.61031 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 82: loss -92.40821 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 82: loss -94.27195 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 83: loss -95.08045 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 83: loss -96.98370 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 84: loss -97.80280 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 84: loss -99.74605 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 85: loss -100.57574 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 85: loss -102.55948 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 86: loss -103.39974 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 86: loss -105.42446 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 87: loss -106.27524 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 87: loss -108.34143 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 88: loss -109.20272 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 88: loss -111.31084 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 89: loss -112.18256 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 89: loss -114.33306 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 90: loss -115.21522 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 90: loss -117.40868 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 91: loss -118.30125 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 91: loss -120.53813 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 92: loss -121.44109 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 92: loss -123.72190 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 93: loss -124.63521 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 93: loss -126.96045 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 94: loss -127.90108 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 94: loss -130.33750 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 95: loss -131.39773 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 95: loss -133.95425 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 96: loss -135.03681 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 96: loss -137.64745 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 97: loss -138.74267 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 97: loss -141.40496 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 98: loss -142.50876 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 98: loss -145.22030 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 99: loss -146.33484 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 99: loss -149.09867 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=4, bias=True)
    (ReLU1): ReLU()
    (Linear2): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss 0.51117 acc 0.33775 roc_auc 0.40314 prc_auc 0.60173[0m
[93maverage test of epoch 0: loss 0.44366 acc 0.32432 roc_auc 0.06667 prc_auc 0.48798[0m
[92maverage training of epoch 1: loss 0.37042 acc 0.33775 roc_auc 0.41353 prc_auc 0.62170[0m
[93maverage test of epoch 1: loss 0.31360 acc 0.32432 roc_auc 0.49000 prc_auc 0.78593[0m
[92maverage training of epoch 2: loss 0.24638 acc 0.33775 roc_auc 0.42686 prc_auc 0.62792[0m
[93maverage test of epoch 2: loss 0.19641 acc 0.32432 roc_auc 0.60000 prc_auc 0.83100[0m
[92maverage training of epoch 3: loss 0.13997 acc 0.33775 roc_auc 0.43235 prc_auc 0.63376[0m
[93maverage test of epoch 3: loss 0.09409 acc 0.32432 roc_auc 0.66667 prc_auc 0.86812[0m
[92maverage training of epoch 4: loss 0.04494 acc 0.33775 roc_auc 0.43588 prc_auc 0.64033[0m
[93maverage test of epoch 4: loss 0.00101 acc 0.32432 roc_auc 0.64333 prc_auc 0.86044[0m
[92maverage training of epoch 5: loss -0.04081 acc 0.33775 roc_auc 0.42176 prc_auc 0.62449[0m
[93maverage test of epoch 5: loss -0.07392 acc 0.48649 roc_auc 0.69333 prc_auc 0.88157[0m
[92maverage training of epoch 6: loss -0.08747 acc 0.62914 roc_auc 0.43000 prc_auc 0.63007[0m
[93maverage test of epoch 6: loss -0.10514 acc 0.67568 roc_auc 0.68000 prc_auc 0.87315[0m
[92maverage training of epoch 7: loss -0.11775 acc 0.66225 roc_auc 0.42784 prc_auc 0.63320[0m
[93maverage test of epoch 7: loss -0.13606 acc 0.67568 roc_auc 0.68000 prc_auc 0.87654[0m
[92maverage training of epoch 8: loss -0.14777 acc 0.66225 roc_auc 0.43235 prc_auc 0.63701[0m
[93maverage test of epoch 8: loss -0.16657 acc 0.67568 roc_auc 0.65333 prc_auc 0.86448[0m
[92maverage training of epoch 9: loss -0.17729 acc 0.66225 roc_auc 0.42686 prc_auc 0.63864[0m
[93maverage test of epoch 9: loss -0.19693 acc 0.67568 roc_auc 0.66833 prc_auc 0.86989[0m
[92maverage training of epoch 10: loss -0.20663 acc 0.66225 roc_auc 0.43176 prc_auc 0.64255[0m
[93maverage test of epoch 10: loss -0.22698 acc 0.67568 roc_auc 0.68167 prc_auc 0.87315[0m
[92maverage training of epoch 11: loss -0.23585 acc 0.66225 roc_auc 0.43510 prc_auc 0.64284[0m
[93maverage test of epoch 11: loss -0.25757 acc 0.67568 roc_auc 0.70667 prc_auc 0.88957[0m
[92maverage training of epoch 12: loss -0.26525 acc 0.66225 roc_auc 0.43902 prc_auc 0.64654[0m
[93maverage test of epoch 12: loss -0.28853 acc 0.67568 roc_auc 0.78833 prc_auc 0.92120[0m
[92maverage training of epoch 13: loss -0.29548 acc 0.66225 roc_auc 0.44490 prc_auc 0.65124[0m
[93maverage test of epoch 13: loss -0.32046 acc 0.67568 roc_auc 0.82333 prc_auc 0.93244[0m
[92maverage training of epoch 14: loss -0.32825 acc 0.66225 roc_auc 0.44235 prc_auc 0.64584[0m
[93maverage test of epoch 14: loss -0.36148 acc 0.67568 roc_auc 0.84000 prc_auc 0.94076[0m
[92maverage training of epoch 15: loss -0.36867 acc 0.66225 roc_auc 0.38137 prc_auc 0.56939[0m
[93maverage test of epoch 15: loss -0.39335 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 16: loss -0.38690 acc 0.66225 roc_auc 0.36961 prc_auc 0.56815[0m
[93maverage test of epoch 16: loss -0.40450 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 17: loss -0.39800 acc 0.66225 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 17: loss -0.41564 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 18: loss -0.40910 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 18: loss -0.42679 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 19: loss -0.42020 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 19: loss -0.43793 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 20: loss -0.43130 acc 0.66225 roc_auc 0.36980 prc_auc 0.56827[0m
[93maverage test of epoch 20: loss -0.44908 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 21: loss -0.44240 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 21: loss -0.46022 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 22: loss -0.45349 acc 0.66225 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 22: loss -0.47137 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 23: loss -0.46459 acc 0.66225 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 23: loss -0.48251 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 24: loss -0.47569 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 24: loss -0.49366 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 25: loss -0.48679 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 25: loss -0.50480 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 26: loss -0.49788 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 26: loss -0.51595 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 27: loss -0.50898 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 27: loss -0.52709 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 28: loss -0.52008 acc 0.66225 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 28: loss -0.53824 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 29: loss -0.53118 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 29: loss -0.54938 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 30: loss -0.54228 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 30: loss -0.56053 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 31: loss -0.55337 acc 0.66225 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 31: loss -0.57167 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 32: loss -0.56447 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 32: loss -0.58282 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 33: loss -0.57557 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 33: loss -0.59396 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 34: loss -0.58667 acc 0.66225 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 34: loss -0.60511 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 35: loss -0.59777 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 35: loss -0.61625 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 36: loss -0.60886 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 36: loss -0.62740 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 37: loss -0.61996 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 37: loss -0.63854 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 38: loss -0.63106 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 38: loss -0.64969 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 39: loss -0.64216 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 39: loss -0.66084 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -0.65326 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 40: loss -0.67198 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -0.66435 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 41: loss -0.68313 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -0.67545 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 42: loss -0.69427 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -0.68655 acc 0.66225 roc_auc 0.36971 prc_auc 0.56810[0m
[93maverage test of epoch 43: loss -0.70542 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -0.69765 acc 0.66225 roc_auc 0.36971 prc_auc 0.56810[0m
[93maverage test of epoch 44: loss -0.71656 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -0.70875 acc 0.66225 roc_auc 0.36971 prc_auc 0.56810[0m
[93maverage test of epoch 45: loss -0.72771 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -0.71984 acc 0.66225 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 46: loss -0.73885 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -0.73094 acc 0.66225 roc_auc 0.36971 prc_auc 0.56810[0m
[93maverage test of epoch 47: loss -0.75000 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -0.74204 acc 0.66225 roc_auc 0.36971 prc_auc 0.56810[0m
[93maverage test of epoch 48: loss -0.76114 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -0.75314 acc 0.66225 roc_auc 0.36971 prc_auc 0.56810[0m
[93maverage test of epoch 49: loss -0.77229 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 50: loss -0.76424 acc 0.66225 roc_auc 0.36971 prc_auc 0.56810[0m
[93maverage test of epoch 50: loss -0.78343 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 51: loss -0.77534 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 51: loss -0.79458 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 52: loss -0.78643 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 52: loss -0.80572 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 53: loss -0.79753 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 53: loss -0.81687 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 54: loss -0.80863 acc 0.66225 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 54: loss -0.82801 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 55: loss -0.81973 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 55: loss -0.83916 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 56: loss -0.83083 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 56: loss -0.85031 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 57: loss -0.84192 acc 0.66225 roc_auc 0.36971 prc_auc 0.56810[0m
[93maverage test of epoch 57: loss -0.86145 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 58: loss -0.85302 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 58: loss -0.87260 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 59: loss -0.86412 acc 0.66225 roc_auc 0.36971 prc_auc 0.56810[0m
[93maverage test of epoch 59: loss -0.88374 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 60: loss -0.87522 acc 0.66225 roc_auc 0.36971 prc_auc 0.56810[0m
[93maverage test of epoch 60: loss -0.89489 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 61: loss -0.88632 acc 0.66225 roc_auc 0.36971 prc_auc 0.56810[0m
[93maverage test of epoch 61: loss -0.90603 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 62: loss -0.89741 acc 0.66225 roc_auc 0.36971 prc_auc 0.56810[0m
[93maverage test of epoch 62: loss -0.91718 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 63: loss -0.90851 acc 0.66225 roc_auc 0.36971 prc_auc 0.56810[0m
[93maverage test of epoch 63: loss -0.92832 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 64: loss -0.91961 acc 0.66225 roc_auc 0.36971 prc_auc 0.56808[0m
[93maverage test of epoch 64: loss -0.93947 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 65: loss -0.93068 acc 0.66225 roc_auc 0.36539 prc_auc 0.56678[0m
[93maverage test of epoch 65: loss -0.95061 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 66: loss -0.94181 acc 0.66225 roc_auc 0.36971 prc_auc 0.56810[0m
[93maverage test of epoch 66: loss -0.96176 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 67: loss -0.95290 acc 0.66225 roc_auc 0.36971 prc_auc 0.56808[0m
[93maverage test of epoch 67: loss -0.97290 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 68: loss -0.96400 acc 0.66225 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 68: loss -0.98405 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 69: loss -0.97510 acc 0.66225 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 69: loss -0.99519 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 70: loss -0.98620 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 70: loss -1.00634 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 71: loss -0.99730 acc 0.66225 roc_auc 0.36971 prc_auc 0.56810[0m
[93maverage test of epoch 71: loss -1.01748 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 72: loss -1.00840 acc 0.66225 roc_auc 0.36971 prc_auc 0.56810[0m
[93maverage test of epoch 72: loss -1.02863 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 73: loss -1.01949 acc 0.66225 roc_auc 0.36971 prc_auc 0.56810[0m
[93maverage test of epoch 73: loss -1.03977 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 74: loss -1.03059 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 74: loss -1.05092 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 75: loss -1.04169 acc 0.66225 roc_auc 0.36971 prc_auc 0.56810[0m
[93maverage test of epoch 75: loss -1.06207 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 76: loss -1.05279 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 76: loss -1.07321 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 77: loss -1.06389 acc 0.66225 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 77: loss -1.08436 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 78: loss -1.07498 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 78: loss -1.09550 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 79: loss -1.08608 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 79: loss -1.10665 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 80: loss -1.09718 acc 0.66225 roc_auc 0.36971 prc_auc 0.56810[0m
[93maverage test of epoch 80: loss -1.11779 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 81: loss -1.10828 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 81: loss -1.12894 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 82: loss -1.11938 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 82: loss -1.14008 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 83: loss -1.13047 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 83: loss -1.15123 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 84: loss -1.14157 acc 0.66225 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 84: loss -1.16237 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 85: loss -1.15267 acc 0.66225 roc_auc 0.36971 prc_auc 0.56810[0m
[93maverage test of epoch 85: loss -1.17352 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 86: loss -1.16377 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 86: loss -1.18466 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 87: loss -1.17487 acc 0.66225 roc_auc 0.36971 prc_auc 0.56810[0m
[93maverage test of epoch 87: loss -1.19581 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 88: loss -1.18596 acc 0.66225 roc_auc 0.36971 prc_auc 0.56808[0m
[93maverage test of epoch 88: loss -1.20695 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 89: loss -1.19706 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 89: loss -1.21810 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 90: loss -1.20816 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 90: loss -1.22924 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 91: loss -1.21926 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 91: loss -1.24039 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 92: loss -1.23036 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 92: loss -1.25153 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 93: loss -1.24145 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 93: loss -1.26268 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 94: loss -1.25255 acc 0.66225 roc_auc 0.36971 prc_auc 0.56810[0m
[93maverage test of epoch 94: loss -1.27382 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 95: loss -1.26365 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 95: loss -1.28497 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 96: loss -1.27475 acc 0.66225 roc_auc 0.36971 prc_auc 0.56810[0m
[93maverage test of epoch 96: loss -1.29611 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 97: loss -1.28585 acc 0.66225 roc_auc 0.36971 prc_auc 0.56810[0m
[93maverage test of epoch 97: loss -1.30726 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 98: loss -1.29694 acc 0.66225 roc_auc 0.36971 prc_auc 0.56810[0m
[93maverage test of epoch 98: loss -1.31841 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 99: loss -1.30804 acc 0.66225 roc_auc 0.36971 prc_auc 0.56810[0m
[93maverage test of epoch 99: loss -1.32955 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 2)
('lr', 0.0001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.66501 ROC_AUC (avg): 0.5 PRC_AUC (avg): 0.66501 

Average forward propagation time taken(ms): 3.105204543677664
Average backward propagation time taken(ms): 0.9945381090485357

