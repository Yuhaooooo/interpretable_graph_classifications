# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.0001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-22-38-14/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-22-38-14/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 16,
 'epochs': 50,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 8,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.0001,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 2,
 'num_workers': 8,
 'number_of_mlp_layer': 0,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-17-22-38-14',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 50, 'learning_rate': 0.0001, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.75525 acc 0.64667 roc_auc 0.43240 prc_auc 0.64188[0m
[93maverage test of epoch 0: loss -0.89197 acc 0.65789 roc_auc 0.44000 prc_auc 0.64134[0m
[92maverage training of epoch 1: loss -0.99472 acc 0.66667 roc_auc 0.50360 prc_auc 0.68107[0m
[93maverage test of epoch 1: loss -1.11131 acc 0.65789 roc_auc 0.60615 prc_auc 0.78325[0m
[92maverage training of epoch 2: loss -1.18920 acc 0.66667 roc_auc 0.46100 prc_auc 0.66676[0m
[93maverage test of epoch 2: loss -1.29953 acc 0.65789 roc_auc 0.66769 prc_auc 0.83523[0m
[92maverage training of epoch 3: loss -1.37709 acc 0.66667 roc_auc 0.52380 prc_auc 0.72818[0m
[93maverage test of epoch 3: loss -1.47614 acc 0.65789 roc_auc 0.66154 prc_auc 0.81380[0m
[92maverage training of epoch 4: loss -1.59137 acc 0.66667 roc_auc 0.61500 prc_auc 0.76974[0m
[93maverage test of epoch 4: loss -1.68208 acc 0.65789 roc_auc 0.63385 prc_auc 0.80256[0m
[92maverage training of epoch 5: loss -1.81048 acc 0.66667 roc_auc 0.64320 prc_auc 0.77931[0m
[93maverage test of epoch 5: loss -1.88642 acc 0.65789 roc_auc 0.55692 prc_auc 0.74498[0m
[92maverage training of epoch 6: loss -2.02083 acc 0.66667 roc_auc 0.76420 prc_auc 0.87093[0m
[93maverage test of epoch 6: loss -2.09190 acc 0.65789 roc_auc 0.79692 prc_auc 0.85745[0m
[92maverage training of epoch 7: loss -2.18008 acc 0.66667 roc_auc 0.65360 prc_auc 0.80124[0m
[93maverage test of epoch 7: loss -2.28922 acc 0.65789 roc_auc 0.89846 prc_auc 0.95340[0m
[92maverage training of epoch 8: loss -2.35717 acc 0.66667 roc_auc 0.78620 prc_auc 0.88326[0m
[93maverage test of epoch 8: loss -2.41088 acc 0.65789 roc_auc 0.76923 prc_auc 0.87741[0m
[92maverage training of epoch 9: loss -2.51398 acc 0.66667 roc_auc 0.82980 prc_auc 0.89681[0m
[93maverage test of epoch 9: loss -2.60678 acc 0.65789 roc_auc 0.86462 prc_auc 0.92749[0m
[92maverage training of epoch 10: loss -2.68136 acc 0.66667 roc_auc 0.84320 prc_auc 0.91798[0m
[93maverage test of epoch 10: loss -2.74815 acc 0.65789 roc_auc 0.84000 prc_auc 0.91571[0m
[92maverage training of epoch 11: loss -2.82988 acc 0.66667 roc_auc 0.87560 prc_auc 0.93160[0m
[93maverage test of epoch 11: loss -2.90451 acc 0.65789 roc_auc 0.86154 prc_auc 0.92687[0m
[92maverage training of epoch 12: loss -2.98793 acc 0.68667 roc_auc 0.88340 prc_auc 0.93365[0m
[93maverage test of epoch 12: loss -3.04765 acc 0.65789 roc_auc 0.84308 prc_auc 0.91745[0m
[92maverage training of epoch 13: loss -3.13212 acc 0.73333 roc_auc 0.87360 prc_auc 0.92660[0m
[93maverage test of epoch 13: loss -3.18538 acc 0.78947 roc_auc 0.87692 prc_auc 0.93696[0m
[92maverage training of epoch 14: loss -3.26110 acc 0.79333 roc_auc 0.85640 prc_auc 0.89101[0m
[93maverage test of epoch 14: loss -3.32224 acc 0.78947 roc_auc 0.84000 prc_auc 0.85058[0m
[92maverage training of epoch 15: loss -3.39533 acc 0.82000 roc_auc 0.85380 prc_auc 0.90654[0m
[93maverage test of epoch 15: loss -3.48142 acc 0.78947 roc_auc 0.89231 prc_auc 0.95455[0m
[92maverage training of epoch 16: loss -3.51943 acc 0.83333 roc_auc 0.86400 prc_auc 0.90749[0m
[93maverage test of epoch 16: loss -3.59699 acc 0.81579 roc_auc 0.89538 prc_auc 0.95152[0m
[92maverage training of epoch 17: loss -3.64633 acc 0.83333 roc_auc 0.88640 prc_auc 0.94334[0m
[93maverage test of epoch 17: loss -3.70251 acc 0.81579 roc_auc 0.85538 prc_auc 0.92824[0m
[92maverage training of epoch 18: loss -3.77116 acc 0.82000 roc_auc 0.86720 prc_auc 0.91206[0m
[93maverage test of epoch 18: loss -3.83472 acc 0.84211 roc_auc 0.86769 prc_auc 0.93893[0m
[92maverage training of epoch 19: loss -3.89238 acc 0.84667 roc_auc 0.89480 prc_auc 0.93976[0m
[93maverage test of epoch 19: loss -3.92239 acc 0.78947 roc_auc 0.88000 prc_auc 0.93821[0m
[92maverage training of epoch 20: loss -3.99344 acc 0.84667 roc_auc 0.87460 prc_auc 0.92487[0m
[93maverage test of epoch 20: loss -4.02235 acc 0.78947 roc_auc 0.89846 prc_auc 0.95389[0m
[92maverage training of epoch 21: loss -4.10865 acc 0.84000 roc_auc 0.89360 prc_auc 0.93853[0m
[93maverage test of epoch 21: loss -4.12257 acc 0.81579 roc_auc 0.85231 prc_auc 0.93462[0m
[92maverage training of epoch 22: loss -4.20692 acc 0.84000 roc_auc 0.90300 prc_auc 0.94578[0m
[93maverage test of epoch 22: loss -4.22116 acc 0.78947 roc_auc 0.89846 prc_auc 0.94900[0m
[92maverage training of epoch 23: loss -4.27078 acc 0.83333 roc_auc 0.85800 prc_auc 0.90412[0m
[93maverage test of epoch 23: loss -4.27920 acc 0.78947 roc_auc 0.81846 prc_auc 0.91809[0m
[92maverage training of epoch 24: loss -4.41715 acc 0.85333 roc_auc 0.90260 prc_auc 0.94662[0m
[93maverage test of epoch 24: loss -4.40524 acc 0.78947 roc_auc 0.88615 prc_auc 0.93718[0m
[92maverage training of epoch 25: loss -4.50633 acc 0.83333 roc_auc 0.88000 prc_auc 0.92920[0m
[93maverage test of epoch 25: loss -4.51765 acc 0.81579 roc_auc 0.86462 prc_auc 0.93309[0m
[92maverage training of epoch 26: loss -4.58544 acc 0.84000 roc_auc 0.87740 prc_auc 0.92873[0m
[93maverage test of epoch 26: loss -4.60563 acc 0.81579 roc_auc 0.83692 prc_auc 0.89977[0m
[92maverage training of epoch 27: loss -4.65987 acc 0.84000 roc_auc 0.85140 prc_auc 0.90577[0m
[93maverage test of epoch 27: loss -4.69460 acc 0.81579 roc_auc 0.88615 prc_auc 0.95293[0m
[92maverage training of epoch 28: loss -4.77481 acc 0.84000 roc_auc 0.88120 prc_auc 0.91763[0m
[93maverage test of epoch 28: loss -4.78900 acc 0.81579 roc_auc 0.84000 prc_auc 0.92536[0m
[92maverage training of epoch 29: loss -4.86942 acc 0.85333 roc_auc 0.86560 prc_auc 0.91699[0m
[93maverage test of epoch 29: loss -4.88837 acc 0.81579 roc_auc 0.88615 prc_auc 0.95229[0m
[92maverage training of epoch 30: loss -4.94041 acc 0.82667 roc_auc 0.89080 prc_auc 0.93706[0m
[93maverage test of epoch 30: loss -5.01479 acc 0.84211 roc_auc 0.82462 prc_auc 0.89104[0m
[92maverage training of epoch 31: loss -5.05181 acc 0.82667 roc_auc 0.86440 prc_auc 0.88902[0m
[93maverage test of epoch 31: loss -5.02579 acc 0.78947 roc_auc 0.84615 prc_auc 0.90809[0m
[92maverage training of epoch 32: loss -5.12998 acc 0.82667 roc_auc 0.87240 prc_auc 0.93030[0m
[93maverage test of epoch 32: loss -5.11968 acc 0.78947 roc_auc 0.89846 prc_auc 0.95380[0m
[92maverage training of epoch 33: loss -5.23588 acc 0.84000 roc_auc 0.89980 prc_auc 0.94733[0m
[93maverage test of epoch 33: loss -5.23478 acc 0.81579 roc_auc 0.87077 prc_auc 0.94413[0m
[92maverage training of epoch 34: loss -5.32951 acc 0.83333 roc_auc 0.89640 prc_auc 0.93986[0m
[93maverage test of epoch 34: loss -5.45935 acc 0.86842 roc_auc 0.88615 prc_auc 0.93999[0m
[92maverage training of epoch 35: loss -5.40395 acc 0.84000 roc_auc 0.86720 prc_auc 0.92266[0m
[93maverage test of epoch 35: loss -5.37718 acc 0.78947 roc_auc 0.86154 prc_auc 0.93900[0m
[92maverage training of epoch 36: loss -5.51018 acc 0.85333 roc_auc 0.87040 prc_auc 0.90906[0m
[93maverage test of epoch 36: loss -5.52550 acc 0.81579 roc_auc 0.91077 prc_auc 0.95807[0m
[92maverage training of epoch 37: loss -5.60145 acc 0.84000 roc_auc 0.86920 prc_auc 0.92203[0m
[93maverage test of epoch 37: loss -5.68107 acc 0.84211 roc_auc 0.88615 prc_auc 0.94099[0m
[92maverage training of epoch 38: loss -5.67896 acc 0.82667 roc_auc 0.89900 prc_auc 0.94361[0m
[93maverage test of epoch 38: loss -5.67716 acc 0.81579 roc_auc 0.82154 prc_auc 0.88735[0m
[92maverage training of epoch 39: loss -5.79930 acc 0.85333 roc_auc 0.84860 prc_auc 0.90293[0m
[93maverage test of epoch 39: loss -5.76410 acc 0.81579 roc_auc 0.84308 prc_auc 0.92426[0m
[92maverage training of epoch 40: loss -5.82919 acc 0.80667 roc_auc 0.87760 prc_auc 0.92715[0m
[93maverage test of epoch 40: loss -5.92001 acc 0.81579 roc_auc 0.87385 prc_auc 0.94147[0m
[92maverage training of epoch 41: loss -5.94572 acc 0.83333 roc_auc 0.83960 prc_auc 0.88227[0m
[93maverage test of epoch 41: loss -5.91281 acc 0.78947 roc_auc 0.84615 prc_auc 0.91981[0m
[92maverage training of epoch 42: loss -6.14019 acc 0.86000 roc_auc 0.87140 prc_auc 0.91386[0m
[93maverage test of epoch 42: loss -6.07024 acc 0.81579 roc_auc 0.84923 prc_auc 0.92822[0m
[92maverage training of epoch 43: loss -6.14274 acc 0.82667 roc_auc 0.87940 prc_auc 0.93243[0m
[93maverage test of epoch 43: loss -6.18983 acc 0.81579 roc_auc 0.90462 prc_auc 0.95418[0m
[92maverage training of epoch 44: loss -6.22731 acc 0.82667 roc_auc 0.84300 prc_auc 0.89440[0m
[93maverage test of epoch 44: loss -6.28373 acc 0.81579 roc_auc 0.88000 prc_auc 0.93136[0m
[92maverage training of epoch 45: loss -6.39573 acc 0.84667 roc_auc 0.88480 prc_auc 0.93315[0m
[93maverage test of epoch 45: loss -6.35743 acc 0.81579 roc_auc 0.85538 prc_auc 0.93570[0m
[92maverage training of epoch 46: loss -6.44070 acc 0.84667 roc_auc 0.81260 prc_auc 0.88211[0m
[93maverage test of epoch 46: loss -6.49471 acc 0.81579 roc_auc 0.85538 prc_auc 0.92671[0m
[92maverage training of epoch 47: loss -6.58674 acc 0.86000 roc_auc 0.80960 prc_auc 0.85501[0m
[93maverage test of epoch 47: loss -6.55082 acc 0.81579 roc_auc 0.85538 prc_auc 0.89284[0m
[92maverage training of epoch 48: loss -6.67906 acc 0.85333 roc_auc 0.85520 prc_auc 0.89636[0m
[93maverage test of epoch 48: loss -6.63448 acc 0.81579 roc_auc 0.87077 prc_auc 0.93756[0m
[92maverage training of epoch 49: loss -6.74890 acc 0.84000 roc_auc 0.86140 prc_auc 0.90825[0m
[93maverage test of epoch 49: loss -6.73498 acc 0.81579 roc_auc 0.82769 prc_auc 0.91086[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.89867 acc 0.66667 roc_auc 0.46830 prc_auc 0.65215[0m
[93maverage test of epoch 0: loss -1.08848 acc 0.65789 roc_auc 0.36615 prc_auc 0.57783[0m
[92maverage training of epoch 1: loss -1.32978 acc 0.66667 roc_auc 0.48080 prc_auc 0.64936[0m
[93maverage test of epoch 1: loss -1.52387 acc 0.65789 roc_auc 0.57231 prc_auc 0.71794[0m
[92maverage training of epoch 2: loss -1.75570 acc 0.66667 roc_auc 0.38600 prc_auc 0.59250[0m
[93maverage test of epoch 2: loss -2.00053 acc 0.65789 roc_auc 0.58769 prc_auc 0.74724[0m
[92maverage training of epoch 3: loss -2.32723 acc 0.66667 roc_auc 0.48360 prc_auc 0.67210[0m
[93maverage test of epoch 3: loss -2.70981 acc 0.65789 roc_auc 0.38154 prc_auc 0.62950[0m
[92maverage training of epoch 4: loss -3.08258 acc 0.66667 roc_auc 0.48820 prc_auc 0.67292[0m
[93maverage test of epoch 4: loss -3.34936 acc 0.65789 roc_auc 0.34154 prc_auc 0.61238[0m
[92maverage training of epoch 5: loss -3.59042 acc 0.66667 roc_auc 0.50180 prc_auc 0.68646[0m
[93maverage test of epoch 5: loss -3.78482 acc 0.65789 roc_auc 0.41538 prc_auc 0.59823[0m
[92maverage training of epoch 6: loss -3.96552 acc 0.66667 roc_auc 0.46940 prc_auc 0.63624[0m
[93maverage test of epoch 6: loss -4.13741 acc 0.65789 roc_auc 0.60000 prc_auc 0.77396[0m
[92maverage training of epoch 7: loss -4.30186 acc 0.66667 roc_auc 0.46220 prc_auc 0.67749[0m
[93maverage test of epoch 7: loss -4.41382 acc 0.65789 roc_auc 0.43077 prc_auc 0.62755[0m
[92maverage training of epoch 8: loss -4.56674 acc 0.66667 roc_auc 0.55160 prc_auc 0.70254[0m
[93maverage test of epoch 8: loss -4.67612 acc 0.65789 roc_auc 0.54462 prc_auc 0.72910[0m
[92maverage training of epoch 9: loss -4.81095 acc 0.66667 roc_auc 0.46520 prc_auc 0.66464[0m
[93maverage test of epoch 9: loss -4.91493 acc 0.65789 roc_auc 0.53231 prc_auc 0.74688[0m
[92maverage training of epoch 10: loss -5.03566 acc 0.66667 roc_auc 0.49880 prc_auc 0.67096[0m
[93maverage test of epoch 10: loss -5.12423 acc 0.65789 roc_auc 0.67077 prc_auc 0.72550[0m
[92maverage training of epoch 11: loss -5.21912 acc 0.66667 roc_auc 0.46700 prc_auc 0.64620[0m
[93maverage test of epoch 11: loss -5.29360 acc 0.65789 roc_auc 0.64000 prc_auc 0.81139[0m
[92maverage training of epoch 12: loss -5.40656 acc 0.66667 roc_auc 0.48720 prc_auc 0.64687[0m
[93maverage test of epoch 12: loss -5.45905 acc 0.65789 roc_auc 0.52000 prc_auc 0.70819[0m
[92maverage training of epoch 13: loss -5.56388 acc 0.66667 roc_auc 0.46500 prc_auc 0.69990[0m
[93maverage test of epoch 13: loss -5.61739 acc 0.65789 roc_auc 0.44615 prc_auc 0.66982[0m
[92maverage training of epoch 14: loss -5.72268 acc 0.66667 roc_auc 0.47840 prc_auc 0.67095[0m
[93maverage test of epoch 14: loss -5.75501 acc 0.65789 roc_auc 0.39385 prc_auc 0.58836[0m
[92maverage training of epoch 15: loss -5.87336 acc 0.66667 roc_auc 0.48280 prc_auc 0.65312[0m
[93maverage test of epoch 15: loss -5.91475 acc 0.65789 roc_auc 0.31692 prc_auc 0.60042[0m
[92maverage training of epoch 16: loss -6.00599 acc 0.66667 roc_auc 0.48640 prc_auc 0.66050[0m
[93maverage test of epoch 16: loss -6.02802 acc 0.65789 roc_auc 0.49231 prc_auc 0.70968[0m
[92maverage training of epoch 17: loss -6.14262 acc 0.66667 roc_auc 0.45020 prc_auc 0.64071[0m
[93maverage test of epoch 17: loss -6.17595 acc 0.65789 roc_auc 0.32615 prc_auc 0.56253[0m
[92maverage training of epoch 18: loss -6.27259 acc 0.66667 roc_auc 0.49240 prc_auc 0.67628[0m
[93maverage test of epoch 18: loss -6.31952 acc 0.65789 roc_auc 0.72923 prc_auc 0.78898[0m
[92maverage training of epoch 19: loss -6.40177 acc 0.66667 roc_auc 0.49120 prc_auc 0.66342[0m
[93maverage test of epoch 19: loss -6.42848 acc 0.65789 roc_auc 0.61538 prc_auc 0.77303[0m
[92maverage training of epoch 20: loss -6.52015 acc 0.66667 roc_auc 0.45040 prc_auc 0.62498[0m
[93maverage test of epoch 20: loss -6.55591 acc 0.65789 roc_auc 0.49846 prc_auc 0.71336[0m
[92maverage training of epoch 21: loss -6.64069 acc 0.66667 roc_auc 0.47180 prc_auc 0.64812[0m
[93maverage test of epoch 21: loss -6.66381 acc 0.65789 roc_auc 0.40000 prc_auc 0.62301[0m
[92maverage training of epoch 22: loss -6.75718 acc 0.66667 roc_auc 0.49480 prc_auc 0.65962[0m
[93maverage test of epoch 22: loss -6.79047 acc 0.65789 roc_auc 0.37231 prc_auc 0.58220[0m
[92maverage training of epoch 23: loss -6.86874 acc 0.66667 roc_auc 0.49060 prc_auc 0.68024[0m
[93maverage test of epoch 23: loss -6.89381 acc 0.65789 roc_auc 0.47077 prc_auc 0.63035[0m
[92maverage training of epoch 24: loss -6.98654 acc 0.66667 roc_auc 0.48320 prc_auc 0.65878[0m
[93maverage test of epoch 24: loss -7.02652 acc 0.65789 roc_auc 0.60308 prc_auc 0.75139[0m
[92maverage training of epoch 25: loss -7.09865 acc 0.66667 roc_auc 0.48740 prc_auc 0.64951[0m
[93maverage test of epoch 25: loss -7.12520 acc 0.65789 roc_auc 0.45231 prc_auc 0.62442[0m
[92maverage training of epoch 26: loss -7.20796 acc 0.66667 roc_auc 0.39410 prc_auc 0.61208[0m
[93maverage test of epoch 26: loss -7.22915 acc 0.65789 roc_auc 0.63077 prc_auc 0.78537[0m
[92maverage training of epoch 27: loss -7.31650 acc 0.66667 roc_auc 0.45610 prc_auc 0.65921[0m
[93maverage test of epoch 27: loss -7.34724 acc 0.65789 roc_auc 0.51077 prc_auc 0.71278[0m
[92maverage training of epoch 28: loss -7.42453 acc 0.66667 roc_auc 0.39640 prc_auc 0.61026[0m
[93maverage test of epoch 28: loss -7.45460 acc 0.65789 roc_auc 0.38154 prc_auc 0.60635[0m
[92maverage training of epoch 29: loss -7.53253 acc 0.66667 roc_auc 0.44950 prc_auc 0.66711[0m
[93maverage test of epoch 29: loss -7.56251 acc 0.65789 roc_auc 0.48923 prc_auc 0.71115[0m
[92maverage training of epoch 30: loss -7.63846 acc 0.66667 roc_auc 0.45500 prc_auc 0.62544[0m
[93maverage test of epoch 30: loss -7.66280 acc 0.65789 roc_auc 0.56923 prc_auc 0.69402[0m
[92maverage training of epoch 31: loss -7.74378 acc 0.66667 roc_auc 0.44200 prc_auc 0.61475[0m
[93maverage test of epoch 31: loss -7.76553 acc 0.65789 roc_auc 0.35692 prc_auc 0.62556[0m
[92maverage training of epoch 32: loss -7.84873 acc 0.66667 roc_auc 0.44010 prc_auc 0.61443[0m
[93maverage test of epoch 32: loss -7.87739 acc 0.65789 roc_auc 0.56615 prc_auc 0.73150[0m
[92maverage training of epoch 33: loss -7.95337 acc 0.66667 roc_auc 0.49410 prc_auc 0.64381[0m
[93maverage test of epoch 33: loss -7.97743 acc 0.65789 roc_auc 0.39846 prc_auc 0.60195[0m
[92maverage training of epoch 34: loss -8.05763 acc 0.66667 roc_auc 0.46020 prc_auc 0.62840[0m
[93maverage test of epoch 34: loss -8.08750 acc 0.65789 roc_auc 0.36308 prc_auc 0.62924[0m
[92maverage training of epoch 35: loss -8.16144 acc 0.66667 roc_auc 0.46400 prc_auc 0.65994[0m
[93maverage test of epoch 35: loss -8.18597 acc 0.65789 roc_auc 0.59692 prc_auc 0.76965[0m
[92maverage training of epoch 36: loss -8.26918 acc 0.66667 roc_auc 0.40520 prc_auc 0.59389[0m
[93maverage test of epoch 36: loss -8.28338 acc 0.65789 roc_auc 0.51077 prc_auc 0.73579[0m
[92maverage training of epoch 37: loss -8.37147 acc 0.66667 roc_auc 0.45720 prc_auc 0.63251[0m
[93maverage test of epoch 37: loss -8.39046 acc 0.65789 roc_auc 0.58154 prc_auc 0.72210[0m
[92maverage training of epoch 38: loss -8.47494 acc 0.66667 roc_auc 0.43960 prc_auc 0.63520[0m
[93maverage test of epoch 38: loss -8.49517 acc 0.65789 roc_auc 0.45538 prc_auc 0.68409[0m
[92maverage training of epoch 39: loss -8.57822 acc 0.66667 roc_auc 0.45970 prc_auc 0.62226[0m
[93maverage test of epoch 39: loss -8.59521 acc 0.65789 roc_auc 0.65077 prc_auc 0.72045[0m
[92maverage training of epoch 40: loss -8.67800 acc 0.66667 roc_auc 0.46300 prc_auc 0.61676[0m
[93maverage test of epoch 40: loss -8.69414 acc 0.65789 roc_auc 0.54769 prc_auc 0.68409[0m
[92maverage training of epoch 41: loss -8.77970 acc 0.66667 roc_auc 0.42410 prc_auc 0.61473[0m
[93maverage test of epoch 41: loss -8.79828 acc 0.65789 roc_auc 0.42462 prc_auc 0.61175[0m
[92maverage training of epoch 42: loss -8.88089 acc 0.66667 roc_auc 0.42170 prc_auc 0.63265[0m
[93maverage test of epoch 42: loss -8.90313 acc 0.65789 roc_auc 0.47385 prc_auc 0.69967[0m
[92maverage training of epoch 43: loss -8.98313 acc 0.66667 roc_auc 0.42760 prc_auc 0.60096[0m
[93maverage test of epoch 43: loss -9.00074 acc 0.65789 roc_auc 0.43077 prc_auc 0.60387[0m
[92maverage training of epoch 44: loss -9.08568 acc 0.66667 roc_auc 0.43150 prc_auc 0.60728[0m
[93maverage test of epoch 44: loss -9.09992 acc 0.65789 roc_auc 0.41692 prc_auc 0.63887[0m
[92maverage training of epoch 45: loss -9.18731 acc 0.66667 roc_auc 0.39170 prc_auc 0.58655[0m
[93maverage test of epoch 45: loss -9.20527 acc 0.65789 roc_auc 0.71846 prc_auc 0.83460[0m
[92maverage training of epoch 46: loss -9.28844 acc 0.66667 roc_auc 0.41500 prc_auc 0.61181[0m
[93maverage test of epoch 46: loss -9.30314 acc 0.65789 roc_auc 0.53385 prc_auc 0.68974[0m
[92maverage training of epoch 47: loss -9.39044 acc 0.66667 roc_auc 0.43920 prc_auc 0.61662[0m
[93maverage test of epoch 47: loss -9.40592 acc 0.65789 roc_auc 0.20154 prc_auc 0.50846[0m
[92maverage training of epoch 48: loss -9.49091 acc 0.66667 roc_auc 0.44870 prc_auc 0.62392[0m
[93maverage test of epoch 48: loss -9.50656 acc 0.65789 roc_auc 0.51077 prc_auc 0.71500[0m
[92maverage training of epoch 49: loss -9.59201 acc 0.66667 roc_auc 0.44150 prc_auc 0.61208[0m
[93maverage test of epoch 49: loss -9.60808 acc 0.65789 roc_auc 0.47846 prc_auc 0.61971[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss 0.06642 acc 0.46000 roc_auc 0.46880 prc_auc 0.68768[0m
[93maverage test of epoch 0: loss -0.01763 acc 0.44737 roc_auc 0.43692 prc_auc 0.68145[0m
[92maverage training of epoch 1: loss -0.10284 acc 0.52667 roc_auc 0.52820 prc_auc 0.72577[0m
[93maverage test of epoch 1: loss -0.19016 acc 0.60526 roc_auc 0.63077 prc_auc 0.80171[0m
[92maverage training of epoch 2: loss -0.27843 acc 0.62667 roc_auc 0.52460 prc_auc 0.70974[0m
[93maverage test of epoch 2: loss -0.34227 acc 0.60526 roc_auc 0.37846 prc_auc 0.65179[0m
[92maverage training of epoch 3: loss -0.43334 acc 0.67333 roc_auc 0.47160 prc_auc 0.70536[0m
[93maverage test of epoch 3: loss -0.50922 acc 0.65789 roc_auc 0.50462 prc_auc 0.73393[0m
[92maverage training of epoch 4: loss -0.59606 acc 0.66667 roc_auc 0.57740 prc_auc 0.75151[0m
[93maverage test of epoch 4: loss -0.67544 acc 0.65789 roc_auc 0.59385 prc_auc 0.73368[0m
[92maverage training of epoch 5: loss -0.74725 acc 0.66667 roc_auc 0.52240 prc_auc 0.72341[0m
[93maverage test of epoch 5: loss -0.82006 acc 0.65789 roc_auc 0.59077 prc_auc 0.76830[0m
[92maverage training of epoch 6: loss -0.89739 acc 0.66667 roc_auc 0.51260 prc_auc 0.72419[0m
[93maverage test of epoch 6: loss -0.96745 acc 0.65789 roc_auc 0.49231 prc_auc 0.69736[0m
[92maverage training of epoch 7: loss -1.06666 acc 0.66667 roc_auc 0.63160 prc_auc 0.74947[0m
[93maverage test of epoch 7: loss -1.13375 acc 0.65789 roc_auc 0.62462 prc_auc 0.78170[0m
[92maverage training of epoch 8: loss -1.22956 acc 0.66667 roc_auc 0.52940 prc_auc 0.70744[0m
[93maverage test of epoch 8: loss -1.32613 acc 0.65789 roc_auc 0.72615 prc_auc 0.84203[0m
[92maverage training of epoch 9: loss -1.43858 acc 0.66667 roc_auc 0.51320 prc_auc 0.72496[0m
[93maverage test of epoch 9: loss -1.55763 acc 0.65789 roc_auc 0.69231 prc_auc 0.78427[0m
[92maverage training of epoch 10: loss -1.69207 acc 0.66667 roc_auc 0.58760 prc_auc 0.73701[0m
[93maverage test of epoch 10: loss -1.78470 acc 0.65789 roc_auc 0.60923 prc_auc 0.79550[0m
[92maverage training of epoch 11: loss -1.88661 acc 0.66667 roc_auc 0.53320 prc_auc 0.68413[0m
[93maverage test of epoch 11: loss -1.93628 acc 0.65789 roc_auc 0.38462 prc_auc 0.63363[0m
[92maverage training of epoch 12: loss -2.04563 acc 0.66667 roc_auc 0.44200 prc_auc 0.64593[0m
[93maverage test of epoch 12: loss -2.09817 acc 0.65789 roc_auc 0.60615 prc_auc 0.77220[0m
[92maverage training of epoch 13: loss -2.18468 acc 0.66667 roc_auc 0.45160 prc_auc 0.69939[0m
[93maverage test of epoch 13: loss -2.24500 acc 0.65789 roc_auc 0.56615 prc_auc 0.76059[0m
[92maverage training of epoch 14: loss -2.31106 acc 0.66667 roc_auc 0.41880 prc_auc 0.62796[0m
[93maverage test of epoch 14: loss -2.35634 acc 0.65789 roc_auc 0.32308 prc_auc 0.60187[0m
[92maverage training of epoch 15: loss -2.43131 acc 0.66667 roc_auc 0.49300 prc_auc 0.66377[0m
[93maverage test of epoch 15: loss -2.46850 acc 0.65789 roc_auc 0.41231 prc_auc 0.62438[0m
[92maverage training of epoch 16: loss -2.54935 acc 0.66667 roc_auc 0.55880 prc_auc 0.73240[0m
[93maverage test of epoch 16: loss -2.58921 acc 0.65789 roc_auc 0.42769 prc_auc 0.64439[0m
[92maverage training of epoch 17: loss -2.66029 acc 0.66667 roc_auc 0.47260 prc_auc 0.66333[0m
[93maverage test of epoch 17: loss -2.69575 acc 0.65789 roc_auc 0.39385 prc_auc 0.57909[0m
[92maverage training of epoch 18: loss -2.77113 acc 0.66667 roc_auc 0.54520 prc_auc 0.70474[0m
[93maverage test of epoch 18: loss -2.80166 acc 0.65789 roc_auc 0.45231 prc_auc 0.70412[0m
[92maverage training of epoch 19: loss -2.87915 acc 0.66667 roc_auc 0.53960 prc_auc 0.66731[0m
[93maverage test of epoch 19: loss -2.89967 acc 0.65789 roc_auc 0.46769 prc_auc 0.63426[0m
[92maverage training of epoch 20: loss -2.97740 acc 0.66667 roc_auc 0.47100 prc_auc 0.65944[0m
[93maverage test of epoch 20: loss -3.02731 acc 0.65789 roc_auc 0.65231 prc_auc 0.78835[0m
[92maverage training of epoch 21: loss -3.08368 acc 0.66667 roc_auc 0.49000 prc_auc 0.69710[0m
[93maverage test of epoch 21: loss -3.12091 acc 0.65789 roc_auc 0.56615 prc_auc 0.71112[0m
[92maverage training of epoch 22: loss -3.18528 acc 0.66667 roc_auc 0.49140 prc_auc 0.67301[0m
[93maverage test of epoch 22: loss -3.22366 acc 0.65789 roc_auc 0.54154 prc_auc 0.66380[0m
[92maverage training of epoch 23: loss -3.28920 acc 0.66667 roc_auc 0.46380 prc_auc 0.64183[0m
[93maverage test of epoch 23: loss -3.31577 acc 0.65789 roc_auc 0.32000 prc_auc 0.56756[0m
[92maverage training of epoch 24: loss -3.40158 acc 0.66667 roc_auc 0.53560 prc_auc 0.71692[0m
[93maverage test of epoch 24: loss -3.43680 acc 0.65789 roc_auc 0.44615 prc_auc 0.67336[0m
[92maverage training of epoch 25: loss -3.51083 acc 0.66667 roc_auc 0.47680 prc_auc 0.67260[0m
[93maverage test of epoch 25: loss -3.54855 acc 0.65789 roc_auc 0.57846 prc_auc 0.77629[0m
[92maverage training of epoch 26: loss -3.62421 acc 0.66667 roc_auc 0.50180 prc_auc 0.68375[0m
[93maverage test of epoch 26: loss -3.65922 acc 0.65789 roc_auc 0.53846 prc_auc 0.77251[0m
[92maverage training of epoch 27: loss -3.74299 acc 0.66667 roc_auc 0.47180 prc_auc 0.66334[0m
[93maverage test of epoch 27: loss -3.78203 acc 0.65789 roc_auc 0.52615 prc_auc 0.69724[0m
[92maverage training of epoch 28: loss -3.86618 acc 0.66667 roc_auc 0.42280 prc_auc 0.62451[0m
[93maverage test of epoch 28: loss -3.90134 acc 0.65789 roc_auc 0.46769 prc_auc 0.67723[0m
[92maverage training of epoch 29: loss -3.99528 acc 0.66667 roc_auc 0.51220 prc_auc 0.68052[0m
[93maverage test of epoch 29: loss -4.02980 acc 0.65789 roc_auc 0.55385 prc_auc 0.67668[0m
[92maverage training of epoch 30: loss -4.11637 acc 0.66667 roc_auc 0.46160 prc_auc 0.66271[0m
[93maverage test of epoch 30: loss -4.15723 acc 0.65789 roc_auc 0.56000 prc_auc 0.73307[0m
[92maverage training of epoch 31: loss -4.24301 acc 0.66667 roc_auc 0.49440 prc_auc 0.67902[0m
[93maverage test of epoch 31: loss -4.28018 acc 0.65789 roc_auc 0.59385 prc_auc 0.80794[0m
[92maverage training of epoch 32: loss -4.36043 acc 0.66667 roc_auc 0.43460 prc_auc 0.60935[0m
[93maverage test of epoch 32: loss -4.39823 acc 0.65789 roc_auc 0.46462 prc_auc 0.63618[0m
[92maverage training of epoch 33: loss -4.47724 acc 0.66667 roc_auc 0.47370 prc_auc 0.66577[0m
[93maverage test of epoch 33: loss -4.50907 acc 0.65789 roc_auc 0.42769 prc_auc 0.62773[0m
[92maverage training of epoch 34: loss -4.59244 acc 0.66667 roc_auc 0.41380 prc_auc 0.62923[0m
[93maverage test of epoch 34: loss -4.62403 acc 0.65789 roc_auc 0.28308 prc_auc 0.58423[0m
[92maverage training of epoch 35: loss -4.70742 acc 0.66667 roc_auc 0.44740 prc_auc 0.60516[0m
[93maverage test of epoch 35: loss -4.73608 acc 0.65789 roc_auc 0.53538 prc_auc 0.69593[0m
[92maverage training of epoch 36: loss -4.81762 acc 0.66667 roc_auc 0.41440 prc_auc 0.61087[0m
[93maverage test of epoch 36: loss -4.84491 acc 0.65789 roc_auc 0.59692 prc_auc 0.75646[0m
[92maverage training of epoch 37: loss -4.93130 acc 0.66667 roc_auc 0.49640 prc_auc 0.67955[0m
[93maverage test of epoch 37: loss -4.95649 acc 0.65789 roc_auc 0.57846 prc_auc 0.76179[0m
[92maverage training of epoch 38: loss -5.03740 acc 0.66667 roc_auc 0.44560 prc_auc 0.62716[0m
[93maverage test of epoch 38: loss -5.06377 acc 0.65789 roc_auc 0.52615 prc_auc 0.65902[0m
[92maverage training of epoch 39: loss -5.14569 acc 0.66667 roc_auc 0.47900 prc_auc 0.63550[0m
[93maverage test of epoch 39: loss -5.17174 acc 0.65789 roc_auc 0.61538 prc_auc 0.81700[0m
[92maverage training of epoch 40: loss -5.25020 acc 0.66667 roc_auc 0.46350 prc_auc 0.63547[0m
[93maverage test of epoch 40: loss -5.27120 acc 0.65789 roc_auc 0.60308 prc_auc 0.78578[0m
[92maverage training of epoch 41: loss -5.35413 acc 0.66667 roc_auc 0.42460 prc_auc 0.60729[0m
[93maverage test of epoch 41: loss -5.38303 acc 0.65789 roc_auc 0.53231 prc_auc 0.65857[0m
[92maverage training of epoch 42: loss -5.46385 acc 0.66667 roc_auc 0.38120 prc_auc 0.60187[0m
[93maverage test of epoch 42: loss -5.48480 acc 0.65789 roc_auc 0.49846 prc_auc 0.69739[0m
[92maverage training of epoch 43: loss -5.56668 acc 0.66667 roc_auc 0.42580 prc_auc 0.61463[0m
[93maverage test of epoch 43: loss -5.58604 acc 0.65789 roc_auc 0.44923 prc_auc 0.67778[0m
[92maverage training of epoch 44: loss -5.67492 acc 0.66667 roc_auc 0.46540 prc_auc 0.64574[0m
[93maverage test of epoch 44: loss -5.69049 acc 0.65789 roc_auc 0.44000 prc_auc 0.65526[0m
[92maverage training of epoch 45: loss -5.77576 acc 0.66667 roc_auc 0.44840 prc_auc 0.64559[0m
[93maverage test of epoch 45: loss -5.79811 acc 0.65789 roc_auc 0.42154 prc_auc 0.63300[0m
[92maverage training of epoch 46: loss -5.87893 acc 0.66667 roc_auc 0.38420 prc_auc 0.61023[0m
[93maverage test of epoch 46: loss -5.89928 acc 0.65789 roc_auc 0.35692 prc_auc 0.59770[0m
[92maverage training of epoch 47: loss -5.98136 acc 0.66667 roc_auc 0.46780 prc_auc 0.63404[0m
[93maverage test of epoch 47: loss -6.00519 acc 0.65789 roc_auc 0.47692 prc_auc 0.66458[0m
[92maverage training of epoch 48: loss -6.08616 acc 0.66667 roc_auc 0.39430 prc_auc 0.58794[0m
[93maverage test of epoch 48: loss -6.10579 acc 0.65789 roc_auc 0.58154 prc_auc 0.77557[0m
[92maverage training of epoch 49: loss -6.18873 acc 0.66667 roc_auc 0.44700 prc_auc 0.63237[0m
[93maverage test of epoch 49: loss -6.20868 acc 0.65789 roc_auc 0.45846 prc_auc 0.69946[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss 0.54303 acc 0.33775 roc_auc 0.43608 prc_auc 0.65621[0m
[93maverage test of epoch 0: loss 0.31328 acc 0.32432 roc_auc 0.46000 prc_auc 0.70831[0m
[92maverage training of epoch 1: loss 0.00879 acc 0.33775 roc_auc 0.51745 prc_auc 0.71309[0m
[93maverage test of epoch 1: loss -0.23310 acc 0.32432 roc_auc 0.88667 prc_auc 0.95149[0m
[92maverage training of epoch 2: loss -0.42743 acc 0.33775 roc_auc 0.69882 prc_auc 0.84553[0m
[93maverage test of epoch 2: loss -0.55911 acc 0.32432 roc_auc 0.67667 prc_auc 0.83945[0m
[92maverage training of epoch 3: loss -0.69037 acc 0.39735 roc_auc 0.68608 prc_auc 0.81620[0m
[93maverage test of epoch 3: loss -0.80200 acc 0.43243 roc_auc 0.73000 prc_auc 0.86796[0m
[92maverage training of epoch 4: loss -0.94291 acc 0.68874 roc_auc 0.81353 prc_auc 0.90502[0m
[93maverage test of epoch 4: loss -1.02081 acc 0.67568 roc_auc 0.74333 prc_auc 0.86870[0m
[92maverage training of epoch 5: loss -1.15356 acc 0.73510 roc_auc 0.79941 prc_auc 0.89710[0m
[93maverage test of epoch 5: loss -1.25194 acc 0.72973 roc_auc 0.77333 prc_auc 0.88871[0m
[92maverage training of epoch 6: loss -1.40737 acc 0.76821 roc_auc 0.87706 prc_auc 0.93271[0m
[93maverage test of epoch 6: loss -1.49922 acc 0.75676 roc_auc 0.83000 prc_auc 0.90908[0m
[92maverage training of epoch 7: loss -1.67850 acc 0.76159 roc_auc 0.89196 prc_auc 0.94441[0m
[93maverage test of epoch 7: loss -1.78907 acc 0.75676 roc_auc 0.85667 prc_auc 0.91403[0m
[92maverage training of epoch 8: loss -1.96426 acc 0.76159 roc_auc 0.87706 prc_auc 0.92253[0m
[93maverage test of epoch 8: loss -2.10058 acc 0.72973 roc_auc 0.83667 prc_auc 0.90553[0m
[92maverage training of epoch 9: loss -2.27298 acc 0.72848 roc_auc 0.87902 prc_auc 0.93003[0m
[93maverage test of epoch 9: loss -2.35338 acc 0.72973 roc_auc 0.86000 prc_auc 0.92071[0m
[92maverage training of epoch 10: loss -2.53491 acc 0.75497 roc_auc 0.86373 prc_auc 0.91778[0m
[93maverage test of epoch 10: loss -2.63584 acc 0.78378 roc_auc 0.85667 prc_auc 0.91724[0m
[92maverage training of epoch 11: loss -2.79923 acc 0.78808 roc_auc 0.88059 prc_auc 0.93001[0m
[93maverage test of epoch 11: loss -2.85079 acc 0.78378 roc_auc 0.84333 prc_auc 0.89794[0m
[92maverage training of epoch 12: loss -2.99028 acc 0.80132 roc_auc 0.86392 prc_auc 0.91203[0m
[93maverage test of epoch 12: loss -3.01178 acc 0.75676 roc_auc 0.86000 prc_auc 0.93049[0m
[92maverage training of epoch 13: loss -3.20083 acc 0.82119 roc_auc 0.89078 prc_auc 0.94082[0m
[93maverage test of epoch 13: loss -3.12865 acc 0.75676 roc_auc 0.84333 prc_auc 0.91081[0m
[92maverage training of epoch 14: loss -3.36259 acc 0.82119 roc_auc 0.86490 prc_auc 0.91171[0m
[93maverage test of epoch 14: loss -3.30323 acc 0.78378 roc_auc 0.86667 prc_auc 0.93332[0m
[92maverage training of epoch 15: loss -3.49797 acc 0.83444 roc_auc 0.88863 prc_auc 0.94063[0m
[93maverage test of epoch 15: loss -3.42540 acc 0.78378 roc_auc 0.79333 prc_auc 0.85313[0m
[92maverage training of epoch 16: loss -3.63649 acc 0.84106 roc_auc 0.87451 prc_auc 0.92709[0m
[93maverage test of epoch 16: loss -3.52296 acc 0.78378 roc_auc 0.79333 prc_auc 0.87282[0m
[92maverage training of epoch 17: loss -3.75546 acc 0.83444 roc_auc 0.88010 prc_auc 0.93556[0m
[93maverage test of epoch 17: loss -3.66444 acc 0.78378 roc_auc 0.89000 prc_auc 0.95442[0m
[92maverage training of epoch 18: loss -3.87773 acc 0.82781 roc_auc 0.87627 prc_auc 0.91860[0m
[93maverage test of epoch 18: loss -3.80658 acc 0.78378 roc_auc 0.88000 prc_auc 0.94610[0m
[92maverage training of epoch 19: loss -3.99424 acc 0.82119 roc_auc 0.86902 prc_auc 0.90660[0m
[93maverage test of epoch 19: loss -3.88318 acc 0.78378 roc_auc 0.78333 prc_auc 0.87798[0m
[92maverage training of epoch 20: loss -4.09153 acc 0.82119 roc_auc 0.87294 prc_auc 0.91906[0m
[93maverage test of epoch 20: loss -3.99965 acc 0.78378 roc_auc 0.79000 prc_auc 0.84626[0m
[92maverage training of epoch 21: loss -4.23559 acc 0.83444 roc_auc 0.85892 prc_auc 0.89595[0m
[93maverage test of epoch 21: loss -4.07838 acc 0.78378 roc_auc 0.79667 prc_auc 0.86411[0m
[92maverage training of epoch 22: loss -4.31742 acc 0.82119 roc_auc 0.86000 prc_auc 0.90618[0m
[93maverage test of epoch 22: loss -4.22450 acc 0.78378 roc_auc 0.80000 prc_auc 0.89266[0m
[92maverage training of epoch 23: loss -4.43521 acc 0.82781 roc_auc 0.87784 prc_auc 0.91826[0m
[93maverage test of epoch 23: loss -4.29511 acc 0.78378 roc_auc 0.80667 prc_auc 0.88848[0m
[92maverage training of epoch 24: loss -4.55124 acc 0.82781 roc_auc 0.85549 prc_auc 0.90483[0m
[93maverage test of epoch 24: loss -4.40210 acc 0.78378 roc_auc 0.85000 prc_auc 0.89761[0m
[92maverage training of epoch 25: loss -4.63934 acc 0.82119 roc_auc 0.85059 prc_auc 0.89264[0m
[93maverage test of epoch 25: loss -4.51474 acc 0.81081 roc_auc 0.84333 prc_auc 0.89968[0m
[92maverage training of epoch 26: loss -4.74232 acc 0.83444 roc_auc 0.86961 prc_auc 0.90429[0m
[93maverage test of epoch 26: loss -4.62238 acc 0.81081 roc_auc 0.71667 prc_auc 0.78460[0m
[92maverage training of epoch 27: loss -4.84181 acc 0.83444 roc_auc 0.86549 prc_auc 0.91476[0m
[93maverage test of epoch 27: loss -4.73561 acc 0.81081 roc_auc 0.79667 prc_auc 0.85824[0m
[92maverage training of epoch 28: loss -4.95821 acc 0.83444 roc_auc 0.88020 prc_auc 0.92696[0m
[93maverage test of epoch 28: loss -4.84056 acc 0.81081 roc_auc 0.84000 prc_auc 0.91063[0m
[92maverage training of epoch 29: loss -5.03824 acc 0.82781 roc_auc 0.85020 prc_auc 0.89890[0m
[93maverage test of epoch 29: loss -4.89469 acc 0.78378 roc_auc 0.87333 prc_auc 0.92674[0m
[92maverage training of epoch 30: loss -5.17262 acc 0.84106 roc_auc 0.84059 prc_auc 0.87773[0m
[93maverage test of epoch 30: loss -5.00122 acc 0.81081 roc_auc 0.83333 prc_auc 0.91340[0m
[92maverage training of epoch 31: loss -5.23887 acc 0.83444 roc_auc 0.85167 prc_auc 0.90710[0m
[93maverage test of epoch 31: loss -5.13688 acc 0.81081 roc_auc 0.76000 prc_auc 0.83192[0m
[92maverage training of epoch 32: loss -5.31940 acc 0.82119 roc_auc 0.85627 prc_auc 0.90255[0m
[93maverage test of epoch 32: loss -5.20259 acc 0.81081 roc_auc 0.74667 prc_auc 0.81103[0m
[92maverage training of epoch 33: loss -5.45783 acc 0.82781 roc_auc 0.88118 prc_auc 0.92804[0m
[93maverage test of epoch 33: loss -5.30344 acc 0.81081 roc_auc 0.85667 prc_auc 0.93167[0m
[92maverage training of epoch 34: loss -5.58701 acc 0.84768 roc_auc 0.87676 prc_auc 0.92698[0m
[93maverage test of epoch 34: loss -5.40195 acc 0.81081 roc_auc 0.77000 prc_auc 0.85240[0m
[92maverage training of epoch 35: loss -5.64149 acc 0.82781 roc_auc 0.85647 prc_auc 0.90541[0m
[93maverage test of epoch 35: loss -5.49725 acc 0.81081 roc_auc 0.89667 prc_auc 0.95261[0m
[92maverage training of epoch 36: loss -5.72367 acc 0.83444 roc_auc 0.86324 prc_auc 0.90719[0m
[93maverage test of epoch 36: loss -5.59936 acc 0.81081 roc_auc 0.78500 prc_auc 0.86636[0m
[92maverage training of epoch 37: loss -5.82224 acc 0.83444 roc_auc 0.85343 prc_auc 0.90767[0m
[93maverage test of epoch 37: loss -5.69436 acc 0.81081 roc_auc 0.90333 prc_auc 0.95901[0m
[92maverage training of epoch 38: loss -5.92978 acc 0.84106 roc_auc 0.87794 prc_auc 0.92477[0m
[93maverage test of epoch 38: loss -5.71237 acc 0.78378 roc_auc 0.83333 prc_auc 0.91733[0m
[92maverage training of epoch 39: loss -6.05133 acc 0.84106 roc_auc 0.85745 prc_auc 0.89951[0m
[93maverage test of epoch 39: loss -5.82061 acc 0.78378 roc_auc 0.77667 prc_auc 0.84655[0m
[92maverage training of epoch 40: loss -6.09794 acc 0.84106 roc_auc 0.87078 prc_auc 0.91479[0m
[93maverage test of epoch 40: loss -5.85703 acc 0.78378 roc_auc 0.84000 prc_auc 0.91912[0m
[92maverage training of epoch 41: loss -6.20935 acc 0.84106 roc_auc 0.85461 prc_auc 0.90985[0m
[93maverage test of epoch 41: loss -6.13627 acc 0.83784 roc_auc 0.86333 prc_auc 0.91250[0m
[92maverage training of epoch 42: loss -6.30975 acc 0.84768 roc_auc 0.87363 prc_auc 0.92414[0m
[93maverage test of epoch 42: loss -6.12248 acc 0.81081 roc_auc 0.77333 prc_auc 0.83584[0m
[92maverage training of epoch 43: loss -6.36766 acc 0.83444 roc_auc 0.82735 prc_auc 0.88285[0m
[93maverage test of epoch 43: loss -6.21813 acc 0.81081 roc_auc 0.84833 prc_auc 0.91447[0m
[92maverage training of epoch 44: loss -6.52158 acc 0.85430 roc_auc 0.85471 prc_auc 0.89590[0m
[93maverage test of epoch 44: loss -6.28169 acc 0.81081 roc_auc 0.87667 prc_auc 0.93552[0m
[92maverage training of epoch 45: loss -6.53475 acc 0.83444 roc_auc 0.82539 prc_auc 0.87809[0m
[93maverage test of epoch 45: loss -6.39867 acc 0.81081 roc_auc 0.71000 prc_auc 0.79935[0m
[92maverage training of epoch 46: loss -6.66068 acc 0.84106 roc_auc 0.84186 prc_auc 0.87556[0m
[93maverage test of epoch 46: loss -6.44631 acc 0.81081 roc_auc 0.83667 prc_auc 0.92863[0m
[92maverage training of epoch 47: loss -6.79944 acc 0.84768 roc_auc 0.80069 prc_auc 0.85539[0m
[93maverage test of epoch 47: loss -6.57826 acc 0.81081 roc_auc 0.88000 prc_auc 0.94083[0m
[92maverage training of epoch 48: loss -6.82740 acc 0.83444 roc_auc 0.81696 prc_auc 0.87217[0m
[93maverage test of epoch 48: loss -6.67008 acc 0.81081 roc_auc 0.84667 prc_auc 0.91291[0m
[92maverage training of epoch 49: loss -6.94875 acc 0.84768 roc_auc 0.87824 prc_auc 0.92134[0m
[93maverage test of epoch 49: loss -6.69739 acc 0.81081 roc_auc 0.78000 prc_auc 0.83690[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.24499 acc 0.36424 roc_auc 0.49588 prc_auc 0.66368[0m
[93maverage test of epoch 0: loss -0.44406 acc 0.35135 roc_auc 0.45000 prc_auc 0.67355[0m
[92maverage training of epoch 1: loss -0.62357 acc 0.41060 roc_auc 0.45824 prc_auc 0.65571[0m
[93maverage test of epoch 1: loss -0.78386 acc 0.56757 roc_auc 0.63000 prc_auc 0.83108[0m
[92maverage training of epoch 2: loss -0.93977 acc 0.60927 roc_auc 0.46922 prc_auc 0.67248[0m
[93maverage test of epoch 2: loss -1.07767 acc 0.67568 roc_auc 0.59333 prc_auc 0.73408[0m
[92maverage training of epoch 3: loss -1.21912 acc 0.66225 roc_auc 0.46902 prc_auc 0.65295[0m
[93maverage test of epoch 3: loss -1.34015 acc 0.67568 roc_auc 0.46000 prc_auc 0.70048[0m
[92maverage training of epoch 4: loss -1.47963 acc 0.66225 roc_auc 0.50902 prc_auc 0.72440[0m
[93maverage test of epoch 4: loss -1.62960 acc 0.67568 roc_auc 0.53333 prc_auc 0.74113[0m
[92maverage training of epoch 5: loss -1.76262 acc 0.66225 roc_auc 0.45745 prc_auc 0.64698[0m
[93maverage test of epoch 5: loss -1.93896 acc 0.67568 roc_auc 0.61000 prc_auc 0.70294[0m
[92maverage training of epoch 6: loss -2.12473 acc 0.66225 roc_auc 0.50686 prc_auc 0.65158[0m
[93maverage test of epoch 6: loss -2.34445 acc 0.67568 roc_auc 0.59000 prc_auc 0.72792[0m
[92maverage training of epoch 7: loss -2.57823 acc 0.66225 roc_auc 0.42098 prc_auc 0.62137[0mUsing backend: pytorch

[93maverage test of epoch 7: loss -2.84034 acc 0.67568 roc_auc 0.21333 prc_auc 0.55819[0m
[92maverage training of epoch 8: loss -3.11516 acc 0.66225 roc_auc 0.44059 prc_auc 0.63507[0m
[93maverage test of epoch 8: loss -3.38054 acc 0.67568 roc_auc 0.38333 prc_auc 0.59664[0m
[92maverage training of epoch 9: loss -3.61538 acc 0.66225 roc_auc 0.55569 prc_auc 0.72528[0m
[93maverage test of epoch 9: loss -3.85578 acc 0.67568 roc_auc 0.52000 prc_auc 0.72072[0m
[92maverage training of epoch 10: loss -4.01156 acc 0.66225 roc_auc 0.47000 prc_auc 0.62975[0m
[93maverage test of epoch 10: loss -4.17645 acc 0.67568 roc_auc 0.34000 prc_auc 0.60295[0m
[92maverage training of epoch 11: loss -4.29962 acc 0.66225 roc_auc 0.40902 prc_auc 0.61162[0m
[93maverage test of epoch 11: loss -4.47041 acc 0.67568 roc_auc 0.68000 prc_auc 0.85600[0m
[92maverage training of epoch 12: loss -4.52769 acc 0.66225 roc_auc 0.42471 prc_auc 0.61947[0m
[93maverage test of epoch 12: loss -4.64778 acc 0.67568 roc_auc 0.52000 prc_auc 0.72168[0m
[92maverage training of epoch 13: loss -4.72664 acc 0.66225 roc_auc 0.41863 prc_auc 0.59157[0m
[93maverage test of epoch 13: loss -4.84197 acc 0.67568 roc_auc 0.46000 prc_auc 0.65622[0m
[92maverage training of epoch 14: loss -4.90392 acc 0.66225 roc_auc 0.40902 prc_auc 0.61048[0m
[93maverage test of epoch 14: loss -5.01020 acc 0.67568 roc_auc 0.48333 prc_auc 0.70365[0m
[92maverage training of epoch 15: loss -5.06312 acc 0.66225 roc_auc 0.45627 prc_auc 0.65458[0m
[93maverage test of epoch 15: loss -5.16555 acc 0.67568 roc_auc 0.66667 prc_auc 0.80007[0m
[92maverage training of epoch 16: loss -5.20997 acc 0.66225 roc_auc 0.46686 prc_auc 0.62450[0m
[93maverage test of epoch 16: loss -5.30867 acc 0.67568 roc_auc 0.29667 prc_auc 0.57673[0m
[92maverage training of epoch 17: loss -5.36291 acc 0.66225 roc_auc 0.47608 prc_auc 0.64637[0m
[93maverage test of epoch 17: loss -5.43972 acc 0.67568 roc_auc 0.54000 prc_auc 0.69802[0m
[92maverage training of epoch 18: loss -5.49629 acc 0.66225 roc_auc 0.42333 prc_auc 0.59178[0m
[93maverage test of epoch 18: loss -5.58982 acc 0.67568 roc_auc 0.44667 prc_auc 0.63913[0m
[92maverage training of epoch 19: loss -5.62956 acc 0.66225 roc_auc 0.38510 prc_auc 0.60102[0m
[93maverage test of epoch 19: loss -5.69790 acc 0.67568 roc_auc 0.55000 prc_auc 0.70967[0m
[92maverage training of epoch 20: loss -5.76280 acc 0.66225 roc_auc 0.43314 prc_auc 0.62985[0m
[93maverage test of epoch 20: loss -5.84379 acc 0.67568 roc_auc 0.58000 prc_auc 0.78000[0m
[92maverage training of epoch 21: loss -5.88266 acc 0.66225 roc_auc 0.41333 prc_auc 0.62532[0m
[93maverage test of epoch 21: loss -5.96122 acc 0.67568 roc_auc 0.34667 prc_auc 0.63656[0m
[92maverage training of epoch 22: loss -5.99772 acc 0.66225 roc_auc 0.44216 prc_auc 0.64806[0m
[93maverage test of epoch 22: loss -6.07301 acc 0.67568 roc_auc 0.48000 prc_auc 0.62944[0m
[92maverage training of epoch 23: loss -6.11506 acc 0.66225 roc_auc 0.40176 prc_auc 0.59838[0m
[93maverage test of epoch 23: loss -6.19350 acc 0.67568 roc_auc 0.47000 prc_auc 0.70263[0m
[92maverage training of epoch 24: loss -6.22906 acc 0.66225 roc_auc 0.44784 prc_auc 0.62344[0m
[93maverage test of epoch 24: loss -6.31024 acc 0.67568 roc_auc 0.35667 prc_auc 0.61168[0m
[92maverage training of epoch 25: loss -6.34375 acc 0.66225 roc_auc 0.44216 prc_auc 0.61197[0m
[93maverage test of epoch 25: loss -6.42484 acc 0.67568 roc_auc 0.53000 prc_auc 0.72017[0m
[92maverage training of epoch 26: loss -6.45381 acc 0.66225 roc_auc 0.37078 prc_auc 0.57661[0m
[93maverage test of epoch 26: loss -6.53503 acc 0.67568 roc_auc 0.50667 prc_auc 0.67420[0m
[92maverage training of epoch 27: loss -6.56297 acc 0.66225 roc_auc 0.41059 prc_auc 0.64051[0m
[93maverage test of epoch 27: loss -6.64794 acc 0.67568 roc_auc 0.42667 prc_auc 0.68888[0m
[92maverage training of epoch 28: loss -6.67375 acc 0.66225 roc_auc 0.38353 prc_auc 0.59438[0m
[93maverage test of epoch 28: loss -6.76246 acc 0.67568 roc_auc 0.50333 prc_auc 0.65469[0m
[92maverage training of epoch 29: loss -6.78163 acc 0.66225 roc_auc 0.43824 prc_auc 0.62433[0m
[93maverage test of epoch 29: loss -6.86356 acc 0.67568 roc_auc 0.35667 prc_auc 0.66200[0m
[92maverage training of epoch 30: loss -6.89022 acc 0.66225 roc_auc 0.40520 prc_auc 0.64003[0m
[93maverage test of epoch 30: loss -6.97051 acc 0.67568 roc_auc 0.64000 prc_auc 0.82093[0m
[92maverage training of epoch 31: loss -6.99542 acc 0.66225 roc_auc 0.37961 prc_auc 0.56752[0m
[93maverage test of epoch 31: loss -7.07548 acc 0.67568 roc_auc 0.46333 prc_auc 0.74409[0m
[92maverage training of epoch 32: loss -7.10468 acc 0.66225 roc_auc 0.38627 prc_auc 0.58499[0m
[93maverage test of epoch 32: loss -7.18501 acc 0.67568 roc_auc 0.46000 prc_auc 0.69802[0m
[92maverage training of epoch 33: loss -7.20470 acc 0.66225 roc_auc 0.39549 prc_auc 0.61198[0m
[93maverage test of epoch 33: loss -7.28607 acc 0.67568 roc_auc 0.58667 prc_auc 0.79885[0m
[92maverage training of epoch 34: loss -7.31493 acc 0.66225 roc_auc 0.38882 prc_auc 0.58146[0m
[93maverage test of epoch 34: loss -7.39682 acc 0.67568 roc_auc 0.55000 prc_auc 0.73048[0m
[92maverage training of epoch 35: loss -7.41796 acc 0.66225 roc_auc 0.42529 prc_auc 0.60427[0m
[93maverage test of epoch 35: loss -7.49529 acc 0.67568 roc_auc 0.51667 prc_auc 0.75300[0m
[92maverage training of epoch 36: loss -7.51888 acc 0.66225 roc_auc 0.40608 prc_auc 0.58685[0m
[93maverage test of epoch 36: loss -7.60472 acc 0.67568 roc_auc 0.51333 prc_auc 0.70001[0m
[92maverage training of epoch 37: loss -7.62571 acc 0.66225 roc_auc 0.38020 prc_auc 0.58691[0m
[93maverage test of epoch 37: loss -7.70865 acc 0.67568 roc_auc 0.55333 prc_auc 0.73408[0m
[92maverage training of epoch 38: loss -7.72737 acc 0.66225 roc_auc 0.35863 prc_auc 0.56752[0m
[93maverage test of epoch 38: loss -7.80845 acc 0.67568 roc_auc 0.38000 prc_auc 0.67499[0m
[92maverage training of epoch 39: loss -7.83042 acc 0.66225 roc_auc 0.35824 prc_auc 0.56830[0m
[93maverage test of epoch 39: loss -7.91409 acc 0.67568 roc_auc 0.43333 prc_auc 0.66645[0m
[92maverage training of epoch 40: loss -7.93462 acc 0.66225 roc_auc 0.41745 prc_auc 0.61065[0m
[93maverage test of epoch 40: loss -8.02008 acc 0.67568 roc_auc 0.56667 prc_auc 0.80603[0m
[92maverage training of epoch 41: loss -8.03865 acc 0.66225 roc_auc 0.39196 prc_auc 0.60323[0m
[93maverage test of epoch 41: loss -8.11854 acc 0.67568 roc_auc 0.45833 prc_auc 0.67768[0m
[92maverage training of epoch 42: loss -8.14009 acc 0.66225 roc_auc 0.38775 prc_auc 0.58907[0m
[93maverage test of epoch 42: loss -8.22211 acc 0.67568 roc_auc 0.62000 prc_auc 0.77907[0m
[92maverage training of epoch 43: loss -8.24266 acc 0.66225 roc_auc 0.42510 prc_auc 0.60416[0m
[93maverage test of epoch 43: loss -8.32390 acc 0.67568 roc_auc 0.57167 prc_auc 0.71572[0m
[92maverage training of epoch 44: loss -8.34257 acc 0.66225 roc_auc 0.38373 prc_auc 0.59901[0m
[93maverage test of epoch 44: loss -8.42676 acc 0.67568 roc_auc 0.52500 prc_auc 0.67659[0m
[92maverage training of epoch 45: loss -8.44291 acc 0.66225 roc_auc 0.41176 prc_auc 0.60516[0m
[93maverage test of epoch 45: loss -8.52979 acc 0.67568 roc_auc 0.57333 prc_auc 0.74017[0m
[92maverage training of epoch 46: loss -8.54785 acc 0.66225 roc_auc 0.39333 prc_auc 0.58883[0m
[93maverage test of epoch 46: loss -8.63428 acc 0.67568 roc_auc 0.62667 prc_auc 0.80252[0m
[92maverage training of epoch 47: loss -8.64829 acc 0.66225 roc_auc 0.39206 prc_auc 0.60283[0m
[93maverage test of epoch 47: loss -8.73583 acc 0.67568 roc_auc 0.61667 prc_auc 0.78350[0m
[92maverage training of epoch 48: loss -8.75059 acc 0.66225 roc_auc 0.40824 prc_auc 0.60977[0m
[93maverage test of epoch 48: loss -8.83526 acc 0.67568 roc_auc 0.57667 prc_auc 0.67837[0m
[92maverage training of epoch 49: loss -8.85188 acc 0.66225 roc_auc 0.37667 prc_auc 0.57761[0m
[93maverage test of epoch 49: loss -8.93947 acc 0.67568 roc_auc 0.39000 prc_auc 0.59372[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.0001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.72361 ROC_AUC (avg): 0.58692 PRC_AUC (avg): 0.73213 

Average forward propagation time taken(ms): 3.9517440022857135
Average backward propagation time taken(ms): 1.511013210302437

