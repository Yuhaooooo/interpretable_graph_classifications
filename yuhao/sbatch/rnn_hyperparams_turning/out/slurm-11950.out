# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.0001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-01-03-37/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-01-03-37/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 8,
 'epochs': 100,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 8,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.0001,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 1,
 'num_workers': 8,
 'number_of_mlp_layer': 0,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-18-01-03-37',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 100, 'learning_rate': 0.0001, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss 0.25362 acc 0.36000 roc_auc 0.54040 prc_auc 0.75097[0m
[93maverage test of epoch 0: loss 0.18429 acc 0.39474 roc_auc 0.87385 prc_auc 0.94095[0m
[92maverage training of epoch 1: loss 0.12361 acc 0.38667 roc_auc 0.56920 prc_auc 0.76993[0m
[93maverage test of epoch 1: loss 0.05473 acc 0.42105 roc_auc 0.86769 prc_auc 0.93902[0m
[92maverage training of epoch 2: loss -0.00732 acc 0.50667 roc_auc 0.57520 prc_auc 0.77667[0m
[93maverage test of epoch 2: loss -0.07645 acc 0.73684 roc_auc 0.86769 prc_auc 0.93902[0m
[92maverage training of epoch 3: loss -0.14087 acc 0.63333 roc_auc 0.57520 prc_auc 0.77512[0m
[93maverage test of epoch 3: loss -0.21142 acc 0.65789 roc_auc 0.87385 prc_auc 0.94085[0m
[92maverage training of epoch 4: loss -0.28031 acc 0.66667 roc_auc 0.57000 prc_auc 0.77288[0m
[93maverage test of epoch 4: loss -0.35499 acc 0.65789 roc_auc 0.87692 prc_auc 0.94174[0m
[92maverage training of epoch 5: loss -0.43306 acc 0.66667 roc_auc 0.54560 prc_auc 0.75386[0m
[93maverage test of epoch 5: loss -0.51802 acc 0.65789 roc_auc 0.87077 prc_auc 0.93581[0m
[92maverage training of epoch 6: loss -0.61567 acc 0.66667 roc_auc 0.51080 prc_auc 0.71869[0m
[93maverage test of epoch 6: loss -0.72300 acc 0.65789 roc_auc 0.86154 prc_auc 0.92141[0m
[92maverage training of epoch 7: loss -0.85167 acc 0.66667 roc_auc 0.42040 prc_auc 0.62418[0m
[93maverage test of epoch 7: loss -0.98798 acc 0.65789 roc_auc 0.60923 prc_auc 0.75761[0m
[92maverage training of epoch 8: loss -1.13445 acc 0.66667 roc_auc 0.35800 prc_auc 0.59096[0m
[93maverage test of epoch 8: loss -1.27766 acc 0.65789 roc_auc 0.24615 prc_auc 0.59794[0m
[92maverage training of epoch 9: loss -1.40328 acc 0.66667 roc_auc 0.34700 prc_auc 0.59263[0m
[93maverage test of epoch 9: loss -1.51772 acc 0.65789 roc_auc 0.25077 prc_auc 0.62901[0m
[92maverage training of epoch 10: loss -1.61218 acc 0.66667 roc_auc 0.38220 prc_auc 0.60919[0m
[93maverage test of epoch 10: loss -1.69968 acc 0.65789 roc_auc 0.24769 prc_auc 0.60570[0m
[92maverage training of epoch 11: loss -1.77720 acc 0.66667 roc_auc 0.42300 prc_auc 0.63270[0m
[93maverage test of epoch 11: loss -1.85130 acc 0.65789 roc_auc 0.24000 prc_auc 0.60265[0m
[92maverage training of epoch 12: loss -1.92098 acc 0.66667 roc_auc 0.46540 prc_auc 0.67208[0m
[93maverage test of epoch 12: loss -1.98901 acc 0.65789 roc_auc 0.25538 prc_auc 0.62341[0m
[92maverage training of epoch 13: loss -2.05482 acc 0.66667 roc_auc 0.50260 prc_auc 0.71314[0m
[93maverage test of epoch 13: loss -2.12009 acc 0.65789 roc_auc 0.70769 prc_auc 0.85829[0m
[92maverage training of epoch 14: loss -2.18371 acc 0.66667 roc_auc 0.53140 prc_auc 0.73902[0m
[93maverage test of epoch 14: loss -2.24765 acc 0.65789 roc_auc 0.82462 prc_auc 0.90298[0m
[92maverage training of epoch 15: loss -2.30965 acc 0.66667 roc_auc 0.54880 prc_auc 0.75197[0m
[93maverage test of epoch 15: loss -2.37272 acc 0.65789 roc_auc 0.86154 prc_auc 0.92386[0m
[92maverage training of epoch 16: loss -2.43320 acc 0.66667 roc_auc 0.56000 prc_auc 0.75779[0m
[93maverage test of epoch 16: loss -2.49541 acc 0.65789 roc_auc 0.87385 prc_auc 0.92576[0m
[92maverage training of epoch 17: loss -2.55432 acc 0.66667 roc_auc 0.56680 prc_auc 0.76375[0m
[93maverage test of epoch 17: loss -2.61557 acc 0.65789 roc_auc 0.86769 prc_auc 0.92373[0m
[92maverage training of epoch 18: loss -2.67291 acc 0.60667 roc_auc 0.56600 prc_auc 0.76427[0m
[93maverage test of epoch 18: loss -2.73317 acc 0.42105 roc_auc 0.86154 prc_auc 0.92126[0m
[92maverage training of epoch 19: loss -2.78901 acc 0.36000 roc_auc 0.56600 prc_auc 0.76411[0m
[93maverage test of epoch 19: loss -2.84836 acc 0.36842 roc_auc 0.85385 prc_auc 0.91866[0m
[92maverage training of epoch 20: loss -2.90286 acc 0.34000 roc_auc 0.56280 prc_auc 0.76014[0m
[93maverage test of epoch 20: loss -2.96145 acc 0.34211 roc_auc 0.84923 prc_auc 0.91705[0m
[92maverage training of epoch 21: loss -3.01479 acc 0.33333 roc_auc 0.56000 prc_auc 0.75901[0m
[93maverage test of epoch 21: loss -3.07281 acc 0.34211 roc_auc 0.85231 prc_auc 0.91839[0m
[92maverage training of epoch 22: loss -3.12519 acc 0.33333 roc_auc 0.56000 prc_auc 0.75918[0m
[93maverage test of epoch 22: loss -3.18285 acc 0.34211 roc_auc 0.87077 prc_auc 0.93575[0m
[92maverage training of epoch 23: loss -3.23444 acc 0.33333 roc_auc 0.56240 prc_auc 0.76190[0m
[93maverage test of epoch 23: loss -3.29198 acc 0.34211 roc_auc 0.87385 prc_auc 0.93727[0m
[92maverage training of epoch 24: loss -3.34296 acc 0.33333 roc_auc 0.56980 prc_auc 0.76710[0m
[93maverage test of epoch 24: loss -3.40059 acc 0.34211 roc_auc 0.87385 prc_auc 0.93727[0m
[92maverage training of epoch 25: loss -3.45111 acc 0.33333 roc_auc 0.57820 prc_auc 0.77416[0m
[93maverage test of epoch 25: loss -3.50904 acc 0.34211 roc_auc 0.87077 prc_auc 0.93622[0m
[92maverage training of epoch 26: loss -3.55925 acc 0.33333 roc_auc 0.58600 prc_auc 0.77995[0m
[93maverage test of epoch 26: loss -3.61768 acc 0.34211 roc_auc 0.87077 prc_auc 0.93637[0m
[92maverage training of epoch 27: loss -3.66769 acc 0.33333 roc_auc 0.59200 prc_auc 0.78375[0m
[93maverage test of epoch 27: loss -3.72679 acc 0.34211 roc_auc 0.87385 prc_auc 0.93705[0m
[92maverage training of epoch 28: loss -3.77671 acc 0.33333 roc_auc 0.60600 prc_auc 0.79606[0m
[93maverage test of epoch 28: loss -3.83660 acc 0.34211 roc_auc 0.87692 prc_auc 0.93712[0m
[92maverage training of epoch 29: loss -3.88648 acc 0.33333 roc_auc 0.61760 prc_auc 0.80634[0m
[93maverage test of epoch 29: loss -3.94725 acc 0.34211 roc_auc 0.87692 prc_auc 0.93712[0m
[92maverage training of epoch 30: loss -3.99710 acc 0.33333 roc_auc 0.62740 prc_auc 0.81352[0m
[93maverage test of epoch 30: loss -4.05873 acc 0.34211 roc_auc 0.87077 prc_auc 0.93516[0m
[92maverage training of epoch 31: loss -4.10851 acc 0.33333 roc_auc 0.63280 prc_auc 0.81710[0m
[93maverage test of epoch 31: loss -4.17094 acc 0.34211 roc_auc 0.86769 prc_auc 0.93415[0m
[92maverage training of epoch 32: loss -4.22058 acc 0.33333 roc_auc 0.64200 prc_auc 0.82224[0m
[93maverage test of epoch 32: loss -4.28376 acc 0.34211 roc_auc 0.86769 prc_auc 0.93415[0m
[92maverage training of epoch 33: loss -4.33319 acc 0.33333 roc_auc 0.66440 prc_auc 0.82948[0m
[93maverage test of epoch 33: loss -4.39715 acc 0.34211 roc_auc 0.86462 prc_auc 0.93326[0m
[92maverage training of epoch 34: loss -4.44649 acc 0.33333 roc_auc 0.71580 prc_auc 0.85447[0m
[93maverage test of epoch 34: loss -4.51155 acc 0.34211 roc_auc 0.86154 prc_auc 0.93235[0m
[92maverage training of epoch 35: loss -4.56122 acc 0.33333 roc_auc 0.75880 prc_auc 0.87532[0m
[93maverage test of epoch 35: loss -4.62810 acc 0.34211 roc_auc 0.85846 prc_auc 0.93142[0m
[92maverage training of epoch 36: loss -4.67872 acc 0.33333 roc_auc 0.78540 prc_auc 0.88860[0m
[93maverage test of epoch 36: loss -4.74762 acc 0.34211 roc_auc 0.85846 prc_auc 0.93142[0m
[92maverage training of epoch 37: loss -4.79911 acc 0.33333 roc_auc 0.82800 prc_auc 0.90547[0m
[93maverage test of epoch 37: loss -4.86820 acc 0.34211 roc_auc 0.85846 prc_auc 0.93142[0m
[92maverage training of epoch 38: loss -4.91995 acc 0.33333 roc_auc 0.86560 prc_auc 0.92205[0m
[93maverage test of epoch 38: loss -4.98726 acc 0.34211 roc_auc 0.86154 prc_auc 0.93450[0m
[92maverage training of epoch 39: loss -5.03937 acc 0.33333 roc_auc 0.87120 prc_auc 0.92561[0m
[93maverage test of epoch 39: loss -5.10452 acc 0.34211 roc_auc 0.86462 prc_auc 0.93736[0m
[92maverage training of epoch 40: loss -5.15734 acc 0.33333 roc_auc 0.87980 prc_auc 0.92980[0m
[93maverage test of epoch 40: loss -5.22054 acc 0.34211 roc_auc 0.86462 prc_auc 0.93736[0m
[92maverage training of epoch 41: loss -5.27433 acc 0.33333 roc_auc 0.88300 prc_auc 0.93123[0m
[93maverage test of epoch 41: loss -5.33570 acc 0.34211 roc_auc 0.86462 prc_auc 0.93736[0m
[92maverage training of epoch 42: loss -5.39064 acc 0.33333 roc_auc 0.88580 prc_auc 0.93205[0m
[93maverage test of epoch 42: loss -5.45011 acc 0.34211 roc_auc 0.86769 prc_auc 0.93837[0m
[92maverage training of epoch 43: loss -5.50634 acc 0.52000 roc_auc 0.88700 prc_auc 0.93141[0m
[93maverage test of epoch 43: loss -5.56362 acc 0.65789 roc_auc 0.86769 prc_auc 0.93837[0m
[92maverage training of epoch 44: loss -5.62123 acc 0.67333 roc_auc 0.88680 prc_auc 0.93003[0m
[93maverage test of epoch 44: loss -5.67608 acc 0.73684 roc_auc 0.86769 prc_auc 0.93837[0m
[92maverage training of epoch 45: loss -5.73528 acc 0.73333 roc_auc 0.88700 prc_auc 0.92893[0m
[93maverage test of epoch 45: loss -5.78752 acc 0.73684 roc_auc 0.86769 prc_auc 0.93837[0m
[92maverage training of epoch 46: loss -5.84852 acc 0.76000 roc_auc 0.88620 prc_auc 0.92654[0m
[93maverage test of epoch 46: loss -5.89799 acc 0.78947 roc_auc 0.86769 prc_auc 0.93837[0m
[92maverage training of epoch 47: loss -5.96094 acc 0.84000 roc_auc 0.88340 prc_auc 0.92256[0m
[93maverage test of epoch 47: loss -6.00750 acc 0.81579 roc_auc 0.86769 prc_auc 0.93837[0m
[92maverage training of epoch 48: loss -6.07254 acc 0.86000 roc_auc 0.88140 prc_auc 0.91818[0m
[93maverage test of epoch 48: loss -6.11607 acc 0.81579 roc_auc 0.86769 prc_auc 0.93837[0m
[92maverage training of epoch 49: loss -6.18333 acc 0.86667 roc_auc 0.87960 prc_auc 0.91188[0m
[93maverage test of epoch 49: loss -6.22374 acc 0.81579 roc_auc 0.86769 prc_auc 0.93837[0m
[92maverage training of epoch 50: loss -6.29334 acc 0.86000 roc_auc 0.87760 prc_auc 0.90724[0m
[93maverage test of epoch 50: loss -6.33053 acc 0.84211 roc_auc 0.87077 prc_auc 0.93945[0m
[92maverage training of epoch 51: loss -6.40258 acc 0.86000 roc_auc 0.87620 prc_auc 0.90271[0m
[93maverage test of epoch 51: loss -6.43647 acc 0.84211 roc_auc 0.87077 prc_auc 0.93945[0m
[92maverage training of epoch 52: loss -6.51106 acc 0.85333 roc_auc 0.87700 prc_auc 0.90268[0m
[93maverage test of epoch 52: loss -6.54159 acc 0.84211 roc_auc 0.87077 prc_auc 0.93945[0m
[92maverage training of epoch 53: loss -6.61879 acc 0.87333 roc_auc 0.87540 prc_auc 0.89892[0m
[93maverage test of epoch 53: loss -6.64593 acc 0.84211 roc_auc 0.87077 prc_auc 0.93945[0m
[92maverage training of epoch 54: loss -6.72582 acc 0.86000 roc_auc 0.87360 prc_auc 0.89686[0m
[93maverage test of epoch 54: loss -6.74956 acc 0.84211 roc_auc 0.87077 prc_auc 0.93945[0m
[92maverage training of epoch 55: loss -6.83220 acc 0.86667 roc_auc 0.87140 prc_auc 0.89131[0m
[93maverage test of epoch 55: loss -6.85254 acc 0.84211 roc_auc 0.87077 prc_auc 0.93945[0m
[92maverage training of epoch 56: loss -6.93796 acc 0.86667 roc_auc 0.86880 prc_auc 0.88351[0m
[93maverage test of epoch 56: loss -6.95490 acc 0.84211 roc_auc 0.87385 prc_auc 0.94038[0m
[92maverage training of epoch 57: loss -7.04312 acc 0.86667 roc_auc 0.86880 prc_auc 0.88415[0m
[93maverage test of epoch 57: loss -7.05669 acc 0.84211 roc_auc 0.87385 prc_auc 0.94038[0m
[92maverage training of epoch 58: loss -7.14772 acc 0.86667 roc_auc 0.86740 prc_auc 0.88201[0m
[93maverage test of epoch 58: loss -7.15796 acc 0.84211 roc_auc 0.87385 prc_auc 0.94038[0m
[92maverage training of epoch 59: loss -7.25177 acc 0.86667 roc_auc 0.86720 prc_auc 0.88187[0m
[93maverage test of epoch 59: loss -7.25875 acc 0.84211 roc_auc 0.87385 prc_auc 0.94038[0m
[92maverage training of epoch 60: loss -7.35532 acc 0.86667 roc_auc 0.86700 prc_auc 0.88144[0m
[93maverage test of epoch 60: loss -7.35909 acc 0.84211 roc_auc 0.87385 prc_auc 0.94038[0m
[92maverage training of epoch 61: loss -7.45837 acc 0.86667 roc_auc 0.86700 prc_auc 0.88172[0m
[93maverage test of epoch 61: loss -7.45901 acc 0.84211 roc_auc 0.87385 prc_auc 0.94038[0m
[92maverage training of epoch 62: loss -7.56093 acc 0.86667 roc_auc 0.86620 prc_auc 0.88055[0m
[93maverage test of epoch 62: loss -7.55852 acc 0.84211 roc_auc 0.87692 prc_auc 0.94305[0m
[92maverage training of epoch 63: loss -7.66298 acc 0.86667 roc_auc 0.86580 prc_auc 0.88032[0m
[93maverage test of epoch 63: loss -7.65762 acc 0.84211 roc_auc 0.87692 prc_auc 0.94305[0m
[92maverage training of epoch 64: loss -7.76451 acc 0.86667 roc_auc 0.86580 prc_auc 0.88072[0m
[93maverage test of epoch 64: loss -7.75632 acc 0.84211 roc_auc 0.87692 prc_auc 0.94305[0m
[92maverage training of epoch 65: loss -7.86555 acc 0.86667 roc_auc 0.86600 prc_auc 0.88051[0m
[93maverage test of epoch 65: loss -7.85465 acc 0.84211 roc_auc 0.88000 prc_auc 0.94555[0m
[92maverage training of epoch 66: loss -7.96612 acc 0.86667 roc_auc 0.86600 prc_auc 0.88075[0m
[93maverage test of epoch 66: loss -7.95261 acc 0.84211 roc_auc 0.88000 prc_auc 0.94555[0m
[92maverage training of epoch 67: loss -8.06626 acc 0.86667 roc_auc 0.86640 prc_auc 0.88023[0m
[93maverage test of epoch 67: loss -8.05025 acc 0.84211 roc_auc 0.88000 prc_auc 0.94555[0m
[92maverage training of epoch 68: loss -8.16598 acc 0.86667 roc_auc 0.86580 prc_auc 0.87827[0m
[93maverage test of epoch 68: loss -8.14757 acc 0.84211 roc_auc 0.88000 prc_auc 0.94555[0m
[92maverage training of epoch 69: loss -8.26531 acc 0.86667 roc_auc 0.86480 prc_auc 0.87561[0m
[93maverage test of epoch 69: loss -8.24459 acc 0.84211 roc_auc 0.88000 prc_auc 0.94555[0m
[92maverage training of epoch 70: loss -8.36429 acc 0.86667 roc_auc 0.86320 prc_auc 0.87310[0m
[93maverage test of epoch 70: loss -8.34135 acc 0.84211 roc_auc 0.88000 prc_auc 0.94555[0m
[92maverage training of epoch 71: loss -8.46297 acc 0.86667 roc_auc 0.86240 prc_auc 0.87174[0m
[93maverage test of epoch 71: loss -8.43787 acc 0.84211 roc_auc 0.88000 prc_auc 0.94555[0m
[92maverage training of epoch 72: loss -8.56137 acc 0.85333 roc_auc 0.86200 prc_auc 0.87124[0m
[93maverage test of epoch 72: loss -8.53417 acc 0.81579 roc_auc 0.88308 prc_auc 0.94721[0m
[92maverage training of epoch 73: loss -8.65953 acc 0.86000 roc_auc 0.86240 prc_auc 0.87503[0m
[93maverage test of epoch 73: loss -8.63027 acc 0.81579 roc_auc 0.88308 prc_auc 0.94721[0m
[92maverage training of epoch 74: loss -8.75746 acc 0.86000 roc_auc 0.86200 prc_auc 0.87383[0m
[93maverage test of epoch 74: loss -8.72618 acc 0.81579 roc_auc 0.88308 prc_auc 0.94721[0m
[92maverage training of epoch 75: loss -8.85519 acc 0.86000 roc_auc 0.86160 prc_auc 0.87312[0m
[93maverage test of epoch 75: loss -8.82193 acc 0.81579 roc_auc 0.88308 prc_auc 0.94721[0m
[92maverage training of epoch 76: loss -8.95274 acc 0.86000 roc_auc 0.86160 prc_auc 0.87259[0m
[93maverage test of epoch 76: loss -8.91752 acc 0.81579 roc_auc 0.88308 prc_auc 0.94721[0m
[92maverage training of epoch 77: loss -9.05011 acc 0.86000 roc_auc 0.86060 prc_auc 0.87099[0m
[93maverage test of epoch 77: loss -9.01298 acc 0.81579 roc_auc 0.88308 prc_auc 0.94721[0m
[92maverage training of epoch 78: loss -9.14734 acc 0.86000 roc_auc 0.86040 prc_auc 0.87037[0m
[93maverage test of epoch 78: loss -9.10832 acc 0.81579 roc_auc 0.88308 prc_auc 0.94721[0m
[92maverage training of epoch 79: loss -9.24443 acc 0.86000 roc_auc 0.86000 prc_auc 0.86973[0m
[93maverage test of epoch 79: loss -9.20354 acc 0.81579 roc_auc 0.88308 prc_auc 0.94721[0m
[92maverage training of epoch 80: loss -9.34139 acc 0.86667 roc_auc 0.86020 prc_auc 0.86908[0m
[93maverage test of epoch 80: loss -9.29865 acc 0.81579 roc_auc 0.88308 prc_auc 0.94721[0m
[92maverage training of epoch 81: loss -9.43824 acc 0.86667 roc_auc 0.86000 prc_auc 0.86874[0m
[93maverage test of epoch 81: loss -9.39368 acc 0.81579 roc_auc 0.88308 prc_auc 0.94721[0m
[92maverage training of epoch 82: loss -9.53499 acc 0.86667 roc_auc 0.86000 prc_auc 0.86874[0m
[93maverage test of epoch 82: loss -9.48862 acc 0.81579 roc_auc 0.88308 prc_auc 0.94721[0m
[92maverage training of epoch 83: loss -9.63164 acc 0.86667 roc_auc 0.86000 prc_auc 0.86874[0m
[93maverage test of epoch 83: loss -9.58348 acc 0.81579 roc_auc 0.88308 prc_auc 0.94721[0m
[92maverage training of epoch 84: loss -9.72820 acc 0.86667 roc_auc 0.86040 prc_auc 0.86924[0m
[93maverage test of epoch 84: loss -9.67827 acc 0.81579 roc_auc 0.88308 prc_auc 0.94721[0m
[92maverage training of epoch 85: loss -9.82469 acc 0.86667 roc_auc 0.86040 prc_auc 0.86894[0m
[93maverage test of epoch 85: loss -9.77299 acc 0.81579 roc_auc 0.88308 prc_auc 0.94721[0m
[92maverage training of epoch 86: loss -9.92110 acc 0.86667 roc_auc 0.86040 prc_auc 0.86847[0m
[93maverage test of epoch 86: loss -9.86765 acc 0.81579 roc_auc 0.88308 prc_auc 0.94721[0m
[92maverage training of epoch 87: loss -10.01744 acc 0.86667 roc_auc 0.86000 prc_auc 0.86797[0m
[93maverage test of epoch 87: loss -9.96226 acc 0.81579 roc_auc 0.88308 prc_auc 0.94721[0m
[92maverage training of epoch 88: loss -10.11373 acc 0.86667 roc_auc 0.86000 prc_auc 0.86797[0m
[93maverage test of epoch 88: loss -10.05681 acc 0.81579 roc_auc 0.88308 prc_auc 0.94721[0m
[92maverage training of epoch 89: loss -10.20995 acc 0.86667 roc_auc 0.86000 prc_auc 0.86797[0m
[93maverage test of epoch 89: loss -10.15132 acc 0.81579 roc_auc 0.88308 prc_auc 0.94721[0m
[92maverage training of epoch 90: loss -10.30612 acc 0.86667 roc_auc 0.85980 prc_auc 0.86752[0m
[93maverage test of epoch 90: loss -10.24579 acc 0.81579 roc_auc 0.88308 prc_auc 0.94721[0m
[92maverage training of epoch 91: loss -10.40225 acc 0.86667 roc_auc 0.85960 prc_auc 0.86704[0m
[93maverage test of epoch 91: loss -10.34021 acc 0.81579 roc_auc 0.88308 prc_auc 0.94721[0m
[92maverage training of epoch 92: loss -10.49833 acc 0.86667 roc_auc 0.85960 prc_auc 0.86704[0m
[93maverage test of epoch 92: loss -10.43460 acc 0.81579 roc_auc 0.88308 prc_auc 0.94721[0m
[92maverage training of epoch 93: loss -10.59436 acc 0.86667 roc_auc 0.85940 prc_auc 0.86699[0m
[93maverage test of epoch 93: loss -10.52895 acc 0.81579 roc_auc 0.88308 prc_auc 0.94721[0m
[92maverage training of epoch 94: loss -10.69036 acc 0.86667 roc_auc 0.85940 prc_auc 0.86699[0m
[93maverage test of epoch 94: loss -10.62327 acc 0.81579 roc_auc 0.88308 prc_auc 0.94721[0m
[92maverage training of epoch 95: loss -10.78631 acc 0.86667 roc_auc 0.85940 prc_auc 0.86699[0m
[93maverage test of epoch 95: loss -10.71756 acc 0.81579 roc_auc 0.88308 prc_auc 0.94721[0m
[92maverage training of epoch 96: loss -10.88224 acc 0.86667 roc_auc 0.85960 prc_auc 0.86705[0m
[93maverage test of epoch 96: loss -10.81182 acc 0.81579 roc_auc 0.88308 prc_auc 0.94721[0m
[92maverage training of epoch 97: loss -10.97814 acc 0.86667 roc_auc 0.85940 prc_auc 0.86700[0m
[93maverage test of epoch 97: loss -10.90606 acc 0.81579 roc_auc 0.88308 prc_auc 0.94721[0m
[92maverage training of epoch 98: loss -11.07401 acc 0.86667 roc_auc 0.85940 prc_auc 0.86700[0m
[93maverage test of epoch 98: loss -11.00027 acc 0.81579 roc_auc 0.88308 prc_auc 0.94721[0m
[92maverage training of epoch 99: loss -11.16985 acc 0.86667 roc_auc 0.85900 prc_auc 0.86608[0m
[93maverage test of epoch 99: loss -11.09446 acc 0.81579 roc_auc 0.88615 prc_auc 0.94956[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.14601 acc 0.66667 roc_auc 0.35580 prc_auc 0.57218[0m
[93maverage test of epoch 0: loss -0.28116 acc 0.65789 roc_auc 0.21231 prc_auc 0.56568[0m
[92maverage training of epoch 1: loss -0.42088 acc 0.66667 roc_auc 0.33840 prc_auc 0.56418[0m
[93maverage test of epoch 1: loss -0.55135 acc 0.65789 roc_auc 0.16308 prc_auc 0.49895[0m
[92maverage training of epoch 2: loss -0.68435 acc 0.66667 roc_auc 0.33140 prc_auc 0.55907[0m
[93maverage test of epoch 2: loss -0.80516 acc 0.65789 roc_auc 0.15385 prc_auc 0.49597[0m
[92maverage training of epoch 3: loss -0.92876 acc 0.66667 roc_auc 0.32830 prc_auc 0.55495[0m
[93maverage test of epoch 3: loss -1.03891 acc 0.65789 roc_auc 0.15077 prc_auc 0.49502[0m
[92maverage training of epoch 4: loss -1.15530 acc 0.66667 roc_auc 0.32540 prc_auc 0.55254[0m
[93maverage test of epoch 4: loss -1.25903 acc 0.65789 roc_auc 0.15077 prc_auc 0.49502[0m
[92maverage training of epoch 5: loss -1.37516 acc 0.66667 roc_auc 0.32130 prc_auc 0.55037[0m
[93maverage test of epoch 5: loss -1.48267 acc 0.65789 roc_auc 0.15077 prc_auc 0.49502[0m
[92maverage training of epoch 6: loss -1.61252 acc 0.66667 roc_auc 0.29620 prc_auc 0.54096[0m
[93maverage test of epoch 6: loss -1.74509 acc 0.65789 roc_auc 0.15077 prc_auc 0.49518[0m
[92maverage training of epoch 7: loss -1.91076 acc 0.66667 roc_auc 0.23740 prc_auc 0.51780[0m
[93maverage test of epoch 7: loss -2.08714 acc 0.65789 roc_auc 0.13538 prc_auc 0.49075[0m
[92maverage training of epoch 8: loss -2.26058 acc 0.66667 roc_auc 0.31220 prc_auc 0.54844[0m
[93maverage test of epoch 8: loss -2.42263 acc 0.65789 roc_auc 0.13231 prc_auc 0.48948[0m
[92maverage training of epoch 9: loss -2.57081 acc 0.66667 roc_auc 0.36880 prc_auc 0.58047[0m
[93maverage test of epoch 9: loss -2.70467 acc 0.65789 roc_auc 0.12615 prc_auc 0.48735[0m
[92maverage training of epoch 10: loss -2.84613 acc 0.66667 roc_auc 0.38560 prc_auc 0.58694[0m
[93maverage test of epoch 10: loss -2.98100 acc 0.65789 roc_auc 0.13846 prc_auc 0.49076[0m
[92maverage training of epoch 11: loss -3.12278 acc 0.66667 roc_auc 0.39220 prc_auc 0.59967[0m
[93maverage test of epoch 11: loss -3.24966 acc 0.65789 roc_auc 0.23077 prc_auc 0.57029[0m
[92maverage training of epoch 12: loss -3.36918 acc 0.66667 roc_auc 0.39880 prc_auc 0.60183[0m
[93maverage test of epoch 12: loss -3.47523 acc 0.65789 roc_auc 0.22769 prc_auc 0.56924[0m
[92maverage training of epoch 13: loss -3.57957 acc 0.66667 roc_auc 0.40060 prc_auc 0.60045[0m
[93maverage test of epoch 13: loss -3.67336 acc 0.65789 roc_auc 0.23077 prc_auc 0.57010[0m
[92maverage training of epoch 14: loss -3.76914 acc 0.66667 roc_auc 0.40600 prc_auc 0.60442[0m
[93maverage test of epoch 14: loss -3.85459 acc 0.65789 roc_auc 0.23385 prc_auc 0.57115[0m
[92maverage training of epoch 15: loss -3.94477 acc 0.66667 roc_auc 0.41060 prc_auc 0.60667[0m
[93maverage test of epoch 15: loss -4.02351 acc 0.65789 roc_auc 0.25846 prc_auc 0.57798[0m
[92maverage training of epoch 16: loss -4.10969 acc 0.66667 roc_auc 0.41500 prc_auc 0.60896[0m
[93maverage test of epoch 16: loss -4.18268 acc 0.65789 roc_auc 0.30769 prc_auc 0.63391[0m
[92maverage training of epoch 17: loss -4.26585 acc 0.66667 roc_auc 0.41920 prc_auc 0.61159[0m
[93maverage test of epoch 17: loss -4.33379 acc 0.65789 roc_auc 0.34615 prc_auc 0.66219[0m
[92maverage training of epoch 18: loss -4.41463 acc 0.66667 roc_auc 0.42060 prc_auc 0.61593[0m
[93maverage test of epoch 18: loss -4.47810 acc 0.65789 roc_auc 0.36923 prc_auc 0.68531[0m
[92maverage training of epoch 19: loss -4.55713 acc 0.66667 roc_auc 0.42060 prc_auc 0.61705[0m
[93maverage test of epoch 19: loss -4.61662 acc 0.65789 roc_auc 0.54462 prc_auc 0.79920[0m
[92maverage training of epoch 20: loss -4.69423 acc 0.66667 roc_auc 0.42440 prc_auc 0.61702[0m
[93maverage test of epoch 20: loss -4.75017 acc 0.65789 roc_auc 0.69538 prc_auc 0.86642[0m
[92maverage training of epoch 21: loss -4.82670 acc 0.66667 roc_auc 0.42900 prc_auc 0.61771[0m
[93maverage test of epoch 21: loss -4.87948 acc 0.65789 roc_auc 0.76308 prc_auc 0.90000[0m
[92maverage training of epoch 22: loss -4.95518 acc 0.66667 roc_auc 0.43140 prc_auc 0.62463[0m
[93maverage test of epoch 22: loss -5.00515 acc 0.65789 roc_auc 0.82462 prc_auc 0.92544[0m
[92maverage training of epoch 23: loss -5.08025 acc 0.66667 roc_auc 0.43460 prc_auc 0.62820[0m
[93maverage test of epoch 23: loss -5.12773 acc 0.65789 roc_auc 0.87692 prc_auc 0.94170[0m
[92maverage training of epoch 24: loss -5.20241 acc 0.66667 roc_auc 0.43780 prc_auc 0.63029[0m
[93maverage test of epoch 24: loss -5.24767 acc 0.65789 roc_auc 0.90769 prc_auc 0.95015[0m
[92maverage training of epoch 25: loss -5.32209 acc 0.66667 roc_auc 0.44180 prc_auc 0.63377[0m
[93maverage test of epoch 25: loss -5.36537 acc 0.65789 roc_auc 0.91385 prc_auc 0.95410[0m
[92maverage training of epoch 26: loss -5.43968 acc 0.66667 roc_auc 0.44430 prc_auc 0.64204[0m
[93maverage test of epoch 26: loss -5.48120 acc 0.65789 roc_auc 0.90769 prc_auc 0.94923[0m
[92maverage training of epoch 27: loss -5.55550 acc 0.66667 roc_auc 0.44720 prc_auc 0.64813[0m
[93maverage test of epoch 27: loss -5.59543 acc 0.65789 roc_auc 0.90462 prc_auc 0.94549[0m
[92maverage training of epoch 28: loss -5.66982 acc 0.66667 roc_auc 0.44880 prc_auc 0.64900[0m
[93maverage test of epoch 28: loss -5.70833 acc 0.65789 roc_auc 0.90462 prc_auc 0.94549[0m
[92maverage training of epoch 29: loss -5.78288 acc 0.66667 roc_auc 0.45360 prc_auc 0.65425[0m
[93maverage test of epoch 29: loss -5.82012 acc 0.65789 roc_auc 0.90462 prc_auc 0.94549[0m
[92maverage training of epoch 30: loss -5.89490 acc 0.66667 roc_auc 0.45410 prc_auc 0.65554[0m
[93maverage test of epoch 30: loss -5.93099 acc 0.65789 roc_auc 0.90462 prc_auc 0.94549[0m
[92maverage training of epoch 31: loss -6.00605 acc 0.66667 roc_auc 0.45480 prc_auc 0.65704[0m
[93maverage test of epoch 31: loss -6.04111 acc 0.65789 roc_auc 0.90462 prc_auc 0.94549[0m
[92maverage training of epoch 32: loss -6.11649 acc 0.66667 roc_auc 0.45380 prc_auc 0.65521[0m
[93maverage test of epoch 32: loss -6.15062 acc 0.65789 roc_auc 0.90462 prc_auc 0.94549[0m
[92maverage training of epoch 33: loss -6.22636 acc 0.66667 roc_auc 0.45220 prc_auc 0.65338[0m
[93maverage test of epoch 33: loss -6.25966 acc 0.65789 roc_auc 0.90769 prc_auc 0.94707[0m
[92maverage training of epoch 34: loss -6.33578 acc 0.66667 roc_auc 0.44980 prc_auc 0.65176[0m
[93maverage test of epoch 34: loss -6.36834 acc 0.65789 roc_auc 0.90769 prc_auc 0.94720[0m
[92maverage training of epoch 35: loss -6.44485 acc 0.66667 roc_auc 0.44520 prc_auc 0.64897[0m
[93maverage test of epoch 35: loss -6.47675 acc 0.65789 roc_auc 0.90769 prc_auc 0.94707[0m
[92maverage training of epoch 36: loss -6.55367 acc 0.66667 roc_auc 0.44380 prc_auc 0.64689[0m
[93maverage test of epoch 36: loss -6.58499 acc 0.65789 roc_auc 0.90769 prc_auc 0.94707[0m
[92maverage training of epoch 37: loss -6.66230 acc 0.66667 roc_auc 0.44130 prc_auc 0.64536[0m
[93maverage test of epoch 37: loss -6.69310 acc 0.65789 roc_auc 0.90769 prc_auc 0.94748[0m
[92maverage training of epoch 38: loss -6.77081 acc 0.66667 roc_auc 0.43920 prc_auc 0.64371[0m
[93maverage test of epoch 38: loss -6.80115 acc 0.65789 roc_auc 0.90923 prc_auc 0.94722[0m
[92maverage training of epoch 39: loss -6.87923 acc 0.66667 roc_auc 0.43700 prc_auc 0.64221[0m
[93maverage test of epoch 39: loss -6.90914 acc 0.65789 roc_auc 0.90923 prc_auc 0.94723[0m
[92maverage training of epoch 40: loss -6.98759 acc 0.66667 roc_auc 0.43500 prc_auc 0.63573[0m
[93maverage test of epoch 40: loss -7.01710 acc 0.65789 roc_auc 0.90615 prc_auc 0.94443[0m
[92maverage training of epoch 41: loss -7.09587 acc 0.66667 roc_auc 0.43160 prc_auc 0.62851[0m
[93maverage test of epoch 41: loss -7.12502 acc 0.65789 roc_auc 0.90769 prc_auc 0.94748[0m
[92maverage training of epoch 42: loss -7.20409 acc 0.66667 roc_auc 0.42900 prc_auc 0.62528[0m
[93maverage test of epoch 42: loss -7.23287 acc 0.65789 roc_auc 0.90615 prc_auc 0.94375[0m
[92maverage training of epoch 43: loss -7.31221 acc 0.66667 roc_auc 0.42550 prc_auc 0.60848[0m
[93maverage test of epoch 43: loss -7.34063 acc 0.65789 roc_auc 0.90923 prc_auc 0.94635[0m
[92maverage training of epoch 44: loss -7.42020 acc 0.66667 roc_auc 0.42070 prc_auc 0.60336[0m
[93maverage test of epoch 44: loss -7.44825 acc 0.65789 roc_auc 0.82923 prc_auc 0.90908[0m
[92maverage training of epoch 45: loss -7.52803 acc 0.66667 roc_auc 0.41720 prc_auc 0.59961[0m
[93maverage test of epoch 45: loss -7.55570 acc 0.65789 roc_auc 0.82923 prc_auc 0.90769[0m
[92maverage training of epoch 46: loss -7.63565 acc 0.66667 roc_auc 0.41460 prc_auc 0.59806[0m
[93maverage test of epoch 46: loss -7.66294 acc 0.65789 roc_auc 0.83231 prc_auc 0.91029[0m
[92maverage training of epoch 47: loss -7.74304 acc 0.66667 roc_auc 0.41280 prc_auc 0.59611[0m
[93maverage test of epoch 47: loss -7.76993 acc 0.65789 roc_auc 0.82462 prc_auc 0.90165[0m
[92maverage training of epoch 48: loss -7.85016 acc 0.66667 roc_auc 0.41280 prc_auc 0.59561[0m
[93maverage test of epoch 48: loss -7.87663 acc 0.65789 roc_auc 0.81846 prc_auc 0.89864[0m
[92maverage training of epoch 49: loss -7.95697 acc 0.66667 roc_auc 0.41170 prc_auc 0.59502[0m
[93maverage test of epoch 49: loss -7.98301 acc 0.65789 roc_auc 0.82308 prc_auc 0.89763[0m
[92maverage training of epoch 50: loss -8.06346 acc 0.66667 roc_auc 0.41210 prc_auc 0.59529[0m
[93maverage test of epoch 50: loss -8.08906 acc 0.65789 roc_auc 0.82462 prc_auc 0.90647[0m
[92maverage training of epoch 51: loss -8.16961 acc 0.66667 roc_auc 0.41120 prc_auc 0.59391[0m
[93maverage test of epoch 51: loss -8.19476 acc 0.65789 roc_auc 0.80000 prc_auc 0.88520[0m
[92maverage training of epoch 52: loss -8.27540 acc 0.66667 roc_auc 0.40990 prc_auc 0.59323[0m
[93maverage test of epoch 52: loss -8.30011 acc 0.65789 roc_auc 0.76923 prc_auc 0.86957[0m
[92maverage training of epoch 53: loss -8.38084 acc 0.66667 roc_auc 0.41020 prc_auc 0.59368[0m
[93maverage test of epoch 53: loss -8.40509 acc 0.65789 roc_auc 0.70154 prc_auc 0.83188[0m
[92maverage training of epoch 54: loss -8.48593 acc 0.66667 roc_auc 0.41090 prc_auc 0.59369[0m
[93maverage test of epoch 54: loss -8.50972 acc 0.65789 roc_auc 0.65385 prc_auc 0.79964[0m
[92maverage training of epoch 55: loss -8.59066 acc 0.66667 roc_auc 0.41050 prc_auc 0.59346[0m
[93maverage test of epoch 55: loss -8.61400 acc 0.65789 roc_auc 0.57077 prc_auc 0.74065[0m
[92maverage training of epoch 56: loss -8.69505 acc 0.66667 roc_auc 0.41090 prc_auc 0.59356[0m
[93maverage test of epoch 56: loss -8.71794 acc 0.65789 roc_auc 0.54615 prc_auc 0.73348[0m
[92maverage training of epoch 57: loss -8.79912 acc 0.66667 roc_auc 0.41080 prc_auc 0.59280[0m
[93maverage test of epoch 57: loss -8.82155 acc 0.65789 roc_auc 0.51538 prc_auc 0.71803[0m
[92maverage training of epoch 58: loss -8.90287 acc 0.66667 roc_auc 0.41060 prc_auc 0.59230[0m
[93maverage test of epoch 58: loss -8.92485 acc 0.65789 roc_auc 0.48923 prc_auc 0.70780[0m
[92maverage training of epoch 59: loss -9.00631 acc 0.66667 roc_auc 0.41070 prc_auc 0.59192[0m
[93maverage test of epoch 59: loss -9.02786 acc 0.65789 roc_auc 0.45692 prc_auc 0.66791[0m
[92maverage training of epoch 60: loss -9.10948 acc 0.66667 roc_auc 0.41040 prc_auc 0.59116[0m
[93maverage test of epoch 60: loss -9.13059 acc 0.65789 roc_auc 0.34923 prc_auc 0.61285[0m
[92maverage training of epoch 61: loss -9.21237 acc 0.66667 roc_auc 0.41110 prc_auc 0.59161[0m
[93maverage test of epoch 61: loss -9.23306 acc 0.65789 roc_auc 0.40615 prc_auc 0.64499[0m
[92maverage training of epoch 62: loss -9.31501 acc 0.66667 roc_auc 0.41350 prc_auc 0.59340[0m
[93maverage test of epoch 62: loss -9.33528 acc 0.65789 roc_auc 0.35538 prc_auc 0.59587[0m
[92maverage training of epoch 63: loss -9.41741 acc 0.66667 roc_auc 0.41410 prc_auc 0.59370[0m
[93maverage test of epoch 63: loss -9.43727 acc 0.65789 roc_auc 0.26462 prc_auc 0.55812[0m
[92maverage training of epoch 64: loss -9.51960 acc 0.66667 roc_auc 0.41370 prc_auc 0.59315[0m
[93maverage test of epoch 64: loss -9.53905 acc 0.65789 roc_auc 0.29846 prc_auc 0.57117[0m
[92maverage training of epoch 65: loss -9.62157 acc 0.66667 roc_auc 0.41340 prc_auc 0.59324[0m
[93maverage test of epoch 65: loss -9.64063 acc 0.65789 roc_auc 0.28769 prc_auc 0.56657[0m
[92maverage training of epoch 66: loss -9.72336 acc 0.66667 roc_auc 0.41290 prc_auc 0.59219[0m
[93maverage test of epoch 66: loss -9.74202 acc 0.65789 roc_auc 0.30308 prc_auc 0.57310[0m
[92maverage training of epoch 67: loss -9.82497 acc 0.66667 roc_auc 0.41300 prc_auc 0.59203[0m
[93maverage test of epoch 67: loss -9.84324 acc 0.65789 roc_auc 0.36000 prc_auc 0.59810[0m
[92maverage training of epoch 68: loss -9.92641 acc 0.66667 roc_auc 0.41310 prc_auc 0.59200[0m
[93maverage test of epoch 68: loss -9.94430 acc 0.65789 roc_auc 0.32154 prc_auc 0.58486[0m
[92maverage training of epoch 69: loss -10.02769 acc 0.66667 roc_auc 0.41370 prc_auc 0.59296[0m
[93maverage test of epoch 69: loss -10.04521 acc 0.65789 roc_auc 0.20923 prc_auc 0.59704[0m
[92maverage training of epoch 70: loss -10.12884 acc 0.66667 roc_auc 0.41380 prc_auc 0.59365[0m
[93maverage test of epoch 70: loss -10.14599 acc 0.65789 roc_auc 0.32000 prc_auc 0.58425[0m
[92maverage training of epoch 71: loss -10.22985 acc 0.66667 roc_auc 0.41420 prc_auc 0.59573[0m
[93maverage test of epoch 71: loss -10.24664 acc 0.65789 roc_auc 0.46923 prc_auc 0.64485[0m
[92maverage training of epoch 72: loss -10.33075 acc 0.66667 roc_auc 0.41420 prc_auc 0.59556[0m
[93maverage test of epoch 72: loss -10.34718 acc 0.65789 roc_auc 0.32000 prc_auc 0.58462[0m
[92maverage training of epoch 73: loss -10.43153 acc 0.66667 roc_auc 0.41420 prc_auc 0.59556[0m
[93maverage test of epoch 73: loss -10.44761 acc 0.65789 roc_auc 0.52462 prc_auc 0.67893[0m
[92maverage training of epoch 74: loss -10.53220 acc 0.66667 roc_auc 0.41440 prc_auc 0.59625[0m
[93maverage test of epoch 74: loss -10.54793 acc 0.65789 roc_auc 0.46000 prc_auc 0.64041[0m
[92maverage training of epoch 75: loss -10.63278 acc 0.66667 roc_auc 0.41450 prc_auc 0.59623[0m
[93maverage test of epoch 75: loss -10.64817 acc 0.65789 roc_auc 0.46000 prc_auc 0.64041[0m
[92maverage training of epoch 76: loss -10.73327 acc 0.66667 roc_auc 0.41470 prc_auc 0.59718[0m
[93maverage test of epoch 76: loss -10.74832 acc 0.65789 roc_auc 0.46000 prc_auc 0.64041[0m
[92maverage training of epoch 77: loss -10.83368 acc 0.66667 roc_auc 0.41500 prc_auc 0.59734[0m
[93maverage test of epoch 77: loss -10.84839 acc 0.65789 roc_auc 0.50923 prc_auc 0.66708[0m
[92maverage training of epoch 78: loss -10.93401 acc 0.66667 roc_auc 0.41560 prc_auc 0.59818[0m
[93maverage test of epoch 78: loss -10.94839 acc 0.65789 roc_auc 0.32000 prc_auc 0.58462[0m
[92maverage training of epoch 79: loss -11.03428 acc 0.66667 roc_auc 0.41660 prc_auc 0.60045[0m
[93maverage test of epoch 79: loss -11.04833 acc 0.65789 roc_auc 0.46000 prc_auc 0.64004[0m
[92maverage training of epoch 80: loss -11.13448 acc 0.66667 roc_auc 0.41680 prc_auc 0.60045[0m
[93maverage test of epoch 80: loss -11.14820 acc 0.65789 roc_auc 0.46000 prc_auc 0.64041[0m
[92maverage training of epoch 81: loss -11.23462 acc 0.66667 roc_auc 0.41740 prc_auc 0.60120[0m
[93maverage test of epoch 81: loss -11.24802 acc 0.65789 roc_auc 0.15077 prc_auc 0.58085[0m
[92maverage training of epoch 82: loss -11.33470 acc 0.66667 roc_auc 0.41760 prc_auc 0.60138[0m
[93maverage test of epoch 82: loss -11.34779 acc 0.65789 roc_auc 0.46000 prc_auc 0.64004[0m
[92maverage training of epoch 83: loss -11.43474 acc 0.66667 roc_auc 0.41770 prc_auc 0.60148[0m
[93maverage test of epoch 83: loss -11.44751 acc 0.65789 roc_auc 0.46000 prc_auc 0.64041[0m
[92maverage training of epoch 84: loss -11.53473 acc 0.66667 roc_auc 0.41800 prc_auc 0.60166[0m
[93maverage test of epoch 84: loss -11.54718 acc 0.65789 roc_auc 0.46000 prc_auc 0.64041[0m
[92maverage training of epoch 85: loss -11.63467 acc 0.66667 roc_auc 0.41780 prc_auc 0.60235[0m
[93maverage test of epoch 85: loss -11.64681 acc 0.65789 roc_auc 0.50462 prc_auc 0.66619[0m
[92maverage training of epoch 86: loss -11.73458 acc 0.66667 roc_auc 0.41800 prc_auc 0.60176[0m
[93maverage test of epoch 86: loss -11.74641 acc 0.65789 roc_auc 0.46000 prc_auc 0.64041[0m
[92maverage training of epoch 87: loss -11.83445 acc 0.66667 roc_auc 0.41840 prc_auc 0.60174[0m
[93maverage test of epoch 87: loss -11.84597 acc 0.65789 roc_auc 0.46000 prc_auc 0.64041[0m
[92maverage training of epoch 88: loss -11.93429 acc 0.66667 roc_auc 0.41860 prc_auc 0.60258[0m
[93maverage test of epoch 88: loss -11.94550 acc 0.65789 roc_auc 0.38000 prc_auc 0.60610[0m
[92maverage training of epoch 89: loss -12.03409 acc 0.66667 roc_auc 0.41890 prc_auc 0.60262[0m
[93maverage test of epoch 89: loss -12.04500 acc 0.65789 roc_auc 0.10615 prc_auc 0.64041[0m
[92maverage training of epoch 90: loss -12.13387 acc 0.66667 roc_auc 0.41920 prc_auc 0.60302[0m
[93maverage test of epoch 90: loss -12.14447 acc 0.65789 roc_auc 0.46000 prc_auc 0.64041[0m
[92maverage training of epoch 91: loss -12.23362 acc 0.66667 roc_auc 0.41930 prc_auc 0.60356[0m
[93maverage test of epoch 91: loss -12.24392 acc 0.65789 roc_auc 0.46000 prc_auc 0.64041[0m
[92maverage training of epoch 92: loss -12.33334 acc 0.66667 roc_auc 0.41940 prc_auc 0.60442[0m
[93maverage test of epoch 92: loss -12.34334 acc 0.65789 roc_auc 0.37538 prc_auc 0.60459[0m
[92maverage training of epoch 93: loss -12.43304 acc 0.66667 roc_auc 0.41940 prc_auc 0.60415[0m
[93maverage test of epoch 93: loss -12.44274 acc 0.65789 roc_auc 0.46000 prc_auc 0.64041[0m
[92maverage training of epoch 94: loss -12.53272 acc 0.66667 roc_auc 0.41930 prc_auc 0.60398[0m
[93maverage test of epoch 94: loss -12.54213 acc 0.65789 roc_auc 0.46000 prc_auc 0.64041[0m
[92maverage training of epoch 95: loss -12.63239 acc 0.66667 roc_auc 0.41950 prc_auc 0.60412[0m
[93maverage test of epoch 95: loss -12.64149 acc 0.65789 roc_auc 0.46000 prc_auc 0.64041[0m
[92maverage training of epoch 96: loss -12.73203 acc 0.66667 roc_auc 0.41960 prc_auc 0.60420[0m
[93maverage test of epoch 96: loss -12.74084 acc 0.65789 roc_auc 0.46000 prc_auc 0.64041[0m
[92maverage training of epoch 97: loss -12.83166 acc 0.66667 roc_auc 0.41940 prc_auc 0.60393[0m
[93maverage test of epoch 97: loss -12.84017 acc 0.65789 roc_auc 0.46000 prc_auc 0.64041[0m
[92maverage training of epoch 98: loss -12.93127 acc 0.66667 roc_auc 0.41960 prc_auc 0.60415[0m
[93maverage test of epoch 98: loss -12.93949 acc 0.65789 roc_auc 0.46000 prc_auc 0.64041[0m
[92maverage training of epoch 99: loss -13.03087 acc 0.66667 roc_auc 0.41960 prc_auc 0.60404[0m
[93maverage test of epoch 99: loss -13.03880 acc 0.65789 roc_auc 0.61692 prc_auc 0.72352[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.21316 acc 0.66667 roc_auc 0.45420 prc_auc 0.65581[0m
[93maverage test of epoch 0: loss -0.38728 acc 0.65789 roc_auc 0.90769 prc_auc 0.96098[0m
[92maverage training of epoch 1: loss -0.56288 acc 0.66667 roc_auc 0.43300 prc_auc 0.63888[0m
[93maverage test of epoch 1: loss -0.73599 acc 0.65789 roc_auc 0.75077 prc_auc 0.89971[0m
[92maverage training of epoch 2: loss -0.90878 acc 0.66667 roc_auc 0.42000 prc_auc 0.62845[0m
[93maverage test of epoch 2: loss -1.07407 acc 0.65789 roc_auc 0.43077 prc_auc 0.72678[0m
[92maverage training of epoch 3: loss -1.23647 acc 0.66667 roc_auc 0.41580 prc_auc 0.62056[0m
[93maverage test of epoch 3: loss -1.38802 acc 0.65789 roc_auc 0.16923 prc_auc 0.56408[0m
[92maverage training of epoch 4: loss -1.53928 acc 0.66667 roc_auc 0.41860 prc_auc 0.62712[0m
[93maverage test of epoch 4: loss -1.67942 acc 0.65789 roc_auc 0.40615 prc_auc 0.71420[0m
[92maverage training of epoch 5: loss -1.82720 acc 0.66667 roc_auc 0.42350 prc_auc 0.62994[0m
[93maverage test of epoch 5: loss -1.96616 acc 0.65789 roc_auc 0.86769 prc_auc 0.94761[0m
[92maverage training of epoch 6: loss -2.12430 acc 0.66667 roc_auc 0.42380 prc_auc 0.63130[0m
[93maverage test of epoch 6: loss -2.27681 acc 0.65789 roc_auc 0.92462 prc_auc 0.97079[0m
[92maverage training of epoch 7: loss -2.45542 acc 0.66667 roc_auc 0.43180 prc_auc 0.63847[0m
[93maverage test of epoch 7: loss -2.62718 acc 0.65789 roc_auc 0.96000 prc_auc 0.98266[0m
[92maverage training of epoch 8: loss -2.82299 acc 0.66667 roc_auc 0.43440 prc_auc 0.63990[0m
[93maverage test of epoch 8: loss -3.00958 acc 0.65789 roc_auc 0.95077 prc_auc 0.97769[0m
[92maverage training of epoch 9: loss -3.22574 acc 0.66667 roc_auc 0.43940 prc_auc 0.64197[0m
[93maverage test of epoch 9: loss -3.43354 acc 0.65789 roc_auc 0.95231 prc_auc 0.97791[0m
[92maverage training of epoch 10: loss -3.67725 acc 0.66667 roc_auc 0.44780 prc_auc 0.64955[0m
[93maverage test of epoch 10: loss -3.90466 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 11: loss -4.15811 acc 0.66667 roc_auc 0.45880 prc_auc 0.65692[0m
[93maverage test of epoch 11: loss -4.37781 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 12: loss -4.60535 acc 0.66667 roc_auc 0.46940 prc_auc 0.66145[0m
[93maverage test of epoch 12: loss -4.78210 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 13: loss -4.96119 acc 0.66667 roc_auc 0.46820 prc_auc 0.66120[0m
[93maverage test of epoch 13: loss -5.08838 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 14: loss -5.23181 acc 0.66667 roc_auc 0.45740 prc_auc 0.65191[0m
[93maverage test of epoch 14: loss -5.32792 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 15: loss -5.45156 acc 0.66667 roc_auc 0.44720 prc_auc 0.64213[0m
[93maverage test of epoch 15: loss -5.53003 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 16: loss -5.64211 acc 0.66667 roc_auc 0.43610 prc_auc 0.63287[0m
[93maverage test of epoch 16: loss -5.70957 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 17: loss -5.81417 acc 0.66667 roc_auc 0.42740 prc_auc 0.62710[0m
[93maverage test of epoch 17: loss -5.87404 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 18: loss -5.97338 acc 0.66667 roc_auc 0.42120 prc_auc 0.62633[0m
[93maverage test of epoch 18: loss -6.02762 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 19: loss -6.12306 acc 0.66667 roc_auc 0.41820 prc_auc 0.62520[0m
[93maverage test of epoch 19: loss -6.17293 acc 0.65789 roc_auc 0.95538 prc_auc 0.97933[0m
[92maverage training of epoch 20: loss -6.26538 acc 0.66667 roc_auc 0.41610 prc_auc 0.62513[0m
[93maverage test of epoch 20: loss -6.31175 acc 0.65789 roc_auc 0.95538 prc_auc 0.97933[0m
[92maverage training of epoch 21: loss -6.40183 acc 0.66667 roc_auc 0.41320 prc_auc 0.62428[0m
[93maverage test of epoch 21: loss -6.44531 acc 0.65789 roc_auc 0.95538 prc_auc 0.97933[0m
[92maverage training of epoch 22: loss -6.53350 acc 0.66667 roc_auc 0.40980 prc_auc 0.62129[0m
[93maverage test of epoch 22: loss -6.57456 acc 0.65789 roc_auc 0.95538 prc_auc 0.97933[0m
[92maverage training of epoch 23: loss -6.66121 acc 0.66667 roc_auc 0.40680 prc_auc 0.61684[0m
[93maverage test of epoch 23: loss -6.70020 acc 0.65789 roc_auc 0.95538 prc_auc 0.97933[0m
[92maverage training of epoch 24: loss -6.78560 acc 0.66667 roc_auc 0.40380 prc_auc 0.61508[0m
[93maverage test of epoch 24: loss -6.82280 acc 0.65789 roc_auc 0.95385 prc_auc 0.97808[0m
[92maverage training of epoch 25: loss -6.90716 acc 0.66667 roc_auc 0.40210 prc_auc 0.61374[0m
[93maverage test of epoch 25: loss -6.94280 acc 0.65789 roc_auc 0.95538 prc_auc 0.97933[0m
[92maverage training of epoch 26: loss -7.02631 acc 0.66667 roc_auc 0.39950 prc_auc 0.61085[0m
[93maverage test of epoch 26: loss -7.06057 acc 0.65789 roc_auc 0.95538 prc_auc 0.97946[0m
[92maverage training of epoch 27: loss -7.14336 acc 0.66667 roc_auc 0.39640 prc_auc 0.60892[0m
[93maverage test of epoch 27: loss -7.17639 acc 0.65789 roc_auc 0.95385 prc_auc 0.97808[0m
[92maverage training of epoch 28: loss -7.25859 acc 0.66667 roc_auc 0.39500 prc_auc 0.60838[0m
[93maverage test of epoch 28: loss -7.29052 acc 0.65789 roc_auc 0.95385 prc_auc 0.97808[0m
[92maverage training of epoch 29: loss -7.37224 acc 0.66667 roc_auc 0.39360 prc_auc 0.60702[0m
[93maverage test of epoch 29: loss -7.40317 acc 0.65789 roc_auc 0.95231 prc_auc 0.97697[0m
[92maverage training of epoch 30: loss -7.48449 acc 0.66667 roc_auc 0.39240 prc_auc 0.60631[0m
[93maverage test of epoch 30: loss -7.51450 acc 0.65789 roc_auc 0.95231 prc_auc 0.97697[0m
[92maverage training of epoch 31: loss -7.59550 acc 0.66667 roc_auc 0.39220 prc_auc 0.60578[0m
[93maverage test of epoch 31: loss -7.62468 acc 0.65789 roc_auc 0.95231 prc_auc 0.97697[0m
[92maverage training of epoch 32: loss -7.70543 acc 0.66667 roc_auc 0.39160 prc_auc 0.60563[0m
[93maverage test of epoch 32: loss -7.73383 acc 0.65789 roc_auc 0.95077 prc_auc 0.97663[0m
[92maverage training of epoch 33: loss -7.81437 acc 0.66667 roc_auc 0.39060 prc_auc 0.60513[0m
[93maverage test of epoch 33: loss -7.84206 acc 0.65789 roc_auc 0.95231 prc_auc 0.97697[0m
[92maverage training of epoch 34: loss -7.92245 acc 0.66667 roc_auc 0.38960 prc_auc 0.60448[0m
[93maverage test of epoch 34: loss -7.94947 acc 0.65789 roc_auc 0.95385 prc_auc 0.97697[0m
[92maverage training of epoch 35: loss -8.02974 acc 0.66667 roc_auc 0.38910 prc_auc 0.60395[0m
[93maverage test of epoch 35: loss -8.05614 acc 0.65789 roc_auc 0.95385 prc_auc 0.97697[0m
[92maverage training of epoch 36: loss -8.13634 acc 0.66667 roc_auc 0.38870 prc_auc 0.60418[0m
[93maverage test of epoch 36: loss -8.16214 acc 0.65789 roc_auc 0.95077 prc_auc 0.97663[0m
[92maverage training of epoch 37: loss -8.24231 acc 0.66667 roc_auc 0.38840 prc_auc 0.60366[0m
[93maverage test of epoch 37: loss -8.26755 acc 0.65789 roc_auc 0.95385 prc_auc 0.97697[0m
[92maverage training of epoch 38: loss -8.34771 acc 0.66667 roc_auc 0.38750 prc_auc 0.60271[0m
[93maverage test of epoch 38: loss -8.37242 acc 0.65789 roc_auc 0.95538 prc_auc 0.97808[0m
[92maverage training of epoch 39: loss -8.45259 acc 0.66667 roc_auc 0.38730 prc_auc 0.60287[0m
[93maverage test of epoch 39: loss -8.47680 acc 0.65789 roc_auc 0.95692 prc_auc 0.97946[0m
[92maverage training of epoch 40: loss -8.55701 acc 0.66667 roc_auc 0.38690 prc_auc 0.60247[0m
[93maverage test of epoch 40: loss -8.58074 acc 0.65789 roc_auc 0.95846 prc_auc 0.97697[0m
[92maverage training of epoch 41: loss -8.66101 acc 0.66667 roc_auc 0.38640 prc_auc 0.60242[0m
[93maverage test of epoch 41: loss -8.68427 acc 0.65789 roc_auc 0.95846 prc_auc 0.97693[0m
[92maverage training of epoch 42: loss -8.76462 acc 0.66667 roc_auc 0.38640 prc_auc 0.60205[0m
[93maverage test of epoch 42: loss -8.78744 acc 0.65789 roc_auc 0.96308 prc_auc 0.97697[0m
[92maverage training of epoch 43: loss -8.86788 acc 0.66667 roc_auc 0.38620 prc_auc 0.60217[0m
[93maverage test of epoch 43: loss -8.89027 acc 0.65789 roc_auc 0.94462 prc_auc 0.97298[0m
[92maverage training of epoch 44: loss -8.97083 acc 0.66667 roc_auc 0.38560 prc_auc 0.60017[0m
[93maverage test of epoch 44: loss -8.99281 acc 0.65789 roc_auc 0.95538 prc_auc 0.97363[0m
[92maverage training of epoch 45: loss -9.07348 acc 0.66667 roc_auc 0.38530 prc_auc 0.60038[0m
[93maverage test of epoch 45: loss -9.09506 acc 0.65789 roc_auc 0.96769 prc_auc 0.97697[0m
[92maverage training of epoch 46: loss -9.17587 acc 0.66667 roc_auc 0.38550 prc_auc 0.59784[0m
[93maverage test of epoch 46: loss -9.19706 acc 0.65789 roc_auc 0.95692 prc_auc 0.97298[0m
[92maverage training of epoch 47: loss -9.27802 acc 0.66667 roc_auc 0.38510 prc_auc 0.59787[0m
[93maverage test of epoch 47: loss -9.29883 acc 0.65789 roc_auc 0.94769 prc_auc 0.96111[0m
[92maverage training of epoch 48: loss -9.37995 acc 0.66667 roc_auc 0.38490 prc_auc 0.59743[0m
[93maverage test of epoch 48: loss -9.40038 acc 0.65789 roc_auc 0.94000 prc_auc 0.95822[0m
[92maverage training of epoch 49: loss -9.48168 acc 0.66667 roc_auc 0.38450 prc_auc 0.59682[0m
[93maverage test of epoch 49: loss -9.50174 acc 0.65789 roc_auc 0.93538 prc_auc 0.95965[0m
[92maverage training of epoch 50: loss -9.58322 acc 0.66667 roc_auc 0.38440 prc_auc 0.59672[0m
[93maverage test of epoch 50: loss -9.60293 acc 0.65789 roc_auc 0.92923 prc_auc 0.95141[0m
[92maverage training of epoch 51: loss -9.68459 acc 0.66667 roc_auc 0.38420 prc_auc 0.59682[0m
[93maverage test of epoch 51: loss -9.70395 acc 0.65789 roc_auc 0.94308 prc_auc 0.95125[0m
[92maverage training of epoch 52: loss -9.78581 acc 0.66667 roc_auc 0.38440 prc_auc 0.59660[0m
[93maverage test of epoch 52: loss -9.80482 acc 0.65789 roc_auc 0.91538 prc_auc 0.93832[0m
[92maverage training of epoch 53: loss -9.88688 acc 0.66667 roc_auc 0.38440 prc_auc 0.59689[0m
[93maverage test of epoch 53: loss -9.90555 acc 0.65789 roc_auc 0.92462 prc_auc 0.94060[0m
[92maverage training of epoch 54: loss -9.98782 acc 0.66667 roc_auc 0.38430 prc_auc 0.59660[0m
[93maverage test of epoch 54: loss -10.00616 acc 0.65789 roc_auc 0.92462 prc_auc 0.94060[0m
[92maverage training of epoch 55: loss -10.08864 acc 0.66667 roc_auc 0.38440 prc_auc 0.59680[0m
[93maverage test of epoch 55: loss -10.10665 acc 0.65789 roc_auc 0.90615 prc_auc 0.93032[0m
[92maverage training of epoch 56: loss -10.18935 acc 0.66667 roc_auc 0.38410 prc_auc 0.59610[0m
[93maverage test of epoch 56: loss -10.20703 acc 0.65789 roc_auc 0.85231 prc_auc 0.89622[0m
[92maverage training of epoch 57: loss -10.28996 acc 0.66667 roc_auc 0.38410 prc_auc 0.59619[0m
[93maverage test of epoch 57: loss -10.30732 acc 0.65789 roc_auc 0.90000 prc_auc 0.91774[0m
[92maverage training of epoch 58: loss -10.39048 acc 0.66667 roc_auc 0.38370 prc_auc 0.59597[0m
[93maverage test of epoch 58: loss -10.40752 acc 0.65789 roc_auc 0.75385 prc_auc 0.81714[0m
[92maverage training of epoch 59: loss -10.49091 acc 0.66667 roc_auc 0.38370 prc_auc 0.59622[0m
[93maverage test of epoch 59: loss -10.50764 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 60: loss -10.59126 acc 0.66667 roc_auc 0.38360 prc_auc 0.59621[0m
[93maverage test of epoch 60: loss -10.60767 acc 0.65789 roc_auc 0.69231 prc_auc 0.75758[0m
[92maverage training of epoch 61: loss -10.69154 acc 0.66667 roc_auc 0.38340 prc_auc 0.59280[0m
[93maverage test of epoch 61: loss -10.70764 acc 0.65789 roc_auc 0.72000 prc_auc 0.80842[0m
[92maverage training of epoch 62: loss -10.79175 acc 0.66667 roc_auc 0.38280 prc_auc 0.58962[0m
[93maverage test of epoch 62: loss -10.80755 acc 0.65789 roc_auc 0.84308 prc_auc 0.87222[0m
[92maverage training of epoch 63: loss -10.89190 acc 0.66667 roc_auc 0.38230 prc_auc 0.58890[0m
[93maverage test of epoch 63: loss -10.90739 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 64: loss -10.99199 acc 0.66667 roc_auc 0.38220 prc_auc 0.58845[0m
[93maverage test of epoch 64: loss -11.00718 acc 0.65789 roc_auc 0.78769 prc_auc 0.82080[0m
[92maverage training of epoch 65: loss -11.09204 acc 0.66667 roc_auc 0.38230 prc_auc 0.58856[0m
[93maverage test of epoch 65: loss -11.10692 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 66: loss -11.19203 acc 0.66667 roc_auc 0.38130 prc_auc 0.58719[0m
[93maverage test of epoch 66: loss -11.20661 acc 0.65789 roc_auc 0.88000 prc_auc 0.91789[0m
[92maverage training of epoch 67: loss -11.29198 acc 0.66667 roc_auc 0.38090 prc_auc 0.58703[0m
[93maverage test of epoch 67: loss -11.30626 acc 0.65789 roc_auc 0.52000 prc_auc 0.67158[0m
[92maverage training of epoch 68: loss -11.39189 acc 0.66667 roc_auc 0.38060 prc_auc 0.58659[0m
[93maverage test of epoch 68: loss -11.40587 acc 0.65789 roc_auc 0.86000 prc_auc 0.90421[0m
[92maverage training of epoch 69: loss -11.49176 acc 0.66667 roc_auc 0.38060 prc_auc 0.58659[0m
[93maverage test of epoch 69: loss -11.50545 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 70: loss -11.59159 acc 0.66667 roc_auc 0.38050 prc_auc 0.58664[0m
[93maverage test of epoch 70: loss -11.60499 acc 0.65789 roc_auc 0.76000 prc_auc 0.83579[0m
[92maverage training of epoch 71: loss -11.69140 acc 0.66667 roc_auc 0.38060 prc_auc 0.58657[0m
[93maverage test of epoch 71: loss -11.70449 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 72: loss -11.79117 acc 0.66667 roc_auc 0.38030 prc_auc 0.58114[0m
[93maverage test of epoch 72: loss -11.80397 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 73: loss -11.89091 acc 0.66667 roc_auc 0.38030 prc_auc 0.58148[0m
[93maverage test of epoch 73: loss -11.90342 acc 0.65789 roc_auc 0.64000 prc_auc 0.75368[0m
[92maverage training of epoch 74: loss -11.99064 acc 0.66667 roc_auc 0.37930 prc_auc 0.57786[0m
[93maverage test of epoch 74: loss -12.00285 acc 0.65789 roc_auc 0.52000 prc_auc 0.67158[0m
[92maverage training of epoch 75: loss -12.09033 acc 0.66667 roc_auc 0.37910 prc_auc 0.57739[0m
[93maverage test of epoch 75: loss -12.10226 acc 0.65789 roc_auc 0.80615 prc_auc 0.83634[0m
[92maverage training of epoch 76: loss -12.19001 acc 0.66667 roc_auc 0.37890 prc_auc 0.57692[0m
[93maverage test of epoch 76: loss -12.20165 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 77: loss -12.28967 acc 0.66667 roc_auc 0.37880 prc_auc 0.57668[0m
[93maverage test of epoch 77: loss -12.30102 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 78: loss -12.38931 acc 0.66667 roc_auc 0.37850 prc_auc 0.57661[0m
[93maverage test of epoch 78: loss -12.40037 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 79: loss -12.48893 acc 0.66667 roc_auc 0.37860 prc_auc 0.57759[0m
[93maverage test of epoch 79: loss -12.49970 acc 0.65789 roc_auc 0.52000 prc_auc 0.67158[0m
[92maverage training of epoch 80: loss -12.58854 acc 0.66667 roc_auc 0.37860 prc_auc 0.57637[0m
[93maverage test of epoch 80: loss -12.59902 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 81: loss -12.68814 acc 0.66667 roc_auc 0.37830 prc_auc 0.57624[0m
[93maverage test of epoch 81: loss -12.69833 acc 0.65789 roc_auc 0.80615 prc_auc 0.83634[0m
[92maverage training of epoch 82: loss -12.78772 acc 0.66667 roc_auc 0.37830 prc_auc 0.57622[0m
[93maverage test of epoch 82: loss -12.79762 acc 0.65789 roc_auc 0.68923 prc_auc 0.75860[0m
[92maverage training of epoch 83: loss -12.88729 acc 0.66667 roc_auc 0.37800 prc_auc 0.57582[0m
[93maverage test of epoch 83: loss -12.89690 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 84: loss -12.98684 acc 0.66667 roc_auc 0.37800 prc_auc 0.57560[0m
[93maverage test of epoch 84: loss -12.99617 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 85: loss -13.08639 acc 0.66667 roc_auc 0.37740 prc_auc 0.57567[0m
[93maverage test of epoch 85: loss -13.09543 acc 0.65789 roc_auc 0.62000 prc_auc 0.74000[0m
[92maverage training of epoch 86: loss -13.18593 acc 0.66667 roc_auc 0.37740 prc_auc 0.57594[0m
[93maverage test of epoch 86: loss -13.19468 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 87: loss -13.28546 acc 0.66667 roc_auc 0.37730 prc_auc 0.57521[0m
[93maverage test of epoch 87: loss -13.29393 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 88: loss -13.38498 acc 0.66667 roc_auc 0.37730 prc_auc 0.57519[0m
[93maverage test of epoch 88: loss -13.39316 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 89: loss -13.48450 acc 0.66667 roc_auc 0.37710 prc_auc 0.57491[0m
[93maverage test of epoch 89: loss -13.49239 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -13.58400 acc 0.66667 roc_auc 0.37680 prc_auc 0.57502[0m
[93maverage test of epoch 90: loss -13.59161 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 91: loss -13.68350 acc 0.66667 roc_auc 0.37670 prc_auc 0.57437[0m
[93maverage test of epoch 91: loss -13.69083 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 92: loss -13.78300 acc 0.66667 roc_auc 0.37700 prc_auc 0.57476[0m
[93maverage test of epoch 92: loss -13.79004 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 93: loss -13.88249 acc 0.66667 roc_auc 0.37700 prc_auc 0.57471[0m
[93maverage test of epoch 93: loss -13.88924 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 94: loss -13.98197 acc 0.66667 roc_auc 0.37660 prc_auc 0.57485[0m
[93maverage test of epoch 94: loss -13.98844 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 95: loss -14.08145 acc 0.66667 roc_auc 0.37670 prc_auc 0.57496[0m
[93maverage test of epoch 95: loss -14.08763 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 96: loss -14.18093 acc 0.66667 roc_auc 0.37680 prc_auc 0.57486[0m
[93maverage test of epoch 96: loss -14.18682 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 97: loss -14.28040 acc 0.66667 roc_auc 0.37670 prc_auc 0.57481[0m
[93maverage test of epoch 97: loss -14.28601 acc 0.65789 roc_auc 0.67231 prc_auc 0.74632[0m
[92maverage training of epoch 98: loss -14.37986 acc 0.66667 roc_auc 0.37700 prc_auc 0.57509[0m
[93maverage test of epoch 98: loss -14.38519 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -14.47933 acc 0.66667 roc_auc 0.37680 prc_auc 0.57489[0m
[93maverage test of epoch 99: loss -14.48437 acc 0.65789 roc_auc 0.82615 prc_auc 0.84917[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.16745 acc 0.66225 roc_auc 0.37510 prc_auc 0.57691[0m
[93maverage test of epoch 0: loss -0.32981 acc 0.67568 roc_auc 0.17333 prc_auc 0.54929[0m
[92maverage training of epoch 1: loss -0.44420 acc 0.66225 roc_auc 0.39255 prc_auc 0.59233[0m
[93maverage test of epoch 1: loss -0.62590 acc 0.67568 roc_auc 0.21000 prc_auc 0.57302[0m
[92maverage training of epoch 2: loss -0.79184 acc 0.66225 roc_auc 0.42608 prc_auc 0.62290[0m
[93maverage test of epoch 2: loss -1.04417 acc 0.67568 roc_auc 0.50667 prc_auc 0.78701[0m
[92maverage training of epoch 3: loss -1.23053 acc 0.66225 roc_auc 0.45314 prc_auc 0.64613[0m
[93maverage test of epoch 3: loss -1.45912 acc 0.67568 roc_auc 0.81333 prc_auc 0.91420[0m
[92maverage training of epoch 4: loss -1.58112 acc 0.66225 roc_auc 0.48039 prc_auc 0.69305[0m
[93maverage test of epoch 4: loss -1.75305 acc 0.67568 roc_auc 0.84000 prc_auc 0.92200[0m
[92maverage training of epoch 5: loss -1.83765 acc 0.66225 roc_auc 0.48667 prc_auc 0.69828[0m
[93maverage test of epoch 5: loss -1.98311 acc 0.67568 roc_auc 0.83000 prc_auc 0.91346[0m
[92maverage training of epoch 6: loss -2.04771 acc 0.66225 roc_auc 0.46294 prc_auc 0.67735[0m
[93maverage test of epoch 6: loss -2.17962 acc 0.67568 roc_auc 0.82667 prc_auc 0.91099[0m
[92maverage training of epoch 7: loss -2.23147 acc 0.66225 roc_auc 0.44941 prc_auc 0.65590[0m
[93maverage test of epoch 7: loss -2.35530 acc 0.67568 roc_auc 0.82667 prc_auc 0.91099[0m
[92maverage training of epoch 8: loss -2.39824 acc 0.66225 roc_auc 0.44294 prc_auc 0.63730[0m
[93maverage test of epoch 8: loss -2.51713 acc 0.67568 roc_auc 0.83333 prc_auc 0.91580[0m
[92maverage training of epoch 9: loss -2.55350 acc 0.66225 roc_auc 0.44627 prc_auc 0.63491[0m
[93maverage test of epoch 9: loss -2.66944 acc 0.67568 roc_auc 0.87333 prc_auc 0.93239[0m
[92maverage training of epoch 10: loss -2.70074 acc 0.66225 roc_auc 0.45471 prc_auc 0.64674[0m
[93maverage test of epoch 10: loss -2.81504 acc 0.67568 roc_auc 0.87333 prc_auc 0.93239[0m
[92maverage training of epoch 11: loss -2.84225 acc 0.66225 roc_auc 0.46157 prc_auc 0.65186[0m
[93maverage test of epoch 11: loss -2.95577 acc 0.67568 roc_auc 0.87167 prc_auc 0.93097[0m
[92maverage training of epoch 12: loss -2.97957 acc 0.66225 roc_auc 0.46392 prc_auc 0.65830[0m
[93maverage test of epoch 12: loss -3.09285 acc 0.67568 roc_auc 0.87000 prc_auc 0.93112[0m
[92maverage training of epoch 13: loss -3.11370 acc 0.66225 roc_auc 0.46490 prc_auc 0.65836[0m
[93maverage test of epoch 13: loss -3.22713 acc 0.67568 roc_auc 0.87000 prc_auc 0.93097[0m
[92maverage training of epoch 14: loss -3.24537 acc 0.66225 roc_auc 0.46392 prc_auc 0.65786[0m
[93maverage test of epoch 14: loss -3.35919 acc 0.67568 roc_auc 0.87000 prc_auc 0.93097[0m
[92maverage training of epoch 15: loss -3.37507 acc 0.66225 roc_auc 0.46275 prc_auc 0.65739[0m
[93maverage test of epoch 15: loss -3.48943 acc 0.67568 roc_auc 0.86667 prc_auc 0.92877[0m
[92maverage training of epoch 16: loss -3.50314 acc 0.66225 roc_auc 0.46196 prc_auc 0.65689[0m
[93maverage test of epoch 16: loss -3.61814 acc 0.67568 roc_auc 0.86500 prc_auc 0.92774[0m
[92maverage training of epoch 17: loss -3.62984 acc 0.66225 roc_auc 0.46039 prc_auc 0.65574[0m
[93maverage test of epoch 17: loss -3.74553 acc 0.67568 roc_auc 0.86500 prc_auc 0.92774[0m
[92maverage training of epoch 18: loss -3.75535 acc 0.66225 roc_auc 0.46020 prc_auc 0.65551[0m
[93maverage test of epoch 18: loss -3.87173 acc 0.67568 roc_auc 0.86333 prc_auc 0.92540[0m
[92maverage training of epoch 19: loss -3.87978 acc 0.66225 roc_auc 0.45765 prc_auc 0.65353[0m
[93maverage test of epoch 19: loss -3.99685 acc 0.67568 roc_auc 0.86500 prc_auc 0.92918[0m
[92maverage training of epoch 20: loss -4.00321 acc 0.66225 roc_auc 0.45608 prc_auc 0.65224[0m
[93maverage test of epoch 20: loss -4.12095 acc 0.67568 roc_auc 0.86500 prc_auc 0.92904[0m
[92maverage training of epoch 21: loss -4.12571 acc 0.66225 roc_auc 0.45255 prc_auc 0.64897[0m
[93maverage test of epoch 21: loss -4.24406 acc 0.67568 roc_auc 0.86667 prc_auc 0.92925[0m
[92maverage training of epoch 22: loss -4.24729 acc 0.66225 roc_auc 0.44882 prc_auc 0.64432[0m
[93maverage test of epoch 22: loss -4.36622 acc 0.67568 roc_auc 0.86667 prc_auc 0.92925[0m
[92maverage training of epoch 23: loss -4.36798 acc 0.66225 roc_auc 0.44627 prc_auc 0.64232[0m
[93maverage test of epoch 23: loss -4.48743 acc 0.67568 roc_auc 0.86500 prc_auc 0.92564[0m
[92maverage training of epoch 24: loss -4.48778 acc 0.66225 roc_auc 0.44294 prc_auc 0.64025[0m
[93maverage test of epoch 24: loss -4.60771 acc 0.67568 roc_auc 0.86667 prc_auc 0.92969[0m
[92maverage training of epoch 25: loss -4.60670 acc 0.66225 roc_auc 0.43922 prc_auc 0.63726[0m
[93maverage test of epoch 25: loss -4.72706 acc 0.67568 roc_auc 0.86667 prc_auc 0.93040[0m
[92maverage training of epoch 26: loss -4.72473 acc 0.66225 roc_auc 0.43520 prc_auc 0.63109[0m
[93maverage test of epoch 26: loss -4.84548 acc 0.67568 roc_auc 0.86500 prc_auc 0.92587[0m
[92maverage training of epoch 27: loss -4.84188 acc 0.66225 roc_auc 0.43206 prc_auc 0.62825[0m
[93maverage test of epoch 27: loss -4.96298 acc 0.67568 roc_auc 0.86667 prc_auc 0.92951[0m
[92maverage training of epoch 28: loss -4.95816 acc 0.66225 roc_auc 0.42794 prc_auc 0.62565[0m
[93maverage test of epoch 28: loss -5.07958 acc 0.67568 roc_auc 0.86833 prc_auc 0.92779[0m
[92maverage training of epoch 29: loss -5.07358 acc 0.66225 roc_auc 0.42382 prc_auc 0.62123[0m
[93maverage test of epoch 29: loss -5.19530 acc 0.67568 roc_auc 0.86833 prc_auc 0.92691[0m
[92maverage training of epoch 30: loss -5.18816 acc 0.66225 roc_auc 0.42206 prc_auc 0.61847[0m
[93maverage test of epoch 30: loss -5.31014 acc 0.67568 roc_auc 0.86500 prc_auc 0.92676[0m
[92maverage training of epoch 31: loss -5.30190 acc 0.66225 roc_auc 0.41971 prc_auc 0.61675[0m
[93maverage test of epoch 31: loss -5.42414 acc 0.67568 roc_auc 0.86833 prc_auc 0.93071[0m
[92maverage training of epoch 32: loss -5.41485 acc 0.66225 roc_auc 0.41725 prc_auc 0.61481[0m
[93maverage test of epoch 32: loss -5.53733 acc 0.67568 roc_auc 0.86833 prc_auc 0.92691[0m
[92maverage training of epoch 33: loss -5.52701 acc 0.66225 roc_auc 0.41441 prc_auc 0.61319[0m
[93maverage test of epoch 33: loss -5.64974 acc 0.67568 roc_auc 0.86667 prc_auc 0.92659[0m
[92maverage training of epoch 34: loss -5.63844 acc 0.66225 roc_auc 0.41225 prc_auc 0.61061[0m
[93maverage test of epoch 34: loss -5.76140 acc 0.67568 roc_auc 0.86833 prc_auc 0.92834[0m
[92maverage training of epoch 35: loss -5.74915 acc 0.66225 roc_auc 0.41088 prc_auc 0.60868[0m
[93maverage test of epoch 35: loss -5.87234 acc 0.67568 roc_auc 0.86833 prc_auc 0.93118[0m
[92maverage training of epoch 36: loss -5.85917 acc 0.66225 roc_auc 0.40833 prc_auc 0.60611[0m
[93maverage test of epoch 36: loss -5.98260 acc 0.67568 roc_auc 0.86833 prc_auc 0.92834[0m
[92maverage training of epoch 37: loss -5.96855 acc 0.66225 roc_auc 0.40647 prc_auc 0.60521[0m
[93maverage test of epoch 37: loss -6.09221 acc 0.67568 roc_auc 0.86667 prc_auc 0.92487[0m
[92maverage training of epoch 38: loss -6.07732 acc 0.66225 roc_auc 0.40471 prc_auc 0.60404[0m
[93maverage test of epoch 38: loss -6.20121 acc 0.67568 roc_auc 0.86333 prc_auc 0.92317[0m
[92maverage training of epoch 39: loss -6.18550 acc 0.66225 roc_auc 0.40304 prc_auc 0.60317[0mUsing backend: pytorch
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))

[93maverage test of epoch 39: loss -6.30964 acc 0.67568 roc_auc 0.87333 prc_auc 0.92316[0m
[92maverage training of epoch 40: loss -6.29314 acc 0.66225 roc_auc 0.40157 prc_auc 0.60250[0m
[93maverage test of epoch 40: loss -6.41753 acc 0.67568 roc_auc 0.86500 prc_auc 0.92113[0m
[92maverage training of epoch 41: loss -6.40026 acc 0.66225 roc_auc 0.40127 prc_auc 0.60212[0m
[93maverage test of epoch 41: loss -6.52491 acc 0.67568 roc_auc 0.86167 prc_auc 0.92814[0m
[92maverage training of epoch 42: loss -6.50690 acc 0.66225 roc_auc 0.40108 prc_auc 0.60207[0m
[93maverage test of epoch 42: loss -6.63181 acc 0.67568 roc_auc 0.86833 prc_auc 0.92874[0m
[92maverage training of epoch 43: loss -6.61308 acc 0.66225 roc_auc 0.40029 prc_auc 0.60084[0m
[93maverage test of epoch 43: loss -6.73826 acc 0.67568 roc_auc 0.87333 prc_auc 0.92319[0m
[92maverage training of epoch 44: loss -6.71883 acc 0.66225 roc_auc 0.39912 prc_auc 0.59999[0m
[93maverage test of epoch 44: loss -6.84428 acc 0.67568 roc_auc 0.85667 prc_auc 0.91459[0m
[92maverage training of epoch 45: loss -6.82418 acc 0.66225 roc_auc 0.39843 prc_auc 0.59967[0m
[93maverage test of epoch 45: loss -6.94992 acc 0.67568 roc_auc 0.88333 prc_auc 0.93208[0m
[92maverage training of epoch 46: loss -6.92916 acc 0.66225 roc_auc 0.39882 prc_auc 0.60038[0m
[93maverage test of epoch 46: loss -7.05518 acc 0.67568 roc_auc 0.88333 prc_auc 0.92072[0m
[92maverage training of epoch 47: loss -7.03378 acc 0.66225 roc_auc 0.39814 prc_auc 0.59995[0m
[93maverage test of epoch 47: loss -7.16010 acc 0.67568 roc_auc 0.87833 prc_auc 0.91988[0m
[92maverage training of epoch 48: loss -7.13808 acc 0.66225 roc_auc 0.39745 prc_auc 0.59920[0m
[93maverage test of epoch 48: loss -7.26470 acc 0.67568 roc_auc 0.85000 prc_auc 0.90123[0m
[92maverage training of epoch 49: loss -7.24207 acc 0.66225 roc_auc 0.39667 prc_auc 0.59833[0m
[93maverage test of epoch 49: loss -7.36900 acc 0.67568 roc_auc 0.86500 prc_auc 0.89299[0m
[92maverage training of epoch 50: loss -7.34577 acc 0.66225 roc_auc 0.39578 prc_auc 0.59805[0m
[93maverage test of epoch 50: loss -7.47301 acc 0.67568 roc_auc 0.88000 prc_auc 0.91108[0m
[92maverage training of epoch 51: loss -7.44920 acc 0.66225 roc_auc 0.39490 prc_auc 0.59758[0m
[93maverage test of epoch 51: loss -7.57676 acc 0.67568 roc_auc 0.84833 prc_auc 0.88133[0m
[92maverage training of epoch 52: loss -7.55237 acc 0.66225 roc_auc 0.39412 prc_auc 0.59689[0m
[93maverage test of epoch 52: loss -7.68027 acc 0.67568 roc_auc 0.87000 prc_auc 0.90021[0m
[92maverage training of epoch 53: loss -7.65532 acc 0.66225 roc_auc 0.39402 prc_auc 0.59682[0m
[93maverage test of epoch 53: loss -7.78354 acc 0.67568 roc_auc 0.68000 prc_auc 0.78032[0m
[92maverage training of epoch 54: loss -7.75804 acc 0.66225 roc_auc 0.39343 prc_auc 0.59635[0m
[93maverage test of epoch 54: loss -7.88660 acc 0.67568 roc_auc 0.66000 prc_auc 0.77268[0m
[92maverage training of epoch 55: loss -7.86056 acc 0.66225 roc_auc 0.39304 prc_auc 0.59032[0m
[93maverage test of epoch 55: loss -7.98947 acc 0.67568 roc_auc 0.78000 prc_auc 0.84119[0m
[92maverage training of epoch 56: loss -7.96289 acc 0.66225 roc_auc 0.38941 prc_auc 0.58601[0m
[93maverage test of epoch 56: loss -8.09214 acc 0.67568 roc_auc 0.66000 prc_auc 0.77268[0m
[92maverage training of epoch 57: loss -8.06504 acc 0.66225 roc_auc 0.38804 prc_auc 0.58575[0m
[93maverage test of epoch 57: loss -8.19465 acc 0.67568 roc_auc 0.68000 prc_auc 0.78032[0m
[92maverage training of epoch 58: loss -8.16703 acc 0.66225 roc_auc 0.38765 prc_auc 0.58550[0m
[93maverage test of epoch 58: loss -8.29699 acc 0.67568 roc_auc 0.66000 prc_auc 0.77946[0m
[92maverage training of epoch 59: loss -8.26886 acc 0.66225 roc_auc 0.38637 prc_auc 0.58380[0m
[93maverage test of epoch 59: loss -8.39918 acc 0.67568 roc_auc 0.54000 prc_auc 0.70162[0m
[92maverage training of epoch 60: loss -8.37055 acc 0.66225 roc_auc 0.38637 prc_auc 0.58455[0m
[93maverage test of epoch 60: loss -8.50124 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 61: loss -8.47210 acc 0.66225 roc_auc 0.38569 prc_auc 0.58427[0m
[93maverage test of epoch 61: loss -8.60316 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 62: loss -8.57353 acc 0.66225 roc_auc 0.38451 prc_auc 0.58390[0m
[93maverage test of epoch 62: loss -8.70497 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 63: loss -8.67485 acc 0.66225 roc_auc 0.38402 prc_auc 0.58529[0m
[93maverage test of epoch 63: loss -8.80666 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 64: loss -8.77607 acc 0.66225 roc_auc 0.38402 prc_auc 0.58376[0m
[93maverage test of epoch 64: loss -8.90825 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 65: loss -8.87718 acc 0.66225 roc_auc 0.38343 prc_auc 0.58452[0m
[93maverage test of epoch 65: loss -9.00975 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 66: loss -8.97820 acc 0.66225 roc_auc 0.38304 prc_auc 0.58310[0m
[93maverage test of epoch 66: loss -9.11115 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 67: loss -9.07914 acc 0.66225 roc_auc 0.38343 prc_auc 0.58332[0m
[93maverage test of epoch 67: loss -9.21248 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 68: loss -9.17999 acc 0.66225 roc_auc 0.38304 prc_auc 0.58300[0m
[93maverage test of epoch 68: loss -9.31373 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 69: loss -9.28078 acc 0.66225 roc_auc 0.38353 prc_auc 0.58352[0m
[93maverage test of epoch 69: loss -9.41490 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 70: loss -9.38150 acc 0.66225 roc_auc 0.38284 prc_auc 0.58390[0m
[93maverage test of epoch 70: loss -9.51601 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 71: loss -9.48215 acc 0.66225 roc_auc 0.38216 prc_auc 0.58228[0m
[93maverage test of epoch 71: loss -9.61707 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 72: loss -9.58275 acc 0.66225 roc_auc 0.38255 prc_auc 0.58328[0m
[93maverage test of epoch 72: loss -9.71806 acc 0.67568 roc_auc 0.54000 prc_auc 0.70162[0m
[92maverage training of epoch 73: loss -9.68329 acc 0.66225 roc_auc 0.38235 prc_auc 0.58302[0m
[93maverage test of epoch 73: loss -9.81901 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 74: loss -9.78378 acc 0.66225 roc_auc 0.38265 prc_auc 0.58378[0m
[93maverage test of epoch 74: loss -9.91990 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 75: loss -9.88423 acc 0.66225 roc_auc 0.38216 prc_auc 0.58327[0m
[93maverage test of epoch 75: loss -10.02075 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 76: loss -9.98463 acc 0.66225 roc_auc 0.38265 prc_auc 0.58385[0m
[93maverage test of epoch 76: loss -10.12156 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 77: loss -10.08499 acc 0.66225 roc_auc 0.38245 prc_auc 0.58234[0m
[93maverage test of epoch 77: loss -10.22233 acc 0.67568 roc_auc 0.70000 prc_auc 0.79751[0m
[92maverage training of epoch 78: loss -10.18532 acc 0.66225 roc_auc 0.38255 prc_auc 0.58377[0m
[93maverage test of epoch 78: loss -10.32306 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 79: loss -10.28561 acc 0.66225 roc_auc 0.38275 prc_auc 0.58339[0m
[93maverage test of epoch 79: loss -10.42377 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 80: loss -10.38588 acc 0.66225 roc_auc 0.38245 prc_auc 0.58312[0m
[93maverage test of epoch 80: loss -10.52444 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 81: loss -10.48611 acc 0.66225 roc_auc 0.38216 prc_auc 0.58193[0m
[93maverage test of epoch 81: loss -10.62508 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 82: loss -10.58631 acc 0.66225 roc_auc 0.38196 prc_auc 0.58208[0m
[93maverage test of epoch 82: loss -10.72570 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 83: loss -10.68649 acc 0.66225 roc_auc 0.38137 prc_auc 0.58204[0m
[93maverage test of epoch 83: loss -10.82629 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 84: loss -10.78665 acc 0.66225 roc_auc 0.38206 prc_auc 0.57621[0m
[93maverage test of epoch 84: loss -10.92686 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 85: loss -10.88679 acc 0.66225 roc_auc 0.38147 prc_auc 0.57484[0m
[93maverage test of epoch 85: loss -11.02741 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 86: loss -10.98690 acc 0.66225 roc_auc 0.38118 prc_auc 0.57430[0m
[93maverage test of epoch 86: loss -11.12795 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 87: loss -11.08700 acc 0.66225 roc_auc 0.38078 prc_auc 0.57405[0m
[93maverage test of epoch 87: loss -11.22846 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 88: loss -11.18708 acc 0.66225 roc_auc 0.38039 prc_auc 0.57541[0m
[93maverage test of epoch 88: loss -11.32896 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 89: loss -11.28715 acc 0.66225 roc_auc 0.37941 prc_auc 0.57229[0m
[93maverage test of epoch 89: loss -11.42944 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 90: loss -11.38720 acc 0.66225 roc_auc 0.37980 prc_auc 0.57280[0m
[93maverage test of epoch 90: loss -11.52991 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 91: loss -11.48723 acc 0.66225 roc_auc 0.37863 prc_auc 0.57132[0m
[93maverage test of epoch 91: loss -11.63037 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 92: loss -11.58726 acc 0.66225 roc_auc 0.37882 prc_auc 0.57387[0m
[93maverage test of epoch 92: loss -11.73081 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 93: loss -11.68727 acc 0.66225 roc_auc 0.37804 prc_auc 0.57202[0m
[93maverage test of epoch 93: loss -11.83124 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 94: loss -11.78728 acc 0.66225 roc_auc 0.37833 prc_auc 0.57193[0m
[93maverage test of epoch 94: loss -11.93167 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 95: loss -11.88727 acc 0.66225 roc_auc 0.37804 prc_auc 0.57319[0m
[93maverage test of epoch 95: loss -12.03208 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 96: loss -11.98725 acc 0.66225 roc_auc 0.37745 prc_auc 0.57248[0m
[93maverage test of epoch 96: loss -12.13248 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 97: loss -12.08723 acc 0.66225 roc_auc 0.37706 prc_auc 0.57232[0m
[93maverage test of epoch 97: loss -12.23288 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 98: loss -12.18720 acc 0.66225 roc_auc 0.37706 prc_auc 0.57212[0m
[93maverage test of epoch 98: loss -12.33327 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 99: loss -12.28716 acc 0.66225 roc_auc 0.37686 prc_auc 0.57235[0m
[93maverage test of epoch 99: loss -12.43365 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.62024 acc 0.33775 roc_auc 0.36686 prc_auc 0.57833[0m
[93maverage test of epoch 0: loss -0.73949 acc 0.32432 roc_auc 0.67000 prc_auc 0.87304[0m
[92maverage training of epoch 1: loss -0.84325 acc 0.33775 roc_auc 0.37980 prc_auc 0.58578[0m
[93maverage test of epoch 1: loss -0.96469 acc 0.32432 roc_auc 0.64333 prc_auc 0.86150[0m
[92maverage training of epoch 2: loss -1.07282 acc 0.47020 roc_auc 0.39667 prc_auc 0.59772[0m
[93maverage test of epoch 2: loss -1.19988 acc 0.67568 roc_auc 0.62000 prc_auc 0.84230[0m
[92maverage training of epoch 3: loss -1.31834 acc 0.65563 roc_auc 0.42078 prc_auc 0.63161[0m
[93maverage test of epoch 3: loss -1.45944 acc 0.67568 roc_auc 0.68667 prc_auc 0.87984[0m
[92maverage training of epoch 4: loss -1.60053 acc 0.66225 roc_auc 0.44882 prc_auc 0.65035[0m
[93maverage test of epoch 4: loss -1.77490 acc 0.67568 roc_auc 0.84667 prc_auc 0.93857[0m
[92maverage training of epoch 5: loss -1.95377 acc 0.66225 roc_auc 0.46961 prc_auc 0.66707[0m
[93maverage test of epoch 5: loss -2.17853 acc 0.67568 roc_auc 0.93333 prc_auc 0.97438[0m
[92maverage training of epoch 6: loss -2.37614 acc 0.66225 roc_auc 0.48294 prc_auc 0.67591[0m
[93maverage test of epoch 6: loss -2.61415 acc 0.67568 roc_auc 0.92333 prc_auc 0.96958[0m
[92maverage training of epoch 7: loss -2.77851 acc 0.66225 roc_auc 0.49137 prc_auc 0.68571[0m
[93maverage test of epoch 7: loss -2.98158 acc 0.67568 roc_auc 0.92333 prc_auc 0.96958[0m
[92maverage training of epoch 8: loss -3.10174 acc 0.66225 roc_auc 0.49314 prc_auc 0.69203[0m
[93maverage test of epoch 8: loss -3.26955 acc 0.67568 roc_auc 0.94000 prc_auc 0.97574[0m
[92maverage training of epoch 9: loss -3.35793 acc 0.66225 roc_auc 0.49412 prc_auc 0.69334[0m
[93maverage test of epoch 9: loss -3.50306 acc 0.67568 roc_auc 0.94333 prc_auc 0.97669[0m
[92maverage training of epoch 10: loss -3.57078 acc 0.66225 roc_auc 0.49863 prc_auc 0.69712[0m
[93maverage test of epoch 10: loss -3.70220 acc 0.67568 roc_auc 0.94667 prc_auc 0.97770[0m
[92maverage training of epoch 11: loss -3.75621 acc 0.66225 roc_auc 0.50039 prc_auc 0.70238[0m
[93maverage test of epoch 11: loss -3.87917 acc 0.67568 roc_auc 0.94667 prc_auc 0.97770[0m
[92maverage training of epoch 12: loss -3.92370 acc 0.66225 roc_auc 0.49706 prc_auc 0.69849[0m
[93maverage test of epoch 12: loss -4.04143 acc 0.67568 roc_auc 0.94667 prc_auc 0.97770[0m
[92maverage training of epoch 13: loss -4.07936 acc 0.66225 roc_auc 0.49196 prc_auc 0.69171[0m
[93maverage test of epoch 13: loss -4.19421 acc 0.67568 roc_auc 0.94667 prc_auc 0.97770[0m
[92maverage training of epoch 14: loss -4.22805 acc 0.66225 roc_auc 0.48902 prc_auc 0.68902[0m
[93maverage test of epoch 14: loss -4.34248 acc 0.67568 roc_auc 0.94667 prc_auc 0.97787[0m
[92maverage training of epoch 15: loss -4.37533 acc 0.66225 roc_auc 0.48137 prc_auc 0.68458[0m
[93maverage test of epoch 15: loss -4.49294 acc 0.67568 roc_auc 0.95333 prc_auc 0.97995[0m
[92maverage training of epoch 16: loss -4.52884 acc 0.66225 roc_auc 0.48010 prc_auc 0.68442[0m
[93maverage test of epoch 16: loss -4.65403 acc 0.67568 roc_auc 0.95333 prc_auc 0.97995[0m
[92maverage training of epoch 17: loss -4.69422 acc 0.66225 roc_auc 0.49069 prc_auc 0.69373[0m
[93maverage test of epoch 17: loss -4.82634 acc 0.67568 roc_auc 0.95000 prc_auc 0.97888[0m
[92maverage training of epoch 18: loss -4.86377 acc 0.66225 roc_auc 0.51078 prc_auc 0.70963[0m
[93maverage test of epoch 18: loss -4.99487 acc 0.67568 roc_auc 0.93667 prc_auc 0.97464[0m
[92maverage training of epoch 19: loss -5.02443 acc 0.66225 roc_auc 0.51922 prc_auc 0.71616[0m
[93maverage test of epoch 19: loss -5.15135 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 20: loss -5.17416 acc 0.66225 roc_auc 0.51510 prc_auc 0.71305[0m
[93maverage test of epoch 20: loss -5.29800 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 21: loss -5.31583 acc 0.66225 roc_auc 0.50382 prc_auc 0.70106[0m
[93maverage test of epoch 21: loss -5.43773 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 22: loss -5.45167 acc 0.66225 roc_auc 0.49039 prc_auc 0.68951[0m
[93maverage test of epoch 22: loss -5.57229 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 23: loss -5.58304 acc 0.66225 roc_auc 0.47824 prc_auc 0.67792[0m
[93maverage test of epoch 23: loss -5.70278 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 24: loss -5.71079 acc 0.66225 roc_auc 0.46922 prc_auc 0.67088[0m
[93maverage test of epoch 24: loss -5.82992 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 25: loss -5.83551 acc 0.66225 roc_auc 0.46324 prc_auc 0.66561[0m
[93maverage test of epoch 25: loss -5.95421 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 26: loss -5.95764 acc 0.66225 roc_auc 0.45667 prc_auc 0.65927[0m
[93maverage test of epoch 26: loss -6.07606 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 27: loss -6.07753 acc 0.66225 roc_auc 0.44578 prc_auc 0.65031[0m
[93maverage test of epoch 27: loss -6.19578 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 28: loss -6.19547 acc 0.66225 roc_auc 0.43814 prc_auc 0.64462[0m
[93maverage test of epoch 28: loss -6.31363 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 29: loss -6.31168 acc 0.66225 roc_auc 0.43069 prc_auc 0.63950[0m
[93maverage test of epoch 29: loss -6.42983 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 30: loss -6.42636 acc 0.66225 roc_auc 0.42490 prc_auc 0.63582[0m
[93maverage test of epoch 30: loss -6.54456 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 31: loss -6.53969 acc 0.66225 roc_auc 0.42000 prc_auc 0.63271[0m
[93maverage test of epoch 31: loss -6.65798 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 32: loss -6.65179 acc 0.66225 roc_auc 0.41333 prc_auc 0.62699[0m
[93maverage test of epoch 32: loss -6.77023 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 33: loss -6.76281 acc 0.66225 roc_auc 0.41059 prc_auc 0.62618[0m
[93maverage test of epoch 33: loss -6.88142 acc 0.67568 roc_auc 0.93000 prc_auc 0.97294[0m
[92maverage training of epoch 34: loss -6.87285 acc 0.66225 roc_auc 0.40637 prc_auc 0.62408[0m
[93maverage test of epoch 34: loss -6.99166 acc 0.67568 roc_auc 0.92833 prc_auc 0.97135[0m
[92maverage training of epoch 35: loss -6.98200 acc 0.66225 roc_auc 0.40216 prc_auc 0.62036[0m
[93maverage test of epoch 35: loss -7.10105 acc 0.67568 roc_auc 0.92500 prc_auc 0.96853[0m
[92maverage training of epoch 36: loss -7.09035 acc 0.66225 roc_auc 0.39931 prc_auc 0.61873[0m
[93maverage test of epoch 36: loss -7.20966 acc 0.67568 roc_auc 0.92833 prc_auc 0.97135[0m
[92maverage training of epoch 37: loss -7.19798 acc 0.66225 roc_auc 0.39706 prc_auc 0.61737[0m
[93maverage test of epoch 37: loss -7.31757 acc 0.67568 roc_auc 0.92500 prc_auc 0.96853[0m
[92maverage training of epoch 38: loss -7.30496 acc 0.66225 roc_auc 0.39667 prc_auc 0.61679[0m
[93maverage test of epoch 38: loss -7.42484 acc 0.67568 roc_auc 0.92500 prc_auc 0.96853[0m
[92maverage training of epoch 39: loss -7.41134 acc 0.66225 roc_auc 0.39569 prc_auc 0.61684[0m
[93maverage test of epoch 39: loss -7.53153 acc 0.67568 roc_auc 0.92500 prc_auc 0.96853[0m
[92maverage training of epoch 40: loss -7.51718 acc 0.66225 roc_auc 0.39294 prc_auc 0.61252[0m
[93maverage test of epoch 40: loss -7.63769 acc 0.67568 roc_auc 0.92500 prc_auc 0.96822[0m
[92maverage training of epoch 41: loss -7.62252 acc 0.66225 roc_auc 0.39108 prc_auc 0.61008[0m
[93maverage test of epoch 41: loss -7.74337 acc 0.67568 roc_auc 0.93667 prc_auc 0.97294[0m
[92maverage training of epoch 42: loss -7.72742 acc 0.66225 roc_auc 0.38892 prc_auc 0.60667[0m
[93maverage test of epoch 42: loss -7.84861 acc 0.67568 roc_auc 0.92667 prc_auc 0.96853[0m
[92maverage training of epoch 43: loss -7.83190 acc 0.66225 roc_auc 0.38814 prc_auc 0.60411[0m
[93maverage test of epoch 43: loss -7.95345 acc 0.67568 roc_auc 0.93333 prc_auc 0.97135[0m
[92maverage training of epoch 44: loss -7.93601 acc 0.66225 roc_auc 0.38784 prc_auc 0.60378[0m
[93maverage test of epoch 44: loss -8.05792 acc 0.67568 roc_auc 0.93000 prc_auc 0.96958[0m
[92maverage training of epoch 45: loss -8.03978 acc 0.66225 roc_auc 0.38412 prc_auc 0.59480[0m
[93maverage test of epoch 45: loss -8.16205 acc 0.67568 roc_auc 0.93333 prc_auc 0.96875[0m
[92maverage training of epoch 46: loss -8.14323 acc 0.66225 roc_auc 0.38255 prc_auc 0.59277[0m
[93maverage test of epoch 46: loss -8.26588 acc 0.67568 roc_auc 0.93333 prc_auc 0.96875[0m
[92maverage training of epoch 47: loss -8.24640 acc 0.66225 roc_auc 0.38157 prc_auc 0.59120[0m
[93maverage test of epoch 47: loss -8.36943 acc 0.67568 roc_auc 0.92667 prc_auc 0.96512[0m
[92maverage training of epoch 48: loss -8.34930 acc 0.66225 roc_auc 0.38127 prc_auc 0.59139[0m
[93maverage test of epoch 48: loss -8.47271 acc 0.67568 roc_auc 0.94333 prc_auc 0.96875[0m
[92maverage training of epoch 49: loss -8.45196 acc 0.66225 roc_auc 0.38049 prc_auc 0.59115[0m
[93maverage test of epoch 49: loss -8.57576 acc 0.67568 roc_auc 0.92500 prc_auc 0.96330[0m
[92maverage training of epoch 50: loss -8.55440 acc 0.66225 roc_auc 0.37990 prc_auc 0.59013[0m
[93maverage test of epoch 50: loss -8.67859 acc 0.67568 roc_auc 0.93333 prc_auc 0.96875[0m
[92maverage training of epoch 51: loss -8.65664 acc 0.66225 roc_auc 0.37980 prc_auc 0.59106[0m
[93maverage test of epoch 51: loss -8.78122 acc 0.67568 roc_auc 0.92000 prc_auc 0.95690[0m
[92maverage training of epoch 52: loss -8.75869 acc 0.66225 roc_auc 0.38020 prc_auc 0.59225[0m
[93maverage test of epoch 52: loss -8.88367 acc 0.67568 roc_auc 0.89000 prc_auc 0.92925[0m
[92maverage training of epoch 53: loss -8.86056 acc 0.66225 roc_auc 0.37951 prc_auc 0.59016[0m
[93maverage test of epoch 53: loss -8.98595 acc 0.67568 roc_auc 0.92000 prc_auc 0.94505[0m
[92maverage training of epoch 54: loss -8.96228 acc 0.66225 roc_auc 0.37941 prc_auc 0.59099[0m
[93maverage test of epoch 54: loss -9.08807 acc 0.67568 roc_auc 0.94000 prc_auc 0.96632[0m
[92maverage training of epoch 55: loss -9.06386 acc 0.66225 roc_auc 0.37931 prc_auc 0.59023[0m
[93maverage test of epoch 55: loss -9.19005 acc 0.67568 roc_auc 0.82667 prc_auc 0.86209[0m
[92maverage training of epoch 56: loss -9.16530 acc 0.66225 roc_auc 0.37922 prc_auc 0.59032[0m
[93maverage test of epoch 56: loss -9.29190 acc 0.67568 roc_auc 0.80667 prc_auc 0.84431[0m
[92maverage training of epoch 57: loss -9.26662 acc 0.66225 roc_auc 0.37902 prc_auc 0.59017[0m
[93maverage test of epoch 57: loss -9.39363 acc 0.67568 roc_auc 0.85333 prc_auc 0.91212[0m
[92maverage training of epoch 58: loss -9.36783 acc 0.66225 roc_auc 0.37892 prc_auc 0.59009[0m
[93maverage test of epoch 58: loss -9.49524 acc 0.67568 roc_auc 0.79333 prc_auc 0.83776[0m
[92maverage training of epoch 59: loss -9.46893 acc 0.66225 roc_auc 0.37902 prc_auc 0.59065[0m
[93maverage test of epoch 59: loss -9.59676 acc 0.67568 roc_auc 0.75167 prc_auc 0.80977[0m
[92maverage training of epoch 60: loss -9.56994 acc 0.66225 roc_auc 0.37902 prc_auc 0.59071[0m
[93maverage test of epoch 60: loss -9.69818 acc 0.67568 roc_auc 0.88000 prc_auc 0.92216[0m
[92maverage training of epoch 61: loss -9.67086 acc 0.66225 roc_auc 0.37912 prc_auc 0.59048[0m
[93maverage test of epoch 61: loss -9.79951 acc 0.67568 roc_auc 0.75167 prc_auc 0.80977[0m
[92maverage training of epoch 62: loss -9.77170 acc 0.66225 roc_auc 0.37922 prc_auc 0.59156[0m
[93maverage test of epoch 62: loss -9.90077 acc 0.67568 roc_auc 0.54167 prc_auc 0.69444[0m
[92maverage training of epoch 63: loss -9.87246 acc 0.66225 roc_auc 0.37941 prc_auc 0.59129[0m
[93maverage test of epoch 63: loss -10.00195 acc 0.67568 roc_auc 0.66667 prc_auc 0.75758[0m
[92maverage training of epoch 64: loss -9.97316 acc 0.66225 roc_auc 0.37882 prc_auc 0.59118[0m
[93maverage test of epoch 64: loss -10.10306 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 65: loss -10.07379 acc 0.66225 roc_auc 0.37843 prc_auc 0.59089[0m
[93maverage test of epoch 65: loss -10.20411 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 66: loss -10.17436 acc 0.66225 roc_auc 0.37824 prc_auc 0.59088[0m
[93maverage test of epoch 66: loss -10.30510 acc 0.67568 roc_auc 0.64667 prc_auc 0.74703[0m
[92maverage training of epoch 67: loss -10.27488 acc 0.66225 roc_auc 0.37824 prc_auc 0.59048[0m
[93maverage test of epoch 67: loss -10.40604 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 68: loss -10.37535 acc 0.66225 roc_auc 0.37775 prc_auc 0.58973[0m
[93maverage test of epoch 68: loss -10.50692 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 69: loss -10.47578 acc 0.66225 roc_auc 0.37725 prc_auc 0.58998[0m
[93maverage test of epoch 69: loss -10.60777 acc 0.67568 roc_auc 0.75167 prc_auc 0.80977[0m
[92maverage training of epoch 70: loss -10.57616 acc 0.66225 roc_auc 0.37755 prc_auc 0.58991[0m
[93maverage test of epoch 70: loss -10.70857 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 71: loss -10.67650 acc 0.66225 roc_auc 0.37745 prc_auc 0.58991[0m
[93maverage test of epoch 71: loss -10.80934 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 72: loss -10.77681 acc 0.66225 roc_auc 0.37706 prc_auc 0.58377[0m
[93maverage test of epoch 72: loss -10.91006 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 73: loss -10.87708 acc 0.66225 roc_auc 0.37618 prc_auc 0.58312[0m
[93maverage test of epoch 73: loss -11.01076 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 74: loss -10.97733 acc 0.66225 roc_auc 0.37647 prc_auc 0.58271[0m
[93maverage test of epoch 74: loss -11.11142 acc 0.67568 roc_auc 0.62000 prc_auc 0.75351[0m
[92maverage training of epoch 75: loss -11.07754 acc 0.66225 roc_auc 0.37618 prc_auc 0.58178[0m
[93maverage test of epoch 75: loss -11.21206 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 76: loss -11.17773 acc 0.66225 roc_auc 0.37569 prc_auc 0.57778[0m
[93maverage test of epoch 76: loss -11.31267 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 77: loss -11.27790 acc 0.66225 roc_auc 0.37569 prc_auc 0.57525[0m
[93maverage test of epoch 77: loss -11.41326 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 78: loss -11.37804 acc 0.66225 roc_auc 0.37451 prc_auc 0.57370[0m
[93maverage test of epoch 78: loss -11.51383 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 79: loss -11.47817 acc 0.66225 roc_auc 0.37441 prc_auc 0.57193[0m
[93maverage test of epoch 79: loss -11.61438 acc 0.67568 roc_auc 0.79333 prc_auc 0.83776[0m
[92maverage training of epoch 80: loss -11.57827 acc 0.66225 roc_auc 0.37412 prc_auc 0.57152[0m
[93maverage test of epoch 80: loss -11.71490 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 81: loss -11.67836 acc 0.66225 roc_auc 0.37353 prc_auc 0.57268[0m
[93maverage test of epoch 81: loss -11.81542 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 82: loss -11.77843 acc 0.66225 roc_auc 0.37324 prc_auc 0.57235[0m
[93maverage test of epoch 82: loss -11.91591 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 83: loss -11.87849 acc 0.66225 roc_auc 0.37324 prc_auc 0.57187[0m
[93maverage test of epoch 83: loss -12.01639 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 84: loss -11.97853 acc 0.66225 roc_auc 0.37304 prc_auc 0.57159[0m
[93maverage test of epoch 84: loss -12.11686 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 85: loss -12.07856 acc 0.66225 roc_auc 0.37245 prc_auc 0.57132[0m
[93maverage test of epoch 85: loss -12.21731 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 86: loss -12.17858 acc 0.66225 roc_auc 0.37265 prc_auc 0.57209[0m
[93maverage test of epoch 86: loss -12.31775 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 87: loss -12.27859 acc 0.66225 roc_auc 0.37265 prc_auc 0.57216[0m
[93maverage test of epoch 87: loss -12.41818 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 88: loss -12.37859 acc 0.66225 roc_auc 0.37235 prc_auc 0.57119[0m
[93maverage test of epoch 88: loss -12.51860 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 89: loss -12.47857 acc 0.66225 roc_auc 0.37176 prc_auc 0.57065[0m
[93maverage test of epoch 89: loss -12.61902 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 90: loss -12.57855 acc 0.66225 roc_auc 0.37216 prc_auc 0.57126[0m
[93maverage test of epoch 90: loss -12.71942 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 91: loss -12.67852 acc 0.66225 roc_auc 0.37147 prc_auc 0.57046[0m
[93maverage test of epoch 91: loss -12.81982 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 92: loss -12.77849 acc 0.66225 roc_auc 0.37088 prc_auc 0.57006[0m
[93maverage test of epoch 92: loss -12.92021 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 93: loss -12.87845 acc 0.66225 roc_auc 0.37069 prc_auc 0.57185[0m
[93maverage test of epoch 93: loss -13.02059 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 94: loss -12.97840 acc 0.66225 roc_auc 0.36990 prc_auc 0.56979[0m
[93maverage test of epoch 94: loss -13.12097 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 95: loss -13.07835 acc 0.66225 roc_auc 0.37029 prc_auc 0.57034[0m
[93maverage test of epoch 95: loss -13.22134 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 96: loss -13.17829 acc 0.66225 roc_auc 0.37029 prc_auc 0.56944[0m
[93maverage test of epoch 96: loss -13.32171 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 97: loss -13.27823 acc 0.66225 roc_auc 0.37020 prc_auc 0.57010[0m
[93maverage test of epoch 97: loss -13.42207 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 98: loss -13.37816 acc 0.66225 roc_auc 0.36990 prc_auc 0.56892[0m
[93maverage test of epoch 98: loss -13.52243 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 99: loss -13.47809 acc 0.66225 roc_auc 0.37059 prc_auc 0.57062[0m
[93maverage test of epoch 99: loss -13.62278 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.0001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.69659 ROC_AUC (avg): 0.66985 PRC_AUC (avg): 0.77732 

Average forward propagation time taken(ms): 2.4884826402233338
Average backward propagation time taken(ms): 0.8762910251233066

