# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 1)
('lr', 0.0003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-18-26-17/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-18-26-17/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 16,
 'epochs': 50,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 4,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.0003,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 1,
 'num_workers': 8,
 'number_of_mlp_layer': 1,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-17-18-26-17',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 50, 'learning_rate': 0.0003, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.57079 acc 0.66667 roc_auc 0.43000 prc_auc 0.64159[0m
[93maverage test of epoch 0: loss -0.91760 acc 0.65789 roc_auc 0.77538 prc_auc 0.89964[0m
[92maverage training of epoch 1: loss -1.27511 acc 0.66667 roc_auc 0.44720 prc_auc 0.66793[0m
[93maverage test of epoch 1: loss -1.58955 acc 0.65789 roc_auc 0.89231 prc_auc 0.94250[0m
[92maverage training of epoch 2: loss -1.95925 acc 0.66667 roc_auc 0.47480 prc_auc 0.68877[0m
[93maverage test of epoch 2: loss -2.32380 acc 0.65789 roc_auc 0.86154 prc_auc 0.93235[0m
[92maverage training of epoch 3: loss -2.72191 acc 0.66667 roc_auc 0.47640 prc_auc 0.67853[0m
[93maverage test of epoch 3: loss -3.04916 acc 0.65789 roc_auc 0.85846 prc_auc 0.93142[0m
[92maverage training of epoch 4: loss -3.43982 acc 0.66667 roc_auc 0.44900 prc_auc 0.66137[0m
[93maverage test of epoch 4: loss -3.88895 acc 0.65789 roc_auc 0.85846 prc_auc 0.93153[0m
[92maverage training of epoch 5: loss -4.47068 acc 0.66667 roc_auc 0.43760 prc_auc 0.65186[0m
[93maverage test of epoch 5: loss -4.96344 acc 0.65789 roc_auc 0.85846 prc_auc 0.93142[0m
[92maverage training of epoch 6: loss -5.49702 acc 0.66667 roc_auc 0.43120 prc_auc 0.64414[0m
[93maverage test of epoch 6: loss -5.93834 acc 0.65789 roc_auc 0.85692 prc_auc 0.93097[0m
[92maverage training of epoch 7: loss -6.44179 acc 0.66667 roc_auc 0.42820 prc_auc 0.63913[0m
[93maverage test of epoch 7: loss -6.85544 acc 0.65789 roc_auc 0.86000 prc_auc 0.93165[0m
[92maverage training of epoch 8: loss -7.35028 acc 0.66667 roc_auc 0.42740 prc_auc 0.63879[0m
[93maverage test of epoch 8: loss -7.75377 acc 0.65789 roc_auc 0.86462 prc_auc 0.93299[0m
[92maverage training of epoch 9: loss -8.25072 acc 0.66667 roc_auc 0.42660 prc_auc 0.63800[0m
[93maverage test of epoch 9: loss -8.65303 acc 0.65789 roc_auc 0.86462 prc_auc 0.89714[0m
[92maverage training of epoch 10: loss -9.15801 acc 0.66667 roc_auc 0.42570 prc_auc 0.63678[0m
[93maverage test of epoch 10: loss -9.56404 acc 0.65789 roc_auc 0.85231 prc_auc 0.88546[0m
[92maverage training of epoch 11: loss -10.08055 acc 0.66667 roc_auc 0.42330 prc_auc 0.63494[0m
[93maverage test of epoch 11: loss -10.49314 acc 0.65789 roc_auc 0.76769 prc_auc 0.81510[0m
[92maverage training of epoch 12: loss -11.02307 acc 0.66667 roc_auc 0.42240 prc_auc 0.63459[0m
[93maverage test of epoch 12: loss -11.44281 acc 0.65789 roc_auc 0.61538 prc_auc 0.71429[0m
[92maverage training of epoch 13: loss -11.98486 acc 0.66667 roc_auc 0.42190 prc_auc 0.63434[0m
[93maverage test of epoch 13: loss -12.41100 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 14: loss -12.96653 acc 0.66667 roc_auc 0.42140 prc_auc 0.63403[0m
[93maverage test of epoch 14: loss -13.40050 acc 0.65789 roc_auc 0.72154 prc_auc 0.79865[0m
[92maverage training of epoch 15: loss -13.97074 acc 0.66667 roc_auc 0.42040 prc_auc 0.62787[0m
[93maverage test of epoch 15: loss -14.41316 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 16: loss -14.99823 acc 0.66667 roc_auc 0.41990 prc_auc 0.62754[0m
[93maverage test of epoch 16: loss -15.44896 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 17: loss -16.04963 acc 0.66667 roc_auc 0.42040 prc_auc 0.62457[0m
[93maverage test of epoch 17: loss -16.50932 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 18: loss -17.12630 acc 0.66667 roc_auc 0.41790 prc_auc 0.62224[0m
[93maverage test of epoch 18: loss -17.59545 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -18.22930 acc 0.66667 roc_auc 0.41780 prc_auc 0.62136[0m
[93maverage test of epoch 19: loss -18.70824 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -19.35943 acc 0.66667 roc_auc 0.41770 prc_auc 0.62105[0m
[93maverage test of epoch 20: loss -19.84842 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -20.51732 acc 0.66667 roc_auc 0.41720 prc_auc 0.61952[0m
[93maverage test of epoch 21: loss -21.01654 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -21.70347 acc 0.66667 roc_auc 0.41470 prc_auc 0.61753[0m
[93maverage test of epoch 22: loss -22.21305 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -22.91827 acc 0.66667 roc_auc 0.41050 prc_auc 0.61530[0m
[93maverage test of epoch 23: loss -23.43829 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -24.16204 acc 0.66667 roc_auc 0.42070 prc_auc 0.62582[0m
[93maverage test of epoch 24: loss -24.69254 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -25.43504 acc 0.66667 roc_auc 0.41120 prc_auc 0.62221[0m
[93maverage test of epoch 25: loss -25.97605 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -26.73747 acc 0.66667 roc_auc 0.42600 prc_auc 0.63980[0m
[93maverage test of epoch 26: loss -27.28899 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -28.06950 acc 0.66667 roc_auc 0.40740 prc_auc 0.62238[0m
[93maverage test of epoch 27: loss -28.63151 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -29.43124 acc 0.66667 roc_auc 0.48220 prc_auc 0.65986[0m
[93maverage test of epoch 28: loss -30.00367 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -30.82197 acc 0.66667 roc_auc 0.42500 prc_auc 0.63772[0m
[93maverage test of epoch 29: loss -31.40332 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -32.23961 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 30: loss -32.82958 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -33.68413 acc 0.66667 roc_auc 0.40000 prc_auc 0.62886[0m
[93maverage test of epoch 31: loss -34.28285 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -35.15592 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 32: loss -35.76351 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -36.65532 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 33: loss -37.27187 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -38.18263 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -38.80819 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -39.73810 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -40.37270 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -41.32194 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -41.96561 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -42.93434 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -43.58709 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -44.57546 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -45.23727 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -46.24583 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -46.92391 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -48.06613 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -48.89693 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -50.10589 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -50.95866 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -52.18923 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -53.05265 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -54.30790 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -55.18390 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -56.46514 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -57.35459 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -58.66270 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -59.56608 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -60.90170 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -61.81925 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -63.18271 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -64.11461 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -65.50620 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -66.45241 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -67.87255 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -68.83332 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.22384 acc 0.66667 roc_auc 0.45300 prc_auc 0.63494[0m
[93maverage test of epoch 0: loss -0.34524 acc 0.65789 roc_auc 0.14769 prc_auc 0.49538[0m
[92maverage training of epoch 1: loss -0.48679 acc 0.66667 roc_auc 0.46100 prc_auc 0.63999[0m
[93maverage test of epoch 1: loss -0.62221 acc 0.65789 roc_auc 0.63692 prc_auc 0.84605[0m
[92maverage training of epoch 2: loss -0.78107 acc 0.66667 roc_auc 0.46980 prc_auc 0.65651[0m
[93maverage test of epoch 2: loss -0.96616 acc 0.65789 roc_auc 0.89846 prc_auc 0.94428[0m
[92maverage training of epoch 3: loss -1.30355 acc 0.66667 roc_auc 0.47760 prc_auc 0.66123[0m
[93maverage test of epoch 3: loss -1.64888 acc 0.65789 roc_auc 0.90154 prc_auc 0.94336[0m
[92maverage training of epoch 4: loss -1.89007 acc 0.66667 roc_auc 0.47220 prc_auc 0.65266[0m
[93maverage test of epoch 4: loss -2.11263 acc 0.65789 roc_auc 0.90154 prc_auc 0.94607[0m
[92maverage training of epoch 5: loss -2.33086 acc 0.66667 roc_auc 0.46800 prc_auc 0.64900[0m
[93maverage test of epoch 5: loss -2.53944 acc 0.65789 roc_auc 0.89692 prc_auc 0.94035[0m
[92maverage training of epoch 6: loss -2.75541 acc 0.66667 roc_auc 0.46440 prc_auc 0.64627[0m
[93maverage test of epoch 6: loss -2.96213 acc 0.65789 roc_auc 0.89077 prc_auc 0.93598[0m
[92maverage training of epoch 7: loss -3.18059 acc 0.66667 roc_auc 0.46140 prc_auc 0.64388[0m
[93maverage test of epoch 7: loss -3.38880 acc 0.65789 roc_auc 0.89385 prc_auc 0.93645[0m
[92maverage training of epoch 8: loss -3.61181 acc 0.66667 roc_auc 0.46080 prc_auc 0.64329[0m
[93maverage test of epoch 8: loss -3.82319 acc 0.65789 roc_auc 0.88923 prc_auc 0.93543[0m
[92maverage training of epoch 9: loss -4.05184 acc 0.66667 roc_auc 0.45900 prc_auc 0.64199[0m
[93maverage test of epoch 9: loss -4.26665 acc 0.65789 roc_auc 0.89538 prc_auc 0.93407[0m
[92maverage training of epoch 10: loss -4.49956 acc 0.66667 roc_auc 0.45700 prc_auc 0.64015[0m
[93maverage test of epoch 10: loss -4.71661 acc 0.65789 roc_auc 0.89231 prc_auc 0.93175[0m
[92maverage training of epoch 11: loss -4.95447 acc 0.66667 roc_auc 0.45680 prc_auc 0.64001[0m
[93maverage test of epoch 11: loss -5.17484 acc 0.65789 roc_auc 0.88769 prc_auc 0.92627[0m
[92maverage training of epoch 12: loss -5.41867 acc 0.66667 roc_auc 0.45620 prc_auc 0.63974[0m
[93maverage test of epoch 12: loss -5.64323 acc 0.65789 roc_auc 0.88923 prc_auc 0.92303[0m
[92maverage training of epoch 13: loss -5.89376 acc 0.66667 roc_auc 0.45600 prc_auc 0.63851[0m
[93maverage test of epoch 13: loss -6.12310 acc 0.65789 roc_auc 0.88462 prc_auc 0.92089[0m
[92maverage training of epoch 14: loss -6.38083 acc 0.66667 roc_auc 0.45560 prc_auc 0.63832[0m
[93maverage test of epoch 14: loss -6.61536 acc 0.65789 roc_auc 0.87692 prc_auc 0.90380[0m
[92maverage training of epoch 15: loss -6.88068 acc 0.66667 roc_auc 0.45560 prc_auc 0.63832[0m
[93maverage test of epoch 15: loss -7.12068 acc 0.65789 roc_auc 0.89077 prc_auc 0.92425[0m
[92maverage training of epoch 16: loss -7.39383 acc 0.66667 roc_auc 0.45530 prc_auc 0.63720[0m
[93maverage test of epoch 16: loss -7.63925 acc 0.65789 roc_auc 0.88308 prc_auc 0.91520[0m
[92maverage training of epoch 17: loss -7.91961 acc 0.66667 roc_auc 0.45520 prc_auc 0.63732[0m
[93maverage test of epoch 17: loss -8.16969 acc 0.65789 roc_auc 0.88000 prc_auc 0.90094[0m
[92maverage training of epoch 18: loss -8.45731 acc 0.66667 roc_auc 0.45520 prc_auc 0.63732[0m
[93maverage test of epoch 18: loss -8.71223 acc 0.65789 roc_auc 0.86462 prc_auc 0.89079[0m
[92maverage training of epoch 19: loss -9.00738 acc 0.66667 roc_auc 0.45530 prc_auc 0.63732[0m
[93maverage test of epoch 19: loss -9.26733 acc 0.65789 roc_auc 0.86615 prc_auc 0.89070[0m
[92maverage training of epoch 20: loss -9.57022 acc 0.66667 roc_auc 0.45520 prc_auc 0.63746[0m
[93maverage test of epoch 20: loss -9.83534 acc 0.65789 roc_auc 0.82615 prc_auc 0.85333[0m
[92maverage training of epoch 21: loss -10.14615 acc 0.66667 roc_auc 0.45520 prc_auc 0.63746[0m
[93maverage test of epoch 21: loss -10.41654 acc 0.65789 roc_auc 0.82154 prc_auc 0.84961[0m
[92maverage training of epoch 22: loss -10.73543 acc 0.66667 roc_auc 0.45520 prc_auc 0.63748[0m
[93maverage test of epoch 22: loss -11.01118 acc 0.65789 roc_auc 0.75846 prc_auc 0.81158[0m
[92maverage training of epoch 23: loss -11.33829 acc 0.66667 roc_auc 0.45520 prc_auc 0.63746[0m
[93maverage test of epoch 23: loss -11.61944 acc 0.65789 roc_auc 0.75231 prc_auc 0.79875[0m
[92maverage training of epoch 24: loss -11.95490 acc 0.66667 roc_auc 0.45520 prc_auc 0.63746[0m
[93maverage test of epoch 24: loss -12.24151 acc 0.65789 roc_auc 0.70923 prc_auc 0.78947[0m
[92maverage training of epoch 25: loss -12.58543 acc 0.66667 roc_auc 0.45520 prc_auc 0.63746[0m
[93maverage test of epoch 25: loss -12.87752 acc 0.65789 roc_auc 0.69385 prc_auc 0.77649[0m
[92maverage training of epoch 26: loss -13.23000 acc 0.66667 roc_auc 0.45520 prc_auc 0.63746[0m
[93maverage test of epoch 26: loss -13.52759 acc 0.65789 roc_auc 0.73846 prc_auc 0.79963[0m
[92maverage training of epoch 27: loss -13.88872 acc 0.66667 roc_auc 0.45520 prc_auc 0.63746[0m
[93maverage test of epoch 27: loss -14.19183 acc 0.65789 roc_auc 0.76308 prc_auc 0.81080[0m
[92maverage training of epoch 28: loss -14.56169 acc 0.66667 roc_auc 0.45520 prc_auc 0.63746[0m
[93maverage test of epoch 28: loss -14.87032 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 29: loss -15.24900 acc 0.66667 roc_auc 0.45520 prc_auc 0.63748[0m
[93maverage test of epoch 29: loss -15.56314 acc 0.65789 roc_auc 0.65846 prc_auc 0.75368[0m
[92maverage training of epoch 30: loss -15.95071 acc 0.66667 roc_auc 0.45520 prc_auc 0.63746[0m
[93maverage test of epoch 30: loss -16.27036 acc 0.65789 roc_auc 0.47538 prc_auc 0.66158[0m
[92maverage training of epoch 31: loss -16.66689 acc 0.66667 roc_auc 0.45520 prc_auc 0.63748[0m
[93maverage test of epoch 31: loss -16.99203 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 32: loss -17.39759 acc 0.66667 roc_auc 0.45510 prc_auc 0.63728[0m
[93maverage test of epoch 32: loss -17.72822 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 33: loss -18.14287 acc 0.66667 roc_auc 0.45510 prc_auc 0.63728[0m
[93maverage test of epoch 33: loss -18.47896 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 34: loss -18.90275 acc 0.66667 roc_auc 0.45500 prc_auc 0.63710[0m
[93maverage test of epoch 34: loss -19.24429 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 35: loss -19.67729 acc 0.66667 roc_auc 0.45510 prc_auc 0.63728[0m
[93maverage test of epoch 35: loss -20.02423 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 36: loss -20.46651 acc 0.66667 roc_auc 0.45500 prc_auc 0.63708[0m
[93maverage test of epoch 36: loss -20.81884 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 37: loss -21.27043 acc 0.66667 roc_auc 0.45510 prc_auc 0.63738[0m
[93maverage test of epoch 37: loss -21.62811 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 38: loss -22.08909 acc 0.66667 roc_auc 0.45540 prc_auc 0.63745[0m
[93maverage test of epoch 38: loss -22.45212 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 39: loss -22.92250 acc 0.66667 roc_auc 0.45510 prc_auc 0.63710[0m
[93maverage test of epoch 39: loss -23.29080 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 40: loss -23.77069 acc 0.66667 roc_auc 0.45490 prc_auc 0.63696[0m
[93maverage test of epoch 40: loss -24.14429 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 41: loss -24.63370 acc 0.66667 roc_auc 0.45510 prc_auc 0.63714[0m
[93maverage test of epoch 41: loss -25.01249 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 42: loss -25.51146 acc 0.66667 roc_auc 0.45540 prc_auc 0.63720[0m
[93maverage test of epoch 42: loss -25.89546 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -26.40408 acc 0.66667 roc_auc 0.45510 prc_auc 0.63729[0m
[93maverage test of epoch 43: loss -26.79325 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 44: loss -27.31157 acc 0.66667 roc_auc 0.45550 prc_auc 0.63759[0m
[93maverage test of epoch 44: loss -27.70588 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -28.23390 acc 0.66667 roc_auc 0.45570 prc_auc 0.63780[0m
[93maverage test of epoch 45: loss -28.63324 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -29.17096 acc 0.66667 roc_auc 0.45640 prc_auc 0.63723[0m
[93maverage test of epoch 46: loss -29.57532 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -30.12288 acc 0.66667 roc_auc 0.45660 prc_auc 0.63679[0m
[93maverage test of epoch 47: loss -30.53227 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -31.08971 acc 0.66667 roc_auc 0.45700 prc_auc 0.63792[0m
[93maverage test of epoch 48: loss -31.50409 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -32.07146 acc 0.66667 roc_auc 0.45660 prc_auc 0.63597[0m
[93maverage test of epoch 49: loss -32.49079 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.27151 acc 0.33333 roc_auc 0.37920 prc_auc 0.58480[0m
[93maverage test of epoch 0: loss -0.31605 acc 0.34211 roc_auc 0.53231 prc_auc 0.77764[0m
[92maverage training of epoch 1: loss -0.33187 acc 0.33333 roc_auc 0.36980 prc_auc 0.57982[0m
[93maverage test of epoch 1: loss -0.36378 acc 0.34211 roc_auc 0.53385 prc_auc 0.78882[0m
[92maverage training of epoch 2: loss -0.38095 acc 0.33333 roc_auc 0.37300 prc_auc 0.57960[0m
[93maverage test of epoch 2: loss -0.40892 acc 0.34211 roc_auc 0.56769 prc_auc 0.81165[0m
[92maverage training of epoch 3: loss -0.42758 acc 0.33333 roc_auc 0.37360 prc_auc 0.57395[0m
[93maverage test of epoch 3: loss -0.45178 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 4: loss -0.46715 acc 0.33333 roc_auc 0.37140 prc_auc 0.57330[0m
[93maverage test of epoch 4: loss -0.48481 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 5: loss -0.50036 acc 0.33333 roc_auc 0.37700 prc_auc 0.57535[0m
[93maverage test of epoch 5: loss -0.51784 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 6: loss -0.53357 acc 0.33333 roc_auc 0.37660 prc_auc 0.57505[0m
[93maverage test of epoch 6: loss -0.55088 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 7: loss -0.56679 acc 0.33333 roc_auc 0.37640 prc_auc 0.57486[0m
[93maverage test of epoch 7: loss -0.58392 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 8: loss -0.59993 acc 0.33333 roc_auc 0.37800 prc_auc 0.57538[0m
[93maverage test of epoch 8: loss -0.61696 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 9: loss -0.63307 acc 0.33333 roc_auc 0.37740 prc_auc 0.57503[0m
[93maverage test of epoch 9: loss -0.65000 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 10: loss -0.66620 acc 0.32000 roc_auc 0.37740 prc_auc 0.57503[0m
[93maverage test of epoch 10: loss -0.68305 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 11: loss -0.69934 acc 0.66667 roc_auc 0.37720 prc_auc 0.57494[0m
[93maverage test of epoch 11: loss -0.71609 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 12: loss -0.73248 acc 0.66667 roc_auc 0.37700 prc_auc 0.57482[0m
[93maverage test of epoch 12: loss -0.74914 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 13: loss -0.76562 acc 0.66667 roc_auc 0.37690 prc_auc 0.57465[0m
[93maverage test of epoch 13: loss -0.78218 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 14: loss -0.79876 acc 0.66667 roc_auc 0.37690 prc_auc 0.57463[0m
[93maverage test of epoch 14: loss -0.81523 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 15: loss -0.83190 acc 0.66667 roc_auc 0.37690 prc_auc 0.57465[0m
[93maverage test of epoch 15: loss -0.84828 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 16: loss -0.86504 acc 0.66667 roc_auc 0.37680 prc_auc 0.57485[0m
[93maverage test of epoch 16: loss -0.88132 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 17: loss -0.89818 acc 0.66667 roc_auc 0.37680 prc_auc 0.57463[0m
[93maverage test of epoch 17: loss -0.91437 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 18: loss -0.93132 acc 0.66667 roc_auc 0.37680 prc_auc 0.57465[0m
[93maverage test of epoch 18: loss -0.94742 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -0.96447 acc 0.66667 roc_auc 0.37680 prc_auc 0.57460[0m
[93maverage test of epoch 19: loss -0.98046 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -0.99761 acc 0.66667 roc_auc 0.37670 prc_auc 0.57458[0m
[93maverage test of epoch 20: loss -1.01351 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -1.03075 acc 0.66667 roc_auc 0.37660 prc_auc 0.57442[0m
[93maverage test of epoch 21: loss -1.04656 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -1.06389 acc 0.66667 roc_auc 0.37650 prc_auc 0.57439[0m
[93maverage test of epoch 22: loss -1.07960 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -1.09703 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 23: loss -1.11265 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -1.13017 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 24: loss -1.14570 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -1.16331 acc 0.66667 roc_auc 0.37650 prc_auc 0.57439[0m
[93maverage test of epoch 25: loss -1.17874 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -1.19645 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 26: loss -1.21179 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -1.22960 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 27: loss -1.24484 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -1.26274 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 28: loss -1.27788 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -1.29588 acc 0.66667 roc_auc 0.37640 prc_auc 0.57442[0m
[93maverage test of epoch 29: loss -1.31093 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -1.32902 acc 0.66667 roc_auc 0.37650 prc_auc 0.57439[0m
[93maverage test of epoch 30: loss -1.34398 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -1.36216 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 31: loss -1.37703 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -1.39530 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 32: loss -1.41007 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -1.42844 acc 0.66667 roc_auc 0.37640 prc_auc 0.57442[0m
[93maverage test of epoch 33: loss -1.44312 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -1.46159 acc 0.66667 roc_auc 0.37640 prc_auc 0.57442[0m
[93maverage test of epoch 34: loss -1.47617 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -1.49473 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 35: loss -1.50921 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -1.52787 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 36: loss -1.54226 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -1.56101 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 37: loss -1.57531 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -1.59415 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 38: loss -1.60835 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -1.62729 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 39: loss -1.64140 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -1.66044 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 40: loss -1.67445 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -1.69358 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 41: loss -1.70750 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -1.72672 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 42: loss -1.74054 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -1.75986 acc 0.66667 roc_auc 0.37640 prc_auc 0.57445[0m
[93maverage test of epoch 43: loss -1.77359 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -1.79300 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 44: loss -1.80664 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -1.82613 acc 0.66667 roc_auc 0.37490 prc_auc 0.57400[0m
[93maverage test of epoch 45: loss -1.83968 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -1.85928 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 46: loss -1.87273 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -1.89242 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 47: loss -1.90578 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -1.92557 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 48: loss -1.93882 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -1.95871 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 49: loss -1.97187 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss 0.47073 acc 0.33775 roc_auc 0.50353 prc_auc 0.64089[0m
[93maverage test of epoch 0: loss -0.00250 acc 0.32432 roc_auc 0.72500 prc_auc 0.85020[0m
[92maverage training of epoch 1: loss -0.18397 acc 0.33775 roc_auc 0.39784 prc_auc 0.62236[0m
[93maverage test of epoch 1: loss -0.21276 acc 0.35135 roc_auc 0.54000 prc_auc 0.70162[0m
[92maverage training of epoch 2: loss -0.23354 acc 0.35762 roc_auc 0.52686 prc_auc 0.71311[0m
[93maverage test of epoch 2: loss -0.27025 acc 0.37838 roc_auc 0.85000 prc_auc 0.91401[0m
[92maverage training of epoch 3: loss -0.38623 acc 0.56291 roc_auc 0.59686 prc_auc 0.78600[0m
[93maverage test of epoch 3: loss -0.51418 acc 0.67568 roc_auc 0.85667 prc_auc 0.91693[0m
[92maverage training of epoch 4: loss -0.67290 acc 0.66225 roc_auc 0.64000 prc_auc 0.78528[0m
[93maverage test of epoch 4: loss -0.88353 acc 0.67568 roc_auc 0.86000 prc_auc 0.92137[0m
[92maverage training of epoch 5: loss -1.11331 acc 0.66225 roc_auc 0.68961 prc_auc 0.80760[0m
[93maverage test of epoch 5: loss -1.35810 acc 0.67568 roc_auc 0.85667 prc_auc 0.92034[0m
[92maverage training of epoch 6: loss -1.49575 acc 0.66225 roc_auc 0.81020 prc_auc 0.85430[0m
[93maverage test of epoch 6: loss -1.69057 acc 0.67568 roc_auc 0.86000 prc_auc 0.92585[0m
[92maverage training of epoch 7: loss -1.80748 acc 0.66225 roc_auc 0.81922 prc_auc 0.85588[0m
[93maverage test of epoch 7: loss -2.00253 acc 0.67568 roc_auc 0.86000 prc_auc 0.92585[0m
[92maverage training of epoch 8: loss -2.11514 acc 0.66225 roc_auc 0.81784 prc_auc 0.85553[0m
[93maverage test of epoch 8: loss -2.31748 acc 0.67568 roc_auc 0.86333 prc_auc 0.92682[0m
[92maverage training of epoch 9: loss -2.42924 acc 0.66225 roc_auc 0.81961 prc_auc 0.85897[0m
[93maverage test of epoch 9: loss -2.64038 acc 0.67568 roc_auc 0.86000 prc_auc 0.92282[0m
[92maverage training of epoch 10: loss -2.75313 acc 0.66225 roc_auc 0.82647 prc_auc 0.86665[0m
[93maverage test of epoch 10: loss -2.97254 acc 0.67568 roc_auc 0.86000 prc_auc 0.92282[0m
[92maverage training of epoch 11: loss -3.09208 acc 0.66225 roc_auc 0.84216 prc_auc 0.87819[0m
[93maverage test of epoch 11: loss -3.31989 acc 0.67568 roc_auc 0.86000 prc_auc 0.92282[0m
[92maverage training of epoch 12: loss -3.45371 acc 0.66225 roc_auc 0.85706 prc_auc 0.88827[0m
[93maverage test of epoch 12: loss -3.69148 acc 0.67568 roc_auc 0.86000 prc_auc 0.92282[0m
[92maverage training of epoch 13: loss -3.84149 acc 0.66225 roc_auc 0.86373 prc_auc 0.89306[0m
[93maverage test of epoch 13: loss -4.09269 acc 0.67568 roc_auc 0.86000 prc_auc 0.92282[0m
[92maverage training of epoch 14: loss -4.25859 acc 0.66225 roc_auc 0.86431 prc_auc 0.89319[0m
[93maverage test of epoch 14: loss -4.52843 acc 0.67568 roc_auc 0.86000 prc_auc 0.92137[0m
[92maverage training of epoch 15: loss -4.71449 acc 0.66225 roc_auc 0.86157 prc_auc 0.88884[0m
[93maverage test of epoch 15: loss -5.00935 acc 0.67568 roc_auc 0.85667 prc_auc 0.92034[0m
[92maverage training of epoch 16: loss -5.21766 acc 0.66225 roc_auc 0.86235 prc_auc 0.88746[0m
[93maverage test of epoch 16: loss -5.53898 acc 0.67568 roc_auc 0.85333 prc_auc 0.91937[0m
[92maverage training of epoch 17: loss -5.75151 acc 0.66225 roc_auc 0.86196 prc_auc 0.88433[0m
[93maverage test of epoch 17: loss -6.09044 acc 0.67568 roc_auc 0.85333 prc_auc 0.91937[0m
[92maverage training of epoch 18: loss -6.30998 acc 0.66225 roc_auc 0.86333 prc_auc 0.88242[0m
[93maverage test of epoch 18: loss -6.66767 acc 0.67568 roc_auc 0.85333 prc_auc 0.91937[0m
[92maverage training of epoch 19: loss -6.89783 acc 0.66225 roc_auc 0.86157 prc_auc 0.87974[0m
[93maverage test of epoch 19: loss -7.27386 acc 0.67568 roc_auc 0.85333 prc_auc 0.91937[0m
[92maverage training of epoch 20: loss -7.51369 acc 0.66225 roc_auc 0.86039 prc_auc 0.87788[0m
[93maverage test of epoch 20: loss -7.90719 acc 0.67568 roc_auc 0.85667 prc_auc 0.92211[0m
[92maverage training of epoch 21: loss -8.15773 acc 0.66225 roc_auc 0.85843 prc_auc 0.87639[0m
[93maverage test of epoch 21: loss -8.56887 acc 0.67568 roc_auc 0.85667 prc_auc 0.92247[0m
[92maverage training of epoch 22: loss -8.83081 acc 0.66225 roc_auc 0.85422 prc_auc 0.87281[0m
[93maverage test of epoch 22: loss -9.25977 acc 0.67568 roc_auc 0.85833 prc_auc 0.91999[0m
[92maverage training of epoch 23: loss -9.53366 acc 0.66225 roc_auc 0.85098 prc_auc 0.86930[0m
[93maverage test of epoch 23: loss -9.98072 acc 0.67568 roc_auc 0.84833 prc_auc 0.89701[0m
[92maverage training of epoch 24: loss -10.26700 acc 0.66225 roc_auc 0.84814 prc_auc 0.86229[0m
[93maverage test of epoch 24: loss -10.73335 acc 0.67568 roc_auc 0.84667 prc_auc 0.89454[0m
[92maverage training of epoch 25: loss -11.03177 acc 0.66225 roc_auc 0.84392 prc_auc 0.85317[0m
[93maverage test of epoch 25: loss -11.52066 acc 0.67568 roc_auc 0.85000 prc_auc 0.90030[0m
[92maverage training of epoch 26: loss -11.83160 acc 0.66225 roc_auc 0.81833 prc_auc 0.83649[0m
[93maverage test of epoch 26: loss -12.34931 acc 0.67568 roc_auc 0.85000 prc_auc 0.90049[0m
[92maverage training of epoch 27: loss -12.68375 acc 0.66225 roc_auc 0.79382 prc_auc 0.81248[0m
[93maverage test of epoch 27: loss -13.24328 acc 0.67568 roc_auc 0.83500 prc_auc 0.87919[0m
[92maverage training of epoch 28: loss -13.61828 acc 0.66225 roc_auc 0.73549 prc_auc 0.77162[0m
[93maverage test of epoch 28: loss -14.21963 acc 0.67568 roc_auc 0.86333 prc_auc 0.90396[0m
[92maverage training of epoch 29: loss -14.59719 acc 0.66225 roc_auc 0.59618 prc_auc 0.69160[0m
[93maverage test of epoch 29: loss -15.21513 acc 0.67568 roc_auc 0.86500 prc_auc 0.90396[0m
[92maverage training of epoch 30: loss -15.60051 acc 0.66225 roc_auc 0.49990 prc_auc 0.65163[0m
[93maverage test of epoch 30: loss -16.23707 acc 0.67568 roc_auc 0.86667 prc_auc 0.90396[0m
[92maverage training of epoch 31: loss -16.63456 acc 0.66225 roc_auc 0.46196 prc_auc 0.62833[0m
[93maverage test of epoch 31: loss -17.29122 acc 0.67568 roc_auc 0.83500 prc_auc 0.87703[0m
[92maverage training of epoch 32: loss -17.70103 acc 0.66225 roc_auc 0.44961 prc_auc 0.62111[0m
[93maverage test of epoch 32: loss -18.37821 acc 0.67568 roc_auc 0.76167 prc_auc 0.82143[0m
[92maverage training of epoch 33: loss -18.80022 acc 0.66225 roc_auc 0.43392 prc_auc 0.61073[0m
[93maverage test of epoch 33: loss -19.49815 acc 0.67568 roc_auc 0.62167 prc_auc 0.73766[0m
[92maverage training of epoch 34: loss -19.93193 acc 0.66225 roc_auc 0.42588 prc_auc 0.60624[0m
[93maverage test of epoch 34: loss -20.64979 acc 0.67568 roc_auc 0.58333 prc_auc 0.71798[0m
[92maverage training of epoch 35: loss -21.09221 acc 0.66225 roc_auc 0.42275 prc_auc 0.60392[0m
[93maverage test of epoch 35: loss -21.82793 acc 0.67568 roc_auc 0.62333 prc_auc 0.73766[0m
[92maverage training of epoch 36: loss -22.27872 acc 0.66225 roc_auc 0.41716 prc_auc 0.59755[0m
[93maverage test of epoch 36: loss -23.03292 acc 0.67568 roc_auc 0.60000 prc_auc 0.72571[0m
[92maverage training of epoch 37: loss -23.49235 acc 0.66225 roc_auc 0.42059 prc_auc 0.60195[0m
[93maverage test of epoch 37: loss -24.26565 acc 0.67568 roc_auc 0.60000 prc_auc 0.72571[0m
[92maverage training of epoch 38: loss -24.73387 acc 0.66225 roc_auc 0.42167 prc_auc 0.60237[0m
[93maverage test of epoch 38: loss -25.52676 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 39: loss -26.00387 acc 0.66225 roc_auc 0.41804 prc_auc 0.60036[0m
[93maverage test of epoch 39: loss -26.81680 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 40: loss -27.30284 acc 0.66225 roc_auc 0.42598 prc_auc 0.60961[0m
[93maverage test of epoch 40: loss -28.13618 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -28.63119 acc 0.66225 roc_auc 0.41363 prc_auc 0.60228[0m
[93maverage test of epoch 41: loss -29.48528 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -29.98923 acc 0.66225 roc_auc 0.41275 prc_auc 0.60652[0m
[93maverage test of epoch 42: loss -30.86436 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -31.37722 acc 0.66225 roc_auc 0.41382 prc_auc 0.61529[0m
[93maverage test of epoch 43: loss -32.27368 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -32.79538 acc 0.66225 roc_auc 0.44059 prc_auc 0.63048[0m
[93maverage test of epoch 44: loss -33.71342 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -34.24389 acc 0.66225 roc_auc 0.41706 prc_auc 0.61905[0m
[93maverage test of epoch 45: loss -35.18372 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -35.72287 acc 0.66225 roc_auc 0.41922 prc_auc 0.62292[0m
[93maverage test of epoch 46: loss -36.68469 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -37.23242 acc 0.66225 roc_auc 0.42745 prc_auc 0.63225[0m
[93maverage test of epoch 47: loss -38.21643 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -38.77262 acc 0.66225 roc_auc 0.42725 prc_auc 0.63225[0m
[93maverage test of epoch 48: loss -39.77900 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -40.34354 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 49: loss -41.37246 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss 0.45640 acc 0.33775 roc_auc 0.43078 prc_auc 0.63450[0m
[93maverage test of epoch 0: loss 0.23487 acc 0.32432 roc_auc 0.92667 prc_auc 0.97104[0m
[92maverage training of epoch 1: loss 0.05548 acc 0.33775 roc_auc 0.37922 prc_auc 0.57118[0m
[93maverage test of epoch 1: loss 0.00742 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 2: loss -0.01904 acc 0.33775 roc_auc 0.37059 prc_auc 0.56870[0m
[93maverage test of epoch 2: loss -0.02596 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 3: loss -0.05229 acc 0.33775 roc_auc 0.37039 prc_auc 0.56872[0m
[93maverage test of epoch 3: loss -0.05935 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 4: loss -0.08555 acc 0.33775 roc_auc 0.37000 prc_auc 0.56849[0mUsing backend: pytorch
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))

[93maverage test of epoch 4: loss -0.09276 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 5: loss -0.11882 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 5: loss -0.12618 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 6: loss -0.15210 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 6: loss -0.15960 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 7: loss -0.18538 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 7: loss -0.19302 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 8: loss -0.21867 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 8: loss -0.22645 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 9: loss -0.25195 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 9: loss -0.25988 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 10: loss -0.28524 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 10: loss -0.29330 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 11: loss -0.31853 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 11: loss -0.32673 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 12: loss -0.35182 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 12: loss -0.36017 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 13: loss -0.38511 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 13: loss -0.39360 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 14: loss -0.41840 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 14: loss -0.42703 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 15: loss -0.45169 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 15: loss -0.46046 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 16: loss -0.48498 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 16: loss -0.49390 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 17: loss -0.51827 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 17: loss -0.52733 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 18: loss -0.55156 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 18: loss -0.56076 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 19: loss -0.58485 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 19: loss -0.59420 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 20: loss -0.61815 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 20: loss -0.62763 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 21: loss -0.65144 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 21: loss -0.66106 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 22: loss -0.68473 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 22: loss -0.69450 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 23: loss -0.71803 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 23: loss -0.72793 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 24: loss -0.75132 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 24: loss -0.76137 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 25: loss -0.78461 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 25: loss -0.79480 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 26: loss -0.81790 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 26: loss -0.82824 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 27: loss -0.85120 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 27: loss -0.86167 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 28: loss -0.88449 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 28: loss -0.89511 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 29: loss -0.91778 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 29: loss -0.92854 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 30: loss -0.95108 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 30: loss -0.96197 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 31: loss -0.98437 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 31: loss -0.99541 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 32: loss -1.01766 acc 0.33775 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 32: loss -1.02884 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 33: loss -1.05095 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 33: loss -1.06228 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 34: loss -1.08425 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 34: loss -1.09571 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 35: loss -1.11754 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 35: loss -1.12915 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 36: loss -1.15083 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 36: loss -1.16258 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 37: loss -1.18412 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 37: loss -1.19602 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 38: loss -1.21742 acc 0.33775 roc_auc 0.36971 prc_auc 0.56810[0m
[93maverage test of epoch 38: loss -1.22945 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 39: loss -1.25071 acc 0.33775 roc_auc 0.36971 prc_auc 0.56808[0m
[93maverage test of epoch 39: loss -1.26289 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -1.28400 acc 0.33775 roc_auc 0.36971 prc_auc 0.56808[0m
[93maverage test of epoch 40: loss -1.29632 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -1.31730 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 41: loss -1.32975 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -1.35059 acc 0.33775 roc_auc 0.37000 prc_auc 0.56825[0m
[93maverage test of epoch 42: loss -1.36319 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -1.38388 acc 0.33775 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 43: loss -1.39662 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -1.41718 acc 0.33775 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 44: loss -1.43006 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -1.45047 acc 0.33775 roc_auc 0.36971 prc_auc 0.56808[0m
[93maverage test of epoch 45: loss -1.46349 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -1.48376 acc 0.33775 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 46: loss -1.49693 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -1.51705 acc 0.33775 roc_auc 0.36971 prc_auc 0.56810[0m
[93maverage test of epoch 47: loss -1.53036 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -1.55035 acc 0.33775 roc_auc 0.36971 prc_auc 0.56808[0m
[93maverage test of epoch 48: loss -1.56380 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -1.58364 acc 0.33775 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 49: loss -1.59723 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 1)
('lr', 0.0003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.59474 ROC_AUC (avg): 0.5 PRC_AUC (avg): 0.66501 

Average forward propagation time taken(ms): 2.7766177160074124
Average backward propagation time taken(ms): 0.9299440982511832

