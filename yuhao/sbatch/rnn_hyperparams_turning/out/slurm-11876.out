# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.0003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-19-42-26/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-19-42-26/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 8,
 'epochs': 50,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 4,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.0003,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 2,
 'num_workers': 8,
 'number_of_mlp_layer': 0,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-17-19-42-26',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 50, 'learning_rate': 0.0003, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.84995 acc 0.33333 roc_auc 0.41980 prc_auc 0.61977[0m
[93maverage test of epoch 0: loss -1.05233 acc 0.34211 roc_auc 0.45538 prc_auc 0.71289[0m
[92maverage training of epoch 1: loss -1.26695 acc 0.36000 roc_auc 0.45140 prc_auc 0.66210[0m
[93maverage test of epoch 1: loss -1.50299 acc 0.63158 roc_auc 0.56615 prc_auc 0.74990[0m
[92maverage training of epoch 2: loss -1.76792 acc 0.64000 roc_auc 0.47360 prc_auc 0.66424[0m
[93maverage test of epoch 2: loss -2.09123 acc 0.65789 roc_auc 0.65846 prc_auc 0.80022[0m
[92maverage training of epoch 3: loss -2.45892 acc 0.66667 roc_auc 0.44180 prc_auc 0.66125[0m
[93maverage test of epoch 3: loss -2.85855 acc 0.65789 roc_auc 0.60308 prc_auc 0.77380[0m
[92maverage training of epoch 4: loss -3.18414 acc 0.66667 roc_auc 0.38580 prc_auc 0.59409[0m
[93maverage test of epoch 4: loss -3.51124 acc 0.65789 roc_auc 0.46769 prc_auc 0.72668[0m
[92maverage training of epoch 5: loss -3.89171 acc 0.66667 roc_auc 0.47080 prc_auc 0.66404[0m
[93maverage test of epoch 5: loss -4.16438 acc 0.65789 roc_auc 0.60308 prc_auc 0.76104[0m
[92maverage training of epoch 6: loss -4.44612 acc 0.66667 roc_auc 0.44360 prc_auc 0.63794[0m
[93maverage test of epoch 6: loss -4.66197 acc 0.65789 roc_auc 0.58154 prc_auc 0.72154[0m
[92maverage training of epoch 7: loss -4.84783 acc 0.66667 roc_auc 0.33000 prc_auc 0.56468[0m
[93maverage test of epoch 7: loss -5.00478 acc 0.65789 roc_auc 0.66769 prc_auc 0.82092[0m
[92maverage training of epoch 8: loss -5.17279 acc 0.66667 roc_auc 0.46060 prc_auc 0.61588[0m
[93maverage test of epoch 8: loss -5.30611 acc 0.65789 roc_auc 0.49846 prc_auc 0.69235[0m
[92maverage training of epoch 9: loss -5.45328 acc 0.66667 roc_auc 0.52280 prc_auc 0.66728[0m
[93maverage test of epoch 9: loss -5.55939 acc 0.65789 roc_auc 0.32615 prc_auc 0.60188[0m
[92maverage training of epoch 10: loss -5.69735 acc 0.66667 roc_auc 0.45100 prc_auc 0.63405[0m
[93maverage test of epoch 10: loss -5.78224 acc 0.65789 roc_auc 0.44615 prc_auc 0.65546[0m
[92maverage training of epoch 11: loss -5.92518 acc 0.66667 roc_auc 0.39020 prc_auc 0.57523[0m
[93maverage test of epoch 11: loss -5.99899 acc 0.65789 roc_auc 0.38154 prc_auc 0.60402[0m
[92maverage training of epoch 12: loss -6.13736 acc 0.66667 roc_auc 0.42550 prc_auc 0.59496[0m
[93maverage test of epoch 12: loss -6.22091 acc 0.65789 roc_auc 0.59692 prc_auc 0.76366[0m
[92maverage training of epoch 13: loss -6.33335 acc 0.66667 roc_auc 0.41980 prc_auc 0.61517[0m
[93maverage test of epoch 13: loss -6.40062 acc 0.65789 roc_auc 0.53538 prc_auc 0.71982[0m
[92maverage training of epoch 14: loss -6.53207 acc 0.66667 roc_auc 0.47640 prc_auc 0.65560[0m
[93maverage test of epoch 14: loss -6.59077 acc 0.65789 roc_auc 0.50154 prc_auc 0.72605[0m
[92maverage training of epoch 15: loss -6.71317 acc 0.66667 roc_auc 0.44760 prc_auc 0.64486[0m
[93maverage test of epoch 15: loss -6.77479 acc 0.65789 roc_auc 0.48923 prc_auc 0.70629[0m
[92maverage training of epoch 16: loss -6.89830 acc 0.66667 roc_auc 0.36000 prc_auc 0.58009[0m
[93maverage test of epoch 16: loss -6.96900 acc 0.65789 roc_auc 0.28615 prc_auc 0.53839[0m
[92maverage training of epoch 17: loss -7.08081 acc 0.66667 roc_auc 0.40360 prc_auc 0.60092[0m
[93maverage test of epoch 17: loss -7.14342 acc 0.65789 roc_auc 0.49846 prc_auc 0.74015[0m
[92maverage training of epoch 18: loss -7.26150 acc 0.66667 roc_auc 0.35440 prc_auc 0.58836[0m
[93maverage test of epoch 18: loss -7.33228 acc 0.65789 roc_auc 0.55385 prc_auc 0.75810[0m
[92maverage training of epoch 19: loss -7.43760 acc 0.66667 roc_auc 0.39960 prc_auc 0.58606[0m
[93maverage test of epoch 19: loss -7.50551 acc 0.65789 roc_auc 0.56154 prc_auc 0.68967[0m
[92maverage training of epoch 20: loss -7.61703 acc 0.66667 roc_auc 0.43380 prc_auc 0.63300[0m
[93maverage test of epoch 20: loss -7.66964 acc 0.65789 roc_auc 0.55385 prc_auc 0.69425[0m
[92maverage training of epoch 21: loss -7.79792 acc 0.66667 roc_auc 0.46780 prc_auc 0.64165[0m
[93maverage test of epoch 21: loss -7.86307 acc 0.65789 roc_auc 0.46462 prc_auc 0.68315[0m
[92maverage training of epoch 22: loss -7.97101 acc 0.66667 roc_auc 0.44760 prc_auc 0.60674[0m
[93maverage test of epoch 22: loss -8.02709 acc 0.65789 roc_auc 0.72615 prc_auc 0.83562[0m
[92maverage training of epoch 23: loss -8.14160 acc 0.66667 roc_auc 0.34780 prc_auc 0.56642[0m
[93maverage test of epoch 23: loss -8.19837 acc 0.65789 roc_auc 0.46615 prc_auc 0.66662[0m
[92maverage training of epoch 24: loss -8.31501 acc 0.66667 roc_auc 0.43380 prc_auc 0.60266[0m
[93maverage test of epoch 24: loss -8.36577 acc 0.65789 roc_auc 0.58615 prc_auc 0.74950[0m
[92maverage training of epoch 25: loss -8.48568 acc 0.66667 roc_auc 0.40220 prc_auc 0.60101[0m
[93maverage test of epoch 25: loss -8.54097 acc 0.65789 roc_auc 0.51538 prc_auc 0.73669[0m
[92maverage training of epoch 26: loss -8.65447 acc 0.66667 roc_auc 0.39160 prc_auc 0.58837[0m
[93maverage test of epoch 26: loss -8.70371 acc 0.65789 roc_auc 0.48923 prc_auc 0.72765[0m
[92maverage training of epoch 27: loss -8.82933 acc 0.66667 roc_auc 0.39940 prc_auc 0.59173[0m
[93maverage test of epoch 27: loss -8.88113 acc 0.65789 roc_auc 0.64154 prc_auc 0.79251[0m
[92maverage training of epoch 28: loss -8.99609 acc 0.66667 roc_auc 0.48520 prc_auc 0.65176[0m
[93maverage test of epoch 28: loss -9.05008 acc 0.65789 roc_auc 0.59077 prc_auc 0.79060[0m
[92maverage training of epoch 29: loss -9.16395 acc 0.66667 roc_auc 0.38450 prc_auc 0.58250[0m
[93maverage test of epoch 29: loss -9.21183 acc 0.65789 roc_auc 0.47692 prc_auc 0.68377[0m
[92maverage training of epoch 30: loss -9.33388 acc 0.66667 roc_auc 0.38480 prc_auc 0.59023[0m
[93maverage test of epoch 30: loss -9.38773 acc 0.65789 roc_auc 0.72308 prc_auc 0.85588[0m
[92maverage training of epoch 31: loss -9.50167 acc 0.66667 roc_auc 0.37510 prc_auc 0.58652[0m
[93maverage test of epoch 31: loss -9.55267 acc 0.65789 roc_auc 0.28000 prc_auc 0.56182[0m
[92maverage training of epoch 32: loss -9.67314 acc 0.66667 roc_auc 0.39220 prc_auc 0.60622[0m
[93maverage test of epoch 32: loss -9.71912 acc 0.65789 roc_auc 0.61077 prc_auc 0.77100[0m
[92maverage training of epoch 33: loss -9.83896 acc 0.66667 roc_auc 0.37300 prc_auc 0.59143[0m
[93maverage test of epoch 33: loss -9.88642 acc 0.65789 roc_auc 0.54308 prc_auc 0.71247[0m
[92maverage training of epoch 34: loss -10.00569 acc 0.66667 roc_auc 0.41680 prc_auc 0.59539[0m
[93maverage test of epoch 34: loss -10.05671 acc 0.65789 roc_auc 0.51231 prc_auc 0.66087[0m
[92maverage training of epoch 35: loss -10.17246 acc 0.66667 roc_auc 0.37450 prc_auc 0.59214[0m
[93maverage test of epoch 35: loss -10.22292 acc 0.65789 roc_auc 0.32000 prc_auc 0.55124[0m
[92maverage training of epoch 36: loss -10.34257 acc 0.66667 roc_auc 0.39400 prc_auc 0.58974[0m
[93maverage test of epoch 36: loss -10.39049 acc 0.65789 roc_auc 0.41231 prc_auc 0.61568[0m
[92maverage training of epoch 37: loss -10.50845 acc 0.66667 roc_auc 0.39920 prc_auc 0.60221[0m
[93maverage test of epoch 37: loss -10.55692 acc 0.65789 roc_auc 0.38462 prc_auc 0.64711[0m
[92maverage training of epoch 38: loss -10.67685 acc 0.66667 roc_auc 0.37550 prc_auc 0.57548[0m
[93maverage test of epoch 38: loss -10.71882 acc 0.65789 roc_auc 0.47692 prc_auc 0.64073[0m
[92maverage training of epoch 39: loss -10.84489 acc 0.66667 roc_auc 0.38880 prc_auc 0.59733[0m
[93maverage test of epoch 39: loss -10.88313 acc 0.65789 roc_auc 0.52308 prc_auc 0.71426[0m
[92maverage training of epoch 40: loss -11.01095 acc 0.66667 roc_auc 0.40930 prc_auc 0.60160[0m
[93maverage test of epoch 40: loss -11.05200 acc 0.65789 roc_auc 0.70154 prc_auc 0.76634[0m
[92maverage training of epoch 41: loss -11.17609 acc 0.66667 roc_auc 0.37100 prc_auc 0.58173[0m
[93maverage test of epoch 41: loss -11.21182 acc 0.65789 roc_auc 0.40923 prc_auc 0.61001[0m
[92maverage training of epoch 42: loss -11.34609 acc 0.66667 roc_auc 0.37730 prc_auc 0.57908[0m
[93maverage test of epoch 42: loss -11.38828 acc 0.65789 roc_auc 0.57077 prc_auc 0.73286[0m
[92maverage training of epoch 43: loss -11.51115 acc 0.66667 roc_auc 0.35780 prc_auc 0.56703[0m
[93maverage test of epoch 43: loss -11.55415 acc 0.65789 roc_auc 0.40615 prc_auc 0.60238[0m
[92maverage training of epoch 44: loss -11.67874 acc 0.66667 roc_auc 0.36450 prc_auc 0.57132[0m
[93maverage test of epoch 44: loss -11.71912 acc 0.65789 roc_auc 0.47846 prc_auc 0.64507[0m
[92maverage training of epoch 45: loss -11.84416 acc 0.66667 roc_auc 0.39560 prc_auc 0.59290[0m
[93maverage test of epoch 45: loss -11.88256 acc 0.65789 roc_auc 0.50154 prc_auc 0.66592[0m
[92maverage training of epoch 46: loss -12.01055 acc 0.66667 roc_auc 0.38140 prc_auc 0.58136[0m
[93maverage test of epoch 46: loss -12.05323 acc 0.65789 roc_auc 0.65385 prc_auc 0.74734[0m
[92maverage training of epoch 47: loss -12.17655 acc 0.66667 roc_auc 0.36910 prc_auc 0.57548[0m
[93maverage test of epoch 47: loss -12.21699 acc 0.65789 roc_auc 0.35385 prc_auc 0.57158[0m
[92maverage training of epoch 48: loss -12.34236 acc 0.66667 roc_auc 0.39480 prc_auc 0.59568[0m
[93maverage test of epoch 48: loss -12.38385 acc 0.65789 roc_auc 0.52923 prc_auc 0.68477[0m
[92maverage training of epoch 49: loss -12.50868 acc 0.66667 roc_auc 0.37430 prc_auc 0.58554[0m
[93maverage test of epoch 49: loss -12.54690 acc 0.65789 roc_auc 0.46923 prc_auc 0.63943[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.47008 acc 0.33333 roc_auc 0.51600 prc_auc 0.65847[0m
[93maverage test of epoch 0: loss -0.80587 acc 0.34211 roc_auc 0.22462 prc_auc 0.55688[0m
[92maverage training of epoch 1: loss -1.15811 acc 0.33333 roc_auc 0.58080 prc_auc 0.73626[0m
[93maverage test of epoch 1: loss -1.58370 acc 0.34211 roc_auc 0.30462 prc_auc 0.58803[0m
[92maverage training of epoch 2: loss -1.91717 acc 0.33333 roc_auc 0.49460 prc_auc 0.66438[0m
[93maverage test of epoch 2: loss -2.19465 acc 0.34211 roc_auc 0.30462 prc_auc 0.59025[0m
[92maverage training of epoch 3: loss -2.38558 acc 0.33333 roc_auc 0.36500 prc_auc 0.57122[0m
[93maverage test of epoch 3: loss -2.58906 acc 0.34211 roc_auc 0.45846 prc_auc 0.71813[0m
[92maverage training of epoch 4: loss -2.72743 acc 0.33333 roc_auc 0.39120 prc_auc 0.59463[0m
[93maverage test of epoch 4: loss -2.90217 acc 0.34211 roc_auc 0.31077 prc_auc 0.55422[0m
[92maverage training of epoch 5: loss -3.04066 acc 0.33333 roc_auc 0.42730 prc_auc 0.62695[0m
[93maverage test of epoch 5: loss -3.20493 acc 0.34211 roc_auc 0.54462 prc_auc 0.75982[0m
[92maverage training of epoch 6: loss -3.32566 acc 0.33333 roc_auc 0.44540 prc_auc 0.62328[0m
[93maverage test of epoch 6: loss -3.48464 acc 0.34211 roc_auc 0.64308 prc_auc 0.76417[0m
[92maverage training of epoch 7: loss -3.58559 acc 0.33333 roc_auc 0.50420 prc_auc 0.65617[0m
[93maverage test of epoch 7: loss -3.72443 acc 0.34211 roc_auc 0.60923 prc_auc 0.78400[0m
[92maverage training of epoch 8: loss -3.81303 acc 0.33333 roc_auc 0.40800 prc_auc 0.58745[0m
[93maverage test of epoch 8: loss -3.92737 acc 0.34211 roc_auc 0.39385 prc_auc 0.62643[0m
[92maverage training of epoch 9: loss -4.02218 acc 0.33333 roc_auc 0.43020 prc_auc 0.63631[0m
[93maverage test of epoch 9: loss -4.14995 acc 0.34211 roc_auc 0.51846 prc_auc 0.73981[0m
[92maverage training of epoch 10: loss -4.23000 acc 0.33333 roc_auc 0.46480 prc_auc 0.65586[0m
[93maverage test of epoch 10: loss -4.34450 acc 0.34211 roc_auc 0.59385 prc_auc 0.73894[0m
[92maverage training of epoch 11: loss -4.42803 acc 0.33333 roc_auc 0.45660 prc_auc 0.63040[0m
[93maverage test of epoch 11: loss -4.53664 acc 0.34211 roc_auc 0.44615 prc_auc 0.68895[0m
[92maverage training of epoch 12: loss -4.61075 acc 0.33333 roc_auc 0.46260 prc_auc 0.63806[0m
[93maverage test of epoch 12: loss -4.73170 acc 0.34211 roc_auc 0.65385 prc_auc 0.79373[0m
[92maverage training of epoch 13: loss -4.80374 acc 0.33333 roc_auc 0.46720 prc_auc 0.64032[0m
[93maverage test of epoch 13: loss -4.90634 acc 0.34211 roc_auc 0.52615 prc_auc 0.73425[0m
[92maverage training of epoch 14: loss -4.98538 acc 0.33333 roc_auc 0.41760 prc_auc 0.59322[0m
[93maverage test of epoch 14: loss -5.08668 acc 0.34211 roc_auc 0.50923 prc_auc 0.71865[0m
[92maverage training of epoch 15: loss -5.16842 acc 0.33333 roc_auc 0.42700 prc_auc 0.60669[0m
[93maverage test of epoch 15: loss -5.25235 acc 0.34211 roc_auc 0.56000 prc_auc 0.75729[0m
[92maverage training of epoch 16: loss -5.34652 acc 0.33333 roc_auc 0.43960 prc_auc 0.61640[0m
[93maverage test of epoch 16: loss -5.45342 acc 0.34211 roc_auc 0.59231 prc_auc 0.75484[0m
[92maverage training of epoch 17: loss -5.52474 acc 0.33333 roc_auc 0.41720 prc_auc 0.60116[0m
[93maverage test of epoch 17: loss -5.62745 acc 0.34211 roc_auc 0.55538 prc_auc 0.75025[0m
[92maverage training of epoch 18: loss -5.70368 acc 0.33333 roc_auc 0.47160 prc_auc 0.64693[0m
[93maverage test of epoch 18: loss -5.79324 acc 0.34211 roc_auc 0.46923 prc_auc 0.67365[0m
[92maverage training of epoch 19: loss -5.87537 acc 0.33333 roc_auc 0.45600 prc_auc 0.64119[0m
[93maverage test of epoch 19: loss -5.96656 acc 0.34211 roc_auc 0.48923 prc_auc 0.70050[0m
[92maverage training of epoch 20: loss -6.04663 acc 0.33333 roc_auc 0.42820 prc_auc 0.60166[0m
[93maverage test of epoch 20: loss -6.14592 acc 0.34211 roc_auc 0.32769 prc_auc 0.60798[0m
[92maverage training of epoch 21: loss -6.21606 acc 0.33333 roc_auc 0.40730 prc_auc 0.60319[0m
[93maverage test of epoch 21: loss -6.30864 acc 0.34211 roc_auc 0.60923 prc_auc 0.79670[0m
[92maverage training of epoch 22: loss -6.39352 acc 0.33333 roc_auc 0.41460 prc_auc 0.60437[0m
[93maverage test of epoch 22: loss -6.48112 acc 0.34211 roc_auc 0.42154 prc_auc 0.68256[0m
[92maverage training of epoch 23: loss -6.56238 acc 0.33333 roc_auc 0.45170 prc_auc 0.63408[0m
[93maverage test of epoch 23: loss -6.65512 acc 0.34211 roc_auc 0.48769 prc_auc 0.70691[0m
[92maverage training of epoch 24: loss -6.73432 acc 0.33333 roc_auc 0.42020 prc_auc 0.60818[0m
[93maverage test of epoch 24: loss -6.82248 acc 0.34211 roc_auc 0.62769 prc_auc 0.78374[0m
[92maverage training of epoch 25: loss -6.90416 acc 0.33333 roc_auc 0.43910 prc_auc 0.62902[0m
[93maverage test of epoch 25: loss -6.99040 acc 0.34211 roc_auc 0.55692 prc_auc 0.69844[0m
[92maverage training of epoch 26: loss -7.07363 acc 0.33333 roc_auc 0.41780 prc_auc 0.61193[0m
[93maverage test of epoch 26: loss -7.16125 acc 0.34211 roc_auc 0.45538 prc_auc 0.66691[0m
[92maverage training of epoch 27: loss -7.24230 acc 0.33333 roc_auc 0.43540 prc_auc 0.61599[0m
[93maverage test of epoch 27: loss -7.32968 acc 0.34211 roc_auc 0.42462 prc_auc 0.65198[0m
[92maverage training of epoch 28: loss -7.41108 acc 0.60000 roc_auc 0.43420 prc_auc 0.63021[0m
[93maverage test of epoch 28: loss -7.49684 acc 0.65789 roc_auc 0.46769 prc_auc 0.66469[0m
[92maverage training of epoch 29: loss -7.58043 acc 0.66667 roc_auc 0.42460 prc_auc 0.60771[0m
[93maverage test of epoch 29: loss -7.66121 acc 0.65789 roc_auc 0.36308 prc_auc 0.61971[0m
[92maverage training of epoch 30: loss -7.74671 acc 0.66667 roc_auc 0.44280 prc_auc 0.62755[0m
[93maverage test of epoch 30: loss -7.82916 acc 0.65789 roc_auc 0.40308 prc_auc 0.66027[0m
[92maverage training of epoch 31: loss -7.91593 acc 0.66667 roc_auc 0.43440 prc_auc 0.61413[0m
[93maverage test of epoch 31: loss -7.99301 acc 0.65789 roc_auc 0.40769 prc_auc 0.61216[0m
[92maverage training of epoch 32: loss -8.08298 acc 0.66667 roc_auc 0.42300 prc_auc 0.60104[0m
[93maverage test of epoch 32: loss -8.16488 acc 0.65789 roc_auc 0.44462 prc_auc 0.67551[0m
[92maverage training of epoch 33: loss -8.25109 acc 0.66667 roc_auc 0.42500 prc_auc 0.60963[0m
[93maverage test of epoch 33: loss -8.33590 acc 0.65789 roc_auc 0.62462 prc_auc 0.76744[0m
[92maverage training of epoch 34: loss -8.41884 acc 0.66667 roc_auc 0.42420 prc_auc 0.60966[0m
[93maverage test of epoch 34: loss -8.49988 acc 0.65789 roc_auc 0.52615 prc_auc 0.66847[0m
[92maverage training of epoch 35: loss -8.58671 acc 0.66667 roc_auc 0.42020 prc_auc 0.61388[0m
[93maverage test of epoch 35: loss -8.66588 acc 0.65789 roc_auc 0.52308 prc_auc 0.68559[0m
[92maverage training of epoch 36: loss -8.75442 acc 0.66667 roc_auc 0.43520 prc_auc 0.61513[0m
[93maverage test of epoch 36: loss -8.83420 acc 0.65789 roc_auc 0.74154 prc_auc 0.77951[0m
[92maverage training of epoch 37: loss -8.91953 acc 0.66667 roc_auc 0.41500 prc_auc 0.59368[0m
[93maverage test of epoch 37: loss -8.99788 acc 0.65789 roc_auc 0.57077 prc_auc 0.73868[0m
[92maverage training of epoch 38: loss -9.08650 acc 0.66667 roc_auc 0.42360 prc_auc 0.60036[0m
[93maverage test of epoch 38: loss -9.16583 acc 0.65789 roc_auc 0.63538 prc_auc 0.79377[0m
[92maverage training of epoch 39: loss -9.25203 acc 0.66667 roc_auc 0.41680 prc_auc 0.59918[0m
[93maverage test of epoch 39: loss -9.33347 acc 0.65789 roc_auc 0.66154 prc_auc 0.79647[0m
[92maverage training of epoch 40: loss -9.42031 acc 0.66667 roc_auc 0.42380 prc_auc 0.59641[0m
[93maverage test of epoch 40: loss -9.49860 acc 0.65789 roc_auc 0.54308 prc_auc 0.68429[0m
[92maverage training of epoch 41: loss -9.58753 acc 0.66667 roc_auc 0.43760 prc_auc 0.61472[0m
[93maverage test of epoch 41: loss -9.66188 acc 0.65789 roc_auc 0.37231 prc_auc 0.61968[0m
[92maverage training of epoch 42: loss -9.75255 acc 0.66667 roc_auc 0.42240 prc_auc 0.60991[0m
[93maverage test of epoch 42: loss -9.82947 acc 0.65789 roc_auc 0.70769 prc_auc 0.79022[0m
[92maverage training of epoch 43: loss -9.91912 acc 0.66667 roc_auc 0.44200 prc_auc 0.62135[0m
[93maverage test of epoch 43: loss -9.99783 acc 0.65789 roc_auc 0.65846 prc_auc 0.81926[0m
[92maverage training of epoch 44: loss -10.08672 acc 0.66667 roc_auc 0.42040 prc_auc 0.60645[0m
[93maverage test of epoch 44: loss -10.16348 acc 0.65789 roc_auc 0.54462 prc_auc 0.71548[0m
[92maverage training of epoch 45: loss -10.25235 acc 0.66667 roc_auc 0.42580 prc_auc 0.60861[0m
[93maverage test of epoch 45: loss -10.32722 acc 0.65789 roc_auc 0.51385 prc_auc 0.68843[0m
[92maverage training of epoch 46: loss -10.41860 acc 0.66667 roc_auc 0.41260 prc_auc 0.59110[0m
[93maverage test of epoch 46: loss -10.49277 acc 0.65789 roc_auc 0.31692 prc_auc 0.59004[0m
[92maverage training of epoch 47: loss -10.58435 acc 0.66667 roc_auc 0.41520 prc_auc 0.59991[0m
[93maverage test of epoch 47: loss -10.66039 acc 0.65789 roc_auc 0.50923 prc_auc 0.69142[0m
[92maverage training of epoch 48: loss -10.75162 acc 0.66667 roc_auc 0.42920 prc_auc 0.61454[0m
[93maverage test of epoch 48: loss -10.82579 acc 0.65789 roc_auc 0.66615 prc_auc 0.76100[0m
[92maverage training of epoch 49: loss -10.91730 acc 0.66667 roc_auc 0.42340 prc_auc 0.60985[0m
[93maverage test of epoch 49: loss -10.99076 acc 0.65789 roc_auc 0.43692 prc_auc 0.66738[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.46835 acc 0.66667 roc_auc 0.41080 prc_auc 0.63455[0m
[93maverage test of epoch 0: loss -0.66366 acc 0.65789 roc_auc 0.51077 prc_auc 0.63846[0m
[92maverage training of epoch 1: loss -0.94566 acc 0.66667 roc_auc 0.45260 prc_auc 0.65510[0m
[93maverage test of epoch 1: loss -1.21113 acc 0.65789 roc_auc 0.64308 prc_auc 0.75172[0m
[92maverage training of epoch 2: loss -1.42120 acc 0.66667 roc_auc 0.40440 prc_auc 0.60615[0m
[93maverage test of epoch 2: loss -1.59696 acc 0.65789 roc_auc 0.46154 prc_auc 0.61307[0m
[92maverage training of epoch 3: loss -1.76622 acc 0.66667 roc_auc 0.45160 prc_auc 0.62297[0m
[93maverage test of epoch 3: loss -1.89811 acc 0.65789 roc_auc 0.48000 prc_auc 0.65679[0m
[92maverage training of epoch 4: loss -2.06603 acc 0.66667 roc_auc 0.46940 prc_auc 0.65048[0m
[93maverage test of epoch 4: loss -2.19233 acc 0.65789 roc_auc 0.53538 prc_auc 0.70958[0m
[92maverage training of epoch 5: loss -2.34647 acc 0.66667 roc_auc 0.45360 prc_auc 0.64247[0m
[93maverage test of epoch 5: loss -2.45876 acc 0.65789 roc_auc 0.47077 prc_auc 0.67459[0m
[92maverage training of epoch 6: loss -2.59477 acc 0.66667 roc_auc 0.44060 prc_auc 0.63531[0m
[93maverage test of epoch 6: loss -2.71578 acc 0.65789 roc_auc 0.51077 prc_auc 0.73213[0m
[92maverage training of epoch 7: loss -2.84371 acc 0.66667 roc_auc 0.50740 prc_auc 0.67792[0m
[93maverage test of epoch 7: loss -2.93218 acc 0.65789 roc_auc 0.46154 prc_auc 0.66630[0m
[92maverage training of epoch 8: loss -3.06858 acc 0.66667 roc_auc 0.47080 prc_auc 0.64531[0m
[93maverage test of epoch 8: loss -3.14916 acc 0.65789 roc_auc 0.43077 prc_auc 0.68296[0m
[92maverage training of epoch 9: loss -3.28398 acc 0.66667 roc_auc 0.45480 prc_auc 0.63131[0m
[93maverage test of epoch 9: loss -3.35837 acc 0.65789 roc_auc 0.64615 prc_auc 0.71525[0m
[92maverage training of epoch 10: loss -3.47809 acc 0.66667 roc_auc 0.37360 prc_auc 0.59590[0m
[93maverage test of epoch 10: loss -3.56759 acc 0.65789 roc_auc 0.68000 prc_auc 0.80828[0m
[92maverage training of epoch 11: loss -3.68069 acc 0.66667 roc_auc 0.40050 prc_auc 0.59984[0m
[93maverage test of epoch 11: loss -3.75077 acc 0.65789 roc_auc 0.59692 prc_auc 0.74222[0m
[92maverage training of epoch 12: loss -3.87195 acc 0.66667 roc_auc 0.43850 prc_auc 0.62323[0m
[93maverage test of epoch 12: loss -3.92932 acc 0.65789 roc_auc 0.35692 prc_auc 0.63205[0m
[92maverage training of epoch 13: loss -4.05301 acc 0.66667 roc_auc 0.41700 prc_auc 0.60833[0m
[93maverage test of epoch 13: loss -4.13157 acc 0.65789 roc_auc 0.72308 prc_auc 0.84685[0m
[92maverage training of epoch 14: loss -4.23651 acc 0.66667 roc_auc 0.41120 prc_auc 0.59551[0m
[93maverage test of epoch 14: loss -4.30819 acc 0.65789 roc_auc 0.40923 prc_auc 0.62632[0m
[92maverage training of epoch 15: loss -4.41792 acc 0.66667 roc_auc 0.40780 prc_auc 0.59714[0m
[93maverage test of epoch 15: loss -4.48040 acc 0.65789 roc_auc 0.36000 prc_auc 0.56644[0m
[92maverage training of epoch 16: loss -4.59713 acc 0.66667 roc_auc 0.44050 prc_auc 0.61307[0m
[93maverage test of epoch 16: loss -4.65366 acc 0.65789 roc_auc 0.47231 prc_auc 0.70372[0m
[92maverage training of epoch 17: loss -4.77053 acc 0.66667 roc_auc 0.39900 prc_auc 0.58561[0m
[93maverage test of epoch 17: loss -4.83604 acc 0.65789 roc_auc 0.78000 prc_auc 0.88310[0m
[92maverage training of epoch 18: loss -4.94692 acc 0.66667 roc_auc 0.44700 prc_auc 0.60844[0m
[93maverage test of epoch 18: loss -5.01476 acc 0.65789 roc_auc 0.58769 prc_auc 0.76108[0m
[92maverage training of epoch 19: loss -5.12475 acc 0.66667 roc_auc 0.42000 prc_auc 0.60411[0m
[93maverage test of epoch 19: loss -5.18325 acc 0.65789 roc_auc 0.56000 prc_auc 0.71353[0m
[92maverage training of epoch 20: loss -5.29509 acc 0.66667 roc_auc 0.45160 prc_auc 0.62599[0m
[93maverage test of epoch 20: loss -5.34943 acc 0.65789 roc_auc 0.37385 prc_auc 0.59784[0m
[92maverage training of epoch 21: loss -5.46685 acc 0.66667 roc_auc 0.41180 prc_auc 0.59707[0m
[93maverage test of epoch 21: loss -5.51912 acc 0.65789 roc_auc 0.44769 prc_auc 0.72876[0m
[92maverage training of epoch 22: loss -5.64217 acc 0.66667 roc_auc 0.48840 prc_auc 0.67694[0m
[93maverage test of epoch 22: loss -5.69185 acc 0.65789 roc_auc 0.52308 prc_auc 0.67349[0m
[92maverage training of epoch 23: loss -5.80800 acc 0.66667 roc_auc 0.44190 prc_auc 0.63235[0m
[93maverage test of epoch 23: loss -5.86456 acc 0.65789 roc_auc 0.61077 prc_auc 0.77261[0m
[92maverage training of epoch 24: loss -5.98130 acc 0.66667 roc_auc 0.47060 prc_auc 0.63418[0m
[93maverage test of epoch 24: loss -6.03391 acc 0.65789 roc_auc 0.67077 prc_auc 0.77792[0m
[92maverage training of epoch 25: loss -6.14948 acc 0.66667 roc_auc 0.38340 prc_auc 0.59146[0m
[93maverage test of epoch 25: loss -6.20778 acc 0.65789 roc_auc 0.56000 prc_auc 0.72962[0m
[92maverage training of epoch 26: loss -6.31948 acc 0.66667 roc_auc 0.45970 prc_auc 0.64891[0m
[93maverage test of epoch 26: loss -6.37313 acc 0.65789 roc_auc 0.33231 prc_auc 0.59570[0m
[92maverage training of epoch 27: loss -6.48850 acc 0.66667 roc_auc 0.38700 prc_auc 0.58804[0m
[93maverage test of epoch 27: loss -6.54405 acc 0.65789 roc_auc 0.48615 prc_auc 0.63167[0m
[92maverage training of epoch 28: loss -6.65796 acc 0.66667 roc_auc 0.42000 prc_auc 0.61030[0m
[93maverage test of epoch 28: loss -6.71311 acc 0.65789 roc_auc 0.53538 prc_auc 0.72005[0m
[92maverage training of epoch 29: loss -6.82552 acc 0.66667 roc_auc 0.40350 prc_auc 0.59160[0m
[93maverage test of epoch 29: loss -6.88028 acc 0.65789 roc_auc 0.67692 prc_auc 0.83732[0m
[92maverage training of epoch 30: loss -6.99562 acc 0.66667 roc_auc 0.40720 prc_auc 0.60810[0m
[93maverage test of epoch 30: loss -7.04486 acc 0.65789 roc_auc 0.64154 prc_auc 0.80503[0m
[92maverage training of epoch 31: loss -7.16330 acc 0.66667 roc_auc 0.46380 prc_auc 0.62059[0m
[93maverage test of epoch 31: loss -7.21810 acc 0.65789 roc_auc 0.71077 prc_auc 0.81155[0m
[92maverage training of epoch 32: loss -7.33005 acc 0.66667 roc_auc 0.44290 prc_auc 0.60965[0m
[93maverage test of epoch 32: loss -7.38006 acc 0.65789 roc_auc 0.47846 prc_auc 0.68879[0m
[92maverage training of epoch 33: loss -7.49770 acc 0.66667 roc_auc 0.39480 prc_auc 0.58641[0m
[93maverage test of epoch 33: loss -7.54687 acc 0.65789 roc_auc 0.45538 prc_auc 0.68681[0m
[92maverage training of epoch 34: loss -7.66452 acc 0.66667 roc_auc 0.38390 prc_auc 0.58015[0m
[93maverage test of epoch 34: loss -7.71302 acc 0.65789 roc_auc 0.52769 prc_auc 0.66652[0m
[92maverage training of epoch 35: loss -7.82979 acc 0.66667 roc_auc 0.41700 prc_auc 0.61912[0m
[93maverage test of epoch 35: loss -7.87917 acc 0.65789 roc_auc 0.48000 prc_auc 0.65644[0m
[92maverage training of epoch 36: loss -7.99786 acc 0.66667 roc_auc 0.37330 prc_auc 0.58705[0m
[93maverage test of epoch 36: loss -8.04547 acc 0.65789 roc_auc 0.44615 prc_auc 0.66471[0m
[92maverage training of epoch 37: loss -8.16583 acc 0.66667 roc_auc 0.38070 prc_auc 0.59668[0m
[93maverage test of epoch 37: loss -8.21045 acc 0.65789 roc_auc 0.43385 prc_auc 0.68501[0m
[92maverage training of epoch 38: loss -8.33239 acc 0.66667 roc_auc 0.43350 prc_auc 0.62558[0m
[93maverage test of epoch 38: loss -8.37907 acc 0.65789 roc_auc 0.49846 prc_auc 0.66649[0m
[92maverage training of epoch 39: loss -8.49958 acc 0.66667 roc_auc 0.40270 prc_auc 0.60240[0m
[93maverage test of epoch 39: loss -8.54711 acc 0.65789 roc_auc 0.48615 prc_auc 0.67476[0m
[92maverage training of epoch 40: loss -8.66615 acc 0.66667 roc_auc 0.36840 prc_auc 0.57131[0m
[93maverage test of epoch 40: loss -8.71036 acc 0.65789 roc_auc 0.43385 prc_auc 0.63208[0m
[92maverage training of epoch 41: loss -8.83249 acc 0.66667 roc_auc 0.39540 prc_auc 0.58063[0m
[93maverage test of epoch 41: loss -8.87695 acc 0.65789 roc_auc 0.45231 prc_auc 0.65979[0m
[92maverage training of epoch 42: loss -8.99959 acc 0.66667 roc_auc 0.40350 prc_auc 0.59894[0m
[93maverage test of epoch 42: loss -9.04401 acc 0.65789 roc_auc 0.52462 prc_auc 0.67687[0m
[92maverage training of epoch 43: loss -9.16641 acc 0.66667 roc_auc 0.39950 prc_auc 0.60393[0m
[93maverage test of epoch 43: loss -9.20825 acc 0.65789 roc_auc 0.39385 prc_auc 0.62865[0m
[92maverage training of epoch 44: loss -9.33274 acc 0.66667 roc_auc 0.39590 prc_auc 0.59066[0m
[93maverage test of epoch 44: loss -9.37707 acc 0.65789 roc_auc 0.63538 prc_auc 0.76702[0m
[92maverage training of epoch 45: loss -9.49839 acc 0.66667 roc_auc 0.39000 prc_auc 0.58708[0m
[93maverage test of epoch 45: loss -9.53998 acc 0.65789 roc_auc 0.41077 prc_auc 0.62215[0m
[92maverage training of epoch 46: loss -9.66463 acc 0.66667 roc_auc 0.37760 prc_auc 0.57893[0m
[93maverage test of epoch 46: loss -9.70795 acc 0.65789 roc_auc 0.64923 prc_auc 0.76920[0m
[92maverage training of epoch 47: loss -9.82986 acc 0.66667 roc_auc 0.38610 prc_auc 0.58986[0m
[93maverage test of epoch 47: loss -9.87341 acc 0.65789 roc_auc 0.54769 prc_auc 0.68989[0m
[92maverage training of epoch 48: loss -9.99693 acc 0.66667 roc_auc 0.39440 prc_auc 0.59539[0m
[93maverage test of epoch 48: loss -10.03848 acc 0.65789 roc_auc 0.53538 prc_auc 0.70779[0m
[92maverage training of epoch 49: loss -10.16390 acc 0.66667 roc_auc 0.39180 prc_auc 0.59765[0m
[93maverage test of epoch 49: loss -10.20500 acc 0.65789 roc_auc 0.66615 prc_auc 0.74692[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss 0.47699 acc 0.60927 roc_auc 0.43765 prc_auc 0.60598[0m
[93maverage test of epoch 0: loss 0.34603 acc 0.64865 roc_auc 0.56333 prc_auc 0.71568[0m
[92maverage training of epoch 1: loss 0.28434 acc 0.66887 roc_auc 0.43059 prc_auc 0.62647[0m
[93maverage test of epoch 1: loss 0.14986 acc 0.67568 roc_auc 0.63667 prc_auc 0.77808[0m
[92maverage training of epoch 2: loss 0.09766 acc 0.66225 roc_auc 0.51235 prc_auc 0.67518[0m
[93maverage test of epoch 2: loss 0.00799 acc 0.67568 roc_auc 0.40333 prc_auc 0.62416[0m
[92maverage training of epoch 3: loss -0.08305 acc 0.66225 roc_auc 0.42392 prc_auc 0.61102[0m
[93maverage test of epoch 3: loss -0.27579 acc 0.67568 roc_auc 0.45667 prc_auc 0.66179[0m
[92maverage training of epoch 4: loss -0.44644 acc 0.66225 roc_auc 0.45549 prc_auc 0.65247[0m
[93maverage test of epoch 4: loss -0.69296 acc 0.67568 roc_auc 0.55000 prc_auc 0.77979[0m
[92maverage training of epoch 5: loss -0.91332 acc 0.66225 roc_auc 0.44020 prc_auc 0.62191[0m
[93maverage test of epoch 5: loss -1.21680 acc 0.67568 roc_auc 0.46333 prc_auc 0.70920[0m
[92maverage training of epoch 6: loss -1.34537 acc 0.66225 roc_auc 0.47471 prc_auc 0.64202[0m
[93maverage test of epoch 6: loss -1.61270 acc 0.67568 roc_auc 0.61000 prc_auc 0.79083[0m
[92maverage training of epoch 7: loss -1.64517 acc 0.66225 roc_auc 0.35333 prc_auc 0.56025[0m
[93maverage test of epoch 7: loss -1.90374 acc 0.67568 roc_auc 0.67000 prc_auc 0.78805[0m
[92maverage training of epoch 8: loss -1.93672 acc 0.66225 roc_auc 0.51971 prc_auc 0.65788[0m
[93maverage test of epoch 8: loss -2.15817 acc 0.67568 roc_auc 0.64333 prc_auc 0.72496[0m
[92maverage training of epoch 9: loss -2.15510 acc 0.66225 roc_auc 0.52882 prc_auc 0.66291[0m
[93maverage test of epoch 9: loss -2.34722 acc 0.67568 roc_auc 0.36333 prc_auc 0.61942[0m
[92maverage training of epoch 10: loss -2.36684 acc 0.66225 roc_auc 0.51176 prc_auc 0.67886[0m
[93maverage test of epoch 10: loss -2.54102 acc 0.67568 roc_auc 0.46000 prc_auc 0.72175[0m
[92maverage training of epoch 11: loss -2.57330 acc 0.66225 roc_auc 0.50912 prc_auc 0.68580[0m
[93maverage test of epoch 11: loss -2.74859 acc 0.67568 roc_auc 0.47000 prc_auc 0.69493[0m
[92maverage training of epoch 12: loss -2.80164 acc 0.66225 roc_auc 0.56265 prc_auc 0.68142[0m
[93maverage test of epoch 12: loss -2.99696 acc 0.67568 roc_auc 0.47667 prc_auc 0.68847[0m
[92maverage training of epoch 13: loss -3.07420 acc 0.66225 roc_auc 0.58000 prc_auc 0.76457[0m
[93maverage test of epoch 13: loss -3.34169 acc 0.67568 roc_auc 0.50667 prc_auc 0.77461[0m
[92maverage training of epoch 14: loss -3.52198 acc 0.66225 roc_auc 0.61853 prc_auc 0.75301[0m
[93maverage test of epoch 14: loss -3.83495 acc 0.67568 roc_auc 0.54000 prc_auc 0.75055[0m
[92maverage training of epoch 15: loss -3.92222 acc 0.66225 roc_auc 0.57765 prc_auc 0.70757[0m
[93maverage test of epoch 15: loss -4.15431 acc 0.67568 roc_auc 0.68667 prc_auc 0.83051[0m
[92maverage training of epoch 16: loss -4.21647 acc 0.66225 roc_auc 0.64755 prc_auc 0.76903[0m
[93maverage test of epoch 16: loss -4.45537 acc 0.67568 roc_auc 0.56667 prc_auc 0.76595[0m
[92maverage training of epoch 17: loss -4.47131 acc 0.66225 roc_auc 0.66353 prc_auc 0.76824[0m
[93maverage test of epoch 17: loss -4.69111 acc 0.67568 roc_auc 0.54667 prc_auc 0.75518[0m
[92maverage training of epoch 18: loss -4.71309 acc 0.66225 roc_auc 0.62196 prc_auc 0.74352[0m
[93maverage test of epoch 18: loss -4.91207 acc 0.67568 roc_auc 0.65000 prc_auc 0.80599[0m
[92maverage training of epoch 19: loss -4.93516 acc 0.66225 roc_auc 0.63588 prc_auc 0.75644[0m
[93maverage test of epoch 19: loss -5.12530 acc 0.67568 roc_auc 0.72333 prc_auc 0.85980[0m
[92maverage training of epoch 20: loss -5.12412 acc 0.66225 roc_auc 0.62608 prc_auc 0.73019[0m
[93maverage test of epoch 20: loss -5.31372 acc 0.67568 roc_auc 0.64500 prc_auc 0.79738[0m
[92maverage training of epoch 21: loss -5.33915 acc 0.66225 roc_auc 0.58343 prc_auc 0.70689[0m
[93maverage test of epoch 21: loss -5.51922 acc 0.67568 roc_auc 0.52000 prc_auc 0.74649[0m
[92maverage training of epoch 22: loss -5.53152 acc 0.66225 roc_auc 0.60392 prc_auc 0.70747[0m
[93maverage test of epoch 22: loss -5.71380 acc 0.67568 roc_auc 0.65500 prc_auc 0.82922[0m
[92maverage training of epoch 23: loss -5.71615 acc 0.66225 roc_auc 0.55206 prc_auc 0.75723[0m
[93maverage test of epoch 23: loss -5.89716 acc 0.67568 roc_auc 0.50833 prc_auc 0.76776[0m
[92maverage training of epoch 24: loss -5.90173 acc 0.66225 roc_auc 0.49990 prc_auc 0.66502[0m
[93maverage test of epoch 24: loss -6.07511 acc 0.67568 roc_auc 0.47833 prc_auc 0.74323[0m
[92maverage training of epoch 25: loss -6.08353 acc 0.66225 roc_auc 0.53549 prc_auc 0.67175[0m
[93maverage test of epoch 25: loss -6.26775 acc 0.67568 roc_auc 0.67667 prc_auc 0.84342[0m
[92maverage training of epoch 26: loss -6.26957 acc 0.66225 roc_auc 0.47029 prc_auc 0.62793[0m
[93maverage test of epoch 26: loss -6.46745 acc 0.67568 roc_auc 0.70000 prc_auc 0.84752[0m
[92maverage training of epoch 27: loss -6.44819 acc 0.66225 roc_auc 0.40137 prc_auc 0.58648[0m
[93maverage test of epoch 27: loss -6.62589 acc 0.67568 roc_auc 0.58000 prc_auc 0.80885[0m
[92maverage training of epoch 28: loss -6.63092 acc 0.66225 roc_auc 0.45343 prc_auc 0.62085[0m
[93maverage test of epoch 28: loss -6.80884 acc 0.67568 roc_auc 0.52833 prc_auc 0.79202[0m
[92maverage training of epoch 29: loss -6.80114 acc 0.66225 roc_auc 0.52245 prc_auc 0.66777[0m
[93maverage test of epoch 29: loss -6.98900 acc 0.67568 roc_auc 0.57667 prc_auc 0.79873[0m
[92maverage training of epoch 30: loss -6.97709 acc 0.66225 roc_auc 0.55755 prc_auc 0.67952[0m
[93maverage test of epoch 30: loss -7.15891 acc 0.67568 roc_auc 0.49500 prc_auc 0.74120[0m
[92maverage training of epoch 31: loss -7.15370 acc 0.66225 roc_auc 0.46020 prc_auc 0.63126[0m
[93maverage test of epoch 31: loss -7.33681 acc 0.67568 roc_auc 0.62833 prc_auc 0.81189[0m
[92maverage training of epoch 32: loss -7.32430 acc 0.66225 roc_auc 0.37843 prc_auc 0.58915[0m
[93maverage test of epoch 32: loss -7.50766 acc 0.67568 roc_auc 0.54500 prc_auc 0.78588[0m
[92maverage training of epoch 33: loss -7.49458 acc 0.66225 roc_auc 0.35990 prc_auc 0.57317[0m
[93maverage test of epoch 33: loss -7.68557 acc 0.67568 roc_auc 0.58167 prc_auc 0.70607[0m
[92maverage training of epoch 34: loss -7.66965 acc 0.66225 roc_auc 0.44333 prc_auc 0.62899[0m
[93maverage test of epoch 34: loss -7.85839 acc 0.67568 roc_auc 0.64167 prc_auc 0.76999[0m
[92maverage training of epoch 35: loss -7.83854 acc 0.66225 roc_auc 0.37206 prc_auc 0.58307[0m
[93maverage test of epoch 35: loss -8.02831 acc 0.67568 roc_auc 0.44667 prc_auc 0.69476[0m
[92maverage training of epoch 36: loss -8.01514 acc 0.66225 roc_auc 0.45882 prc_auc 0.63572[0m
[93maverage test of epoch 36: loss -8.19375 acc 0.67568 roc_auc 0.54333 prc_auc 0.70152[0m
[92maverage training of epoch 37: loss -8.18216 acc 0.66225 roc_auc 0.40490 prc_auc 0.60047[0m
[93maverage test of epoch 37: loss -8.37174 acc 0.67568 roc_auc 0.56333 prc_auc 0.74259[0m
[92maverage training of epoch 38: loss -8.35180 acc 0.66225 roc_auc 0.42451 prc_auc 0.60080[0m
[93maverage test of epoch 38: loss -8.54118 acc 0.67568 roc_auc 0.54333 prc_auc 0.73582[0m
[92maverage training of epoch 39: loss -8.52189 acc 0.66225 roc_auc 0.39667 prc_auc 0.58162[0m
[93maverage test of epoch 39: loss -8.71344 acc 0.67568 roc_auc 0.56000 prc_auc 0.69223[0m
[92maverage training of epoch 40: loss -8.69212 acc 0.66225 roc_auc 0.35686 prc_auc 0.56573[0m
[93maverage test of epoch 40: loss -8.88292 acc 0.67568 roc_auc 0.40000 prc_auc 0.62107[0m
[92maverage training of epoch 41: loss -8.86023 acc 0.66225 roc_auc 0.39304 prc_auc 0.58705[0m
[93maverage test of epoch 41: loss -9.05105 acc 0.67568 roc_auc 0.51833 prc_auc 0.74785[0m
[92maverage training of epoch 42: loss -9.03009 acc 0.66225 roc_auc 0.41294 prc_auc 0.58798[0m
[93maverage test of epoch 42: loss -9.22025 acc 0.67568 roc_auc 0.46833 prc_auc 0.68888[0m
[92maverage training of epoch 43: loss -9.19991 acc 0.66225 roc_auc 0.41745 prc_auc 0.60174[0m
[93maverage test of epoch 43: loss -9.38873 acc 0.67568 roc_auc 0.59333 prc_auc 0.76286[0m
[92maverage training of epoch 44: loss -9.36749 acc 0.66225 roc_auc 0.41490 prc_auc 0.59642[0m
[93maverage test of epoch 44: loss -9.56125 acc 0.67568 roc_auc 0.47333 prc_auc 0.64261[0m
[92maverage training of epoch 45: loss -9.53425 acc 0.66225 roc_auc 0.38824 prc_auc 0.58661[0m
[93maverage test of epoch 45: loss -9.72779 acc 0.67568 roc_auc 0.30500 prc_auc 0.60936[0m
[92maverage training of epoch 46: loss -9.70305 acc 0.66225 roc_auc 0.41539 prc_auc 0.60456[0m
[93maverage test of epoch 46: loss -9.89997 acc 0.67568 roc_auc 0.55667 prc_auc 0.72330[0m
[92maverage training of epoch 47: loss -9.86951 acc 0.66225 roc_auc 0.38676 prc_auc 0.58647[0m
[93maverage test of epoch 47: loss -10.06643 acc 0.67568 roc_auc 0.36833 prc_auc 0.61019[0m
[92maverage training of epoch 48: loss -10.03965 acc 0.66225 roc_auc 0.39353 prc_auc 0.57505[0m
[93maverage test of epoch 48: loss -10.23568 acc 0.67568 roc_auc 0.48833 prc_auc 0.69981[0m
[92maverage training of epoch 49: loss -10.20781 acc 0.66225 roc_auc 0.36471 prc_auc 0.56226[0m
[93maverage test of epoch 49: loss -10.40405 acc 0.67568 roc_auc 0.49500 prc_auc 0.68177[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.30119 acc 0.33775 roc_auc 0.46275 prc_auc 0.67926[0m
[93maverage test of epoch 0: loss -0.62628 acc 0.32432 roc_auc 0.45333 prc_auc 0.68972[0m
[92maverage training of epoch 1: loss -0.96282 acc 0.45033 roc_auc 0.46863 prc_auc 0.65573[0m
[93maverage test of epoch 1: loss -1.28202 acc 0.67568 roc_auc 0.62333 prc_auc 0.80435[0m
[92maverage training of epoch 2: loss -1.55898 acc 0.66225 roc_auc 0.50020 prc_auc 0.71596[0m
[93maverage test of epoch 2: loss -1.84648 acc 0.67568 roc_auc 0.67667 prc_auc 0.85061[0m
[92maverage training of epoch 3: loss -2.02560 acc 0.66225 roc_auc 0.47686 prc_auc 0.67186[0m
[93maverage test of epoch 3: loss -2.22185 acc 0.67568 roc_auc 0.44333 prc_auc 0.67973[0m
[92maverage training of epoch 4: loss -2.35402 acc 0.66225 roc_auc 0.50314 prc_auc 0.67253[0m
[93maverage test of epoch 4: loss -2.51689 acc 0.67568 roc_auc 0.45333 prc_auc 0.72290[0m
[92maverage training of epoch 5: loss -2.62417 acc 0.66225 roc_auc 0.48137 prc_auc 0.69387[0m
[93maverage test of epoch 5: loss -2.78859 acc 0.67568 roc_auc 0.69667 prc_auc 0.81353[0m
[92maverage training of epoch 6: loss -2.86931 acc 0.66225 roc_auc 0.46078 prc_auc 0.67416[0m
[93maverage test of epoch 6: loss -3.01028 acc 0.67568 roc_auc 0.48333 prc_auc 0.73001[0mUsing backend: pytorch

[92maverage training of epoch 7: loss -3.09387 acc 0.66225 roc_auc 0.38980 prc_auc 0.59446[0m
[93maverage test of epoch 7: loss -3.23177 acc 0.67568 roc_auc 0.54667 prc_auc 0.77204[0m
[92maverage training of epoch 8: loss -3.31007 acc 0.66225 roc_auc 0.51118 prc_auc 0.67128[0m
[93maverage test of epoch 8: loss -3.44922 acc 0.67568 roc_auc 0.70333 prc_auc 0.86430[0m
[92maverage training of epoch 9: loss -3.51409 acc 0.66225 roc_auc 0.50922 prc_auc 0.67614[0m
[93maverage test of epoch 9: loss -3.64933 acc 0.67568 roc_auc 0.61333 prc_auc 0.81878[0m
[92maverage training of epoch 10: loss -3.70639 acc 0.66225 roc_auc 0.46824 prc_auc 0.66057[0m
[93maverage test of epoch 10: loss -3.84035 acc 0.67568 roc_auc 0.58667 prc_auc 0.74624[0m
[92maverage training of epoch 11: loss -3.90135 acc 0.66225 roc_auc 0.50745 prc_auc 0.65538[0m
[93maverage test of epoch 11: loss -4.03136 acc 0.67568 roc_auc 0.61333 prc_auc 0.80326[0m
[92maverage training of epoch 12: loss -4.08728 acc 0.66225 roc_auc 0.42745 prc_auc 0.61184[0m
[93maverage test of epoch 12: loss -4.21734 acc 0.67568 roc_auc 0.55667 prc_auc 0.73882[0m
[92maverage training of epoch 13: loss -4.26288 acc 0.66225 roc_auc 0.42980 prc_auc 0.61777[0m
[93maverage test of epoch 13: loss -4.39447 acc 0.67568 roc_auc 0.56000 prc_auc 0.71826[0m
[92maverage training of epoch 14: loss -4.45155 acc 0.66225 roc_auc 0.47157 prc_auc 0.65578[0m
[93maverage test of epoch 14: loss -4.57487 acc 0.67568 roc_auc 0.49000 prc_auc 0.67454[0m
[92maverage training of epoch 15: loss -4.62822 acc 0.66225 roc_auc 0.42078 prc_auc 0.59593[0m
[93maverage test of epoch 15: loss -4.76407 acc 0.67568 roc_auc 0.63833 prc_auc 0.77317[0m
[92maverage training of epoch 16: loss -4.80423 acc 0.66225 roc_auc 0.42196 prc_auc 0.59371[0m
[93maverage test of epoch 16: loss -4.92962 acc 0.67568 roc_auc 0.45833 prc_auc 0.69882[0m
[92maverage training of epoch 17: loss -4.98336 acc 0.66225 roc_auc 0.38137 prc_auc 0.59372[0m
[93maverage test of epoch 17: loss -5.11008 acc 0.67568 roc_auc 0.49000 prc_auc 0.67990[0m
[92maverage training of epoch 18: loss -5.15437 acc 0.66225 roc_auc 0.40667 prc_auc 0.59695[0m
[93maverage test of epoch 18: loss -5.28701 acc 0.67568 roc_auc 0.44667 prc_auc 0.73211[0m
[92maverage training of epoch 19: loss -5.32968 acc 0.66225 roc_auc 0.42196 prc_auc 0.59546[0m
[93maverage test of epoch 19: loss -5.45530 acc 0.67568 roc_auc 0.41667 prc_auc 0.71609[0m
[92maverage training of epoch 20: loss -5.50581 acc 0.66225 roc_auc 0.42961 prc_auc 0.60613[0m
[93maverage test of epoch 20: loss -5.63696 acc 0.67568 roc_auc 0.49000 prc_auc 0.72933[0m
[92maverage training of epoch 21: loss -5.67254 acc 0.66225 roc_auc 0.38863 prc_auc 0.60127[0m
[93maverage test of epoch 21: loss -5.80802 acc 0.67568 roc_auc 0.55833 prc_auc 0.73789[0m
[92maverage training of epoch 22: loss -5.84879 acc 0.66225 roc_auc 0.42471 prc_auc 0.59926[0m
[93maverage test of epoch 22: loss -5.97814 acc 0.67568 roc_auc 0.58000 prc_auc 0.76114[0m
[92maverage training of epoch 23: loss -6.01818 acc 0.66225 roc_auc 0.43235 prc_auc 0.61421[0m
[93maverage test of epoch 23: loss -6.14914 acc 0.67568 roc_auc 0.52333 prc_auc 0.75805[0m
[92maverage training of epoch 24: loss -6.18745 acc 0.66225 roc_auc 0.38922 prc_auc 0.56901[0m
[93maverage test of epoch 24: loss -6.32259 acc 0.67568 roc_auc 0.60500 prc_auc 0.81055[0m
[92maverage training of epoch 25: loss -6.35796 acc 0.66225 roc_auc 0.36549 prc_auc 0.56215[0m
[93maverage test of epoch 25: loss -6.49720 acc 0.67568 roc_auc 0.61500 prc_auc 0.81376[0m
[92maverage training of epoch 26: loss -6.52821 acc 0.66225 roc_auc 0.42882 prc_auc 0.61158[0m
[93maverage test of epoch 26: loss -6.66713 acc 0.67568 roc_auc 0.52833 prc_auc 0.73679[0m
[92maverage training of epoch 27: loss -6.69718 acc 0.66225 roc_auc 0.36314 prc_auc 0.55826[0m
[93maverage test of epoch 27: loss -6.83329 acc 0.67568 roc_auc 0.42333 prc_auc 0.71242[0m
[92maverage training of epoch 28: loss -6.86865 acc 0.66225 roc_auc 0.41098 prc_auc 0.59297[0m
[93maverage test of epoch 28: loss -6.99588 acc 0.67568 roc_auc 0.15833 prc_auc 0.51069[0m
[92maverage training of epoch 29: loss -7.03636 acc 0.66225 roc_auc 0.41745 prc_auc 0.60234[0m
[93maverage test of epoch 29: loss -7.17065 acc 0.67568 roc_auc 0.66833 prc_auc 0.80859[0m
[92maverage training of epoch 30: loss -7.20481 acc 0.66225 roc_auc 0.38020 prc_auc 0.56978[0m
[93maverage test of epoch 30: loss -7.34280 acc 0.67568 roc_auc 0.71500 prc_auc 0.84000[0m
[92maverage training of epoch 31: loss -7.37252 acc 0.66225 roc_auc 0.41745 prc_auc 0.59082[0m
[93maverage test of epoch 31: loss -7.50708 acc 0.67568 roc_auc 0.25833 prc_auc 0.59654[0m
[92maverage training of epoch 32: loss -7.54087 acc 0.66225 roc_auc 0.40304 prc_auc 0.58172[0m
[93maverage test of epoch 32: loss -7.67801 acc 0.67568 roc_auc 0.40500 prc_auc 0.67552[0m
[92maverage training of epoch 33: loss -7.70811 acc 0.66225 roc_auc 0.39216 prc_auc 0.58030[0m
[93maverage test of epoch 33: loss -7.84735 acc 0.67568 roc_auc 0.62667 prc_auc 0.78434[0m
[92maverage training of epoch 34: loss -7.87610 acc 0.66225 roc_auc 0.41059 prc_auc 0.58926[0m
[93maverage test of epoch 34: loss -8.01636 acc 0.67568 roc_auc 0.53667 prc_auc 0.72101[0m
[92maverage training of epoch 35: loss -8.04489 acc 0.66225 roc_auc 0.36000 prc_auc 0.55825[0m
[93maverage test of epoch 35: loss -8.18220 acc 0.67568 roc_auc 0.35500 prc_auc 0.64422[0m
[92maverage training of epoch 36: loss -8.21073 acc 0.66225 roc_auc 0.34745 prc_auc 0.55209[0m
[93maverage test of epoch 36: loss -8.35415 acc 0.67568 roc_auc 0.63833 prc_auc 0.82287[0m
[92maverage training of epoch 37: loss -8.37953 acc 0.66225 roc_auc 0.37059 prc_auc 0.56581[0m
[93maverage test of epoch 37: loss -8.52236 acc 0.67568 roc_auc 0.49167 prc_auc 0.67785[0m
[92maverage training of epoch 38: loss -8.54583 acc 0.66225 roc_auc 0.37441 prc_auc 0.57857[0m
[93maverage test of epoch 38: loss -8.68906 acc 0.67568 roc_auc 0.63167 prc_auc 0.75830[0m
[92maverage training of epoch 39: loss -8.71348 acc 0.66225 roc_auc 0.35412 prc_auc 0.56104[0m
[93maverage test of epoch 39: loss -8.85615 acc 0.67568 roc_auc 0.61500 prc_auc 0.75057[0m
[92maverage training of epoch 40: loss -8.88109 acc 0.66225 roc_auc 0.36176 prc_auc 0.56260[0m
[93maverage test of epoch 40: loss -9.02562 acc 0.67568 roc_auc 0.29667 prc_auc 0.65583[0m
[92maverage training of epoch 41: loss -9.04764 acc 0.66225 roc_auc 0.37412 prc_auc 0.57008[0m
[93maverage test of epoch 41: loss -9.19380 acc 0.67568 roc_auc 0.48000 prc_auc 0.68633[0m
[92maverage training of epoch 42: loss -9.21567 acc 0.66225 roc_auc 0.37451 prc_auc 0.57048[0m
[93maverage test of epoch 42: loss -9.36147 acc 0.67568 roc_auc 0.63000 prc_auc 0.81946[0m
[92maverage training of epoch 43: loss -9.38312 acc 0.66225 roc_auc 0.35951 prc_auc 0.56515[0m
[93maverage test of epoch 43: loss -9.52902 acc 0.67568 roc_auc 0.48667 prc_auc 0.69038[0m
[92maverage training of epoch 44: loss -9.54992 acc 0.66225 roc_auc 0.36314 prc_auc 0.56146[0m
[93maverage test of epoch 44: loss -9.69517 acc 0.67568 roc_auc 0.58667 prc_auc 0.73375[0m
[92maverage training of epoch 45: loss -9.71747 acc 0.66225 roc_auc 0.39294 prc_auc 0.58511[0m
[93maverage test of epoch 45: loss -9.86354 acc 0.67568 roc_auc 0.64833 prc_auc 0.78013[0m
[92maverage training of epoch 46: loss -9.88374 acc 0.66225 roc_auc 0.37333 prc_auc 0.57241[0m
[93maverage test of epoch 46: loss -10.03197 acc 0.67568 roc_auc 0.49000 prc_auc 0.66426[0m
[92maverage training of epoch 47: loss -10.05040 acc 0.66225 roc_auc 0.35471 prc_auc 0.56171[0m
[93maverage test of epoch 47: loss -10.19742 acc 0.67568 roc_auc 0.47667 prc_auc 0.71855[0m
[92maverage training of epoch 48: loss -10.21828 acc 0.66225 roc_auc 0.37637 prc_auc 0.58038[0m
[93maverage test of epoch 48: loss -10.36641 acc 0.67568 roc_auc 0.66167 prc_auc 0.77694[0m
[92maverage training of epoch 49: loss -10.38520 acc 0.66225 roc_auc 0.37647 prc_auc 0.58419[0m
[93maverage test of epoch 49: loss -10.53459 acc 0.67568 roc_auc 0.37833 prc_auc 0.60672[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.0003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.66501 ROC_AUC (avg): 0.48913 PRC_AUC (avg): 0.66844 

Average forward propagation time taken(ms): 3.9793998720990316
Average backward propagation time taken(ms): 1.516362424099748

