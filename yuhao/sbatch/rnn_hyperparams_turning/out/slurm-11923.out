# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-22-49-37/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-22-49-37/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 16,
 'epochs': 50,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 8,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.003,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 2,
 'num_workers': 8,
 'number_of_mlp_layer': 0,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-17-22-49-37',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 50, 'learning_rate': 0.003, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.003
[92maverage training of epoch 0: loss -2.67982 acc 0.66667 roc_auc 0.41880 prc_auc 0.61688[0m
[93maverage test of epoch 0: loss -4.50634 acc 0.65789 roc_auc 0.53846 prc_auc 0.72519[0m
[92maverage training of epoch 1: loss -6.08701 acc 0.63333 roc_auc 0.51780 prc_auc 0.67240[0m
[93maverage test of epoch 1: loss -8.16186 acc 0.65789 roc_auc 0.66769 prc_auc 0.82774[0m
[92maverage training of epoch 2: loss -9.91581 acc 0.66667 roc_auc 0.36320 prc_auc 0.56543[0m
[93maverage test of epoch 2: loss -11.61440 acc 0.65789 roc_auc 0.61231 prc_auc 0.79319[0m
[92maverage training of epoch 3: loss -13.24537 acc 0.66667 roc_auc 0.35940 prc_auc 0.56482[0m
[93maverage test of epoch 3: loss -14.84687 acc 0.65789 roc_auc 0.54462 prc_auc 0.72792[0m
[92maverage training of epoch 4: loss -16.43748 acc 0.66667 roc_auc 0.35720 prc_auc 0.56224[0m
[93maverage test of epoch 4: loss -17.99037 acc 0.65789 roc_auc 0.49692 prc_auc 0.70562[0m
[92maverage training of epoch 5: loss -19.56559 acc 0.66667 roc_auc 0.35810 prc_auc 0.56306[0m
[93maverage test of epoch 5: loss -21.08676 acc 0.65789 roc_auc 0.59692 prc_auc 0.74455[0m
[92maverage training of epoch 6: loss -22.65472 acc 0.66667 roc_auc 0.35870 prc_auc 0.56340[0m
[93maverage test of epoch 6: loss -24.15094 acc 0.65789 roc_auc 0.68923 prc_auc 0.82762[0m
[92maverage training of epoch 7: loss -25.71975 acc 0.66667 roc_auc 0.35940 prc_auc 0.56392[0m
[93maverage test of epoch 7: loss -27.19842 acc 0.65789 roc_auc 0.41692 prc_auc 0.62047[0m
[92maverage training of epoch 8: loss -28.76718 acc 0.66667 roc_auc 0.35710 prc_auc 0.56315[0m
[93maverage test of epoch 8: loss -30.22859 acc 0.65789 roc_auc 0.36615 prc_auc 0.60173[0m
[92maverage training of epoch 9: loss -31.80100 acc 0.66667 roc_auc 0.35870 prc_auc 0.56325[0m
[93maverage test of epoch 9: loss -33.25021 acc 0.65789 roc_auc 0.47692 prc_auc 0.64762[0m
[92maverage training of epoch 10: loss -34.82585 acc 0.66667 roc_auc 0.35730 prc_auc 0.56566[0m
[93maverage test of epoch 10: loss -36.26233 acc 0.65789 roc_auc 0.46000 prc_auc 0.64041[0m
[92maverage training of epoch 11: loss -37.84234 acc 0.66667 roc_auc 0.35930 prc_auc 0.56953[0m
[93maverage test of epoch 11: loss -39.26753 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 12: loss -40.85377 acc 0.66667 roc_auc 0.36610 prc_auc 0.58248[0m
[93maverage test of epoch 12: loss -42.26789 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 13: loss -43.86012 acc 0.66667 roc_auc 0.36470 prc_auc 0.59724[0m
[93maverage test of epoch 13: loss -45.26285 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 14: loss -46.86226 acc 0.66667 roc_auc 0.42420 prc_auc 0.63010[0m
[93maverage test of epoch 14: loss -48.25538 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 15: loss -49.86154 acc 0.66667 roc_auc 0.44500 prc_auc 0.64328[0m
[93maverage test of epoch 15: loss -51.24388 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 16: loss -52.85777 acc 0.66667 roc_auc 0.45000 prc_auc 0.64543[0m
[93maverage test of epoch 16: loss -54.23089 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 17: loss -55.85229 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 17: loss -57.21558 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 18: loss -58.84462 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 18: loss -60.19850 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -61.83530 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 19: loss -63.17997 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -64.82464 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 20: loss -66.16044 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -67.81313 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 21: loss -69.13961 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -70.80039 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 22: loss -72.11800 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -73.78690 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 23: loss -75.09551 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -76.77284 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 24: loss -78.07249 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -79.75801 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 25: loss -81.04888 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -82.74250 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 26: loss -84.02473 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -85.72652 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 27: loss -87.00025 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -88.71053 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 28: loss -89.97529 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -91.69396 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 29: loss -92.94984 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -94.67696 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 30: loss -95.92443 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -97.65990 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 31: loss -98.89863 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -100.64241 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 32: loss -101.87260 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -103.62485 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 33: loss -104.84636 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -106.60714 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -107.82000 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -109.58918 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -110.79360 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -112.57106 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -113.76672 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -115.55282 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -116.74008 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -118.53448 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -119.71287 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -121.51608 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -122.68571 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -124.49752 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -125.65901 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -127.47885 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -128.63176 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -130.46012 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -131.60445 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -133.44121 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -134.57711 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -136.42227 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -137.54951 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -139.40334 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -140.52208 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -142.38427 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -143.49427 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -145.36508 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -146.46684 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -148.34600 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -149.43909 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -151.32681 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -152.41143 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.003
[92maverage training of epoch 0: loss -4.91338 acc 0.66667 roc_auc 0.43020 prc_auc 0.61499[0m
[93maverage test of epoch 0: loss -7.53162 acc 0.65789 roc_auc 0.34462 prc_auc 0.61362[0m
[92maverage training of epoch 1: loss -9.21593 acc 0.66667 roc_auc 0.42620 prc_auc 0.60869[0m
[93maverage test of epoch 1: loss -10.82113 acc 0.65789 roc_auc 0.39692 prc_auc 0.59682[0m
[92maverage training of epoch 2: loss -12.41316 acc 0.66667 roc_auc 0.41740 prc_auc 0.60191[0m
[93maverage test of epoch 2: loss -13.94420 acc 0.65789 roc_auc 0.51846 prc_auc 0.69049[0m
[92maverage training of epoch 3: loss -15.51285 acc 0.66667 roc_auc 0.42220 prc_auc 0.60414[0m
[93maverage test of epoch 3: loss -17.01277 acc 0.65789 roc_auc 0.44923 prc_auc 0.64052[0m
[92maverage training of epoch 4: loss -18.57634 acc 0.66667 roc_auc 0.42180 prc_auc 0.60445[0m
[93maverage test of epoch 4: loss -20.05496 acc 0.65789 roc_auc 0.63385 prc_auc 0.76854[0m
[92maverage training of epoch 5: loss -21.61576 acc 0.66667 roc_auc 0.41880 prc_auc 0.60210[0m
[93maverage test of epoch 5: loss -23.07875 acc 0.65789 roc_auc 0.42308 prc_auc 0.64220[0m
[92maverage training of epoch 6: loss -24.64217 acc 0.66667 roc_auc 0.42040 prc_auc 0.60472[0m
[93maverage test of epoch 6: loss -26.09057 acc 0.65789 roc_auc 0.63231 prc_auc 0.72385[0m
[92maverage training of epoch 7: loss -27.65886 acc 0.66667 roc_auc 0.41970 prc_auc 0.60434[0m
[93maverage test of epoch 7: loss -29.09453 acc 0.65789 roc_auc 0.49846 prc_auc 0.65720[0m
[92maverage training of epoch 8: loss -30.66884 acc 0.66667 roc_auc 0.42080 prc_auc 0.60485[0m
[93maverage test of epoch 8: loss -32.09281 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 9: loss -33.67321 acc 0.66667 roc_auc 0.41970 prc_auc 0.60120[0m
[93maverage test of epoch 9: loss -35.08730 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 10: loss -36.67448 acc 0.66667 roc_auc 0.43140 prc_auc 0.61437[0m
[93maverage test of epoch 10: loss -38.07811 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 11: loss -39.67119 acc 0.66667 roc_auc 0.43230 prc_auc 0.62078[0m
[93maverage test of epoch 11: loss -41.06534 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 12: loss -42.66698 acc 0.66667 roc_auc 0.45060 prc_auc 0.64093[0m
[93maverage test of epoch 12: loss -44.04963 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 13: loss -45.65969 acc 0.66667 roc_auc 0.49000 prc_auc 0.66226[0m
[93maverage test of epoch 13: loss -47.03393 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 14: loss -48.65079 acc 0.66667 roc_auc 0.46500 prc_auc 0.65167[0m
[93maverage test of epoch 14: loss -50.01524 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 15: loss -51.64076 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 15: loss -52.99653 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 16: loss -54.62917 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 16: loss -55.97536 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 17: loss -57.61694 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 17: loss -58.95452 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 18: loss -60.60378 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 18: loss -61.93279 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -63.58986 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 19: loss -64.90956 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -66.57518 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 20: loss -67.88669 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -69.56025 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 21: loss -70.86197 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -72.54457 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 22: loss -73.83857 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -75.52859 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 23: loss -76.81351 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -78.51259 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 24: loss -79.78921 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -81.49599 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 25: loss -82.76376 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -84.47932 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 26: loss -85.73800 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -87.46210 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 27: loss -88.71275 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -90.44486 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 28: loss -91.68678 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -93.42748 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 29: loss -94.66093 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -96.40991 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 30: loss -97.63448 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -99.39215 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 31: loss -100.60783 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -102.37415 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 32: loss -103.58199 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -105.35635 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 33: loss -106.55521 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -108.33830 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -109.52889 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -111.32009 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -112.50201 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -114.30197 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -115.47498 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -117.28352 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -118.44824 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -120.26515 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -121.42138 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -123.24668 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -124.39418 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -126.22795 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -127.36693 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -129.20940 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -130.33994 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -132.19064 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -133.31283 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -135.17195 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -136.28540 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -138.15320 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -139.25788 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -141.13437 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -142.23070 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -144.11543 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -145.20300 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -147.09650 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -148.17579 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -150.07744 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -151.14826 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -153.05840 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -154.12070 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.003
[92maverage training of epoch 0: loss -1.73254 acc 0.56667 roc_auc 0.40900 prc_auc 0.61401[0m
[93maverage test of epoch 0: loss -3.86048 acc 0.65789 roc_auc 0.60923 prc_auc 0.70949[0m
[92maverage training of epoch 1: loss -5.80611 acc 0.66667 roc_auc 0.38100 prc_auc 0.58253[0m
[93maverage test of epoch 1: loss -7.64859 acc 0.65789 roc_auc 0.62769 prc_auc 0.76289[0m
[92maverage training of epoch 2: loss -9.32817 acc 0.66667 roc_auc 0.38690 prc_auc 0.58726[0m
[93maverage test of epoch 2: loss -10.95131 acc 0.65789 roc_auc 0.52923 prc_auc 0.72909[0m
[92maverage training of epoch 3: loss -12.56434 acc 0.66667 roc_auc 0.38040 prc_auc 0.58299[0m
[93maverage test of epoch 3: loss -14.12001 acc 0.65789 roc_auc 0.57231 prc_auc 0.69230[0m
[92maverage training of epoch 4: loss -15.70938 acc 0.66667 roc_auc 0.37620 prc_auc 0.57967[0m
[93maverage test of epoch 4: loss -17.22949 acc 0.65789 roc_auc 0.60308 prc_auc 0.76186[0m
[92maverage training of epoch 5: loss -18.80876 acc 0.66667 roc_auc 0.37580 prc_auc 0.57449[0m
[93maverage test of epoch 5: loss -20.30248 acc 0.65789 roc_auc 0.62154 prc_auc 0.74510[0m
[92maverage training of epoch 6: loss -21.87751 acc 0.66667 roc_auc 0.37860 prc_auc 0.57749[0m
[93maverage test of epoch 6: loss -23.34959 acc 0.65789 roc_auc 0.39538 prc_auc 0.61005[0m
[92maverage training of epoch 7: loss -24.92712 acc 0.66667 roc_auc 0.37840 prc_auc 0.57757[0m
[93maverage test of epoch 7: loss -26.38372 acc 0.65789 roc_auc 0.64308 prc_auc 0.73285[0m
[92maverage training of epoch 8: loss -27.96253 acc 0.66667 roc_auc 0.37950 prc_auc 0.57914[0m
[93maverage test of epoch 8: loss -29.40480 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 9: loss -30.98808 acc 0.66667 roc_auc 0.38140 prc_auc 0.58662[0m
[93maverage test of epoch 9: loss -32.41657 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 10: loss -34.00530 acc 0.66667 roc_auc 0.37380 prc_auc 0.58524[0m
[93maverage test of epoch 10: loss -35.42261 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 11: loss -37.01599 acc 0.66667 roc_auc 0.38400 prc_auc 0.59712[0m
[93maverage test of epoch 11: loss -38.42197 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 12: loss -40.02251 acc 0.66667 roc_auc 0.43510 prc_auc 0.63185[0m
[93maverage test of epoch 12: loss -41.41736 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 13: loss -43.02446 acc 0.66667 roc_auc 0.43980 prc_auc 0.63780[0m
[93maverage test of epoch 13: loss -44.40992 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 14: loss -46.02370 acc 0.66667 roc_auc 0.43500 prc_auc 0.63996[0m
[93maverage test of epoch 14: loss -47.39877 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 15: loss -49.01991 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 15: loss -50.38493 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 16: loss -52.01362 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 16: loss -53.36967 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 17: loss -55.00616 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 17: loss -56.35254 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 18: loss -57.99664 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 18: loss -59.33378 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -60.98581 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 19: loss -62.31382 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -63.97396 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 20: loss -65.29329 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -66.96118 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 21: loss -68.27128 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -69.94739 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 22: loss -71.24867 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -72.93321 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 23: loss -74.22580 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -75.91820 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 24: loss -77.20191 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -78.90280 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 25: loss -80.17758 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -81.88681 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 26: loss -83.15302 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -84.87051 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 27: loss -86.12792 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -87.85387 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 28: loss -89.10247 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -90.83684 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 29: loss -92.07696 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -93.81965 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 30: loss -95.05114 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -96.80225 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 31: loss -98.02515 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -99.78460 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 32: loss -100.99887 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -102.76669 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 33: loss -103.97237 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -105.74870 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -106.94580 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -108.73054 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -109.91906 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -111.71231 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -112.89202 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -114.69392 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -115.86527 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -117.67537 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -118.83820 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -120.65678 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -121.81108 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -123.63804 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -124.78345 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -126.61926 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -127.75655 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -129.60054 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -130.72901 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -132.58160 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -133.70143 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -135.56268 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -136.67400 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -138.54361 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -139.64655 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -141.52450 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -142.61891 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -144.50535 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -145.59128 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -147.48620 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -148.56342 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -150.46686 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -151.53562 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.003
[92maverage training of epoch 0: loss -2.25437 acc 0.58278 roc_auc 0.53353 prc_auc 0.68042[0m
[93maverage test of epoch 0: loss -4.23549 acc 0.67568 roc_auc 0.55333 prc_auc 0.79032[0m
[92maverage training of epoch 1: loss -6.21765 acc 0.66225 roc_auc 0.72157 prc_auc 0.79011[0m
[93maverage test of epoch 1: loss -8.24896 acc 0.67568 roc_auc 0.90333 prc_auc 0.95178[0m
[92maverage training of epoch 2: loss -9.68403 acc 0.66225 roc_auc 0.75275 prc_auc 0.76760[0m
[93maverage test of epoch 2: loss -11.12724 acc 0.67568 roc_auc 0.73167 prc_auc 0.82207[0m
[92maverage training of epoch 3: loss -12.65304 acc 0.66225 roc_auc 0.63098 prc_auc 0.70026[0m
[93maverage test of epoch 3: loss -14.41268 acc 0.67568 roc_auc 0.79667 prc_auc 0.84579[0m
[92maverage training of epoch 4: loss -15.88802 acc 0.66225 roc_auc 0.78922 prc_auc 0.80160[0m
[93maverage test of epoch 4: loss -17.47327 acc 0.67568 roc_auc 0.90500 prc_auc 0.95418[0m
[92maverage training of epoch 5: loss -18.84905 acc 0.66225 roc_auc 0.79882 prc_auc 0.80897[0m
[93maverage test of epoch 5: loss -20.41875 acc 0.67568 roc_auc 0.84500 prc_auc 0.88802[0m
[92maverage training of epoch 6: loss -21.79497 acc 0.66225 roc_auc 0.79873 prc_auc 0.81915[0m
[93maverage test of epoch 6: loss -23.35924 acc 0.67568 roc_auc 0.83167 prc_auc 0.87415[0m
[92maverage training of epoch 7: loss -24.69233 acc 0.66225 roc_auc 0.82431 prc_auc 0.84932[0m
[93maverage test of epoch 7: loss -26.35113 acc 0.67568 roc_auc 0.81333 prc_auc 0.86665[0m
[92maverage training of epoch 8: loss -27.64984 acc 0.66225 roc_auc 0.78020 prc_auc 0.82242[0m
[93maverage test of epoch 8: loss -29.04800 acc 0.67568 roc_auc 0.68667 prc_auc 0.77180[0m
[92maverage training of epoch 9: loss -30.52680 acc 0.66225 roc_auc 0.81000 prc_auc 0.85151[0m
[93maverage test of epoch 9: loss -32.24592 acc 0.67568 roc_auc 0.87000 prc_auc 0.90488[0m
[92maverage training of epoch 10: loss -33.43434 acc 0.66225 roc_auc 0.79873 prc_auc 0.83787[0m
[93maverage test of epoch 10: loss -34.67881 acc 0.67568 roc_auc 0.54167 prc_auc 0.69444[0m
[92maverage training of epoch 11: loss -36.03720 acc 0.66225 roc_auc 0.64931 prc_auc 0.73960[0m
[93maverage test of epoch 11: loss -38.07447 acc 0.67568 roc_auc 0.82667 prc_auc 0.87287[0m
[92maverage training of epoch 12: loss -39.03135 acc 0.66225 roc_auc 0.85078 prc_auc 0.88433[0m
[93maverage test of epoch 12: loss -40.78885 acc 0.67568 roc_auc 0.79333 prc_auc 0.84401[0m
[92maverage training of epoch 13: loss -41.93356 acc 0.66225 roc_auc 0.80882 prc_auc 0.84774[0m
[93maverage test of epoch 13: loss -43.69336 acc 0.67568 roc_auc 0.82833 prc_auc 0.87326[0m
[92maverage training of epoch 14: loss -44.90320 acc 0.66225 roc_auc 0.82000 prc_auc 0.85742[0m
[93maverage test of epoch 14: loss -46.54339 acc 0.67568 roc_auc 0.74833 prc_auc 0.81422[0m
[92maverage training of epoch 15: loss -47.74654 acc 0.66225 roc_auc 0.81471 prc_auc 0.85169[0m
[93maverage test of epoch 15: loss -49.34047 acc 0.67568 roc_auc 0.74500 prc_auc 0.81338[0m
[92maverage training of epoch 16: loss -50.65656 acc 0.66225 roc_auc 0.81843 prc_auc 0.85288[0m
[93maverage test of epoch 16: loss -52.07414 acc 0.67568 roc_auc 0.71000 prc_auc 0.78816[0m
[92maverage training of epoch 17: loss -53.38423 acc 0.66225 roc_auc 0.81510 prc_auc 0.85190[0m
[93maverage test of epoch 17: loss -54.85826 acc 0.67568 roc_auc 0.60667 prc_auc 0.72675[0m
[92maverage training of epoch 18: loss -56.34660 acc 0.66225 roc_auc 0.84059 prc_auc 0.87350[0m
[93maverage test of epoch 18: loss -57.82919 acc 0.67568 roc_auc 0.74833 prc_auc 0.81422[0m
[92maverage training of epoch 19: loss -59.25087 acc 0.66225 roc_auc 0.81961 prc_auc 0.85421[0m
[93maverage test of epoch 19: loss -60.71704 acc 0.67568 roc_auc 0.70833 prc_auc 0.78743[0m
[92maverage training of epoch 20: loss -62.18611 acc 0.66225 roc_auc 0.83206 prc_auc 0.86267[0m
[93maverage test of epoch 20: loss -63.50101 acc 0.67568 roc_auc 0.70667 prc_auc 0.78668[0m
[92maverage training of epoch 21: loss -65.22370 acc 0.66225 roc_auc 0.84186 prc_auc 0.87120[0m
[93maverage test of epoch 21: loss -66.53161 acc 0.67568 roc_auc 0.75000 prc_auc 0.81429[0m
[92maverage training of epoch 22: loss -68.17294 acc 0.66225 roc_auc 0.83186 prc_auc 0.86094[0m
[93maverage test of epoch 22: loss -69.41229 acc 0.67568 roc_auc 0.75167 prc_auc 0.81474[0m
[92maverage training of epoch 23: loss -71.20925 acc 0.66225 roc_auc 0.83618 prc_auc 0.86596[0m
[93maverage test of epoch 23: loss -72.29203 acc 0.67568 roc_auc 0.74833 prc_auc 0.80977[0m
[92maverage training of epoch 24: loss -74.03008 acc 0.66225 roc_auc 0.84814 prc_auc 0.87402[0m
[93maverage test of epoch 24: loss -75.16671 acc 0.67568 roc_auc 0.74833 prc_auc 0.80977[0m
[92maverage training of epoch 25: loss -77.10819 acc 0.66225 roc_auc 0.87000 prc_auc 0.89205[0m
[93maverage test of epoch 25: loss -77.98802 acc 0.67568 roc_auc 0.71000 prc_auc 0.78371[0m
[92maverage training of epoch 26: loss -79.84212 acc 0.66225 roc_auc 0.84990 prc_auc 0.87507[0m
[93maverage test of epoch 26: loss -80.79506 acc 0.67568 roc_auc 0.71000 prc_auc 0.78577[0m
[92maverage training of epoch 27: loss -82.90024 acc 0.66225 roc_auc 0.86000 prc_auc 0.88386[0m
[93maverage test of epoch 27: loss -83.92208 acc 0.67568 roc_auc 0.75167 prc_auc 0.80977[0m
[92maverage training of epoch 28: loss -85.76273 acc 0.66225 roc_auc 0.85980 prc_auc 0.88293[0m
[93maverage test of epoch 28: loss -86.67777 acc 0.67568 roc_auc 0.74833 prc_auc 0.80977[0m
[92maverage training of epoch 29: loss -88.77894 acc 0.66225 roc_auc 0.87127 prc_auc 0.89190[0m
[93maverage test of epoch 29: loss -89.56771 acc 0.67568 roc_auc 0.74833 prc_auc 0.80977[0m
[92maverage training of epoch 30: loss -91.64267 acc 0.66225 roc_auc 0.86186 prc_auc 0.88298[0m
[93maverage test of epoch 30: loss -92.79922 acc 0.67568 roc_auc 0.75167 prc_auc 0.80977[0m
[92maverage training of epoch 31: loss -94.50631 acc 0.66225 roc_auc 0.87441 prc_auc 0.89095[0m
[93maverage test of epoch 31: loss -95.30810 acc 0.67568 roc_auc 0.75833 prc_auc 0.81474[0m
[92maverage training of epoch 32: loss -97.36065 acc 0.66225 roc_auc 0.86098 prc_auc 0.88073[0m
[93maverage test of epoch 32: loss -98.18524 acc 0.67568 roc_auc 0.75167 prc_auc 0.80977[0m
[92maverage training of epoch 33: loss -100.20929 acc 0.66225 roc_auc 0.86588 prc_auc 0.88780[0m
[93maverage test of epoch 33: loss -101.05436 acc 0.67568 roc_auc 0.74833 prc_auc 0.80977[0m
[92maverage training of epoch 34: loss -103.26745 acc 0.66225 roc_auc 0.87137 prc_auc 0.88885[0m
[93maverage test of epoch 34: loss -103.45015 acc 0.67568 roc_auc 0.75167 prc_auc 0.80977[0m
[92maverage training of epoch 35: loss -106.01381 acc 0.66225 roc_auc 0.87216 prc_auc 0.88780[0m
[93maverage test of epoch 35: loss -106.63150 acc 0.67568 roc_auc 0.71000 prc_auc 0.78371[0m
[92maverage training of epoch 36: loss -109.07704 acc 0.66225 roc_auc 0.77412 prc_auc 0.81418[0m
[93maverage test of epoch 36: loss -109.47583 acc 0.67568 roc_auc 0.71000 prc_auc 0.78371[0m
[92maverage training of epoch 37: loss -111.98317 acc 0.66225 roc_auc 0.57343 prc_auc 0.69683[0m
[93maverage test of epoch 37: loss -112.34791 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 38: loss -114.81856 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 38: loss -115.00626 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 39: loss -117.78659 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 39: loss -118.47927 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -120.68890 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 40: loss -121.18653 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -123.59079 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 41: loss -124.13660 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -126.49269 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 42: loss -126.79470 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -129.39441 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 43: loss -129.48892 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -132.29592 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 44: loss -132.76454 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -135.19733 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 45: loss -135.23715 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -138.09843 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 46: loss -138.54162 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -140.99963 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 47: loss -141.37798 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -143.90050 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 48: loss -143.79128 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -146.80150 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 49: loss -146.87055 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.003
[92maverage training of epoch 0: loss -3.82893 acc 0.62914 roc_auc 0.36824 prc_auc 0.56303[0m
[93maverage test of epoch 0: loss -6.78288 acc 0.67568 roc_auc 0.62333 prc_auc 0.71034[0m
[92maverage training of epoch 1: loss -8.48099 acc 0.66225 roc_auc 0.36627 prc_auc 0.56502[0m
[93maverage test of epoch 1: loss -10.22836 acc 0.67568 roc_auc 0.48333 prc_auc 0.66794[0m
[92maverage training of epoch 2: loss -11.77270 acc 0.66225 roc_auc 0.37049 prc_auc 0.56919[0m
[93maverage test of epoch 2: loss -13.44492 acc 0.67568 roc_auc 0.50000 prc_auc 0.69448[0m
[92maverage training of epoch 3: loss -14.93076 acc 0.66225 roc_auc 0.37176 prc_auc 0.56953[0m
[93maverage test of epoch 3: loss -16.58348 acc 0.67568 roc_auc 0.51833 prc_auc 0.66098[0m
[92maverage training of epoch 4: loss -18.03592 acc 0.66225 roc_auc 0.36980 prc_auc 0.56785[0m
[93maverage test of epoch 4: loss -19.68503 acc 0.67568 roc_auc 0.34667 prc_auc 0.59993[0mUsing backend: pytorch

[92maverage training of epoch 5: loss -21.10800 acc 0.66225 roc_auc 0.36853 prc_auc 0.56852[0m
[93maverage test of epoch 5: loss -22.75979 acc 0.67568 roc_auc 0.58667 prc_auc 0.70125[0m
[92maverage training of epoch 6: loss -24.16305 acc 0.66225 roc_auc 0.37010 prc_auc 0.56839[0m
[93maverage test of epoch 6: loss -25.81896 acc 0.67568 roc_auc 0.55167 prc_auc 0.69808[0m
[92maverage training of epoch 7: loss -27.20424 acc 0.66225 roc_auc 0.36951 prc_auc 0.56789[0m
[93maverage test of epoch 7: loss -28.86867 acc 0.67568 roc_auc 0.41167 prc_auc 0.63507[0m
[92maverage training of epoch 8: loss -30.23668 acc 0.66225 roc_auc 0.36961 prc_auc 0.56826[0m
[93maverage test of epoch 8: loss -31.90980 acc 0.67568 roc_auc 0.59167 prc_auc 0.71911[0m
[92maverage training of epoch 9: loss -33.26158 acc 0.66225 roc_auc 0.37000 prc_auc 0.57052[0m
[93maverage test of epoch 9: loss -34.94541 acc 0.67568 roc_auc 0.54167 prc_auc 0.69444[0m
[92maverage training of epoch 10: loss -36.28106 acc 0.66225 roc_auc 0.36922 prc_auc 0.57236[0m
[93maverage test of epoch 10: loss -37.97543 acc 0.67568 roc_auc 0.61667 prc_auc 0.73874[0m
[92maverage training of epoch 11: loss -39.29688 acc 0.66225 roc_auc 0.36275 prc_auc 0.56664[0m
[93maverage test of epoch 11: loss -41.00240 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 12: loss -42.30906 acc 0.66225 roc_auc 0.36196 prc_auc 0.57423[0m
[93maverage test of epoch 12: loss -44.02524 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 13: loss -45.31862 acc 0.66225 roc_auc 0.37451 prc_auc 0.59201[0m
[93maverage test of epoch 13: loss -47.04692 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 14: loss -48.32595 acc 0.66225 roc_auc 0.43059 prc_auc 0.63098[0m
[93maverage test of epoch 14: loss -50.06595 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 15: loss -51.33130 acc 0.66225 roc_auc 0.46882 prc_auc 0.64865[0m
[93maverage test of epoch 15: loss -53.08321 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 16: loss -54.33514 acc 0.66225 roc_auc 0.46343 prc_auc 0.64640[0m
[93maverage test of epoch 16: loss -56.09925 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 17: loss -57.33769 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 17: loss -59.11368 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 18: loss -60.33911 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 18: loss -62.12740 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 19: loss -63.33957 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 19: loss -65.14003 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 20: loss -66.33934 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 20: loss -68.15240 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 21: loss -69.33831 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 21: loss -71.16390 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 22: loss -72.33658 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 22: loss -74.17463 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 23: loss -75.33467 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 23: loss -77.18534 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 24: loss -78.33216 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 24: loss -80.19529 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 25: loss -81.32938 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 25: loss -83.20513 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 26: loss -84.32620 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 26: loss -86.21467 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 27: loss -87.32265 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 27: loss -89.22395 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 28: loss -90.31898 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 28: loss -92.23290 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 29: loss -93.31501 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 29: loss -95.24148 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 30: loss -96.31093 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 30: loss -98.24993 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 31: loss -99.30656 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 31: loss -101.25827 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 32: loss -102.30220 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 32: loss -104.26663 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 33: loss -105.29749 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 33: loss -107.27440 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 34: loss -108.29284 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 34: loss -110.28270 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 35: loss -111.28798 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 35: loss -113.29041 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 36: loss -114.28301 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 36: loss -116.29832 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 37: loss -117.27807 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 37: loss -119.30603 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 38: loss -120.27290 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 38: loss -122.31355 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 39: loss -123.26770 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 39: loss -125.32113 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -126.26248 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 40: loss -128.32863 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -129.25713 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 41: loss -131.33583 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -132.25167 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 42: loss -134.34319 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -135.24612 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 43: loss -137.35037 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -138.24051 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 44: loss -140.35762 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -141.23487 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 45: loss -143.36476 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -144.22934 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 46: loss -146.37185 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -147.22355 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 47: loss -149.37884 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -150.21777 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 48: loss -152.38570 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -153.21189 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 49: loss -155.39268 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.66501 ROC_AUC (avg): 0.5 PRC_AUC (avg): 0.66501 

Average forward propagation time taken(ms): 3.952539214295137
Average backward propagation time taken(ms): 1.5121759368406056

