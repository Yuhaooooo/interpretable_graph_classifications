# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 2)
('lr', 0.0001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-17-53-43/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-17-53-43/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 8,
 'epochs': 50,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 8,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.0001,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 1,
 'num_workers': 8,
 'number_of_mlp_layer': 2,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-17-17-53-43',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 50, 'learning_rate': 0.0001, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=8, bias=True)
    (ReLU1): ReLU()
    (Linear2): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.68500 acc 0.66667 roc_auc 0.40240 prc_auc 0.62555[0m
[93maverage test of epoch 0: loss -0.88287 acc 0.65789 roc_auc 0.44923 prc_auc 0.73700[0m
[92maverage training of epoch 1: loss -1.11495 acc 0.66667 roc_auc 0.41020 prc_auc 0.61763[0m
[93maverage test of epoch 1: loss -1.36844 acc 0.65789 roc_auc 0.52615 prc_auc 0.78301[0m
[92maverage training of epoch 2: loss -1.68875 acc 0.66667 roc_auc 0.42140 prc_auc 0.63736[0m
[93maverage test of epoch 2: loss -2.03964 acc 0.65789 roc_auc 0.44615 prc_auc 0.74925[0m
[92maverage training of epoch 3: loss -2.48347 acc 0.66667 roc_auc 0.42560 prc_auc 0.63968[0m
[93maverage test of epoch 3: loss -2.95686 acc 0.65789 roc_auc 0.47077 prc_auc 0.75702[0m
[92maverage training of epoch 4: loss -3.51374 acc 0.66667 roc_auc 0.42400 prc_auc 0.62711[0m
[93maverage test of epoch 4: loss -4.05600 acc 0.65789 roc_auc 0.82769 prc_auc 0.92589[0m
[92maverage training of epoch 5: loss -4.60877 acc 0.66667 roc_auc 0.42020 prc_auc 0.62559[0m
[93maverage test of epoch 5: loss -5.11209 acc 0.65789 roc_auc 0.83077 prc_auc 0.92291[0m
[92maverage training of epoch 6: loss -5.64678 acc 0.66667 roc_auc 0.41540 prc_auc 0.62260[0m
[93maverage test of epoch 6: loss -6.13051 acc 0.65789 roc_auc 0.83385 prc_auc 0.92351[0m
[92maverage training of epoch 7: loss -6.67887 acc 0.66667 roc_auc 0.41480 prc_auc 0.62158[0m
[93maverage test of epoch 7: loss -7.17286 acc 0.65789 roc_auc 0.75538 prc_auc 0.89246[0m
[92maverage training of epoch 8: loss -7.75005 acc 0.66667 roc_auc 0.41480 prc_auc 0.62148[0m
[93maverage test of epoch 8: loss -8.26337 acc 0.65789 roc_auc 0.77846 prc_auc 0.89970[0m
[92maverage training of epoch 9: loss -8.87399 acc 0.66667 roc_auc 0.41540 prc_auc 0.62171[0m
[93maverage test of epoch 9: loss -9.41136 acc 0.65789 roc_auc 0.81538 prc_auc 0.90787[0m
[92maverage training of epoch 10: loss -10.05850 acc 0.66667 roc_auc 0.41720 prc_auc 0.62310[0m
[93maverage test of epoch 10: loss -10.62251 acc 0.65789 roc_auc 0.85538 prc_auc 0.92113[0m
[92maverage training of epoch 11: loss -11.30858 acc 0.66667 roc_auc 0.41840 prc_auc 0.62451[0m
[93maverage test of epoch 11: loss -11.90139 acc 0.65789 roc_auc 0.89231 prc_auc 0.93045[0m
[92maverage training of epoch 12: loss -12.62909 acc 0.66667 roc_auc 0.41910 prc_auc 0.62470[0m
[93maverage test of epoch 12: loss -13.25280 acc 0.65789 roc_auc 0.85692 prc_auc 0.89909[0m
[92maverage training of epoch 13: loss -14.02422 acc 0.66667 roc_auc 0.41940 prc_auc 0.62507[0m
[93maverage test of epoch 13: loss -14.68019 acc 0.65789 roc_auc 0.85077 prc_auc 0.89189[0m
[92maverage training of epoch 14: loss -15.49886 acc 0.66667 roc_auc 0.41970 prc_auc 0.62474[0m
[93maverage test of epoch 14: loss -16.19912 acc 0.65789 roc_auc 0.72000 prc_auc 0.80842[0m
[92maverage training of epoch 15: loss -17.10648 acc 0.66667 roc_auc 0.41990 prc_auc 0.62479[0m
[93maverage test of epoch 15: loss -17.91176 acc 0.65789 roc_auc 0.58000 prc_auc 0.71263[0m
[92maverage training of epoch 16: loss -18.97609 acc 0.66667 roc_auc 0.41980 prc_auc 0.62494[0m
[93maverage test of epoch 16: loss -19.91333 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 17: loss -21.04094 acc 0.66667 roc_auc 0.41610 prc_auc 0.62175[0m
[93maverage test of epoch 17: loss -21.99868 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 18: loss -23.15551 acc 0.66667 roc_auc 0.41110 prc_auc 0.62138[0m
[93maverage test of epoch 18: loss -24.13169 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -25.33376 acc 0.66667 roc_auc 0.42050 prc_auc 0.63557[0m
[93maverage test of epoch 19: loss -26.34113 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -27.59650 acc 0.66667 roc_auc 0.44080 prc_auc 0.63937[0m
[93maverage test of epoch 20: loss -28.64130 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -29.95423 acc 0.66667 roc_auc 0.48000 prc_auc 0.65939[0m
[93maverage test of epoch 21: loss -31.03986 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -32.41343 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 22: loss -33.54215 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -34.97884 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 23: loss -36.15279 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -37.65528 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 24: loss -38.87657 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -40.44570 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 25: loss -41.71384 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -43.34930 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 26: loss -44.66328 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -46.36485 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 27: loss -47.72483 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -49.49454 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 28: loss -50.90221 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -52.74224 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 29: loss -54.19794 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -56.10839 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 30: loss -57.61257 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -59.59656 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 31: loss -61.15152 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -63.21206 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 32: loss -64.81988 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -66.95999 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 33: loss -68.62261 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -70.84509 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -72.56435 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -74.87209 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -76.64985 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -79.04569 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -80.88367 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -83.37025 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -85.27001 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -87.85023 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -89.81351 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -92.49009 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -94.51850 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -97.29417 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -99.38917 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -102.26657 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -104.42897 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -107.40870 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -109.63727 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -112.72142 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -115.01750 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -118.20901 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -120.57438 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -123.87607 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -126.31209 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -129.72668 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -132.23464 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -135.76464 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -138.34576 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -141.99377 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -144.64896 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -148.41731 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -151.14741 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=8, bias=True)
    (ReLU1): ReLU()
    (Linear2): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss 0.89632 acc 0.33333 roc_auc 0.47560 prc_auc 0.66023[0m
[93maverage test of epoch 0: loss 0.72766 acc 0.34211 roc_auc 0.80923 prc_auc 0.88936[0m
[92maverage training of epoch 1: loss 0.66879 acc 0.33333 roc_auc 0.48820 prc_auc 0.67193[0m
[93maverage test of epoch 1: loss 0.51783 acc 0.34211 roc_auc 0.83692 prc_auc 0.91540[0m
[92maverage training of epoch 2: loss 0.46780 acc 0.33333 roc_auc 0.50640 prc_auc 0.69121[0m
[93maverage test of epoch 2: loss 0.33016 acc 0.34211 roc_auc 0.87692 prc_auc 0.93112[0m
[92maverage training of epoch 3: loss 0.29555 acc 0.33333 roc_auc 0.53260 prc_auc 0.72390[0m
[93maverage test of epoch 3: loss 0.17302 acc 0.34211 roc_auc 0.88000 prc_auc 0.93321[0m
[92maverage training of epoch 4: loss 0.15060 acc 0.33333 roc_auc 0.56620 prc_auc 0.75607[0m
[93maverage test of epoch 4: loss 0.04869 acc 0.34211 roc_auc 0.88000 prc_auc 0.93321[0m
[92maverage training of epoch 5: loss 0.03960 acc 0.33333 roc_auc 0.59620 prc_auc 0.78412[0m
[93maverage test of epoch 5: loss -0.05777 acc 0.34211 roc_auc 0.89231 prc_auc 0.94026[0m
[92maverage training of epoch 6: loss -0.05618 acc 0.33333 roc_auc 0.63700 prc_auc 0.81274[0m
[93maverage test of epoch 6: loss -0.12702 acc 0.34211 roc_auc 0.91077 prc_auc 0.95119[0m
[92maverage training of epoch 7: loss -0.11868 acc 0.33333 roc_auc 0.71120 prc_auc 0.85640[0m
[93maverage test of epoch 7: loss -0.16615 acc 0.34211 roc_auc 0.90462 prc_auc 0.94889[0m
[92maverage training of epoch 8: loss -0.15670 acc 0.33333 roc_auc 0.78960 prc_auc 0.90276[0m
[93maverage test of epoch 8: loss -0.18777 acc 0.34211 roc_auc 0.90154 prc_auc 0.94604[0m
[92maverage training of epoch 9: loss -0.18085 acc 0.33333 roc_auc 0.83880 prc_auc 0.92609[0m
[93maverage test of epoch 9: loss -0.20900 acc 0.34211 roc_auc 0.90154 prc_auc 0.94604[0m
[92maverage training of epoch 10: loss -0.20359 acc 0.33333 roc_auc 0.86200 prc_auc 0.93799[0m
[93maverage test of epoch 10: loss -0.23228 acc 0.34211 roc_auc 0.90154 prc_auc 0.94604[0m
[92maverage training of epoch 11: loss -0.22693 acc 0.33333 roc_auc 0.86920 prc_auc 0.94033[0m
[93maverage test of epoch 11: loss -0.25581 acc 0.34211 roc_auc 0.88308 prc_auc 0.90911[0m
[92maverage training of epoch 12: loss -0.25096 acc 0.33333 roc_auc 0.87560 prc_auc 0.94311[0m
[93maverage test of epoch 12: loss -0.28026 acc 0.34211 roc_auc 0.88308 prc_auc 0.90911[0m
[92maverage training of epoch 13: loss -0.27627 acc 0.33333 roc_auc 0.88020 prc_auc 0.94593[0m
[93maverage test of epoch 13: loss -0.30608 acc 0.34211 roc_auc 0.88769 prc_auc 0.90859[0m
[92maverage training of epoch 14: loss -0.30324 acc 0.33333 roc_auc 0.88620 prc_auc 0.94864[0m
[93maverage test of epoch 14: loss -0.33393 acc 0.34211 roc_auc 0.88769 prc_auc 0.90859[0m
[92maverage training of epoch 15: loss -0.33260 acc 0.33333 roc_auc 0.88880 prc_auc 0.95009[0m
[93maverage test of epoch 15: loss -0.36474 acc 0.34211 roc_auc 0.88769 prc_auc 0.90859[0m
[92maverage training of epoch 16: loss -0.36546 acc 0.33333 roc_auc 0.89060 prc_auc 0.95085[0m
[93maverage test of epoch 16: loss -0.39921 acc 0.34211 roc_auc 0.88769 prc_auc 0.90859[0m
[92maverage training of epoch 17: loss -0.40358 acc 0.33333 roc_auc 0.89540 prc_auc 0.95325[0m
[93maverage test of epoch 17: loss -0.44001 acc 0.34211 roc_auc 0.88923 prc_auc 0.91141[0m
[92maverage training of epoch 18: loss -0.44868 acc 0.33333 roc_auc 0.89000 prc_auc 0.95096[0m
[93maverage test of epoch 18: loss -0.49142 acc 0.34211 roc_auc 0.88769 prc_auc 0.90859[0m
[92maverage training of epoch 19: loss -0.50524 acc 0.33333 roc_auc 0.89340 prc_auc 0.94957[0m
[93maverage test of epoch 19: loss -0.55509 acc 0.34211 roc_auc 0.88769 prc_auc 0.90859[0m
[92maverage training of epoch 20: loss -0.57536 acc 0.33333 roc_auc 0.89740 prc_auc 0.95224[0m
[93maverage test of epoch 20: loss -0.63108 acc 0.34211 roc_auc 0.88462 prc_auc 0.91017[0m
[92maverage training of epoch 21: loss -0.66186 acc 0.33333 roc_auc 0.90080 prc_auc 0.95492[0m
[93maverage test of epoch 21: loss -0.72300 acc 0.34211 roc_auc 0.86462 prc_auc 0.88372[0m
[92maverage training of epoch 22: loss -0.76973 acc 0.33333 roc_auc 0.90440 prc_auc 0.95661[0m
[93maverage test of epoch 22: loss -0.83295 acc 0.34211 roc_auc 0.87077 prc_auc 0.89167[0m
[92maverage training of epoch 23: loss -0.89625 acc 0.33333 roc_auc 0.90760 prc_auc 0.95755[0m
[93maverage test of epoch 23: loss -0.95669 acc 0.34211 roc_auc 0.84615 prc_auc 0.87049[0m
[92maverage training of epoch 24: loss -1.04289 acc 0.33333 roc_auc 0.91000 prc_auc 0.95970[0m
[93maverage test of epoch 24: loss -1.09861 acc 0.34211 roc_auc 0.85846 prc_auc 0.88382[0m
[92maverage training of epoch 25: loss -1.19731 acc 0.33333 roc_auc 0.90340 prc_auc 0.95095[0m
[93maverage test of epoch 25: loss -1.25251 acc 0.34211 roc_auc 0.88308 prc_auc 0.90649[0m
[92maverage training of epoch 26: loss -1.36492 acc 0.33333 roc_auc 0.89160 prc_auc 0.94493[0m
[93maverage test of epoch 26: loss -1.40843 acc 0.34211 roc_auc 0.88615 prc_auc 0.93563[0m
[92maverage training of epoch 27: loss -1.54368 acc 0.33333 roc_auc 0.89200 prc_auc 0.94791[0m
[93maverage test of epoch 27: loss -1.57105 acc 0.34211 roc_auc 0.89231 prc_auc 0.93951[0m
[92maverage training of epoch 28: loss -1.73418 acc 0.33333 roc_auc 0.88920 prc_auc 0.94758[0m
[93maverage test of epoch 28: loss -1.74275 acc 0.34211 roc_auc 0.90462 prc_auc 0.94644[0m
[92maverage training of epoch 29: loss -1.93229 acc 0.33333 roc_auc 0.88700 prc_auc 0.94688[0m
[93maverage test of epoch 29: loss -1.92222 acc 0.34211 roc_auc 0.91385 prc_auc 0.95188[0m
[92maverage training of epoch 30: loss -2.13505 acc 0.33333 roc_auc 0.88640 prc_auc 0.94659[0m
[93maverage test of epoch 30: loss -2.10919 acc 0.34211 roc_auc 0.91385 prc_auc 0.95188[0m
[92maverage training of epoch 31: loss -2.33623 acc 0.33333 roc_auc 0.88700 prc_auc 0.94757[0m
[93maverage test of epoch 31: loss -2.29876 acc 0.34211 roc_auc 0.91077 prc_auc 0.95015[0m
[92maverage training of epoch 32: loss -2.54692 acc 0.33333 roc_auc 0.88740 prc_auc 0.94761[0m
[93maverage test of epoch 32: loss -2.48316 acc 0.34211 roc_auc 0.91077 prc_auc 0.95015[0m
[92maverage training of epoch 33: loss -2.76942 acc 0.33333 roc_auc 0.89320 prc_auc 0.95263[0m
[93maverage test of epoch 33: loss -2.70165 acc 0.34211 roc_auc 0.92615 prc_auc 0.95663[0m
[92maverage training of epoch 34: loss -3.01321 acc 0.33333 roc_auc 0.89160 prc_auc 0.95126[0m
[93maverage test of epoch 34: loss -2.94971 acc 0.34211 roc_auc 0.93231 prc_auc 0.95937[0m
[92maverage training of epoch 35: loss -3.26127 acc 0.33333 roc_auc 0.89240 prc_auc 0.95164[0m
[93maverage test of epoch 35: loss -3.25397 acc 0.34211 roc_auc 0.93846 prc_auc 0.96346[0m
[92maverage training of epoch 36: loss -3.50220 acc 0.33333 roc_auc 0.89180 prc_auc 0.95130[0m
[93maverage test of epoch 36: loss -3.63318 acc 0.34211 roc_auc 0.93846 prc_auc 0.96346[0m
[92maverage training of epoch 37: loss -3.76222 acc 0.33333 roc_auc 0.89180 prc_auc 0.95096[0m
[93maverage test of epoch 37: loss -3.94370 acc 0.34211 roc_auc 0.93538 prc_auc 0.96222[0m
[92maverage training of epoch 38: loss -4.01616 acc 0.33333 roc_auc 0.89240 prc_auc 0.95126[0m
[93maverage test of epoch 38: loss -4.24819 acc 0.34211 roc_auc 0.93538 prc_auc 0.96222[0m
[92maverage training of epoch 39: loss -4.26069 acc 0.33333 roc_auc 0.89300 prc_auc 0.95199[0m
[93maverage test of epoch 39: loss -4.55139 acc 0.34211 roc_auc 0.93538 prc_auc 0.96222[0m
[92maverage training of epoch 40: loss -4.54709 acc 0.33333 roc_auc 0.89740 prc_auc 0.95713[0m
[93maverage test of epoch 40: loss -4.84923 acc 0.34211 roc_auc 0.93538 prc_auc 0.96222[0m
[92maverage training of epoch 41: loss -4.84273 acc 0.33333 roc_auc 0.89600 prc_auc 0.95658[0m
[93maverage test of epoch 41: loss -5.15472 acc 0.34211 roc_auc 0.93538 prc_auc 0.96222[0m
[92maverage training of epoch 42: loss -5.16811 acc 0.33333 roc_auc 0.89980 prc_auc 0.95953[0m
[93maverage test of epoch 42: loss -5.48712 acc 0.34211 roc_auc 0.93538 prc_auc 0.96222[0m
[92maverage training of epoch 43: loss -5.51280 acc 0.33333 roc_auc 0.89880 prc_auc 0.95906[0m
[93maverage test of epoch 43: loss -5.83791 acc 0.34211 roc_auc 0.93231 prc_auc 0.96033[0m
[92maverage training of epoch 44: loss -5.88062 acc 0.33333 roc_auc 0.89760 prc_auc 0.95832[0m
[93maverage test of epoch 44: loss -6.18660 acc 0.34211 roc_auc 0.93538 prc_auc 0.96156[0m
[92maverage training of epoch 45: loss -6.25634 acc 0.33333 roc_auc 0.89460 prc_auc 0.95561[0m
[93maverage test of epoch 45: loss -6.58691 acc 0.34211 roc_auc 0.93538 prc_auc 0.96156[0m
[92maverage training of epoch 46: loss -6.65953 acc 0.33333 roc_auc 0.89400 prc_auc 0.95539[0m
[93maverage test of epoch 46: loss -6.97692 acc 0.34211 roc_auc 0.93538 prc_auc 0.96156[0m
[92maverage training of epoch 47: loss -7.08023 acc 0.33333 roc_auc 0.89140 prc_auc 0.95285[0m
[93maverage test of epoch 47: loss -7.39125 acc 0.34211 roc_auc 0.93538 prc_auc 0.96156[0m
[92maverage training of epoch 48: loss -7.51299 acc 0.33333 roc_auc 0.89020 prc_auc 0.95163[0m
[93maverage test of epoch 48: loss -7.81801 acc 0.34211 roc_auc 0.93538 prc_auc 0.96156[0m
[92maverage training of epoch 49: loss -7.94404 acc 0.33333 roc_auc 0.88780 prc_auc 0.94960[0m
[93maverage test of epoch 49: loss -8.23769 acc 0.34211 roc_auc 0.92923 prc_auc 0.95563[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=8, bias=True)
    (ReLU1): ReLU()
    (Linear2): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss 1.04021 acc 0.66667 roc_auc 0.42920 prc_auc 0.64253[0m
[93maverage test of epoch 0: loss 0.74660 acc 0.65789 roc_auc 0.44000 prc_auc 0.74580[0m
[92maverage training of epoch 1: loss 0.45292 acc 0.66667 roc_auc 0.43860 prc_auc 0.64671[0m
[93maverage test of epoch 1: loss 0.20507 acc 0.65789 roc_auc 0.38154 prc_auc 0.71827[0m
[92maverage training of epoch 2: loss -0.09221 acc 0.66667 roc_auc 0.50150 prc_auc 0.71203[0m
[93maverage test of epoch 2: loss -0.32374 acc 0.65789 roc_auc 0.95385 prc_auc 0.97965[0m
[92maverage training of epoch 3: loss -0.58668 acc 0.66667 roc_auc 0.53060 prc_auc 0.72113[0m
[93maverage test of epoch 3: loss -0.76096 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 4: loss -1.00398 acc 0.66667 roc_auc 0.52560 prc_auc 0.71547[0m
[93maverage test of epoch 4: loss -1.19951 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 5: loss -1.50939 acc 0.66667 roc_auc 0.52220 prc_auc 0.71528[0m
[93maverage test of epoch 5: loss -1.73272 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 6: loss -2.01617 acc 0.66667 roc_auc 0.53040 prc_auc 0.72278[0m
[93maverage test of epoch 6: loss -2.22853 acc 0.65789 roc_auc 0.94923 prc_auc 0.97702[0m
[92maverage training of epoch 7: loss -2.56075 acc 0.66667 roc_auc 0.52090 prc_auc 0.71502[0m
[93maverage test of epoch 7: loss -2.78546 acc 0.65789 roc_auc 0.93231 prc_auc 0.96885[0m
[92maverage training of epoch 8: loss -3.13785 acc 0.66667 roc_auc 0.50290 prc_auc 0.70257[0m
[93maverage test of epoch 8: loss -3.34231 acc 0.65789 roc_auc 0.93846 prc_auc 0.96567[0m
[92maverage training of epoch 9: loss -3.70005 acc 0.66667 roc_auc 0.49490 prc_auc 0.69775[0m
[93maverage test of epoch 9: loss -3.87928 acc 0.65789 roc_auc 0.94308 prc_auc 0.95774[0m
[92maverage training of epoch 10: loss -4.24485 acc 0.66667 roc_auc 0.48950 prc_auc 0.68740[0m
[93maverage test of epoch 10: loss -4.40568 acc 0.65789 roc_auc 0.80000 prc_auc 0.86316[0m
[92maverage training of epoch 11: loss -4.78065 acc 0.66667 roc_auc 0.49250 prc_auc 0.68520[0m
[93maverage test of epoch 11: loss -4.92711 acc 0.65789 roc_auc 0.74000 prc_auc 0.82211[0m
[92maverage training of epoch 12: loss -5.31357 acc 0.66667 roc_auc 0.46360 prc_auc 0.64931[0m
[93maverage test of epoch 12: loss -5.45026 acc 0.65789 roc_auc 0.62000 prc_auc 0.74000[0m
[92maverage training of epoch 13: loss -5.85033 acc 0.66667 roc_auc 0.49000 prc_auc 0.66390[0m
[93maverage test of epoch 13: loss -5.97997 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 14: loss -6.39453 acc 0.66667 roc_auc 0.44000 prc_auc 0.64213[0m
[93maverage test of epoch 14: loss -6.51985 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 15: loss -6.94976 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 15: loss -7.07138 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 16: loss -7.51719 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 16: loss -7.63654 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 17: loss -8.09878 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 17: loss -8.21746 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 18: loss -8.69711 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 18: loss -8.81588 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -9.31315 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 19: loss -9.43313 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -9.94926 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 20: loss -10.07107 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -10.60293 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 21: loss -10.72411 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -11.27610 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 22: loss -11.40087 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -11.97323 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 23: loss -12.10191 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -12.69403 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 24: loss -12.82646 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -13.43954 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 25: loss -13.57634 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -14.21080 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 26: loss -14.35249 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -15.00931 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 27: loss -15.15688 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -15.83727 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 28: loss -15.99141 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -16.69671 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 29: loss -16.85819 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -17.58881 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 30: loss -17.75843 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -18.51568 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 31: loss -18.69343 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -19.47883 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 32: loss -19.66600 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -20.48027 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 33: loss -20.67752 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -21.52196 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -21.72980 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -22.60410 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -22.82117 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -23.72640 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -23.95377 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -24.89162 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -25.13030 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -26.10183 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -26.35217 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -27.35889 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -27.62190 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -28.66518 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -28.94144 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -30.02286 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -30.31303 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -31.43375 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -31.73822 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -32.89914 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -33.21798 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -34.41999 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -34.75313 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -35.99713 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -36.34465 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -37.63164 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -37.99383 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -39.32530 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -39.70280 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -41.08002 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -41.47319 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -42.89769 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -43.30705 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=8, bias=True)
    (ReLU1): ReLU()
    (Linear2): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.67650 acc 0.33775 roc_auc 0.45784 prc_auc 0.64117[0m
[93maverage test of epoch 0: loss -0.89175 acc 0.32432 roc_auc 0.85000 prc_auc 0.92059[0m
[92maverage training of epoch 1: loss -1.10252 acc 0.33775 roc_auc 0.46000 prc_auc 0.64916[0m
[93maverage test of epoch 1: loss -1.29617 acc 0.32432 roc_auc 0.81000 prc_auc 0.90174[0m
[92maverage training of epoch 2: loss -1.55209 acc 0.55629 roc_auc 0.45431 prc_auc 0.64002[0m
[93maverage test of epoch 2: loss -1.84033 acc 0.67568 roc_auc 0.85000 prc_auc 0.92022[0m
[92maverage training of epoch 3: loss -2.18820 acc 0.66225 roc_auc 0.45137 prc_auc 0.63725[0m
[93maverage test of epoch 3: loss -2.57475 acc 0.67568 roc_auc 0.84333 prc_auc 0.91519[0m
[92maverage training of epoch 4: loss -3.01042 acc 0.66225 roc_auc 0.44686 prc_auc 0.63391[0m
[93maverage test of epoch 4: loss -3.48428 acc 0.67568 roc_auc 0.85333 prc_auc 0.91994[0m
[92maverage training of epoch 5: loss -3.98894 acc 0.66225 roc_auc 0.44235 prc_auc 0.63465[0m
[93maverage test of epoch 5: loss -4.53994 acc 0.67568 roc_auc 0.85667 prc_auc 0.92140[0m
[92maverage training of epoch 6: loss -5.10766 acc 0.66225 roc_auc 0.43245 prc_auc 0.62278[0m
[93maverage test of epoch 6: loss -5.73346 acc 0.67568 roc_auc 0.85667 prc_auc 0.92185[0m
[92maverage training of epoch 7: loss -6.36435 acc 0.66225 roc_auc 0.42510 prc_auc 0.61783[0m
[93maverage test of epoch 7: loss -7.06800 acc 0.67568 roc_auc 0.85667 prc_auc 0.92185[0m
[92maverage training of epoch 8: loss -7.76934 acc 0.66225 roc_auc 0.42157 prc_auc 0.61272[0m
[93maverage test of epoch 8: loss -8.55633 acc 0.67568 roc_auc 0.85333 prc_auc 0.91740[0m
[92maverage training of epoch 9: loss -9.33495 acc 0.66225 roc_auc 0.41647 prc_auc 0.60733[0m
[93maverage test of epoch 9: loss -10.20971 acc 0.67568 roc_auc 0.85333 prc_auc 0.91755[0m
[92maverage training of epoch 10: loss -11.06553 acc 0.66225 roc_auc 0.40882 prc_auc 0.59970[0m
[93maverage test of epoch 10: loss -12.02379 acc 0.67568 roc_auc 0.84000 prc_auc 0.90720[0m
[92maverage training of epoch 11: loss -12.94776 acc 0.66225 roc_auc 0.40176 prc_auc 0.59674[0m
[93maverage test of epoch 11: loss -13.97826 acc 0.67568 roc_auc 0.85833 prc_auc 0.91855[0m
[92maverage training of epoch 12: loss -14.96926 acc 0.66225 roc_auc 0.41216 prc_auc 0.60538[0m
[93maverage test of epoch 12: loss -16.10785 acc 0.67568 roc_auc 0.85500 prc_auc 0.91756[0m
[92maverage training of epoch 13: loss -17.25210 acc 0.66225 roc_auc 0.41157 prc_auc 0.60489[0m
[93maverage test of epoch 13: loss -18.53382 acc 0.67568 roc_auc 0.86167 prc_auc 0.92118[0m
[92maverage training of epoch 14: loss -19.76145 acc 0.66225 roc_auc 0.41157 prc_auc 0.60534[0m
[93maverage test of epoch 14: loss -21.13173 acc 0.67568 roc_auc 0.86000 prc_auc 0.92134[0m
[92maverage training of epoch 15: loss -22.42755 acc 0.66225 roc_auc 0.41255 prc_auc 0.59827[0m
[93maverage test of epoch 15: loss -23.87439 acc 0.67568 roc_auc 0.86167 prc_auc 0.92164[0m
[92maverage training of epoch 16: loss -25.23129 acc 0.66225 roc_auc 0.41490 prc_auc 0.59964[0m
[93maverage test of epoch 16: loss -26.75285 acc 0.67568 roc_auc 0.87000 prc_auc 0.92392[0m
[92maverage training of epoch 17: loss -28.17270 acc 0.66225 roc_auc 0.41627 prc_auc 0.59982[0m
[93maverage test of epoch 17: loss -29.77249 acc 0.67568 roc_auc 0.87000 prc_auc 0.92495[0m
[92maverage training of epoch 18: loss -31.25894 acc 0.66225 roc_auc 0.41745 prc_auc 0.60108[0m
[93maverage test of epoch 18: loss -32.94254 acc 0.67568 roc_auc 0.87000 prc_auc 0.90937[0m
[92maverage training of epoch 19: loss -34.49936 acc 0.66225 roc_auc 0.41990 prc_auc 0.60276[0m
[93maverage test of epoch 19: loss -36.26990 acc 0.67568 roc_auc 0.84500 prc_auc 0.88337[0m
[92maverage training of epoch 20: loss -37.89529 acc 0.66225 roc_auc 0.42020 prc_auc 0.60303[0m
[93maverage test of epoch 20: loss -39.75427 acc 0.67568 roc_auc 0.80667 prc_auc 0.84961[0m
[92maverage training of epoch 21: loss -41.45117 acc 0.66225 roc_auc 0.42098 prc_auc 0.60382[0m
[93maverage test of epoch 21: loss -43.40204 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 22: loss -45.17117 acc 0.66225 roc_auc 0.42225 prc_auc 0.60561[0m
[93maverage test of epoch 22: loss -47.21733 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 23: loss -49.06180 acc 0.66225 roc_auc 0.42314 prc_auc 0.60729[0m
[93maverage test of epoch 23: loss -51.20796 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 24: loss -53.13034 acc 0.66225 roc_auc 0.42637 prc_auc 0.60917[0m
[93maverage test of epoch 24: loss -55.38126 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 25: loss -57.38475 acc 0.66225 roc_auc 0.42667 prc_auc 0.60932[0m
[93maverage test of epoch 25: loss -59.74550 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 26: loss -61.83306 acc 0.66225 roc_auc 0.42765 prc_auc 0.60945[0m
[93maverage test of epoch 26: loss -64.30846 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 27: loss -66.48244 acc 0.66225 roc_auc 0.42971 prc_auc 0.60879[0m
[93maverage test of epoch 27: loss -69.07639 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 28: loss -71.33767 acc 0.66225 roc_auc 0.43363 prc_auc 0.61824[0m
[93maverage test of epoch 28: loss -74.05273 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 29: loss -76.40309 acc 0.66225 roc_auc 0.42069 prc_auc 0.61190[0m
[93maverage test of epoch 29: loss -79.24343 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 30: loss -81.68449 acc 0.66225 roc_auc 0.41265 prc_auc 0.61749[0m
[93maverage test of epoch 30: loss -84.65303 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 31: loss -87.18609 acc 0.66225 roc_auc 0.43088 prc_auc 0.63424[0m
[93maverage test of epoch 31: loss -90.28658 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 32: loss -92.91384 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 32: loss -96.15045 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 33: loss -98.87391 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 33: loss -102.25053 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 34: loss -105.07154 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 34: loss -108.59150 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 35: loss -111.51175 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 35: loss -115.17895 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 36: loss -118.19979 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 36: loss -122.01693 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 37: loss -125.13869 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 37: loss -129.10853 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 38: loss -132.33213 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 38: loss -136.45712 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 39: loss -139.78340 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 39: loss -144.06701 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -147.49785 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 40: loss -151.94381 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -155.48035 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 41: loss -160.09188 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -163.73561 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 42: loss -168.51641 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -172.26875 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 43: loss -177.22247 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -181.08494 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 44: loss -186.21550 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -190.18978 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 45: loss -195.50105 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -199.58836 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 46: loss -205.08388 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -209.28573 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 47: loss -214.96953 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -219.28729 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 48: loss -225.16313 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -229.59807 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 49: loss -235.66963 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=8, bias=True)
    (ReLU1): ReLU()
    (Linear2): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.63562 acc 0.66225 roc_auc 0.40529 prc_auc 0.60234[0m
[93maverage test of epoch 0: loss -0.71978 acc 0.67568 roc_auc 0.10667 prc_auc 0.50832[0m
[92maverage training of epoch 1: loss -0.75688 acc 0.66225 roc_auc 0.41294 prc_auc 0.60733[0m
[93maverage test of epoch 1: loss -0.84945 acc 0.67568 roc_auc 0.47667 prc_auc 0.77626[0mUsing backend: pytorch
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))

[92maverage training of epoch 2: loss -0.92981 acc 0.66225 roc_auc 0.41627 prc_auc 0.61533[0m
[93maverage test of epoch 2: loss -1.18709 acc 0.67568 roc_auc 0.86000 prc_auc 0.94454[0m
[92maverage training of epoch 3: loss -1.41555 acc 0.66225 roc_auc 0.42373 prc_auc 0.63335[0m
[93maverage test of epoch 3: loss -1.78275 acc 0.67568 roc_auc 0.89000 prc_auc 0.95367[0m
[92maverage training of epoch 4: loss -2.33888 acc 0.66225 roc_auc 0.42314 prc_auc 0.62074[0m
[93maverage test of epoch 4: loss -2.97765 acc 0.67568 roc_auc 0.50833 prc_auc 0.79388[0m
[92maverage training of epoch 5: loss -3.47336 acc 0.66225 roc_auc 0.42294 prc_auc 0.62274[0m
[93maverage test of epoch 5: loss -4.07567 acc 0.67568 roc_auc 0.90667 prc_auc 0.96218[0m
[92maverage training of epoch 6: loss -4.60068 acc 0.66225 roc_auc 0.42098 prc_auc 0.62110[0m
[93maverage test of epoch 6: loss -5.24517 acc 0.67568 roc_auc 0.92000 prc_auc 0.97009[0m
[92maverage training of epoch 7: loss -5.78312 acc 0.66225 roc_auc 0.42118 prc_auc 0.62117[0m
[93maverage test of epoch 7: loss -6.45482 acc 0.67568 roc_auc 0.92333 prc_auc 0.97185[0m
[92maverage training of epoch 8: loss -7.00098 acc 0.66225 roc_auc 0.42118 prc_auc 0.62118[0m
[93maverage test of epoch 8: loss -7.70281 acc 0.67568 roc_auc 0.92667 prc_auc 0.97185[0m
[92maverage training of epoch 9: loss -8.27317 acc 0.66225 roc_auc 0.42176 prc_auc 0.62146[0m
[93maverage test of epoch 9: loss -9.03200 acc 0.67568 roc_auc 0.92833 prc_auc 0.97185[0m
[92maverage training of epoch 10: loss -9.68561 acc 0.66225 roc_auc 0.42275 prc_auc 0.62220[0m
[93maverage test of epoch 10: loss -10.61068 acc 0.67568 roc_auc 0.94000 prc_auc 0.97122[0m
[92maverage training of epoch 11: loss -11.39005 acc 0.66225 roc_auc 0.42480 prc_auc 0.62440[0m
[93maverage test of epoch 11: loss -12.34474 acc 0.67568 roc_auc 0.94833 prc_auc 0.97346[0m
[92maverage training of epoch 12: loss -13.02548 acc 0.66225 roc_auc 0.42412 prc_auc 0.62312[0m
[93maverage test of epoch 12: loss -13.94593 acc 0.67568 roc_auc 0.92667 prc_auc 0.95977[0m
[92maverage training of epoch 13: loss -14.61736 acc 0.66225 roc_auc 0.42422 prc_auc 0.62342[0m
[93maverage test of epoch 13: loss -15.56283 acc 0.67568 roc_auc 0.92000 prc_auc 0.94811[0m
[92maverage training of epoch 14: loss -16.24435 acc 0.66225 roc_auc 0.42441 prc_auc 0.62337[0m
[93maverage test of epoch 14: loss -17.22759 acc 0.67568 roc_auc 0.58000 prc_auc 0.72757[0m
[92maverage training of epoch 15: loss -17.92479 acc 0.66225 roc_auc 0.42402 prc_auc 0.62212[0m
[93maverage test of epoch 15: loss -18.94991 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 16: loss -19.66463 acc 0.66225 roc_auc 0.42451 prc_auc 0.62167[0m
[93maverage test of epoch 16: loss -20.73415 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 17: loss -21.46881 acc 0.66225 roc_auc 0.41833 prc_auc 0.61867[0m
[93maverage test of epoch 17: loss -22.58597 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 18: loss -23.34305 acc 0.66225 roc_auc 0.40186 prc_auc 0.60345[0m
[93maverage test of epoch 18: loss -24.51115 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 19: loss -25.29290 acc 0.66225 roc_auc 0.43471 prc_auc 0.63159[0m
[93maverage test of epoch 19: loss -26.51473 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 20: loss -27.32078 acc 0.66225 roc_auc 0.50500 prc_auc 0.66563[0m
[93maverage test of epoch 20: loss -28.59670 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 21: loss -29.42801 acc 0.66225 roc_auc 0.49922 prc_auc 0.66190[0m
[93maverage test of epoch 21: loss -30.76094 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 22: loss -31.61974 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 22: loss -33.01307 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 23: loss -33.90135 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 23: loss -35.35822 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 24: loss -36.27770 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 24: loss -37.80115 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 25: loss -38.75333 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 25: loss -40.34627 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 26: loss -41.33261 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 26: loss -42.99795 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 27: loss -44.01975 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 27: loss -45.76035 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 28: loss -46.81867 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 28: loss -48.63664 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 29: loss -49.73112 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 29: loss -51.62733 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 30: loss -52.75721 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 30: loss -54.73209 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 31: loss -55.89795 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 31: loss -57.95430 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 32: loss -59.15729 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 32: loss -61.29780 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 33: loss -62.53819 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 33: loss -64.76360 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 34: loss -66.04011 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 34: loss -68.35134 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 35: loss -69.66495 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 35: loss -72.06495 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 36: loss -73.41702 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 36: loss -75.90893 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 37: loss -77.30019 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 37: loss -79.88640 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 38: loss -81.31781 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 38: loss -84.00137 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 39: loss -85.47393 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 39: loss -88.25780 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -89.77234 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 40: loss -92.65940 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -94.21661 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 41: loss -97.20971 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -98.81030 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 42: loss -101.91231 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -103.55700 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 43: loss -106.77080 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -108.46003 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 44: loss -111.78826 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -113.52217 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 45: loss -116.96725 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -118.74602 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 46: loss -122.31028 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -124.13399 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 47: loss -127.81974 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -129.68822 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 48: loss -133.49687 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -135.40794 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 49: loss -139.33909 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 2)
('lr', 0.0001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.60185 ROC_AUC (avg): 0.58585 PRC_AUC (avg): 0.72455 

Average forward propagation time taken(ms): 3.1049670080814256
Average backward propagation time taken(ms): 0.9969272418413936

