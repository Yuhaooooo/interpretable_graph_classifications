# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.0001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-05-20-37/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-05-20-37/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 8,
 'epochs': 100,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 4,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.0001,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 2,
 'num_workers': 8,
 'number_of_mlp_layer': 0,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-18-05-20-37',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 100, 'learning_rate': 0.0001, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.70252 acc 0.33333 roc_auc 0.46180 prc_auc 0.63617[0m
[93maverage test of epoch 0: loss -0.76159 acc 0.34211 roc_auc 0.46769 prc_auc 0.71143[0m
[92maverage training of epoch 1: loss -0.83710 acc 0.33333 roc_auc 0.51260 prc_auc 0.69221[0m
[93maverage test of epoch 1: loss -0.93405 acc 0.34211 roc_auc 0.55692 prc_auc 0.75324[0m
[92maverage training of epoch 2: loss -0.98927 acc 0.33333 roc_auc 0.43840 prc_auc 0.67428[0m
[93maverage test of epoch 2: loss -1.07274 acc 0.34211 roc_auc 0.53846 prc_auc 0.66531[0m
[92maverage training of epoch 3: loss -1.14023 acc 0.34000 roc_auc 0.46580 prc_auc 0.66943[0m
[93maverage test of epoch 3: loss -1.23126 acc 0.34211 roc_auc 0.64615 prc_auc 0.81847[0m
[92maverage training of epoch 4: loss -1.28738 acc 0.37333 roc_auc 0.44340 prc_auc 0.66262[0m
[93maverage test of epoch 4: loss -1.35683 acc 0.34211 roc_auc 0.52308 prc_auc 0.72214[0m
[92maverage training of epoch 5: loss -1.42926 acc 0.44667 roc_auc 0.50280 prc_auc 0.66585[0m
[93maverage test of epoch 5: loss -1.51769 acc 0.55263 roc_auc 0.52615 prc_auc 0.71084[0m
[92maverage training of epoch 6: loss -1.59903 acc 0.62667 roc_auc 0.46860 prc_auc 0.68463[0m
[93maverage test of epoch 6: loss -1.67120 acc 0.57895 roc_auc 0.48923 prc_auc 0.71495[0m
[92maverage training of epoch 7: loss -1.77140 acc 0.64667 roc_auc 0.38200 prc_auc 0.61622[0m
[93maverage test of epoch 7: loss -1.88576 acc 0.65789 roc_auc 0.56308 prc_auc 0.68846[0m
[92maverage training of epoch 8: loss -1.97792 acc 0.66667 roc_auc 0.46560 prc_auc 0.66010[0m
[93maverage test of epoch 8: loss -2.09329 acc 0.65789 roc_auc 0.55385 prc_auc 0.73467[0m
[92maverage training of epoch 9: loss -2.20230 acc 0.66667 roc_auc 0.49860 prc_auc 0.68205[0m
[93maverage test of epoch 9: loss -2.32117 acc 0.65789 roc_auc 0.37231 prc_auc 0.63670[0m
[92maverage training of epoch 10: loss -2.44139 acc 0.66667 roc_auc 0.49340 prc_auc 0.67176[0m
[93maverage test of epoch 10: loss -2.54442 acc 0.65789 roc_auc 0.46154 prc_auc 0.70076[0m
[92maverage training of epoch 11: loss -2.68414 acc 0.66667 roc_auc 0.43940 prc_auc 0.61920[0m
[93maverage test of epoch 11: loss -2.79586 acc 0.65789 roc_auc 0.60000 prc_auc 0.79806[0m
[92maverage training of epoch 12: loss -2.91255 acc 0.66667 roc_auc 0.42480 prc_auc 0.64096[0m
[93maverage test of epoch 12: loss -3.00188 acc 0.65789 roc_auc 0.53846 prc_auc 0.74965[0m
[92maverage training of epoch 13: loss -3.11833 acc 0.66667 roc_auc 0.56740 prc_auc 0.73892[0m
[93maverage test of epoch 13: loss -3.22002 acc 0.65789 roc_auc 0.63385 prc_auc 0.79671[0m
[92maverage training of epoch 14: loss -3.34097 acc 0.66667 roc_auc 0.50540 prc_auc 0.69605[0m
[93maverage test of epoch 14: loss -3.41012 acc 0.65789 roc_auc 0.47692 prc_auc 0.71682[0m
[92maverage training of epoch 15: loss -3.54526 acc 0.66667 roc_auc 0.58360 prc_auc 0.74496[0m
[93maverage test of epoch 15: loss -3.62214 acc 0.65789 roc_auc 0.45538 prc_auc 0.65696[0m
[92maverage training of epoch 16: loss -3.74949 acc 0.66667 roc_auc 0.46880 prc_auc 0.64669[0m
[93maverage test of epoch 16: loss -3.85324 acc 0.65789 roc_auc 0.46769 prc_auc 0.62410[0m
[92maverage training of epoch 17: loss -3.94567 acc 0.66667 roc_auc 0.49540 prc_auc 0.66223[0m
[93maverage test of epoch 17: loss -4.02999 acc 0.65789 roc_auc 0.49846 prc_auc 0.67288[0m
[92maverage training of epoch 18: loss -4.12446 acc 0.66667 roc_auc 0.43600 prc_auc 0.65391[0m
[93maverage test of epoch 18: loss -4.20845 acc 0.65789 roc_auc 0.66769 prc_auc 0.81931[0m
[92maverage training of epoch 19: loss -4.28427 acc 0.66667 roc_auc 0.48140 prc_auc 0.65824[0m
[93maverage test of epoch 19: loss -4.35584 acc 0.65789 roc_auc 0.57231 prc_auc 0.70889[0m
[92maverage training of epoch 20: loss -4.43224 acc 0.66667 roc_auc 0.52480 prc_auc 0.69354[0m
[93maverage test of epoch 20: loss -4.45982 acc 0.65789 roc_auc 0.52923 prc_auc 0.65550[0m
[92maverage training of epoch 21: loss -4.57831 acc 0.66667 roc_auc 0.60210 prc_auc 0.77525[0m
[93maverage test of epoch 21: loss -4.63700 acc 0.65789 roc_auc 0.58769 prc_auc 0.75828[0m
[92maverage training of epoch 22: loss -4.68801 acc 0.66667 roc_auc 0.54840 prc_auc 0.68774[0m
[93maverage test of epoch 22: loss -4.73521 acc 0.65789 roc_auc 0.84308 prc_auc 0.89909[0m
[92maverage training of epoch 23: loss -4.80036 acc 0.66667 roc_auc 0.40260 prc_auc 0.60437[0m
[93maverage test of epoch 23: loss -4.84422 acc 0.65789 roc_auc 0.52615 prc_auc 0.69774[0m
[92maverage training of epoch 24: loss -4.90755 acc 0.66667 roc_auc 0.55480 prc_auc 0.68169[0m
[93maverage test of epoch 24: loss -4.93516 acc 0.65789 roc_auc 0.56923 prc_auc 0.73450[0m
[92maverage training of epoch 25: loss -5.01590 acc 0.66667 roc_auc 0.51000 prc_auc 0.66850[0m
[93maverage test of epoch 25: loss -5.03658 acc 0.65789 roc_auc 0.42769 prc_auc 0.62701[0m
[92maverage training of epoch 26: loss -5.09281 acc 0.66667 roc_auc 0.45380 prc_auc 0.63745[0m
[93maverage test of epoch 26: loss -5.11758 acc 0.65789 roc_auc 0.53538 prc_auc 0.73685[0m
[92maverage training of epoch 27: loss -5.19752 acc 0.66667 roc_auc 0.45200 prc_auc 0.62683[0m
[93maverage test of epoch 27: loss -5.21937 acc 0.65789 roc_auc 0.63385 prc_auc 0.80569[0m
[92maverage training of epoch 28: loss -5.27656 acc 0.66667 roc_auc 0.62210 prc_auc 0.74012[0m
[93maverage test of epoch 28: loss -5.30914 acc 0.65789 roc_auc 0.63385 prc_auc 0.80063[0m
[92maverage training of epoch 29: loss -5.34896 acc 0.66667 roc_auc 0.45720 prc_auc 0.62727[0m
[93maverage test of epoch 29: loss -5.34643 acc 0.65789 roc_auc 0.44308 prc_auc 0.66556[0m
[92maverage training of epoch 30: loss -5.43631 acc 0.66667 roc_auc 0.44560 prc_auc 0.64230[0m
[93maverage test of epoch 30: loss -5.46425 acc 0.65789 roc_auc 0.71385 prc_auc 0.85007[0m
[92maverage training of epoch 31: loss -5.50719 acc 0.66667 roc_auc 0.48340 prc_auc 0.67527[0m
[93maverage test of epoch 31: loss -5.52178 acc 0.65789 roc_auc 0.30462 prc_auc 0.60674[0m
[92maverage training of epoch 32: loss -5.58693 acc 0.66667 roc_auc 0.49400 prc_auc 0.68779[0m
[93maverage test of epoch 32: loss -5.60188 acc 0.65789 roc_auc 0.60615 prc_auc 0.78263[0m
[92maverage training of epoch 33: loss -5.65193 acc 0.66667 roc_auc 0.46320 prc_auc 0.66199[0m
[93maverage test of epoch 33: loss -5.66119 acc 0.65789 roc_auc 0.56308 prc_auc 0.75479[0m
[92maverage training of epoch 34: loss -5.72425 acc 0.66667 roc_auc 0.44880 prc_auc 0.60948[0m
[93maverage test of epoch 34: loss -5.74923 acc 0.65789 roc_auc 0.50769 prc_auc 0.69087[0m
[92maverage training of epoch 35: loss -5.78460 acc 0.66667 roc_auc 0.43130 prc_auc 0.64275[0m
[93maverage test of epoch 35: loss -5.80508 acc 0.65789 roc_auc 0.34154 prc_auc 0.60089[0m
[92maverage training of epoch 36: loss -5.86219 acc 0.66667 roc_auc 0.53240 prc_auc 0.69760[0m
[93maverage test of epoch 36: loss -5.88287 acc 0.65789 roc_auc 0.42462 prc_auc 0.64305[0m
[92maverage training of epoch 37: loss -5.92374 acc 0.66667 roc_auc 0.51820 prc_auc 0.69916[0m
[93maverage test of epoch 37: loss -5.94127 acc 0.65789 roc_auc 0.39077 prc_auc 0.66881[0m
[92maverage training of epoch 38: loss -5.99582 acc 0.66667 roc_auc 0.45120 prc_auc 0.62542[0m
[93maverage test of epoch 38: loss -5.99218 acc 0.65789 roc_auc 0.47077 prc_auc 0.68528[0m
[92maverage training of epoch 39: loss -6.06414 acc 0.66667 roc_auc 0.50180 prc_auc 0.65388[0m
[93maverage test of epoch 39: loss -6.05258 acc 0.65789 roc_auc 0.56000 prc_auc 0.78547[0m
[92maverage training of epoch 40: loss -6.12543 acc 0.66667 roc_auc 0.59440 prc_auc 0.74065[0m
[93maverage test of epoch 40: loss -6.12753 acc 0.65789 roc_auc 0.70462 prc_auc 0.81979[0m
[92maverage training of epoch 41: loss -6.18071 acc 0.66667 roc_auc 0.45410 prc_auc 0.62813[0m
[93maverage test of epoch 41: loss -6.15848 acc 0.65789 roc_auc 0.40000 prc_auc 0.62141[0m
[92maverage training of epoch 42: loss -6.25858 acc 0.66667 roc_auc 0.48000 prc_auc 0.65399[0m
[93maverage test of epoch 42: loss -6.26557 acc 0.65789 roc_auc 0.60923 prc_auc 0.78770[0m
[92maverage training of epoch 43: loss -6.31214 acc 0.66667 roc_auc 0.44640 prc_auc 0.62116[0m
[93maverage test of epoch 43: loss -6.32485 acc 0.65789 roc_auc 0.37231 prc_auc 0.61538[0m
[92maverage training of epoch 44: loss -6.38213 acc 0.66667 roc_auc 0.45010 prc_auc 0.64580[0m
[93maverage test of epoch 44: loss -6.37852 acc 0.65789 roc_auc 0.49231 prc_auc 0.70788[0m
[92maverage training of epoch 45: loss -6.43786 acc 0.66667 roc_auc 0.59720 prc_auc 0.70202[0m
[93maverage test of epoch 45: loss -6.43202 acc 0.65789 roc_auc 0.55385 prc_auc 0.71729[0m
[92maverage training of epoch 46: loss -6.49725 acc 0.66667 roc_auc 0.53200 prc_auc 0.68496[0m
[93maverage test of epoch 46: loss -6.51730 acc 0.65789 roc_auc 0.66769 prc_auc 0.80182[0m
[92maverage training of epoch 47: loss -6.55532 acc 0.66667 roc_auc 0.43540 prc_auc 0.62558[0m
[93maverage test of epoch 47: loss -6.55964 acc 0.65789 roc_auc 0.29231 prc_auc 0.54843[0m
[92maverage training of epoch 48: loss -6.61484 acc 0.66667 roc_auc 0.53520 prc_auc 0.69370[0m
[93maverage test of epoch 48: loss -6.62652 acc 0.65789 roc_auc 0.56769 prc_auc 0.77251[0m
[92maverage training of epoch 49: loss -6.67179 acc 0.66667 roc_auc 0.45190 prc_auc 0.61562[0m
[93maverage test of epoch 49: loss -6.67388 acc 0.65789 roc_auc 0.58154 prc_auc 0.79613[0m
[92maverage training of epoch 50: loss -6.73854 acc 0.66667 roc_auc 0.41880 prc_auc 0.59507[0m
[93maverage test of epoch 50: loss -6.74093 acc 0.65789 roc_auc 0.48154 prc_auc 0.70194[0m
[92maverage training of epoch 51: loss -6.79709 acc 0.66667 roc_auc 0.55500 prc_auc 0.68290[0m
[93maverage test of epoch 51: loss -6.79765 acc 0.65789 roc_auc 0.56769 prc_auc 0.77009[0m
[92maverage training of epoch 52: loss -6.85573 acc 0.66667 roc_auc 0.54780 prc_auc 0.69920[0m
[93maverage test of epoch 52: loss -6.85494 acc 0.65789 roc_auc 0.48000 prc_auc 0.67234[0m
[92maverage training of epoch 53: loss -6.91627 acc 0.66667 roc_auc 0.40700 prc_auc 0.60356[0m
[93maverage test of epoch 53: loss -6.91708 acc 0.65789 roc_auc 0.53846 prc_auc 0.72009[0m
[92maverage training of epoch 54: loss -6.96804 acc 0.66667 roc_auc 0.39400 prc_auc 0.60112[0m
[93maverage test of epoch 54: loss -6.97439 acc 0.65789 roc_auc 0.51692 prc_auc 0.72497[0m
[92maverage training of epoch 55: loss -7.03339 acc 0.66667 roc_auc 0.51300 prc_auc 0.66651[0m
[93maverage test of epoch 55: loss -7.03461 acc 0.65789 roc_auc 0.48308 prc_auc 0.70805[0m
[92maverage training of epoch 56: loss -7.08663 acc 0.66667 roc_auc 0.42240 prc_auc 0.62664[0m
[93maverage test of epoch 56: loss -7.09177 acc 0.65789 roc_auc 0.43692 prc_auc 0.67006[0m
[92maverage training of epoch 57: loss -7.14785 acc 0.66667 roc_auc 0.40580 prc_auc 0.61674[0m
[93maverage test of epoch 57: loss -7.15122 acc 0.65789 roc_auc 0.51692 prc_auc 0.72656[0m
[92maverage training of epoch 58: loss -7.20373 acc 0.66667 roc_auc 0.33730 prc_auc 0.57166[0m
[93maverage test of epoch 58: loss -7.20279 acc 0.65789 roc_auc 0.48923 prc_auc 0.71416[0m
[92maverage training of epoch 59: loss -7.26337 acc 0.66667 roc_auc 0.42480 prc_auc 0.60567[0m
[93maverage test of epoch 59: loss -7.26881 acc 0.65789 roc_auc 0.48000 prc_auc 0.69544[0m
[92maverage training of epoch 60: loss -7.32125 acc 0.66667 roc_auc 0.48600 prc_auc 0.64591[0m
[93maverage test of epoch 60: loss -7.32195 acc 0.65789 roc_auc 0.47077 prc_auc 0.73261[0m
[92maverage training of epoch 61: loss -7.37906 acc 0.66667 roc_auc 0.44180 prc_auc 0.60864[0m
[93maverage test of epoch 61: loss -7.37660 acc 0.65789 roc_auc 0.47385 prc_auc 0.61713[0m
[92maverage training of epoch 62: loss -7.43147 acc 0.66667 roc_auc 0.49720 prc_auc 0.66282[0m
[93maverage test of epoch 62: loss -7.44032 acc 0.65789 roc_auc 0.42769 prc_auc 0.63615[0m
[92maverage training of epoch 63: loss -7.49293 acc 0.66667 roc_auc 0.43600 prc_auc 0.60879[0m
[93maverage test of epoch 63: loss -7.49091 acc 0.65789 roc_auc 0.58615 prc_auc 0.77543[0m
[92maverage training of epoch 64: loss -7.55094 acc 0.66667 roc_auc 0.45040 prc_auc 0.61091[0m
[93maverage test of epoch 64: loss -7.55114 acc 0.65789 roc_auc 0.44923 prc_auc 0.61581[0m
[92maverage training of epoch 65: loss -7.61147 acc 0.66667 roc_auc 0.52510 prc_auc 0.66197[0m
[93maverage test of epoch 65: loss -7.59611 acc 0.65789 roc_auc 0.37692 prc_auc 0.58493[0m
[92maverage training of epoch 66: loss -7.66498 acc 0.66667 roc_auc 0.43940 prc_auc 0.61664[0m
[93maverage test of epoch 66: loss -7.66850 acc 0.65789 roc_auc 0.59231 prc_auc 0.69897[0m
[92maverage training of epoch 67: loss -7.72342 acc 0.66667 roc_auc 0.49020 prc_auc 0.62834[0m
[93maverage test of epoch 67: loss -7.72420 acc 0.65789 roc_auc 0.63385 prc_auc 0.77672[0m
[92maverage training of epoch 68: loss -7.78231 acc 0.66667 roc_auc 0.43100 prc_auc 0.60313[0m
[93maverage test of epoch 68: loss -7.77679 acc 0.65789 roc_auc 0.64308 prc_auc 0.74380[0m
[92maverage training of epoch 69: loss -7.83544 acc 0.66667 roc_auc 0.41500 prc_auc 0.59861[0m
[93maverage test of epoch 69: loss -7.83373 acc 0.65789 roc_auc 0.57077 prc_auc 0.74662[0m
[92maverage training of epoch 70: loss -7.89166 acc 0.66667 roc_auc 0.38980 prc_auc 0.58923[0m
[93maverage test of epoch 70: loss -7.89323 acc 0.65789 roc_auc 0.53231 prc_auc 0.71139[0m
[92maverage training of epoch 71: loss -7.94871 acc 0.66667 roc_auc 0.52330 prc_auc 0.64138[0m
[93maverage test of epoch 71: loss -7.94109 acc 0.65789 roc_auc 0.37538 prc_auc 0.65663[0m
[92maverage training of epoch 72: loss -8.00553 acc 0.66667 roc_auc 0.36570 prc_auc 0.58178[0m
[93maverage test of epoch 72: loss -8.00096 acc 0.65789 roc_auc 0.63692 prc_auc 0.76346[0m
[92maverage training of epoch 73: loss -8.06141 acc 0.66667 roc_auc 0.39840 prc_auc 0.59035[0m
[93maverage test of epoch 73: loss -8.06046 acc 0.65789 roc_auc 0.53231 prc_auc 0.74474[0m
[92maverage training of epoch 74: loss -8.12037 acc 0.66667 roc_auc 0.46500 prc_auc 0.63254[0m
[93maverage test of epoch 74: loss -8.11556 acc 0.65789 roc_auc 0.49231 prc_auc 0.70396[0m
[92maverage training of epoch 75: loss -8.17670 acc 0.66667 roc_auc 0.51160 prc_auc 0.62980[0m
[93maverage test of epoch 75: loss -8.16987 acc 0.65789 roc_auc 0.36308 prc_auc 0.60512[0m
[92maverage training of epoch 76: loss -8.23036 acc 0.66667 roc_auc 0.41950 prc_auc 0.60114[0m
[93maverage test of epoch 76: loss -8.22755 acc 0.65789 roc_auc 0.40000 prc_auc 0.58202[0m
[92maverage training of epoch 77: loss -8.28566 acc 0.66667 roc_auc 0.39640 prc_auc 0.60308[0m
[93maverage test of epoch 77: loss -8.28487 acc 0.65789 roc_auc 0.48615 prc_auc 0.67563[0m
[92maverage training of epoch 78: loss -8.34392 acc 0.66667 roc_auc 0.45700 prc_auc 0.62642[0m
[93maverage test of epoch 78: loss -8.33911 acc 0.65789 roc_auc 0.44000 prc_auc 0.66164[0m
[92maverage training of epoch 79: loss -8.39985 acc 0.66667 roc_auc 0.41650 prc_auc 0.59237[0m
[93maverage test of epoch 79: loss -8.39116 acc 0.65789 roc_auc 0.43385 prc_auc 0.63711[0m
[92maverage training of epoch 80: loss -8.45500 acc 0.66667 roc_auc 0.40080 prc_auc 0.59040[0m
[93maverage test of epoch 80: loss -8.44858 acc 0.65789 roc_auc 0.47538 prc_auc 0.62679[0m
[92maverage training of epoch 81: loss -8.51136 acc 0.66667 roc_auc 0.41810 prc_auc 0.60967[0m
[93maverage test of epoch 81: loss -8.50013 acc 0.65789 roc_auc 0.36615 prc_auc 0.60101[0m
[92maverage training of epoch 82: loss -8.56719 acc 0.66667 roc_auc 0.48580 prc_auc 0.66248[0m
[93maverage test of epoch 82: loss -8.55821 acc 0.65789 roc_auc 0.41692 prc_auc 0.67043[0m
[92maverage training of epoch 83: loss -8.62354 acc 0.66667 roc_auc 0.39580 prc_auc 0.58847[0m
[93maverage test of epoch 83: loss -8.62072 acc 0.65789 roc_auc 0.58154 prc_auc 0.69755[0m
[92maverage training of epoch 84: loss -8.67896 acc 0.66667 roc_auc 0.34490 prc_auc 0.56828[0m
[93maverage test of epoch 84: loss -8.67164 acc 0.65789 roc_auc 0.34769 prc_auc 0.58384[0m
[92maverage training of epoch 85: loss -8.73548 acc 0.66667 roc_auc 0.39920 prc_auc 0.60021[0m
[93maverage test of epoch 85: loss -8.72899 acc 0.65789 roc_auc 0.38154 prc_auc 0.58889[0m
[92maverage training of epoch 86: loss -8.79157 acc 0.66667 roc_auc 0.43540 prc_auc 0.61462[0m
[93maverage test of epoch 86: loss -8.78531 acc 0.65789 roc_auc 0.51385 prc_auc 0.69133[0m
[92maverage training of epoch 87: loss -8.84611 acc 0.66667 roc_auc 0.35840 prc_auc 0.58047[0m
[93maverage test of epoch 87: loss -8.83886 acc 0.65789 roc_auc 0.59538 prc_auc 0.73540[0m
[92maverage training of epoch 88: loss -8.90295 acc 0.66667 roc_auc 0.47680 prc_auc 0.63215[0m
[93maverage test of epoch 88: loss -8.89448 acc 0.65789 roc_auc 0.37231 prc_auc 0.59373[0m
[92maverage training of epoch 89: loss -8.95611 acc 0.66667 roc_auc 0.33340 prc_auc 0.55826[0m
[93maverage test of epoch 89: loss -8.95295 acc 0.65789 roc_auc 0.58615 prc_auc 0.70368[0m
[92maverage training of epoch 90: loss -9.01456 acc 0.66667 roc_auc 0.48340 prc_auc 0.64868[0m
[93maverage test of epoch 90: loss -9.00660 acc 0.65789 roc_auc 0.49231 prc_auc 0.66282[0m
[92maverage training of epoch 91: loss -9.07014 acc 0.66667 roc_auc 0.38090 prc_auc 0.58472[0m
[93maverage test of epoch 91: loss -9.06097 acc 0.65789 roc_auc 0.66308 prc_auc 0.80589[0m
[92maverage training of epoch 92: loss -9.12479 acc 0.66667 roc_auc 0.41120 prc_auc 0.59271[0m
[93maverage test of epoch 92: loss -9.11700 acc 0.65789 roc_auc 0.63538 prc_auc 0.73219[0m
[92maverage training of epoch 93: loss -9.18018 acc 0.66667 roc_auc 0.38280 prc_auc 0.58307[0m
[93maverage test of epoch 93: loss -9.17439 acc 0.65789 roc_auc 0.68154 prc_auc 0.83603[0m
[92maverage training of epoch 94: loss -9.23732 acc 0.66667 roc_auc 0.40550 prc_auc 0.60205[0m
[93maverage test of epoch 94: loss -9.22936 acc 0.65789 roc_auc 0.30615 prc_auc 0.56607[0m
[92maverage training of epoch 95: loss -9.29197 acc 0.66667 roc_auc 0.37130 prc_auc 0.57350[0m
[93maverage test of epoch 95: loss -9.28405 acc 0.65789 roc_auc 0.66308 prc_auc 0.76463[0m
[92maverage training of epoch 96: loss -9.34706 acc 0.66667 roc_auc 0.40730 prc_auc 0.62063[0m
[93maverage test of epoch 96: loss -9.33876 acc 0.65789 roc_auc 0.48769 prc_auc 0.65035[0m
[92maverage training of epoch 97: loss -9.40237 acc 0.66667 roc_auc 0.39940 prc_auc 0.59813[0m
[93maverage test of epoch 97: loss -9.39499 acc 0.65789 roc_auc 0.40923 prc_auc 0.61403[0m
[92maverage training of epoch 98: loss -9.45894 acc 0.66667 roc_auc 0.33490 prc_auc 0.55338[0m
[93maverage test of epoch 98: loss -9.44955 acc 0.65789 roc_auc 0.41385 prc_auc 0.60897[0m
[92maverage training of epoch 99: loss -9.51423 acc 0.66667 roc_auc 0.36310 prc_auc 0.57719[0m
[93maverage test of epoch 99: loss -9.50378 acc 0.65789 roc_auc 0.44923 prc_auc 0.63268[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.24667 acc 0.33333 roc_auc 0.59580 prc_auc 0.74696[0m
[93maverage test of epoch 0: loss -0.39189 acc 0.34211 roc_auc 0.62154 prc_auc 0.78288[0m
[92maverage training of epoch 1: loss -0.48519 acc 0.33333 roc_auc 0.50500 prc_auc 0.69235[0m
[93maverage test of epoch 1: loss -0.59522 acc 0.34211 roc_auc 0.63385 prc_auc 0.72026[0m
[92maverage training of epoch 2: loss -0.69597 acc 0.33333 roc_auc 0.42960 prc_auc 0.61862[0m
[93maverage test of epoch 2: loss -0.81872 acc 0.34211 roc_auc 0.47385 prc_auc 0.69899[0m
[92maverage training of epoch 3: loss -0.91289 acc 0.33333 roc_auc 0.45780 prc_auc 0.65246[0m
[93maverage test of epoch 3: loss -1.03290 acc 0.34211 roc_auc 0.45846 prc_auc 0.72030[0m
[92maverage training of epoch 4: loss -1.18360 acc 0.33333 roc_auc 0.57860 prc_auc 0.75352[0m
[93maverage test of epoch 4: loss -1.32176 acc 0.34211 roc_auc 0.42154 prc_auc 0.61298[0m
[92maverage training of epoch 5: loss -1.46982 acc 0.33333 roc_auc 0.57280 prc_auc 0.72890[0m
[93maverage test of epoch 5: loss -1.63773 acc 0.34211 roc_auc 0.43077 prc_auc 0.61150[0m
[92maverage training of epoch 6: loss -1.74197 acc 0.33333 roc_auc 0.50200 prc_auc 0.67999[0m
[93maverage test of epoch 6: loss -1.87633 acc 0.34211 roc_auc 0.54154 prc_auc 0.70667[0m
[92maverage training of epoch 7: loss -1.94766 acc 0.33333 roc_auc 0.46820 prc_auc 0.65647[0m
[93maverage test of epoch 7: loss -2.04120 acc 0.34211 roc_auc 0.56923 prc_auc 0.74282[0m
[92maverage training of epoch 8: loss -2.11201 acc 0.33333 roc_auc 0.43080 prc_auc 0.63660[0m
[93maverage test of epoch 8: loss -2.19998 acc 0.34211 roc_auc 0.57231 prc_auc 0.73440[0m
[92maverage training of epoch 9: loss -2.25418 acc 0.33333 roc_auc 0.50380 prc_auc 0.69998[0m
[93maverage test of epoch 9: loss -2.31219 acc 0.34211 roc_auc 0.41231 prc_auc 0.65995[0m
[92maverage training of epoch 10: loss -2.37100 acc 0.33333 roc_auc 0.47260 prc_auc 0.68152[0m
[93maverage test of epoch 10: loss -2.45204 acc 0.34211 roc_auc 0.68615 prc_auc 0.76443[0m
[92maverage training of epoch 11: loss -2.48839 acc 0.33333 roc_auc 0.40460 prc_auc 0.60383[0m
[93maverage test of epoch 11: loss -2.55426 acc 0.34211 roc_auc 0.45846 prc_auc 0.64788[0m
[92maverage training of epoch 12: loss -2.60068 acc 0.33333 roc_auc 0.46200 prc_auc 0.65087[0m
[93maverage test of epoch 12: loss -2.65903 acc 0.34211 roc_auc 0.48615 prc_auc 0.72159[0m
[92maverage training of epoch 13: loss -2.69873 acc 0.33333 roc_auc 0.48700 prc_auc 0.66594[0m
[93maverage test of epoch 13: loss -2.77010 acc 0.34211 roc_auc 0.36615 prc_auc 0.56649[0m
[92maverage training of epoch 14: loss -2.80225 acc 0.33333 roc_auc 0.40640 prc_auc 0.60990[0m
[93maverage test of epoch 14: loss -2.88165 acc 0.34211 roc_auc 0.48923 prc_auc 0.64118[0m
[92maverage training of epoch 15: loss -2.90180 acc 0.33333 roc_auc 0.40200 prc_auc 0.61922[0m
[93maverage test of epoch 15: loss -2.96725 acc 0.34211 roc_auc 0.47385 prc_auc 0.73327[0m
[92maverage training of epoch 16: loss -2.99920 acc 0.33333 roc_auc 0.44560 prc_auc 0.62506[0m
[93maverage test of epoch 16: loss -3.05234 acc 0.34211 roc_auc 0.40308 prc_auc 0.66860[0m
[92maverage training of epoch 17: loss -3.08512 acc 0.33333 roc_auc 0.42120 prc_auc 0.61293[0m
[93maverage test of epoch 17: loss -3.14197 acc 0.34211 roc_auc 0.37846 prc_auc 0.61155[0m
[92maverage training of epoch 18: loss -3.18196 acc 0.33333 roc_auc 0.42300 prc_auc 0.62937[0m
[93maverage test of epoch 18: loss -3.25344 acc 0.34211 roc_auc 0.37538 prc_auc 0.57553[0m
[92maverage training of epoch 19: loss -3.28280 acc 0.33333 roc_auc 0.44700 prc_auc 0.63407[0m
[93maverage test of epoch 19: loss -3.32754 acc 0.34211 roc_auc 0.44615 prc_auc 0.69490[0m
[92maverage training of epoch 20: loss -3.36236 acc 0.33333 roc_auc 0.46680 prc_auc 0.65443[0m
[93maverage test of epoch 20: loss -3.40873 acc 0.34211 roc_auc 0.55077 prc_auc 0.70563[0m
[92maverage training of epoch 21: loss -3.44496 acc 0.33333 roc_auc 0.45240 prc_auc 0.68342[0m
[93maverage test of epoch 21: loss -3.49195 acc 0.34211 roc_auc 0.33846 prc_auc 0.60716[0m
[92maverage training of epoch 22: loss -3.53342 acc 0.33333 roc_auc 0.46560 prc_auc 0.65506[0m
[93maverage test of epoch 22: loss -3.56465 acc 0.34211 roc_auc 0.67692 prc_auc 0.79396[0m
[92maverage training of epoch 23: loss -3.60064 acc 0.33333 roc_auc 0.46540 prc_auc 0.64788[0m
[93maverage test of epoch 23: loss -3.64862 acc 0.34211 roc_auc 0.49538 prc_auc 0.69518[0m
[92maverage training of epoch 24: loss -3.67891 acc 0.33333 roc_auc 0.51280 prc_auc 0.68303[0m
[93maverage test of epoch 24: loss -3.71590 acc 0.34211 roc_auc 0.48308 prc_auc 0.67485[0m
[92maverage training of epoch 25: loss -3.75270 acc 0.33333 roc_auc 0.42900 prc_auc 0.63440[0m
[93maverage test of epoch 25: loss -3.81382 acc 0.34211 roc_auc 0.45231 prc_auc 0.63657[0m
[92maverage training of epoch 26: loss -3.82089 acc 0.33333 roc_auc 0.40320 prc_auc 0.61570[0m
[93maverage test of epoch 26: loss -3.86601 acc 0.34211 roc_auc 0.34462 prc_auc 0.58336[0m
[92maverage training of epoch 27: loss -3.89516 acc 0.33333 roc_auc 0.47540 prc_auc 0.66614[0m
[93maverage test of epoch 27: loss -3.94227 acc 0.34211 roc_auc 0.60000 prc_auc 0.78508[0m
[92maverage training of epoch 28: loss -3.96252 acc 0.33333 roc_auc 0.43220 prc_auc 0.64904[0m
[93maverage test of epoch 28: loss -4.01719 acc 0.34211 roc_auc 0.43077 prc_auc 0.65581[0m
[92maverage training of epoch 29: loss -4.02736 acc 0.33333 roc_auc 0.46800 prc_auc 0.66011[0m
[93maverage test of epoch 29: loss -4.07962 acc 0.34211 roc_auc 0.47692 prc_auc 0.67956[0m
[92maverage training of epoch 30: loss -4.10031 acc 0.33333 roc_auc 0.43080 prc_auc 0.61078[0m
[93maverage test of epoch 30: loss -4.13673 acc 0.34211 roc_auc 0.50769 prc_auc 0.66155[0m
[92maverage training of epoch 31: loss -4.16186 acc 0.33333 roc_auc 0.42500 prc_auc 0.61388[0m
[93maverage test of epoch 31: loss -4.22311 acc 0.34211 roc_auc 0.45538 prc_auc 0.71077[0m
[92maverage training of epoch 32: loss -4.22448 acc 0.33333 roc_auc 0.46160 prc_auc 0.63792[0m
[93maverage test of epoch 32: loss -4.26672 acc 0.34211 roc_auc 0.60000 prc_auc 0.77981[0m
[92maverage training of epoch 33: loss -4.28905 acc 0.33333 roc_auc 0.36720 prc_auc 0.58775[0m
[93maverage test of epoch 33: loss -4.33388 acc 0.34211 roc_auc 0.52462 prc_auc 0.69055[0m
[92maverage training of epoch 34: loss -4.35215 acc 0.33333 roc_auc 0.47340 prc_auc 0.65670[0m
[93maverage test of epoch 34: loss -4.38799 acc 0.34211 roc_auc 0.59077 prc_auc 0.76686[0m
[92maverage training of epoch 35: loss -4.40696 acc 0.33333 roc_auc 0.39160 prc_auc 0.60180[0m
[93maverage test of epoch 35: loss -4.45231 acc 0.34211 roc_auc 0.59692 prc_auc 0.76969[0m
[92maverage training of epoch 36: loss -4.47356 acc 0.33333 roc_auc 0.41700 prc_auc 0.61959[0m
[93maverage test of epoch 36: loss -4.51856 acc 0.34211 roc_auc 0.59538 prc_auc 0.75721[0m
[92maverage training of epoch 37: loss -4.53920 acc 0.33333 roc_auc 0.46540 prc_auc 0.64596[0m
[93maverage test of epoch 37: loss -4.56727 acc 0.34211 roc_auc 0.43077 prc_auc 0.65959[0m
[92maverage training of epoch 38: loss -4.59626 acc 0.33333 roc_auc 0.47000 prc_auc 0.64548[0m
[93maverage test of epoch 38: loss -4.63155 acc 0.34211 roc_auc 0.41077 prc_auc 0.61393[0m
[92maverage training of epoch 39: loss -4.65939 acc 0.33333 roc_auc 0.48240 prc_auc 0.64131[0m
[93maverage test of epoch 39: loss -4.70391 acc 0.34211 roc_auc 0.59077 prc_auc 0.76530[0m
[92maverage training of epoch 40: loss -4.71922 acc 0.33333 roc_auc 0.45160 prc_auc 0.64189[0m
[93maverage test of epoch 40: loss -4.75226 acc 0.34211 roc_auc 0.52000 prc_auc 0.73966[0m
[92maverage training of epoch 41: loss -4.77663 acc 0.33333 roc_auc 0.46920 prc_auc 0.65961[0m
[93maverage test of epoch 41: loss -4.81162 acc 0.34211 roc_auc 0.45846 prc_auc 0.67251[0m
[92maverage training of epoch 42: loss -4.84022 acc 0.33333 roc_auc 0.45820 prc_auc 0.64154[0m
[93maverage test of epoch 42: loss -4.87512 acc 0.34211 roc_auc 0.45538 prc_auc 0.61937[0m
[92maverage training of epoch 43: loss -4.90053 acc 0.33333 roc_auc 0.44960 prc_auc 0.64850[0m
[93maverage test of epoch 43: loss -4.92840 acc 0.34211 roc_auc 0.48615 prc_auc 0.69445[0m
[92maverage training of epoch 44: loss -4.95969 acc 0.33333 roc_auc 0.45220 prc_auc 0.64210[0m
[93maverage test of epoch 44: loss -4.99816 acc 0.34211 roc_auc 0.38615 prc_auc 0.67174[0m
[92maverage training of epoch 45: loss -5.01607 acc 0.33333 roc_auc 0.45000 prc_auc 0.65761[0m
[93maverage test of epoch 45: loss -5.04854 acc 0.34211 roc_auc 0.49692 prc_auc 0.68378[0m
[92maverage training of epoch 46: loss -5.07389 acc 0.33333 roc_auc 0.45600 prc_auc 0.63804[0m
[93maverage test of epoch 46: loss -5.11165 acc 0.34211 roc_auc 0.56308 prc_auc 0.71870[0m
[92maverage training of epoch 47: loss -5.12838 acc 0.33333 roc_auc 0.42960 prc_auc 0.61765[0m
[93maverage test of epoch 47: loss -5.17140 acc 0.34211 roc_auc 0.47692 prc_auc 0.69351[0m
[92maverage training of epoch 48: loss -5.18992 acc 0.33333 roc_auc 0.44200 prc_auc 0.62641[0m
[93maverage test of epoch 48: loss -5.22526 acc 0.34211 roc_auc 0.52308 prc_auc 0.69796[0m
[92maverage training of epoch 49: loss -5.25042 acc 0.33333 roc_auc 0.41240 prc_auc 0.59822[0m
[93maverage test of epoch 49: loss -5.28737 acc 0.34211 roc_auc 0.51385 prc_auc 0.64251[0m
[92maverage training of epoch 50: loss -5.30364 acc 0.33333 roc_auc 0.39780 prc_auc 0.60198[0m
[93maverage test of epoch 50: loss -5.34194 acc 0.34211 roc_auc 0.39077 prc_auc 0.61372[0m
[92maverage training of epoch 51: loss -5.36187 acc 0.33333 roc_auc 0.41780 prc_auc 0.59212[0m
[93maverage test of epoch 51: loss -5.39462 acc 0.34211 roc_auc 0.58308 prc_auc 0.75647[0m
[92maverage training of epoch 52: loss -5.42042 acc 0.33333 roc_auc 0.42350 prc_auc 0.61474[0m
[93maverage test of epoch 52: loss -5.45745 acc 0.34211 roc_auc 0.39231 prc_auc 0.64266[0m
[92maverage training of epoch 53: loss -5.47730 acc 0.33333 roc_auc 0.45700 prc_auc 0.63670[0m
[93maverage test of epoch 53: loss -5.51087 acc 0.34211 roc_auc 0.66000 prc_auc 0.76533[0m
[92maverage training of epoch 54: loss -5.54121 acc 0.33333 roc_auc 0.44960 prc_auc 0.63641[0m
[93maverage test of epoch 54: loss -5.56749 acc 0.34211 roc_auc 0.60615 prc_auc 0.78673[0m
[92maverage training of epoch 55: loss -5.59395 acc 0.33333 roc_auc 0.47850 prc_auc 0.63976[0m
[93maverage test of epoch 55: loss -5.62933 acc 0.34211 roc_auc 0.51692 prc_auc 0.73527[0m
[92maverage training of epoch 56: loss -5.64956 acc 0.33333 roc_auc 0.44140 prc_auc 0.60944[0m
[93maverage test of epoch 56: loss -5.68344 acc 0.34211 roc_auc 0.58308 prc_auc 0.73712[0m
[92maverage training of epoch 57: loss -5.70598 acc 0.33333 roc_auc 0.41960 prc_auc 0.60278[0m
[93maverage test of epoch 57: loss -5.74457 acc 0.34211 roc_auc 0.59538 prc_auc 0.78063[0m
[92maverage training of epoch 58: loss -5.76370 acc 0.33333 roc_auc 0.42440 prc_auc 0.61443[0m
[93maverage test of epoch 58: loss -5.79835 acc 0.34211 roc_auc 0.32769 prc_auc 0.61410[0m
[92maverage training of epoch 59: loss -5.81932 acc 0.33333 roc_auc 0.47650 prc_auc 0.65982[0m
[93maverage test of epoch 59: loss -5.85469 acc 0.34211 roc_auc 0.53846 prc_auc 0.72403[0m
[92maverage training of epoch 60: loss -5.87703 acc 0.33333 roc_auc 0.44080 prc_auc 0.62935[0m
[93maverage test of epoch 60: loss -5.90927 acc 0.34211 roc_auc 0.51846 prc_auc 0.68758[0m
[92maverage training of epoch 61: loss -5.93357 acc 0.33333 roc_auc 0.43140 prc_auc 0.60931[0m
[93maverage test of epoch 61: loss -5.96859 acc 0.34211 roc_auc 0.57538 prc_auc 0.74362[0m
[92maverage training of epoch 62: loss -5.99206 acc 0.33333 roc_auc 0.42220 prc_auc 0.60702[0m
[93maverage test of epoch 62: loss -6.02513 acc 0.34211 roc_auc 0.35231 prc_auc 0.63413[0m
[92maverage training of epoch 63: loss -6.04606 acc 0.33333 roc_auc 0.43500 prc_auc 0.59981[0m
[93maverage test of epoch 63: loss -6.08219 acc 0.34211 roc_auc 0.50923 prc_auc 0.71034[0m
[92maverage training of epoch 64: loss -6.10069 acc 0.33333 roc_auc 0.44390 prc_auc 0.64648[0m
[93maverage test of epoch 64: loss -6.13674 acc 0.34211 roc_auc 0.77077 prc_auc 0.89609[0m
[92maverage training of epoch 65: loss -6.15854 acc 0.33333 roc_auc 0.42260 prc_auc 0.59824[0m
[93maverage test of epoch 65: loss -6.19303 acc 0.34211 roc_auc 0.44923 prc_auc 0.69570[0m
[92maverage training of epoch 66: loss -6.21566 acc 0.33333 roc_auc 0.44060 prc_auc 0.61666[0m
[93maverage test of epoch 66: loss -6.24975 acc 0.34211 roc_auc 0.32923 prc_auc 0.59300[0m
[92maverage training of epoch 67: loss -6.27426 acc 0.33333 roc_auc 0.43650 prc_auc 0.62164[0m
[93maverage test of epoch 67: loss -6.30368 acc 0.34211 roc_auc 0.68000 prc_auc 0.82548[0m
[92maverage training of epoch 68: loss -6.32818 acc 0.33333 roc_auc 0.43430 prc_auc 0.61298[0m
[93maverage test of epoch 68: loss -6.36022 acc 0.34211 roc_auc 0.47692 prc_auc 0.62603[0m
[92maverage training of epoch 69: loss -6.38479 acc 0.33333 roc_auc 0.40600 prc_auc 0.59423[0m
[93maverage test of epoch 69: loss -6.41463 acc 0.34211 roc_auc 0.57231 prc_auc 0.78730[0m
[92maverage training of epoch 70: loss -6.44154 acc 0.33333 roc_auc 0.46260 prc_auc 0.63753[0m
[93maverage test of epoch 70: loss -6.47189 acc 0.34211 roc_auc 0.51231 prc_auc 0.72166[0m
[92maverage training of epoch 71: loss -6.49805 acc 0.33333 roc_auc 0.42380 prc_auc 0.60369[0m
[93maverage test of epoch 71: loss -6.52859 acc 0.34211 roc_auc 0.48154 prc_auc 0.68182[0m
[92maverage training of epoch 72: loss -6.55340 acc 0.33333 roc_auc 0.43280 prc_auc 0.60590[0m
[93maverage test of epoch 72: loss -6.58562 acc 0.34211 roc_auc 0.49846 prc_auc 0.64448[0m
[92maverage training of epoch 73: loss -6.60831 acc 0.33333 roc_auc 0.43260 prc_auc 0.62720[0m
[93maverage test of epoch 73: loss -6.63959 acc 0.34211 roc_auc 0.58615 prc_auc 0.74287[0m
[92maverage training of epoch 74: loss -6.66537 acc 0.33333 roc_auc 0.43120 prc_auc 0.60641[0m
[93maverage test of epoch 74: loss -6.69356 acc 0.34211 roc_auc 0.48923 prc_auc 0.68568[0m
[92maverage training of epoch 75: loss -6.72047 acc 0.33333 roc_auc 0.42620 prc_auc 0.60193[0m
[93maverage test of epoch 75: loss -6.74722 acc 0.34211 roc_auc 0.51231 prc_auc 0.65192[0m
[92maverage training of epoch 76: loss -6.77633 acc 0.33333 roc_auc 0.42820 prc_auc 0.59692[0m
[93maverage test of epoch 76: loss -6.80961 acc 0.34211 roc_auc 0.50308 prc_auc 0.71773[0m
[92maverage training of epoch 77: loss -6.83252 acc 0.33333 roc_auc 0.40850 prc_auc 0.60032[0m
[93maverage test of epoch 77: loss -6.85696 acc 0.34211 roc_auc 0.53385 prc_auc 0.68317[0m
[92maverage training of epoch 78: loss -6.88929 acc 0.33333 roc_auc 0.43920 prc_auc 0.61372[0m
[93maverage test of epoch 78: loss -6.91616 acc 0.34211 roc_auc 0.65231 prc_auc 0.78471[0m
[92maverage training of epoch 79: loss -6.94238 acc 0.33333 roc_auc 0.45480 prc_auc 0.64785[0m
[93maverage test of epoch 79: loss -6.97401 acc 0.34211 roc_auc 0.26308 prc_auc 0.57173[0m
[92maverage training of epoch 80: loss -6.99875 acc 0.33333 roc_auc 0.46800 prc_auc 0.65792[0m
[93maverage test of epoch 80: loss -7.02998 acc 0.34211 roc_auc 0.62154 prc_auc 0.77308[0m
[92maverage training of epoch 81: loss -7.05515 acc 0.33333 roc_auc 0.42120 prc_auc 0.62170[0m
[93maverage test of epoch 81: loss -7.08443 acc 0.34211 roc_auc 0.48000 prc_auc 0.68570[0m
[92maverage training of epoch 82: loss -7.11154 acc 0.33333 roc_auc 0.42140 prc_auc 0.61757[0m
[93maverage test of epoch 82: loss -7.13977 acc 0.34211 roc_auc 0.53846 prc_auc 0.72400[0m
[92maverage training of epoch 83: loss -7.16669 acc 0.33333 roc_auc 0.44740 prc_auc 0.63377[0m
[93maverage test of epoch 83: loss -7.19631 acc 0.34211 roc_auc 0.52923 prc_auc 0.69105[0m
[92maverage training of epoch 84: loss -7.22177 acc 0.33333 roc_auc 0.42870 prc_auc 0.62158[0m
[93maverage test of epoch 84: loss -7.25075 acc 0.34211 roc_auc 0.61231 prc_auc 0.77571[0m
[92maverage training of epoch 85: loss -7.27747 acc 0.33333 roc_auc 0.42280 prc_auc 0.61943[0m
[93maverage test of epoch 85: loss -7.30449 acc 0.34211 roc_auc 0.52615 prc_auc 0.75798[0m
[92maverage training of epoch 86: loss -7.33405 acc 0.52000 roc_auc 0.42680 prc_auc 0.60645[0m
[93maverage test of epoch 86: loss -7.35911 acc 0.63158 roc_auc 0.50923 prc_auc 0.70162[0m
[92maverage training of epoch 87: loss -7.38873 acc 0.66667 roc_auc 0.43460 prc_auc 0.60372[0m
[93maverage test of epoch 87: loss -7.41627 acc 0.65789 roc_auc 0.51846 prc_auc 0.65974[0m
[92maverage training of epoch 88: loss -7.44349 acc 0.66667 roc_auc 0.43470 prc_auc 0.63641[0m
[93maverage test of epoch 88: loss -7.47231 acc 0.65789 roc_auc 0.59538 prc_auc 0.73832[0m
[92maverage training of epoch 89: loss -7.49972 acc 0.66667 roc_auc 0.40720 prc_auc 0.59290[0m
[93maverage test of epoch 89: loss -7.52684 acc 0.65789 roc_auc 0.42308 prc_auc 0.64765[0m
[92maverage training of epoch 90: loss -7.55619 acc 0.66667 roc_auc 0.42520 prc_auc 0.60656[0m
[93maverage test of epoch 90: loss -7.58368 acc 0.65789 roc_auc 0.54615 prc_auc 0.75610[0m
[92maverage training of epoch 91: loss -7.61063 acc 0.66667 roc_auc 0.44100 prc_auc 0.61530[0m
[93maverage test of epoch 91: loss -7.63896 acc 0.65789 roc_auc 0.51538 prc_auc 0.67563[0m
[92maverage training of epoch 92: loss -7.66626 acc 0.66667 roc_auc 0.43480 prc_auc 0.61741[0m
[93maverage test of epoch 92: loss -7.69341 acc 0.65789 roc_auc 0.66000 prc_auc 0.84768[0m
[92maverage training of epoch 93: loss -7.72267 acc 0.66667 roc_auc 0.42640 prc_auc 0.60546[0m
[93maverage test of epoch 93: loss -7.74786 acc 0.65789 roc_auc 0.53231 prc_auc 0.68341[0m
[92maverage training of epoch 94: loss -7.77787 acc 0.66667 roc_auc 0.43230 prc_auc 0.61647[0m
[93maverage test of epoch 94: loss -7.80472 acc 0.65789 roc_auc 0.51231 prc_auc 0.71369[0m
[92maverage training of epoch 95: loss -7.83266 acc 0.66667 roc_auc 0.42680 prc_auc 0.62092[0m
[93maverage test of epoch 95: loss -7.86010 acc 0.65789 roc_auc 0.67385 prc_auc 0.81029[0m
[92maverage training of epoch 96: loss -7.88829 acc 0.66667 roc_auc 0.43200 prc_auc 0.60844[0m
[93maverage test of epoch 96: loss -7.91605 acc 0.65789 roc_auc 0.58308 prc_auc 0.73878[0m
[92maverage training of epoch 97: loss -7.94312 acc 0.66667 roc_auc 0.41640 prc_auc 0.59708[0m
[93maverage test of epoch 97: loss -7.97019 acc 0.65789 roc_auc 0.44923 prc_auc 0.68922[0m
[92maverage training of epoch 98: loss -7.99939 acc 0.66667 roc_auc 0.42980 prc_auc 0.60944[0m
[93maverage test of epoch 98: loss -8.02602 acc 0.65789 roc_auc 0.43385 prc_auc 0.65197[0m
[92maverage training of epoch 99: loss -8.05512 acc 0.66667 roc_auc 0.40970 prc_auc 0.59638[0m
[93maverage test of epoch 99: loss -8.08142 acc 0.65789 roc_auc 0.46615 prc_auc 0.64713[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.35193 acc 0.66667 roc_auc 0.35500 prc_auc 0.57240[0m
[93maverage test of epoch 0: loss -0.39560 acc 0.65789 roc_auc 0.45538 prc_auc 0.67384[0m
[92maverage training of epoch 1: loss -0.47694 acc 0.66667 roc_auc 0.49900 prc_auc 0.66708[0m
[93maverage test of epoch 1: loss -0.54511 acc 0.65789 roc_auc 0.64615 prc_auc 0.71515[0m
[92maverage training of epoch 2: loss -0.60079 acc 0.66667 roc_auc 0.46960 prc_auc 0.68969[0m
[93maverage test of epoch 2: loss -0.66315 acc 0.65789 roc_auc 0.40000 prc_auc 0.60726[0m
[92maverage training of epoch 3: loss -0.76831 acc 0.66667 roc_auc 0.49980 prc_auc 0.67097[0m
[93maverage test of epoch 3: loss -0.86614 acc 0.65789 roc_auc 0.53231 prc_auc 0.73860[0m
[92maverage training of epoch 4: loss -0.95985 acc 0.66667 roc_auc 0.42400 prc_auc 0.60583[0m
[93maverage test of epoch 4: loss -1.04617 acc 0.65789 roc_auc 0.38769 prc_auc 0.60409[0m
[92maverage training of epoch 5: loss -1.15132 acc 0.66667 roc_auc 0.46740 prc_auc 0.65009[0m
[93maverage test of epoch 5: loss -1.22849 acc 0.65789 roc_auc 0.53538 prc_auc 0.75733[0m
[92maverage training of epoch 6: loss -1.30560 acc 0.66667 roc_auc 0.53840 prc_auc 0.68903[0m
[93maverage test of epoch 6: loss -1.33858 acc 0.65789 roc_auc 0.44615 prc_auc 0.66825[0m
[92maverage training of epoch 7: loss -1.43510 acc 0.66667 roc_auc 0.45220 prc_auc 0.64202[0m
[93maverage test of epoch 7: loss -1.47378 acc 0.65789 roc_auc 0.66769 prc_auc 0.82651[0m
[92maverage training of epoch 8: loss -1.53640 acc 0.66667 roc_auc 0.38860 prc_auc 0.62243[0m
[93maverage test of epoch 8: loss -1.60245 acc 0.65789 roc_auc 0.69231 prc_auc 0.81771[0m
[92maverage training of epoch 9: loss -1.65394 acc 0.66667 roc_auc 0.44320 prc_auc 0.64599[0m
[93maverage test of epoch 9: loss -1.70528 acc 0.65789 roc_auc 0.65846 prc_auc 0.76176[0m
[92maverage training of epoch 10: loss -1.75518 acc 0.66667 roc_auc 0.49820 prc_auc 0.66357[0m
[93maverage test of epoch 10: loss -1.78510 acc 0.65789 roc_auc 0.50462 prc_auc 0.69282[0m
[92maverage training of epoch 11: loss -1.86052 acc 0.66667 roc_auc 0.47960 prc_auc 0.69319[0m
[93maverage test of epoch 11: loss -1.88358 acc 0.65789 roc_auc 0.36000 prc_auc 0.63076[0m
[92maverage training of epoch 12: loss -1.95718 acc 0.66667 roc_auc 0.41960 prc_auc 0.59750[0m
[93maverage test of epoch 12: loss -1.98548 acc 0.65789 roc_auc 0.54154 prc_auc 0.77506[0m
[92maverage training of epoch 13: loss -2.04593 acc 0.66667 roc_auc 0.49840 prc_auc 0.69445[0m
[93maverage test of epoch 13: loss -2.06224 acc 0.65789 roc_auc 0.43692 prc_auc 0.63657[0m
[92maverage training of epoch 14: loss -2.13819 acc 0.66667 roc_auc 0.44280 prc_auc 0.62619[0m
[93maverage test of epoch 14: loss -2.15451 acc 0.65789 roc_auc 0.48615 prc_auc 0.73566[0m
[92maverage training of epoch 15: loss -2.22704 acc 0.66667 roc_auc 0.46640 prc_auc 0.66418[0m
[93maverage test of epoch 15: loss -2.24733 acc 0.65789 roc_auc 0.52615 prc_auc 0.73110[0m
[92maverage training of epoch 16: loss -2.30729 acc 0.66667 roc_auc 0.47970 prc_auc 0.65816[0m
[93maverage test of epoch 16: loss -2.32299 acc 0.65789 roc_auc 0.44308 prc_auc 0.61257[0m
[92maverage training of epoch 17: loss -2.39272 acc 0.66667 roc_auc 0.48920 prc_auc 0.67416[0m
[93maverage test of epoch 17: loss -2.41180 acc 0.65789 roc_auc 0.52615 prc_auc 0.74815[0m
[92maverage training of epoch 18: loss -2.46796 acc 0.66667 roc_auc 0.39980 prc_auc 0.59776[0m
[93maverage test of epoch 18: loss -2.50664 acc 0.65789 roc_auc 0.53538 prc_auc 0.64984[0m
[92maverage training of epoch 19: loss -2.55525 acc 0.66667 roc_auc 0.50600 prc_auc 0.68010[0m
[93maverage test of epoch 19: loss -2.57836 acc 0.65789 roc_auc 0.52923 prc_auc 0.69797[0m
[92maverage training of epoch 20: loss -2.63620 acc 0.66667 roc_auc 0.48700 prc_auc 0.67496[0m
[93maverage test of epoch 20: loss -2.66483 acc 0.65789 roc_auc 0.55692 prc_auc 0.73519[0m
[92maverage training of epoch 21: loss -2.71161 acc 0.66667 roc_auc 0.52140 prc_auc 0.68153[0m
[93maverage test of epoch 21: loss -2.72984 acc 0.65789 roc_auc 0.48615 prc_auc 0.62989[0m
[92maverage training of epoch 22: loss -2.78978 acc 0.66667 roc_auc 0.48760 prc_auc 0.65435[0m
[93maverage test of epoch 22: loss -2.79936 acc 0.65789 roc_auc 0.59692 prc_auc 0.77484[0m
[92maverage training of epoch 23: loss -2.86223 acc 0.66667 roc_auc 0.54440 prc_auc 0.74773[0m
[93maverage test of epoch 23: loss -2.87104 acc 0.65789 roc_auc 0.42769 prc_auc 0.67370[0m
[92maverage training of epoch 24: loss -2.92757 acc 0.66667 roc_auc 0.46840 prc_auc 0.64378[0m
[93maverage test of epoch 24: loss -2.94304 acc 0.65789 roc_auc 0.44923 prc_auc 0.66009[0m
[92maverage training of epoch 25: loss -3.00473 acc 0.66667 roc_auc 0.52320 prc_auc 0.70318[0m
[93maverage test of epoch 25: loss -3.02551 acc 0.65789 roc_auc 0.54462 prc_auc 0.76827[0m
[92maverage training of epoch 26: loss -3.07271 acc 0.66667 roc_auc 0.43140 prc_auc 0.63480[0m
[93maverage test of epoch 26: loss -3.09594 acc 0.65789 roc_auc 0.59077 prc_auc 0.73180[0m
[92maverage training of epoch 27: loss -3.13972 acc 0.66667 roc_auc 0.53340 prc_auc 0.70289[0m
[93maverage test of epoch 27: loss -3.15299 acc 0.65789 roc_auc 0.52308 prc_auc 0.69424[0m
[92maverage training of epoch 28: loss -3.21202 acc 0.66667 roc_auc 0.49880 prc_auc 0.64556[0m
[93maverage test of epoch 28: loss -3.20927 acc 0.65789 roc_auc 0.50154 prc_auc 0.71596[0m
[92maverage training of epoch 29: loss -3.27470 acc 0.66667 roc_auc 0.50200 prc_auc 0.65688[0m
[93maverage test of epoch 29: loss -3.28923 acc 0.65789 roc_auc 0.69231 prc_auc 0.78062[0m
[92maverage training of epoch 30: loss -3.34213 acc 0.66667 roc_auc 0.50040 prc_auc 0.64665[0m
[93maverage test of epoch 30: loss -3.35016 acc 0.65789 roc_auc 0.58769 prc_auc 0.71900[0m
[92maverage training of epoch 31: loss -3.40048 acc 0.66667 roc_auc 0.49640 prc_auc 0.70697[0m
[93maverage test of epoch 31: loss -3.40629 acc 0.65789 roc_auc 0.47077 prc_auc 0.64096[0m
[92maverage training of epoch 32: loss -3.46501 acc 0.66667 roc_auc 0.51540 prc_auc 0.66855[0m
[93maverage test of epoch 32: loss -3.47572 acc 0.65789 roc_auc 0.49538 prc_auc 0.66637[0m
[92maverage training of epoch 33: loss -3.52313 acc 0.66667 roc_auc 0.41880 prc_auc 0.64276[0m
[93maverage test of epoch 33: loss -3.53832 acc 0.65789 roc_auc 0.55692 prc_auc 0.70643[0m
[92maverage training of epoch 34: loss -3.58705 acc 0.66667 roc_auc 0.45200 prc_auc 0.62654[0m
[93maverage test of epoch 34: loss -3.59104 acc 0.65789 roc_auc 0.35692 prc_auc 0.58392[0m
[92maverage training of epoch 35: loss -3.65662 acc 0.66667 roc_auc 0.46840 prc_auc 0.64338[0m
[93maverage test of epoch 35: loss -3.65444 acc 0.65789 roc_auc 0.55692 prc_auc 0.72932[0m
[92maverage training of epoch 36: loss -3.70913 acc 0.66667 roc_auc 0.45410 prc_auc 0.63830[0m
[93maverage test of epoch 36: loss -3.72361 acc 0.65789 roc_auc 0.52923 prc_auc 0.70092[0m
[92maverage training of epoch 37: loss -3.77344 acc 0.66667 roc_auc 0.44780 prc_auc 0.63416[0m
[93maverage test of epoch 37: loss -3.78128 acc 0.65789 roc_auc 0.46154 prc_auc 0.65826[0m
[92maverage training of epoch 38: loss -3.83026 acc 0.66667 roc_auc 0.42700 prc_auc 0.61537[0m
[93maverage test of epoch 38: loss -3.83192 acc 0.65789 roc_auc 0.46154 prc_auc 0.67947[0m
[92maverage training of epoch 39: loss -3.89072 acc 0.66667 roc_auc 0.43880 prc_auc 0.63534[0m
[93maverage test of epoch 39: loss -3.89012 acc 0.65789 roc_auc 0.51385 prc_auc 0.68964[0m
[92maverage training of epoch 40: loss -3.95385 acc 0.66667 roc_auc 0.49080 prc_auc 0.67321[0m
[93maverage test of epoch 40: loss -3.96788 acc 0.65789 roc_auc 0.66615 prc_auc 0.81194[0m
[92maverage training of epoch 41: loss -4.01079 acc 0.66667 roc_auc 0.48420 prc_auc 0.62491[0m
[93maverage test of epoch 41: loss -4.02361 acc 0.65789 roc_auc 0.56615 prc_auc 0.70241[0m
[92maverage training of epoch 42: loss -4.07278 acc 0.66667 roc_auc 0.53500 prc_auc 0.67942[0m
[93maverage test of epoch 42: loss -4.07554 acc 0.65789 roc_auc 0.36923 prc_auc 0.62219[0m
[92maverage training of epoch 43: loss -4.13242 acc 0.66667 roc_auc 0.41360 prc_auc 0.63816[0m
[93maverage test of epoch 43: loss -4.13151 acc 0.65789 roc_auc 0.45538 prc_auc 0.68257[0m
[92maverage training of epoch 44: loss -4.19129 acc 0.66667 roc_auc 0.49500 prc_auc 0.64810[0m
[93maverage test of epoch 44: loss -4.19851 acc 0.65789 roc_auc 0.76000 prc_auc 0.87590[0m
[92maverage training of epoch 45: loss -4.25061 acc 0.66667 roc_auc 0.47650 prc_auc 0.64886[0m
[93maverage test of epoch 45: loss -4.25224 acc 0.65789 roc_auc 0.49846 prc_auc 0.69511[0m
[92maverage training of epoch 46: loss -4.30436 acc 0.66667 roc_auc 0.39720 prc_auc 0.61635[0m
[93maverage test of epoch 46: loss -4.31361 acc 0.65789 roc_auc 0.63692 prc_auc 0.79006[0m
[92maverage training of epoch 47: loss -4.36379 acc 0.66667 roc_auc 0.44270 prc_auc 0.63525[0m
[93maverage test of epoch 47: loss -4.36414 acc 0.65789 roc_auc 0.43692 prc_auc 0.64566[0m
[92maverage training of epoch 48: loss -4.42417 acc 0.66667 roc_auc 0.40010 prc_auc 0.60045[0m
[93maverage test of epoch 48: loss -4.42321 acc 0.65789 roc_auc 0.47692 prc_auc 0.71319[0m
[92maverage training of epoch 49: loss -4.48483 acc 0.66667 roc_auc 0.54560 prc_auc 0.68386[0m
[93maverage test of epoch 49: loss -4.48775 acc 0.65789 roc_auc 0.56154 prc_auc 0.74760[0m
[92maverage training of epoch 50: loss -4.53923 acc 0.66667 roc_auc 0.42190 prc_auc 0.60238[0m
[93maverage test of epoch 50: loss -4.54105 acc 0.65789 roc_auc 0.50000 prc_auc 0.70303[0m
[92maverage training of epoch 51: loss -4.59874 acc 0.66667 roc_auc 0.48550 prc_auc 0.66259[0m
[93maverage test of epoch 51: loss -4.59803 acc 0.65789 roc_auc 0.44923 prc_auc 0.66032[0m
[92maverage training of epoch 52: loss -4.65273 acc 0.66667 roc_auc 0.48200 prc_auc 0.65853[0m
[93maverage test of epoch 52: loss -4.65173 acc 0.65789 roc_auc 0.51231 prc_auc 0.68913[0m
[92maverage training of epoch 53: loss -4.70958 acc 0.66667 roc_auc 0.43020 prc_auc 0.63283[0m
[93maverage test of epoch 53: loss -4.71543 acc 0.65789 roc_auc 0.50615 prc_auc 0.68806[0m
[92maverage training of epoch 54: loss -4.76920 acc 0.66667 roc_auc 0.48380 prc_auc 0.63745[0m
[93maverage test of epoch 54: loss -4.76976 acc 0.65789 roc_auc 0.48154 prc_auc 0.65232[0m
[92maverage training of epoch 55: loss -4.82542 acc 0.66667 roc_auc 0.45000 prc_auc 0.61868[0m
[93maverage test of epoch 55: loss -4.82796 acc 0.65789 roc_auc 0.43231 prc_auc 0.62344[0m
[92maverage training of epoch 56: loss -4.88434 acc 0.66667 roc_auc 0.46910 prc_auc 0.62283[0m
[93maverage test of epoch 56: loss -4.88534 acc 0.65789 roc_auc 0.66615 prc_auc 0.79560[0m
[92maverage training of epoch 57: loss -4.93655 acc 0.66667 roc_auc 0.33720 prc_auc 0.57876[0m
[93maverage test of epoch 57: loss -4.94407 acc 0.65789 roc_auc 0.38615 prc_auc 0.60612[0m
[92maverage training of epoch 58: loss -4.99637 acc 0.66667 roc_auc 0.41550 prc_auc 0.59519[0m
[93maverage test of epoch 58: loss -4.99563 acc 0.65789 roc_auc 0.45385 prc_auc 0.70335[0m
[92maverage training of epoch 59: loss -5.05265 acc 0.66667 roc_auc 0.46840 prc_auc 0.62400[0m
[93maverage test of epoch 59: loss -5.05041 acc 0.65789 roc_auc 0.40308 prc_auc 0.60893[0m
[92maverage training of epoch 60: loss -5.11021 acc 0.66667 roc_auc 0.43800 prc_auc 0.62575[0m
[93maverage test of epoch 60: loss -5.10806 acc 0.65789 roc_auc 0.56769 prc_auc 0.67670[0m
[92maverage training of epoch 61: loss -5.16654 acc 0.66667 roc_auc 0.47420 prc_auc 0.63673[0m
[93maverage test of epoch 61: loss -5.16784 acc 0.65789 roc_auc 0.59385 prc_auc 0.78258[0m
[92maverage training of epoch 62: loss -5.22380 acc 0.66667 roc_auc 0.45480 prc_auc 0.61568[0m
[93maverage test of epoch 62: loss -5.22040 acc 0.65789 roc_auc 0.44923 prc_auc 0.69832[0m
[92maverage training of epoch 63: loss -5.28015 acc 0.66667 roc_auc 0.40000 prc_auc 0.60656[0m
[93maverage test of epoch 63: loss -5.28220 acc 0.65789 roc_auc 0.54769 prc_auc 0.69324[0m
[92maverage training of epoch 64: loss -5.33696 acc 0.66667 roc_auc 0.41890 prc_auc 0.60522[0m
[93maverage test of epoch 64: loss -5.33593 acc 0.65789 roc_auc 0.42615 prc_auc 0.63671[0m
[92maverage training of epoch 65: loss -5.39299 acc 0.66667 roc_auc 0.46510 prc_auc 0.61704[0m
[93maverage test of epoch 65: loss -5.38939 acc 0.65789 roc_auc 0.38769 prc_auc 0.65258[0m
[92maverage training of epoch 66: loss -5.44922 acc 0.66667 roc_auc 0.41790 prc_auc 0.59718[0m
[93maverage test of epoch 66: loss -5.44701 acc 0.65789 roc_auc 0.29846 prc_auc 0.63490[0m
[92maverage training of epoch 67: loss -5.50616 acc 0.66667 roc_auc 0.48100 prc_auc 0.63646[0m
[93maverage test of epoch 67: loss -5.50248 acc 0.65789 roc_auc 0.59538 prc_auc 0.73533[0m
[92maverage training of epoch 68: loss -5.56086 acc 0.66667 roc_auc 0.44920 prc_auc 0.61400[0m
[93maverage test of epoch 68: loss -5.56151 acc 0.65789 roc_auc 0.52923 prc_auc 0.70160[0m
[92maverage training of epoch 69: loss -5.61761 acc 0.66667 roc_auc 0.47240 prc_auc 0.64829[0m
[93maverage test of epoch 69: loss -5.61047 acc 0.65789 roc_auc 0.42154 prc_auc 0.62525[0m
[92maverage training of epoch 70: loss -5.67260 acc 0.66667 roc_auc 0.44230 prc_auc 0.62229[0m
[93maverage test of epoch 70: loss -5.67051 acc 0.65789 roc_auc 0.48462 prc_auc 0.64693[0m
[92maverage training of epoch 71: loss -5.72939 acc 0.66667 roc_auc 0.50160 prc_auc 0.68210[0m
[93maverage test of epoch 71: loss -5.72842 acc 0.65789 roc_auc 0.58308 prc_auc 0.77265[0m
[92maverage training of epoch 72: loss -5.78466 acc 0.66667 roc_auc 0.38930 prc_auc 0.59354[0m
[93maverage test of epoch 72: loss -5.78194 acc 0.65789 roc_auc 0.54769 prc_auc 0.77116[0m
[92maverage training of epoch 73: loss -5.84087 acc 0.66667 roc_auc 0.40510 prc_auc 0.60200[0m
[93maverage test of epoch 73: loss -5.83820 acc 0.65789 roc_auc 0.44615 prc_auc 0.67342[0m
[92maverage training of epoch 74: loss -5.89645 acc 0.66667 roc_auc 0.46840 prc_auc 0.64230[0m
[93maverage test of epoch 74: loss -5.89295 acc 0.65789 roc_auc 0.47846 prc_auc 0.65841[0m
[92maverage training of epoch 75: loss -5.95230 acc 0.66667 roc_auc 0.39790 prc_auc 0.58144[0m
[93maverage test of epoch 75: loss -5.94830 acc 0.65789 roc_auc 0.39385 prc_auc 0.63738[0m
[92maverage training of epoch 76: loss -6.00813 acc 0.66667 roc_auc 0.32080 prc_auc 0.55274[0m
[93maverage test of epoch 76: loss -6.00761 acc 0.65789 roc_auc 0.63077 prc_auc 0.79371[0m
[92maverage training of epoch 77: loss -6.06461 acc 0.66667 roc_auc 0.40690 prc_auc 0.60058[0m
[93maverage test of epoch 77: loss -6.06269 acc 0.65789 roc_auc 0.53692 prc_auc 0.73437[0m
[92maverage training of epoch 78: loss -6.11992 acc 0.66667 roc_auc 0.43830 prc_auc 0.62788[0m
[93maverage test of epoch 78: loss -6.11628 acc 0.65789 roc_auc 0.41077 prc_auc 0.63903[0m
[92maverage training of epoch 79: loss -6.17640 acc 0.66667 roc_auc 0.50100 prc_auc 0.65976[0m
[93maverage test of epoch 79: loss -6.17150 acc 0.65789 roc_auc 0.41077 prc_auc 0.59319[0m
[92maverage training of epoch 80: loss -6.23094 acc 0.66667 roc_auc 0.39660 prc_auc 0.59877[0m
[93maverage test of epoch 80: loss -6.22730 acc 0.65789 roc_auc 0.30000 prc_auc 0.58148[0m
[92maverage training of epoch 81: loss -6.28813 acc 0.66667 roc_auc 0.43500 prc_auc 0.63551[0m
[93maverage test of epoch 81: loss -6.28186 acc 0.65789 roc_auc 0.48462 prc_auc 0.64829[0m
[92maverage training of epoch 82: loss -6.34350 acc 0.66667 roc_auc 0.45410 prc_auc 0.61267[0m
[93maverage test of epoch 82: loss -6.33754 acc 0.65789 roc_auc 0.39692 prc_auc 0.59158[0m
[92maverage training of epoch 83: loss -6.39879 acc 0.66667 roc_auc 0.45200 prc_auc 0.61980[0m
[93maverage test of epoch 83: loss -6.39593 acc 0.65789 roc_auc 0.43538 prc_auc 0.66523[0m
[92maverage training of epoch 84: loss -6.45551 acc 0.66667 roc_auc 0.45530 prc_auc 0.62318[0m
[93maverage test of epoch 84: loss -6.45119 acc 0.65789 roc_auc 0.51846 prc_auc 0.73120[0m
[92maverage training of epoch 85: loss -6.50895 acc 0.66667 roc_auc 0.37360 prc_auc 0.57833[0m
[93maverage test of epoch 85: loss -6.50562 acc 0.65789 roc_auc 0.48000 prc_auc 0.64203[0m
[92maverage training of epoch 86: loss -6.56539 acc 0.66667 roc_auc 0.36980 prc_auc 0.58001[0m
[93maverage test of epoch 86: loss -6.56216 acc 0.65789 roc_auc 0.64154 prc_auc 0.79281[0m
[92maverage training of epoch 87: loss -6.62156 acc 0.66667 roc_auc 0.43290 prc_auc 0.60648[0m
[93maverage test of epoch 87: loss -6.61638 acc 0.65789 roc_auc 0.66308 prc_auc 0.79139[0m
[92maverage training of epoch 88: loss -6.67612 acc 0.66667 roc_auc 0.40380 prc_auc 0.60388[0m
[93maverage test of epoch 88: loss -6.67023 acc 0.65789 roc_auc 0.59538 prc_auc 0.71134[0m
[92maverage training of epoch 89: loss -6.73196 acc 0.66667 roc_auc 0.39910 prc_auc 0.59535[0m
[93maverage test of epoch 89: loss -6.72582 acc 0.65789 roc_auc 0.54154 prc_auc 0.72693[0m
[92maverage training of epoch 90: loss -6.78770 acc 0.66667 roc_auc 0.41610 prc_auc 0.59913[0m
[93maverage test of epoch 90: loss -6.78403 acc 0.65789 roc_auc 0.61538 prc_auc 0.74977[0m
[92maverage training of epoch 91: loss -6.84405 acc 0.66667 roc_auc 0.42620 prc_auc 0.60246[0m
[93maverage test of epoch 91: loss -6.83683 acc 0.65789 roc_auc 0.52923 prc_auc 0.71370[0m
[92maverage training of epoch 92: loss -6.89923 acc 0.66667 roc_auc 0.42450 prc_auc 0.62065[0m
[93maverage test of epoch 92: loss -6.89321 acc 0.65789 roc_auc 0.44462 prc_auc 0.67218[0m
[92maverage training of epoch 93: loss -6.95426 acc 0.66667 roc_auc 0.46870 prc_auc 0.63393[0m
[93maverage test of epoch 93: loss -6.94714 acc 0.65789 roc_auc 0.60000 prc_auc 0.73807[0m
[92maverage training of epoch 94: loss -7.01011 acc 0.66667 roc_auc 0.40740 prc_auc 0.60501[0m
[93maverage test of epoch 94: loss -7.00482 acc 0.65789 roc_auc 0.66154 prc_auc 0.77263[0m
[92maverage training of epoch 95: loss -7.06487 acc 0.66667 roc_auc 0.40640 prc_auc 0.58862[0m
[93maverage test of epoch 95: loss -7.05919 acc 0.65789 roc_auc 0.33231 prc_auc 0.55487[0m
[92maverage training of epoch 96: loss -7.12109 acc 0.66667 roc_auc 0.45440 prc_auc 0.63005[0m
[93maverage test of epoch 96: loss -7.11577 acc 0.65789 roc_auc 0.37846 prc_auc 0.58942[0m
[92maverage training of epoch 97: loss -7.17668 acc 0.66667 roc_auc 0.44900 prc_auc 0.65475[0m
[93maverage test of epoch 97: loss -7.17036 acc 0.65789 roc_auc 0.50615 prc_auc 0.64309[0m
[92maverage training of epoch 98: loss -7.23202 acc 0.66667 roc_auc 0.37730 prc_auc 0.58183[0m
[93maverage test of epoch 98: loss -7.22480 acc 0.65789 roc_auc 0.46308 prc_auc 0.65660[0m
[92maverage training of epoch 99: loss -7.28700 acc 0.66667 roc_auc 0.38660 prc_auc 0.58137[0m
[93maverage test of epoch 99: loss -7.28108 acc 0.65789 roc_auc 0.70462 prc_auc 0.81444[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss 0.55819 acc 0.50331 roc_auc 0.38000 prc_auc 0.62132[0m
[93maverage test of epoch 0: loss 0.53778 acc 0.54054 roc_auc 0.32000 prc_auc 0.57470[0m
[92maverage training of epoch 1: loss 0.47623 acc 0.62914 roc_auc 0.43157 prc_auc 0.64681[0m
[93maverage test of epoch 1: loss 0.45074 acc 0.62162 roc_auc 0.39000 prc_auc 0.63479[0m
[92maverage training of epoch 2: loss 0.41906 acc 0.64901 roc_auc 0.40961 prc_auc 0.59104[0m
[93maverage test of epoch 2: loss 0.36975 acc 0.67568 roc_auc 0.36333 prc_auc 0.57789[0m
[92maverage training of epoch 3: loss 0.34010 acc 0.65563 roc_auc 0.48961 prc_auc 0.65269[0m
[93maverage test of epoch 3: loss 0.28590 acc 0.67568 roc_auc 0.51000 prc_auc 0.73221[0m
[92maverage training of epoch 4: loss 0.29169 acc 0.65563 roc_auc 0.41549 prc_auc 0.59981[0m
[93maverage test of epoch 4: loss 0.24991 acc 0.70270 roc_auc 0.43667 prc_auc 0.65691[0m
[92maverage training of epoch 5: loss 0.21314 acc 0.66887 roc_auc 0.50098 prc_auc 0.64648[0m
[93maverage test of epoch 5: loss 0.17271 acc 0.67568 roc_auc 0.51000 prc_auc 0.66619[0m
[92maverage training of epoch 6: loss 0.17484 acc 0.66225 roc_auc 0.47157 prc_auc 0.65455[0m
[93maverage test of epoch 6: loss 0.14189 acc 0.67568 roc_auc 0.35000 prc_auc 0.57925[0m
[92maverage training of epoch 7: loss 0.11001 acc 0.66225 roc_auc 0.47451 prc_auc 0.62407[0m
[93maverage test of epoch 7: loss 0.10249 acc 0.67568 roc_auc 0.45000 prc_auc 0.71083[0m
[92maverage training of epoch 8: loss 0.05891 acc 0.66225 roc_auc 0.48235 prc_auc 0.67753[0m
[93maverage test of epoch 8: loss 0.00958 acc 0.67568 roc_auc 0.57000 prc_auc 0.72994[0m
[92maverage training of epoch 9: loss -0.03007 acc 0.66225 roc_auc 0.55314 prc_auc 0.73844[0m
[93maverage test of epoch 9: loss -0.03971 acc 0.67568 roc_auc 0.47000 prc_auc 0.68841[0m
[92maverage training of epoch 10: loss -0.09022 acc 0.66225 roc_auc 0.49784 prc_auc 0.68592[0m
[93maverage test of epoch 10: loss -0.13169 acc 0.67568 roc_auc 0.32667 prc_auc 0.59587[0m
[92maverage training of epoch 11: loss -0.17189 acc 0.66225 roc_auc 0.43157 prc_auc 0.61961[0m
[93maverage test of epoch 11: loss -0.26856 acc 0.67568 roc_auc 0.50000 prc_auc 0.72925[0m
[92maverage training of epoch 12: loss -0.33736 acc 0.66225 roc_auc 0.60275 prc_auc 0.73622[0m
[93maverage test of epoch 12: loss -0.36734 acc 0.67568 roc_auc 0.50333 prc_auc 0.65734[0m
[92maverage training of epoch 13: loss -0.42985 acc 0.66225 roc_auc 0.46196 prc_auc 0.63730[0m
[93maverage test of epoch 13: loss -0.51129 acc 0.67568 roc_auc 0.51333 prc_auc 0.74646[0m
[92maverage training of epoch 14: loss -0.61798 acc 0.66225 roc_auc 0.54118 prc_auc 0.67871[0m
[93maverage test of epoch 14: loss -0.65630 acc 0.67568 roc_auc 0.36000 prc_auc 0.62835[0m
[92maverage training of epoch 15: loss -0.71296 acc 0.66225 roc_auc 0.49392 prc_auc 0.66693[0m
[93maverage test of epoch 15: loss -0.84762 acc 0.67568 roc_auc 0.35667 prc_auc 0.59687[0m
[92maverage training of epoch 16: loss -0.87799 acc 0.66225 roc_auc 0.50824 prc_auc 0.66459[0m
[93maverage test of epoch 16: loss -0.97235 acc 0.67568 roc_auc 0.51000 prc_auc 0.68955[0m
[92maverage training of epoch 17: loss -1.03409 acc 0.66225 roc_auc 0.54431 prc_auc 0.70085[0m
[93maverage test of epoch 17: loss -1.11921 acc 0.67568 roc_auc 0.48667 prc_auc 0.67311[0m
[92maverage training of epoch 18: loss -1.12677 acc 0.66225 roc_auc 0.42706 prc_auc 0.62712[0m
[93maverage test of epoch 18: loss -1.26360 acc 0.67568 roc_auc 0.54667 prc_auc 0.74585[0m
[92maverage training of epoch 19: loss -1.27126 acc 0.66225 roc_auc 0.54157 prc_auc 0.70771[0m
[93maverage test of epoch 19: loss -1.37048 acc 0.67568 roc_auc 0.63333 prc_auc 0.82016[0m
[92maverage training of epoch 20: loss -1.35798 acc 0.66225 roc_auc 0.49059 prc_auc 0.66364[0m
[93maverage test of epoch 20: loss -1.42534 acc 0.67568 roc_auc 0.36667 prc_auc 0.62709[0m
[92maverage training of epoch 21: loss -1.45569 acc 0.66225 roc_auc 0.50647 prc_auc 0.65634[0m
[93maverage test of epoch 21: loss -1.58321 acc 0.67568 roc_auc 0.52667 prc_auc 0.71674[0m
[92maverage training of epoch 22: loss -1.52699 acc 0.66225 roc_auc 0.51510 prc_auc 0.70857[0m
[93maverage test of epoch 22: loss -1.64118 acc 0.67568 roc_auc 0.52667 prc_auc 0.72739[0m
[92maverage training of epoch 23: loss -1.61687 acc 0.66225 roc_auc 0.45853 prc_auc 0.64083[0m
[93maverage test of epoch 23: loss -1.73968 acc 0.67568 roc_auc 0.48000 prc_auc 0.74478[0m
[92maverage training of epoch 24: loss -1.70744 acc 0.66225 roc_auc 0.51471 prc_auc 0.65091[0m
[93maverage test of epoch 24: loss -1.81488 acc 0.67568 roc_auc 0.52333 prc_auc 0.69825[0m
[92maverage training of epoch 25: loss -1.77747 acc 0.66225 roc_auc 0.44294 prc_auc 0.61388[0m
[93maverage test of epoch 25: loss -1.89769 acc 0.67568 roc_auc 0.50000 prc_auc 0.70991[0m
[92maverage training of epoch 26: loss -1.87274 acc 0.66225 roc_auc 0.57912 prc_auc 0.71106[0m
[93maverage test of epoch 26: loss -1.97564 acc 0.67568 roc_auc 0.47833 prc_auc 0.71336[0m
[92maverage training of epoch 27: loss -1.93036 acc 0.66225 roc_auc 0.43480 prc_auc 0.63305[0m
[93maverage test of epoch 27: loss -2.02654 acc 0.67568 roc_auc 0.47667 prc_auc 0.71891[0m
[92maverage training of epoch 28: loss -1.99690 acc 0.66225 roc_auc 0.54098 prc_auc 0.73030[0m
[93maverage test of epoch 28: loss -2.10079 acc 0.67568 roc_auc 0.54333 prc_auc 0.72673[0m
[92maverage training of epoch 29: loss -2.05958 acc 0.66225 roc_auc 0.45294 prc_auc 0.64936[0m
[93maverage test of epoch 29: loss -2.12641 acc 0.67568 roc_auc 0.27333 prc_auc 0.59322[0m
[92maverage training of epoch 30: loss -2.12322 acc 0.66225 roc_auc 0.51745 prc_auc 0.70626[0m
[93maverage test of epoch 30: loss -2.25918 acc 0.67568 roc_auc 0.65333 prc_auc 0.80251[0m
[92maverage training of epoch 31: loss -2.19565 acc 0.66225 roc_auc 0.50627 prc_auc 0.65403[0m
[93maverage test of epoch 31: loss -2.30156 acc 0.67568 roc_auc 0.51667 prc_auc 0.72346[0m
[92maverage training of epoch 32: loss -2.25077 acc 0.66225 roc_auc 0.44833 prc_auc 0.66991[0m
[93maverage test of epoch 32: loss -2.36359 acc 0.67568 roc_auc 0.41333 prc_auc 0.69440[0m
[92maverage training of epoch 33: loss -2.32884 acc 0.66225 roc_auc 0.53118 prc_auc 0.67960[0m
[93maverage test of epoch 33: loss -2.43669 acc 0.67568 roc_auc 0.49333 prc_auc 0.75137[0m
[92maverage training of epoch 34: loss -2.39464 acc 0.66225 roc_auc 0.55333 prc_auc 0.71040[0m
[93maverage test of epoch 34: loss -2.51078 acc 0.67568 roc_auc 0.54333 prc_auc 0.73288[0m
[92maverage training of epoch 35: loss -2.45863 acc 0.66225 roc_auc 0.49990 prc_auc 0.69202[0m
[93maverage test of epoch 35: loss -2.57803 acc 0.67568 roc_auc 0.50333 prc_auc 0.74832[0m
[92maverage training of epoch 36: loss -2.54549 acc 0.66225 roc_auc 0.55157 prc_auc 0.72162[0m
[93maverage test of epoch 36: loss -2.69910 acc 0.67568 roc_auc 0.78000 prc_auc 0.87731[0m
[92maverage training of epoch 37: loss -2.62141 acc 0.66225 roc_auc 0.45225 prc_auc 0.65844[0m
[93maverage test of epoch 37: loss -2.75548 acc 0.67568 roc_auc 0.61667 prc_auc 0.82090[0m
[92maverage training of epoch 38: loss -2.71715 acc 0.66225 roc_auc 0.48578 prc_auc 0.67211[0m
[93maverage test of epoch 38: loss -2.87487 acc 0.67568 roc_auc 0.62667 prc_auc 0.78082[0m
[92maverage training of epoch 39: loss -2.85899 acc 0.66225 roc_auc 0.55412 prc_auc 0.73470[0m
[93maverage test of epoch 39: loss -3.05444 acc 0.67568 roc_auc 0.73667 prc_auc 0.86100[0mUsing backend: pytorch

[92maverage training of epoch 40: loss -3.04065 acc 0.66225 roc_auc 0.68206 prc_auc 0.80485[0m
[93maverage test of epoch 40: loss -3.21722 acc 0.67568 roc_auc 0.65667 prc_auc 0.77410[0m
[92maverage training of epoch 41: loss -3.20568 acc 0.66225 roc_auc 0.73363 prc_auc 0.84517[0m
[93maverage test of epoch 41: loss -3.37272 acc 0.67568 roc_auc 0.58000 prc_auc 0.68638[0m
[92maverage training of epoch 42: loss -3.34605 acc 0.66225 roc_auc 0.75725 prc_auc 0.85186[0m
[93maverage test of epoch 42: loss -3.37465 acc 0.67568 roc_auc 0.74667 prc_auc 0.86912[0m
[92maverage training of epoch 43: loss -3.42422 acc 0.66225 roc_auc 0.77510 prc_auc 0.86433[0m
[93maverage test of epoch 43: loss -3.55551 acc 0.67568 roc_auc 0.76333 prc_auc 0.87737[0m
[92maverage training of epoch 44: loss -3.55699 acc 0.66225 roc_auc 0.82235 prc_auc 0.89800[0m
[93maverage test of epoch 44: loss -3.61885 acc 0.67568 roc_auc 0.76667 prc_auc 0.87226[0m
[92maverage training of epoch 45: loss -3.65917 acc 0.66225 roc_auc 0.85118 prc_auc 0.87830[0m
[93maverage test of epoch 45: loss -3.76589 acc 0.67568 roc_auc 0.80000 prc_auc 0.85220[0m
[92maverage training of epoch 46: loss -3.71940 acc 0.66225 roc_auc 0.83549 prc_auc 0.90446[0m
[93maverage test of epoch 46: loss -3.80011 acc 0.67568 roc_auc 0.86333 prc_auc 0.94015[0m
[92maverage training of epoch 47: loss -3.75744 acc 0.67550 roc_auc 0.85510 prc_auc 0.92044[0m
[93maverage test of epoch 47: loss -3.79234 acc 0.67568 roc_auc 0.77333 prc_auc 0.86225[0m
[92maverage training of epoch 48: loss -3.79404 acc 0.68212 roc_auc 0.84529 prc_auc 0.91660[0m
[93maverage test of epoch 48: loss -3.98287 acc 0.67568 roc_auc 0.88333 prc_auc 0.94744[0m
[92maverage training of epoch 49: loss -3.99110 acc 0.68212 roc_auc 0.89000 prc_auc 0.93031[0m
[93maverage test of epoch 49: loss -4.04818 acc 0.67568 roc_auc 0.85333 prc_auc 0.85934[0m
[92maverage training of epoch 50: loss -4.03184 acc 0.72185 roc_auc 0.86882 prc_auc 0.91380[0m
[93maverage test of epoch 50: loss -4.07111 acc 0.67568 roc_auc 0.89000 prc_auc 0.95260[0m
[92maverage training of epoch 51: loss -4.05255 acc 0.67550 roc_auc 0.84255 prc_auc 0.90705[0m
[93maverage test of epoch 51: loss -4.13517 acc 0.67568 roc_auc 0.84000 prc_auc 0.90139[0m
[92maverage training of epoch 52: loss -4.11686 acc 0.70199 roc_auc 0.86569 prc_auc 0.92357[0m
[93maverage test of epoch 52: loss -4.14888 acc 0.78378 roc_auc 0.84667 prc_auc 0.89435[0m
[92maverage training of epoch 53: loss -4.20332 acc 0.74172 roc_auc 0.88255 prc_auc 0.91373[0m
[93maverage test of epoch 53: loss -4.31204 acc 0.70270 roc_auc 0.88667 prc_auc 0.93079[0m
[92maverage training of epoch 54: loss -4.29145 acc 0.73510 roc_auc 0.89412 prc_auc 0.94563[0m
[93maverage test of epoch 54: loss -4.34434 acc 0.72973 roc_auc 0.87000 prc_auc 0.93765[0m
[92maverage training of epoch 55: loss -4.29441 acc 0.78146 roc_auc 0.88196 prc_auc 0.93748[0m
[93maverage test of epoch 55: loss -4.44255 acc 0.78378 roc_auc 0.92667 prc_auc 0.97080[0m
[92maverage training of epoch 56: loss -4.44651 acc 0.79470 roc_auc 0.89843 prc_auc 0.94154[0m
[93maverage test of epoch 56: loss -4.46734 acc 0.70270 roc_auc 0.84667 prc_auc 0.89497[0m
[92maverage training of epoch 57: loss -4.44731 acc 0.76159 roc_auc 0.88343 prc_auc 0.92770[0m
[93maverage test of epoch 57: loss -4.46521 acc 0.72973 roc_auc 0.88000 prc_auc 0.94721[0m
[92maverage training of epoch 58: loss -4.49798 acc 0.79470 roc_auc 0.89882 prc_auc 0.94422[0m
[93maverage test of epoch 58: loss -4.61721 acc 0.75676 roc_auc 0.84333 prc_auc 0.88406[0m
[92maverage training of epoch 59: loss -4.56206 acc 0.74172 roc_auc 0.88980 prc_auc 0.93961[0m
[93maverage test of epoch 59: loss -4.67554 acc 0.81081 roc_auc 0.92333 prc_auc 0.96581[0m
[92maverage training of epoch 60: loss -4.65961 acc 0.81457 roc_auc 0.88980 prc_auc 0.93031[0m
[93maverage test of epoch 60: loss -4.67459 acc 0.81081 roc_auc 0.81333 prc_auc 0.86585[0m
[92maverage training of epoch 61: loss -4.68043 acc 0.78808 roc_auc 0.87137 prc_auc 0.89973[0m
[93maverage test of epoch 61: loss -4.58730 acc 0.75676 roc_auc 0.83333 prc_auc 0.89297[0m
[92maverage training of epoch 62: loss -4.77004 acc 0.82119 roc_auc 0.90176 prc_auc 0.94404[0m
[93maverage test of epoch 62: loss -4.80165 acc 0.78378 roc_auc 0.84333 prc_auc 0.87444[0m
[92maverage training of epoch 63: loss -4.86384 acc 0.82781 roc_auc 0.90294 prc_auc 0.94346[0m
[93maverage test of epoch 63: loss -4.86227 acc 0.78378 roc_auc 0.86333 prc_auc 0.92606[0m
[92maverage training of epoch 64: loss -4.82928 acc 0.81457 roc_auc 0.88922 prc_auc 0.93901[0m
[93maverage test of epoch 64: loss -4.78177 acc 0.75676 roc_auc 0.82000 prc_auc 0.88628[0m
[92maverage training of epoch 65: loss -4.89301 acc 0.80795 roc_auc 0.88627 prc_auc 0.93066[0m
[93maverage test of epoch 65: loss -4.84815 acc 0.78378 roc_auc 0.82000 prc_auc 0.89247[0m
[92maverage training of epoch 66: loss -4.91738 acc 0.79470 roc_auc 0.88020 prc_auc 0.92316[0m
[93maverage test of epoch 66: loss -4.99587 acc 0.81081 roc_auc 0.87000 prc_auc 0.93810[0m
[92maverage training of epoch 67: loss -5.01142 acc 0.82781 roc_auc 0.88059 prc_auc 0.90614[0m
[93maverage test of epoch 67: loss -5.10475 acc 0.81081 roc_auc 0.85333 prc_auc 0.91067[0m
[92maverage training of epoch 68: loss -5.07315 acc 0.81457 roc_auc 0.90529 prc_auc 0.95044[0m
[93maverage test of epoch 68: loss -5.15888 acc 0.81081 roc_auc 0.90667 prc_auc 0.95847[0m
[92maverage training of epoch 69: loss -5.10902 acc 0.83444 roc_auc 0.87980 prc_auc 0.91840[0m
[93maverage test of epoch 69: loss -5.32776 acc 0.83784 roc_auc 0.88667 prc_auc 0.92760[0m
[92maverage training of epoch 70: loss -5.15711 acc 0.80132 roc_auc 0.90824 prc_auc 0.95042[0m
[93maverage test of epoch 70: loss -5.22928 acc 0.81081 roc_auc 0.86667 prc_auc 0.91659[0m
[92maverage training of epoch 71: loss -5.25741 acc 0.84106 roc_auc 0.91647 prc_auc 0.95644[0m
[93maverage test of epoch 71: loss -5.32491 acc 0.83784 roc_auc 0.83333 prc_auc 0.89226[0m
[92maverage training of epoch 72: loss -5.29558 acc 0.81457 roc_auc 0.90490 prc_auc 0.95050[0m
[93maverage test of epoch 72: loss -5.45472 acc 0.81081 roc_auc 0.84667 prc_auc 0.88189[0m
[92maverage training of epoch 73: loss -5.34021 acc 0.82781 roc_auc 0.87765 prc_auc 0.90497[0m
[93maverage test of epoch 73: loss -5.46478 acc 0.86486 roc_auc 0.84667 prc_auc 0.89595[0m
[92maverage training of epoch 74: loss -5.35678 acc 0.81457 roc_auc 0.89353 prc_auc 0.91117[0m
[93maverage test of epoch 74: loss -5.38882 acc 0.78378 roc_auc 0.83667 prc_auc 0.89367[0m
[92maverage training of epoch 75: loss -5.47437 acc 0.80795 roc_auc 0.89333 prc_auc 0.92514[0m
[93maverage test of epoch 75: loss -5.61331 acc 0.81081 roc_auc 0.84000 prc_auc 0.89190[0m
[92maverage training of epoch 76: loss -5.52723 acc 0.83444 roc_auc 0.87931 prc_auc 0.89918[0m
[93maverage test of epoch 76: loss -5.49264 acc 0.78378 roc_auc 0.82667 prc_auc 0.88351[0m
[92maverage training of epoch 77: loss -5.55553 acc 0.81457 roc_auc 0.86716 prc_auc 0.87639[0m
[93maverage test of epoch 77: loss -5.65054 acc 0.83784 roc_auc 0.88667 prc_auc 0.94351[0m
[92maverage training of epoch 78: loss -5.60634 acc 0.82119 roc_auc 0.90412 prc_auc 0.92924[0m
[93maverage test of epoch 78: loss -5.77436 acc 0.86486 roc_auc 0.89000 prc_auc 0.94730[0m
[92maverage training of epoch 79: loss -5.70341 acc 0.82781 roc_auc 0.91069 prc_auc 0.94277[0m
[93maverage test of epoch 79: loss -5.74765 acc 0.86486 roc_auc 0.82667 prc_auc 0.85125[0m
[92maverage training of epoch 80: loss -5.68870 acc 0.82119 roc_auc 0.90814 prc_auc 0.95237[0m
[93maverage test of epoch 80: loss -5.79311 acc 0.75676 roc_auc 0.82333 prc_auc 0.85754[0m
[92maverage training of epoch 81: loss -5.76914 acc 0.82119 roc_auc 0.89627 prc_auc 0.93766[0m
[93maverage test of epoch 81: loss -5.78381 acc 0.72973 roc_auc 0.80000 prc_auc 0.82131[0m
[92maverage training of epoch 82: loss -5.84872 acc 0.81457 roc_auc 0.90265 prc_auc 0.92339[0m
[93maverage test of epoch 82: loss -5.90298 acc 0.81081 roc_auc 0.84667 prc_auc 0.90979[0m
[92maverage training of epoch 83: loss -5.84603 acc 0.80795 roc_auc 0.88980 prc_auc 0.92845[0m
[93maverage test of epoch 83: loss -5.91734 acc 0.75676 roc_auc 0.86333 prc_auc 0.91050[0m
[92maverage training of epoch 84: loss -5.93387 acc 0.84106 roc_auc 0.88206 prc_auc 0.90811[0m
[93maverage test of epoch 84: loss -6.08924 acc 0.81081 roc_auc 0.84000 prc_auc 0.87947[0m
[92maverage training of epoch 85: loss -5.94150 acc 0.80795 roc_auc 0.89245 prc_auc 0.91768[0m
[93maverage test of epoch 85: loss -6.18196 acc 0.81081 roc_auc 0.94333 prc_auc 0.97584[0m
[92maverage training of epoch 86: loss -5.97149 acc 0.82119 roc_auc 0.86137 prc_auc 0.87909[0m
[93maverage test of epoch 86: loss -6.22841 acc 0.83784 roc_auc 0.85667 prc_auc 0.90301[0m
[92maverage training of epoch 87: loss -6.07358 acc 0.82119 roc_auc 0.88471 prc_auc 0.92299[0m
[93maverage test of epoch 87: loss -6.25998 acc 0.83784 roc_auc 0.87833 prc_auc 0.91574[0m
[92maverage training of epoch 88: loss -6.10627 acc 0.84106 roc_auc 0.90265 prc_auc 0.94493[0m
[93maverage test of epoch 88: loss -6.12565 acc 0.75676 roc_auc 0.79333 prc_auc 0.82387[0m
[92maverage training of epoch 89: loss -6.20172 acc 0.82781 roc_auc 0.90039 prc_auc 0.94148[0m
[93maverage test of epoch 89: loss -6.22030 acc 0.75676 roc_auc 0.87667 prc_auc 0.93566[0m
[92maverage training of epoch 90: loss -6.23328 acc 0.82119 roc_auc 0.87490 prc_auc 0.89528[0m
[93maverage test of epoch 90: loss -6.41138 acc 0.78378 roc_auc 0.84000 prc_auc 0.88392[0m
[92maverage training of epoch 91: loss -6.33466 acc 0.82781 roc_auc 0.92225 prc_auc 0.95965[0m
[93maverage test of epoch 91: loss -6.37130 acc 0.78378 roc_auc 0.85667 prc_auc 0.86176[0m
[92maverage training of epoch 92: loss -6.34324 acc 0.83444 roc_auc 0.89108 prc_auc 0.92484[0m
[93maverage test of epoch 92: loss -6.44496 acc 0.78378 roc_auc 0.88000 prc_auc 0.92586[0m
[92maverage training of epoch 93: loss -6.36997 acc 0.82781 roc_auc 0.90412 prc_auc 0.92947[0m
[93maverage test of epoch 93: loss -6.51468 acc 0.81081 roc_auc 0.84000 prc_auc 0.88680[0m
[92maverage training of epoch 94: loss -6.45245 acc 0.80795 roc_auc 0.90000 prc_auc 0.92002[0m
[93maverage test of epoch 94: loss -6.53621 acc 0.78378 roc_auc 0.84000 prc_auc 0.89146[0m
[92maverage training of epoch 95: loss -6.51527 acc 0.82781 roc_auc 0.88441 prc_auc 0.91972[0m
[93maverage test of epoch 95: loss -6.56820 acc 0.78378 roc_auc 0.87333 prc_auc 0.93558[0m
[92maverage training of epoch 96: loss -6.50250 acc 0.80132 roc_auc 0.88480 prc_auc 0.91082[0m
[93maverage test of epoch 96: loss -6.60224 acc 0.81081 roc_auc 0.83667 prc_auc 0.86821[0m
[92maverage training of epoch 97: loss -6.56281 acc 0.81457 roc_auc 0.87892 prc_auc 0.90083[0m
[93maverage test of epoch 97: loss -6.66604 acc 0.86486 roc_auc 0.87000 prc_auc 0.92503[0m
[92maverage training of epoch 98: loss -6.66119 acc 0.82781 roc_auc 0.90147 prc_auc 0.93546[0m
[93maverage test of epoch 98: loss -6.86320 acc 0.83784 roc_auc 0.83500 prc_auc 0.87373[0m
[92maverage training of epoch 99: loss -6.72583 acc 0.82781 roc_auc 0.89902 prc_auc 0.93348[0m
[93maverage test of epoch 99: loss -6.62370 acc 0.70270 roc_auc 0.82000 prc_auc 0.88410[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.09142 acc 0.33775 roc_auc 0.44431 prc_auc 0.61292[0m
[93maverage test of epoch 0: loss -0.16796 acc 0.32432 roc_auc 0.58333 prc_auc 0.73734[0m
[92maverage training of epoch 1: loss -0.30420 acc 0.33775 roc_auc 0.51098 prc_auc 0.68466[0m
[93maverage test of epoch 1: loss -0.39265 acc 0.32432 roc_auc 0.51000 prc_auc 0.67121[0m
[92maverage training of epoch 2: loss -0.53174 acc 0.33775 roc_auc 0.55529 prc_auc 0.73156[0m
[93maverage test of epoch 2: loss -0.64228 acc 0.32432 roc_auc 0.58333 prc_auc 0.76931[0m
[92maverage training of epoch 3: loss -0.76777 acc 0.33775 roc_auc 0.49137 prc_auc 0.70096[0m
[93maverage test of epoch 3: loss -0.88852 acc 0.29730 roc_auc 0.55333 prc_auc 0.72074[0m
[92maverage training of epoch 4: loss -0.99345 acc 0.46358 roc_auc 0.51196 prc_auc 0.70651[0m
[93maverage test of epoch 4: loss -1.08173 acc 0.56757 roc_auc 0.49000 prc_auc 0.72394[0m
[92maverage training of epoch 5: loss -1.19559 acc 0.64901 roc_auc 0.53392 prc_auc 0.70339[0m
[93maverage test of epoch 5: loss -1.31466 acc 0.67568 roc_auc 0.68333 prc_auc 0.83117[0m
[92maverage training of epoch 6: loss -1.39017 acc 0.66225 roc_auc 0.55098 prc_auc 0.70768[0m
[93maverage test of epoch 6: loss -1.51213 acc 0.67568 roc_auc 0.65000 prc_auc 0.82706[0m
[92maverage training of epoch 7: loss -1.60726 acc 0.66225 roc_auc 0.60529 prc_auc 0.78051[0m
[93maverage test of epoch 7: loss -1.70976 acc 0.67568 roc_auc 0.66000 prc_auc 0.81010[0m
[92maverage training of epoch 8: loss -1.78351 acc 0.66225 roc_auc 0.61902 prc_auc 0.76413[0m
[93maverage test of epoch 8: loss -1.87284 acc 0.67568 roc_auc 0.70333 prc_auc 0.85990[0m
[92maverage training of epoch 9: loss -1.92263 acc 0.66225 roc_auc 0.67059 prc_auc 0.79975[0m
[93maverage test of epoch 9: loss -1.99862 acc 0.67568 roc_auc 0.73333 prc_auc 0.85822[0m
[92maverage training of epoch 10: loss -2.04648 acc 0.66225 roc_auc 0.68941 prc_auc 0.79596[0m
[93maverage test of epoch 10: loss -2.12874 acc 0.67568 roc_auc 0.79333 prc_auc 0.89229[0m
[92maverage training of epoch 11: loss -2.14922 acc 0.66225 roc_auc 0.59039 prc_auc 0.74127[0m
[93maverage test of epoch 11: loss -2.23019 acc 0.67568 roc_auc 0.71333 prc_auc 0.82650[0m
[92maverage training of epoch 12: loss -2.24292 acc 0.66225 roc_auc 0.56863 prc_auc 0.71607[0m
[93maverage test of epoch 12: loss -2.31213 acc 0.67568 roc_auc 0.61333 prc_auc 0.83520[0m
[92maverage training of epoch 13: loss -2.34388 acc 0.66225 roc_auc 0.54471 prc_auc 0.69906[0m
[93maverage test of epoch 13: loss -2.41183 acc 0.67568 roc_auc 0.60667 prc_auc 0.80272[0m
[92maverage training of epoch 14: loss -2.43591 acc 0.66225 roc_auc 0.58588 prc_auc 0.74879[0m
[93maverage test of epoch 14: loss -2.51003 acc 0.67568 roc_auc 0.53000 prc_auc 0.72869[0m
[92maverage training of epoch 15: loss -2.52111 acc 0.66225 roc_auc 0.58490 prc_auc 0.74842[0m
[93maverage test of epoch 15: loss -2.58214 acc 0.67568 roc_auc 0.47667 prc_auc 0.78573[0m
[92maverage training of epoch 16: loss -2.60764 acc 0.66225 roc_auc 0.63863 prc_auc 0.79040[0m
[93maverage test of epoch 16: loss -2.66559 acc 0.67568 roc_auc 0.68000 prc_auc 0.82185[0m
[92maverage training of epoch 17: loss -2.67823 acc 0.66225 roc_auc 0.53118 prc_auc 0.71225[0m
[93maverage test of epoch 17: loss -2.74802 acc 0.67568 roc_auc 0.70333 prc_auc 0.83451[0m
[92maverage training of epoch 18: loss -2.75645 acc 0.66225 roc_auc 0.51824 prc_auc 0.67415[0m
[93maverage test of epoch 18: loss -2.83148 acc 0.67568 roc_auc 0.62667 prc_auc 0.80393[0m
[92maverage training of epoch 19: loss -2.83638 acc 0.66225 roc_auc 0.58216 prc_auc 0.74387[0m
[93maverage test of epoch 19: loss -2.90391 acc 0.67568 roc_auc 0.68667 prc_auc 0.87125[0m
[92maverage training of epoch 20: loss -2.90448 acc 0.66225 roc_auc 0.42980 prc_auc 0.63189[0m
[93maverage test of epoch 20: loss -2.96725 acc 0.67568 roc_auc 0.52667 prc_auc 0.76177[0m
[92maverage training of epoch 21: loss -2.97666 acc 0.66225 roc_auc 0.44667 prc_auc 0.62467[0m
[93maverage test of epoch 21: loss -3.04394 acc 0.67568 roc_auc 0.63333 prc_auc 0.71563[0m
[92maverage training of epoch 22: loss -3.04977 acc 0.66225 roc_auc 0.51706 prc_auc 0.66777[0m
[93maverage test of epoch 22: loss -3.11085 acc 0.67568 roc_auc 0.51333 prc_auc 0.71752[0m
[92maverage training of epoch 23: loss -3.12080 acc 0.66225 roc_auc 0.47608 prc_auc 0.64008[0m
[93maverage test of epoch 23: loss -3.18222 acc 0.67568 roc_auc 0.56333 prc_auc 0.74705[0m
[92maverage training of epoch 24: loss -3.19193 acc 0.66225 roc_auc 0.56706 prc_auc 0.72399[0m
[93maverage test of epoch 24: loss -3.25869 acc 0.67568 roc_auc 0.49667 prc_auc 0.72024[0m
[92maverage training of epoch 25: loss -3.26144 acc 0.66225 roc_auc 0.47235 prc_auc 0.63289[0m
[93maverage test of epoch 25: loss -3.32320 acc 0.67568 roc_auc 0.57000 prc_auc 0.75694[0m
[92maverage training of epoch 26: loss -3.33114 acc 0.66225 roc_auc 0.60667 prc_auc 0.73956[0m
[93maverage test of epoch 26: loss -3.39526 acc 0.67568 roc_auc 0.67333 prc_auc 0.82508[0m
[92maverage training of epoch 27: loss -3.38818 acc 0.66225 roc_auc 0.52020 prc_auc 0.66864[0m
[93maverage test of epoch 27: loss -3.45759 acc 0.67568 roc_auc 0.49000 prc_auc 0.69516[0m
[92maverage training of epoch 28: loss -3.45190 acc 0.66225 roc_auc 0.44627 prc_auc 0.63342[0m
[93maverage test of epoch 28: loss -3.50363 acc 0.67568 roc_auc 0.52333 prc_auc 0.73296[0m
[92maverage training of epoch 29: loss -3.51770 acc 0.66225 roc_auc 0.45343 prc_auc 0.61481[0m
[93maverage test of epoch 29: loss -3.57517 acc 0.67568 roc_auc 0.55333 prc_auc 0.76420[0m
[92maverage training of epoch 30: loss -3.58087 acc 0.66225 roc_auc 0.46706 prc_auc 0.64945[0m
[93maverage test of epoch 30: loss -3.65061 acc 0.67568 roc_auc 0.49667 prc_auc 0.70177[0m
[92maverage training of epoch 31: loss -3.64388 acc 0.66225 roc_auc 0.43608 prc_auc 0.63408[0m
[93maverage test of epoch 31: loss -3.70869 acc 0.67568 roc_auc 0.46000 prc_auc 0.63430[0m
[92maverage training of epoch 32: loss -3.71124 acc 0.66225 roc_auc 0.51098 prc_auc 0.70525[0m
[93maverage test of epoch 32: loss -3.77601 acc 0.67568 roc_auc 0.57333 prc_auc 0.76862[0m
[92maverage training of epoch 33: loss -3.77294 acc 0.66225 roc_auc 0.57725 prc_auc 0.72052[0m
[93maverage test of epoch 33: loss -3.83169 acc 0.67568 roc_auc 0.60333 prc_auc 0.81973[0m
[92maverage training of epoch 34: loss -3.83276 acc 0.66225 roc_auc 0.46843 prc_auc 0.61988[0m
[93maverage test of epoch 34: loss -3.89274 acc 0.67568 roc_auc 0.47333 prc_auc 0.68801[0m
[92maverage training of epoch 35: loss -3.89275 acc 0.66225 roc_auc 0.47863 prc_auc 0.65949[0m
[93maverage test of epoch 35: loss -3.95491 acc 0.67568 roc_auc 0.67333 prc_auc 0.83652[0m
[92maverage training of epoch 36: loss -3.95435 acc 0.66225 roc_auc 0.43314 prc_auc 0.61108[0m
[93maverage test of epoch 36: loss -4.03030 acc 0.67568 roc_auc 0.47333 prc_auc 0.68871[0m
[92maverage training of epoch 37: loss -4.01217 acc 0.66225 roc_auc 0.43647 prc_auc 0.62977[0m
[93maverage test of epoch 37: loss -4.08139 acc 0.67568 roc_auc 0.56333 prc_auc 0.72675[0m
[92maverage training of epoch 38: loss -4.07380 acc 0.66225 roc_auc 0.48490 prc_auc 0.63122[0m
[93maverage test of epoch 38: loss -4.14858 acc 0.67568 roc_auc 0.67000 prc_auc 0.83815[0m
[92maverage training of epoch 39: loss -4.13712 acc 0.66225 roc_auc 0.45588 prc_auc 0.63838[0m
[93maverage test of epoch 39: loss -4.20400 acc 0.67568 roc_auc 0.51333 prc_auc 0.68008[0m
[92maverage training of epoch 40: loss -4.19668 acc 0.66225 roc_auc 0.49157 prc_auc 0.67111[0m
[93maverage test of epoch 40: loss -4.26742 acc 0.67568 roc_auc 0.55333 prc_auc 0.77427[0m
[92maverage training of epoch 41: loss -4.25102 acc 0.66225 roc_auc 0.38843 prc_auc 0.61691[0m
[93maverage test of epoch 41: loss -4.32781 acc 0.67568 roc_auc 0.63833 prc_auc 0.80463[0m
[92maverage training of epoch 42: loss -4.31498 acc 0.66225 roc_auc 0.49255 prc_auc 0.62272[0m
[93maverage test of epoch 42: loss -4.38095 acc 0.67568 roc_auc 0.54333 prc_auc 0.74422[0m
[92maverage training of epoch 43: loss -4.37060 acc 0.66225 roc_auc 0.45471 prc_auc 0.60888[0m
[93maverage test of epoch 43: loss -4.43595 acc 0.67568 roc_auc 0.42833 prc_auc 0.67766[0m
[92maverage training of epoch 44: loss -4.43153 acc 0.66225 roc_auc 0.49176 prc_auc 0.64808[0m
[93maverage test of epoch 44: loss -4.50731 acc 0.67568 roc_auc 0.64333 prc_auc 0.75132[0m
[92maverage training of epoch 45: loss -4.48830 acc 0.66225 roc_auc 0.46108 prc_auc 0.63658[0m
[93maverage test of epoch 45: loss -4.56041 acc 0.67568 roc_auc 0.58167 prc_auc 0.78216[0m
[92maverage training of epoch 46: loss -4.54761 acc 0.66225 roc_auc 0.47167 prc_auc 0.64980[0m
[93maverage test of epoch 46: loss -4.61476 acc 0.67568 roc_auc 0.64667 prc_auc 0.83580[0m
[92maverage training of epoch 47: loss -4.60522 acc 0.66225 roc_auc 0.44343 prc_auc 0.63471[0m
[93maverage test of epoch 47: loss -4.67843 acc 0.67568 roc_auc 0.58333 prc_auc 0.78334[0m
[92maverage training of epoch 48: loss -4.66393 acc 0.66225 roc_auc 0.48196 prc_auc 0.63169[0m
[93maverage test of epoch 48: loss -4.72860 acc 0.67568 roc_auc 0.39333 prc_auc 0.66172[0m
[92maverage training of epoch 49: loss -4.71834 acc 0.66225 roc_auc 0.45108 prc_auc 0.62924[0m
[93maverage test of epoch 49: loss -4.79123 acc 0.67568 roc_auc 0.49333 prc_auc 0.73497[0m
[92maverage training of epoch 50: loss -4.77854 acc 0.66225 roc_auc 0.43696 prc_auc 0.60953[0m
[93maverage test of epoch 50: loss -4.84943 acc 0.67568 roc_auc 0.51500 prc_auc 0.75715[0m
[92maverage training of epoch 51: loss -4.83660 acc 0.66225 roc_auc 0.41784 prc_auc 0.59641[0m
[93maverage test of epoch 51: loss -4.90458 acc 0.67568 roc_auc 0.59333 prc_auc 0.75417[0m
[92maverage training of epoch 52: loss -4.89454 acc 0.66225 roc_auc 0.47147 prc_auc 0.64535[0m
[93maverage test of epoch 52: loss -4.96061 acc 0.67568 roc_auc 0.37667 prc_auc 0.64675[0m
[92maverage training of epoch 53: loss -4.95258 acc 0.66225 roc_auc 0.39549 prc_auc 0.57600[0m
[93maverage test of epoch 53: loss -5.01777 acc 0.67568 roc_auc 0.54000 prc_auc 0.76495[0m
[92maverage training of epoch 54: loss -5.00636 acc 0.66225 roc_auc 0.45765 prc_auc 0.62548[0m
[93maverage test of epoch 54: loss -5.07791 acc 0.67568 roc_auc 0.54667 prc_auc 0.74183[0m
[92maverage training of epoch 55: loss -5.06392 acc 0.66225 roc_auc 0.48529 prc_auc 0.64668[0m
[93maverage test of epoch 55: loss -5.14024 acc 0.67568 roc_auc 0.33667 prc_auc 0.68203[0m
[92maverage training of epoch 56: loss -5.12111 acc 0.66225 roc_auc 0.43480 prc_auc 0.61802[0m
[93maverage test of epoch 56: loss -5.18936 acc 0.67568 roc_auc 0.53667 prc_auc 0.73171[0m
[92maverage training of epoch 57: loss -5.18059 acc 0.66225 roc_auc 0.40157 prc_auc 0.59381[0m
[93maverage test of epoch 57: loss -5.24301 acc 0.67568 roc_auc 0.33333 prc_auc 0.64089[0m
[92maverage training of epoch 58: loss -5.23869 acc 0.66225 roc_auc 0.50392 prc_auc 0.65538[0m
[93maverage test of epoch 58: loss -5.31098 acc 0.67568 roc_auc 0.64667 prc_auc 0.79604[0m
[92maverage training of epoch 59: loss -5.29064 acc 0.66225 roc_auc 0.39569 prc_auc 0.59060[0m
[93maverage test of epoch 59: loss -5.36366 acc 0.67568 roc_auc 0.37333 prc_auc 0.68264[0m
[92maverage training of epoch 60: loss -5.35052 acc 0.66225 roc_auc 0.47637 prc_auc 0.63530[0m
[93maverage test of epoch 60: loss -5.41990 acc 0.67568 roc_auc 0.45667 prc_auc 0.68843[0m
[92maverage training of epoch 61: loss -5.40841 acc 0.66225 roc_auc 0.43029 prc_auc 0.60574[0m
[93maverage test of epoch 61: loss -5.48264 acc 0.67568 roc_auc 0.66000 prc_auc 0.82840[0m
[92maverage training of epoch 62: loss -5.46407 acc 0.66225 roc_auc 0.45059 prc_auc 0.61952[0m
[93maverage test of epoch 62: loss -5.53954 acc 0.67568 roc_auc 0.62667 prc_auc 0.80932[0m
[92maverage training of epoch 63: loss -5.52221 acc 0.66225 roc_auc 0.51961 prc_auc 0.67028[0m
[93maverage test of epoch 63: loss -5.59262 acc 0.67568 roc_auc 0.44000 prc_auc 0.69486[0m
[92maverage training of epoch 64: loss -5.57536 acc 0.66225 roc_auc 0.38961 prc_auc 0.56983[0m
[93maverage test of epoch 64: loss -5.64959 acc 0.67568 roc_auc 0.58500 prc_auc 0.76867[0m
[92maverage training of epoch 65: loss -5.63462 acc 0.66225 roc_auc 0.40490 prc_auc 0.58709[0m
[93maverage test of epoch 65: loss -5.70634 acc 0.67568 roc_auc 0.52667 prc_auc 0.74915[0m
[92maverage training of epoch 66: loss -5.68990 acc 0.66225 roc_auc 0.50882 prc_auc 0.64648[0m
[93maverage test of epoch 66: loss -5.76482 acc 0.67568 roc_auc 0.48333 prc_auc 0.72625[0m
[92maverage training of epoch 67: loss -5.74714 acc 0.66225 roc_auc 0.43598 prc_auc 0.63172[0m
[93maverage test of epoch 67: loss -5.81919 acc 0.67568 roc_auc 0.34667 prc_auc 0.62663[0m
[92maverage training of epoch 68: loss -5.80299 acc 0.66225 roc_auc 0.34029 prc_auc 0.55463[0m
[93maverage test of epoch 68: loss -5.87556 acc 0.67568 roc_auc 0.41667 prc_auc 0.69106[0m
[92maverage training of epoch 69: loss -5.85724 acc 0.66225 roc_auc 0.33304 prc_auc 0.54601[0m
[93maverage test of epoch 69: loss -5.93369 acc 0.67568 roc_auc 0.35667 prc_auc 0.64306[0m
[92maverage training of epoch 70: loss -5.91482 acc 0.66225 roc_auc 0.39510 prc_auc 0.56926[0m
[93maverage test of epoch 70: loss -5.98883 acc 0.67568 roc_auc 0.40167 prc_auc 0.68655[0m
[92maverage training of epoch 71: loss -5.97129 acc 0.66225 roc_auc 0.40059 prc_auc 0.59956[0m
[93maverage test of epoch 71: loss -6.04666 acc 0.67568 roc_auc 0.44333 prc_auc 0.67670[0m
[92maverage training of epoch 72: loss -6.02579 acc 0.66225 roc_auc 0.51735 prc_auc 0.64446[0m
[93maverage test of epoch 72: loss -6.09970 acc 0.67568 roc_auc 0.48833 prc_auc 0.70966[0m
[92maverage training of epoch 73: loss -6.08353 acc 0.66225 roc_auc 0.37000 prc_auc 0.58068[0m
[93maverage test of epoch 73: loss -6.15608 acc 0.67568 roc_auc 0.44500 prc_auc 0.67801[0m
[92maverage training of epoch 74: loss -6.13986 acc 0.66225 roc_auc 0.43824 prc_auc 0.60987[0m
[93maverage test of epoch 74: loss -6.21095 acc 0.67568 roc_auc 0.42833 prc_auc 0.70874[0m
[92maverage training of epoch 75: loss -6.19484 acc 0.66225 roc_auc 0.47569 prc_auc 0.61830[0m
[93maverage test of epoch 75: loss -6.26941 acc 0.67568 roc_auc 0.62167 prc_auc 0.75792[0m
[92maverage training of epoch 76: loss -6.25152 acc 0.66225 roc_auc 0.38049 prc_auc 0.58500[0m
[93maverage test of epoch 76: loss -6.32839 acc 0.67568 roc_auc 0.66833 prc_auc 0.80924[0m
[92maverage training of epoch 77: loss -6.30714 acc 0.66225 roc_auc 0.35529 prc_auc 0.56308[0m
[93maverage test of epoch 77: loss -6.38185 acc 0.67568 roc_auc 0.49833 prc_auc 0.71502[0m
[92maverage training of epoch 78: loss -6.36421 acc 0.66225 roc_auc 0.40147 prc_auc 0.59544[0m
[93maverage test of epoch 78: loss -6.43806 acc 0.67568 roc_auc 0.56167 prc_auc 0.73188[0m
[92maverage training of epoch 79: loss -6.41990 acc 0.66225 roc_auc 0.38931 prc_auc 0.57207[0m
[93maverage test of epoch 79: loss -6.49552 acc 0.67568 roc_auc 0.64833 prc_auc 0.81769[0m
[92maverage training of epoch 80: loss -6.47544 acc 0.66225 roc_auc 0.43333 prc_auc 0.60415[0m
[93maverage test of epoch 80: loss -6.55147 acc 0.67568 roc_auc 0.44667 prc_auc 0.70874[0m
[92maverage training of epoch 81: loss -6.53120 acc 0.66225 roc_auc 0.39108 prc_auc 0.57474[0m
[93maverage test of epoch 81: loss -6.60808 acc 0.67568 roc_auc 0.60833 prc_auc 0.80433[0m
[92maverage training of epoch 82: loss -6.58721 acc 0.66225 roc_auc 0.38922 prc_auc 0.59477[0m
[93maverage test of epoch 82: loss -6.66501 acc 0.67568 roc_auc 0.62833 prc_auc 0.79411[0m
[92maverage training of epoch 83: loss -6.64263 acc 0.66225 roc_auc 0.37353 prc_auc 0.57852[0m
[93maverage test of epoch 83: loss -6.71922 acc 0.67568 roc_auc 0.48333 prc_auc 0.72369[0m
[92maverage training of epoch 84: loss -6.69901 acc 0.66225 roc_auc 0.45608 prc_auc 0.62771[0m
[93maverage test of epoch 84: loss -6.77657 acc 0.67568 roc_auc 0.41667 prc_auc 0.66602[0m
[92maverage training of epoch 85: loss -6.75438 acc 0.66225 roc_auc 0.37186 prc_auc 0.56746[0m
[93maverage test of epoch 85: loss -6.83094 acc 0.67568 roc_auc 0.56500 prc_auc 0.75542[0m
[92maverage training of epoch 86: loss -6.81044 acc 0.66225 roc_auc 0.36147 prc_auc 0.57525[0m
[93maverage test of epoch 86: loss -6.88826 acc 0.67568 roc_auc 0.40000 prc_auc 0.66869[0m
[92maverage training of epoch 87: loss -6.86629 acc 0.66225 roc_auc 0.43000 prc_auc 0.59824[0m
[93maverage test of epoch 87: loss -6.94519 acc 0.67568 roc_auc 0.61833 prc_auc 0.73906[0m
[92maverage training of epoch 88: loss -6.92121 acc 0.66225 roc_auc 0.43725 prc_auc 0.60844[0m
[93maverage test of epoch 88: loss -6.99898 acc 0.67568 roc_auc 0.50667 prc_auc 0.73322[0m
[92maverage training of epoch 89: loss -6.97825 acc 0.66225 roc_auc 0.43196 prc_auc 0.61435[0m
[93maverage test of epoch 89: loss -7.05445 acc 0.67568 roc_auc 0.48833 prc_auc 0.73107[0m
[92maverage training of epoch 90: loss -7.03402 acc 0.66225 roc_auc 0.38882 prc_auc 0.57938[0m
[93maverage test of epoch 90: loss -7.11232 acc 0.67568 roc_auc 0.63333 prc_auc 0.80096[0m
[92maverage training of epoch 91: loss -7.08938 acc 0.66225 roc_auc 0.40431 prc_auc 0.59908[0m
[93maverage test of epoch 91: loss -7.16787 acc 0.67568 roc_auc 0.54500 prc_auc 0.71383[0m
[92maverage training of epoch 92: loss -7.14483 acc 0.66225 roc_auc 0.41627 prc_auc 0.60769[0m
[93maverage test of epoch 92: loss -7.22272 acc 0.67568 roc_auc 0.45333 prc_auc 0.70793[0m
[92maverage training of epoch 93: loss -7.20045 acc 0.66225 roc_auc 0.42873 prc_auc 0.60431[0m
[93maverage test of epoch 93: loss -7.27879 acc 0.67568 roc_auc 0.45333 prc_auc 0.71016[0m
[92maverage training of epoch 94: loss -7.25640 acc 0.66225 roc_auc 0.36029 prc_auc 0.55618[0m
[93maverage test of epoch 94: loss -7.33596 acc 0.67568 roc_auc 0.49000 prc_auc 0.65672[0m
[92maverage training of epoch 95: loss -7.31227 acc 0.66225 roc_auc 0.39765 prc_auc 0.58798[0m
[93maverage test of epoch 95: loss -7.39047 acc 0.67568 roc_auc 0.66333 prc_auc 0.82011[0m
[92maverage training of epoch 96: loss -7.36736 acc 0.66225 roc_auc 0.37010 prc_auc 0.56900[0m
[93maverage test of epoch 96: loss -7.44530 acc 0.67568 roc_auc 0.68833 prc_auc 0.80306[0m
[92maverage training of epoch 97: loss -7.42301 acc 0.66225 roc_auc 0.36696 prc_auc 0.57388[0m
[93maverage test of epoch 97: loss -7.50188 acc 0.67568 roc_auc 0.63667 prc_auc 0.82295[0m
[92maverage training of epoch 98: loss -7.47960 acc 0.66225 roc_auc 0.38853 prc_auc 0.57628[0m
[93maverage test of epoch 98: loss -7.55962 acc 0.67568 roc_auc 0.56167 prc_auc 0.72155[0m
[92maverage training of epoch 99: loss -7.53453 acc 0.66225 roc_auc 0.39980 prc_auc 0.60537[0m
[93maverage test of epoch 99: loss -7.61563 acc 0.67568 roc_auc 0.67833 prc_auc 0.82357[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.0001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.67041 ROC_AUC (avg): 0.62367 PRC_AUC (avg): 0.76038 

Average forward propagation time taken(ms): 3.967376079100699
Average backward propagation time taken(ms): 1.5106451705185322

