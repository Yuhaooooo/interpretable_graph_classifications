# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.0003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-05-27-56/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-05-27-56/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 8,
 'epochs': 100,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 4,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.0003,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 2,
 'num_workers': 8,
 'number_of_mlp_layer': 0,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-18-05-27-56',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 100, 'learning_rate': 0.0003, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.84995 acc 0.33333 roc_auc 0.41980 prc_auc 0.61977[0m
[93maverage test of epoch 0: loss -1.05233 acc 0.34211 roc_auc 0.45538 prc_auc 0.71289[0m
[92maverage training of epoch 1: loss -1.26695 acc 0.36000 roc_auc 0.45140 prc_auc 0.66210[0m
[93maverage test of epoch 1: loss -1.50299 acc 0.63158 roc_auc 0.56615 prc_auc 0.74990[0m
[92maverage training of epoch 2: loss -1.76792 acc 0.64000 roc_auc 0.47360 prc_auc 0.66424[0m
[93maverage test of epoch 2: loss -2.09123 acc 0.65789 roc_auc 0.65846 prc_auc 0.80022[0m
[92maverage training of epoch 3: loss -2.45892 acc 0.66667 roc_auc 0.44180 prc_auc 0.66125[0m
[93maverage test of epoch 3: loss -2.85855 acc 0.65789 roc_auc 0.60308 prc_auc 0.77380[0m
[92maverage training of epoch 4: loss -3.18414 acc 0.66667 roc_auc 0.38580 prc_auc 0.59409[0m
[93maverage test of epoch 4: loss -3.51124 acc 0.65789 roc_auc 0.46769 prc_auc 0.72668[0m
[92maverage training of epoch 5: loss -3.89171 acc 0.66667 roc_auc 0.47080 prc_auc 0.66404[0m
[93maverage test of epoch 5: loss -4.16438 acc 0.65789 roc_auc 0.60308 prc_auc 0.76104[0m
[92maverage training of epoch 6: loss -4.44612 acc 0.66667 roc_auc 0.44360 prc_auc 0.63794[0m
[93maverage test of epoch 6: loss -4.66197 acc 0.65789 roc_auc 0.58154 prc_auc 0.72154[0m
[92maverage training of epoch 7: loss -4.84783 acc 0.66667 roc_auc 0.33000 prc_auc 0.56468[0m
[93maverage test of epoch 7: loss -5.00478 acc 0.65789 roc_auc 0.66769 prc_auc 0.82092[0m
[92maverage training of epoch 8: loss -5.17279 acc 0.66667 roc_auc 0.46060 prc_auc 0.61588[0m
[93maverage test of epoch 8: loss -5.30611 acc 0.65789 roc_auc 0.49846 prc_auc 0.69235[0m
[92maverage training of epoch 9: loss -5.45328 acc 0.66667 roc_auc 0.52280 prc_auc 0.66728[0m
[93maverage test of epoch 9: loss -5.55939 acc 0.65789 roc_auc 0.32615 prc_auc 0.60188[0m
[92maverage training of epoch 10: loss -5.69735 acc 0.66667 roc_auc 0.45100 prc_auc 0.63405[0m
[93maverage test of epoch 10: loss -5.78224 acc 0.65789 roc_auc 0.44615 prc_auc 0.65546[0m
[92maverage training of epoch 11: loss -5.92518 acc 0.66667 roc_auc 0.39020 prc_auc 0.57523[0m
[93maverage test of epoch 11: loss -5.99899 acc 0.65789 roc_auc 0.38154 prc_auc 0.60402[0m
[92maverage training of epoch 12: loss -6.13736 acc 0.66667 roc_auc 0.42550 prc_auc 0.59496[0m
[93maverage test of epoch 12: loss -6.22091 acc 0.65789 roc_auc 0.59692 prc_auc 0.76366[0m
[92maverage training of epoch 13: loss -6.33335 acc 0.66667 roc_auc 0.41980 prc_auc 0.61517[0m
[93maverage test of epoch 13: loss -6.40062 acc 0.65789 roc_auc 0.53538 prc_auc 0.71982[0m
[92maverage training of epoch 14: loss -6.53207 acc 0.66667 roc_auc 0.47640 prc_auc 0.65560[0m
[93maverage test of epoch 14: loss -6.59077 acc 0.65789 roc_auc 0.50154 prc_auc 0.72605[0m
[92maverage training of epoch 15: loss -6.71317 acc 0.66667 roc_auc 0.44760 prc_auc 0.64486[0m
[93maverage test of epoch 15: loss -6.77479 acc 0.65789 roc_auc 0.48923 prc_auc 0.70629[0m
[92maverage training of epoch 16: loss -6.89830 acc 0.66667 roc_auc 0.36000 prc_auc 0.58009[0m
[93maverage test of epoch 16: loss -6.96900 acc 0.65789 roc_auc 0.28615 prc_auc 0.53839[0m
[92maverage training of epoch 17: loss -7.08081 acc 0.66667 roc_auc 0.40360 prc_auc 0.60092[0m
[93maverage test of epoch 17: loss -7.14342 acc 0.65789 roc_auc 0.49846 prc_auc 0.74015[0m
[92maverage training of epoch 18: loss -7.26150 acc 0.66667 roc_auc 0.35440 prc_auc 0.58836[0m
[93maverage test of epoch 18: loss -7.33228 acc 0.65789 roc_auc 0.55385 prc_auc 0.75810[0m
[92maverage training of epoch 19: loss -7.43760 acc 0.66667 roc_auc 0.39960 prc_auc 0.58606[0m
[93maverage test of epoch 19: loss -7.50551 acc 0.65789 roc_auc 0.56154 prc_auc 0.68967[0m
[92maverage training of epoch 20: loss -7.61703 acc 0.66667 roc_auc 0.43380 prc_auc 0.63300[0m
[93maverage test of epoch 20: loss -7.66964 acc 0.65789 roc_auc 0.55385 prc_auc 0.69425[0m
[92maverage training of epoch 21: loss -7.79792 acc 0.66667 roc_auc 0.46780 prc_auc 0.64165[0m
[93maverage test of epoch 21: loss -7.86307 acc 0.65789 roc_auc 0.46462 prc_auc 0.68315[0m
[92maverage training of epoch 22: loss -7.97101 acc 0.66667 roc_auc 0.44760 prc_auc 0.60674[0m
[93maverage test of epoch 22: loss -8.02709 acc 0.65789 roc_auc 0.72615 prc_auc 0.83562[0m
[92maverage training of epoch 23: loss -8.14160 acc 0.66667 roc_auc 0.34780 prc_auc 0.56642[0m
[93maverage test of epoch 23: loss -8.19837 acc 0.65789 roc_auc 0.46615 prc_auc 0.66662[0m
[92maverage training of epoch 24: loss -8.31501 acc 0.66667 roc_auc 0.43380 prc_auc 0.60266[0m
[93maverage test of epoch 24: loss -8.36577 acc 0.65789 roc_auc 0.58615 prc_auc 0.74950[0m
[92maverage training of epoch 25: loss -8.48568 acc 0.66667 roc_auc 0.40220 prc_auc 0.60101[0m
[93maverage test of epoch 25: loss -8.54097 acc 0.65789 roc_auc 0.51538 prc_auc 0.73669[0m
[92maverage training of epoch 26: loss -8.65447 acc 0.66667 roc_auc 0.39160 prc_auc 0.58837[0m
[93maverage test of epoch 26: loss -8.70371 acc 0.65789 roc_auc 0.48923 prc_auc 0.72765[0m
[92maverage training of epoch 27: loss -8.82933 acc 0.66667 roc_auc 0.39940 prc_auc 0.59173[0m
[93maverage test of epoch 27: loss -8.88113 acc 0.65789 roc_auc 0.64154 prc_auc 0.79251[0m
[92maverage training of epoch 28: loss -8.99609 acc 0.66667 roc_auc 0.48520 prc_auc 0.65176[0m
[93maverage test of epoch 28: loss -9.05008 acc 0.65789 roc_auc 0.59077 prc_auc 0.79060[0m
[92maverage training of epoch 29: loss -9.16395 acc 0.66667 roc_auc 0.38450 prc_auc 0.58250[0m
[93maverage test of epoch 29: loss -9.21183 acc 0.65789 roc_auc 0.47692 prc_auc 0.68377[0m
[92maverage training of epoch 30: loss -9.33388 acc 0.66667 roc_auc 0.38480 prc_auc 0.59023[0m
[93maverage test of epoch 30: loss -9.38773 acc 0.65789 roc_auc 0.72308 prc_auc 0.85588[0m
[92maverage training of epoch 31: loss -9.50167 acc 0.66667 roc_auc 0.37510 prc_auc 0.58652[0m
[93maverage test of epoch 31: loss -9.55267 acc 0.65789 roc_auc 0.28000 prc_auc 0.56182[0m
[92maverage training of epoch 32: loss -9.67314 acc 0.66667 roc_auc 0.39220 prc_auc 0.60622[0m
[93maverage test of epoch 32: loss -9.71912 acc 0.65789 roc_auc 0.61077 prc_auc 0.77100[0m
[92maverage training of epoch 33: loss -9.83896 acc 0.66667 roc_auc 0.37300 prc_auc 0.59143[0m
[93maverage test of epoch 33: loss -9.88642 acc 0.65789 roc_auc 0.54308 prc_auc 0.71247[0m
[92maverage training of epoch 34: loss -10.00569 acc 0.66667 roc_auc 0.41680 prc_auc 0.59539[0m
[93maverage test of epoch 34: loss -10.05671 acc 0.65789 roc_auc 0.51231 prc_auc 0.66087[0m
[92maverage training of epoch 35: loss -10.17246 acc 0.66667 roc_auc 0.37450 prc_auc 0.59214[0m
[93maverage test of epoch 35: loss -10.22292 acc 0.65789 roc_auc 0.32000 prc_auc 0.55124[0m
[92maverage training of epoch 36: loss -10.34257 acc 0.66667 roc_auc 0.39400 prc_auc 0.58974[0m
[93maverage test of epoch 36: loss -10.39049 acc 0.65789 roc_auc 0.41231 prc_auc 0.61568[0m
[92maverage training of epoch 37: loss -10.50845 acc 0.66667 roc_auc 0.39920 prc_auc 0.60221[0m
[93maverage test of epoch 37: loss -10.55692 acc 0.65789 roc_auc 0.38462 prc_auc 0.64711[0m
[92maverage training of epoch 38: loss -10.67685 acc 0.66667 roc_auc 0.37550 prc_auc 0.57548[0m
[93maverage test of epoch 38: loss -10.71882 acc 0.65789 roc_auc 0.47692 prc_auc 0.64073[0m
[92maverage training of epoch 39: loss -10.84489 acc 0.66667 roc_auc 0.38880 prc_auc 0.59733[0m
[93maverage test of epoch 39: loss -10.88313 acc 0.65789 roc_auc 0.52308 prc_auc 0.71426[0m
[92maverage training of epoch 40: loss -11.01095 acc 0.66667 roc_auc 0.40930 prc_auc 0.60160[0m
[93maverage test of epoch 40: loss -11.05200 acc 0.65789 roc_auc 0.70154 prc_auc 0.76634[0m
[92maverage training of epoch 41: loss -11.17609 acc 0.66667 roc_auc 0.37100 prc_auc 0.58173[0m
[93maverage test of epoch 41: loss -11.21182 acc 0.65789 roc_auc 0.40923 prc_auc 0.61001[0m
[92maverage training of epoch 42: loss -11.34609 acc 0.66667 roc_auc 0.37730 prc_auc 0.57908[0m
[93maverage test of epoch 42: loss -11.38828 acc 0.65789 roc_auc 0.57077 prc_auc 0.73286[0m
[92maverage training of epoch 43: loss -11.51115 acc 0.66667 roc_auc 0.35780 prc_auc 0.56703[0m
[93maverage test of epoch 43: loss -11.55415 acc 0.65789 roc_auc 0.40615 prc_auc 0.60238[0m
[92maverage training of epoch 44: loss -11.67874 acc 0.66667 roc_auc 0.36450 prc_auc 0.57132[0m
[93maverage test of epoch 44: loss -11.71912 acc 0.65789 roc_auc 0.47846 prc_auc 0.64507[0m
[92maverage training of epoch 45: loss -11.84416 acc 0.66667 roc_auc 0.39560 prc_auc 0.59290[0m
[93maverage test of epoch 45: loss -11.88256 acc 0.65789 roc_auc 0.50154 prc_auc 0.66592[0m
[92maverage training of epoch 46: loss -12.01055 acc 0.66667 roc_auc 0.38140 prc_auc 0.58136[0m
[93maverage test of epoch 46: loss -12.05323 acc 0.65789 roc_auc 0.65385 prc_auc 0.74734[0m
[92maverage training of epoch 47: loss -12.17655 acc 0.66667 roc_auc 0.36910 prc_auc 0.57548[0m
[93maverage test of epoch 47: loss -12.21699 acc 0.65789 roc_auc 0.35385 prc_auc 0.57158[0m
[92maverage training of epoch 48: loss -12.34236 acc 0.66667 roc_auc 0.39480 prc_auc 0.59568[0m
[93maverage test of epoch 48: loss -12.38385 acc 0.65789 roc_auc 0.52923 prc_auc 0.68477[0m
[92maverage training of epoch 49: loss -12.50868 acc 0.66667 roc_auc 0.37430 prc_auc 0.58554[0m
[93maverage test of epoch 49: loss -12.54690 acc 0.65789 roc_auc 0.46923 prc_auc 0.63943[0m
[92maverage training of epoch 50: loss -12.67601 acc 0.66667 roc_auc 0.35860 prc_auc 0.56279[0m
[93maverage test of epoch 50: loss -12.71425 acc 0.65789 roc_auc 0.50308 prc_auc 0.67592[0m
[92maverage training of epoch 51: loss -12.84152 acc 0.66667 roc_auc 0.37980 prc_auc 0.58791[0m
[93maverage test of epoch 51: loss -12.87992 acc 0.65789 roc_auc 0.49538 prc_auc 0.64855[0m
[92maverage training of epoch 52: loss -13.00756 acc 0.66667 roc_auc 0.37700 prc_auc 0.58859[0m
[93maverage test of epoch 52: loss -13.04513 acc 0.65789 roc_auc 0.51077 prc_auc 0.67122[0m
[92maverage training of epoch 53: loss -13.17437 acc 0.66667 roc_auc 0.34440 prc_auc 0.55845[0m
[93maverage test of epoch 53: loss -13.21117 acc 0.65789 roc_auc 0.58308 prc_auc 0.71058[0m
[92maverage training of epoch 54: loss -13.33953 acc 0.66667 roc_auc 0.36100 prc_auc 0.56675[0m
[93maverage test of epoch 54: loss -13.37710 acc 0.65789 roc_auc 0.44923 prc_auc 0.62973[0m
[92maverage training of epoch 55: loss -13.50675 acc 0.66667 roc_auc 0.38050 prc_auc 0.58262[0m
[93maverage test of epoch 55: loss -13.54269 acc 0.65789 roc_auc 0.44000 prc_auc 0.63332[0m
[92maverage training of epoch 56: loss -13.67205 acc 0.66667 roc_auc 0.37160 prc_auc 0.57890[0m
[93maverage test of epoch 56: loss -13.70820 acc 0.65789 roc_auc 0.49538 prc_auc 0.65912[0m
[92maverage training of epoch 57: loss -13.83832 acc 0.66667 roc_auc 0.36770 prc_auc 0.56970[0m
[93maverage test of epoch 57: loss -13.87411 acc 0.65789 roc_auc 0.50462 prc_auc 0.65167[0m
[92maverage training of epoch 58: loss -14.00419 acc 0.66667 roc_auc 0.35770 prc_auc 0.56057[0m
[93maverage test of epoch 58: loss -14.03850 acc 0.65789 roc_auc 0.52154 prc_auc 0.67219[0m
[92maverage training of epoch 59: loss -14.17026 acc 0.66667 roc_auc 0.35950 prc_auc 0.56492[0m
[93maverage test of epoch 59: loss -14.20513 acc 0.65789 roc_auc 0.50154 prc_auc 0.65430[0m
[92maverage training of epoch 60: loss -14.33619 acc 0.66667 roc_auc 0.36050 prc_auc 0.56825[0m
[93maverage test of epoch 60: loss -14.37003 acc 0.65789 roc_auc 0.39077 prc_auc 0.60537[0m
[92maverage training of epoch 61: loss -14.50202 acc 0.66667 roc_auc 0.36720 prc_auc 0.56906[0m
[93maverage test of epoch 61: loss -14.53527 acc 0.65789 roc_auc 0.48000 prc_auc 0.63513[0m
[92maverage training of epoch 62: loss -14.66753 acc 0.66667 roc_auc 0.37350 prc_auc 0.57523[0m
[93maverage test of epoch 62: loss -14.70139 acc 0.65789 roc_auc 0.44462 prc_auc 0.63425[0m
[92maverage training of epoch 63: loss -14.83398 acc 0.66667 roc_auc 0.35560 prc_auc 0.56196[0m
[93maverage test of epoch 63: loss -14.86565 acc 0.65789 roc_auc 0.50462 prc_auc 0.65666[0m
[92maverage training of epoch 64: loss -14.99978 acc 0.66667 roc_auc 0.36500 prc_auc 0.56743[0m
[93maverage test of epoch 64: loss -15.03192 acc 0.65789 roc_auc 0.45077 prc_auc 0.62252[0m
[92maverage training of epoch 65: loss -15.16626 acc 0.66667 roc_auc 0.36470 prc_auc 0.56681[0m
[93maverage test of epoch 65: loss -15.19565 acc 0.65789 roc_auc 0.36615 prc_auc 0.59614[0m
[92maverage training of epoch 66: loss -15.33170 acc 0.66667 roc_auc 0.36550 prc_auc 0.56840[0m
[93maverage test of epoch 66: loss -15.36279 acc 0.65789 roc_auc 0.60615 prc_auc 0.72202[0m
[92maverage training of epoch 67: loss -15.49769 acc 0.66667 roc_auc 0.36390 prc_auc 0.56887[0m
[93maverage test of epoch 67: loss -15.52804 acc 0.65789 roc_auc 0.62769 prc_auc 0.72984[0m
[92maverage training of epoch 68: loss -15.66381 acc 0.66667 roc_auc 0.35900 prc_auc 0.56379[0m
[93maverage test of epoch 68: loss -15.69294 acc 0.65789 roc_auc 0.62154 prc_auc 0.71311[0m
[92maverage training of epoch 69: loss -15.82908 acc 0.66667 roc_auc 0.36160 prc_auc 0.56560[0m
[93maverage test of epoch 69: loss -15.85847 acc 0.65789 roc_auc 0.54462 prc_auc 0.69510[0m
[92maverage training of epoch 70: loss -15.99490 acc 0.66667 roc_auc 0.35090 prc_auc 0.55949[0m
[93maverage test of epoch 70: loss -16.02405 acc 0.65789 roc_auc 0.43231 prc_auc 0.62626[0m
[92maverage training of epoch 71: loss -16.16056 acc 0.66667 roc_auc 0.38190 prc_auc 0.57708[0m
[93maverage test of epoch 71: loss -16.18875 acc 0.65789 roc_auc 0.28923 prc_auc 0.56130[0m
[92maverage training of epoch 72: loss -16.32670 acc 0.66667 roc_auc 0.35290 prc_auc 0.56056[0m
[93maverage test of epoch 72: loss -16.35410 acc 0.65789 roc_auc 0.62308 prc_auc 0.72414[0m
[92maverage training of epoch 73: loss -16.49232 acc 0.66667 roc_auc 0.35810 prc_auc 0.56381[0m
[93maverage test of epoch 73: loss -16.51995 acc 0.65789 roc_auc 0.54308 prc_auc 0.71233[0m
[92maverage training of epoch 74: loss -16.65845 acc 0.66667 roc_auc 0.36310 prc_auc 0.56735[0m
[93maverage test of epoch 74: loss -16.68518 acc 0.65789 roc_auc 0.46462 prc_auc 0.64795[0m
[92maverage training of epoch 75: loss -16.82416 acc 0.66667 roc_auc 0.37100 prc_auc 0.57048[0m
[93maverage test of epoch 75: loss -16.85026 acc 0.65789 roc_auc 0.30462 prc_auc 0.56601[0m
[92maverage training of epoch 76: loss -16.98978 acc 0.66667 roc_auc 0.36360 prc_auc 0.56926[0m
[93maverage test of epoch 76: loss -17.01576 acc 0.65789 roc_auc 0.40154 prc_auc 0.60148[0m
[92maverage training of epoch 77: loss -17.15537 acc 0.66667 roc_auc 0.35340 prc_auc 0.56008[0m
[93maverage test of epoch 77: loss -17.18121 acc 0.65789 roc_auc 0.42923 prc_auc 0.61750[0m
[92maverage training of epoch 78: loss -17.32141 acc 0.66667 roc_auc 0.36140 prc_auc 0.56670[0m
[93maverage test of epoch 78: loss -17.34626 acc 0.65789 roc_auc 0.41538 prc_auc 0.61935[0m
[92maverage training of epoch 79: loss -17.48711 acc 0.66667 roc_auc 0.35720 prc_auc 0.56201[0m
[93maverage test of epoch 79: loss -17.51085 acc 0.65789 roc_auc 0.42923 prc_auc 0.62294[0m
[92maverage training of epoch 80: loss -17.65270 acc 0.66667 roc_auc 0.35560 prc_auc 0.56190[0m
[93maverage test of epoch 80: loss -17.67646 acc 0.65789 roc_auc 0.51692 prc_auc 0.66352[0m
[92maverage training of epoch 81: loss -17.81856 acc 0.66667 roc_auc 0.36130 prc_auc 0.56949[0m
[93maverage test of epoch 81: loss -17.84151 acc 0.65789 roc_auc 0.42462 prc_auc 0.62897[0m
[92maverage training of epoch 82: loss -17.98429 acc 0.66667 roc_auc 0.36040 prc_auc 0.56696[0m
[93maverage test of epoch 82: loss -18.00700 acc 0.65789 roc_auc 0.38462 prc_auc 0.60868[0m
[92maverage training of epoch 83: loss -18.15019 acc 0.66667 roc_auc 0.35830 prc_auc 0.56216[0m
[93maverage test of epoch 83: loss -18.17283 acc 0.65789 roc_auc 0.58462 prc_auc 0.69770[0m
[92maverage training of epoch 84: loss -18.31586 acc 0.66667 roc_auc 0.35470 prc_auc 0.56364[0m
[93maverage test of epoch 84: loss -18.33776 acc 0.65789 roc_auc 0.38154 prc_auc 0.59879[0m
[92maverage training of epoch 85: loss -18.48166 acc 0.66667 roc_auc 0.35560 prc_auc 0.56170[0m
[93maverage test of epoch 85: loss -18.50309 acc 0.65789 roc_auc 0.38923 prc_auc 0.60520[0m
[92maverage training of epoch 86: loss -18.64746 acc 0.66667 roc_auc 0.36270 prc_auc 0.56759[0m
[93maverage test of epoch 86: loss -18.66844 acc 0.65789 roc_auc 0.53692 prc_auc 0.68643[0m
[92maverage training of epoch 87: loss -18.81304 acc 0.66667 roc_auc 0.35910 prc_auc 0.56476[0m
[93maverage test of epoch 87: loss -18.83351 acc 0.65789 roc_auc 0.57385 prc_auc 0.69556[0m
[92maverage training of epoch 88: loss -18.97885 acc 0.66667 roc_auc 0.36300 prc_auc 0.56773[0m
[93maverage test of epoch 88: loss -18.99868 acc 0.65789 roc_auc 0.36769 prc_auc 0.59674[0m
[92maverage training of epoch 89: loss -19.14423 acc 0.66667 roc_auc 0.35390 prc_auc 0.56344[0m
[93maverage test of epoch 89: loss -19.16428 acc 0.65789 roc_auc 0.59385 prc_auc 0.70230[0m
[92maverage training of epoch 90: loss -19.31031 acc 0.66667 roc_auc 0.36430 prc_auc 0.56804[0m
[93maverage test of epoch 90: loss -19.32939 acc 0.65789 roc_auc 0.50000 prc_auc 0.66048[0m
[92maverage training of epoch 91: loss -19.47609 acc 0.66667 roc_auc 0.35910 prc_auc 0.56628[0m
[93maverage test of epoch 91: loss -19.49446 acc 0.65789 roc_auc 0.59231 prc_auc 0.71283[0m
[92maverage training of epoch 92: loss -19.64158 acc 0.66667 roc_auc 0.35960 prc_auc 0.56495[0m
[93maverage test of epoch 92: loss -19.65978 acc 0.65789 roc_auc 0.66615 prc_auc 0.75673[0m
[92maverage training of epoch 93: loss -19.80742 acc 0.66667 roc_auc 0.35760 prc_auc 0.56301[0m
[93maverage test of epoch 93: loss -19.82531 acc 0.65789 roc_auc 0.53846 prc_auc 0.68020[0m
[92maverage training of epoch 94: loss -19.97322 acc 0.66667 roc_auc 0.36300 prc_auc 0.56853[0m
[93maverage test of epoch 94: loss -19.99052 acc 0.65789 roc_auc 0.36462 prc_auc 0.59927[0m
[92maverage training of epoch 95: loss -20.13884 acc 0.66667 roc_auc 0.36010 prc_auc 0.56701[0m
[93maverage test of epoch 95: loss -20.15562 acc 0.65789 roc_auc 0.65231 prc_auc 0.74795[0m
[92maverage training of epoch 96: loss -20.30457 acc 0.66667 roc_auc 0.35870 prc_auc 0.56463[0m
[93maverage test of epoch 96: loss -20.32082 acc 0.65789 roc_auc 0.48769 prc_auc 0.65458[0m
[92maverage training of epoch 97: loss -20.47022 acc 0.66667 roc_auc 0.35670 prc_auc 0.56387[0m
[93maverage test of epoch 97: loss -20.48619 acc 0.65789 roc_auc 0.41077 prc_auc 0.62015[0m
[92maverage training of epoch 98: loss -20.63606 acc 0.66667 roc_auc 0.35550 prc_auc 0.56353[0m
[93maverage test of epoch 98: loss -20.65133 acc 0.65789 roc_auc 0.46000 prc_auc 0.64081[0m
[92maverage training of epoch 99: loss -20.80179 acc 0.66667 roc_auc 0.35680 prc_auc 0.56558[0m
[93maverage test of epoch 99: loss -20.81646 acc 0.65789 roc_auc 0.43077 prc_auc 0.62700[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.48404 acc 0.33333 roc_auc 0.58260 prc_auc 0.75302[0m
[93maverage test of epoch 0: loss -0.82843 acc 0.34211 roc_auc 0.67692 prc_auc 0.82220[0m
[92maverage training of epoch 1: loss -1.16650 acc 0.33333 roc_auc 0.47720 prc_auc 0.67358[0m
[93maverage test of epoch 1: loss -1.58222 acc 0.34211 roc_auc 0.53231 prc_auc 0.67757[0m
[92maverage training of epoch 2: loss -1.91307 acc 0.33333 roc_auc 0.38500 prc_auc 0.60835[0m
[93maverage test of epoch 2: loss -2.20149 acc 0.34211 roc_auc 0.44000 prc_auc 0.66323[0m
[92maverage training of epoch 3: loss -2.37853 acc 0.33333 roc_auc 0.39080 prc_auc 0.61785[0m
[93maverage test of epoch 3: loss -2.56816 acc 0.34211 roc_auc 0.42154 prc_auc 0.67712[0m
[92maverage training of epoch 4: loss -2.72971 acc 0.33333 roc_auc 0.46140 prc_auc 0.67271[0m
[93maverage test of epoch 4: loss -2.88765 acc 0.34211 roc_auc 0.46769 prc_auc 0.62460[0m
[92maverage training of epoch 5: loss -3.03962 acc 0.33333 roc_auc 0.45840 prc_auc 0.65465[0m
[93maverage test of epoch 5: loss -3.19969 acc 0.34211 roc_auc 0.43077 prc_auc 0.60265[0m
[92maverage training of epoch 6: loss -3.31575 acc 0.33333 roc_auc 0.39300 prc_auc 0.58825[0m
[93maverage test of epoch 6: loss -3.47748 acc 0.34211 roc_auc 0.50462 prc_auc 0.68055[0m
[92maverage training of epoch 7: loss -3.58062 acc 0.33333 roc_auc 0.42520 prc_auc 0.60570[0m
[93maverage test of epoch 7: loss -3.70738 acc 0.34211 roc_auc 0.72308 prc_auc 0.87474[0m
[92maverage training of epoch 8: loss -3.81675 acc 0.33333 roc_auc 0.45620 prc_auc 0.62479[0m
[93maverage test of epoch 8: loss -3.93912 acc 0.34211 roc_auc 0.51385 prc_auc 0.75035[0m
[92maverage training of epoch 9: loss -4.03298 acc 0.33333 roc_auc 0.45740 prc_auc 0.63995[0m
[93maverage test of epoch 9: loss -4.13364 acc 0.34211 roc_auc 0.42462 prc_auc 0.65380[0m
[92maverage training of epoch 10: loss -4.23154 acc 0.33333 roc_auc 0.46220 prc_auc 0.64783[0m
[93maverage test of epoch 10: loss -4.33931 acc 0.34211 roc_auc 0.60000 prc_auc 0.77848[0m
[92maverage training of epoch 11: loss -4.43140 acc 0.33333 roc_auc 0.43800 prc_auc 0.61070[0m
[93maverage test of epoch 11: loss -4.53058 acc 0.34211 roc_auc 0.60308 prc_auc 0.73396[0m
[92maverage training of epoch 12: loss -4.62155 acc 0.33333 roc_auc 0.42020 prc_auc 0.60605[0m
[93maverage test of epoch 12: loss -4.72121 acc 0.34211 roc_auc 0.57692 prc_auc 0.74713[0m
[92maverage training of epoch 13: loss -4.80531 acc 0.33333 roc_auc 0.47320 prc_auc 0.64606[0m
[93maverage test of epoch 13: loss -4.90738 acc 0.34211 roc_auc 0.67385 prc_auc 0.77080[0m
[92maverage training of epoch 14: loss -4.98785 acc 0.33333 roc_auc 0.42260 prc_auc 0.61582[0m
[93maverage test of epoch 14: loss -5.09247 acc 0.34211 roc_auc 0.62769 prc_auc 0.78687[0m
[92maverage training of epoch 15: loss -5.16903 acc 0.33333 roc_auc 0.44760 prc_auc 0.61870[0m
[93maverage test of epoch 15: loss -5.26602 acc 0.34211 roc_auc 0.47385 prc_auc 0.69442[0m
[92maverage training of epoch 16: loss -5.35095 acc 0.33333 roc_auc 0.44180 prc_auc 0.62734[0m
[93maverage test of epoch 16: loss -5.43746 acc 0.34211 roc_auc 0.52615 prc_auc 0.71078[0m
[92maverage training of epoch 17: loss -5.51993 acc 0.33333 roc_auc 0.43360 prc_auc 0.61344[0m
[93maverage test of epoch 17: loss -5.61606 acc 0.34211 roc_auc 0.35538 prc_auc 0.60429[0m
[92maverage training of epoch 18: loss -5.69864 acc 0.33333 roc_auc 0.40480 prc_auc 0.58601[0m
[93maverage test of epoch 18: loss -5.79739 acc 0.34211 roc_auc 0.59692 prc_auc 0.77232[0m
[92maverage training of epoch 19: loss -5.87682 acc 0.33333 roc_auc 0.45060 prc_auc 0.61944[0m
[93maverage test of epoch 19: loss -5.96643 acc 0.34211 roc_auc 0.53538 prc_auc 0.74882[0m
[92maverage training of epoch 20: loss -6.04749 acc 0.33333 roc_auc 0.44000 prc_auc 0.63410[0m
[93maverage test of epoch 20: loss -6.13641 acc 0.34211 roc_auc 0.48615 prc_auc 0.68690[0m
[92maverage training of epoch 21: loss -6.21864 acc 0.33333 roc_auc 0.41340 prc_auc 0.60145[0m
[93maverage test of epoch 21: loss -6.30582 acc 0.34211 roc_auc 0.48308 prc_auc 0.67005[0m
[92maverage training of epoch 22: loss -6.39405 acc 0.33333 roc_auc 0.41620 prc_auc 0.60175[0m
[93maverage test of epoch 22: loss -6.47385 acc 0.34211 roc_auc 0.52615 prc_auc 0.63823[0m
[92maverage training of epoch 23: loss -6.56148 acc 0.33333 roc_auc 0.43680 prc_auc 0.61954[0m
[93maverage test of epoch 23: loss -6.64556 acc 0.34211 roc_auc 0.52923 prc_auc 0.73749[0m
[92maverage training of epoch 24: loss -6.73329 acc 0.33333 roc_auc 0.43120 prc_auc 0.59979[0m
[93maverage test of epoch 24: loss -6.81596 acc 0.34211 roc_auc 0.44308 prc_auc 0.65089[0m
[92maverage training of epoch 25: loss -6.90279 acc 0.33333 roc_auc 0.41840 prc_auc 0.59877[0m
[93maverage test of epoch 25: loss -6.99444 acc 0.34211 roc_auc 0.58923 prc_auc 0.77523[0m
[92maverage training of epoch 26: loss -7.07114 acc 0.33333 roc_auc 0.42160 prc_auc 0.61373[0m
[93maverage test of epoch 26: loss -7.15870 acc 0.34211 roc_auc 0.47077 prc_auc 0.69577[0m
[92maverage training of epoch 27: loss -7.24112 acc 0.33333 roc_auc 0.42860 prc_auc 0.63623[0m
[93maverage test of epoch 27: loss -7.32836 acc 0.34211 roc_auc 0.42923 prc_auc 0.69965[0m
[92maverage training of epoch 28: loss -7.41085 acc 0.62667 roc_auc 0.41980 prc_auc 0.61959[0m
[93maverage test of epoch 28: loss -7.49901 acc 0.65789 roc_auc 0.59077 prc_auc 0.74976[0m
[92maverage training of epoch 29: loss -7.57797 acc 0.66667 roc_auc 0.42460 prc_auc 0.60040[0m
[93maverage test of epoch 29: loss -7.66509 acc 0.65789 roc_auc 0.47231 prc_auc 0.66071[0m
[92maverage training of epoch 30: loss -7.74872 acc 0.66667 roc_auc 0.41680 prc_auc 0.59894[0m
[93maverage test of epoch 30: loss -7.82909 acc 0.65789 roc_auc 0.61538 prc_auc 0.75549[0m
[92maverage training of epoch 31: loss -7.91570 acc 0.66667 roc_auc 0.42560 prc_auc 0.61423[0m
[93maverage test of epoch 31: loss -8.00369 acc 0.65789 roc_auc 0.42154 prc_auc 0.65016[0m
[92maverage training of epoch 32: loss -8.08102 acc 0.66667 roc_auc 0.41760 prc_auc 0.60195[0m
[93maverage test of epoch 32: loss -8.16574 acc 0.65789 roc_auc 0.63077 prc_auc 0.79081[0m
[92maverage training of epoch 33: loss -8.25031 acc 0.66667 roc_auc 0.41780 prc_auc 0.59875[0m
[93maverage test of epoch 33: loss -8.33368 acc 0.65789 roc_auc 0.46000 prc_auc 0.65997[0m
[92maverage training of epoch 34: loss -8.41753 acc 0.66667 roc_auc 0.42920 prc_auc 0.61841[0m
[93maverage test of epoch 34: loss -8.49558 acc 0.65789 roc_auc 0.64615 prc_auc 0.76626[0m
[92maverage training of epoch 35: loss -8.58177 acc 0.66667 roc_auc 0.40810 prc_auc 0.58940[0m
[93maverage test of epoch 35: loss -8.66444 acc 0.65789 roc_auc 0.54615 prc_auc 0.70784[0m
[92maverage training of epoch 36: loss -8.75121 acc 0.66667 roc_auc 0.42110 prc_auc 0.60198[0m
[93maverage test of epoch 36: loss -8.83175 acc 0.65789 roc_auc 0.53538 prc_auc 0.67778[0m
[92maverage training of epoch 37: loss -8.91883 acc 0.66667 roc_auc 0.42200 prc_auc 0.60680[0m
[93maverage test of epoch 37: loss -8.99590 acc 0.65789 roc_auc 0.35077 prc_auc 0.57782[0m
[92maverage training of epoch 38: loss -9.08493 acc 0.66667 roc_auc 0.42380 prc_auc 0.60099[0m
[93maverage test of epoch 38: loss -9.16318 acc 0.65789 roc_auc 0.53846 prc_auc 0.72196[0m
[92maverage training of epoch 39: loss -9.25236 acc 0.66667 roc_auc 0.42920 prc_auc 0.60180[0m
[93maverage test of epoch 39: loss -9.33261 acc 0.65789 roc_auc 0.62462 prc_auc 0.77874[0m
[92maverage training of epoch 40: loss -9.41874 acc 0.66667 roc_auc 0.42120 prc_auc 0.60379[0m
[93maverage test of epoch 40: loss -9.49579 acc 0.65789 roc_auc 0.46000 prc_auc 0.67004[0m
[92maverage training of epoch 41: loss -9.58518 acc 0.66667 roc_auc 0.43360 prc_auc 0.61084[0m
[93maverage test of epoch 41: loss -9.66103 acc 0.65789 roc_auc 0.39231 prc_auc 0.59908[0m
[92maverage training of epoch 42: loss -9.75233 acc 0.66667 roc_auc 0.42460 prc_auc 0.61739[0m
[93maverage test of epoch 42: loss -9.82947 acc 0.65789 roc_auc 0.47385 prc_auc 0.62297[0m
[92maverage training of epoch 43: loss -9.91924 acc 0.66667 roc_auc 0.42260 prc_auc 0.60983[0m
[93maverage test of epoch 43: loss -9.99304 acc 0.65789 roc_auc 0.50769 prc_auc 0.69506[0m
[92maverage training of epoch 44: loss -10.08566 acc 0.66667 roc_auc 0.42120 prc_auc 0.60433[0m
[93maverage test of epoch 44: loss -10.16226 acc 0.65789 roc_auc 0.34769 prc_auc 0.59973[0m
[92maverage training of epoch 45: loss -10.25130 acc 0.66667 roc_auc 0.42220 prc_auc 0.60191[0m
[93maverage test of epoch 45: loss -10.32643 acc 0.65789 roc_auc 0.51692 prc_auc 0.71735[0m
[92maverage training of epoch 46: loss -10.41726 acc 0.66667 roc_auc 0.41920 prc_auc 0.60422[0m
[93maverage test of epoch 46: loss -10.49291 acc 0.65789 roc_auc 0.60000 prc_auc 0.74361[0m
[92maverage training of epoch 47: loss -10.58239 acc 0.66667 roc_auc 0.41820 prc_auc 0.60572[0m
[93maverage test of epoch 47: loss -10.65874 acc 0.65789 roc_auc 0.47846 prc_auc 0.65826[0m
[92maverage training of epoch 48: loss -10.74964 acc 0.66667 roc_auc 0.42640 prc_auc 0.61203[0m
[93maverage test of epoch 48: loss -10.82401 acc 0.65789 roc_auc 0.52615 prc_auc 0.67309[0m
[92maverage training of epoch 49: loss -10.91650 acc 0.66667 roc_auc 0.41300 prc_auc 0.59907[0m
[93maverage test of epoch 49: loss -10.99054 acc 0.65789 roc_auc 0.47538 prc_auc 0.62608[0m
[92maverage training of epoch 50: loss -11.08108 acc 0.66667 roc_auc 0.41260 prc_auc 0.60249[0m
[93maverage test of epoch 50: loss -11.15556 acc 0.65789 roc_auc 0.40923 prc_auc 0.63325[0m
[92maverage training of epoch 51: loss -11.24782 acc 0.66667 roc_auc 0.41600 prc_auc 0.59286[0m
[93maverage test of epoch 51: loss -11.32020 acc 0.65789 roc_auc 0.45538 prc_auc 0.65543[0m
[92maverage training of epoch 52: loss -11.41392 acc 0.66667 roc_auc 0.41620 prc_auc 0.60442[0m
[93maverage test of epoch 52: loss -11.48672 acc 0.65789 roc_auc 0.45385 prc_auc 0.65911[0m
[92maverage training of epoch 53: loss -11.57983 acc 0.66667 roc_auc 0.42050 prc_auc 0.60417[0m
[93maverage test of epoch 53: loss -11.65177 acc 0.65789 roc_auc 0.60923 prc_auc 0.75657[0m
[92maverage training of epoch 54: loss -11.74725 acc 0.66667 roc_auc 0.42070 prc_auc 0.60976[0m
[93maverage test of epoch 54: loss -11.81734 acc 0.65789 roc_auc 0.56615 prc_auc 0.72100[0m
[92maverage training of epoch 55: loss -11.91228 acc 0.66667 roc_auc 0.43360 prc_auc 0.61300[0m
[93maverage test of epoch 55: loss -11.98371 acc 0.65789 roc_auc 0.53385 prc_auc 0.75403[0m
[92maverage training of epoch 56: loss -12.07808 acc 0.66667 roc_auc 0.41980 prc_auc 0.60441[0m
[93maverage test of epoch 56: loss -12.14848 acc 0.65789 roc_auc 0.54154 prc_auc 0.71613[0m
[92maverage training of epoch 57: loss -12.24405 acc 0.66667 roc_auc 0.41490 prc_auc 0.59632[0m
[93maverage test of epoch 57: loss -12.31473 acc 0.65789 roc_auc 0.51846 prc_auc 0.66235[0m
[92maverage training of epoch 58: loss -12.41011 acc 0.66667 roc_auc 0.42060 prc_auc 0.60287[0m
[93maverage test of epoch 58: loss -12.47987 acc 0.65789 roc_auc 0.34154 prc_auc 0.61571[0m
[92maverage training of epoch 59: loss -12.57569 acc 0.66667 roc_auc 0.42420 prc_auc 0.61014[0m
[93maverage test of epoch 59: loss -12.64527 acc 0.65789 roc_auc 0.59846 prc_auc 0.75258[0m
[92maverage training of epoch 60: loss -12.74171 acc 0.66667 roc_auc 0.41660 prc_auc 0.61149[0m
[93maverage test of epoch 60: loss -12.81020 acc 0.65789 roc_auc 0.49077 prc_auc 0.66431[0m
[92maverage training of epoch 61: loss -12.90766 acc 0.66667 roc_auc 0.42480 prc_auc 0.60463[0m
[93maverage test of epoch 61: loss -12.97623 acc 0.65789 roc_auc 0.58923 prc_auc 0.77524[0m
[92maverage training of epoch 62: loss -13.07397 acc 0.66667 roc_auc 0.41920 prc_auc 0.60428[0m
[93maverage test of epoch 62: loss -13.14169 acc 0.65789 roc_auc 0.35538 prc_auc 0.62328[0m
[92maverage training of epoch 63: loss -13.23925 acc 0.66667 roc_auc 0.42440 prc_auc 0.60241[0m
[93maverage test of epoch 63: loss -13.30703 acc 0.65789 roc_auc 0.49846 prc_auc 0.66674[0m
[92maverage training of epoch 64: loss -13.40483 acc 0.66667 roc_auc 0.42040 prc_auc 0.59995[0m
[93maverage test of epoch 64: loss -13.47243 acc 0.65789 roc_auc 0.78308 prc_auc 0.86988[0m
[92maverage training of epoch 65: loss -13.57109 acc 0.66667 roc_auc 0.41590 prc_auc 0.59973[0m
[93maverage test of epoch 65: loss -13.63760 acc 0.65789 roc_auc 0.43231 prc_auc 0.63483[0m
[92maverage training of epoch 66: loss -13.73708 acc 0.66667 roc_auc 0.42040 prc_auc 0.60258[0m
[93maverage test of epoch 66: loss -13.80308 acc 0.65789 roc_auc 0.37385 prc_auc 0.63922[0m
[92maverage training of epoch 67: loss -13.90326 acc 0.66667 roc_auc 0.41780 prc_auc 0.60045[0m
[93maverage test of epoch 67: loss -13.96812 acc 0.65789 roc_auc 0.66769 prc_auc 0.81504[0m
[92maverage training of epoch 68: loss -14.06883 acc 0.66667 roc_auc 0.42080 prc_auc 0.60233[0m
[93maverage test of epoch 68: loss -14.13348 acc 0.65789 roc_auc 0.48769 prc_auc 0.63418[0m
[92maverage training of epoch 69: loss -14.23449 acc 0.66667 roc_auc 0.41880 prc_auc 0.60229[0m
[93maverage test of epoch 69: loss -14.29867 acc 0.65789 roc_auc 0.49538 prc_auc 0.69935[0m
[92maverage training of epoch 70: loss -14.40043 acc 0.66667 roc_auc 0.42280 prc_auc 0.60933[0m
[93maverage test of epoch 70: loss -14.46424 acc 0.65789 roc_auc 0.49077 prc_auc 0.69609[0m
[92maverage training of epoch 71: loss -14.56638 acc 0.66667 roc_auc 0.41660 prc_auc 0.59941[0m
[93maverage test of epoch 71: loss -14.62968 acc 0.65789 roc_auc 0.52308 prc_auc 0.69347[0m
[92maverage training of epoch 72: loss -14.73207 acc 0.66667 roc_auc 0.41900 prc_auc 0.59698[0m
[93maverage test of epoch 72: loss -14.79516 acc 0.65789 roc_auc 0.47538 prc_auc 0.63472[0m
[92maverage training of epoch 73: loss -14.89777 acc 0.66667 roc_auc 0.42280 prc_auc 0.60750[0m
[93maverage test of epoch 73: loss -14.96015 acc 0.65789 roc_auc 0.60000 prc_auc 0.73009[0m
[92maverage training of epoch 74: loss -15.06369 acc 0.66667 roc_auc 0.42240 prc_auc 0.60612[0m
[93maverage test of epoch 74: loss -15.12513 acc 0.65789 roc_auc 0.46923 prc_auc 0.64087[0m
[92maverage training of epoch 75: loss -15.22938 acc 0.66667 roc_auc 0.41920 prc_auc 0.59961[0m
[93maverage test of epoch 75: loss -15.29016 acc 0.65789 roc_auc 0.53385 prc_auc 0.67229[0m
[92maverage training of epoch 76: loss -15.39507 acc 0.66667 roc_auc 0.42280 prc_auc 0.60744[0m
[93maverage test of epoch 76: loss -15.45647 acc 0.65789 roc_auc 0.50615 prc_auc 0.70499[0m
[92maverage training of epoch 77: loss -15.56091 acc 0.66667 roc_auc 0.41880 prc_auc 0.60410[0m
[93maverage test of epoch 77: loss -15.62032 acc 0.65789 roc_auc 0.52462 prc_auc 0.63617[0m
[92maverage training of epoch 78: loss -15.72690 acc 0.66667 roc_auc 0.42220 prc_auc 0.60429[0m
[93maverage test of epoch 78: loss -15.78622 acc 0.65789 roc_auc 0.65231 prc_auc 0.75409[0m
[92maverage training of epoch 79: loss -15.89222 acc 0.66667 roc_auc 0.42140 prc_auc 0.60815[0m
[93maverage test of epoch 79: loss -15.95196 acc 0.65789 roc_auc 0.22615 prc_auc 0.51867[0m
[92maverage training of epoch 80: loss -16.05813 acc 0.66667 roc_auc 0.42350 prc_auc 0.61865[0m
[93maverage test of epoch 80: loss -16.11739 acc 0.65789 roc_auc 0.60462 prc_auc 0.73069[0m
[92maverage training of epoch 81: loss -16.22397 acc 0.66667 roc_auc 0.41740 prc_auc 0.60454[0m
[93maverage test of epoch 81: loss -16.28252 acc 0.65789 roc_auc 0.46462 prc_auc 0.67686[0m
[92maverage training of epoch 82: loss -16.38978 acc 0.66667 roc_auc 0.41930 prc_auc 0.60467[0m
[93maverage test of epoch 82: loss -16.44765 acc 0.65789 roc_auc 0.46462 prc_auc 0.61961[0m
[92maverage training of epoch 83: loss -16.55549 acc 0.66667 roc_auc 0.42220 prc_auc 0.60781[0m
[93maverage test of epoch 83: loss -16.61317 acc 0.65789 roc_auc 0.54000 prc_auc 0.72296[0m
[92maverage training of epoch 84: loss -16.72118 acc 0.66667 roc_auc 0.42120 prc_auc 0.60671[0m
[93maverage test of epoch 84: loss -16.77828 acc 0.65789 roc_auc 0.58154 prc_auc 0.76018[0m
[92maverage training of epoch 85: loss -16.88691 acc 0.66667 roc_auc 0.41970 prc_auc 0.60515[0m
[93maverage test of epoch 85: loss -16.94332 acc 0.65789 roc_auc 0.46769 prc_auc 0.65292[0m
[92maverage training of epoch 86: loss -17.05278 acc 0.66667 roc_auc 0.42000 prc_auc 0.60392[0m
[93maverage test of epoch 86: loss -17.10821 acc 0.65789 roc_auc 0.50000 prc_auc 0.67849[0m
[92maverage training of epoch 87: loss -17.21834 acc 0.66667 roc_auc 0.42260 prc_auc 0.60553[0m
[93maverage test of epoch 87: loss -17.27401 acc 0.65789 roc_auc 0.50462 prc_auc 0.64188[0m
[92maverage training of epoch 88: loss -17.38392 acc 0.66667 roc_auc 0.42290 prc_auc 0.60936[0m
[93maverage test of epoch 88: loss -17.43933 acc 0.65789 roc_auc 0.63538 prc_auc 0.76613[0m
[92maverage training of epoch 89: loss -17.54987 acc 0.66667 roc_auc 0.41720 prc_auc 0.60037[0m
[93maverage test of epoch 89: loss -17.60450 acc 0.65789 roc_auc 0.43692 prc_auc 0.65353[0m
[92maverage training of epoch 90: loss -17.71574 acc 0.66667 roc_auc 0.42060 prc_auc 0.60258[0m
[93maverage test of epoch 90: loss -17.76995 acc 0.65789 roc_auc 0.44462 prc_auc 0.62566[0m
[92maverage training of epoch 91: loss -17.88130 acc 0.66667 roc_auc 0.42200 prc_auc 0.60636[0m
[93maverage test of epoch 91: loss -17.93521 acc 0.65789 roc_auc 0.47692 prc_auc 0.62414[0m
[92maverage training of epoch 92: loss -18.04707 acc 0.66667 roc_auc 0.42200 prc_auc 0.60665[0m
[93maverage test of epoch 92: loss -18.10031 acc 0.65789 roc_auc 0.62462 prc_auc 0.78590[0m
[92maverage training of epoch 93: loss -18.21292 acc 0.66667 roc_auc 0.42000 prc_auc 0.60619[0m
[93maverage test of epoch 93: loss -18.26545 acc 0.65789 roc_auc 0.51231 prc_auc 0.66043[0m
[92maverage training of epoch 94: loss -18.37859 acc 0.66667 roc_auc 0.41910 prc_auc 0.60433[0m
[93maverage test of epoch 94: loss -18.43097 acc 0.65789 roc_auc 0.49538 prc_auc 0.65841[0m
[92maverage training of epoch 95: loss -18.54424 acc 0.66667 roc_auc 0.42000 prc_auc 0.60204[0m
[93maverage test of epoch 95: loss -18.59622 acc 0.65789 roc_auc 0.67692 prc_auc 0.80787[0m
[92maverage training of epoch 96: loss -18.70994 acc 0.66667 roc_auc 0.42250 prc_auc 0.60270[0m
[93maverage test of epoch 96: loss -18.76153 acc 0.65789 roc_auc 0.52923 prc_auc 0.66662[0m
[92maverage training of epoch 97: loss -18.87561 acc 0.66667 roc_auc 0.41820 prc_auc 0.60287[0m
[93maverage test of epoch 97: loss -18.92662 acc 0.65789 roc_auc 0.44923 prc_auc 0.66782[0m
[92maverage training of epoch 98: loss -19.04149 acc 0.66667 roc_auc 0.42100 prc_auc 0.60374[0m
[93maverage test of epoch 98: loss -19.09197 acc 0.65789 roc_auc 0.45692 prc_auc 0.66941[0m
[92maverage training of epoch 99: loss -19.20723 acc 0.66667 roc_auc 0.41870 prc_auc 0.60302[0m
[93maverage test of epoch 99: loss -19.25727 acc 0.65789 roc_auc 0.41692 prc_auc 0.62351[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.46464 acc 0.66667 roc_auc 0.35500 prc_auc 0.56892[0m
[93maverage test of epoch 0: loss -0.64616 acc 0.65789 roc_auc 0.46154 prc_auc 0.66916[0m
[92maverage training of epoch 1: loss -0.94411 acc 0.66667 roc_auc 0.45160 prc_auc 0.62472[0m
[93maverage test of epoch 1: loss -1.23897 acc 0.65789 roc_auc 0.72615 prc_auc 0.78331[0m
[92maverage training of epoch 2: loss -1.41923 acc 0.66667 roc_auc 0.45500 prc_auc 0.69842[0m
[93maverage test of epoch 2: loss -1.58261 acc 0.65789 roc_auc 0.41538 prc_auc 0.64702[0m
[92maverage training of epoch 3: loss -1.76816 acc 0.66667 roc_auc 0.43320 prc_auc 0.63021[0m
[93maverage test of epoch 3: loss -1.91882 acc 0.65789 roc_auc 0.48923 prc_auc 0.67823[0m
[92maverage training of epoch 4: loss -2.07071 acc 0.66667 roc_auc 0.43240 prc_auc 0.60623[0m
[93maverage test of epoch 4: loss -2.19005 acc 0.65789 roc_auc 0.47385 prc_auc 0.64136[0m
[92maverage training of epoch 5: loss -2.34462 acc 0.66667 roc_auc 0.42760 prc_auc 0.61201[0m
[93maverage test of epoch 5: loss -2.46180 acc 0.65789 roc_auc 0.48308 prc_auc 0.71470[0m
[92maverage training of epoch 6: loss -2.60042 acc 0.66667 roc_auc 0.50920 prc_auc 0.66694[0m
[93maverage test of epoch 6: loss -2.68998 acc 0.65789 roc_auc 0.49231 prc_auc 0.72155[0m
[92maverage training of epoch 7: loss -2.83899 acc 0.66667 roc_auc 0.41800 prc_auc 0.62636[0m
[93maverage test of epoch 7: loss -2.92584 acc 0.65789 roc_auc 0.64000 prc_auc 0.81418[0m
[92maverage training of epoch 8: loss -3.05710 acc 0.66667 roc_auc 0.35860 prc_auc 0.58811[0m
[93maverage test of epoch 8: loss -3.16440 acc 0.65789 roc_auc 0.68615 prc_auc 0.81406[0m
[92maverage training of epoch 9: loss -3.27839 acc 0.66667 roc_auc 0.43160 prc_auc 0.62094[0m
[93maverage test of epoch 9: loss -3.36880 acc 0.65789 roc_auc 0.63692 prc_auc 0.74204[0m
[92maverage training of epoch 10: loss -3.48011 acc 0.66667 roc_auc 0.51740 prc_auc 0.68009[0m
[93maverage test of epoch 10: loss -3.55590 acc 0.65789 roc_auc 0.48923 prc_auc 0.65950[0m
[92maverage training of epoch 11: loss -3.67819 acc 0.66667 roc_auc 0.43500 prc_auc 0.62774[0m
[93maverage test of epoch 11: loss -3.74969 acc 0.65789 roc_auc 0.43385 prc_auc 0.66156[0m
[92maverage training of epoch 12: loss -3.86876 acc 0.66667 roc_auc 0.41220 prc_auc 0.59078[0m
[93maverage test of epoch 12: loss -3.93169 acc 0.65789 roc_auc 0.56308 prc_auc 0.77188[0m
[92maverage training of epoch 13: loss -4.05154 acc 0.66667 roc_auc 0.48700 prc_auc 0.65224[0m
[93maverage test of epoch 13: loss -4.10708 acc 0.65789 roc_auc 0.38769 prc_auc 0.61688[0m
[92maverage training of epoch 14: loss -4.23834 acc 0.66667 roc_auc 0.45460 prc_auc 0.62618[0m
[93maverage test of epoch 14: loss -4.29305 acc 0.65789 roc_auc 0.52308 prc_auc 0.75554[0m
[92maverage training of epoch 15: loss -4.41523 acc 0.66667 roc_auc 0.40400 prc_auc 0.58543[0m
[93maverage test of epoch 15: loss -4.48071 acc 0.65789 roc_auc 0.47385 prc_auc 0.68552[0m
[92maverage training of epoch 16: loss -4.58986 acc 0.66667 roc_auc 0.41440 prc_auc 0.60919[0m
[93maverage test of epoch 16: loss -4.64953 acc 0.65789 roc_auc 0.40308 prc_auc 0.62627[0m
[92maverage training of epoch 17: loss -4.77289 acc 0.66667 roc_auc 0.43680 prc_auc 0.62629[0m
[93maverage test of epoch 17: loss -4.82753 acc 0.65789 roc_auc 0.43692 prc_auc 0.68824[0m
[92maverage training of epoch 18: loss -4.94401 acc 0.66667 roc_auc 0.37780 prc_auc 0.59745[0m
[93maverage test of epoch 18: loss -5.01325 acc 0.65789 roc_auc 0.65231 prc_auc 0.80802[0m
[92maverage training of epoch 19: loss -5.12022 acc 0.66667 roc_auc 0.44500 prc_auc 0.62932[0m
[93maverage test of epoch 19: loss -5.18093 acc 0.65789 roc_auc 0.57231 prc_auc 0.73220[0m
[92maverage training of epoch 20: loss -5.29564 acc 0.66667 roc_auc 0.39560 prc_auc 0.61258[0m
[93maverage test of epoch 20: loss -5.35753 acc 0.65789 roc_auc 0.57077 prc_auc 0.74842[0m
[92maverage training of epoch 21: loss -5.46546 acc 0.66667 roc_auc 0.46220 prc_auc 0.62680[0m
[93maverage test of epoch 21: loss -5.52423 acc 0.65789 roc_auc 0.61538 prc_auc 0.76536[0m
[92maverage training of epoch 22: loss -5.63934 acc 0.66667 roc_auc 0.40880 prc_auc 0.59278[0m
[93maverage test of epoch 22: loss -5.69222 acc 0.65789 roc_auc 0.56615 prc_auc 0.75978[0m
[92maverage training of epoch 23: loss -5.81016 acc 0.66667 roc_auc 0.47790 prc_auc 0.65991[0m
[93maverage test of epoch 23: loss -5.86255 acc 0.65789 roc_auc 0.41077 prc_auc 0.64497[0m
[92maverage training of epoch 24: loss -5.97777 acc 0.66667 roc_auc 0.39770 prc_auc 0.59892[0m
[93maverage test of epoch 24: loss -6.03370 acc 0.65789 roc_auc 0.37231 prc_auc 0.58939[0m
[92maverage training of epoch 25: loss -6.15016 acc 0.66667 roc_auc 0.44740 prc_auc 0.62074[0m
[93maverage test of epoch 25: loss -6.20718 acc 0.65789 roc_auc 0.41077 prc_auc 0.67333[0m
[92maverage training of epoch 26: loss -6.31854 acc 0.66667 roc_auc 0.38120 prc_auc 0.58153[0m
[93maverage test of epoch 26: loss -6.37590 acc 0.65789 roc_auc 0.61231 prc_auc 0.72384[0m
[92maverage training of epoch 27: loss -6.48788 acc 0.66667 roc_auc 0.43680 prc_auc 0.62599[0m
[93maverage test of epoch 27: loss -6.54220 acc 0.65789 roc_auc 0.55385 prc_auc 0.75649[0m
[92maverage training of epoch 28: loss -6.65890 acc 0.66667 roc_auc 0.43380 prc_auc 0.62272[0m
[93maverage test of epoch 28: loss -6.70559 acc 0.65789 roc_auc 0.52462 prc_auc 0.67388[0m
[92maverage training of epoch 29: loss -6.82569 acc 0.66667 roc_auc 0.42000 prc_auc 0.62079[0m
[93maverage test of epoch 29: loss -6.87763 acc 0.65789 roc_auc 0.69077 prc_auc 0.81385[0m
[92maverage training of epoch 30: loss -6.99465 acc 0.66667 roc_auc 0.43100 prc_auc 0.59914[0m
[93maverage test of epoch 30: loss -7.04503 acc 0.65789 roc_auc 0.48923 prc_auc 0.69370[0m
[92maverage training of epoch 31: loss -7.16088 acc 0.66667 roc_auc 0.42500 prc_auc 0.62268[0m
[93maverage test of epoch 31: loss -7.21008 acc 0.65789 roc_auc 0.45231 prc_auc 0.67103[0m
[92maverage training of epoch 32: loss -7.32890 acc 0.66667 roc_auc 0.43480 prc_auc 0.61184[0m
[93maverage test of epoch 32: loss -7.37919 acc 0.65789 roc_auc 0.47385 prc_auc 0.69182[0m
[92maverage training of epoch 33: loss -7.49534 acc 0.66667 roc_auc 0.36690 prc_auc 0.57190[0m
[93maverage test of epoch 33: loss -7.54539 acc 0.65789 roc_auc 0.47846 prc_auc 0.62120[0m
[92maverage training of epoch 34: loss -7.66310 acc 0.66667 roc_auc 0.40410 prc_auc 0.59004[0m
[93maverage test of epoch 34: loss -7.71104 acc 0.65789 roc_auc 0.31692 prc_auc 0.57819[0m
[92maverage training of epoch 35: loss -7.83240 acc 0.66667 roc_auc 0.40020 prc_auc 0.58934[0m
[93maverage test of epoch 35: loss -7.87777 acc 0.65789 roc_auc 0.44462 prc_auc 0.63928[0m
[92maverage training of epoch 36: loss -7.99665 acc 0.66667 roc_auc 0.39000 prc_auc 0.58082[0m
[93maverage test of epoch 36: loss -8.04705 acc 0.65789 roc_auc 0.58923 prc_auc 0.70839[0m
[92maverage training of epoch 37: loss -8.16505 acc 0.66667 roc_auc 0.37680 prc_auc 0.57300[0m
[93maverage test of epoch 37: loss -8.21325 acc 0.65789 roc_auc 0.51846 prc_auc 0.74183[0m
[92maverage training of epoch 38: loss -8.33107 acc 0.66667 roc_auc 0.38300 prc_auc 0.59090[0m
[93maverage test of epoch 38: loss -8.37688 acc 0.65789 roc_auc 0.53692 prc_auc 0.73195[0m
[92maverage training of epoch 39: loss -8.49794 acc 0.66667 roc_auc 0.36670 prc_auc 0.56838[0m
[93maverage test of epoch 39: loss -8.54237 acc 0.65789 roc_auc 0.50923 prc_auc 0.71420[0m
[92maverage training of epoch 40: loss -8.66545 acc 0.66667 roc_auc 0.42220 prc_auc 0.61250[0m
[93maverage test of epoch 40: loss -8.71251 acc 0.65789 roc_auc 0.60308 prc_auc 0.72334[0m
[92maverage training of epoch 41: loss -8.83110 acc 0.66667 roc_auc 0.41520 prc_auc 0.58949[0m
[93maverage test of epoch 41: loss -8.87792 acc 0.65789 roc_auc 0.50154 prc_auc 0.66559[0m
[92maverage training of epoch 42: loss -8.99871 acc 0.66667 roc_auc 0.41290 prc_auc 0.60777[0m
[93maverage test of epoch 42: loss -9.04326 acc 0.65789 roc_auc 0.46308 prc_auc 0.63806[0m
[92maverage training of epoch 43: loss -9.16507 acc 0.66667 roc_auc 0.37610 prc_auc 0.58036[0m
[93maverage test of epoch 43: loss -9.20835 acc 0.65789 roc_auc 0.44308 prc_auc 0.63338[0m
[92maverage training of epoch 44: loss -9.33148 acc 0.66667 roc_auc 0.39300 prc_auc 0.58762[0m
[93maverage test of epoch 44: loss -9.37452 acc 0.65789 roc_auc 0.69077 prc_auc 0.77650[0m
[92maverage training of epoch 45: loss -9.49793 acc 0.66667 roc_auc 0.39500 prc_auc 0.59907[0m
[93maverage test of epoch 45: loss -9.54055 acc 0.65789 roc_auc 0.39385 prc_auc 0.58303[0m
[92maverage training of epoch 46: loss -9.66344 acc 0.66667 roc_auc 0.38860 prc_auc 0.59873[0m
[93maverage test of epoch 46: loss -9.70699 acc 0.65789 roc_auc 0.63846 prc_auc 0.76058[0m
[92maverage training of epoch 47: loss -9.82991 acc 0.66667 roc_auc 0.39340 prc_auc 0.59381[0m
[93maverage test of epoch 47: loss -9.87098 acc 0.65789 roc_auc 0.40769 prc_auc 0.59632[0m
[92maverage training of epoch 48: loss -9.99659 acc 0.66667 roc_auc 0.37600 prc_auc 0.58209[0m
[93maverage test of epoch 48: loss -10.03693 acc 0.65789 roc_auc 0.44000 prc_auc 0.61898[0m
[92maverage training of epoch 49: loss -10.16297 acc 0.66667 roc_auc 0.39850 prc_auc 0.59700[0m
[93maverage test of epoch 49: loss -10.20424 acc 0.65789 roc_auc 0.54923 prc_auc 0.69394[0m
[92maverage training of epoch 50: loss -10.32844 acc 0.66667 roc_auc 0.36670 prc_auc 0.56714[0m
[93maverage test of epoch 50: loss -10.36893 acc 0.65789 roc_auc 0.48154 prc_auc 0.67193[0m
[92maverage training of epoch 51: loss -10.49505 acc 0.66667 roc_auc 0.39410 prc_auc 0.59257[0m
[93maverage test of epoch 51: loss -10.53462 acc 0.65789 roc_auc 0.41846 prc_auc 0.60692[0m
[92maverage training of epoch 52: loss -10.66039 acc 0.66667 roc_auc 0.38790 prc_auc 0.59453[0m
[93maverage test of epoch 52: loss -10.69919 acc 0.65789 roc_auc 0.51231 prc_auc 0.66386[0m
[92maverage training of epoch 53: loss -10.82642 acc 0.66667 roc_auc 0.37350 prc_auc 0.58202[0m
[93maverage test of epoch 53: loss -10.86622 acc 0.65789 roc_auc 0.48308 prc_auc 0.64345[0m
[92maverage training of epoch 54: loss -10.99272 acc 0.66667 roc_auc 0.39920 prc_auc 0.58590[0m
[93maverage test of epoch 54: loss -11.03132 acc 0.65789 roc_auc 0.54615 prc_auc 0.69671[0m
[92maverage training of epoch 55: loss -11.15853 acc 0.66667 roc_auc 0.37480 prc_auc 0.58039[0m
[93maverage test of epoch 55: loss -11.19693 acc 0.65789 roc_auc 0.48000 prc_auc 0.64017[0m
[92maverage training of epoch 56: loss -11.32482 acc 0.66667 roc_auc 0.37950 prc_auc 0.58233[0m
[93maverage test of epoch 56: loss -11.36244 acc 0.65789 roc_auc 0.64000 prc_auc 0.72486[0m
[92maverage training of epoch 57: loss -11.49022 acc 0.66667 roc_auc 0.36630 prc_auc 0.57002[0m
[93maverage test of epoch 57: loss -11.52846 acc 0.65789 roc_auc 0.43231 prc_auc 0.62607[0m
[92maverage training of epoch 58: loss -11.65658 acc 0.66667 roc_auc 0.37400 prc_auc 0.56973[0m
[93maverage test of epoch 58: loss -11.69295 acc 0.65789 roc_auc 0.45538 prc_auc 0.66618[0m
[92maverage training of epoch 59: loss -11.82229 acc 0.66667 roc_auc 0.39020 prc_auc 0.58483[0m
[93maverage test of epoch 59: loss -11.85822 acc 0.65789 roc_auc 0.42923 prc_auc 0.60423[0m
[92maverage training of epoch 60: loss -11.98834 acc 0.66667 roc_auc 0.38420 prc_auc 0.58181[0m
[93maverage test of epoch 60: loss -12.02356 acc 0.65789 roc_auc 0.62769 prc_auc 0.74453[0m
[92maverage training of epoch 61: loss -12.15409 acc 0.66667 roc_auc 0.38170 prc_auc 0.57945[0m
[93maverage test of epoch 61: loss -12.18951 acc 0.65789 roc_auc 0.54923 prc_auc 0.70427[0m
[92maverage training of epoch 62: loss -12.32018 acc 0.66667 roc_auc 0.38100 prc_auc 0.58290[0m
[93maverage test of epoch 62: loss -12.35446 acc 0.65789 roc_auc 0.44615 prc_auc 0.64645[0m
[92maverage training of epoch 63: loss -12.48601 acc 0.66667 roc_auc 0.37100 prc_auc 0.57013[0m
[93maverage test of epoch 63: loss -12.52059 acc 0.65789 roc_auc 0.55692 prc_auc 0.68088[0m
[92maverage training of epoch 64: loss -12.65196 acc 0.66667 roc_auc 0.37670 prc_auc 0.57762[0m
[93maverage test of epoch 64: loss -12.68561 acc 0.65789 roc_auc 0.40615 prc_auc 0.60954[0m
[92maverage training of epoch 65: loss -12.81772 acc 0.66667 roc_auc 0.38110 prc_auc 0.57887[0m
[93maverage test of epoch 65: loss -12.85075 acc 0.65789 roc_auc 0.37846 prc_auc 0.60205[0m
[92maverage training of epoch 66: loss -12.98358 acc 0.66667 roc_auc 0.37910 prc_auc 0.57495[0m
[93maverage test of epoch 66: loss -13.01628 acc 0.65789 roc_auc 0.28154 prc_auc 0.55627[0m
[92maverage training of epoch 67: loss -13.14935 acc 0.66667 roc_auc 0.38140 prc_auc 0.57510[0m
[93maverage test of epoch 67: loss -13.18115 acc 0.65789 roc_auc 0.58308 prc_auc 0.72290[0m
[92maverage training of epoch 68: loss -13.31491 acc 0.66667 roc_auc 0.37530 prc_auc 0.57428[0m
[93maverage test of epoch 68: loss -13.34712 acc 0.65789 roc_auc 0.51077 prc_auc 0.65617[0m
[92maverage training of epoch 69: loss -13.48085 acc 0.66667 roc_auc 0.38580 prc_auc 0.58612[0m
[93maverage test of epoch 69: loss -13.51151 acc 0.65789 roc_auc 0.43692 prc_auc 0.62624[0m
[92maverage training of epoch 70: loss -13.64651 acc 0.66667 roc_auc 0.37880 prc_auc 0.57617[0m
[93maverage test of epoch 70: loss -13.67736 acc 0.65789 roc_auc 0.50154 prc_auc 0.65750[0m
[92maverage training of epoch 71: loss -13.81237 acc 0.66667 roc_auc 0.38320 prc_auc 0.58695[0m
[93maverage test of epoch 71: loss -13.84299 acc 0.65789 roc_auc 0.58462 prc_auc 0.72695[0m
[92maverage training of epoch 72: loss -13.97809 acc 0.66667 roc_auc 0.38010 prc_auc 0.57982[0m
[93maverage test of epoch 72: loss -14.00795 acc 0.65789 roc_auc 0.52615 prc_auc 0.70857[0m
[92maverage training of epoch 73: loss -14.14388 acc 0.66667 roc_auc 0.37200 prc_auc 0.57417[0m
[93maverage test of epoch 73: loss -14.17337 acc 0.65789 roc_auc 0.50769 prc_auc 0.67815[0m
[92maverage training of epoch 74: loss -14.30963 acc 0.66667 roc_auc 0.38190 prc_auc 0.57649[0m
[93maverage test of epoch 74: loss -14.33852 acc 0.65789 roc_auc 0.43846 prc_auc 0.62922[0m
[92maverage training of epoch 75: loss -14.47537 acc 0.66667 roc_auc 0.38060 prc_auc 0.57457[0m
[93maverage test of epoch 75: loss -14.50377 acc 0.65789 roc_auc 0.36308 prc_auc 0.58650[0m
[92maverage training of epoch 76: loss -14.64120 acc 0.66667 roc_auc 0.37040 prc_auc 0.56853[0m
[93maverage test of epoch 76: loss -14.66941 acc 0.65789 roc_auc 0.63077 prc_auc 0.76021[0m
[92maverage training of epoch 77: loss -14.80699 acc 0.66667 roc_auc 0.37720 prc_auc 0.57557[0m
[93maverage test of epoch 77: loss -14.83469 acc 0.65789 roc_auc 0.49846 prc_auc 0.66800[0m
[92maverage training of epoch 78: loss -14.97262 acc 0.66667 roc_auc 0.38220 prc_auc 0.58771[0m
[93maverage test of epoch 78: loss -14.99975 acc 0.65789 roc_auc 0.43077 prc_auc 0.64194[0m
[92maverage training of epoch 79: loss -15.13842 acc 0.66667 roc_auc 0.38290 prc_auc 0.58558[0m
[93maverage test of epoch 79: loss -15.16486 acc 0.65789 roc_auc 0.43846 prc_auc 0.62745[0m
[92maverage training of epoch 80: loss -15.30410 acc 0.66667 roc_auc 0.37520 prc_auc 0.58034[0m
[93maverage test of epoch 80: loss -15.33027 acc 0.65789 roc_auc 0.31231 prc_auc 0.58085[0m
[92maverage training of epoch 81: loss -15.47003 acc 0.66667 roc_auc 0.37880 prc_auc 0.57951[0m
[93maverage test of epoch 81: loss -15.49516 acc 0.65789 roc_auc 0.49231 prc_auc 0.65171[0m
[92maverage training of epoch 82: loss -15.63568 acc 0.66667 roc_auc 0.38380 prc_auc 0.58707[0m
[93maverage test of epoch 82: loss -15.66063 acc 0.65789 roc_auc 0.41846 prc_auc 0.61717[0m
[92maverage training of epoch 83: loss -15.80137 acc 0.66667 roc_auc 0.38150 prc_auc 0.57767[0m
[93maverage test of epoch 83: loss -15.82622 acc 0.65789 roc_auc 0.45077 prc_auc 0.63729[0m
[92maverage training of epoch 84: loss -15.96723 acc 0.66667 roc_auc 0.38010 prc_auc 0.57768[0m
[93maverage test of epoch 84: loss -15.99145 acc 0.65789 roc_auc 0.42462 prc_auc 0.62035[0m
[92maverage training of epoch 85: loss -16.13269 acc 0.66667 roc_auc 0.37220 prc_auc 0.57622[0m
[93maverage test of epoch 85: loss -16.15654 acc 0.65789 roc_auc 0.47692 prc_auc 0.64764[0m
[92maverage training of epoch 86: loss -16.29850 acc 0.66667 roc_auc 0.37840 prc_auc 0.57953[0m
[93maverage test of epoch 86: loss -16.32198 acc 0.65789 roc_auc 0.63846 prc_auc 0.72788[0m
[92maverage training of epoch 87: loss -16.46430 acc 0.66667 roc_auc 0.38540 prc_auc 0.57729[0m
[93maverage test of epoch 87: loss -16.48702 acc 0.65789 roc_auc 0.64462 prc_auc 0.74429[0m
[92maverage training of epoch 88: loss -16.62993 acc 0.66667 roc_auc 0.37530 prc_auc 0.58009[0m
[93maverage test of epoch 88: loss -16.65198 acc 0.65789 roc_auc 0.54308 prc_auc 0.68156[0m
[92maverage training of epoch 89: loss -16.79568 acc 0.66667 roc_auc 0.37670 prc_auc 0.57487[0m
[93maverage test of epoch 89: loss -16.81727 acc 0.65789 roc_auc 0.49846 prc_auc 0.66383[0m
[92maverage training of epoch 90: loss -16.96143 acc 0.66667 roc_auc 0.38050 prc_auc 0.57673[0m
[93maverage test of epoch 90: loss -16.98298 acc 0.65789 roc_auc 0.54769 prc_auc 0.68072[0m
[92maverage training of epoch 91: loss -17.12723 acc 0.66667 roc_auc 0.38040 prc_auc 0.57993[0m
[93maverage test of epoch 91: loss -17.14785 acc 0.65789 roc_auc 0.46462 prc_auc 0.64928[0m
[92maverage training of epoch 92: loss -17.29291 acc 0.66667 roc_auc 0.37950 prc_auc 0.57804[0m
[93maverage test of epoch 92: loss -17.31325 acc 0.65789 roc_auc 0.38000 prc_auc 0.60308[0m
[92maverage training of epoch 93: loss -17.45854 acc 0.66667 roc_auc 0.38100 prc_auc 0.58686[0m
[93maverage test of epoch 93: loss -17.47833 acc 0.65789 roc_auc 0.52308 prc_auc 0.66932[0m
[92maverage training of epoch 94: loss -17.62433 acc 0.66667 roc_auc 0.37810 prc_auc 0.57513[0m
[93maverage test of epoch 94: loss -17.64385 acc 0.65789 roc_auc 0.61385 prc_auc 0.71866[0m
[92maverage training of epoch 95: loss -17.78992 acc 0.66667 roc_auc 0.37680 prc_auc 0.57459[0m
[93maverage test of epoch 95: loss -17.80904 acc 0.65789 roc_auc 0.36308 prc_auc 0.61558[0m
[92maverage training of epoch 96: loss -17.95573 acc 0.66667 roc_auc 0.37990 prc_auc 0.58316[0m
[93maverage test of epoch 96: loss -17.97438 acc 0.65789 roc_auc 0.37077 prc_auc 0.60563[0m
[92maverage training of epoch 97: loss -18.12146 acc 0.66667 roc_auc 0.38260 prc_auc 0.58141[0m
[93maverage test of epoch 97: loss -18.13952 acc 0.65789 roc_auc 0.48769 prc_auc 0.65104[0m
[92maverage training of epoch 98: loss -18.28718 acc 0.66667 roc_auc 0.37950 prc_auc 0.57729[0m
[93maverage test of epoch 98: loss -18.30465 acc 0.65789 roc_auc 0.44308 prc_auc 0.63240[0m
[92maverage training of epoch 99: loss -18.45278 acc 0.66667 roc_auc 0.37890 prc_auc 0.57581[0m
[93maverage test of epoch 99: loss -18.46999 acc 0.65789 roc_auc 0.56000 prc_auc 0.68608[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss 0.48818 acc 0.60927 roc_auc 0.36333 prc_auc 0.60455[0m
[93maverage test of epoch 0: loss 0.39581 acc 0.64865 roc_auc 0.34667 prc_auc 0.58290[0m
[92maverage training of epoch 1: loss 0.29082 acc 0.65563 roc_auc 0.40608 prc_auc 0.62186[0m
[93maverage test of epoch 1: loss 0.21037 acc 0.67568 roc_auc 0.36667 prc_auc 0.60873[0m
[92maverage training of epoch 2: loss 0.13711 acc 0.65563 roc_auc 0.40137 prc_auc 0.59221[0m
[93maverage test of epoch 2: loss 0.01526 acc 0.67568 roc_auc 0.34667 prc_auc 0.57136[0m
[92maverage training of epoch 3: loss -0.08236 acc 0.66225 roc_auc 0.44118 prc_auc 0.62787[0m
[93maverage test of epoch 3: loss -0.27127 acc 0.67568 roc_auc 0.51667 prc_auc 0.72187[0m
[92maverage training of epoch 4: loss -0.40261 acc 0.66225 roc_auc 0.42529 prc_auc 0.63093[0m
[93maverage test of epoch 4: loss -0.66739 acc 0.67568 roc_auc 0.46667 prc_auc 0.68179[0m
[92maverage training of epoch 5: loss -0.89167 acc 0.66225 roc_auc 0.47569 prc_auc 0.67189[0m
[93maverage test of epoch 5: loss -1.19140 acc 0.67568 roc_auc 0.42667 prc_auc 0.61280[0m
[92maverage training of epoch 6: loss -1.29606 acc 0.66225 roc_auc 0.46157 prc_auc 0.66277[0m
[93maverage test of epoch 6: loss -1.56473 acc 0.67568 roc_auc 0.39667 prc_auc 0.60451[0m
[92maverage training of epoch 7: loss -1.63922 acc 0.66225 roc_auc 0.47471 prc_auc 0.61886[0m
[93maverage test of epoch 7: loss -1.82822 acc 0.67568 roc_auc 0.48000 prc_auc 0.75008[0m
[92maverage training of epoch 8: loss -1.89688 acc 0.66225 roc_auc 0.42922 prc_auc 0.62265[0m
[93maverage test of epoch 8: loss -2.10154 acc 0.67568 roc_auc 0.59333 prc_auc 0.80643[0m
[92maverage training of epoch 9: loss -2.14904 acc 0.66225 roc_auc 0.56608 prc_auc 0.72759[0m
[93maverage test of epoch 9: loss -2.28947 acc 0.67568 roc_auc 0.37667 prc_auc 0.68065[0m
[92maverage training of epoch 10: loss -2.34704 acc 0.66225 roc_auc 0.47588 prc_auc 0.63747[0m
[93maverage test of epoch 10: loss -2.53405 acc 0.67568 roc_auc 0.42833 prc_auc 0.70213[0m
[92maverage training of epoch 11: loss -2.54340 acc 0.66225 roc_auc 0.45971 prc_auc 0.64455[0m
[93maverage test of epoch 11: loss -2.73798 acc 0.67568 roc_auc 0.52833 prc_auc 0.77262[0m
[92maverage training of epoch 12: loss -2.76733 acc 0.66225 roc_auc 0.58814 prc_auc 0.75031[0m
[93maverage test of epoch 12: loss -2.94625 acc 0.67568 roc_auc 0.53333 prc_auc 0.76286[0m
[92maverage training of epoch 13: loss -3.01676 acc 0.66225 roc_auc 0.54137 prc_auc 0.73793[0m
[93maverage test of epoch 13: loss -3.24185 acc 0.67568 roc_auc 0.53000 prc_auc 0.73389[0m
[92maverage training of epoch 14: loss -3.40763 acc 0.66225 roc_auc 0.69598 prc_auc 0.83921[0m
[93maverage test of epoch 14: loss -3.73448 acc 0.67568 roc_auc 0.74667 prc_auc 0.86891[0m
[92maverage training of epoch 15: loss -3.74691 acc 0.66225 roc_auc 0.72431 prc_auc 0.83679[0m
[93maverage test of epoch 15: loss -4.07152 acc 0.67568 roc_auc 0.76333 prc_auc 0.88148[0m
[92maverage training of epoch 16: loss -4.10736 acc 0.66225 roc_auc 0.83157 prc_auc 0.87825[0m
[93maverage test of epoch 16: loss -4.32425 acc 0.67568 roc_auc 0.78333 prc_auc 0.85965[0m
[92maverage training of epoch 17: loss -4.33922 acc 0.66887 roc_auc 0.85784 prc_auc 0.92838[0m
[93maverage test of epoch 17: loss -4.53720 acc 0.67568 roc_auc 0.89000 prc_auc 0.94478[0m
[92maverage training of epoch 18: loss -4.62720 acc 0.66887 roc_auc 0.86990 prc_auc 0.90512[0m
[93maverage test of epoch 18: loss -4.87294 acc 0.67568 roc_auc 0.92000 prc_auc 0.95580[0m
[92maverage training of epoch 19: loss -4.76962 acc 0.70861 roc_auc 0.88059 prc_auc 0.93649[0m
[93maverage test of epoch 19: loss -4.99857 acc 0.70270 roc_auc 0.92000 prc_auc 0.96290[0m
[92maverage training of epoch 20: loss -5.03449 acc 0.75497 roc_auc 0.89137 prc_auc 0.92584[0m
[93maverage test of epoch 20: loss -5.04388 acc 0.67568 roc_auc 0.79000 prc_auc 0.82876[0m
[92maverage training of epoch 21: loss -5.14968 acc 0.77483 roc_auc 0.86490 prc_auc 0.88612[0m
[93maverage test of epoch 21: loss -5.30492 acc 0.75676 roc_auc 0.83000 prc_auc 0.90629[0m
[92maverage training of epoch 22: loss -5.32626 acc 0.78146 roc_auc 0.87039 prc_auc 0.90841[0m
[93maverage test of epoch 22: loss -5.53896 acc 0.75676 roc_auc 0.86000 prc_auc 0.91862[0m
[92maverage training of epoch 23: loss -5.51624 acc 0.80132 roc_auc 0.86186 prc_auc 0.88335[0m
[93maverage test of epoch 23: loss -5.54116 acc 0.70270 roc_auc 0.80333 prc_auc 0.86503[0m
[92maverage training of epoch 24: loss -5.60946 acc 0.79470 roc_auc 0.85941 prc_auc 0.88446[0m
[93maverage test of epoch 24: loss -5.81633 acc 0.70270 roc_auc 0.85000 prc_auc 0.92360[0m
[92maverage training of epoch 25: loss -5.82418 acc 0.78146 roc_auc 0.87784 prc_auc 0.91392[0m
[93maverage test of epoch 25: loss -5.96255 acc 0.78378 roc_auc 0.85333 prc_auc 0.91330[0m
[92maverage training of epoch 26: loss -5.98812 acc 0.77483 roc_auc 0.87000 prc_auc 0.89335[0m
[93maverage test of epoch 26: loss -6.14477 acc 0.81081 roc_auc 0.85000 prc_auc 0.90285[0m
[92maverage training of epoch 27: loss -6.09665 acc 0.79470 roc_auc 0.87137 prc_auc 0.89855[0m
[93maverage test of epoch 27: loss -6.21471 acc 0.70270 roc_auc 0.86667 prc_auc 0.93328[0m
[92maverage training of epoch 28: loss -6.28500 acc 0.76821 roc_auc 0.88755 prc_auc 0.92935[0m
[93maverage test of epoch 28: loss -6.47491 acc 0.72973 roc_auc 0.89000 prc_auc 0.94964[0m
[92maverage training of epoch 29: loss -6.49496 acc 0.80132 roc_auc 0.89088 prc_auc 0.92873[0m
[93maverage test of epoch 29: loss -6.54392 acc 0.70270 roc_auc 0.80833 prc_auc 0.87908[0m
[92maverage training of epoch 30: loss -6.65553 acc 0.80132 roc_auc 0.87422 prc_auc 0.91220[0m
[93maverage test of epoch 30: loss -6.77432 acc 0.75676 roc_auc 0.90333 prc_auc 0.95453[0m
[92maverage training of epoch 31: loss -6.79246 acc 0.77483 roc_auc 0.84676 prc_auc 0.87649[0m
[93maverage test of epoch 31: loss -7.06158 acc 0.78378 roc_auc 0.86500 prc_auc 0.89326[0m
[92maverage training of epoch 32: loss -6.97085 acc 0.79470 roc_auc 0.88755 prc_auc 0.91329[0m
[93maverage test of epoch 32: loss -7.05462 acc 0.67568 roc_auc 0.80000 prc_auc 0.84095[0m
[92maverage training of epoch 33: loss -7.08671 acc 0.82119 roc_auc 0.88098 prc_auc 0.91221[0m
[93maverage test of epoch 33: loss -7.25210 acc 0.75676 roc_auc 0.86167 prc_auc 0.92140[0m
[92maverage training of epoch 34: loss -7.18654 acc 0.78808 roc_auc 0.87853 prc_auc 0.91104[0m
[93maverage test of epoch 34: loss -7.36754 acc 0.72973 roc_auc 0.85833 prc_auc 0.90091[0m
[92maverage training of epoch 35: loss -7.34809 acc 0.79470 roc_auc 0.87245 prc_auc 0.90901[0m
[93maverage test of epoch 35: loss -7.60509 acc 0.72973 roc_auc 0.86333 prc_auc 0.91627[0m
[92maverage training of epoch 36: loss -7.52560 acc 0.78808 roc_auc 0.88088 prc_auc 0.89330[0m
[93maverage test of epoch 36: loss -7.90099 acc 0.75676 roc_auc 0.92667 prc_auc 0.96012[0m
[92maverage training of epoch 37: loss -7.70412 acc 0.76821 roc_auc 0.87500 prc_auc 0.89512[0mUsing backend: pytorch

[93maverage test of epoch 37: loss -7.90365 acc 0.70270 roc_auc 0.88667 prc_auc 0.94505[0m
[92maverage training of epoch 38: loss -7.84861 acc 0.77483 roc_auc 0.87598 prc_auc 0.90197[0m
[93maverage test of epoch 38: loss -7.98049 acc 0.70270 roc_auc 0.84667 prc_auc 0.91192[0m
[92maverage training of epoch 39: loss -8.03578 acc 0.78808 roc_auc 0.89882 prc_auc 0.92567[0m
[93maverage test of epoch 39: loss -8.27396 acc 0.75676 roc_auc 0.92667 prc_auc 0.96844[0m
[92maverage training of epoch 40: loss -8.14290 acc 0.76159 roc_auc 0.87451 prc_auc 0.90381[0m
[93maverage test of epoch 40: loss -8.42902 acc 0.70270 roc_auc 0.87167 prc_auc 0.90546[0m
[92maverage training of epoch 41: loss -8.35551 acc 0.76821 roc_auc 0.86088 prc_auc 0.87334[0m
[93maverage test of epoch 41: loss -8.61382 acc 0.67568 roc_auc 0.85167 prc_auc 0.87984[0m
[92maverage training of epoch 42: loss -8.52283 acc 0.75497 roc_auc 0.90186 prc_auc 0.93745[0m
[93maverage test of epoch 42: loss -8.69426 acc 0.70270 roc_auc 0.90167 prc_auc 0.94983[0m
[92maverage training of epoch 43: loss -8.62020 acc 0.75497 roc_auc 0.88186 prc_auc 0.89394[0m
[93maverage test of epoch 43: loss -8.90290 acc 0.70270 roc_auc 0.90333 prc_auc 0.95178[0m
[92maverage training of epoch 44: loss -8.86022 acc 0.76821 roc_auc 0.90657 prc_auc 0.93628[0m
[93maverage test of epoch 44: loss -9.02276 acc 0.70270 roc_auc 0.88667 prc_auc 0.93514[0m
[92maverage training of epoch 45: loss -9.02629 acc 0.74172 roc_auc 0.89206 prc_auc 0.90417[0m
[93maverage test of epoch 45: loss -9.18881 acc 0.67568 roc_auc 0.86667 prc_auc 0.90871[0m
[92maverage training of epoch 46: loss -9.18288 acc 0.72185 roc_auc 0.86608 prc_auc 0.88729[0m
[93maverage test of epoch 46: loss -9.36845 acc 0.67568 roc_auc 0.88833 prc_auc 0.94028[0m
[92maverage training of epoch 47: loss -9.29394 acc 0.72848 roc_auc 0.87569 prc_auc 0.88824[0m
[93maverage test of epoch 47: loss -9.44904 acc 0.67568 roc_auc 0.82167 prc_auc 0.87353[0m
[92maverage training of epoch 48: loss -9.42851 acc 0.73510 roc_auc 0.87059 prc_auc 0.89885[0m
[93maverage test of epoch 48: loss -9.68505 acc 0.67568 roc_auc 0.88500 prc_auc 0.92595[0m
[92maverage training of epoch 49: loss -9.64585 acc 0.72185 roc_auc 0.90422 prc_auc 0.93099[0m
[93maverage test of epoch 49: loss -9.73806 acc 0.67568 roc_auc 0.87333 prc_auc 0.92062[0m
[92maverage training of epoch 50: loss -9.81068 acc 0.70861 roc_auc 0.89382 prc_auc 0.92108[0m
[93maverage test of epoch 50: loss -9.98647 acc 0.67568 roc_auc 0.91500 prc_auc 0.96002[0m
[92maverage training of epoch 51: loss -9.93565 acc 0.70199 roc_auc 0.86667 prc_auc 0.89254[0m
[93maverage test of epoch 51: loss -10.19089 acc 0.67568 roc_auc 0.86333 prc_auc 0.90951[0m
[92maverage training of epoch 52: loss -10.07731 acc 0.68874 roc_auc 0.87627 prc_auc 0.90452[0m
[93maverage test of epoch 52: loss -10.19307 acc 0.67568 roc_auc 0.84333 prc_auc 0.86905[0m
[92maverage training of epoch 53: loss -10.25503 acc 0.66887 roc_auc 0.90618 prc_auc 0.92327[0m
[93maverage test of epoch 53: loss -10.53487 acc 0.67568 roc_auc 0.90667 prc_auc 0.93035[0m
[92maverage training of epoch 54: loss -10.42283 acc 0.66225 roc_auc 0.88529 prc_auc 0.90858[0m
[93maverage test of epoch 54: loss -10.54995 acc 0.67568 roc_auc 0.85833 prc_auc 0.91059[0m
[92maverage training of epoch 55: loss -10.58825 acc 0.67550 roc_auc 0.89725 prc_auc 0.92855[0m
[93maverage test of epoch 55: loss -10.71785 acc 0.67568 roc_auc 0.92500 prc_auc 0.96498[0m
[92maverage training of epoch 56: loss -10.73179 acc 0.66225 roc_auc 0.88559 prc_auc 0.90214[0m
[93maverage test of epoch 56: loss -10.94960 acc 0.67568 roc_auc 0.87500 prc_auc 0.90877[0m
[92maverage training of epoch 57: loss -10.94445 acc 0.66225 roc_auc 0.88608 prc_auc 0.89695[0m
[93maverage test of epoch 57: loss -11.06134 acc 0.67568 roc_auc 0.88667 prc_auc 0.93302[0m
[92maverage training of epoch 58: loss -11.07268 acc 0.66225 roc_auc 0.89275 prc_auc 0.91583[0m
[93maverage test of epoch 58: loss -11.24266 acc 0.67568 roc_auc 0.88000 prc_auc 0.91591[0m
[92maverage training of epoch 59: loss -11.21520 acc 0.66225 roc_auc 0.88971 prc_auc 0.91470[0m
[93maverage test of epoch 59: loss -11.39425 acc 0.67568 roc_auc 0.93000 prc_auc 0.96517[0m
[92maverage training of epoch 60: loss -11.41564 acc 0.66225 roc_auc 0.88882 prc_auc 0.90049[0m
[93maverage test of epoch 60: loss -11.58172 acc 0.67568 roc_auc 0.84667 prc_auc 0.87359[0m
[92maverage training of epoch 61: loss -11.50287 acc 0.66225 roc_auc 0.87765 prc_auc 0.88756[0m
[93maverage test of epoch 61: loss -11.69121 acc 0.67568 roc_auc 0.87667 prc_auc 0.91468[0m
[92maverage training of epoch 62: loss -11.69450 acc 0.66887 roc_auc 0.89118 prc_auc 0.91409[0m
[93maverage test of epoch 62: loss -11.86706 acc 0.67568 roc_auc 0.83667 prc_auc 0.86497[0m
[92maverage training of epoch 63: loss -11.82752 acc 0.66225 roc_auc 0.88578 prc_auc 0.90471[0m
[93maverage test of epoch 63: loss -11.96592 acc 0.67568 roc_auc 0.87000 prc_auc 0.90921[0m
[92maverage training of epoch 64: loss -11.96388 acc 0.66225 roc_auc 0.88157 prc_auc 0.90683[0m
[93maverage test of epoch 64: loss -12.11757 acc 0.67568 roc_auc 0.81833 prc_auc 0.86187[0m
[92maverage training of epoch 65: loss -12.12598 acc 0.66225 roc_auc 0.88343 prc_auc 0.90410[0m
[93maverage test of epoch 65: loss -12.31384 acc 0.67568 roc_auc 0.85333 prc_auc 0.88316[0m
[92maverage training of epoch 66: loss -12.32013 acc 0.66225 roc_auc 0.88392 prc_auc 0.90088[0m
[93maverage test of epoch 66: loss -12.42218 acc 0.67568 roc_auc 0.84333 prc_auc 0.88256[0m
[92maverage training of epoch 67: loss -12.46196 acc 0.66225 roc_auc 0.88647 prc_auc 0.90140[0m
[93maverage test of epoch 67: loss -12.64550 acc 0.67568 roc_auc 0.88167 prc_auc 0.90949[0m
[92maverage training of epoch 68: loss -12.56981 acc 0.66225 roc_auc 0.89186 prc_auc 0.90970[0m
[93maverage test of epoch 68: loss -12.60649 acc 0.67568 roc_auc 0.88667 prc_auc 0.91751[0m
[92maverage training of epoch 69: loss -12.73576 acc 0.66225 roc_auc 0.87971 prc_auc 0.89322[0m
[93maverage test of epoch 69: loss -13.03782 acc 0.67568 roc_auc 0.86667 prc_auc 0.88698[0m
[92maverage training of epoch 70: loss -12.89680 acc 0.66225 roc_auc 0.90324 prc_auc 0.92202[0m
[93maverage test of epoch 70: loss -12.92823 acc 0.67568 roc_auc 0.88333 prc_auc 0.91844[0m
[92maverage training of epoch 71: loss -13.06387 acc 0.66225 roc_auc 0.89755 prc_auc 0.91320[0m
[93maverage test of epoch 71: loss -13.27065 acc 0.67568 roc_auc 0.85333 prc_auc 0.87417[0m
[92maverage training of epoch 72: loss -13.22493 acc 0.66225 roc_auc 0.89627 prc_auc 0.91936[0m
[93maverage test of epoch 72: loss -13.44434 acc 0.67568 roc_auc 0.86000 prc_auc 0.88535[0m
[92maverage training of epoch 73: loss -13.40603 acc 0.66225 roc_auc 0.89529 prc_auc 0.90744[0m
[93maverage test of epoch 73: loss -13.49764 acc 0.67568 roc_auc 0.86000 prc_auc 0.88940[0m
[92maverage training of epoch 74: loss -13.55303 acc 0.66225 roc_auc 0.89441 prc_auc 0.91286[0m
[93maverage test of epoch 74: loss -13.72717 acc 0.67568 roc_auc 0.86333 prc_auc 0.88796[0m
[92maverage training of epoch 75: loss -13.72738 acc 0.66225 roc_auc 0.89010 prc_auc 0.90867[0m
[93maverage test of epoch 75: loss -13.85974 acc 0.67568 roc_auc 0.86667 prc_auc 0.89036[0m
[92maverage training of epoch 76: loss -13.91020 acc 0.66225 roc_auc 0.89353 prc_auc 0.90122[0m
[93maverage test of epoch 76: loss -14.00619 acc 0.67568 roc_auc 0.87333 prc_auc 0.89735[0m
[92maverage training of epoch 77: loss -13.94987 acc 0.66225 roc_auc 0.87716 prc_auc 0.88974[0m
[93maverage test of epoch 77: loss -14.07809 acc 0.67568 roc_auc 0.89667 prc_auc 0.92853[0m
[92maverage training of epoch 78: loss -14.18479 acc 0.66225 roc_auc 0.91255 prc_auc 0.94153[0m
[93maverage test of epoch 78: loss -14.39952 acc 0.67568 roc_auc 0.88333 prc_auc 0.90274[0m
[92maverage training of epoch 79: loss -14.36098 acc 0.66225 roc_auc 0.90118 prc_auc 0.91987[0m
[93maverage test of epoch 79: loss -14.47976 acc 0.67568 roc_auc 0.87000 prc_auc 0.89545[0m
[92maverage training of epoch 80: loss -14.43008 acc 0.66225 roc_auc 0.89353 prc_auc 0.91948[0m
[93maverage test of epoch 80: loss -14.65111 acc 0.67568 roc_auc 0.85333 prc_auc 0.88437[0m
[92maverage training of epoch 81: loss -14.58099 acc 0.66225 roc_auc 0.87804 prc_auc 0.89796[0m
[93maverage test of epoch 81: loss -14.73343 acc 0.67568 roc_auc 0.86500 prc_auc 0.89948[0m
[92maverage training of epoch 82: loss -14.84223 acc 0.66225 roc_auc 0.90039 prc_auc 0.90693[0m
[93maverage test of epoch 82: loss -14.98983 acc 0.67568 roc_auc 0.87333 prc_auc 0.89834[0m
[92maverage training of epoch 83: loss -14.96656 acc 0.66225 roc_auc 0.88686 prc_auc 0.89892[0m
[93maverage test of epoch 83: loss -14.80969 acc 0.67568 roc_auc 0.87000 prc_auc 0.90262[0m
[92maverage training of epoch 84: loss -15.11464 acc 0.66225 roc_auc 0.89127 prc_auc 0.90918[0m
[93maverage test of epoch 84: loss -15.33909 acc 0.67568 roc_auc 0.87667 prc_auc 0.89872[0m
[92maverage training of epoch 85: loss -15.25128 acc 0.66225 roc_auc 0.90559 prc_auc 0.92345[0m
[93maverage test of epoch 85: loss -15.30881 acc 0.67568 roc_auc 0.87667 prc_auc 0.90017[0m
[92maverage training of epoch 86: loss -15.37251 acc 0.66225 roc_auc 0.88745 prc_auc 0.90279[0m
[93maverage test of epoch 86: loss -15.64699 acc 0.67568 roc_auc 0.83000 prc_auc 0.86176[0m
[92maverage training of epoch 87: loss -15.57568 acc 0.66225 roc_auc 0.88490 prc_auc 0.89733[0m
[93maverage test of epoch 87: loss -15.76151 acc 0.67568 roc_auc 0.88667 prc_auc 0.90423[0m
[92maverage training of epoch 88: loss -15.75352 acc 0.66225 roc_auc 0.89745 prc_auc 0.91312[0m
[93maverage test of epoch 88: loss -15.77245 acc 0.67568 roc_auc 0.84000 prc_auc 0.88349[0m
[92maverage training of epoch 89: loss -15.88585 acc 0.66225 roc_auc 0.91833 prc_auc 0.94196[0m
[93maverage test of epoch 89: loss -16.03329 acc 0.67568 roc_auc 0.87000 prc_auc 0.89096[0m
[92maverage training of epoch 90: loss -16.01834 acc 0.66225 roc_auc 0.91108 prc_auc 0.93295[0m
[93maverage test of epoch 90: loss -16.03935 acc 0.67568 roc_auc 0.87667 prc_auc 0.89986[0m
[92maverage training of epoch 91: loss -16.29407 acc 0.66225 roc_auc 0.93863 prc_auc 0.95513[0m
[93maverage test of epoch 91: loss -16.21222 acc 0.67568 roc_auc 0.85333 prc_auc 0.88544[0m
[92maverage training of epoch 92: loss -16.37179 acc 0.66225 roc_auc 0.91343 prc_auc 0.93120[0m
[93maverage test of epoch 92: loss -16.39208 acc 0.67568 roc_auc 0.86333 prc_auc 0.89599[0m
[92maverage training of epoch 93: loss -16.51304 acc 0.66225 roc_auc 0.90843 prc_auc 0.92644[0m
[93maverage test of epoch 93: loss -16.64055 acc 0.67568 roc_auc 0.87667 prc_auc 0.90228[0m
[92maverage training of epoch 94: loss -16.71051 acc 0.66225 roc_auc 0.89882 prc_auc 0.91721[0m
[93maverage test of epoch 94: loss -16.73982 acc 0.67568 roc_auc 0.87667 prc_auc 0.89741[0m
[92maverage training of epoch 95: loss -16.78106 acc 0.66225 roc_auc 0.90775 prc_auc 0.92967[0m
[93maverage test of epoch 95: loss -16.87181 acc 0.67568 roc_auc 0.87000 prc_auc 0.89355[0m
[92maverage training of epoch 96: loss -17.02036 acc 0.66225 roc_auc 0.91657 prc_auc 0.93603[0m
[93maverage test of epoch 96: loss -16.99689 acc 0.67568 roc_auc 0.86667 prc_auc 0.89414[0m
[92maverage training of epoch 97: loss -17.12927 acc 0.66225 roc_auc 0.90255 prc_auc 0.92440[0m
[93maverage test of epoch 97: loss -17.15399 acc 0.67568 roc_auc 0.85167 prc_auc 0.88784[0m
[92maverage training of epoch 98: loss -17.30726 acc 0.66225 roc_auc 0.92510 prc_auc 0.94198[0m
[93maverage test of epoch 98: loss -17.60178 acc 0.67568 roc_auc 0.88167 prc_auc 0.90290[0m
[92maverage training of epoch 99: loss -17.48459 acc 0.66225 roc_auc 0.91833 prc_auc 0.93657[0m
[93maverage test of epoch 99: loss -17.39680 acc 0.67568 roc_auc 0.84667 prc_auc 0.89035[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.29621 acc 0.33775 roc_auc 0.40608 prc_auc 0.61998[0m
[93maverage test of epoch 0: loss -0.62157 acc 0.32432 roc_auc 0.57667 prc_auc 0.74355[0m
[92maverage training of epoch 1: loss -0.96884 acc 0.44371 roc_auc 0.44353 prc_auc 0.63949[0m
[93maverage test of epoch 1: loss -1.26876 acc 0.67568 roc_auc 0.57000 prc_auc 0.77692[0m
[92maverage training of epoch 2: loss -1.56602 acc 0.66225 roc_auc 0.50784 prc_auc 0.69834[0m
[93maverage test of epoch 2: loss -1.87298 acc 0.67568 roc_auc 0.75333 prc_auc 0.88007[0m
[92maverage training of epoch 3: loss -2.03914 acc 0.66225 roc_auc 0.55176 prc_auc 0.75502[0m
[93maverage test of epoch 3: loss -2.23764 acc 0.67568 roc_auc 0.63667 prc_auc 0.83938[0m
[92maverage training of epoch 4: loss -2.36306 acc 0.66225 roc_auc 0.54647 prc_auc 0.71001[0m
[93maverage test of epoch 4: loss -2.52975 acc 0.67568 roc_auc 0.59000 prc_auc 0.75068[0m
[92maverage training of epoch 5: loss -2.63519 acc 0.66225 roc_auc 0.49490 prc_auc 0.67381[0m
[93maverage test of epoch 5: loss -2.78990 acc 0.67568 roc_auc 0.51000 prc_auc 0.71450[0m
[92maverage training of epoch 6: loss -2.87550 acc 0.66225 roc_auc 0.55157 prc_auc 0.69090[0m
[93maverage test of epoch 6: loss -3.01194 acc 0.67568 roc_auc 0.40333 prc_auc 0.67678[0m
[92maverage training of epoch 7: loss -3.10247 acc 0.66225 roc_auc 0.56255 prc_auc 0.72950[0m
[93maverage test of epoch 7: loss -3.24506 acc 0.67568 roc_auc 0.38333 prc_auc 0.64565[0m
[92maverage training of epoch 8: loss -3.30421 acc 0.66225 roc_auc 0.41471 prc_auc 0.62091[0m
[93maverage test of epoch 8: loss -3.46003 acc 0.67568 roc_auc 0.68000 prc_auc 0.80569[0m
[92maverage training of epoch 9: loss -3.50460 acc 0.66225 roc_auc 0.41373 prc_auc 0.59730[0m
[93maverage test of epoch 9: loss -3.63351 acc 0.67568 roc_auc 0.52000 prc_auc 0.76487[0m
[92maverage training of epoch 10: loss -3.71195 acc 0.66225 roc_auc 0.52824 prc_auc 0.64281[0m
[93maverage test of epoch 10: loss -3.85294 acc 0.67568 roc_auc 0.56333 prc_auc 0.74267[0m
[92maverage training of epoch 11: loss -3.89884 acc 0.66225 roc_auc 0.42196 prc_auc 0.60564[0m
[93maverage test of epoch 11: loss -4.03633 acc 0.67568 roc_auc 0.59333 prc_auc 0.74800[0m
[92maverage training of epoch 12: loss -4.07907 acc 0.66225 roc_auc 0.40961 prc_auc 0.59415[0m
[93maverage test of epoch 12: loss -4.20783 acc 0.67568 roc_auc 0.45000 prc_auc 0.71301[0m
[92maverage training of epoch 13: loss -4.27143 acc 0.66225 roc_auc 0.40569 prc_auc 0.60680[0m
[93maverage test of epoch 13: loss -4.39717 acc 0.67568 roc_auc 0.54667 prc_auc 0.76169[0m
[92maverage training of epoch 14: loss -4.45197 acc 0.66225 roc_auc 0.46471 prc_auc 0.65717[0m
[93maverage test of epoch 14: loss -4.58770 acc 0.67568 roc_auc 0.50667 prc_auc 0.70368[0m
[92maverage training of epoch 15: loss -4.63080 acc 0.66225 roc_auc 0.40431 prc_auc 0.61264[0m
[93maverage test of epoch 15: loss -4.75623 acc 0.67568 roc_auc 0.47000 prc_auc 0.76624[0m
[92maverage training of epoch 16: loss -4.80927 acc 0.66225 roc_auc 0.49147 prc_auc 0.63230[0m
[93maverage test of epoch 16: loss -4.93357 acc 0.67568 roc_auc 0.60167 prc_auc 0.80653[0m
[92maverage training of epoch 17: loss -4.98219 acc 0.66225 roc_auc 0.39725 prc_auc 0.58023[0m
[93maverage test of epoch 17: loss -5.11181 acc 0.67568 roc_auc 0.73000 prc_auc 0.86897[0m
[92maverage training of epoch 18: loss -5.15691 acc 0.66225 roc_auc 0.40608 prc_auc 0.59138[0m
[93maverage test of epoch 18: loss -5.29202 acc 0.67568 roc_auc 0.51667 prc_auc 0.72417[0m
[92maverage training of epoch 19: loss -5.33191 acc 0.66225 roc_auc 0.42333 prc_auc 0.59425[0m
[93maverage test of epoch 19: loss -5.46358 acc 0.67568 roc_auc 0.59333 prc_auc 0.80129[0m
[92maverage training of epoch 20: loss -5.50306 acc 0.66225 roc_auc 0.33275 prc_auc 0.56233[0m
[93maverage test of epoch 20: loss -5.63298 acc 0.67568 roc_auc 0.39333 prc_auc 0.66383[0m
[92maverage training of epoch 21: loss -5.67562 acc 0.66225 roc_auc 0.39000 prc_auc 0.57980[0m
[93maverage test of epoch 21: loss -5.80774 acc 0.67568 roc_auc 0.65667 prc_auc 0.79211[0m
[92maverage training of epoch 22: loss -5.84803 acc 0.66225 roc_auc 0.41647 prc_auc 0.59714[0m
[93maverage test of epoch 22: loss -5.97782 acc 0.67568 roc_auc 0.56000 prc_auc 0.79816[0m
[92maverage training of epoch 23: loss -6.01886 acc 0.66225 roc_auc 0.40863 prc_auc 0.59447[0m
[93maverage test of epoch 23: loss -6.15019 acc 0.67568 roc_auc 0.55000 prc_auc 0.73103[0m
[92maverage training of epoch 24: loss -6.18953 acc 0.66225 roc_auc 0.42431 prc_auc 0.61428[0m
[93maverage test of epoch 24: loss -6.32368 acc 0.67568 roc_auc 0.46333 prc_auc 0.71796[0m
[92maverage training of epoch 25: loss -6.36159 acc 0.66225 roc_auc 0.39706 prc_auc 0.59177[0m
[93maverage test of epoch 25: loss -6.49383 acc 0.67568 roc_auc 0.56333 prc_auc 0.76701[0m
[92maverage training of epoch 26: loss -6.53110 acc 0.66225 roc_auc 0.44069 prc_auc 0.60945[0m
[93maverage test of epoch 26: loss -6.66473 acc 0.67568 roc_auc 0.65500 prc_auc 0.84635[0m
[92maverage training of epoch 27: loss -6.69774 acc 0.66225 roc_auc 0.42294 prc_auc 0.61721[0m
[93maverage test of epoch 27: loss -6.83449 acc 0.67568 roc_auc 0.48833 prc_auc 0.71371[0m
[92maverage training of epoch 28: loss -6.86669 acc 0.66225 roc_auc 0.37225 prc_auc 0.58177[0m
[93maverage test of epoch 28: loss -6.99884 acc 0.67568 roc_auc 0.59333 prc_auc 0.75142[0m
[92maverage training of epoch 29: loss -7.03617 acc 0.66225 roc_auc 0.40186 prc_auc 0.59492[0m
[93maverage test of epoch 29: loss -7.16953 acc 0.67568 roc_auc 0.41000 prc_auc 0.69096[0m
[92maverage training of epoch 30: loss -7.20424 acc 0.66225 roc_auc 0.38647 prc_auc 0.58604[0m
[93maverage test of epoch 30: loss -7.34216 acc 0.67568 roc_auc 0.50500 prc_auc 0.71045[0m
[92maverage training of epoch 31: loss -7.37262 acc 0.66225 roc_auc 0.36235 prc_auc 0.56706[0m
[93maverage test of epoch 31: loss -7.50990 acc 0.67568 roc_auc 0.48667 prc_auc 0.74812[0m
[92maverage training of epoch 32: loss -7.54229 acc 0.66225 roc_auc 0.40569 prc_auc 0.60843[0m
[93maverage test of epoch 32: loss -7.67985 acc 0.67568 roc_auc 0.57333 prc_auc 0.70758[0m
[92maverage training of epoch 33: loss -7.70912 acc 0.66225 roc_auc 0.41392 prc_auc 0.61516[0m
[93maverage test of epoch 33: loss -7.84524 acc 0.67568 roc_auc 0.53667 prc_auc 0.76589[0m
[92maverage training of epoch 34: loss -7.87726 acc 0.66225 roc_auc 0.37216 prc_auc 0.58387[0m
[93maverage test of epoch 34: loss -8.01440 acc 0.67568 roc_auc 0.49000 prc_auc 0.74356[0m
[92maverage training of epoch 35: loss -8.04433 acc 0.66225 roc_auc 0.37765 prc_auc 0.58103[0m
[93maverage test of epoch 35: loss -8.18212 acc 0.67568 roc_auc 0.64167 prc_auc 0.78697[0m
[92maverage training of epoch 36: loss -8.21288 acc 0.66225 roc_auc 0.37049 prc_auc 0.57235[0m
[93maverage test of epoch 36: loss -8.35523 acc 0.67568 roc_auc 0.47500 prc_auc 0.69762[0m
[92maverage training of epoch 37: loss -8.37957 acc 0.66225 roc_auc 0.35000 prc_auc 0.56722[0m
[93maverage test of epoch 37: loss -8.52061 acc 0.67568 roc_auc 0.59833 prc_auc 0.76887[0m
[92maverage training of epoch 38: loss -8.54699 acc 0.66225 roc_auc 0.38647 prc_auc 0.57762[0m
[93maverage test of epoch 38: loss -8.69053 acc 0.67568 roc_auc 0.61333 prc_auc 0.79610[0m
[92maverage training of epoch 39: loss -8.71531 acc 0.66225 roc_auc 0.39304 prc_auc 0.58076[0m
[93maverage test of epoch 39: loss -8.85806 acc 0.67568 roc_auc 0.54000 prc_auc 0.74766[0m
[92maverage training of epoch 40: loss -8.88278 acc 0.66225 roc_auc 0.38294 prc_auc 0.58052[0m
[93maverage test of epoch 40: loss -9.02633 acc 0.67568 roc_auc 0.50000 prc_auc 0.68279[0m
[92maverage training of epoch 41: loss -9.04877 acc 0.66225 roc_auc 0.35118 prc_auc 0.56154[0m
[93maverage test of epoch 41: loss -9.19429 acc 0.67568 roc_auc 0.56333 prc_auc 0.71759[0m
[92maverage training of epoch 42: loss -9.21661 acc 0.66225 roc_auc 0.40627 prc_auc 0.58115[0m
[93maverage test of epoch 42: loss -9.36095 acc 0.67568 roc_auc 0.48167 prc_auc 0.66862[0m
[92maverage training of epoch 43: loss -9.38321 acc 0.66225 roc_auc 0.38039 prc_auc 0.57107[0m
[93maverage test of epoch 43: loss -9.52793 acc 0.67568 roc_auc 0.41667 prc_auc 0.64504[0m
[92maverage training of epoch 44: loss -9.55045 acc 0.66225 roc_auc 0.38324 prc_auc 0.57907[0m
[93maverage test of epoch 44: loss -9.69764 acc 0.67568 roc_auc 0.64500 prc_auc 0.75813[0m
[92maverage training of epoch 45: loss -9.71728 acc 0.66225 roc_auc 0.37088 prc_auc 0.57896[0m
[93maverage test of epoch 45: loss -9.86473 acc 0.67568 roc_auc 0.58167 prc_auc 0.74117[0m
[92maverage training of epoch 46: loss -9.88443 acc 0.66225 roc_auc 0.37647 prc_auc 0.57243[0m
[93maverage test of epoch 46: loss -10.03110 acc 0.67568 roc_auc 0.68167 prc_auc 0.78911[0m
[92maverage training of epoch 47: loss -10.05139 acc 0.66225 roc_auc 0.36010 prc_auc 0.56579[0m
[93maverage test of epoch 47: loss -10.20030 acc 0.67568 roc_auc 0.51833 prc_auc 0.69095[0m
[92maverage training of epoch 48: loss -10.21796 acc 0.66225 roc_auc 0.38216 prc_auc 0.57451[0m
[93maverage test of epoch 48: loss -10.36646 acc 0.67568 roc_auc 0.44167 prc_auc 0.65667[0m
[92maverage training of epoch 49: loss -10.38432 acc 0.66225 roc_auc 0.38333 prc_auc 0.58251[0m
[93maverage test of epoch 49: loss -10.53443 acc 0.67568 roc_auc 0.45333 prc_auc 0.64676[0m
[92maverage training of epoch 50: loss -10.55178 acc 0.66225 roc_auc 0.36284 prc_auc 0.56219[0m
[93maverage test of epoch 50: loss -10.70219 acc 0.67568 roc_auc 0.51000 prc_auc 0.71707[0m
[92maverage training of epoch 51: loss -10.71863 acc 0.66225 roc_auc 0.35814 prc_auc 0.55858[0m
[93maverage test of epoch 51: loss -10.86879 acc 0.67568 roc_auc 0.59833 prc_auc 0.72896[0m
[92maverage training of epoch 52: loss -10.88527 acc 0.66225 roc_auc 0.36559 prc_auc 0.58265[0m
[93maverage test of epoch 52: loss -11.03640 acc 0.67568 roc_auc 0.35167 prc_auc 0.61934[0m
[92maverage training of epoch 53: loss -11.05234 acc 0.66225 roc_auc 0.37127 prc_auc 0.56672[0m
[93maverage test of epoch 53: loss -11.20299 acc 0.67568 roc_auc 0.49000 prc_auc 0.67752[0m
[92maverage training of epoch 54: loss -11.21831 acc 0.66225 roc_auc 0.37461 prc_auc 0.57217[0m
[93maverage test of epoch 54: loss -11.37151 acc 0.67568 roc_auc 0.59667 prc_auc 0.75411[0m
[92maverage training of epoch 55: loss -11.38497 acc 0.66225 roc_auc 0.37980 prc_auc 0.58154[0m
[93maverage test of epoch 55: loss -11.53984 acc 0.67568 roc_auc 0.31167 prc_auc 0.60588[0m
[92maverage training of epoch 56: loss -11.55173 acc 0.66225 roc_auc 0.36725 prc_auc 0.57155[0m
[93maverage test of epoch 56: loss -11.70573 acc 0.67568 roc_auc 0.52167 prc_auc 0.68178[0m
[92maverage training of epoch 57: loss -11.71907 acc 0.66225 roc_auc 0.36206 prc_auc 0.56725[0m
[93maverage test of epoch 57: loss -11.87271 acc 0.67568 roc_auc 0.27667 prc_auc 0.58152[0m
[92maverage training of epoch 58: loss -11.88569 acc 0.66225 roc_auc 0.37520 prc_auc 0.57715[0m
[93maverage test of epoch 58: loss -12.04166 acc 0.67568 roc_auc 0.64500 prc_auc 0.77805[0m
[92maverage training of epoch 59: loss -12.05150 acc 0.66225 roc_auc 0.37245 prc_auc 0.57004[0m
[93maverage test of epoch 59: loss -12.20822 acc 0.67568 roc_auc 0.35833 prc_auc 0.60597[0m
[92maverage training of epoch 60: loss -12.21866 acc 0.66225 roc_auc 0.37520 prc_auc 0.57566[0m
[93maverage test of epoch 60: loss -12.37552 acc 0.67568 roc_auc 0.44833 prc_auc 0.65450[0m
[92maverage training of epoch 61: loss -12.38551 acc 0.66225 roc_auc 0.36931 prc_auc 0.57301[0m
[93maverage test of epoch 61: loss -12.54360 acc 0.67568 roc_auc 0.64000 prc_auc 0.77538[0m
[92maverage training of epoch 62: loss -12.55199 acc 0.66225 roc_auc 0.36961 prc_auc 0.56884[0m
[93maverage test of epoch 62: loss -12.71096 acc 0.67568 roc_auc 0.56000 prc_auc 0.70773[0m
[92maverage training of epoch 63: loss -12.71872 acc 0.66225 roc_auc 0.37569 prc_auc 0.57694[0m
[93maverage test of epoch 63: loss -12.87756 acc 0.67568 roc_auc 0.40667 prc_auc 0.63198[0m
[92maverage training of epoch 64: loss -12.88475 acc 0.66225 roc_auc 0.36559 prc_auc 0.56518[0m
[93maverage test of epoch 64: loss -13.04490 acc 0.67568 roc_auc 0.56167 prc_auc 0.70192[0m
[92maverage training of epoch 65: loss -13.05183 acc 0.66225 roc_auc 0.36549 prc_auc 0.56497[0m
[93maverage test of epoch 65: loss -13.21229 acc 0.67568 roc_auc 0.50000 prc_auc 0.68282[0m
[92maverage training of epoch 66: loss -13.21799 acc 0.66225 roc_auc 0.38049 prc_auc 0.57413[0m
[93maverage test of epoch 66: loss -13.37987 acc 0.67568 roc_auc 0.50167 prc_auc 0.69658[0m
[92maverage training of epoch 67: loss -13.38491 acc 0.66225 roc_auc 0.37069 prc_auc 0.57100[0m
[93maverage test of epoch 67: loss -13.54668 acc 0.67568 roc_auc 0.31667 prc_auc 0.58648[0m
[92maverage training of epoch 68: loss -13.55139 acc 0.66225 roc_auc 0.36294 prc_auc 0.56274[0m
[93maverage test of epoch 68: loss -13.71396 acc 0.67568 roc_auc 0.39167 prc_auc 0.61685[0m
[92maverage training of epoch 69: loss -13.71764 acc 0.66225 roc_auc 0.35931 prc_auc 0.56288[0m
[93maverage test of epoch 69: loss -13.88143 acc 0.67568 roc_auc 0.29667 prc_auc 0.57595[0m
[92maverage training of epoch 70: loss -13.88433 acc 0.66225 roc_auc 0.37039 prc_auc 0.56914[0m
[93maverage test of epoch 70: loss -14.04849 acc 0.67568 roc_auc 0.37833 prc_auc 0.61594[0m
[92maverage training of epoch 71: loss -14.05087 acc 0.66225 roc_auc 0.36931 prc_auc 0.57145[0m
[93maverage test of epoch 71: loss -14.21592 acc 0.67568 roc_auc 0.44333 prc_auc 0.64784[0m
[92maverage training of epoch 72: loss -14.21712 acc 0.66225 roc_auc 0.37824 prc_auc 0.57692[0m
[93maverage test of epoch 72: loss -14.38273 acc 0.67568 roc_auc 0.47333 prc_auc 0.66180[0m
[92maverage training of epoch 73: loss -14.38395 acc 0.66225 roc_auc 0.36373 prc_auc 0.56480[0m
[93maverage test of epoch 73: loss -14.54993 acc 0.67568 roc_auc 0.41000 prc_auc 0.64996[0m
[92maverage training of epoch 74: loss -14.55042 acc 0.66225 roc_auc 0.36833 prc_auc 0.57032[0m
[93maverage test of epoch 74: loss -14.71664 acc 0.67568 roc_auc 0.41500 prc_auc 0.65683[0m
[92maverage training of epoch 75: loss -14.71672 acc 0.66225 roc_auc 0.37578 prc_auc 0.57117[0m
[93maverage test of epoch 75: loss -14.88443 acc 0.67568 roc_auc 0.59500 prc_auc 0.72989[0m
[92maverage training of epoch 76: loss -14.88340 acc 0.66225 roc_auc 0.36422 prc_auc 0.56331[0m
[93maverage test of epoch 76: loss -15.05198 acc 0.67568 roc_auc 0.64667 prc_auc 0.75820[0m
[92maverage training of epoch 77: loss -15.04979 acc 0.66225 roc_auc 0.36461 prc_auc 0.56292[0m
[93maverage test of epoch 77: loss -15.21871 acc 0.67568 roc_auc 0.46000 prc_auc 0.65140[0m
[92maverage training of epoch 78: loss -15.21639 acc 0.66225 roc_auc 0.36833 prc_auc 0.56836[0m
[93maverage test of epoch 78: loss -15.38598 acc 0.67568 roc_auc 0.56500 prc_auc 0.72485[0m
[92maverage training of epoch 79: loss -15.38292 acc 0.66225 roc_auc 0.36775 prc_auc 0.56628[0m
[93maverage test of epoch 79: loss -15.55339 acc 0.67568 roc_auc 0.59167 prc_auc 0.73636[0m
[92maverage training of epoch 80: loss -15.54929 acc 0.66225 roc_auc 0.37402 prc_auc 0.57328[0m
[93maverage test of epoch 80: loss -15.72062 acc 0.67568 roc_auc 0.37667 prc_auc 0.63024[0m
[92maverage training of epoch 81: loss -15.71583 acc 0.66225 roc_auc 0.36696 prc_auc 0.56560[0m
[93maverage test of epoch 81: loss -15.88777 acc 0.67568 roc_auc 0.60500 prc_auc 0.75474[0m
[92maverage training of epoch 82: loss -15.88231 acc 0.66225 roc_auc 0.36784 prc_auc 0.56655[0m
[93maverage test of epoch 82: loss -16.05503 acc 0.67568 roc_auc 0.59333 prc_auc 0.71969[0m
[92maverage training of epoch 83: loss -16.04876 acc 0.66225 roc_auc 0.36882 prc_auc 0.56949[0m
[93maverage test of epoch 83: loss -16.22203 acc 0.67568 roc_auc 0.41167 prc_auc 0.64560[0m
[92maverage training of epoch 84: loss -16.21523 acc 0.66225 roc_auc 0.37147 prc_auc 0.57065[0m
[93maverage test of epoch 84: loss -16.38939 acc 0.67568 roc_auc 0.36500 prc_auc 0.61313[0m
[92maverage training of epoch 85: loss -16.38171 acc 0.66225 roc_auc 0.36775 prc_auc 0.56764[0m
[93maverage test of epoch 85: loss -16.55639 acc 0.67568 roc_auc 0.56167 prc_auc 0.72220[0m
[92maverage training of epoch 86: loss -16.54822 acc 0.66225 roc_auc 0.36912 prc_auc 0.57331[0m
[93maverage test of epoch 86: loss -16.72374 acc 0.67568 roc_auc 0.31333 prc_auc 0.60168[0m
[92maverage training of epoch 87: loss -16.71466 acc 0.66225 roc_auc 0.36931 prc_auc 0.56913[0m
[93maverage test of epoch 87: loss -16.89093 acc 0.67568 roc_auc 0.60500 prc_auc 0.72739[0m
[92maverage training of epoch 88: loss -16.88100 acc 0.66225 roc_auc 0.36922 prc_auc 0.56947[0m
[93maverage test of epoch 88: loss -17.05783 acc 0.67568 roc_auc 0.42833 prc_auc 0.64037[0m
[92maverage training of epoch 89: loss -17.04764 acc 0.66225 roc_auc 0.37088 prc_auc 0.57449[0m
[93maverage test of epoch 89: loss -17.22502 acc 0.67568 roc_auc 0.42833 prc_auc 0.64608[0m
[92maverage training of epoch 90: loss -17.21415 acc 0.66225 roc_auc 0.36755 prc_auc 0.56600[0m
[93maverage test of epoch 90: loss -17.39239 acc 0.67568 roc_auc 0.57667 prc_auc 0.71125[0m
[92maverage training of epoch 91: loss -17.38055 acc 0.66225 roc_auc 0.37088 prc_auc 0.56943[0m
[93maverage test of epoch 91: loss -17.55953 acc 0.67568 roc_auc 0.53167 prc_auc 0.69187[0m
[92maverage training of epoch 92: loss -17.54698 acc 0.66225 roc_auc 0.36853 prc_auc 0.56973[0m
[93maverage test of epoch 92: loss -17.72659 acc 0.67568 roc_auc 0.50667 prc_auc 0.69798[0m
[92maverage training of epoch 93: loss -17.71341 acc 0.66225 roc_auc 0.36814 prc_auc 0.56908[0m
[93maverage test of epoch 93: loss -17.89375 acc 0.67568 roc_auc 0.37667 prc_auc 0.61947[0m
[92maverage training of epoch 94: loss -17.87994 acc 0.66225 roc_auc 0.36657 prc_auc 0.56625[0m
[93maverage test of epoch 94: loss -18.06102 acc 0.67568 roc_auc 0.48833 prc_auc 0.66848[0m
[92maverage training of epoch 95: loss -18.04640 acc 0.66225 roc_auc 0.37010 prc_auc 0.56878[0m
[93maverage test of epoch 95: loss -18.22802 acc 0.67568 roc_auc 0.58167 prc_auc 0.72319[0m
[92maverage training of epoch 96: loss -18.21276 acc 0.66225 roc_auc 0.36735 prc_auc 0.56772[0m
[93maverage test of epoch 96: loss -18.39481 acc 0.67568 roc_auc 0.66833 prc_auc 0.76447[0m
[92maverage training of epoch 97: loss -18.37927 acc 0.66225 roc_auc 0.36667 prc_auc 0.56768[0m
[93maverage test of epoch 97: loss -18.56231 acc 0.67568 roc_auc 0.60833 prc_auc 0.78597[0m
[92maverage training of epoch 98: loss -18.54583 acc 0.66225 roc_auc 0.36853 prc_auc 0.57178[0m
[93maverage test of epoch 98: loss -18.72968 acc 0.67568 roc_auc 0.52167 prc_auc 0.68688[0m
[92maverage training of epoch 99: loss -18.71219 acc 0.66225 roc_auc 0.36784 prc_auc 0.56911[0m
[93maverage test of epoch 99: loss -18.89689 acc 0.67568 roc_auc 0.59000 prc_auc 0.71959[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.0003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.66501 ROC_AUC (avg): 0.56887 PRC_AUC (avg): 0.7093 

Average forward propagation time taken(ms): 3.9774057759037023
Average backward propagation time taken(ms): 1.5174902512046782

