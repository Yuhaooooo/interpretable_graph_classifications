# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.0001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-07-16-13/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-07-16-13/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 8,
 'epochs': 100,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 8,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.0001,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 2,
 'num_workers': 8,
 'number_of_mlp_layer': 0,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-18-07-16-13',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 100, 'learning_rate': 0.0001, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.12739 acc 0.66667 roc_auc 0.44740 prc_auc 0.65238[0m
[93maverage test of epoch 0: loss -0.28430 acc 0.63158 roc_auc 0.57231 prc_auc 0.68445[0m
[92maverage training of epoch 1: loss -0.43357 acc 0.66667 roc_auc 0.44480 prc_auc 0.62778[0m
[93maverage test of epoch 1: loss -0.59226 acc 0.65789 roc_auc 0.46154 prc_auc 0.64997[0m
[92maverage training of epoch 2: loss -0.76330 acc 0.66667 roc_auc 0.50420 prc_auc 0.68480[0m
[93maverage test of epoch 2: loss -0.90786 acc 0.65789 roc_auc 0.49538 prc_auc 0.70125[0m
[92maverage training of epoch 3: loss -1.07066 acc 0.66667 roc_auc 0.53400 prc_auc 0.73282[0m
[93maverage test of epoch 3: loss -1.20854 acc 0.65789 roc_auc 0.42154 prc_auc 0.64390[0m
[92maverage training of epoch 4: loss -1.39953 acc 0.66667 roc_auc 0.50600 prc_auc 0.70823[0m
[93maverage test of epoch 4: loss -1.58100 acc 0.65789 roc_auc 0.73846 prc_auc 0.84184[0m
[92maverage training of epoch 5: loss -1.77055 acc 0.66667 roc_auc 0.45120 prc_auc 0.65141[0m
[93maverage test of epoch 5: loss -1.95634 acc 0.65789 roc_auc 0.81231 prc_auc 0.86930[0m
[92maverage training of epoch 6: loss -2.08520 acc 0.66667 roc_auc 0.48100 prc_auc 0.66975[0m
[93maverage test of epoch 6: loss -2.20783 acc 0.65789 roc_auc 0.42462 prc_auc 0.61896[0m
[92maverage training of epoch 7: loss -2.32466 acc 0.66667 roc_auc 0.43940 prc_auc 0.62479[0m
[93maverage test of epoch 7: loss -2.43085 acc 0.65789 roc_auc 0.46769 prc_auc 0.62358[0m
[92maverage training of epoch 8: loss -2.54556 acc 0.66667 roc_auc 0.51720 prc_auc 0.68728[0m
[93maverage test of epoch 8: loss -2.62603 acc 0.65789 roc_auc 0.75077 prc_auc 0.85865[0m
[92maverage training of epoch 9: loss -2.72903 acc 0.66667 roc_auc 0.47680 prc_auc 0.68729[0m
[93maverage test of epoch 9: loss -2.79389 acc 0.65789 roc_auc 0.48308 prc_auc 0.64002[0m
[92maverage training of epoch 10: loss -2.89087 acc 0.66667 roc_auc 0.45540 prc_auc 0.64432[0m
[93maverage test of epoch 10: loss -2.94477 acc 0.65789 roc_auc 0.36000 prc_auc 0.60945[0m
[92maverage training of epoch 11: loss -3.04560 acc 0.66667 roc_auc 0.47680 prc_auc 0.65052[0m
[93maverage test of epoch 11: loss -3.10344 acc 0.65789 roc_auc 0.48615 prc_auc 0.70973[0m
[92maverage training of epoch 12: loss -3.18601 acc 0.66667 roc_auc 0.47160 prc_auc 0.65659[0m
[93maverage test of epoch 12: loss -3.22337 acc 0.65789 roc_auc 0.30769 prc_auc 0.57172[0m
[92maverage training of epoch 13: loss -3.31059 acc 0.66667 roc_auc 0.50540 prc_auc 0.68040[0m
[93maverage test of epoch 13: loss -3.35925 acc 0.65789 roc_auc 0.46462 prc_auc 0.62261[0m
[92maverage training of epoch 14: loss -3.43381 acc 0.66667 roc_auc 0.46460 prc_auc 0.66272[0m
[93maverage test of epoch 14: loss -3.48692 acc 0.65789 roc_auc 0.57231 prc_auc 0.76085[0m
[92maverage training of epoch 15: loss -3.55043 acc 0.66667 roc_auc 0.48340 prc_auc 0.67101[0m
[93maverage test of epoch 15: loss -3.59523 acc 0.65789 roc_auc 0.35385 prc_auc 0.59421[0m
[92maverage training of epoch 16: loss -3.67802 acc 0.66667 roc_auc 0.48660 prc_auc 0.66948[0m
[93maverage test of epoch 16: loss -3.72152 acc 0.65789 roc_auc 0.60923 prc_auc 0.75410[0m
[92maverage training of epoch 17: loss -3.80038 acc 0.66667 roc_auc 0.45680 prc_auc 0.65686[0m
[93maverage test of epoch 17: loss -3.84708 acc 0.65789 roc_auc 0.47077 prc_auc 0.70437[0m
[92maverage training of epoch 18: loss -3.93714 acc 0.66667 roc_auc 0.43420 prc_auc 0.64185[0m
[93maverage test of epoch 18: loss -3.98929 acc 0.65789 roc_auc 0.43692 prc_auc 0.66430[0m
[92maverage training of epoch 19: loss -4.07169 acc 0.66667 roc_auc 0.46620 prc_auc 0.66782[0m
[93maverage test of epoch 19: loss -4.11295 acc 0.65789 roc_auc 0.40615 prc_auc 0.63766[0m
[92maverage training of epoch 20: loss -4.19429 acc 0.66667 roc_auc 0.47200 prc_auc 0.68089[0m
[93maverage test of epoch 20: loss -4.22920 acc 0.65789 roc_auc 0.58769 prc_auc 0.76269[0m
[92maverage training of epoch 21: loss -4.32150 acc 0.66667 roc_auc 0.49900 prc_auc 0.67348[0m
[93maverage test of epoch 21: loss -4.36765 acc 0.65789 roc_auc 0.69538 prc_auc 0.75804[0m
[92maverage training of epoch 22: loss -4.43634 acc 0.66667 roc_auc 0.45460 prc_auc 0.65351[0m
[93maverage test of epoch 22: loss -4.48376 acc 0.65789 roc_auc 0.68923 prc_auc 0.84973[0m
[92maverage training of epoch 23: loss -4.56082 acc 0.66667 roc_auc 0.53160 prc_auc 0.68266[0m
[93maverage test of epoch 23: loss -4.60166 acc 0.65789 roc_auc 0.59077 prc_auc 0.80570[0m
[92maverage training of epoch 24: loss -4.67022 acc 0.66667 roc_auc 0.43900 prc_auc 0.64184[0m
[93maverage test of epoch 24: loss -4.69650 acc 0.65789 roc_auc 0.44308 prc_auc 0.62077[0m
[92maverage training of epoch 25: loss -4.78228 acc 0.66667 roc_auc 0.39220 prc_auc 0.62187[0m
[93maverage test of epoch 25: loss -4.82486 acc 0.65789 roc_auc 0.61538 prc_auc 0.79299[0m
[92maverage training of epoch 26: loss -4.90126 acc 0.66667 roc_auc 0.50000 prc_auc 0.72152[0m
[93maverage test of epoch 26: loss -4.92751 acc 0.65789 roc_auc 0.47385 prc_auc 0.63020[0m
[92maverage training of epoch 27: loss -5.00463 acc 0.66667 roc_auc 0.39880 prc_auc 0.60857[0m
[93maverage test of epoch 27: loss -5.04189 acc 0.65789 roc_auc 0.37846 prc_auc 0.61167[0m
[92maverage training of epoch 28: loss -5.12516 acc 0.66667 roc_auc 0.48040 prc_auc 0.65384[0m
[93maverage test of epoch 28: loss -5.15903 acc 0.65789 roc_auc 0.64615 prc_auc 0.80398[0m
[92maverage training of epoch 29: loss -5.23441 acc 0.66667 roc_auc 0.54380 prc_auc 0.67965[0m
[93maverage test of epoch 29: loss -5.26671 acc 0.65789 roc_auc 0.56923 prc_auc 0.77029[0m
[92maverage training of epoch 30: loss -5.34237 acc 0.66667 roc_auc 0.46900 prc_auc 0.64060[0m
[93maverage test of epoch 30: loss -5.36933 acc 0.65789 roc_auc 0.28923 prc_auc 0.54357[0m
[92maverage training of epoch 31: loss -5.45248 acc 0.66667 roc_auc 0.47120 prc_auc 0.65309[0m
[93maverage test of epoch 31: loss -5.48853 acc 0.65789 roc_auc 0.50462 prc_auc 0.70349[0m
[92maverage training of epoch 32: loss -5.56184 acc 0.66667 roc_auc 0.47040 prc_auc 0.65599[0m
[93maverage test of epoch 32: loss -5.58792 acc 0.65789 roc_auc 0.55385 prc_auc 0.76159[0m
[92maverage training of epoch 33: loss -5.66473 acc 0.66667 roc_auc 0.40880 prc_auc 0.60552[0m
[93maverage test of epoch 33: loss -5.69749 acc 0.65789 roc_auc 0.50462 prc_auc 0.69607[0m
[92maverage training of epoch 34: loss -5.77382 acc 0.66667 roc_auc 0.39500 prc_auc 0.59524[0m
[93maverage test of epoch 34: loss -5.80164 acc 0.65789 roc_auc 0.52308 prc_auc 0.69769[0m
[92maverage training of epoch 35: loss -5.88298 acc 0.66667 roc_auc 0.46360 prc_auc 0.62597[0m
[93maverage test of epoch 35: loss -5.91346 acc 0.65789 roc_auc 0.51692 prc_auc 0.69441[0m
[92maverage training of epoch 36: loss -5.99213 acc 0.66667 roc_auc 0.49740 prc_auc 0.67729[0m
[93maverage test of epoch 36: loss -6.01793 acc 0.65789 roc_auc 0.38154 prc_auc 0.61952[0m
[92maverage training of epoch 37: loss -6.09474 acc 0.66667 roc_auc 0.45200 prc_auc 0.66031[0m
[93maverage test of epoch 37: loss -6.12680 acc 0.65789 roc_auc 0.63385 prc_auc 0.72753[0m
[92maverage training of epoch 38: loss -6.20507 acc 0.66667 roc_auc 0.47660 prc_auc 0.65989[0m
[93maverage test of epoch 38: loss -6.23654 acc 0.65789 roc_auc 0.72000 prc_auc 0.80739[0m
[92maverage training of epoch 39: loss -6.30589 acc 0.66667 roc_auc 0.48700 prc_auc 0.66332[0m
[93maverage test of epoch 39: loss -6.32694 acc 0.65789 roc_auc 0.50769 prc_auc 0.72285[0m
[92maverage training of epoch 40: loss -6.40927 acc 0.66667 roc_auc 0.43800 prc_auc 0.62424[0m
[93maverage test of epoch 40: loss -6.43664 acc 0.65789 roc_auc 0.64615 prc_auc 0.78848[0m
[92maverage training of epoch 41: loss -6.51630 acc 0.66667 roc_auc 0.46880 prc_auc 0.63287[0m
[93maverage test of epoch 41: loss -6.54693 acc 0.65789 roc_auc 0.65231 prc_auc 0.80787[0m
[92maverage training of epoch 42: loss -6.62139 acc 0.66667 roc_auc 0.44080 prc_auc 0.61310[0m
[93maverage test of epoch 42: loss -6.63651 acc 0.65789 roc_auc 0.43077 prc_auc 0.63568[0m
[92maverage training of epoch 43: loss -6.72071 acc 0.66667 roc_auc 0.38380 prc_auc 0.60228[0m
[93maverage test of epoch 43: loss -6.74296 acc 0.65789 roc_auc 0.48615 prc_auc 0.66840[0m
[92maverage training of epoch 44: loss -6.82710 acc 0.66667 roc_auc 0.44440 prc_auc 0.63438[0m
[93maverage test of epoch 44: loss -6.85020 acc 0.65789 roc_auc 0.58462 prc_auc 0.78655[0m
[92maverage training of epoch 45: loss -6.93198 acc 0.66667 roc_auc 0.41100 prc_auc 0.59465[0m
[93maverage test of epoch 45: loss -6.95495 acc 0.65789 roc_auc 0.54769 prc_auc 0.69951[0m
[92maverage training of epoch 46: loss -7.03840 acc 0.66667 roc_auc 0.45220 prc_auc 0.62727[0m
[93maverage test of epoch 46: loss -7.05443 acc 0.65789 roc_auc 0.51077 prc_auc 0.66986[0m
[92maverage training of epoch 47: loss -7.13782 acc 0.66667 roc_auc 0.41700 prc_auc 0.60841[0m
[93maverage test of epoch 47: loss -7.15680 acc 0.65789 roc_auc 0.47385 prc_auc 0.63217[0m
[92maverage training of epoch 48: loss -7.24460 acc 0.66667 roc_auc 0.46600 prc_auc 0.64901[0m
[93maverage test of epoch 48: loss -7.26268 acc 0.65789 roc_auc 0.60923 prc_auc 0.79356[0m
[92maverage training of epoch 49: loss -7.34461 acc 0.66667 roc_auc 0.34460 prc_auc 0.59386[0m
[93maverage test of epoch 49: loss -7.35752 acc 0.65789 roc_auc 0.52308 prc_auc 0.73835[0m
[92maverage training of epoch 50: loss -7.44581 acc 0.66667 roc_auc 0.40970 prc_auc 0.60787[0m
[93maverage test of epoch 50: loss -7.46510 acc 0.65789 roc_auc 0.52000 prc_auc 0.66344[0m
[92maverage training of epoch 51: loss -7.54738 acc 0.66667 roc_auc 0.43620 prc_auc 0.60802[0m
[93maverage test of epoch 51: loss -7.56928 acc 0.65789 roc_auc 0.50769 prc_auc 0.67694[0m
[92maverage training of epoch 52: loss -7.65241 acc 0.66667 roc_auc 0.48330 prc_auc 0.67003[0m
[93maverage test of epoch 52: loss -7.66703 acc 0.65789 roc_auc 0.59077 prc_auc 0.75232[0m
[92maverage training of epoch 53: loss -7.75470 acc 0.66667 roc_auc 0.46260 prc_auc 0.63082[0m
[93maverage test of epoch 53: loss -7.76957 acc 0.65789 roc_auc 0.52615 prc_auc 0.71381[0m
[92maverage training of epoch 54: loss -7.85437 acc 0.66667 roc_auc 0.41990 prc_auc 0.61569[0m
[93maverage test of epoch 54: loss -7.86637 acc 0.65789 roc_auc 0.34769 prc_auc 0.60412[0m
[92maverage training of epoch 55: loss -7.95593 acc 0.66667 roc_auc 0.39280 prc_auc 0.60393[0m
[93maverage test of epoch 55: loss -7.97386 acc 0.65789 roc_auc 0.55692 prc_auc 0.73454[0m
[92maverage training of epoch 56: loss -8.05874 acc 0.66667 roc_auc 0.43000 prc_auc 0.61166[0m
[93maverage test of epoch 56: loss -8.07214 acc 0.65789 roc_auc 0.53846 prc_auc 0.73928[0m
[92maverage training of epoch 57: loss -8.15740 acc 0.66667 roc_auc 0.38080 prc_auc 0.57795[0m
[93maverage test of epoch 57: loss -8.17557 acc 0.65789 roc_auc 0.59385 prc_auc 0.72419[0m
[92maverage training of epoch 58: loss -8.25819 acc 0.66667 roc_auc 0.42010 prc_auc 0.61538[0m
[93maverage test of epoch 58: loss -8.26999 acc 0.65789 roc_auc 0.37846 prc_auc 0.64943[0m
[92maverage training of epoch 59: loss -8.36072 acc 0.66667 roc_auc 0.38540 prc_auc 0.60462[0m
[93maverage test of epoch 59: loss -8.37521 acc 0.65789 roc_auc 0.54154 prc_auc 0.73955[0m
[92maverage training of epoch 60: loss -8.46152 acc 0.66667 roc_auc 0.40640 prc_auc 0.61745[0m
[93maverage test of epoch 60: loss -8.47767 acc 0.65789 roc_auc 0.56769 prc_auc 0.70944[0m
[92maverage training of epoch 61: loss -8.56267 acc 0.66667 roc_auc 0.42260 prc_auc 0.62244[0m
[93maverage test of epoch 61: loss -8.57957 acc 0.65789 roc_auc 0.62615 prc_auc 0.77469[0m
[92maverage training of epoch 62: loss -8.66448 acc 0.66667 roc_auc 0.44900 prc_auc 0.63324[0m
[93maverage test of epoch 62: loss -8.67675 acc 0.65789 roc_auc 0.47077 prc_auc 0.67706[0m
[92maverage training of epoch 63: loss -8.76487 acc 0.66667 roc_auc 0.47340 prc_auc 0.64489[0m
[93maverage test of epoch 63: loss -8.77738 acc 0.65789 roc_auc 0.50000 prc_auc 0.72212[0m
[92maverage training of epoch 64: loss -8.86550 acc 0.66667 roc_auc 0.44630 prc_auc 0.63017[0m
[93maverage test of epoch 64: loss -8.87751 acc 0.65789 roc_auc 0.52769 prc_auc 0.68752[0m
[92maverage training of epoch 65: loss -8.96585 acc 0.66667 roc_auc 0.47010 prc_auc 0.66155[0m
[93maverage test of epoch 65: loss -8.98018 acc 0.65789 roc_auc 0.63692 prc_auc 0.75547[0m
[92maverage training of epoch 66: loss -9.06554 acc 0.66667 roc_auc 0.41360 prc_auc 0.62217[0m
[93maverage test of epoch 66: loss -9.07678 acc 0.65789 roc_auc 0.57846 prc_auc 0.72411[0m
[92maverage training of epoch 67: loss -9.16595 acc 0.66667 roc_auc 0.40680 prc_auc 0.59919[0m
[93maverage test of epoch 67: loss -9.17597 acc 0.65789 roc_auc 0.47846 prc_auc 0.72240[0m
[92maverage training of epoch 68: loss -9.26805 acc 0.66667 roc_auc 0.49330 prc_auc 0.66537[0m
[93maverage test of epoch 68: loss -9.27626 acc 0.65789 roc_auc 0.37846 prc_auc 0.62174[0m
[92maverage training of epoch 69: loss -9.36691 acc 0.66667 roc_auc 0.38070 prc_auc 0.59140[0m
[93maverage test of epoch 69: loss -9.37861 acc 0.65789 roc_auc 0.51538 prc_auc 0.69901[0m
[92maverage training of epoch 70: loss -9.46673 acc 0.66667 roc_auc 0.34540 prc_auc 0.56281[0m
[93maverage test of epoch 70: loss -9.47686 acc 0.65789 roc_auc 0.57231 prc_auc 0.79832[0m
[92maverage training of epoch 71: loss -9.56764 acc 0.66667 roc_auc 0.45080 prc_auc 0.61176[0m
[93maverage test of epoch 71: loss -9.57733 acc 0.65789 roc_auc 0.56000 prc_auc 0.72938[0m
[92maverage training of epoch 72: loss -9.66724 acc 0.66667 roc_auc 0.42600 prc_auc 0.59163[0m
[93maverage test of epoch 72: loss -9.67658 acc 0.65789 roc_auc 0.44308 prc_auc 0.68295[0m
[92maverage training of epoch 73: loss -9.76694 acc 0.66667 roc_auc 0.44980 prc_auc 0.64597[0m
[93maverage test of epoch 73: loss -9.77642 acc 0.65789 roc_auc 0.58615 prc_auc 0.71379[0m
[92maverage training of epoch 74: loss -9.86726 acc 0.66667 roc_auc 0.37610 prc_auc 0.59216[0m
[93maverage test of epoch 74: loss -9.87693 acc 0.65789 roc_auc 0.53538 prc_auc 0.72219[0m
[92maverage training of epoch 75: loss -9.96775 acc 0.66667 roc_auc 0.41870 prc_auc 0.60809[0m
[93maverage test of epoch 75: loss -9.97456 acc 0.65789 roc_auc 0.48923 prc_auc 0.72968[0m
[92maverage training of epoch 76: loss -10.06729 acc 0.66667 roc_auc 0.38250 prc_auc 0.58036[0m
[93maverage test of epoch 76: loss -10.07482 acc 0.65789 roc_auc 0.54615 prc_auc 0.69849[0m
[92maverage training of epoch 77: loss -10.16795 acc 0.66667 roc_auc 0.41640 prc_auc 0.60778[0m
[93maverage test of epoch 77: loss -10.17442 acc 0.65789 roc_auc 0.61231 prc_auc 0.79888[0m
[92maverage training of epoch 78: loss -10.26782 acc 0.66667 roc_auc 0.42290 prc_auc 0.59775[0m
[93maverage test of epoch 78: loss -10.27443 acc 0.65789 roc_auc 0.48308 prc_auc 0.63498[0m
[92maverage training of epoch 79: loss -10.36807 acc 0.66667 roc_auc 0.41530 prc_auc 0.61009[0m
[93maverage test of epoch 79: loss -10.37536 acc 0.65789 roc_auc 0.54000 prc_auc 0.67502[0m
[92maverage training of epoch 80: loss -10.46765 acc 0.66667 roc_auc 0.40300 prc_auc 0.62034[0m
[93maverage test of epoch 80: loss -10.47512 acc 0.65789 roc_auc 0.53692 prc_auc 0.69872[0m
[92maverage training of epoch 81: loss -10.56707 acc 0.66667 roc_auc 0.38990 prc_auc 0.59321[0m
[93maverage test of epoch 81: loss -10.57477 acc 0.65789 roc_auc 0.66923 prc_auc 0.78894[0m
[92maverage training of epoch 82: loss -10.66749 acc 0.66667 roc_auc 0.39390 prc_auc 0.60961[0m
[93maverage test of epoch 82: loss -10.67309 acc 0.65789 roc_auc 0.53231 prc_auc 0.72898[0m
[92maverage training of epoch 83: loss -10.76651 acc 0.66667 roc_auc 0.38840 prc_auc 0.59205[0m
[93maverage test of epoch 83: loss -10.77314 acc 0.65789 roc_auc 0.68308 prc_auc 0.81989[0m
[92maverage training of epoch 84: loss -10.86613 acc 0.66667 roc_auc 0.37380 prc_auc 0.58077[0m
[93maverage test of epoch 84: loss -10.87338 acc 0.65789 roc_auc 0.62154 prc_auc 0.74225[0m
[92maverage training of epoch 85: loss -10.96625 acc 0.66667 roc_auc 0.36940 prc_auc 0.58200[0m
[93maverage test of epoch 85: loss -10.97260 acc 0.65789 roc_auc 0.61077 prc_auc 0.75193[0m
[92maverage training of epoch 86: loss -11.06632 acc 0.66667 roc_auc 0.38180 prc_auc 0.57692[0m
[93maverage test of epoch 86: loss -11.07193 acc 0.65789 roc_auc 0.43538 prc_auc 0.60816[0m
[92maverage training of epoch 87: loss -11.16592 acc 0.66667 roc_auc 0.37430 prc_auc 0.58155[0m
[93maverage test of epoch 87: loss -11.17026 acc 0.65789 roc_auc 0.58000 prc_auc 0.72144[0m
[92maverage training of epoch 88: loss -11.26578 acc 0.66667 roc_auc 0.37270 prc_auc 0.57878[0m
[93maverage test of epoch 88: loss -11.27036 acc 0.65789 roc_auc 0.43538 prc_auc 0.63458[0m
[92maverage training of epoch 89: loss -11.36512 acc 0.66667 roc_auc 0.37260 prc_auc 0.59771[0m
[93maverage test of epoch 89: loss -11.36980 acc 0.65789 roc_auc 0.61077 prc_auc 0.70956[0m
[92maverage training of epoch 90: loss -11.46474 acc 0.66667 roc_auc 0.36280 prc_auc 0.56961[0m
[93maverage test of epoch 90: loss -11.46883 acc 0.65789 roc_auc 0.56308 prc_auc 0.73583[0m
[92maverage training of epoch 91: loss -11.56430 acc 0.66667 roc_auc 0.37110 prc_auc 0.57850[0m
[93maverage test of epoch 91: loss -11.56831 acc 0.65789 roc_auc 0.50154 prc_auc 0.65049[0m
[92maverage training of epoch 92: loss -11.66421 acc 0.66667 roc_auc 0.37050 prc_auc 0.57967[0m
[93maverage test of epoch 92: loss -11.66752 acc 0.65789 roc_auc 0.38615 prc_auc 0.69073[0m
[92maverage training of epoch 93: loss -11.76394 acc 0.66667 roc_auc 0.36800 prc_auc 0.57706[0m
[93maverage test of epoch 93: loss -11.76720 acc 0.65789 roc_auc 0.39385 prc_auc 0.61002[0m
[92maverage training of epoch 94: loss -11.86318 acc 0.66667 roc_auc 0.34360 prc_auc 0.56256[0m
[93maverage test of epoch 94: loss -11.86641 acc 0.65789 roc_auc 0.44308 prc_auc 0.61192[0m
[92maverage training of epoch 95: loss -11.96294 acc 0.66667 roc_auc 0.36960 prc_auc 0.58216[0m
[93maverage test of epoch 95: loss -11.96530 acc 0.65789 roc_auc 0.36615 prc_auc 0.60568[0m
[92maverage training of epoch 96: loss -12.06251 acc 0.66667 roc_auc 0.37100 prc_auc 0.58010[0m
[93maverage test of epoch 96: loss -12.06466 acc 0.65789 roc_auc 0.52154 prc_auc 0.68334[0m
[92maverage training of epoch 97: loss -12.16222 acc 0.66667 roc_auc 0.35760 prc_auc 0.56632[0m
[93maverage test of epoch 97: loss -12.16356 acc 0.65789 roc_auc 0.51231 prc_auc 0.67197[0m
[92maverage training of epoch 98: loss -12.26142 acc 0.66667 roc_auc 0.36620 prc_auc 0.57691[0m
[93maverage test of epoch 98: loss -12.26330 acc 0.65789 roc_auc 0.49385 prc_auc 0.67821[0m
[92maverage training of epoch 99: loss -12.36107 acc 0.66667 roc_auc 0.35810 prc_auc 0.57537[0m
[93maverage test of epoch 99: loss -12.36258 acc 0.65789 roc_auc 0.42923 prc_auc 0.62195[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.32710 acc 0.36000 roc_auc 0.47940 prc_auc 0.65255[0m
[93maverage test of epoch 0: loss -0.52133 acc 0.60526 roc_auc 0.56000 prc_auc 0.79198[0m
[92maverage training of epoch 1: loss -0.67594 acc 0.64000 roc_auc 0.51500 prc_auc 0.66683[0m
[93maverage test of epoch 1: loss -0.86535 acc 0.65789 roc_auc 0.46462 prc_auc 0.66630[0m
[92maverage training of epoch 2: loss -1.03943 acc 0.66667 roc_auc 0.47680 prc_auc 0.64535[0m
[93maverage test of epoch 2: loss -1.22200 acc 0.65789 roc_auc 0.52615 prc_auc 0.70784[0m
[92maverage training of epoch 3: loss -1.40650 acc 0.66667 roc_auc 0.51120 prc_auc 0.69033[0m
[93maverage test of epoch 3: loss -1.57913 acc 0.65789 roc_auc 0.54154 prc_auc 0.71565[0m
[92maverage training of epoch 4: loss -1.81125 acc 0.66667 roc_auc 0.43440 prc_auc 0.64473[0m
[93maverage test of epoch 4: loss -2.02866 acc 0.65789 roc_auc 0.44000 prc_auc 0.65647[0m
[92maverage training of epoch 5: loss -2.29719 acc 0.66667 roc_auc 0.47640 prc_auc 0.66031[0m
[93maverage test of epoch 5: loss -2.48681 acc 0.65789 roc_auc 0.57231 prc_auc 0.72131[0m
[92maverage training of epoch 6: loss -2.72776 acc 0.66667 roc_auc 0.46500 prc_auc 0.65076[0m
[93maverage test of epoch 6: loss -2.89740 acc 0.65789 roc_auc 0.48000 prc_auc 0.69288[0m
[92maverage training of epoch 7: loss -3.07620 acc 0.66667 roc_auc 0.47160 prc_auc 0.65150[0m
[93maverage test of epoch 7: loss -3.19100 acc 0.65789 roc_auc 0.43077 prc_auc 0.59232[0m
[92maverage training of epoch 8: loss -3.35507 acc 0.66667 roc_auc 0.48940 prc_auc 0.66291[0m
[93maverage test of epoch 8: loss -3.45166 acc 0.65789 roc_auc 0.44615 prc_auc 0.70035[0m
[92maverage training of epoch 9: loss -3.59395 acc 0.66667 roc_auc 0.45620 prc_auc 0.63181[0m
[93maverage test of epoch 9: loss -3.66881 acc 0.65789 roc_auc 0.48615 prc_auc 0.64643[0m
[92maverage training of epoch 10: loss -3.79669 acc 0.66667 roc_auc 0.44860 prc_auc 0.62391[0m
[93maverage test of epoch 10: loss -3.86676 acc 0.65789 roc_auc 0.53846 prc_auc 0.69625[0m
[92maverage training of epoch 11: loss -3.99002 acc 0.66667 roc_auc 0.47340 prc_auc 0.66953[0m
[93maverage test of epoch 11: loss -4.05758 acc 0.65789 roc_auc 0.49231 prc_auc 0.70838[0m
[92maverage training of epoch 12: loss -4.17319 acc 0.66667 roc_auc 0.47460 prc_auc 0.64283[0m
[93maverage test of epoch 12: loss -4.23531 acc 0.65789 roc_auc 0.46769 prc_auc 0.62089[0m
[92maverage training of epoch 13: loss -4.36065 acc 0.66667 roc_auc 0.45700 prc_auc 0.64360[0m
[93maverage test of epoch 13: loss -4.43120 acc 0.65789 roc_auc 0.52000 prc_auc 0.64365[0m
[92maverage training of epoch 14: loss -4.56704 acc 0.66667 roc_auc 0.48980 prc_auc 0.63820[0m
[93maverage test of epoch 14: loss -4.64180 acc 0.65789 roc_auc 0.50769 prc_auc 0.70714[0m
[92maverage training of epoch 15: loss -4.77304 acc 0.66667 roc_auc 0.45780 prc_auc 0.67784[0m
[93maverage test of epoch 15: loss -4.82058 acc 0.65789 roc_auc 0.46769 prc_auc 0.67509[0m
[92maverage training of epoch 16: loss -4.95123 acc 0.66667 roc_auc 0.49310 prc_auc 0.67256[0m
[93maverage test of epoch 16: loss -5.01782 acc 0.65789 roc_auc 0.65538 prc_auc 0.73286[0m
[92maverage training of epoch 17: loss -5.12172 acc 0.66667 roc_auc 0.44310 prc_auc 0.63499[0m
[93maverage test of epoch 17: loss -5.16119 acc 0.65789 roc_auc 0.50154 prc_auc 0.63945[0m
[92maverage training of epoch 18: loss -5.26577 acc 0.66667 roc_auc 0.44800 prc_auc 0.63927[0m
[93maverage test of epoch 18: loss -5.29910 acc 0.65789 roc_auc 0.51385 prc_auc 0.69264[0m
[92maverage training of epoch 19: loss -5.40259 acc 0.66667 roc_auc 0.48060 prc_auc 0.63707[0m
[93maverage test of epoch 19: loss -5.44005 acc 0.65789 roc_auc 0.49231 prc_auc 0.72206[0m
[92maverage training of epoch 20: loss -5.52958 acc 0.66667 roc_auc 0.39760 prc_auc 0.60715[0m
[93maverage test of epoch 20: loss -5.56071 acc 0.65789 roc_auc 0.68615 prc_auc 0.81863[0m
[92maverage training of epoch 21: loss -5.65804 acc 0.66667 roc_auc 0.45940 prc_auc 0.64208[0m
[93maverage test of epoch 21: loss -5.67813 acc 0.65789 roc_auc 0.51385 prc_auc 0.71785[0m
[92maverage training of epoch 22: loss -5.78092 acc 0.66667 roc_auc 0.49940 prc_auc 0.67343[0m
[93maverage test of epoch 22: loss -5.80211 acc 0.65789 roc_auc 0.49538 prc_auc 0.73553[0m
[92maverage training of epoch 23: loss -5.90011 acc 0.66667 roc_auc 0.46470 prc_auc 0.65118[0m
[93maverage test of epoch 23: loss -5.91527 acc 0.65789 roc_auc 0.43077 prc_auc 0.61146[0m
[92maverage training of epoch 24: loss -6.01322 acc 0.66667 roc_auc 0.45960 prc_auc 0.64658[0m
[93maverage test of epoch 24: loss -6.03329 acc 0.65789 roc_auc 0.38769 prc_auc 0.63164[0m
[92maverage training of epoch 25: loss -6.13208 acc 0.66667 roc_auc 0.48110 prc_auc 0.65559[0m
[93maverage test of epoch 25: loss -6.14334 acc 0.65789 roc_auc 0.41846 prc_auc 0.64286[0m
[92maverage training of epoch 26: loss -6.24207 acc 0.66667 roc_auc 0.52400 prc_auc 0.68833[0m
[93maverage test of epoch 26: loss -6.25805 acc 0.65789 roc_auc 0.50769 prc_auc 0.68394[0m
[92maverage training of epoch 27: loss -6.34883 acc 0.66667 roc_auc 0.40410 prc_auc 0.64581[0m
[93maverage test of epoch 27: loss -6.37024 acc 0.65789 roc_auc 0.59077 prc_auc 0.77549[0m
[92maverage training of epoch 28: loss -6.46123 acc 0.66667 roc_auc 0.43440 prc_auc 0.62870[0m
[93maverage test of epoch 28: loss -6.47604 acc 0.65789 roc_auc 0.45846 prc_auc 0.65075[0m
[92maverage training of epoch 29: loss -6.57116 acc 0.66667 roc_auc 0.47540 prc_auc 0.66276[0m
[93maverage test of epoch 29: loss -6.58235 acc 0.65789 roc_auc 0.35692 prc_auc 0.60001[0m
[92maverage training of epoch 30: loss -6.67946 acc 0.66667 roc_auc 0.46340 prc_auc 0.64939[0m
[93maverage test of epoch 30: loss -6.69529 acc 0.65789 roc_auc 0.38154 prc_auc 0.62995[0m
[92maverage training of epoch 31: loss -6.78653 acc 0.66667 roc_auc 0.46630 prc_auc 0.63489[0m
[93maverage test of epoch 31: loss -6.79849 acc 0.65789 roc_auc 0.55692 prc_auc 0.69619[0m
[92maverage training of epoch 32: loss -6.88992 acc 0.66667 roc_auc 0.48480 prc_auc 0.66596[0m
[93maverage test of epoch 32: loss -6.90305 acc 0.65789 roc_auc 0.64000 prc_auc 0.77623[0m
[92maverage training of epoch 33: loss -6.99611 acc 0.66667 roc_auc 0.44230 prc_auc 0.65296[0m
[93maverage test of epoch 33: loss -7.00555 acc 0.65789 roc_auc 0.53231 prc_auc 0.71987[0m
[92maverage training of epoch 34: loss -7.09973 acc 0.66667 roc_auc 0.41770 prc_auc 0.62467[0m
[93maverage test of epoch 34: loss -7.11095 acc 0.65789 roc_auc 0.52462 prc_auc 0.72723[0m
[92maverage training of epoch 35: loss -7.20309 acc 0.66667 roc_auc 0.49470 prc_auc 0.65235[0m
[93maverage test of epoch 35: loss -7.20982 acc 0.65789 roc_auc 0.44308 prc_auc 0.69261[0m
[92maverage training of epoch 36: loss -7.30749 acc 0.66667 roc_auc 0.46460 prc_auc 0.65719[0m
[93maverage test of epoch 36: loss -7.31895 acc 0.65789 roc_auc 0.48000 prc_auc 0.69157[0m
[92maverage training of epoch 37: loss -7.41160 acc 0.66667 roc_auc 0.44770 prc_auc 0.61465[0m
[93maverage test of epoch 37: loss -7.42178 acc 0.65789 roc_auc 0.40923 prc_auc 0.61915[0m
[92maverage training of epoch 38: loss -7.51844 acc 0.66667 roc_auc 0.46460 prc_auc 0.62936[0m
[93maverage test of epoch 38: loss -7.52283 acc 0.65789 roc_auc 0.46000 prc_auc 0.65235[0m
[92maverage training of epoch 39: loss -7.61724 acc 0.66667 roc_auc 0.42980 prc_auc 0.61591[0m
[93maverage test of epoch 39: loss -7.62405 acc 0.65789 roc_auc 0.52923 prc_auc 0.75581[0m
[92maverage training of epoch 40: loss -7.72001 acc 0.66667 roc_auc 0.44420 prc_auc 0.63219[0m
[93maverage test of epoch 40: loss -7.73196 acc 0.65789 roc_auc 0.62462 prc_auc 0.77688[0m
[92maverage training of epoch 41: loss -7.82292 acc 0.66667 roc_auc 0.43290 prc_auc 0.63491[0m
[93maverage test of epoch 41: loss -7.82895 acc 0.65789 roc_auc 0.36769 prc_auc 0.60562[0m
[92maverage training of epoch 42: loss -7.92560 acc 0.66667 roc_auc 0.44640 prc_auc 0.65430[0m
[93maverage test of epoch 42: loss -7.93203 acc 0.65789 roc_auc 0.51231 prc_auc 0.72138[0m
[92maverage training of epoch 43: loss -8.02686 acc 0.66667 roc_auc 0.47010 prc_auc 0.65473[0m
[93maverage test of epoch 43: loss -8.03440 acc 0.65789 roc_auc 0.65538 prc_auc 0.80481[0m
[92maverage training of epoch 44: loss -8.12732 acc 0.66667 roc_auc 0.44830 prc_auc 0.63423[0m
[93maverage test of epoch 44: loss -8.13554 acc 0.65789 roc_auc 0.67538 prc_auc 0.84961[0m
[92maverage training of epoch 45: loss -8.22957 acc 0.66667 roc_auc 0.45980 prc_auc 0.64817[0m
[93maverage test of epoch 45: loss -8.23734 acc 0.65789 roc_auc 0.39385 prc_auc 0.62780[0m
[92maverage training of epoch 46: loss -8.33143 acc 0.66667 roc_auc 0.47110 prc_auc 0.64672[0m
[93maverage test of epoch 46: loss -8.33952 acc 0.65789 roc_auc 0.64000 prc_auc 0.76575[0m
[92maverage training of epoch 47: loss -8.43304 acc 0.66667 roc_auc 0.44970 prc_auc 0.61541[0m
[93maverage test of epoch 47: loss -8.43836 acc 0.65789 roc_auc 0.60615 prc_auc 0.79714[0m
[92maverage training of epoch 48: loss -8.53513 acc 0.66667 roc_auc 0.44110 prc_auc 0.62938[0m
[93maverage test of epoch 48: loss -8.53763 acc 0.65789 roc_auc 0.45077 prc_auc 0.68895[0m
[92maverage training of epoch 49: loss -8.63512 acc 0.66667 roc_auc 0.47580 prc_auc 0.64421[0m
[93maverage test of epoch 49: loss -8.64259 acc 0.65789 roc_auc 0.52923 prc_auc 0.74273[0m
[92maverage training of epoch 50: loss -8.73609 acc 0.66667 roc_auc 0.41080 prc_auc 0.61169[0m
[93maverage test of epoch 50: loss -8.73872 acc 0.65789 roc_auc 0.50462 prc_auc 0.65166[0m
[92maverage training of epoch 51: loss -8.83680 acc 0.66667 roc_auc 0.43220 prc_auc 0.62804[0m
[93maverage test of epoch 51: loss -8.84114 acc 0.65789 roc_auc 0.50000 prc_auc 0.66437[0m
[92maverage training of epoch 52: loss -8.93674 acc 0.66667 roc_auc 0.42770 prc_auc 0.59918[0m
[93maverage test of epoch 52: loss -8.94094 acc 0.65789 roc_auc 0.58308 prc_auc 0.73222[0m
[92maverage training of epoch 53: loss -9.03694 acc 0.66667 roc_auc 0.42970 prc_auc 0.62632[0m
[93maverage test of epoch 53: loss -9.03902 acc 0.65789 roc_auc 0.68462 prc_auc 0.80510[0m
[92maverage training of epoch 54: loss -9.13768 acc 0.66667 roc_auc 0.42310 prc_auc 0.60230[0m
[93maverage test of epoch 54: loss -9.13929 acc 0.65789 roc_auc 0.43077 prc_auc 0.62782[0m
[92maverage training of epoch 55: loss -9.23781 acc 0.66667 roc_auc 0.43940 prc_auc 0.61035[0m
[93maverage test of epoch 55: loss -9.24113 acc 0.65789 roc_auc 0.66308 prc_auc 0.78365[0m
[92maverage training of epoch 56: loss -9.33911 acc 0.66667 roc_auc 0.42450 prc_auc 0.61684[0m
[93maverage test of epoch 56: loss -9.34055 acc 0.65789 roc_auc 0.44769 prc_auc 0.63962[0m
[92maverage training of epoch 57: loss -9.43888 acc 0.66667 roc_auc 0.46090 prc_auc 0.62299[0m
[93maverage test of epoch 57: loss -9.44054 acc 0.65789 roc_auc 0.55538 prc_auc 0.69521[0m
[92maverage training of epoch 58: loss -9.53880 acc 0.66667 roc_auc 0.42770 prc_auc 0.60428[0m
[93maverage test of epoch 58: loss -9.54004 acc 0.65789 roc_auc 0.28923 prc_auc 0.54853[0m
[92maverage training of epoch 59: loss -9.63970 acc 0.66667 roc_auc 0.41050 prc_auc 0.59821[0m
[93maverage test of epoch 59: loss -9.64068 acc 0.65789 roc_auc 0.54154 prc_auc 0.74731[0m
[92maverage training of epoch 60: loss -9.73950 acc 0.66667 roc_auc 0.43870 prc_auc 0.61971[0m
[93maverage test of epoch 60: loss -9.74079 acc 0.65789 roc_auc 0.57538 prc_auc 0.68721[0m
[92maverage training of epoch 61: loss -9.83956 acc 0.66667 roc_auc 0.41070 prc_auc 0.58357[0m
[93maverage test of epoch 61: loss -9.84018 acc 0.65789 roc_auc 0.57231 prc_auc 0.71806[0m
[92maverage training of epoch 62: loss -9.94008 acc 0.66667 roc_auc 0.43370 prc_auc 0.61473[0m
[93maverage test of epoch 62: loss -9.93961 acc 0.65789 roc_auc 0.53846 prc_auc 0.70439[0m
[92maverage training of epoch 63: loss -10.03921 acc 0.66667 roc_auc 0.46090 prc_auc 0.63847[0m
[93maverage test of epoch 63: loss -10.03890 acc 0.65789 roc_auc 0.64000 prc_auc 0.72915[0m
[92maverage training of epoch 64: loss -10.13963 acc 0.66667 roc_auc 0.41810 prc_auc 0.61032[0m
[93maverage test of epoch 64: loss -10.13946 acc 0.65789 roc_auc 0.46923 prc_auc 0.68873[0m
[92maverage training of epoch 65: loss -10.23922 acc 0.66667 roc_auc 0.41000 prc_auc 0.59096[0m
[93maverage test of epoch 65: loss -10.23881 acc 0.65789 roc_auc 0.46462 prc_auc 0.64679[0m
[92maverage training of epoch 66: loss -10.33951 acc 0.66667 roc_auc 0.43510 prc_auc 0.60821[0m
[93maverage test of epoch 66: loss -10.33780 acc 0.65789 roc_auc 0.59231 prc_auc 0.75199[0m
[92maverage training of epoch 67: loss -10.43955 acc 0.66667 roc_auc 0.42530 prc_auc 0.61047[0m
[93maverage test of epoch 67: loss -10.43745 acc 0.65789 roc_auc 0.48769 prc_auc 0.65104[0m
[92maverage training of epoch 68: loss -10.53918 acc 0.66667 roc_auc 0.45640 prc_auc 0.64320[0m
[93maverage test of epoch 68: loss -10.53697 acc 0.65789 roc_auc 0.51692 prc_auc 0.73336[0m
[92maverage training of epoch 69: loss -10.63878 acc 0.66667 roc_auc 0.42850 prc_auc 0.60413[0m
[93maverage test of epoch 69: loss -10.63663 acc 0.65789 roc_auc 0.45231 prc_auc 0.65012[0m
[92maverage training of epoch 70: loss -10.73878 acc 0.66667 roc_auc 0.42690 prc_auc 0.60395[0m
[93maverage test of epoch 70: loss -10.73672 acc 0.65789 roc_auc 0.44000 prc_auc 0.64132[0m
[92maverage training of epoch 71: loss -10.83797 acc 0.66667 roc_auc 0.43600 prc_auc 0.60792[0m
[93maverage test of epoch 71: loss -10.83627 acc 0.65789 roc_auc 0.59077 prc_auc 0.71951[0m
[92maverage training of epoch 72: loss -10.93813 acc 0.66667 roc_auc 0.40840 prc_auc 0.59908[0m
[93maverage test of epoch 72: loss -10.93439 acc 0.65789 roc_auc 0.64769 prc_auc 0.75768[0m
[92maverage training of epoch 73: loss -11.03803 acc 0.66667 roc_auc 0.42350 prc_auc 0.59799[0m
[93maverage test of epoch 73: loss -11.03460 acc 0.65789 roc_auc 0.39692 prc_auc 0.63076[0m
[92maverage training of epoch 74: loss -11.13762 acc 0.66667 roc_auc 0.42630 prc_auc 0.59581[0m
[93maverage test of epoch 74: loss -11.13392 acc 0.65789 roc_auc 0.46615 prc_auc 0.62433[0m
[92maverage training of epoch 75: loss -11.23738 acc 0.66667 roc_auc 0.42030 prc_auc 0.60674[0m
[93maverage test of epoch 75: loss -11.23385 acc 0.65789 roc_auc 0.57385 prc_auc 0.68960[0m
[92maverage training of epoch 76: loss -11.33666 acc 0.66667 roc_auc 0.43010 prc_auc 0.61226[0m
[93maverage test of epoch 76: loss -11.33284 acc 0.65789 roc_auc 0.46769 prc_auc 0.67571[0m
[92maverage training of epoch 77: loss -11.43657 acc 0.66667 roc_auc 0.41680 prc_auc 0.59931[0m
[93maverage test of epoch 77: loss -11.43205 acc 0.65789 roc_auc 0.35231 prc_auc 0.58839[0m
[92maverage training of epoch 78: loss -11.53623 acc 0.66667 roc_auc 0.41730 prc_auc 0.60464[0m
[93maverage test of epoch 78: loss -11.53165 acc 0.65789 roc_auc 0.59692 prc_auc 0.68013[0m
[92maverage training of epoch 79: loss -11.63585 acc 0.66667 roc_auc 0.44700 prc_auc 0.63572[0m
[93maverage test of epoch 79: loss -11.63082 acc 0.65789 roc_auc 0.58923 prc_auc 0.74320[0m
[92maverage training of epoch 80: loss -11.73525 acc 0.66667 roc_auc 0.41760 prc_auc 0.60366[0m
[93maverage test of epoch 80: loss -11.73002 acc 0.65789 roc_auc 0.60923 prc_auc 0.72168[0m
[92maverage training of epoch 81: loss -11.83494 acc 0.66667 roc_auc 0.42080 prc_auc 0.60539[0m
[93maverage test of epoch 81: loss -11.82894 acc 0.65789 roc_auc 0.48154 prc_auc 0.64957[0m
[92maverage training of epoch 82: loss -11.93449 acc 0.66667 roc_auc 0.42110 prc_auc 0.59754[0m
[93maverage test of epoch 82: loss -11.92848 acc 0.65789 roc_auc 0.51538 prc_auc 0.67162[0m
[92maverage training of epoch 83: loss -12.03406 acc 0.66667 roc_auc 0.41160 prc_auc 0.58822[0m
[93maverage test of epoch 83: loss -12.02789 acc 0.65789 roc_auc 0.66308 prc_auc 0.74238[0m
[92maverage training of epoch 84: loss -12.13385 acc 0.66667 roc_auc 0.43130 prc_auc 0.60969[0m
[93maverage test of epoch 84: loss -12.12742 acc 0.65789 roc_auc 0.46462 prc_auc 0.65924[0m
[92maverage training of epoch 85: loss -12.23330 acc 0.66667 roc_auc 0.41720 prc_auc 0.59890[0m
[93maverage test of epoch 85: loss -12.22634 acc 0.65789 roc_auc 0.54462 prc_auc 0.69356[0m
[92maverage training of epoch 86: loss -12.33268 acc 0.66667 roc_auc 0.41750 prc_auc 0.60014[0m
[93maverage test of epoch 86: loss -12.32528 acc 0.65789 roc_auc 0.49385 prc_auc 0.66290[0m
[92maverage training of epoch 87: loss -12.43236 acc 0.66667 roc_auc 0.42380 prc_auc 0.60804[0m
[93maverage test of epoch 87: loss -12.42522 acc 0.65789 roc_auc 0.43846 prc_auc 0.64413[0m
[92maverage training of epoch 88: loss -12.53176 acc 0.66667 roc_auc 0.43040 prc_auc 0.62665[0m
[93maverage test of epoch 88: loss -12.52421 acc 0.65789 roc_auc 0.57231 prc_auc 0.77071[0m
[92maverage training of epoch 89: loss -12.63134 acc 0.66667 roc_auc 0.42340 prc_auc 0.60315[0m
[93maverage test of epoch 89: loss -12.62302 acc 0.65789 roc_auc 0.53077 prc_auc 0.67269[0m
[92maverage training of epoch 90: loss -12.73112 acc 0.66667 roc_auc 0.42400 prc_auc 0.60803[0m
[93maverage test of epoch 90: loss -12.72285 acc 0.65789 roc_auc 0.30000 prc_auc 0.56854[0m
[92maverage training of epoch 91: loss -12.83059 acc 0.66667 roc_auc 0.43550 prc_auc 0.62577[0m
[93maverage test of epoch 91: loss -12.82186 acc 0.65789 roc_auc 0.46154 prc_auc 0.65015[0m
[92maverage training of epoch 92: loss -12.93004 acc 0.66667 roc_auc 0.42670 prc_auc 0.60199[0m
[93maverage test of epoch 92: loss -12.92129 acc 0.65789 roc_auc 0.61538 prc_auc 0.74950[0m
[92maverage training of epoch 93: loss -13.02947 acc 0.66667 roc_auc 0.41740 prc_auc 0.60737[0m
[93maverage test of epoch 93: loss -13.02042 acc 0.65789 roc_auc 0.44154 prc_auc 0.61709[0m
[92maverage training of epoch 94: loss -13.12907 acc 0.66667 roc_auc 0.42040 prc_auc 0.60949[0m
[93maverage test of epoch 94: loss -13.11936 acc 0.65789 roc_auc 0.46615 prc_auc 0.64327[0m
[92maverage training of epoch 95: loss -13.22838 acc 0.66667 roc_auc 0.43260 prc_auc 0.60622[0m
[93maverage test of epoch 95: loss -13.21881 acc 0.65789 roc_auc 0.43538 prc_auc 0.66735[0m
[92maverage training of epoch 96: loss -13.32798 acc 0.66667 roc_auc 0.41670 prc_auc 0.59927[0m
[93maverage test of epoch 96: loss -13.31775 acc 0.65789 roc_auc 0.37692 prc_auc 0.58786[0m
[92maverage training of epoch 97: loss -13.42758 acc 0.66667 roc_auc 0.42400 prc_auc 0.61201[0m
[93maverage test of epoch 97: loss -13.41702 acc 0.65789 roc_auc 0.52308 prc_auc 0.67871[0m
[92maverage training of epoch 98: loss -13.52693 acc 0.66667 roc_auc 0.42450 prc_auc 0.62201[0m
[93maverage test of epoch 98: loss -13.51642 acc 0.65789 roc_auc 0.62154 prc_auc 0.72123[0m
[92maverage training of epoch 99: loss -13.62646 acc 0.66667 roc_auc 0.42100 prc_auc 0.60168[0m
[93maverage test of epoch 99: loss -13.61535 acc 0.65789 roc_auc 0.59385 prc_auc 0.71240[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss 0.55051 acc 0.40667 roc_auc 0.49680 prc_auc 0.68453[0m
[93maverage test of epoch 0: loss 0.37334 acc 0.44737 roc_auc 0.33231 prc_auc 0.56029[0m
[92maverage training of epoch 1: loss 0.13306 acc 0.68667 roc_auc 0.50120 prc_auc 0.71016[0m
[93maverage test of epoch 1: loss -0.08117 acc 0.65789 roc_auc 0.55692 prc_auc 0.71623[0m
[92maverage training of epoch 2: loss -0.32451 acc 0.66667 roc_auc 0.46240 prc_auc 0.65181[0m
[93maverage test of epoch 2: loss -0.54924 acc 0.65789 roc_auc 0.65231 prc_auc 0.80468[0m
[92maverage training of epoch 3: loss -0.76226 acc 0.66667 roc_auc 0.49460 prc_auc 0.69120[0m
[93maverage test of epoch 3: loss -0.94800 acc 0.65789 roc_auc 0.67385 prc_auc 0.77270[0m
[92maverage training of epoch 4: loss -1.14009 acc 0.66667 roc_auc 0.52500 prc_auc 0.70845[0m
[93maverage test of epoch 4: loss -1.31330 acc 0.65789 roc_auc 0.57538 prc_auc 0.72006[0m
[92maverage training of epoch 5: loss -1.48784 acc 0.66667 roc_auc 0.52320 prc_auc 0.69119[0m
[93maverage test of epoch 5: loss -1.68569 acc 0.65789 roc_auc 0.76000 prc_auc 0.84381[0m
[92maverage training of epoch 6: loss -1.91493 acc 0.66667 roc_auc 0.49840 prc_auc 0.65143[0m
[93maverage test of epoch 6: loss -2.14578 acc 0.65789 roc_auc 0.67077 prc_auc 0.81047[0m
[92maverage training of epoch 7: loss -2.37557 acc 0.66667 roc_auc 0.46380 prc_auc 0.66122[0m
[93maverage test of epoch 7: loss -2.54666 acc 0.65789 roc_auc 0.55692 prc_auc 0.79359[0m
[92maverage training of epoch 8: loss -2.76487 acc 0.66667 roc_auc 0.41400 prc_auc 0.62027[0m
[93maverage test of epoch 8: loss -2.90310 acc 0.65789 roc_auc 0.33846 prc_auc 0.60280[0m
[92maverage training of epoch 9: loss -3.07553 acc 0.66667 roc_auc 0.46400 prc_auc 0.65689[0m
[93maverage test of epoch 9: loss -3.17848 acc 0.65789 roc_auc 0.36923 prc_auc 0.59739[0m
[92maverage training of epoch 10: loss -3.33529 acc 0.66667 roc_auc 0.45960 prc_auc 0.64486[0m
[93maverage test of epoch 10: loss -3.41552 acc 0.65789 roc_auc 0.52000 prc_auc 0.74574[0m
[92maverage training of epoch 11: loss -3.54640 acc 0.66667 roc_auc 0.50460 prc_auc 0.72009[0m
[93maverage test of epoch 11: loss -3.61860 acc 0.65789 roc_auc 0.46154 prc_auc 0.66927[0m
[92maverage training of epoch 12: loss -3.72704 acc 0.66667 roc_auc 0.51660 prc_auc 0.67646[0m
[93maverage test of epoch 12: loss -3.76707 acc 0.65789 roc_auc 0.63385 prc_auc 0.79901[0m
[92maverage training of epoch 13: loss -3.87995 acc 0.66667 roc_auc 0.43700 prc_auc 0.63360[0m
[93maverage test of epoch 13: loss -3.90606 acc 0.65789 roc_auc 0.58769 prc_auc 0.69715[0m
[92maverage training of epoch 14: loss -4.00926 acc 0.66667 roc_auc 0.46120 prc_auc 0.64610[0m
[93maverage test of epoch 14: loss -4.05080 acc 0.65789 roc_auc 0.45231 prc_auc 0.63417[0m
[92maverage training of epoch 15: loss -4.15808 acc 0.66667 roc_auc 0.58800 prc_auc 0.75565[0m
[93maverage test of epoch 15: loss -4.21006 acc 0.65789 roc_auc 0.48923 prc_auc 0.65015[0m
[92maverage training of epoch 16: loss -4.28579 acc 0.66667 roc_auc 0.46000 prc_auc 0.65965[0m
[93maverage test of epoch 16: loss -4.33516 acc 0.65789 roc_auc 0.36615 prc_auc 0.63651[0m
[92maverage training of epoch 17: loss -4.43150 acc 0.66667 roc_auc 0.48900 prc_auc 0.65745[0m
[93maverage test of epoch 17: loss -4.46518 acc 0.65789 roc_auc 0.50769 prc_auc 0.68781[0m
[92maverage training of epoch 18: loss -4.55744 acc 0.66667 roc_auc 0.43600 prc_auc 0.63639[0m
[93maverage test of epoch 18: loss -4.63954 acc 0.65789 roc_auc 0.71077 prc_auc 0.82790[0m
[92maverage training of epoch 19: loss -4.74731 acc 0.66667 roc_auc 0.42500 prc_auc 0.61792[0m
[93maverage test of epoch 19: loss -4.80622 acc 0.65789 roc_auc 0.58769 prc_auc 0.75419[0m
[92maverage training of epoch 20: loss -4.92507 acc 0.66667 roc_auc 0.42820 prc_auc 0.60607[0m
[93maverage test of epoch 20: loss -4.98461 acc 0.65789 roc_auc 0.40923 prc_auc 0.66115[0m
[92maverage training of epoch 21: loss -5.10654 acc 0.66667 roc_auc 0.44140 prc_auc 0.62303[0m
[93maverage test of epoch 21: loss -5.14622 acc 0.65789 roc_auc 0.51077 prc_auc 0.69553[0m
[92maverage training of epoch 22: loss -5.28030 acc 0.66667 roc_auc 0.57860 prc_auc 0.73596[0m
[93maverage test of epoch 22: loss -5.33940 acc 0.65789 roc_auc 0.53231 prc_auc 0.69494[0m
[92maverage training of epoch 23: loss -5.45009 acc 0.66667 roc_auc 0.44960 prc_auc 0.63901[0m
[93maverage test of epoch 23: loss -5.50428 acc 0.65789 roc_auc 0.59385 prc_auc 0.72167[0m
[92maverage training of epoch 24: loss -5.59845 acc 0.66667 roc_auc 0.49600 prc_auc 0.70406[0m
[93maverage test of epoch 24: loss -5.64490 acc 0.65789 roc_auc 0.65231 prc_auc 0.80923[0m
[92maverage training of epoch 25: loss -5.73055 acc 0.66667 roc_auc 0.44020 prc_auc 0.64042[0m
[93maverage test of epoch 25: loss -5.76507 acc 0.65789 roc_auc 0.42154 prc_auc 0.61946[0m
[92maverage training of epoch 26: loss -5.87394 acc 0.66667 roc_auc 0.52840 prc_auc 0.67510[0m
[93maverage test of epoch 26: loss -5.90450 acc 0.65789 roc_auc 0.42769 prc_auc 0.64122[0m
[92maverage training of epoch 27: loss -5.99159 acc 0.66667 roc_auc 0.46840 prc_auc 0.67230[0m
[93maverage test of epoch 27: loss -6.02889 acc 0.65789 roc_auc 0.54462 prc_auc 0.68141[0m
[92maverage training of epoch 28: loss -6.10741 acc 0.66667 roc_auc 0.46100 prc_auc 0.65059[0m
[93maverage test of epoch 28: loss -6.13102 acc 0.65789 roc_auc 0.52308 prc_auc 0.69169[0m
[92maverage training of epoch 29: loss -6.22086 acc 0.66667 roc_auc 0.49860 prc_auc 0.66060[0m
[93maverage test of epoch 29: loss -6.23647 acc 0.65789 roc_auc 0.46154 prc_auc 0.69638[0m
[92maverage training of epoch 30: loss -6.32990 acc 0.66667 roc_auc 0.48840 prc_auc 0.70821[0m
[93maverage test of epoch 30: loss -6.34958 acc 0.65789 roc_auc 0.42769 prc_auc 0.66848[0m
[92maverage training of epoch 31: loss -6.43782 acc 0.66667 roc_auc 0.52500 prc_auc 0.70444[0m
[93maverage test of epoch 31: loss -6.46595 acc 0.65789 roc_auc 0.46769 prc_auc 0.66100[0m
[92maverage training of epoch 32: loss -6.55009 acc 0.66667 roc_auc 0.51480 prc_auc 0.66604[0m
[93maverage test of epoch 32: loss -6.55830 acc 0.65789 roc_auc 0.53231 prc_auc 0.65336[0m
[92maverage training of epoch 33: loss -6.64515 acc 0.66667 roc_auc 0.46380 prc_auc 0.63840[0m
[93maverage test of epoch 33: loss -6.66214 acc 0.65789 roc_auc 0.31077 prc_auc 0.58450[0m
[92maverage training of epoch 34: loss -6.74475 acc 0.66667 roc_auc 0.43580 prc_auc 0.63802[0m
[93maverage test of epoch 34: loss -6.76984 acc 0.65789 roc_auc 0.48615 prc_auc 0.67956[0m
[92maverage training of epoch 35: loss -6.85482 acc 0.66667 roc_auc 0.51400 prc_auc 0.67153[0m
[93maverage test of epoch 35: loss -6.85768 acc 0.65789 roc_auc 0.44615 prc_auc 0.70874[0m
[92maverage training of epoch 36: loss -6.95792 acc 0.66667 roc_auc 0.48940 prc_auc 0.64629[0m
[93maverage test of epoch 36: loss -6.96051 acc 0.65789 roc_auc 0.38462 prc_auc 0.63565[0m
[92maverage training of epoch 37: loss -7.05087 acc 0.66667 roc_auc 0.44440 prc_auc 0.63671[0m
[93maverage test of epoch 37: loss -7.08580 acc 0.65789 roc_auc 0.68308 prc_auc 0.77670[0m
[92maverage training of epoch 38: loss -7.15266 acc 0.66667 roc_auc 0.47240 prc_auc 0.65981[0m
[93maverage test of epoch 38: loss -7.17111 acc 0.65789 roc_auc 0.60308 prc_auc 0.75591[0m
[92maverage training of epoch 39: loss -7.24924 acc 0.66667 roc_auc 0.47840 prc_auc 0.64814[0m
[93maverage test of epoch 39: loss -7.26278 acc 0.65789 roc_auc 0.44000 prc_auc 0.62719[0m
[92maverage training of epoch 40: loss -7.34851 acc 0.66667 roc_auc 0.50360 prc_auc 0.70322[0m
[93maverage test of epoch 40: loss -7.35912 acc 0.65789 roc_auc 0.51077 prc_auc 0.71743[0m
[92maverage training of epoch 41: loss -7.44780 acc 0.66667 roc_auc 0.52880 prc_auc 0.67790[0m
[93maverage test of epoch 41: loss -7.45883 acc 0.65789 roc_auc 0.46154 prc_auc 0.65934[0m
[92maverage training of epoch 42: loss -7.54430 acc 0.66667 roc_auc 0.44040 prc_auc 0.65196[0m
[93maverage test of epoch 42: loss -7.56787 acc 0.65789 roc_auc 0.75385 prc_auc 0.88152[0m
[92maverage training of epoch 43: loss -7.64472 acc 0.66667 roc_auc 0.48100 prc_auc 0.65074[0m
[93maverage test of epoch 43: loss -7.65698 acc 0.65789 roc_auc 0.39077 prc_auc 0.66254[0m
[92maverage training of epoch 44: loss -7.74520 acc 0.66667 roc_auc 0.46480 prc_auc 0.65030[0m
[93maverage test of epoch 44: loss -7.76134 acc 0.65789 roc_auc 0.45231 prc_auc 0.68553[0m
[92maverage training of epoch 45: loss -7.84627 acc 0.66667 roc_auc 0.47910 prc_auc 0.64729[0m
[93maverage test of epoch 45: loss -7.85797 acc 0.65789 roc_auc 0.48615 prc_auc 0.69379[0m
[92maverage training of epoch 46: loss -7.95106 acc 0.66667 roc_auc 0.57900 prc_auc 0.74037[0m
[93maverage test of epoch 46: loss -7.96078 acc 0.65789 roc_auc 0.44308 prc_auc 0.64944[0m
[92maverage training of epoch 47: loss -8.04804 acc 0.66667 roc_auc 0.49720 prc_auc 0.66492[0m
[93maverage test of epoch 47: loss -8.06459 acc 0.65789 roc_auc 0.50462 prc_auc 0.70872[0m
[92maverage training of epoch 48: loss -8.15076 acc 0.66667 roc_auc 0.49790 prc_auc 0.64542[0m
[93maverage test of epoch 48: loss -8.17196 acc 0.65789 roc_auc 0.55692 prc_auc 0.75295[0m
[92maverage training of epoch 49: loss -8.25593 acc 0.66667 roc_auc 0.47600 prc_auc 0.67708[0m
[93maverage test of epoch 49: loss -8.26608 acc 0.65789 roc_auc 0.37231 prc_auc 0.57334[0m
[92maverage training of epoch 50: loss -8.36303 acc 0.66667 roc_auc 0.54760 prc_auc 0.69390[0m
[93maverage test of epoch 50: loss -8.38633 acc 0.65789 roc_auc 0.67692 prc_auc 0.83674[0m
[92maverage training of epoch 51: loss -8.46189 acc 0.66667 roc_auc 0.46640 prc_auc 0.67358[0m
[93maverage test of epoch 51: loss -8.47443 acc 0.65789 roc_auc 0.38769 prc_auc 0.64455[0m
[92maverage training of epoch 52: loss -8.56525 acc 0.66667 roc_auc 0.42320 prc_auc 0.62737[0m
[93maverage test of epoch 52: loss -8.58840 acc 0.65789 roc_auc 0.52923 prc_auc 0.74587[0m
[92maverage training of epoch 53: loss -8.67860 acc 0.66667 roc_auc 0.52810 prc_auc 0.70953[0m
[93maverage test of epoch 53: loss -8.69775 acc 0.65789 roc_auc 0.46462 prc_auc 0.69690[0m
[92maverage training of epoch 54: loss -8.78278 acc 0.66667 roc_auc 0.44620 prc_auc 0.63821[0m
[93maverage test of epoch 54: loss -8.79128 acc 0.65789 roc_auc 0.23077 prc_auc 0.52191[0m
[92maverage training of epoch 55: loss -8.89055 acc 0.66667 roc_auc 0.47590 prc_auc 0.63989[0m
[93maverage test of epoch 55: loss -8.90960 acc 0.65789 roc_auc 0.52923 prc_auc 0.67792[0m
[92maverage training of epoch 56: loss -9.00172 acc 0.66667 roc_auc 0.54480 prc_auc 0.68936[0m
[93maverage test of epoch 56: loss -9.02011 acc 0.65789 roc_auc 0.43077 prc_auc 0.66263[0m
[92maverage training of epoch 57: loss -9.10786 acc 0.66667 roc_auc 0.49160 prc_auc 0.68681[0m
[93maverage test of epoch 57: loss -9.13054 acc 0.65789 roc_auc 0.58462 prc_auc 0.73133[0m
[92maverage training of epoch 58: loss -9.21410 acc 0.66667 roc_auc 0.48560 prc_auc 0.66205[0m
[93maverage test of epoch 58: loss -9.24146 acc 0.65789 roc_auc 0.72000 prc_auc 0.82532[0m
[92maverage training of epoch 59: loss -9.31901 acc 0.66667 roc_auc 0.40470 prc_auc 0.60806[0m
[93maverage test of epoch 59: loss -9.34933 acc 0.65789 roc_auc 0.59385 prc_auc 0.71968[0m
[92maverage training of epoch 60: loss -9.43051 acc 0.66667 roc_auc 0.52920 prc_auc 0.68612[0m
[93maverage test of epoch 60: loss -9.44885 acc 0.65789 roc_auc 0.39077 prc_auc 0.66399[0m
[92maverage training of epoch 61: loss -9.54246 acc 0.66667 roc_auc 0.55160 prc_auc 0.68609[0m
[93maverage test of epoch 61: loss -9.55709 acc 0.65789 roc_auc 0.47077 prc_auc 0.71510[0m
[92maverage training of epoch 62: loss -9.64728 acc 0.66667 roc_auc 0.40380 prc_auc 0.61381[0m
[93maverage test of epoch 62: loss -9.67195 acc 0.65789 roc_auc 0.60000 prc_auc 0.78137[0m
[92maverage training of epoch 63: loss -9.75914 acc 0.66667 roc_auc 0.59570 prc_auc 0.74501[0m
[93maverage test of epoch 63: loss -9.77286 acc 0.65789 roc_auc 0.45538 prc_auc 0.68845[0m
[92maverage training of epoch 64: loss -9.85995 acc 0.66667 roc_auc 0.39900 prc_auc 0.60969[0m
[93maverage test of epoch 64: loss -9.88221 acc 0.65789 roc_auc 0.63077 prc_auc 0.74438[0m
[92maverage training of epoch 65: loss -9.96609 acc 0.66667 roc_auc 0.44040 prc_auc 0.65608[0m
[93maverage test of epoch 65: loss -9.98384 acc 0.65789 roc_auc 0.52615 prc_auc 0.66441[0m
[92maverage training of epoch 66: loss -10.07438 acc 0.66667 roc_auc 0.46950 prc_auc 0.68740[0m
[93maverage test of epoch 66: loss -10.08563 acc 0.65789 roc_auc 0.61231 prc_auc 0.75308[0m
[92maverage training of epoch 67: loss -10.17735 acc 0.66667 roc_auc 0.42440 prc_auc 0.62538[0m
[93maverage test of epoch 67: loss -10.19414 acc 0.65789 roc_auc 0.55077 prc_auc 0.67294[0m
[92maverage training of epoch 68: loss -10.27932 acc 0.66667 roc_auc 0.43640 prc_auc 0.65797[0m
[93maverage test of epoch 68: loss -10.29749 acc 0.65789 roc_auc 0.66462 prc_auc 0.83456[0m
[92maverage training of epoch 69: loss -10.38351 acc 0.66667 roc_auc 0.44680 prc_auc 0.62461[0m
[93maverage test of epoch 69: loss -10.40223 acc 0.65789 roc_auc 0.44923 prc_auc 0.71235[0m
[92maverage training of epoch 70: loss -10.48835 acc 0.66667 roc_auc 0.47140 prc_auc 0.67732[0m
[93maverage test of epoch 70: loss -10.50150 acc 0.65789 roc_auc 0.60923 prc_auc 0.75469[0m
[92maverage training of epoch 71: loss -10.58965 acc 0.66667 roc_auc 0.35290 prc_auc 0.56924[0m
[93maverage test of epoch 71: loss -10.60953 acc 0.65789 roc_auc 0.57538 prc_auc 0.76253[0m
[92maverage training of epoch 72: loss -10.69186 acc 0.66667 roc_auc 0.38060 prc_auc 0.62369[0m
[93maverage test of epoch 72: loss -10.71336 acc 0.65789 roc_auc 0.72769 prc_auc 0.78442[0m
[92maverage training of epoch 73: loss -10.79765 acc 0.66667 roc_auc 0.40400 prc_auc 0.63411[0m
[93maverage test of epoch 73: loss -10.81209 acc 0.65789 roc_auc 0.54923 prc_auc 0.73974[0m
[92maverage training of epoch 74: loss -10.89989 acc 0.66667 roc_auc 0.40910 prc_auc 0.63735[0m
[93maverage test of epoch 74: loss -10.91366 acc 0.65789 roc_auc 0.53538 prc_auc 0.71461[0m
[92maverage training of epoch 75: loss -11.00103 acc 0.66667 roc_auc 0.42800 prc_auc 0.64192[0m
[93maverage test of epoch 75: loss -11.01408 acc 0.65789 roc_auc 0.41692 prc_auc 0.65848[0m
[92maverage training of epoch 76: loss -11.10286 acc 0.66667 roc_auc 0.30670 prc_auc 0.53928[0m
[93maverage test of epoch 76: loss -11.11649 acc 0.65789 roc_auc 0.58308 prc_auc 0.72176[0m
[92maverage training of epoch 77: loss -11.20576 acc 0.66667 roc_auc 0.40570 prc_auc 0.62858[0m
[93maverage test of epoch 77: loss -11.21572 acc 0.65789 roc_auc 0.41538 prc_auc 0.60171[0m
[92maverage training of epoch 78: loss -11.30751 acc 0.66667 roc_auc 0.44470 prc_auc 0.65246[0m
[93maverage test of epoch 78: loss -11.31987 acc 0.65789 roc_auc 0.53692 prc_auc 0.66871[0m
[92maverage training of epoch 79: loss -11.40791 acc 0.66667 roc_auc 0.42280 prc_auc 0.60618[0m
[93maverage test of epoch 79: loss -11.42153 acc 0.65789 roc_auc 0.51538 prc_auc 0.69224[0m
[92maverage training of epoch 80: loss -11.50940 acc 0.66667 roc_auc 0.42120 prc_auc 0.64438[0m
[93maverage test of epoch 80: loss -11.52185 acc 0.65789 roc_auc 0.49077 prc_auc 0.65533[0m
[92maverage training of epoch 81: loss -11.61223 acc 0.66667 roc_auc 0.47240 prc_auc 0.67851[0m
[93maverage test of epoch 81: loss -11.62372 acc 0.65789 roc_auc 0.45385 prc_auc 0.66516[0m
[92maverage training of epoch 82: loss -11.71174 acc 0.66667 roc_auc 0.41300 prc_auc 0.64017[0m
[93maverage test of epoch 82: loss -11.72270 acc 0.65789 roc_auc 0.44308 prc_auc 0.64589[0m
[92maverage training of epoch 83: loss -11.81301 acc 0.66667 roc_auc 0.39380 prc_auc 0.61364[0m
[93maverage test of epoch 83: loss -11.82446 acc 0.65789 roc_auc 0.47385 prc_auc 0.65706[0m
[92maverage training of epoch 84: loss -11.91377 acc 0.66667 roc_auc 0.43070 prc_auc 0.67292[0m
[93maverage test of epoch 84: loss -11.92455 acc 0.65789 roc_auc 0.44462 prc_auc 0.70536[0m
[92maverage training of epoch 85: loss -12.01474 acc 0.66667 roc_auc 0.42710 prc_auc 0.65477[0m
[93maverage test of epoch 85: loss -12.02464 acc 0.65789 roc_auc 0.41385 prc_auc 0.58328[0m
[92maverage training of epoch 86: loss -12.11552 acc 0.66667 roc_auc 0.38530 prc_auc 0.61952[0m
[93maverage test of epoch 86: loss -12.12617 acc 0.65789 roc_auc 0.67231 prc_auc 0.78854[0m
[92maverage training of epoch 87: loss -12.21604 acc 0.66667 roc_auc 0.42240 prc_auc 0.65791[0m
[93maverage test of epoch 87: loss -12.22590 acc 0.65789 roc_auc 0.47077 prc_auc 0.67558[0m
[92maverage training of epoch 88: loss -12.31667 acc 0.66667 roc_auc 0.40880 prc_auc 0.59888[0m
[93maverage test of epoch 88: loss -12.32540 acc 0.65789 roc_auc 0.35846 prc_auc 0.59612[0m
[92maverage training of epoch 89: loss -12.41659 acc 0.66667 roc_auc 0.37210 prc_auc 0.58240[0m
[93maverage test of epoch 89: loss -12.42514 acc 0.65789 roc_auc 0.52154 prc_auc 0.71628[0m
[92maverage training of epoch 90: loss -12.51667 acc 0.66667 roc_auc 0.40210 prc_auc 0.60465[0m
[93maverage test of epoch 90: loss -12.52392 acc 0.65789 roc_auc 0.45231 prc_auc 0.64067[0m
[92maverage training of epoch 91: loss -12.61722 acc 0.66667 roc_auc 0.38550 prc_auc 0.59358[0m
[93maverage test of epoch 91: loss -12.62650 acc 0.65789 roc_auc 0.40308 prc_auc 0.65533[0m
[92maverage training of epoch 92: loss -12.71603 acc 0.66667 roc_auc 0.38440 prc_auc 0.58287[0m
[93maverage test of epoch 92: loss -12.72509 acc 0.65789 roc_auc 0.44462 prc_auc 0.67212[0m
[92maverage training of epoch 93: loss -12.81746 acc 0.66667 roc_auc 0.41370 prc_auc 0.61273[0m
[93maverage test of epoch 93: loss -12.82573 acc 0.65789 roc_auc 0.55231 prc_auc 0.72118[0m
[92maverage training of epoch 94: loss -12.91750 acc 0.66667 roc_auc 0.40110 prc_auc 0.61572[0m
[93maverage test of epoch 94: loss -12.92442 acc 0.65789 roc_auc 0.49077 prc_auc 0.67853[0m
[92maverage training of epoch 95: loss -13.01764 acc 0.66667 roc_auc 0.37410 prc_auc 0.57620[0m
[93maverage test of epoch 95: loss -13.02486 acc 0.65789 roc_auc 0.33846 prc_auc 0.60165[0m
[92maverage training of epoch 96: loss -13.11811 acc 0.66667 roc_auc 0.38480 prc_auc 0.58304[0m
[93maverage test of epoch 96: loss -13.12488 acc 0.65789 roc_auc 0.36308 prc_auc 0.58724[0m
[92maverage training of epoch 97: loss -13.21762 acc 0.66667 roc_auc 0.41490 prc_auc 0.65300[0m
[93maverage test of epoch 97: loss -13.22406 acc 0.65789 roc_auc 0.42615 prc_auc 0.64389[0m
[92maverage training of epoch 98: loss -13.31778 acc 0.66667 roc_auc 0.37770 prc_auc 0.57361[0m
[93maverage test of epoch 98: loss -13.32335 acc 0.65789 roc_auc 0.19077 prc_auc 0.50629[0m
[92maverage training of epoch 99: loss -13.41784 acc 0.66667 roc_auc 0.38870 prc_auc 0.58821[0m
[93maverage test of epoch 99: loss -13.42275 acc 0.65789 roc_auc 0.45231 prc_auc 0.65025[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.06391 acc 0.33775 roc_auc 0.40941 prc_auc 0.61694[0m
[93maverage test of epoch 0: loss -0.15894 acc 0.32432 roc_auc 0.54000 prc_auc 0.71104[0m
[92maverage training of epoch 1: loss -0.24995 acc 0.33775 roc_auc 0.57216 prc_auc 0.73889[0m
[93maverage test of epoch 1: loss -0.33942 acc 0.35135 roc_auc 0.64667 prc_auc 0.83658[0m
[92maverage training of epoch 2: loss -0.39083 acc 0.34437 roc_auc 0.51137 prc_auc 0.69015[0m
[93maverage test of epoch 2: loss -0.47956 acc 0.35135 roc_auc 0.58667 prc_auc 0.74244[0m
[92maverage training of epoch 3: loss -0.52586 acc 0.39073 roc_auc 0.51196 prc_auc 0.68678[0m
[93maverage test of epoch 3: loss -0.58212 acc 0.45946 roc_auc 0.45000 prc_auc 0.69788[0m
[92maverage training of epoch 4: loss -0.64021 acc 0.52980 roc_auc 0.48490 prc_auc 0.67464[0m
[93maverage test of epoch 4: loss -0.72113 acc 0.75676 roc_auc 0.64667 prc_auc 0.79785[0m
[92maverage training of epoch 5: loss -0.77928 acc 0.65563 roc_auc 0.55922 prc_auc 0.69653[0m
[93maverage test of epoch 5: loss -0.82913 acc 0.67568 roc_auc 0.43667 prc_auc 0.68078[0m
[92maverage training of epoch 6: loss -0.90290 acc 0.66225 roc_auc 0.53176 prc_auc 0.70926[0m
[93maverage test of epoch 6: loss -1.03679 acc 0.67568 roc_auc 0.71667 prc_auc 0.83276[0m
[92maverage training of epoch 7: loss -1.04821 acc 0.66225 roc_auc 0.56118 prc_auc 0.73395[0m
[93maverage test of epoch 7: loss -1.15908 acc 0.67568 roc_auc 0.66333 prc_auc 0.80308[0m
[92maverage training of epoch 8: loss -1.21556 acc 0.66225 roc_auc 0.53863 prc_auc 0.70650[0m
[93maverage test of epoch 8: loss -1.32605 acc 0.67568 roc_auc 0.62333 prc_auc 0.81693[0m
[92maverage training of epoch 9: loss -1.40421 acc 0.66225 roc_auc 0.61196 prc_auc 0.72923[0m
[93maverage test of epoch 9: loss -1.48713 acc 0.67568 roc_auc 0.54667 prc_auc 0.74859[0m
[92maverage training of epoch 10: loss -1.57709 acc 0.66225 roc_auc 0.61941 prc_auc 0.77762[0m
[93maverage test of epoch 10: loss -1.69439 acc 0.67568 roc_auc 0.66667 prc_auc 0.80905[0m
[92maverage training of epoch 11: loss -1.70888 acc 0.66225 roc_auc 0.49333 prc_auc 0.66088[0m
[93maverage test of epoch 11: loss -1.82578 acc 0.67568 roc_auc 0.58667 prc_auc 0.78326[0m
[92maverage training of epoch 12: loss -1.85622 acc 0.66225 roc_auc 0.46941 prc_auc 0.64978[0m
[93maverage test of epoch 12: loss -1.98904 acc 0.67568 roc_auc 0.48667 prc_auc 0.74551[0m
[92maverage training of epoch 13: loss -2.04359 acc 0.66225 roc_auc 0.56863 prc_auc 0.72501[0m
[93maverage test of epoch 13: loss -2.11572 acc 0.67568 roc_auc 0.38333 prc_auc 0.61354[0m
[92maverage training of epoch 14: loss -2.16752 acc 0.66225 roc_auc 0.52255 prc_auc 0.68137[0m
[93maverage test of epoch 14: loss -2.27939 acc 0.67568 roc_auc 0.46000 prc_auc 0.68429[0m
[92maverage training of epoch 15: loss -2.33394 acc 0.66225 roc_auc 0.63922 prc_auc 0.75975[0m
[93maverage test of epoch 15: loss -2.44864 acc 0.67568 roc_auc 0.48000 prc_auc 0.71045[0m
[92maverage training of epoch 16: loss -2.45874 acc 0.66225 roc_auc 0.55569 prc_auc 0.74117[0m
[93maverage test of epoch 16: loss -2.60753 acc 0.67568 roc_auc 0.72667 prc_auc 0.87041[0m
[92maverage training of epoch 17: loss -2.60432 acc 0.66225 roc_auc 0.59490 prc_auc 0.73844[0m
[93maverage test of epoch 17: loss -2.76101 acc 0.67568 roc_auc 0.74000 prc_auc 0.86902[0m
[92maverage training of epoch 18: loss -2.75450 acc 0.66225 roc_auc 0.70118 prc_auc 0.81069[0m
[93maverage test of epoch 18: loss -2.91188 acc 0.67568 roc_auc 0.79333 prc_auc 0.89405[0m
[92maverage training of epoch 19: loss -2.89102 acc 0.66225 roc_auc 0.65804 prc_auc 0.81560[0m
[93maverage test of epoch 19: loss -3.03710 acc 0.67568 roc_auc 0.73333 prc_auc 0.86517[0m
[92maverage training of epoch 20: loss -3.06227 acc 0.66225 roc_auc 0.75922 prc_auc 0.83374[0m
[93maverage test of epoch 20: loss -3.19237 acc 0.67568 roc_auc 0.74667 prc_auc 0.83881[0m
[92maverage training of epoch 21: loss -3.21424 acc 0.66225 roc_auc 0.81216 prc_auc 0.89844[0m
[93maverage test of epoch 21: loss -3.37410 acc 0.67568 roc_auc 0.80000 prc_auc 0.89659[0m
[92maverage training of epoch 22: loss -3.39708 acc 0.66225 roc_auc 0.83039 prc_auc 0.88679[0m
[93maverage test of epoch 22: loss -3.55860 acc 0.67568 roc_auc 0.81333 prc_auc 0.90354[0m
[92maverage training of epoch 23: loss -3.58166 acc 0.66225 roc_auc 0.84451 prc_auc 0.91688[0m
[93maverage test of epoch 23: loss -3.75498 acc 0.67568 roc_auc 0.87667 prc_auc 0.93493[0m
[92maverage training of epoch 24: loss -3.77159 acc 0.66225 roc_auc 0.87490 prc_auc 0.93386[0m
[93maverage test of epoch 24: loss -3.82101 acc 0.67568 roc_auc 0.79000 prc_auc 0.86864[0m
[92maverage training of epoch 25: loss -3.97916 acc 0.66225 roc_auc 0.88863 prc_auc 0.93732[0m
[93maverage test of epoch 25: loss -4.03385 acc 0.67568 roc_auc 0.81333 prc_auc 0.88891[0m
[92maverage training of epoch 26: loss -4.13693 acc 0.67550 roc_auc 0.89314 prc_auc 0.94900[0m
[93maverage test of epoch 26: loss -4.21280 acc 0.67568 roc_auc 0.89667 prc_auc 0.95748[0m
[92maverage training of epoch 27: loss -4.36224 acc 0.71523 roc_auc 0.91824 prc_auc 0.95904[0m
[93maverage test of epoch 27: loss -4.42839 acc 0.78378 roc_auc 0.86667 prc_auc 0.93327[0m
[92maverage training of epoch 28: loss -4.55523 acc 0.72848 roc_auc 0.92137 prc_auc 0.96289[0m
[93maverage test of epoch 28: loss -4.50705 acc 0.75676 roc_auc 0.82000 prc_auc 0.88854[0m
[92maverage training of epoch 29: loss -4.73070 acc 0.80795 roc_auc 0.94059 prc_auc 0.97370[0m
[93maverage test of epoch 29: loss -4.72190 acc 0.75676 roc_auc 0.83667 prc_auc 0.91223[0m
[92maverage training of epoch 30: loss -4.86717 acc 0.82119 roc_auc 0.91333 prc_auc 0.94494[0m
[93maverage test of epoch 30: loss -4.89832 acc 0.78378 roc_auc 0.87333 prc_auc 0.93960[0m
[92maverage training of epoch 31: loss -5.01432 acc 0.82119 roc_auc 0.93137 prc_auc 0.96849[0m
[93maverage test of epoch 31: loss -4.95881 acc 0.78378 roc_auc 0.82333 prc_auc 0.89221[0m
[92maverage training of epoch 32: loss -5.11546 acc 0.83444 roc_auc 0.92696 prc_auc 0.96511[0m
[93maverage test of epoch 32: loss -5.10459 acc 0.78378 roc_auc 0.86333 prc_auc 0.92796[0m
[92maverage training of epoch 33: loss -5.25179 acc 0.84106 roc_auc 0.93176 prc_auc 0.96923[0m
[93maverage test of epoch 33: loss -5.23207 acc 0.81081 roc_auc 0.89000 prc_auc 0.94735[0m
[92maverage training of epoch 34: loss -5.36476 acc 0.85430 roc_auc 0.93294 prc_auc 0.96935[0m
[93maverage test of epoch 34: loss -5.38079 acc 0.81081 roc_auc 0.84667 prc_auc 0.89883[0m
[92maverage training of epoch 35: loss -5.44945 acc 0.83444 roc_auc 0.92471 prc_auc 0.96433[0m
[93maverage test of epoch 35: loss -5.37721 acc 0.81081 roc_auc 0.84333 prc_auc 0.89482[0m
[92maverage training of epoch 36: loss -5.60036 acc 0.86093 roc_auc 0.92510 prc_auc 0.96524[0m
[93maverage test of epoch 36: loss -5.52257 acc 0.78378 roc_auc 0.83667 prc_auc 0.90087[0m
[92maverage training of epoch 37: loss -5.69596 acc 0.86755 roc_auc 0.93706 prc_auc 0.97125[0m
[93maverage test of epoch 37: loss -5.59530 acc 0.81081 roc_auc 0.85000 prc_auc 0.91280[0m
[92maverage training of epoch 38: loss -5.78227 acc 0.86093 roc_auc 0.92627 prc_auc 0.96903[0m
[93maverage test of epoch 38: loss -5.75453 acc 0.83784 roc_auc 0.87000 prc_auc 0.93917[0mUsing backend: pytorch

[92maverage training of epoch 39: loss -5.92415 acc 0.85430 roc_auc 0.93784 prc_auc 0.97217[0m
[93maverage test of epoch 39: loss -5.89467 acc 0.86486 roc_auc 0.84667 prc_auc 0.90705[0m
[92maverage training of epoch 40: loss -6.03996 acc 0.86755 roc_auc 0.93059 prc_auc 0.96737[0m
[93maverage test of epoch 40: loss -5.94070 acc 0.86486 roc_auc 0.82667 prc_auc 0.90052[0m
[92maverage training of epoch 41: loss -6.15325 acc 0.86093 roc_auc 0.94000 prc_auc 0.97300[0m
[93maverage test of epoch 41: loss -6.12998 acc 0.86486 roc_auc 0.81667 prc_auc 0.87040[0m
[92maverage training of epoch 42: loss -6.27022 acc 0.87417 roc_auc 0.93549 prc_auc 0.97135[0m
[93maverage test of epoch 42: loss -6.14862 acc 0.86486 roc_auc 0.84667 prc_auc 0.90350[0m
[92maverage training of epoch 43: loss -6.37443 acc 0.87417 roc_auc 0.93255 prc_auc 0.97217[0m
[93maverage test of epoch 43: loss -6.29771 acc 0.83784 roc_auc 0.85333 prc_auc 0.92528[0m
[92maverage training of epoch 44: loss -6.55703 acc 0.88079 roc_auc 0.94686 prc_auc 0.97699[0m
[93maverage test of epoch 44: loss -6.42337 acc 0.81081 roc_auc 0.83333 prc_auc 0.90468[0m
[92maverage training of epoch 45: loss -6.57188 acc 0.87417 roc_auc 0.93353 prc_auc 0.96924[0m
[93maverage test of epoch 45: loss -6.51354 acc 0.83784 roc_auc 0.88667 prc_auc 0.94958[0m
[92maverage training of epoch 46: loss -6.72303 acc 0.88079 roc_auc 0.94000 prc_auc 0.97537[0m
[93maverage test of epoch 46: loss -6.61895 acc 0.83784 roc_auc 0.87333 prc_auc 0.93519[0m
[92maverage training of epoch 47: loss -6.85400 acc 0.87417 roc_auc 0.94784 prc_auc 0.97727[0m
[93maverage test of epoch 47: loss -6.77285 acc 0.86486 roc_auc 0.90333 prc_auc 0.95382[0m
[92maverage training of epoch 48: loss -6.94015 acc 0.89404 roc_auc 0.94431 prc_auc 0.97679[0m
[93maverage test of epoch 48: loss -6.78954 acc 0.83784 roc_auc 0.84333 prc_auc 0.91068[0m
[92maverage training of epoch 49: loss -7.01316 acc 0.86755 roc_auc 0.94647 prc_auc 0.97608[0m
[93maverage test of epoch 49: loss -6.87222 acc 0.86486 roc_auc 0.84333 prc_auc 0.91933[0m
[92maverage training of epoch 50: loss -7.17370 acc 0.88742 roc_auc 0.94902 prc_auc 0.97775[0m
[93maverage test of epoch 50: loss -6.85824 acc 0.83784 roc_auc 0.78000 prc_auc 0.83158[0m
[92maverage training of epoch 51: loss -7.28635 acc 0.88742 roc_auc 0.94176 prc_auc 0.97705[0m
[93maverage test of epoch 51: loss -7.08639 acc 0.81081 roc_auc 0.86167 prc_auc 0.92586[0m
[92maverage training of epoch 52: loss -7.31698 acc 0.88079 roc_auc 0.94941 prc_auc 0.97865[0m
[93maverage test of epoch 52: loss -7.18656 acc 0.83784 roc_auc 0.85667 prc_auc 0.90413[0m
[92maverage training of epoch 53: loss -7.49856 acc 0.90066 roc_auc 0.95667 prc_auc 0.98070[0m
[93maverage test of epoch 53: loss -7.22910 acc 0.81081 roc_auc 0.84667 prc_auc 0.91304[0m
[92maverage training of epoch 54: loss -7.61084 acc 0.89404 roc_auc 0.94667 prc_auc 0.97830[0m
[93maverage test of epoch 54: loss -7.34881 acc 0.81081 roc_auc 0.85833 prc_auc 0.92541[0m
[92maverage training of epoch 55: loss -7.69464 acc 0.88079 roc_auc 0.94529 prc_auc 0.97660[0m
[93maverage test of epoch 55: loss -7.29644 acc 0.78378 roc_auc 0.83000 prc_auc 0.90120[0m
[92maverage training of epoch 56: loss -7.74600 acc 0.88742 roc_auc 0.93902 prc_auc 0.97493[0m
[93maverage test of epoch 56: loss -7.51523 acc 0.81081 roc_auc 0.83833 prc_auc 0.91333[0m
[92maverage training of epoch 57: loss -7.71712 acc 0.86755 roc_auc 0.94098 prc_auc 0.97545[0m
[93maverage test of epoch 57: loss -7.67498 acc 0.86486 roc_auc 0.85667 prc_auc 0.91608[0m
[92maverage training of epoch 58: loss -7.87312 acc 0.88079 roc_auc 0.94157 prc_auc 0.97195[0m
[93maverage test of epoch 58: loss -7.62726 acc 0.81081 roc_auc 0.76500 prc_auc 0.79365[0m
[92maverage training of epoch 59: loss -7.96969 acc 0.88742 roc_auc 0.92157 prc_auc 0.96090[0m
[93maverage test of epoch 59: loss -7.64912 acc 0.81081 roc_auc 0.77000 prc_auc 0.84587[0m
[92maverage training of epoch 60: loss -8.13299 acc 0.88079 roc_auc 0.94186 prc_auc 0.97128[0m
[93maverage test of epoch 60: loss -7.74059 acc 0.78378 roc_auc 0.82833 prc_auc 0.88815[0m
[92maverage training of epoch 61: loss -8.25432 acc 0.90066 roc_auc 0.95235 prc_auc 0.97943[0m
[93maverage test of epoch 61: loss -7.85207 acc 0.78378 roc_auc 0.88000 prc_auc 0.93948[0m
[92maverage training of epoch 62: loss -8.39276 acc 0.90728 roc_auc 0.94765 prc_auc 0.97857[0m
[93maverage test of epoch 62: loss -7.78667 acc 0.81081 roc_auc 0.81000 prc_auc 0.90444[0m
[92maverage training of epoch 63: loss -8.42108 acc 0.89404 roc_auc 0.94824 prc_auc 0.97797[0m
[93maverage test of epoch 63: loss -8.18710 acc 0.81081 roc_auc 0.82833 prc_auc 0.89175[0m
[92maverage training of epoch 64: loss -8.50856 acc 0.89404 roc_auc 0.92363 prc_auc 0.96312[0m
[93maverage test of epoch 64: loss -7.70091 acc 0.75676 roc_auc 0.82833 prc_auc 0.91377[0m
[92maverage training of epoch 65: loss -8.47874 acc 0.87417 roc_auc 0.93961 prc_auc 0.97484[0m
[93maverage test of epoch 65: loss -8.24090 acc 0.78378 roc_auc 0.81667 prc_auc 0.85698[0m
[92maverage training of epoch 66: loss -8.55793 acc 0.88079 roc_auc 0.93843 prc_auc 0.97411[0m
[93maverage test of epoch 66: loss -8.44283 acc 0.83784 roc_auc 0.85000 prc_auc 0.91378[0m
[92maverage training of epoch 67: loss -8.60805 acc 0.87417 roc_auc 0.93578 prc_auc 0.97290[0m
[93maverage test of epoch 67: loss -8.54720 acc 0.83784 roc_auc 0.77167 prc_auc 0.81116[0m
[92maverage training of epoch 68: loss -8.83936 acc 0.88742 roc_auc 0.94127 prc_auc 0.97503[0m
[93maverage test of epoch 68: loss -8.45193 acc 0.78378 roc_auc 0.82333 prc_auc 0.88824[0m
[92maverage training of epoch 69: loss -8.85299 acc 0.88079 roc_auc 0.94431 prc_auc 0.97565[0m
[93maverage test of epoch 69: loss -8.64783 acc 0.81081 roc_auc 0.76833 prc_auc 0.83407[0m
[92maverage training of epoch 70: loss -9.14052 acc 0.89404 roc_auc 0.93549 prc_auc 0.97213[0m
[93maverage test of epoch 70: loss -8.27446 acc 0.78378 roc_auc 0.81667 prc_auc 0.87400[0m
[92maverage training of epoch 71: loss -9.13617 acc 0.88742 roc_auc 0.94676 prc_auc 0.97637[0m
[93maverage test of epoch 71: loss -8.79398 acc 0.81081 roc_auc 0.86833 prc_auc 0.93267[0m
[92maverage training of epoch 72: loss -9.21584 acc 0.88079 roc_auc 0.94794 prc_auc 0.97916[0m
[93maverage test of epoch 72: loss -8.77889 acc 0.81081 roc_auc 0.84667 prc_auc 0.92383[0m
[92maverage training of epoch 73: loss -9.05940 acc 0.86093 roc_auc 0.93206 prc_auc 0.96638[0m
[93maverage test of epoch 73: loss -8.77544 acc 0.78378 roc_auc 0.84333 prc_auc 0.90575[0m
[92maverage training of epoch 74: loss -9.37795 acc 0.88079 roc_auc 0.93020 prc_auc 0.97084[0m
[93maverage test of epoch 74: loss -8.95164 acc 0.78378 roc_auc 0.82500 prc_auc 0.90669[0m
[92maverage training of epoch 75: loss -9.44252 acc 0.88079 roc_auc 0.94588 prc_auc 0.97690[0m
[93maverage test of epoch 75: loss -9.25250 acc 0.83784 roc_auc 0.83667 prc_auc 0.91344[0m
[92maverage training of epoch 76: loss -9.41900 acc 0.86755 roc_auc 0.92961 prc_auc 0.96779[0m
[93maverage test of epoch 76: loss -9.17981 acc 0.81081 roc_auc 0.86000 prc_auc 0.93535[0m
[92maverage training of epoch 77: loss -9.57269 acc 0.89404 roc_auc 0.93451 prc_auc 0.97348[0m
[93maverage test of epoch 77: loss -9.26403 acc 0.83784 roc_auc 0.81167 prc_auc 0.87610[0m
[92maverage training of epoch 78: loss -9.70733 acc 0.87417 roc_auc 0.93980 prc_auc 0.97593[0m
[93maverage test of epoch 78: loss -9.49179 acc 0.83784 roc_auc 0.83333 prc_auc 0.88950[0m
[92maverage training of epoch 79: loss -9.72014 acc 0.86755 roc_auc 0.92451 prc_auc 0.96250[0m
[93maverage test of epoch 79: loss -9.47497 acc 0.83784 roc_auc 0.83000 prc_auc 0.90329[0m
[92maverage training of epoch 80: loss -9.85411 acc 0.88079 roc_auc 0.93804 prc_auc 0.97346[0m
[93maverage test of epoch 80: loss -9.45423 acc 0.81081 roc_auc 0.77667 prc_auc 0.83848[0m
[92maverage training of epoch 81: loss -9.93333 acc 0.87417 roc_auc 0.92255 prc_auc 0.96568[0m
[93maverage test of epoch 81: loss -9.79276 acc 0.83784 roc_auc 0.86833 prc_auc 0.93108[0m
[92maverage training of epoch 82: loss -10.17849 acc 0.90728 roc_auc 0.92833 prc_auc 0.95906[0m
[93maverage test of epoch 82: loss -9.54359 acc 0.78378 roc_auc 0.80500 prc_auc 0.87612[0m
[92maverage training of epoch 83: loss -10.06759 acc 0.86093 roc_auc 0.93510 prc_auc 0.97240[0m
[93maverage test of epoch 83: loss -9.10637 acc 0.75676 roc_auc 0.83333 prc_auc 0.92625[0m
[92maverage training of epoch 84: loss -10.17388 acc 0.87417 roc_auc 0.93471 prc_auc 0.97159[0m
[93maverage test of epoch 84: loss -9.71206 acc 0.78378 roc_auc 0.80167 prc_auc 0.85529[0m
[92maverage training of epoch 85: loss -10.53316 acc 0.90066 roc_auc 0.94853 prc_auc 0.97686[0m
[93maverage test of epoch 85: loss -9.88093 acc 0.81081 roc_auc 0.84667 prc_auc 0.92279[0m
[92maverage training of epoch 86: loss -10.36168 acc 0.86755 roc_auc 0.94020 prc_auc 0.97443[0m
[93maverage test of epoch 86: loss -10.07155 acc 0.78378 roc_auc 0.85000 prc_auc 0.90113[0m
[92maverage training of epoch 87: loss -10.60266 acc 0.88742 roc_auc 0.94216 prc_auc 0.97621[0m
[93maverage test of epoch 87: loss -10.24908 acc 0.81081 roc_auc 0.81833 prc_auc 0.89288[0m
[92maverage training of epoch 88: loss -10.79394 acc 0.89404 roc_auc 0.93941 prc_auc 0.97058[0m
[93maverage test of epoch 88: loss -10.38255 acc 0.83784 roc_auc 0.82167 prc_auc 0.89567[0m
[92maverage training of epoch 89: loss -10.63053 acc 0.87417 roc_auc 0.94490 prc_auc 0.97468[0m
[93maverage test of epoch 89: loss -10.36949 acc 0.81081 roc_auc 0.77000 prc_auc 0.82351[0m
[92maverage training of epoch 90: loss -10.82369 acc 0.86755 roc_auc 0.94902 prc_auc 0.97906[0m
[93maverage test of epoch 90: loss -9.91169 acc 0.78378 roc_auc 0.78000 prc_auc 0.82807[0m
[92maverage training of epoch 91: loss -10.90534 acc 0.87417 roc_auc 0.94951 prc_auc 0.97840[0m
[93maverage test of epoch 91: loss -10.32774 acc 0.78378 roc_auc 0.86833 prc_auc 0.94285[0m
[92maverage training of epoch 92: loss -10.93881 acc 0.87417 roc_auc 0.94549 prc_auc 0.97606[0m
[93maverage test of epoch 92: loss -10.64369 acc 0.81081 roc_auc 0.79000 prc_auc 0.82638[0m
[92maverage training of epoch 93: loss -10.95752 acc 0.86093 roc_auc 0.93667 prc_auc 0.96869[0m
[93maverage test of epoch 93: loss -10.80268 acc 0.83784 roc_auc 0.79333 prc_auc 0.85421[0m
[92maverage training of epoch 94: loss -10.96068 acc 0.84768 roc_auc 0.93137 prc_auc 0.96788[0m
[93maverage test of epoch 94: loss -10.70606 acc 0.78378 roc_auc 0.86833 prc_auc 0.92778[0m
[92maverage training of epoch 95: loss -11.20875 acc 0.86093 roc_auc 0.92676 prc_auc 0.95083[0m
[93maverage test of epoch 95: loss -10.85733 acc 0.81081 roc_auc 0.84000 prc_auc 0.90625[0m
[92maverage training of epoch 96: loss -11.34076 acc 0.88079 roc_auc 0.94235 prc_auc 0.96150[0m
[93maverage test of epoch 96: loss -10.96542 acc 0.81081 roc_auc 0.87167 prc_auc 0.92315[0m
[92maverage training of epoch 97: loss -11.03889 acc 0.83444 roc_auc 0.92980 prc_auc 0.96968[0m
[93maverage test of epoch 97: loss -10.75834 acc 0.78378 roc_auc 0.86667 prc_auc 0.91778[0m
[92maverage training of epoch 98: loss -11.50019 acc 0.86755 roc_auc 0.92627 prc_auc 0.95679[0m
[93maverage test of epoch 98: loss -10.99562 acc 0.78378 roc_auc 0.82167 prc_auc 0.87844[0m
[92maverage training of epoch 99: loss -11.59982 acc 0.87417 roc_auc 0.95578 prc_auc 0.98051[0m
[93maverage test of epoch 99: loss -11.29958 acc 0.83784 roc_auc 0.82000 prc_auc 0.86564[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss 0.47924 acc 0.42384 roc_auc 0.39255 prc_auc 0.57623[0m
[93maverage test of epoch 0: loss 0.11937 acc 0.70270 roc_auc 0.61333 prc_auc 0.82338[0m
[92maverage training of epoch 1: loss -0.16391 acc 0.66225 roc_auc 0.45314 prc_auc 0.64567[0m
[93maverage test of epoch 1: loss -0.44332 acc 0.67568 roc_auc 0.53333 prc_auc 0.70910[0m
[92maverage training of epoch 2: loss -0.64865 acc 0.66225 roc_auc 0.43078 prc_auc 0.62652[0m
[93maverage test of epoch 2: loss -0.82439 acc 0.67568 roc_auc 0.46667 prc_auc 0.66774[0m
[92maverage training of epoch 3: loss -1.01504 acc 0.66225 roc_auc 0.51451 prc_auc 0.70610[0m
[93maverage test of epoch 3: loss -1.15698 acc 0.67568 roc_auc 0.46667 prc_auc 0.66891[0m
[92maverage training of epoch 4: loss -1.27369 acc 0.66225 roc_auc 0.51490 prc_auc 0.67403[0m
[93maverage test of epoch 4: loss -1.39699 acc 0.67568 roc_auc 0.50667 prc_auc 0.70366[0m
[92maverage training of epoch 5: loss -1.48052 acc 0.66225 roc_auc 0.50588 prc_auc 0.68402[0m
[93maverage test of epoch 5: loss -1.60467 acc 0.67568 roc_auc 0.62667 prc_auc 0.81425[0m
[92maverage training of epoch 6: loss -1.65878 acc 0.66225 roc_auc 0.40725 prc_auc 0.59922[0m
[93maverage test of epoch 6: loss -1.80168 acc 0.67568 roc_auc 0.77667 prc_auc 0.85532[0m
[92maverage training of epoch 7: loss -1.84372 acc 0.66225 roc_auc 0.50196 prc_auc 0.69204[0m
[93maverage test of epoch 7: loss -1.97341 acc 0.67568 roc_auc 0.56000 prc_auc 0.73271[0m
[92maverage training of epoch 8: loss -2.03095 acc 0.66225 roc_auc 0.43725 prc_auc 0.64781[0m
[93maverage test of epoch 8: loss -2.15207 acc 0.67568 roc_auc 0.32333 prc_auc 0.59659[0m
[92maverage training of epoch 9: loss -2.22828 acc 0.66225 roc_auc 0.49235 prc_auc 0.66633[0m
[93maverage test of epoch 9: loss -2.37536 acc 0.67568 roc_auc 0.54667 prc_auc 0.78125[0m
[92maverage training of epoch 10: loss -2.42434 acc 0.66225 roc_auc 0.49441 prc_auc 0.67127[0m
[93maverage test of epoch 10: loss -2.57512 acc 0.67568 roc_auc 0.64333 prc_auc 0.81870[0m
[92maverage training of epoch 11: loss -2.61490 acc 0.66225 roc_auc 0.43549 prc_auc 0.64241[0m
[93maverage test of epoch 11: loss -2.78006 acc 0.67568 roc_auc 0.81000 prc_auc 0.88343[0m
[92maverage training of epoch 12: loss -2.79616 acc 0.66225 roc_auc 0.54157 prc_auc 0.71270[0m
[93maverage test of epoch 12: loss -2.93859 acc 0.67568 roc_auc 0.70667 prc_auc 0.81682[0m
[92maverage training of epoch 13: loss -2.96957 acc 0.66225 roc_auc 0.42941 prc_auc 0.61607[0m
[93maverage test of epoch 13: loss -3.08824 acc 0.67568 roc_auc 0.53333 prc_auc 0.73797[0m
[92maverage training of epoch 14: loss -3.13039 acc 0.66225 roc_auc 0.48392 prc_auc 0.66030[0m
[93maverage test of epoch 14: loss -3.26351 acc 0.67568 roc_auc 0.57667 prc_auc 0.78589[0m
[92maverage training of epoch 15: loss -3.30603 acc 0.66225 roc_auc 0.53314 prc_auc 0.68559[0m
[93maverage test of epoch 15: loss -3.42614 acc 0.67568 roc_auc 0.48000 prc_auc 0.71062[0m
[92maverage training of epoch 16: loss -3.46107 acc 0.66225 roc_auc 0.41686 prc_auc 0.61047[0m
[93maverage test of epoch 16: loss -3.59267 acc 0.67568 roc_auc 0.46667 prc_auc 0.67257[0m
[92maverage training of epoch 17: loss -3.62499 acc 0.66225 roc_auc 0.49235 prc_auc 0.65445[0m
[93maverage test of epoch 17: loss -3.76185 acc 0.67568 roc_auc 0.45000 prc_auc 0.72056[0m
[92maverage training of epoch 18: loss -3.81500 acc 0.66225 roc_auc 0.40216 prc_auc 0.61015[0m
[93maverage test of epoch 18: loss -3.95942 acc 0.67568 roc_auc 0.53667 prc_auc 0.67506[0m
[92maverage training of epoch 19: loss -3.99304 acc 0.66225 roc_auc 0.40618 prc_auc 0.59362[0m
[93maverage test of epoch 19: loss -4.11618 acc 0.67568 roc_auc 0.58000 prc_auc 0.76651[0m
[92maverage training of epoch 20: loss -4.13828 acc 0.66225 roc_auc 0.44863 prc_auc 0.62607[0m
[93maverage test of epoch 20: loss -4.27293 acc 0.67568 roc_auc 0.49333 prc_auc 0.72101[0m
[92maverage training of epoch 21: loss -4.30222 acc 0.66225 roc_auc 0.45451 prc_auc 0.64996[0m
[93maverage test of epoch 21: loss -4.43560 acc 0.67568 roc_auc 0.60667 prc_auc 0.79922[0m
[92maverage training of epoch 22: loss -4.45015 acc 0.66225 roc_auc 0.44843 prc_auc 0.63311[0m
[93maverage test of epoch 22: loss -4.56237 acc 0.67568 roc_auc 0.37333 prc_auc 0.61087[0m
[92maverage training of epoch 23: loss -4.58883 acc 0.66225 roc_auc 0.47039 prc_auc 0.64397[0m
[93maverage test of epoch 23: loss -4.70363 acc 0.67568 roc_auc 0.50000 prc_auc 0.74793[0m
[92maverage training of epoch 24: loss -4.72596 acc 0.66225 roc_auc 0.47137 prc_auc 0.65252[0m
[93maverage test of epoch 24: loss -4.84926 acc 0.67568 roc_auc 0.45667 prc_auc 0.68124[0m
[92maverage training of epoch 25: loss -4.85441 acc 0.66225 roc_auc 0.47941 prc_auc 0.63067[0m
[93maverage test of epoch 25: loss -4.97430 acc 0.67568 roc_auc 0.43667 prc_auc 0.67258[0m
[92maverage training of epoch 26: loss -4.97244 acc 0.66225 roc_auc 0.37000 prc_auc 0.58915[0m
[93maverage test of epoch 26: loss -5.10373 acc 0.67568 roc_auc 0.60667 prc_auc 0.74006[0m
[92maverage training of epoch 27: loss -5.10188 acc 0.66225 roc_auc 0.38098 prc_auc 0.57110[0m
[93maverage test of epoch 27: loss -5.21555 acc 0.67568 roc_auc 0.54333 prc_auc 0.75794[0m
[92maverage training of epoch 28: loss -5.22208 acc 0.66225 roc_auc 0.39127 prc_auc 0.58502[0m
[93maverage test of epoch 28: loss -5.33463 acc 0.67568 roc_auc 0.67333 prc_auc 0.84402[0m
[92maverage training of epoch 29: loss -5.34449 acc 0.66225 roc_auc 0.52294 prc_auc 0.69727[0m
[93maverage test of epoch 29: loss -5.46058 acc 0.67568 roc_auc 0.44667 prc_auc 0.70544[0m
[92maverage training of epoch 30: loss -5.46048 acc 0.66225 roc_auc 0.47755 prc_auc 0.64324[0m
[93maverage test of epoch 30: loss -5.58269 acc 0.67568 roc_auc 0.70000 prc_auc 0.79235[0m
[92maverage training of epoch 31: loss -5.57220 acc 0.66225 roc_auc 0.40627 prc_auc 0.59297[0m
[93maverage test of epoch 31: loss -5.68372 acc 0.67568 roc_auc 0.49667 prc_auc 0.74785[0m
[92maverage training of epoch 32: loss -5.69101 acc 0.66225 roc_auc 0.42196 prc_auc 0.60736[0m
[93maverage test of epoch 32: loss -5.80940 acc 0.67568 roc_auc 0.65667 prc_auc 0.76928[0m
[92maverage training of epoch 33: loss -5.80062 acc 0.66225 roc_auc 0.49784 prc_auc 0.67995[0m
[93maverage test of epoch 33: loss -5.91183 acc 0.67568 roc_auc 0.42333 prc_auc 0.67584[0m
[92maverage training of epoch 34: loss -5.91169 acc 0.66225 roc_auc 0.46814 prc_auc 0.64658[0m
[93maverage test of epoch 34: loss -6.02756 acc 0.67568 roc_auc 0.69667 prc_auc 0.78009[0m
[92maverage training of epoch 35: loss -6.02444 acc 0.66225 roc_auc 0.39863 prc_auc 0.60818[0m
[93maverage test of epoch 35: loss -6.13012 acc 0.67568 roc_auc 0.62333 prc_auc 0.81181[0m
[92maverage training of epoch 36: loss -6.13123 acc 0.66225 roc_auc 0.37745 prc_auc 0.58645[0m
[93maverage test of epoch 36: loss -6.24535 acc 0.67568 roc_auc 0.59000 prc_auc 0.77288[0m
[92maverage training of epoch 37: loss -6.23841 acc 0.66225 roc_auc 0.37735 prc_auc 0.57818[0m
[93maverage test of epoch 37: loss -6.35310 acc 0.67568 roc_auc 0.42667 prc_auc 0.65278[0m
[92maverage training of epoch 38: loss -6.34907 acc 0.66225 roc_auc 0.45098 prc_auc 0.62627[0m
[93maverage test of epoch 38: loss -6.46433 acc 0.67568 roc_auc 0.51333 prc_auc 0.66398[0m
[92maverage training of epoch 39: loss -6.45108 acc 0.66225 roc_auc 0.42480 prc_auc 0.60981[0m
[93maverage test of epoch 39: loss -6.56597 acc 0.67568 roc_auc 0.51000 prc_auc 0.74402[0m
[92maverage training of epoch 40: loss -6.56038 acc 0.66225 roc_auc 0.42765 prc_auc 0.60795[0m
[93maverage test of epoch 40: loss -6.67224 acc 0.67568 roc_auc 0.49333 prc_auc 0.70125[0m
[92maverage training of epoch 41: loss -6.66571 acc 0.66225 roc_auc 0.43804 prc_auc 0.62298[0m
[93maverage test of epoch 41: loss -6.77839 acc 0.67568 roc_auc 0.57667 prc_auc 0.70458[0m
[92maverage training of epoch 42: loss -6.77036 acc 0.66225 roc_auc 0.42863 prc_auc 0.61961[0m
[93maverage test of epoch 42: loss -6.88439 acc 0.67568 roc_auc 0.53167 prc_auc 0.74701[0m
[92maverage training of epoch 43: loss -6.87495 acc 0.66225 roc_auc 0.39382 prc_auc 0.60093[0m
[93maverage test of epoch 43: loss -6.98900 acc 0.67568 roc_auc 0.51167 prc_auc 0.72744[0m
[92maverage training of epoch 44: loss -6.97819 acc 0.66225 roc_auc 0.44235 prc_auc 0.63709[0m
[93maverage test of epoch 44: loss -7.08908 acc 0.67568 roc_auc 0.36000 prc_auc 0.64057[0m
[92maverage training of epoch 45: loss -7.08181 acc 0.66225 roc_auc 0.38539 prc_auc 0.59469[0m
[93maverage test of epoch 45: loss -7.19588 acc 0.67568 roc_auc 0.62333 prc_auc 0.78492[0m
[92maverage training of epoch 46: loss -7.18905 acc 0.66225 roc_auc 0.40716 prc_auc 0.61041[0m
[93maverage test of epoch 46: loss -7.29784 acc 0.67568 roc_auc 0.61833 prc_auc 0.75484[0m
[92maverage training of epoch 47: loss -7.29074 acc 0.66225 roc_auc 0.41706 prc_auc 0.59461[0m
[93maverage test of epoch 47: loss -7.40573 acc 0.67568 roc_auc 0.70500 prc_auc 0.86856[0m
[92maverage training of epoch 48: loss -7.39149 acc 0.66225 roc_auc 0.36441 prc_auc 0.57591[0m
[93maverage test of epoch 48: loss -7.50903 acc 0.67568 roc_auc 0.60833 prc_auc 0.79166[0m
[92maverage training of epoch 49: loss -7.49324 acc 0.66225 roc_auc 0.35451 prc_auc 0.55452[0m
[93maverage test of epoch 49: loss -7.61105 acc 0.67568 roc_auc 0.37833 prc_auc 0.61202[0m
[92maverage training of epoch 50: loss -7.59833 acc 0.66225 roc_auc 0.40588 prc_auc 0.59229[0m
[93maverage test of epoch 50: loss -7.71543 acc 0.67568 roc_auc 0.61833 prc_auc 0.79371[0m
[92maverage training of epoch 51: loss -7.70107 acc 0.66225 roc_auc 0.39735 prc_auc 0.59413[0m
[93maverage test of epoch 51: loss -7.81508 acc 0.67568 roc_auc 0.38167 prc_auc 0.66953[0m
[92maverage training of epoch 52: loss -7.80347 acc 0.66225 roc_auc 0.42333 prc_auc 0.62686[0m
[93maverage test of epoch 52: loss -7.91903 acc 0.67568 roc_auc 0.56833 prc_auc 0.75272[0m
[92maverage training of epoch 53: loss -7.90420 acc 0.66225 roc_auc 0.40990 prc_auc 0.60271[0m
[93maverage test of epoch 53: loss -8.01920 acc 0.67568 roc_auc 0.45667 prc_auc 0.68344[0m
[92maverage training of epoch 54: loss -8.00454 acc 0.66225 roc_auc 0.39716 prc_auc 0.58621[0m
[93maverage test of epoch 54: loss -8.12257 acc 0.67568 roc_auc 0.64000 prc_auc 0.77369[0m
[92maverage training of epoch 55: loss -8.10664 acc 0.66225 roc_auc 0.36765 prc_auc 0.56249[0m
[93maverage test of epoch 55: loss -8.22691 acc 0.67568 roc_auc 0.51000 prc_auc 0.64673[0m
[92maverage training of epoch 56: loss -8.21076 acc 0.66225 roc_auc 0.36353 prc_auc 0.56223[0m
[93maverage test of epoch 56: loss -8.32654 acc 0.67568 roc_auc 0.48333 prc_auc 0.69341[0m
[92maverage training of epoch 57: loss -8.31178 acc 0.66225 roc_auc 0.38049 prc_auc 0.57370[0m
[93maverage test of epoch 57: loss -8.43023 acc 0.67568 roc_auc 0.58667 prc_auc 0.74533[0m
[92maverage training of epoch 58: loss -8.41120 acc 0.66225 roc_auc 0.34667 prc_auc 0.55712[0m
[93maverage test of epoch 58: loss -8.53107 acc 0.67568 roc_auc 0.51500 prc_auc 0.65439[0m
[92maverage training of epoch 59: loss -8.51271 acc 0.66225 roc_auc 0.41049 prc_auc 0.59085[0m
[93maverage test of epoch 59: loss -8.63130 acc 0.67568 roc_auc 0.59333 prc_auc 0.76671[0m
[92maverage training of epoch 60: loss -8.61368 acc 0.66225 roc_auc 0.38412 prc_auc 0.59752[0m
[93maverage test of epoch 60: loss -8.73181 acc 0.67568 roc_auc 0.48667 prc_auc 0.68111[0m
[92maverage training of epoch 61: loss -8.71591 acc 0.66225 roc_auc 0.36176 prc_auc 0.57320[0m
[93maverage test of epoch 61: loss -8.83449 acc 0.67568 roc_auc 0.30833 prc_auc 0.59326[0m
[92maverage training of epoch 62: loss -8.81701 acc 0.66225 roc_auc 0.41029 prc_auc 0.58647[0m
[93maverage test of epoch 62: loss -8.93777 acc 0.67568 roc_auc 0.62667 prc_auc 0.76861[0m
[92maverage training of epoch 63: loss -8.91688 acc 0.66225 roc_auc 0.38010 prc_auc 0.58382[0m
[93maverage test of epoch 63: loss -9.03636 acc 0.67568 roc_auc 0.63333 prc_auc 0.79436[0m
[92maverage training of epoch 64: loss -9.01762 acc 0.66225 roc_auc 0.35157 prc_auc 0.55943[0m
[93maverage test of epoch 64: loss -9.13812 acc 0.67568 roc_auc 0.41000 prc_auc 0.69588[0m
[92maverage training of epoch 65: loss -9.11865 acc 0.66225 roc_auc 0.36412 prc_auc 0.57282[0m
[93maverage test of epoch 65: loss -9.23921 acc 0.67568 roc_auc 0.52500 prc_auc 0.72945[0m
[92maverage training of epoch 66: loss -9.21905 acc 0.66225 roc_auc 0.38216 prc_auc 0.57497[0m
[93maverage test of epoch 66: loss -9.33994 acc 0.67568 roc_auc 0.55667 prc_auc 0.72119[0m
[92maverage training of epoch 67: loss -9.32044 acc 0.66225 roc_auc 0.36775 prc_auc 0.58392[0m
[93maverage test of epoch 67: loss -9.44302 acc 0.67568 roc_auc 0.40000 prc_auc 0.64327[0m
[92maverage training of epoch 68: loss -9.42057 acc 0.66225 roc_auc 0.35088 prc_auc 0.55789[0m
[93maverage test of epoch 68: loss -9.54418 acc 0.67568 roc_auc 0.36000 prc_auc 0.64665[0m
[92maverage training of epoch 69: loss -9.52174 acc 0.66225 roc_auc 0.38618 prc_auc 0.58303[0m
[93maverage test of epoch 69: loss -9.64418 acc 0.67568 roc_auc 0.42833 prc_auc 0.67732[0m
[92maverage training of epoch 70: loss -9.62202 acc 0.66225 roc_auc 0.38990 prc_auc 0.59667[0m
[93maverage test of epoch 70: loss -9.74488 acc 0.67568 roc_auc 0.61000 prc_auc 0.78647[0m
[92maverage training of epoch 71: loss -9.72190 acc 0.66225 roc_auc 0.37824 prc_auc 0.57455[0m
[93maverage test of epoch 71: loss -9.84525 acc 0.67568 roc_auc 0.54167 prc_auc 0.68645[0m
[92maverage training of epoch 72: loss -9.82280 acc 0.66225 roc_auc 0.38069 prc_auc 0.59263[0m
[93maverage test of epoch 72: loss -9.94630 acc 0.67568 roc_auc 0.61667 prc_auc 0.76405[0m
[92maverage training of epoch 73: loss -9.92288 acc 0.66225 roc_auc 0.37265 prc_auc 0.56527[0m
[93maverage test of epoch 73: loss -10.04692 acc 0.67568 roc_auc 0.61333 prc_auc 0.80599[0m
[92maverage training of epoch 74: loss -10.02280 acc 0.66225 roc_auc 0.36275 prc_auc 0.56723[0m
[93maverage test of epoch 74: loss -10.14804 acc 0.67568 roc_auc 0.68000 prc_auc 0.81858[0m
[92maverage training of epoch 75: loss -10.12359 acc 0.66225 roc_auc 0.36922 prc_auc 0.57098[0m
[93maverage test of epoch 75: loss -10.24697 acc 0.67568 roc_auc 0.47000 prc_auc 0.67243[0m
[92maverage training of epoch 76: loss -10.22421 acc 0.66225 roc_auc 0.38039 prc_auc 0.58543[0m
[93maverage test of epoch 76: loss -10.34944 acc 0.67568 roc_auc 0.49333 prc_auc 0.67844[0m
[92maverage training of epoch 77: loss -10.32391 acc 0.66225 roc_auc 0.38127 prc_auc 0.57929[0m
[93maverage test of epoch 77: loss -10.45044 acc 0.67568 roc_auc 0.51167 prc_auc 0.70139[0m
[92maverage training of epoch 78: loss -10.42426 acc 0.66225 roc_auc 0.36490 prc_auc 0.57215[0m
[93maverage test of epoch 78: loss -10.55094 acc 0.67568 roc_auc 0.57167 prc_auc 0.70007[0m
[92maverage training of epoch 79: loss -10.52439 acc 0.66225 roc_auc 0.36804 prc_auc 0.57632[0m
[93maverage test of epoch 79: loss -10.65140 acc 0.67568 roc_auc 0.45333 prc_auc 0.64740[0m
[92maverage training of epoch 80: loss -10.62440 acc 0.66225 roc_auc 0.36941 prc_auc 0.56832[0m
[93maverage test of epoch 80: loss -10.75087 acc 0.67568 roc_auc 0.37833 prc_auc 0.61574[0m
[92maverage training of epoch 81: loss -10.72504 acc 0.66225 roc_auc 0.37059 prc_auc 0.57356[0m
[93maverage test of epoch 81: loss -10.85251 acc 0.67568 roc_auc 0.56500 prc_auc 0.70724[0m
[92maverage training of epoch 82: loss -10.82510 acc 0.66225 roc_auc 0.37225 prc_auc 0.57308[0m
[93maverage test of epoch 82: loss -10.95206 acc 0.67568 roc_auc 0.47000 prc_auc 0.67148[0m
[92maverage training of epoch 83: loss -10.92488 acc 0.66225 roc_auc 0.36000 prc_auc 0.56989[0m
[93maverage test of epoch 83: loss -11.05283 acc 0.67568 roc_auc 0.49833 prc_auc 0.68304[0m
[92maverage training of epoch 84: loss -11.02530 acc 0.66225 roc_auc 0.36294 prc_auc 0.56314[0m
[93maverage test of epoch 84: loss -11.15431 acc 0.67568 roc_auc 0.41333 prc_auc 0.67331[0m
[92maverage training of epoch 85: loss -11.12490 acc 0.66225 roc_auc 0.36804 prc_auc 0.57095[0m
[93maverage test of epoch 85: loss -11.25476 acc 0.67568 roc_auc 0.58667 prc_auc 0.79639[0m
[92maverage training of epoch 86: loss -11.22506 acc 0.66225 roc_auc 0.36088 prc_auc 0.56560[0m
[93maverage test of epoch 86: loss -11.35439 acc 0.67568 roc_auc 0.29833 prc_auc 0.60701[0m
[92maverage training of epoch 87: loss -11.32565 acc 0.66225 roc_auc 0.37284 prc_auc 0.57070[0m
[93maverage test of epoch 87: loss -11.45536 acc 0.67568 roc_auc 0.46500 prc_auc 0.66003[0m
[92maverage training of epoch 88: loss -11.42535 acc 0.66225 roc_auc 0.37167 prc_auc 0.57413[0m
[93maverage test of epoch 88: loss -11.55547 acc 0.67568 roc_auc 0.49333 prc_auc 0.67057[0m
[92maverage training of epoch 89: loss -11.52557 acc 0.66225 roc_auc 0.37461 prc_auc 0.56806[0m
[93maverage test of epoch 89: loss -11.65637 acc 0.67568 roc_auc 0.51333 prc_auc 0.70302[0m
[92maverage training of epoch 90: loss -11.62572 acc 0.66225 roc_auc 0.37245 prc_auc 0.57456[0m
[93maverage test of epoch 90: loss -11.75710 acc 0.67568 roc_auc 0.42000 prc_auc 0.62794[0m
[92maverage training of epoch 91: loss -11.72597 acc 0.66225 roc_auc 0.36363 prc_auc 0.56593[0m
[93maverage test of epoch 91: loss -11.85712 acc 0.67568 roc_auc 0.42333 prc_auc 0.61770[0m
[92maverage training of epoch 92: loss -11.82567 acc 0.66225 roc_auc 0.36431 prc_auc 0.56248[0m
[93maverage test of epoch 92: loss -11.95749 acc 0.67568 roc_auc 0.50667 prc_auc 0.67174[0m
[92maverage training of epoch 93: loss -11.92570 acc 0.66225 roc_auc 0.36451 prc_auc 0.57240[0m
[93maverage test of epoch 93: loss -12.05808 acc 0.67568 roc_auc 0.40833 prc_auc 0.65908[0m
[92maverage training of epoch 94: loss -12.02569 acc 0.66225 roc_auc 0.37078 prc_auc 0.57004[0m
[93maverage test of epoch 94: loss -12.15831 acc 0.67568 roc_auc 0.34833 prc_auc 0.61429[0m
[92maverage training of epoch 95: loss -12.12561 acc 0.66225 roc_auc 0.37020 prc_auc 0.56937[0m
[93maverage test of epoch 95: loss -12.25895 acc 0.67568 roc_auc 0.68333 prc_auc 0.80689[0m
[92maverage training of epoch 96: loss -12.22569 acc 0.66225 roc_auc 0.36363 prc_auc 0.56407[0m
[93maverage test of epoch 96: loss -12.35941 acc 0.67568 roc_auc 0.53500 prc_auc 0.69771[0m
[92maverage training of epoch 97: loss -12.32576 acc 0.66225 roc_auc 0.36500 prc_auc 0.56304[0m
[93maverage test of epoch 97: loss -12.45905 acc 0.67568 roc_auc 0.49000 prc_auc 0.67361[0m
[92maverage training of epoch 98: loss -12.42561 acc 0.66225 roc_auc 0.37088 prc_auc 0.57198[0m
[93maverage test of epoch 98: loss -12.55949 acc 0.67568 roc_auc 0.52000 prc_auc 0.67251[0m
[92maverage training of epoch 99: loss -12.52551 acc 0.66225 roc_auc 0.36784 prc_auc 0.56655[0m
[93maverage test of epoch 99: loss -12.66029 acc 0.67568 roc_auc 0.43500 prc_auc 0.62753[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.0001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.69744 ROC_AUC (avg): 0.54608 PRC_AUC (avg): 0.69556 

Average forward propagation time taken(ms): 3.9448808896865226
Average backward propagation time taken(ms): 1.5040157826475915

