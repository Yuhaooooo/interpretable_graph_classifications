# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 2)
('lr', 0.0001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-01-58-46/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-01-58-46/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 8,
 'epochs': 100,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 8,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.0001,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 1,
 'num_workers': 8,
 'number_of_mlp_layer': 2,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-18-01-58-46',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 100, 'learning_rate': 0.0001, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=8, bias=True)
    (ReLU1): ReLU()
    (Linear2): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.68500 acc 0.66667 roc_auc 0.40240 prc_auc 0.62555[0m
[93maverage test of epoch 0: loss -0.88287 acc 0.65789 roc_auc 0.44923 prc_auc 0.73700[0m
[92maverage training of epoch 1: loss -1.11495 acc 0.66667 roc_auc 0.41020 prc_auc 0.61763[0m
[93maverage test of epoch 1: loss -1.36844 acc 0.65789 roc_auc 0.52615 prc_auc 0.78301[0m
[92maverage training of epoch 2: loss -1.68875 acc 0.66667 roc_auc 0.42140 prc_auc 0.63736[0m
[93maverage test of epoch 2: loss -2.03964 acc 0.65789 roc_auc 0.44615 prc_auc 0.74925[0m
[92maverage training of epoch 3: loss -2.48347 acc 0.66667 roc_auc 0.42560 prc_auc 0.63968[0m
[93maverage test of epoch 3: loss -2.95686 acc 0.65789 roc_auc 0.47077 prc_auc 0.75702[0m
[92maverage training of epoch 4: loss -3.51374 acc 0.66667 roc_auc 0.42400 prc_auc 0.62711[0m
[93maverage test of epoch 4: loss -4.05600 acc 0.65789 roc_auc 0.82769 prc_auc 0.92589[0m
[92maverage training of epoch 5: loss -4.60877 acc 0.66667 roc_auc 0.42020 prc_auc 0.62559[0m
[93maverage test of epoch 5: loss -5.11209 acc 0.65789 roc_auc 0.83077 prc_auc 0.92291[0m
[92maverage training of epoch 6: loss -5.64678 acc 0.66667 roc_auc 0.41540 prc_auc 0.62260[0m
[93maverage test of epoch 6: loss -6.13051 acc 0.65789 roc_auc 0.83385 prc_auc 0.92351[0m
[92maverage training of epoch 7: loss -6.67887 acc 0.66667 roc_auc 0.41480 prc_auc 0.62158[0m
[93maverage test of epoch 7: loss -7.17286 acc 0.65789 roc_auc 0.75538 prc_auc 0.89246[0m
[92maverage training of epoch 8: loss -7.75005 acc 0.66667 roc_auc 0.41480 prc_auc 0.62148[0m
[93maverage test of epoch 8: loss -8.26337 acc 0.65789 roc_auc 0.77846 prc_auc 0.89970[0m
[92maverage training of epoch 9: loss -8.87399 acc 0.66667 roc_auc 0.41540 prc_auc 0.62171[0m
[93maverage test of epoch 9: loss -9.41136 acc 0.65789 roc_auc 0.81538 prc_auc 0.90787[0m
[92maverage training of epoch 10: loss -10.05850 acc 0.66667 roc_auc 0.41720 prc_auc 0.62310[0m
[93maverage test of epoch 10: loss -10.62251 acc 0.65789 roc_auc 0.85538 prc_auc 0.92113[0m
[92maverage training of epoch 11: loss -11.30858 acc 0.66667 roc_auc 0.41840 prc_auc 0.62451[0m
[93maverage test of epoch 11: loss -11.90139 acc 0.65789 roc_auc 0.89231 prc_auc 0.93045[0m
[92maverage training of epoch 12: loss -12.62909 acc 0.66667 roc_auc 0.41910 prc_auc 0.62470[0m
[93maverage test of epoch 12: loss -13.25280 acc 0.65789 roc_auc 0.85692 prc_auc 0.89909[0m
[92maverage training of epoch 13: loss -14.02422 acc 0.66667 roc_auc 0.41940 prc_auc 0.62507[0m
[93maverage test of epoch 13: loss -14.68019 acc 0.65789 roc_auc 0.85077 prc_auc 0.89189[0m
[92maverage training of epoch 14: loss -15.49886 acc 0.66667 roc_auc 0.41970 prc_auc 0.62474[0m
[93maverage test of epoch 14: loss -16.19912 acc 0.65789 roc_auc 0.72000 prc_auc 0.80842[0m
[92maverage training of epoch 15: loss -17.10648 acc 0.66667 roc_auc 0.41990 prc_auc 0.62479[0m
[93maverage test of epoch 15: loss -17.91176 acc 0.65789 roc_auc 0.58000 prc_auc 0.71263[0m
[92maverage training of epoch 16: loss -18.97609 acc 0.66667 roc_auc 0.41980 prc_auc 0.62494[0m
[93maverage test of epoch 16: loss -19.91333 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 17: loss -21.04094 acc 0.66667 roc_auc 0.41610 prc_auc 0.62175[0m
[93maverage test of epoch 17: loss -21.99868 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 18: loss -23.15551 acc 0.66667 roc_auc 0.41110 prc_auc 0.62138[0m
[93maverage test of epoch 18: loss -24.13169 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -25.33376 acc 0.66667 roc_auc 0.42050 prc_auc 0.63557[0m
[93maverage test of epoch 19: loss -26.34113 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -27.59650 acc 0.66667 roc_auc 0.44080 prc_auc 0.63937[0m
[93maverage test of epoch 20: loss -28.64130 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -29.95423 acc 0.66667 roc_auc 0.48000 prc_auc 0.65939[0m
[93maverage test of epoch 21: loss -31.03986 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -32.41343 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 22: loss -33.54215 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -34.97884 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 23: loss -36.15279 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -37.65528 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 24: loss -38.87657 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -40.44570 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 25: loss -41.71384 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -43.34930 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 26: loss -44.66328 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -46.36485 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 27: loss -47.72483 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -49.49454 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 28: loss -50.90221 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -52.74224 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 29: loss -54.19794 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -56.10839 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 30: loss -57.61257 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -59.59656 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 31: loss -61.15152 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -63.21206 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 32: loss -64.81988 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -66.95999 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 33: loss -68.62261 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -70.84509 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -72.56435 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -74.87209 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -76.64985 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -79.04569 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -80.88367 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -83.37025 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -85.27001 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -87.85023 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -89.81351 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -92.49009 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -94.51850 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -97.29417 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -99.38917 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -102.26657 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -104.42897 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -107.40870 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -109.63727 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -112.72142 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -115.01750 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -118.20901 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -120.57438 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -123.87607 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -126.31209 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -129.72668 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -132.23464 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -135.76464 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -138.34576 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -141.99377 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -144.64896 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -148.41731 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -151.14741 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 50: loss -155.03825 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 50: loss -157.84398 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 51: loss -161.85976 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 51: loss -164.74193 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 52: loss -168.88458 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 52: loss -171.84342 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 53: loss -176.11318 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 53: loss -179.14501 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 54: loss -183.53904 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 54: loss -186.63931 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 55: loss -191.15796 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 55: loss -194.32664 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 56: loss -198.97259 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 56: loss -202.21124 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 57: loss -206.98119 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 57: loss -210.29330 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 58: loss -215.20420 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 58: loss -218.58627 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 59: loss -223.62857 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 59: loss -227.08377 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 60: loss -232.26279 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 60: loss -235.79209 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 61: loss -241.11001 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 61: loss -244.71429 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 62: loss -250.17356 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 62: loss -253.85372 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 63: loss -259.45636 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 63: loss -263.21304 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 64: loss -268.96144 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 64: loss -272.79568 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 65: loss -278.69209 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 65: loss -282.60458 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 66: loss -288.65094 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 66: loss -292.64199 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 67: loss -298.84065 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 67: loss -302.91120 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 68: loss -309.26451 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 68: loss -313.41540 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 69: loss -319.92548 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 69: loss -324.15724 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 70: loss -330.82629 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 70: loss -335.13945 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 71: loss -341.96971 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 71: loss -346.36495 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 72: loss -353.35849 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 72: loss -357.83614 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 73: loss -364.99517 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 73: loss -369.55604 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 74: loss -376.88288 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 74: loss -381.52744 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 75: loss -389.02421 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 75: loss -393.75311 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 76: loss -401.42206 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 76: loss -406.23560 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 77: loss -414.07879 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 77: loss -418.97753 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 78: loss -426.99746 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 78: loss -431.98213 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 79: loss -440.18093 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 79: loss -445.25172 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 80: loss -453.63119 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 80: loss -458.78840 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 81: loss -467.35136 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 81: loss -472.59606 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 82: loss -481.34460 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 82: loss -486.67693 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 83: loss -495.61326 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 83: loss -501.03366 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 84: loss -510.16014 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 84: loss -515.66919 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 85: loss -524.98792 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 85: loss -530.58583 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 86: loss -540.09890 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 86: loss -545.78596 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 87: loss -555.49585 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 87: loss -561.27267 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 88: loss -571.18156 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 88: loss -577.04846 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 89: loss -587.15884 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 89: loss -593.11635 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -603.43026 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 90: loss -609.47853 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 91: loss -619.99847 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 91: loss -626.13807 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 92: loss -636.86601 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 92: loss -643.09737 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 93: loss -654.03610 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 93: loss -660.35931 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 94: loss -671.51102 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 94: loss -677.92665 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 95: loss -689.29366 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 95: loss -695.80210 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 96: loss -707.38679 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 96: loss -713.98837 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 97: loss -725.79283 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 97: loss -732.48749 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 98: loss -744.51406 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 98: loss -751.30219 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -763.55336 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 99: loss -770.43543 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=8, bias=True)
    (ReLU1): ReLU()
    (Linear2): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss 0.89632 acc 0.33333 roc_auc 0.47560 prc_auc 0.66023[0m
[93maverage test of epoch 0: loss 0.72766 acc 0.34211 roc_auc 0.80923 prc_auc 0.88936[0m
[92maverage training of epoch 1: loss 0.66879 acc 0.33333 roc_auc 0.48820 prc_auc 0.67193[0m
[93maverage test of epoch 1: loss 0.51783 acc 0.34211 roc_auc 0.83692 prc_auc 0.91540[0m
[92maverage training of epoch 2: loss 0.46780 acc 0.33333 roc_auc 0.50640 prc_auc 0.69121[0m
[93maverage test of epoch 2: loss 0.33016 acc 0.34211 roc_auc 0.87692 prc_auc 0.93112[0m
[92maverage training of epoch 3: loss 0.29555 acc 0.33333 roc_auc 0.53260 prc_auc 0.72390[0m
[93maverage test of epoch 3: loss 0.17302 acc 0.34211 roc_auc 0.88000 prc_auc 0.93321[0m
[92maverage training of epoch 4: loss 0.15060 acc 0.33333 roc_auc 0.56620 prc_auc 0.75607[0m
[93maverage test of epoch 4: loss 0.04869 acc 0.34211 roc_auc 0.88000 prc_auc 0.93321[0m
[92maverage training of epoch 5: loss 0.03960 acc 0.33333 roc_auc 0.59620 prc_auc 0.78412[0m
[93maverage test of epoch 5: loss -0.05777 acc 0.34211 roc_auc 0.89231 prc_auc 0.94026[0m
[92maverage training of epoch 6: loss -0.05618 acc 0.33333 roc_auc 0.63700 prc_auc 0.81274[0m
[93maverage test of epoch 6: loss -0.12702 acc 0.34211 roc_auc 0.91077 prc_auc 0.95119[0m
[92maverage training of epoch 7: loss -0.11868 acc 0.33333 roc_auc 0.71120 prc_auc 0.85640[0m
[93maverage test of epoch 7: loss -0.16615 acc 0.34211 roc_auc 0.90462 prc_auc 0.94889[0m
[92maverage training of epoch 8: loss -0.15670 acc 0.33333 roc_auc 0.78960 prc_auc 0.90276[0m
[93maverage test of epoch 8: loss -0.18777 acc 0.34211 roc_auc 0.90154 prc_auc 0.94604[0m
[92maverage training of epoch 9: loss -0.18085 acc 0.33333 roc_auc 0.83880 prc_auc 0.92609[0m
[93maverage test of epoch 9: loss -0.20900 acc 0.34211 roc_auc 0.90154 prc_auc 0.94604[0m
[92maverage training of epoch 10: loss -0.20359 acc 0.33333 roc_auc 0.86200 prc_auc 0.93799[0m
[93maverage test of epoch 10: loss -0.23228 acc 0.34211 roc_auc 0.90154 prc_auc 0.94604[0m
[92maverage training of epoch 11: loss -0.22693 acc 0.33333 roc_auc 0.86920 prc_auc 0.94033[0m
[93maverage test of epoch 11: loss -0.25581 acc 0.34211 roc_auc 0.88308 prc_auc 0.90911[0m
[92maverage training of epoch 12: loss -0.25096 acc 0.33333 roc_auc 0.87560 prc_auc 0.94311[0m
[93maverage test of epoch 12: loss -0.28026 acc 0.34211 roc_auc 0.88308 prc_auc 0.90911[0m
[92maverage training of epoch 13: loss -0.27627 acc 0.33333 roc_auc 0.88020 prc_auc 0.94593[0m
[93maverage test of epoch 13: loss -0.30608 acc 0.34211 roc_auc 0.88769 prc_auc 0.90859[0m
[92maverage training of epoch 14: loss -0.30324 acc 0.33333 roc_auc 0.88620 prc_auc 0.94864[0m
[93maverage test of epoch 14: loss -0.33393 acc 0.34211 roc_auc 0.88769 prc_auc 0.90859[0m
[92maverage training of epoch 15: loss -0.33260 acc 0.33333 roc_auc 0.88880 prc_auc 0.95009[0m
[93maverage test of epoch 15: loss -0.36474 acc 0.34211 roc_auc 0.88769 prc_auc 0.90859[0m
[92maverage training of epoch 16: loss -0.36546 acc 0.33333 roc_auc 0.89060 prc_auc 0.95085[0m
[93maverage test of epoch 16: loss -0.39921 acc 0.34211 roc_auc 0.88769 prc_auc 0.90859[0m
[92maverage training of epoch 17: loss -0.40358 acc 0.33333 roc_auc 0.89540 prc_auc 0.95325[0m
[93maverage test of epoch 17: loss -0.44001 acc 0.34211 roc_auc 0.88923 prc_auc 0.91141[0m
[92maverage training of epoch 18: loss -0.44868 acc 0.33333 roc_auc 0.89000 prc_auc 0.95096[0m
[93maverage test of epoch 18: loss -0.49142 acc 0.34211 roc_auc 0.88769 prc_auc 0.90859[0m
[92maverage training of epoch 19: loss -0.50524 acc 0.33333 roc_auc 0.89340 prc_auc 0.94957[0m
[93maverage test of epoch 19: loss -0.55509 acc 0.34211 roc_auc 0.88769 prc_auc 0.90859[0m
[92maverage training of epoch 20: loss -0.57536 acc 0.33333 roc_auc 0.89740 prc_auc 0.95224[0m
[93maverage test of epoch 20: loss -0.63108 acc 0.34211 roc_auc 0.88462 prc_auc 0.91017[0m
[92maverage training of epoch 21: loss -0.66186 acc 0.33333 roc_auc 0.90080 prc_auc 0.95492[0m
[93maverage test of epoch 21: loss -0.72300 acc 0.34211 roc_auc 0.86462 prc_auc 0.88372[0m
[92maverage training of epoch 22: loss -0.76973 acc 0.33333 roc_auc 0.90440 prc_auc 0.95661[0m
[93maverage test of epoch 22: loss -0.83295 acc 0.34211 roc_auc 0.87077 prc_auc 0.89167[0m
[92maverage training of epoch 23: loss -0.89625 acc 0.33333 roc_auc 0.90760 prc_auc 0.95755[0m
[93maverage test of epoch 23: loss -0.95669 acc 0.34211 roc_auc 0.84615 prc_auc 0.87049[0m
[92maverage training of epoch 24: loss -1.04289 acc 0.33333 roc_auc 0.91000 prc_auc 0.95970[0m
[93maverage test of epoch 24: loss -1.09861 acc 0.34211 roc_auc 0.85846 prc_auc 0.88382[0m
[92maverage training of epoch 25: loss -1.19731 acc 0.33333 roc_auc 0.90340 prc_auc 0.95095[0m
[93maverage test of epoch 25: loss -1.25251 acc 0.34211 roc_auc 0.88308 prc_auc 0.90649[0m
[92maverage training of epoch 26: loss -1.36492 acc 0.33333 roc_auc 0.89160 prc_auc 0.94493[0m
[93maverage test of epoch 26: loss -1.40843 acc 0.34211 roc_auc 0.88615 prc_auc 0.93563[0m
[92maverage training of epoch 27: loss -1.54368 acc 0.33333 roc_auc 0.89200 prc_auc 0.94791[0m
[93maverage test of epoch 27: loss -1.57105 acc 0.34211 roc_auc 0.89231 prc_auc 0.93951[0m
[92maverage training of epoch 28: loss -1.73418 acc 0.33333 roc_auc 0.88920 prc_auc 0.94758[0m
[93maverage test of epoch 28: loss -1.74275 acc 0.34211 roc_auc 0.90462 prc_auc 0.94644[0m
[92maverage training of epoch 29: loss -1.93229 acc 0.33333 roc_auc 0.88700 prc_auc 0.94688[0m
[93maverage test of epoch 29: loss -1.92222 acc 0.34211 roc_auc 0.91385 prc_auc 0.95188[0m
[92maverage training of epoch 30: loss -2.13505 acc 0.33333 roc_auc 0.88640 prc_auc 0.94659[0m
[93maverage test of epoch 30: loss -2.10919 acc 0.34211 roc_auc 0.91385 prc_auc 0.95188[0m
[92maverage training of epoch 31: loss -2.33623 acc 0.33333 roc_auc 0.88700 prc_auc 0.94757[0m
[93maverage test of epoch 31: loss -2.29876 acc 0.34211 roc_auc 0.91077 prc_auc 0.95015[0m
[92maverage training of epoch 32: loss -2.54692 acc 0.33333 roc_auc 0.88740 prc_auc 0.94761[0m
[93maverage test of epoch 32: loss -2.48316 acc 0.34211 roc_auc 0.91077 prc_auc 0.95015[0m
[92maverage training of epoch 33: loss -2.76942 acc 0.33333 roc_auc 0.89320 prc_auc 0.95263[0m
[93maverage test of epoch 33: loss -2.70165 acc 0.34211 roc_auc 0.92615 prc_auc 0.95663[0m
[92maverage training of epoch 34: loss -3.01321 acc 0.33333 roc_auc 0.89160 prc_auc 0.95126[0m
[93maverage test of epoch 34: loss -2.94971 acc 0.34211 roc_auc 0.93231 prc_auc 0.95937[0m
[92maverage training of epoch 35: loss -3.26127 acc 0.33333 roc_auc 0.89240 prc_auc 0.95164[0m
[93maverage test of epoch 35: loss -3.25397 acc 0.34211 roc_auc 0.93846 prc_auc 0.96346[0m
[92maverage training of epoch 36: loss -3.50220 acc 0.33333 roc_auc 0.89180 prc_auc 0.95130[0m
[93maverage test of epoch 36: loss -3.63318 acc 0.34211 roc_auc 0.93846 prc_auc 0.96346[0m
[92maverage training of epoch 37: loss -3.76222 acc 0.33333 roc_auc 0.89180 prc_auc 0.95096[0m
[93maverage test of epoch 37: loss -3.94370 acc 0.34211 roc_auc 0.93538 prc_auc 0.96222[0m
[92maverage training of epoch 38: loss -4.01616 acc 0.33333 roc_auc 0.89240 prc_auc 0.95126[0m
[93maverage test of epoch 38: loss -4.24819 acc 0.34211 roc_auc 0.93538 prc_auc 0.96222[0m
[92maverage training of epoch 39: loss -4.26069 acc 0.33333 roc_auc 0.89300 prc_auc 0.95199[0m
[93maverage test of epoch 39: loss -4.55139 acc 0.34211 roc_auc 0.93538 prc_auc 0.96222[0m
[92maverage training of epoch 40: loss -4.54709 acc 0.33333 roc_auc 0.89740 prc_auc 0.95713[0m
[93maverage test of epoch 40: loss -4.84923 acc 0.34211 roc_auc 0.93538 prc_auc 0.96222[0m
[92maverage training of epoch 41: loss -4.84273 acc 0.33333 roc_auc 0.89600 prc_auc 0.95658[0m
[93maverage test of epoch 41: loss -5.15472 acc 0.34211 roc_auc 0.93538 prc_auc 0.96222[0m
[92maverage training of epoch 42: loss -5.16811 acc 0.33333 roc_auc 0.89980 prc_auc 0.95953[0m
[93maverage test of epoch 42: loss -5.48712 acc 0.34211 roc_auc 0.93538 prc_auc 0.96222[0m
[92maverage training of epoch 43: loss -5.51280 acc 0.33333 roc_auc 0.89880 prc_auc 0.95906[0m
[93maverage test of epoch 43: loss -5.83791 acc 0.34211 roc_auc 0.93231 prc_auc 0.96033[0m
[92maverage training of epoch 44: loss -5.88062 acc 0.33333 roc_auc 0.89760 prc_auc 0.95832[0m
[93maverage test of epoch 44: loss -6.18660 acc 0.34211 roc_auc 0.93538 prc_auc 0.96156[0m
[92maverage training of epoch 45: loss -6.25634 acc 0.33333 roc_auc 0.89460 prc_auc 0.95561[0m
[93maverage test of epoch 45: loss -6.58691 acc 0.34211 roc_auc 0.93538 prc_auc 0.96156[0m
[92maverage training of epoch 46: loss -6.65953 acc 0.33333 roc_auc 0.89400 prc_auc 0.95539[0m
[93maverage test of epoch 46: loss -6.97692 acc 0.34211 roc_auc 0.93538 prc_auc 0.96156[0m
[92maverage training of epoch 47: loss -7.08023 acc 0.33333 roc_auc 0.89140 prc_auc 0.95285[0m
[93maverage test of epoch 47: loss -7.39125 acc 0.34211 roc_auc 0.93538 prc_auc 0.96156[0m
[92maverage training of epoch 48: loss -7.51299 acc 0.33333 roc_auc 0.89020 prc_auc 0.95163[0m
[93maverage test of epoch 48: loss -7.81801 acc 0.34211 roc_auc 0.93538 prc_auc 0.96156[0m
[92maverage training of epoch 49: loss -7.94404 acc 0.33333 roc_auc 0.88780 prc_auc 0.94960[0m
[93maverage test of epoch 49: loss -8.23769 acc 0.34211 roc_auc 0.92923 prc_auc 0.95563[0m
[92maverage training of epoch 50: loss -8.41597 acc 0.33333 roc_auc 0.87620 prc_auc 0.93438[0m
[93maverage test of epoch 50: loss -8.68967 acc 0.34211 roc_auc 0.90462 prc_auc 0.93733[0m
[92maverage training of epoch 51: loss -8.87836 acc 0.33333 roc_auc 0.87260 prc_auc 0.92693[0m
[93maverage test of epoch 51: loss -9.14385 acc 0.34211 roc_auc 0.89846 prc_auc 0.92202[0m
[92maverage training of epoch 52: loss -9.33560 acc 0.33333 roc_auc 0.87620 prc_auc 0.91969[0m
[93maverage test of epoch 52: loss -9.55626 acc 0.34211 roc_auc 0.90462 prc_auc 0.92978[0m
[92maverage training of epoch 53: loss -9.85582 acc 0.33333 roc_auc 0.88160 prc_auc 0.91533[0m
[93maverage test of epoch 53: loss -9.99677 acc 0.34211 roc_auc 0.89846 prc_auc 0.92524[0m
[92maverage training of epoch 54: loss -10.41499 acc 0.33333 roc_auc 0.88120 prc_auc 0.91407[0m
[93maverage test of epoch 54: loss -10.62420 acc 0.34211 roc_auc 0.89846 prc_auc 0.92524[0m
[92maverage training of epoch 55: loss -10.89672 acc 0.33333 roc_auc 0.88180 prc_auc 0.91901[0m
[93maverage test of epoch 55: loss -11.13656 acc 0.34211 roc_auc 0.89846 prc_auc 0.92524[0m
[92maverage training of epoch 56: loss -11.46874 acc 0.33333 roc_auc 0.88200 prc_auc 0.91477[0m
[93maverage test of epoch 56: loss -11.69812 acc 0.34211 roc_auc 0.90154 prc_auc 0.92757[0m
[92maverage training of epoch 57: loss -12.07035 acc 0.33333 roc_auc 0.88320 prc_auc 0.92049[0m
[93maverage test of epoch 57: loss -12.26467 acc 0.34211 roc_auc 0.89846 prc_auc 0.92642[0m
[92maverage training of epoch 58: loss -12.71214 acc 0.33333 roc_auc 0.88580 prc_auc 0.92587[0m
[93maverage test of epoch 58: loss -12.84578 acc 0.34211 roc_auc 0.89846 prc_auc 0.92642[0m
[92maverage training of epoch 59: loss -13.36699 acc 0.33333 roc_auc 0.88600 prc_auc 0.93181[0m
[93maverage test of epoch 59: loss -13.42597 acc 0.34211 roc_auc 0.90154 prc_auc 0.93142[0m
[92maverage training of epoch 60: loss -14.02593 acc 0.33333 roc_auc 0.88440 prc_auc 0.92527[0m
[93maverage test of epoch 60: loss -14.04637 acc 0.34211 roc_auc 0.89846 prc_auc 0.92642[0m
[92maverage training of epoch 61: loss -14.70712 acc 0.33333 roc_auc 0.88540 prc_auc 0.92573[0m
[93maverage test of epoch 61: loss -14.71133 acc 0.34211 roc_auc 0.90462 prc_auc 0.93700[0m
[92maverage training of epoch 62: loss -15.39216 acc 0.33333 roc_auc 0.88480 prc_auc 0.93029[0m
[93maverage test of epoch 62: loss -15.35531 acc 0.34211 roc_auc 0.90769 prc_auc 0.94100[0m
[92maverage training of epoch 63: loss -16.11288 acc 0.33333 roc_auc 0.88220 prc_auc 0.92434[0m
[93maverage test of epoch 63: loss -16.04759 acc 0.34211 roc_auc 0.90769 prc_auc 0.94100[0m
[92maverage training of epoch 64: loss -16.87501 acc 0.33333 roc_auc 0.88200 prc_auc 0.92426[0m
[93maverage test of epoch 64: loss -16.75494 acc 0.34211 roc_auc 0.91385 prc_auc 0.94797[0m
[92maverage training of epoch 65: loss -17.69362 acc 0.33333 roc_auc 0.87820 prc_auc 0.92242[0m
[93maverage test of epoch 65: loss -17.51119 acc 0.34211 roc_auc 0.91385 prc_auc 0.94797[0m
[92maverage training of epoch 66: loss -18.50627 acc 0.33333 roc_auc 0.86980 prc_auc 0.91857[0m
[93maverage test of epoch 66: loss -18.31618 acc 0.34211 roc_auc 0.91077 prc_auc 0.94463[0m
[92maverage training of epoch 67: loss -19.34592 acc 0.33333 roc_auc 0.86480 prc_auc 0.93323[0m
[93maverage test of epoch 67: loss -19.04242 acc 0.34211 roc_auc 0.91692 prc_auc 0.95006[0m
[92maverage training of epoch 68: loss -20.37319 acc 0.33333 roc_auc 0.86320 prc_auc 0.91742[0m
[93maverage test of epoch 68: loss -19.96186 acc 0.34211 roc_auc 0.90769 prc_auc 0.94243[0m
[92maverage training of epoch 69: loss -21.96696 acc 0.33333 roc_auc 0.82580 prc_auc 0.92733[0m
[93maverage test of epoch 69: loss -23.88844 acc 0.34211 roc_auc 0.95385 prc_auc 0.97886[0m
[92maverage training of epoch 70: loss -23.97448 acc 0.33333 roc_auc 0.81520 prc_auc 0.92252[0m
[93maverage test of epoch 70: loss -25.21813 acc 0.34211 roc_auc 0.93538 prc_auc 0.97071[0m
[92maverage training of epoch 71: loss -25.91323 acc 0.33333 roc_auc 0.52860 prc_auc 0.69752[0m
[93maverage test of epoch 71: loss -27.65051 acc 0.34211 roc_auc 0.68615 prc_auc 0.86864[0m
[92maverage training of epoch 72: loss -28.23139 acc 0.33333 roc_auc 0.52980 prc_auc 0.67099[0m
[93maverage test of epoch 72: loss -30.01849 acc 0.34211 roc_auc 0.71077 prc_auc 0.88348[0m
[92maverage training of epoch 73: loss -30.64500 acc 0.33333 roc_auc 0.53060 prc_auc 0.67203[0m
[93maverage test of epoch 73: loss -32.51266 acc 0.34211 roc_auc 0.71077 prc_auc 0.88348[0m
[92maverage training of epoch 74: loss -33.19370 acc 0.33333 roc_auc 0.53040 prc_auc 0.67194[0m
[93maverage test of epoch 74: loss -35.15323 acc 0.34211 roc_auc 0.71077 prc_auc 0.88348[0m
[92maverage training of epoch 75: loss -35.89330 acc 0.33333 roc_auc 0.53040 prc_auc 0.67194[0m
[93maverage test of epoch 75: loss -37.95213 acc 0.34211 roc_auc 0.71231 prc_auc 0.88385[0m
[92maverage training of epoch 76: loss -38.75138 acc 0.33333 roc_auc 0.53040 prc_auc 0.67194[0m
[93maverage test of epoch 76: loss -40.91167 acc 0.34211 roc_auc 0.70923 prc_auc 0.88298[0m
[92maverage training of epoch 77: loss -41.76946 acc 0.33333 roc_auc 0.53040 prc_auc 0.67194[0m
[93maverage test of epoch 77: loss -44.03408 acc 0.34211 roc_auc 0.71077 prc_auc 0.88440[0m
[92maverage training of epoch 78: loss -44.95014 acc 0.33333 roc_auc 0.53020 prc_auc 0.67183[0m
[93maverage test of epoch 78: loss -47.32099 acc 0.34211 roc_auc 0.71077 prc_auc 0.88440[0m
[92maverage training of epoch 79: loss -48.29529 acc 0.33333 roc_auc 0.53020 prc_auc 0.67183[0m
[93maverage test of epoch 79: loss -50.77433 acc 0.34211 roc_auc 0.71077 prc_auc 0.88440[0m
[92maverage training of epoch 80: loss -51.80040 acc 0.33333 roc_auc 0.53020 prc_auc 0.67183[0m
[93maverage test of epoch 80: loss -54.38015 acc 0.34211 roc_auc 0.71077 prc_auc 0.88440[0m
[92maverage training of epoch 81: loss -55.45235 acc 0.33333 roc_auc 0.53020 prc_auc 0.67183[0m
[93maverage test of epoch 81: loss -58.13219 acc 0.34211 roc_auc 0.71385 prc_auc 0.88596[0m
[92maverage training of epoch 82: loss -59.24877 acc 0.33333 roc_auc 0.53020 prc_auc 0.67183[0m
[93maverage test of epoch 82: loss -62.02741 acc 0.34211 roc_auc 0.71846 prc_auc 0.88311[0m
[92maverage training of epoch 83: loss -63.18913 acc 0.33333 roc_auc 0.53020 prc_auc 0.67183[0m
[93maverage test of epoch 83: loss -66.06820 acc 0.34211 roc_auc 0.58000 prc_auc 0.72671[0m
[92maverage training of epoch 84: loss -67.27308 acc 0.33333 roc_auc 0.53000 prc_auc 0.67202[0m
[93maverage test of epoch 84: loss -70.25326 acc 0.34211 roc_auc 0.46000 prc_auc 0.64041[0m
[92maverage training of epoch 85: loss -71.50608 acc 0.33333 roc_auc 0.53100 prc_auc 0.66610[0m
[93maverage test of epoch 85: loss -74.59283 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 86: loss -75.89620 acc 0.33333 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 86: loss -79.09313 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 87: loss -80.45083 acc 0.33333 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 87: loss -83.76277 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 88: loss -85.17755 acc 0.33333 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 88: loss -88.60690 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 89: loss -90.07608 acc 0.33333 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 89: loss -93.62233 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -95.14719 acc 0.33333 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 90: loss -98.81278 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 91: loss -100.39600 acc 0.33333 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 91: loss -104.18502 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 92: loss -105.82839 acc 0.33333 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 92: loss -109.74278 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 93: loss -111.44715 acc 0.33333 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 93: loss -115.48894 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 94: loss -117.25675 acc 0.33333 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 94: loss -121.43059 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 95: loss -123.26617 acc 0.33333 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 95: loss -127.57589 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 96: loss -129.48137 acc 0.33333 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 96: loss -133.93093 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 97: loss -135.90784 acc 0.33333 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 97: loss -140.50002 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 98: loss -142.55073 acc 0.33333 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 98: loss -147.28945 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -149.41688 acc 0.33333 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 99: loss -154.30705 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=8, bias=True)
    (ReLU1): ReLU()
    (Linear2): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss 1.04021 acc 0.66667 roc_auc 0.42920 prc_auc 0.64253[0m
[93maverage test of epoch 0: loss 0.74660 acc 0.65789 roc_auc 0.44000 prc_auc 0.74580[0m
[92maverage training of epoch 1: loss 0.45292 acc 0.66667 roc_auc 0.43860 prc_auc 0.64671[0m
[93maverage test of epoch 1: loss 0.20507 acc 0.65789 roc_auc 0.38154 prc_auc 0.71827[0m
[92maverage training of epoch 2: loss -0.09221 acc 0.66667 roc_auc 0.50150 prc_auc 0.71203[0m
[93maverage test of epoch 2: loss -0.32374 acc 0.65789 roc_auc 0.95385 prc_auc 0.97965[0m
[92maverage training of epoch 3: loss -0.58668 acc 0.66667 roc_auc 0.53060 prc_auc 0.72113[0m
[93maverage test of epoch 3: loss -0.76096 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 4: loss -1.00398 acc 0.66667 roc_auc 0.52560 prc_auc 0.71547[0m
[93maverage test of epoch 4: loss -1.19951 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 5: loss -1.50939 acc 0.66667 roc_auc 0.52220 prc_auc 0.71528[0m
[93maverage test of epoch 5: loss -1.73272 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 6: loss -2.01617 acc 0.66667 roc_auc 0.53040 prc_auc 0.72278[0m
[93maverage test of epoch 6: loss -2.22853 acc 0.65789 roc_auc 0.94923 prc_auc 0.97702[0m
[92maverage training of epoch 7: loss -2.56075 acc 0.66667 roc_auc 0.52090 prc_auc 0.71502[0m
[93maverage test of epoch 7: loss -2.78546 acc 0.65789 roc_auc 0.93231 prc_auc 0.96885[0m
[92maverage training of epoch 8: loss -3.13785 acc 0.66667 roc_auc 0.50290 prc_auc 0.70257[0m
[93maverage test of epoch 8: loss -3.34231 acc 0.65789 roc_auc 0.93846 prc_auc 0.96567[0m
[92maverage training of epoch 9: loss -3.70005 acc 0.66667 roc_auc 0.49490 prc_auc 0.69775[0m
[93maverage test of epoch 9: loss -3.87928 acc 0.65789 roc_auc 0.94308 prc_auc 0.95774[0m
[92maverage training of epoch 10: loss -4.24485 acc 0.66667 roc_auc 0.48950 prc_auc 0.68740[0m
[93maverage test of epoch 10: loss -4.40568 acc 0.65789 roc_auc 0.80000 prc_auc 0.86316[0m
[92maverage training of epoch 11: loss -4.78065 acc 0.66667 roc_auc 0.49250 prc_auc 0.68520[0m
[93maverage test of epoch 11: loss -4.92711 acc 0.65789 roc_auc 0.74000 prc_auc 0.82211[0m
[92maverage training of epoch 12: loss -5.31357 acc 0.66667 roc_auc 0.46360 prc_auc 0.64931[0m
[93maverage test of epoch 12: loss -5.45026 acc 0.65789 roc_auc 0.62000 prc_auc 0.74000[0m
[92maverage training of epoch 13: loss -5.85033 acc 0.66667 roc_auc 0.49000 prc_auc 0.66390[0m
[93maverage test of epoch 13: loss -5.97997 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 14: loss -6.39453 acc 0.66667 roc_auc 0.44000 prc_auc 0.64213[0m
[93maverage test of epoch 14: loss -6.51985 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 15: loss -6.94976 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 15: loss -7.07138 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 16: loss -7.51719 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 16: loss -7.63654 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 17: loss -8.09878 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 17: loss -8.21746 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 18: loss -8.69711 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 18: loss -8.81588 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -9.31315 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 19: loss -9.43313 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -9.94926 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 20: loss -10.07107 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -10.60293 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 21: loss -10.72411 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -11.27610 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 22: loss -11.40087 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -11.97323 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 23: loss -12.10191 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -12.69403 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 24: loss -12.82646 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -13.43954 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 25: loss -13.57634 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -14.21080 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 26: loss -14.35249 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -15.00931 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 27: loss -15.15688 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -15.83727 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 28: loss -15.99141 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -16.69671 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 29: loss -16.85819 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -17.58881 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 30: loss -17.75843 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -18.51568 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 31: loss -18.69343 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -19.47883 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 32: loss -19.66600 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -20.48027 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 33: loss -20.67752 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -21.52196 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -21.72980 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -22.60410 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -22.82117 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -23.72640 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -23.95377 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -24.89162 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -25.13030 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -26.10183 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -26.35217 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -27.35889 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -27.62190 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -28.66518 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -28.94144 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -30.02286 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -30.31303 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -31.43375 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -31.73822 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -32.89914 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -33.21798 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -34.41999 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -34.75313 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -35.99713 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -36.34465 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -37.63164 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -37.99383 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -39.32530 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -39.70280 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -41.08002 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -41.47319 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -42.89769 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -43.30705 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 50: loss -44.77959 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 50: loss -45.20529 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 51: loss -46.72574 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 51: loss -47.16525 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 52: loss -48.73339 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 52: loss -49.18646 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 53: loss -50.80287 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 53: loss -51.26897 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 54: loss -52.93476 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 54: loss -53.41452 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 55: loss -55.13126 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 55: loss -55.62549 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 56: loss -57.39446 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 56: loss -57.90344 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 57: loss -59.72615 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 57: loss -60.25064 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 58: loss -62.12850 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 58: loss -62.66897 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 59: loss -64.60344 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 59: loss -65.16055 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 60: loss -67.15282 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 60: loss -67.72663 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 61: loss -69.77814 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 61: loss -70.36922 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 62: loss -72.48141 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 62: loss -73.09031 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 63: loss -75.26424 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 63: loss -75.89079 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 64: loss -78.12721 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 64: loss -78.77088 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 65: loss -81.07067 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 65: loss -81.73163 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 66: loss -84.09611 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 66: loss -84.77465 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 67: loss -87.20507 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 67: loss -87.90145 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 68: loss -90.39902 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 68: loss -91.11336 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 69: loss -93.67927 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 69: loss -94.41175 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 70: loss -97.04707 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 70: loss -97.79788 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 71: loss -100.50381 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 71: loss -101.27279 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 72: loss -104.05043 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 72: loss -104.83785 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 73: loss -107.68818 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 73: loss -108.49377 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 74: loss -111.41779 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 74: loss -112.24161 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 75: loss -115.24033 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 75: loss -116.08231 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 76: loss -119.15667 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 76: loss -120.01659 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 77: loss -123.16717 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 77: loss -124.04370 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 78: loss -127.26787 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 78: loss -128.15687 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 79: loss -131.45512 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 79: loss -132.35706 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 80: loss -135.73077 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 80: loss -136.64611 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 81: loss -140.09637 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 81: loss -141.02532 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 82: loss -144.55336 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 82: loss -145.49603 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 83: loss -149.10271 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 83: loss -150.05936 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 84: loss -153.74578 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 84: loss -154.71635 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 85: loss -158.48379 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 85: loss -159.46868 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 86: loss -163.31814 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 86: loss -164.31741 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 87: loss -168.24980 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 87: loss -169.26293 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 88: loss -173.27632 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 88: loss -174.29915 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 89: loss -178.39350 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 89: loss -179.42615 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -183.60270 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 90: loss -184.64583 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 91: loss -188.90580 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 91: loss -189.95978 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 92: loss -194.30426 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 92: loss -195.36905 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 93: loss -199.79920 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 93: loss -200.87522 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 94: loss -205.39209 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 94: loss -206.47957 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 95: loss -211.08450 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 95: loss -212.18405 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 96: loss -216.87816 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 96: loss -217.98957 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 97: loss -222.77409 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 97: loss -223.89794 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 98: loss -228.77381 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 98: loss -229.90974 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -234.87797 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 99: loss -236.02637 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=8, bias=True)
    (ReLU1): ReLU()
    (Linear2): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.67650 acc 0.33775 roc_auc 0.45784 prc_auc 0.64117[0m
[93maverage test of epoch 0: loss -0.89175 acc 0.32432 roc_auc 0.85000 prc_auc 0.92059[0m
[92maverage training of epoch 1: loss -1.10252 acc 0.33775 roc_auc 0.46000 prc_auc 0.64916[0m
[93maverage test of epoch 1: loss -1.29617 acc 0.32432 roc_auc 0.81000 prc_auc 0.90174[0m
[92maverage training of epoch 2: loss -1.55209 acc 0.55629 roc_auc 0.45431 prc_auc 0.64002[0m
[93maverage test of epoch 2: loss -1.84033 acc 0.67568 roc_auc 0.85000 prc_auc 0.92022[0m
[92maverage training of epoch 3: loss -2.18820 acc 0.66225 roc_auc 0.45137 prc_auc 0.63725[0m
[93maverage test of epoch 3: loss -2.57475 acc 0.67568 roc_auc 0.84333 prc_auc 0.91519[0m
[92maverage training of epoch 4: loss -3.01042 acc 0.66225 roc_auc 0.44686 prc_auc 0.63391[0m
[93maverage test of epoch 4: loss -3.48428 acc 0.67568 roc_auc 0.85333 prc_auc 0.91994[0m
[92maverage training of epoch 5: loss -3.98894 acc 0.66225 roc_auc 0.44235 prc_auc 0.63465[0m
[93maverage test of epoch 5: loss -4.53994 acc 0.67568 roc_auc 0.85667 prc_auc 0.92140[0m
[92maverage training of epoch 6: loss -5.10766 acc 0.66225 roc_auc 0.43245 prc_auc 0.62278[0m
[93maverage test of epoch 6: loss -5.73346 acc 0.67568 roc_auc 0.85667 prc_auc 0.92185[0m
[92maverage training of epoch 7: loss -6.36435 acc 0.66225 roc_auc 0.42510 prc_auc 0.61783[0m
[93maverage test of epoch 7: loss -7.06800 acc 0.67568 roc_auc 0.85667 prc_auc 0.92185[0m
[92maverage training of epoch 8: loss -7.76934 acc 0.66225 roc_auc 0.42157 prc_auc 0.61272[0m
[93maverage test of epoch 8: loss -8.55633 acc 0.67568 roc_auc 0.85333 prc_auc 0.91740[0m
[92maverage training of epoch 9: loss -9.33495 acc 0.66225 roc_auc 0.41647 prc_auc 0.60733[0m
[93maverage test of epoch 9: loss -10.20971 acc 0.67568 roc_auc 0.85333 prc_auc 0.91755[0m
[92maverage training of epoch 10: loss -11.06553 acc 0.66225 roc_auc 0.40882 prc_auc 0.59970[0m
[93maverage test of epoch 10: loss -12.02379 acc 0.67568 roc_auc 0.84000 prc_auc 0.90720[0m
[92maverage training of epoch 11: loss -12.94776 acc 0.66225 roc_auc 0.40176 prc_auc 0.59674[0m
[93maverage test of epoch 11: loss -13.97826 acc 0.67568 roc_auc 0.85833 prc_auc 0.91855[0m
[92maverage training of epoch 12: loss -14.96926 acc 0.66225 roc_auc 0.41216 prc_auc 0.60538[0m
[93maverage test of epoch 12: loss -16.10785 acc 0.67568 roc_auc 0.85500 prc_auc 0.91756[0m
[92maverage training of epoch 13: loss -17.25210 acc 0.66225 roc_auc 0.41157 prc_auc 0.60489[0m
[93maverage test of epoch 13: loss -18.53382 acc 0.67568 roc_auc 0.86167 prc_auc 0.92118[0m
[92maverage training of epoch 14: loss -19.76145 acc 0.66225 roc_auc 0.41157 prc_auc 0.60534[0m
[93maverage test of epoch 14: loss -21.13173 acc 0.67568 roc_auc 0.86000 prc_auc 0.92134[0m
[92maverage training of epoch 15: loss -22.42755 acc 0.66225 roc_auc 0.41255 prc_auc 0.59827[0m
[93maverage test of epoch 15: loss -23.87439 acc 0.67568 roc_auc 0.86167 prc_auc 0.92164[0m
[92maverage training of epoch 16: loss -25.23129 acc 0.66225 roc_auc 0.41490 prc_auc 0.59964[0m
[93maverage test of epoch 16: loss -26.75285 acc 0.67568 roc_auc 0.87000 prc_auc 0.92392[0m
[92maverage training of epoch 17: loss -28.17270 acc 0.66225 roc_auc 0.41627 prc_auc 0.59982[0m
[93maverage test of epoch 17: loss -29.77249 acc 0.67568 roc_auc 0.87000 prc_auc 0.92495[0m
[92maverage training of epoch 18: loss -31.25894 acc 0.66225 roc_auc 0.41745 prc_auc 0.60108[0m
[93maverage test of epoch 18: loss -32.94254 acc 0.67568 roc_auc 0.87000 prc_auc 0.90937[0m
[92maverage training of epoch 19: loss -34.49936 acc 0.66225 roc_auc 0.41990 prc_auc 0.60276[0m
[93maverage test of epoch 19: loss -36.26990 acc 0.67568 roc_auc 0.84500 prc_auc 0.88337[0m
[92maverage training of epoch 20: loss -37.89529 acc 0.66225 roc_auc 0.42020 prc_auc 0.60303[0m
[93maverage test of epoch 20: loss -39.75427 acc 0.67568 roc_auc 0.80667 prc_auc 0.84961[0m
[92maverage training of epoch 21: loss -41.45117 acc 0.66225 roc_auc 0.42098 prc_auc 0.60382[0m
[93maverage test of epoch 21: loss -43.40204 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 22: loss -45.17117 acc 0.66225 roc_auc 0.42225 prc_auc 0.60561[0m
[93maverage test of epoch 22: loss -47.21733 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 23: loss -49.06180 acc 0.66225 roc_auc 0.42314 prc_auc 0.60729[0m
[93maverage test of epoch 23: loss -51.20796 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 24: loss -53.13034 acc 0.66225 roc_auc 0.42637 prc_auc 0.60917[0m
[93maverage test of epoch 24: loss -55.38126 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 25: loss -57.38475 acc 0.66225 roc_auc 0.42667 prc_auc 0.60932[0m
[93maverage test of epoch 25: loss -59.74550 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 26: loss -61.83306 acc 0.66225 roc_auc 0.42765 prc_auc 0.60945[0m
[93maverage test of epoch 26: loss -64.30846 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 27: loss -66.48244 acc 0.66225 roc_auc 0.42971 prc_auc 0.60879[0m
[93maverage test of epoch 27: loss -69.07639 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 28: loss -71.33767 acc 0.66225 roc_auc 0.43363 prc_auc 0.61824[0m
[93maverage test of epoch 28: loss -74.05273 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 29: loss -76.40309 acc 0.66225 roc_auc 0.42069 prc_auc 0.61190[0m
[93maverage test of epoch 29: loss -79.24343 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 30: loss -81.68449 acc 0.66225 roc_auc 0.41265 prc_auc 0.61749[0m
[93maverage test of epoch 30: loss -84.65303 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 31: loss -87.18609 acc 0.66225 roc_auc 0.43088 prc_auc 0.63424[0m
[93maverage test of epoch 31: loss -90.28658 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 32: loss -92.91384 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 32: loss -96.15045 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 33: loss -98.87391 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 33: loss -102.25053 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 34: loss -105.07154 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 34: loss -108.59150 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 35: loss -111.51175 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 35: loss -115.17895 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 36: loss -118.19979 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 36: loss -122.01693 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 37: loss -125.13869 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 37: loss -129.10853 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 38: loss -132.33213 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 38: loss -136.45712 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 39: loss -139.78340 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 39: loss -144.06701 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -147.49785 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 40: loss -151.94381 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -155.48035 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 41: loss -160.09188 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -163.73561 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 42: loss -168.51641 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -172.26875 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 43: loss -177.22247 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -181.08494 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 44: loss -186.21550 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -190.18978 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 45: loss -195.50105 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -199.58836 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 46: loss -205.08388 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -209.28573 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 47: loss -214.96953 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -219.28729 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 48: loss -225.16313 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -229.59807 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 49: loss -235.66963 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 50: loss -240.22262 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 50: loss -246.49340 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 51: loss -251.16595 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 51: loss -257.63999 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 52: loss -262.43322 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 52: loss -269.11425 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 53: loss -274.02926 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 53: loss -280.92114 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 54: loss -285.95926 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 54: loss -293.06593 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 55: loss -298.22823 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 55: loss -305.55368 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 56: loss -310.84135 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 56: loss -318.38934 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 57: loss -323.80336 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 57: loss -331.57780 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 58: loss -337.11914 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 58: loss -345.12390 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 59: loss -350.79352 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 59: loss -359.03239 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 60: loss -364.83118 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 60: loss -373.30824 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 61: loss -379.23734 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 61: loss -387.95654 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 62: loss -394.01685 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 62: loss -402.98217 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 63: loss -409.17444 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 63: loss -418.38968 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 64: loss -424.71481 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 64: loss -434.18420 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 65: loss -440.64304 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 65: loss -450.37048 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 66: loss -456.96395 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 66: loss -466.95348 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 67: loss -473.68235 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 67: loss -483.93805 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 68: loss -490.80299 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 68: loss -501.32890 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 69: loss -508.33072 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 69: loss -519.13082 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 70: loss -526.27009 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 70: loss -537.34854 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 71: loss -544.62614 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 71: loss -555.98715 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 72: loss -563.40367 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 72: loss -575.05130 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 73: loss -582.60734 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 73: loss -594.54570 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 74: loss -602.24183 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 74: loss -614.47497 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 75: loss -622.31188 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 75: loss -634.84409 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 76: loss -642.82233 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 76: loss -655.65763 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 77: loss -663.77782 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 77: loss -676.92077 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 78: loss -685.18342 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 78: loss -698.63813 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 79: loss -707.04396 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 79: loss -720.81488 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 80: loss -729.36427 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 80: loss -743.45567 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 81: loss -752.14912 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 81: loss -766.56529 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 82: loss -775.40334 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 82: loss -790.14857 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 83: loss -799.13172 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 83: loss -814.21044 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 84: loss -823.33903 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 84: loss -838.75558 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 85: loss -848.02992 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 85: loss -863.78853 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 86: loss -873.20919 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 86: loss -889.31448 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 87: loss -898.88169 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 87: loss -915.33808 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 88: loss -925.05198 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 88: loss -941.86361 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 89: loss -951.72474 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 89: loss -968.89637 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 90: loss -978.90504 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 90: loss -996.44120 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 91: loss -1006.59769 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 91: loss -1024.50276 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 92: loss -1034.80740 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 92: loss -1053.08596 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 93: loss -1063.53883 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 93: loss -1082.19538 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 94: loss -1092.79627 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 94: loss -1111.83474 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 95: loss -1122.58423 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 95: loss -1142.00949 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 96: loss -1152.90759 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 96: loss -1172.72472 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 97: loss -1183.77173 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 97: loss -1203.98521 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 98: loss -1215.18158 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 98: loss -1235.79596 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 99: loss -1247.14138 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 99: loss -1268.16106 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=8, bias=True)
    (ReLU1): ReLU()
    (Linear2): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.63562 acc 0.66225 roc_auc 0.40529 prc_auc 0.60234[0m
[93maverage test of epoch 0: loss -0.71978 acc 0.67568 roc_auc 0.10667 prc_auc 0.50832[0m
[92maverage training of epoch 1: loss -0.75688 acc 0.66225 roc_auc 0.41294 prc_auc 0.60733[0m
[93maverage test of epoch 1: loss -0.84945 acc 0.67568 roc_auc 0.47667 prc_auc 0.77626[0m
[92maverage training of epoch 2: loss -0.92981 acc 0.66225 roc_auc 0.41627 prc_auc 0.61533[0m
[93maverage test of epoch 2: loss -1.18709 acc 0.67568 roc_auc 0.86000 prc_auc 0.94454[0m
[92maverage training of epoch 3: loss -1.41555 acc 0.66225 roc_auc 0.42373 prc_auc 0.63335[0m
[93maverage test of epoch 3: loss -1.78275 acc 0.67568 roc_auc 0.89000 prc_auc 0.95367[0m
[92maverage training of epoch 4: loss -2.33888 acc 0.66225 roc_auc 0.42314 prc_auc 0.62074[0m
[93maverage test of epoch 4: loss -2.97765 acc 0.67568 roc_auc 0.50833 prc_auc 0.79388[0m
[92maverage training of epoch 5: loss -3.47336 acc 0.66225 roc_auc 0.42294 prc_auc 0.62274[0m
[93maverage test of epoch 5: loss -4.07567 acc 0.67568 roc_auc 0.90667 prc_auc 0.96218[0m
[92maverage training of epoch 6: loss -4.60068 acc 0.66225 roc_auc 0.42098 prc_auc 0.62110[0m
[93maverage test of epoch 6: loss -5.24517 acc 0.67568 roc_auc 0.92000 prc_auc 0.97009[0m
[92maverage training of epoch 7: loss -5.78312 acc 0.66225 roc_auc 0.42118 prc_auc 0.62117[0m
[93maverage test of epoch 7: loss -6.45482 acc 0.67568 roc_auc 0.92333 prc_auc 0.97185[0m
[92maverage training of epoch 8: loss -7.00098 acc 0.66225 roc_auc 0.42118 prc_auc 0.62118[0m
[93maverage test of epoch 8: loss -7.70281 acc 0.67568 roc_auc 0.92667 prc_auc 0.97185[0m
[92maverage training of epoch 9: loss -8.27317 acc 0.66225 roc_auc 0.42176 prc_auc 0.62146[0m
[93maverage test of epoch 9: loss -9.03200 acc 0.67568 roc_auc 0.92833 prc_auc 0.97185[0m
[92maverage training of epoch 10: loss -9.68561 acc 0.66225 roc_auc 0.42275 prc_auc 0.62220[0m
[93maverage test of epoch 10: loss -10.61068 acc 0.67568 roc_auc 0.94000 prc_auc 0.97122[0m
[92maverage training of epoch 11: loss -11.39005 acc 0.66225 roc_auc 0.42480 prc_auc 0.62440[0m
[93maverage test of epoch 11: loss -12.34474 acc 0.67568 roc_auc 0.94833 prc_auc 0.97346[0m
[92maverage training of epoch 12: loss -13.02548 acc 0.66225 roc_auc 0.42412 prc_auc 0.62312[0m
[93maverage test of epoch 12: loss -13.94593 acc 0.67568 roc_auc 0.92667 prc_auc 0.95977[0m
[92maverage training of epoch 13: loss -14.61736 acc 0.66225 roc_auc 0.42422 prc_auc 0.62342[0m
[93maverage test of epoch 13: loss -15.56283 acc 0.67568 roc_auc 0.92000 prc_auc 0.94811[0m
[92maverage training of epoch 14: loss -16.24435 acc 0.66225 roc_auc 0.42441 prc_auc 0.62337[0m
[93maverage test of epoch 14: loss -17.22759 acc 0.67568 roc_auc 0.58000 prc_auc 0.72757[0m
[92maverage training of epoch 15: loss -17.92479 acc 0.66225 roc_auc 0.42402 prc_auc 0.62212[0m
[93maverage test of epoch 15: loss -18.94991 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 16: loss -19.66463 acc 0.66225 roc_auc 0.42451 prc_auc 0.62167[0m
[93maverage test of epoch 16: loss -20.73415 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 17: loss -21.46881 acc 0.66225 roc_auc 0.41833 prc_auc 0.61867[0m
[93maverage test of epoch 17: loss -22.58597 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 18: loss -23.34305 acc 0.66225 roc_auc 0.40186 prc_auc 0.60345[0m
[93maverage test of epoch 18: loss -24.51115 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 19: loss -25.29290 acc 0.66225 roc_auc 0.43471 prc_auc 0.63159[0m
[93maverage test of epoch 19: loss -26.51473 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 20: loss -27.32078 acc 0.66225 roc_auc 0.50500 prc_auc 0.66563[0m
[93maverage test of epoch 20: loss -28.59670 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 21: loss -29.42801 acc 0.66225 roc_auc 0.49922 prc_auc 0.66190[0m
[93maverage test of epoch 21: loss -30.76094 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 22: loss -31.61974 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 22: loss -33.01307 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 23: loss -33.90135 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 23: loss -35.35822 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 24: loss -36.27770 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 24: loss -37.80115 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 25: loss -38.75333 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 25: loss -40.34627 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 26: loss -41.33261 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 26: loss -42.99795 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 27: loss -44.01975 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 27: loss -45.76035 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 28: loss -46.81867 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 28: loss -48.63664 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 29: loss -49.73112 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 29: loss -51.62733 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 30: loss -52.75721 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 30: loss -54.73209 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 31: loss -55.89795 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 31: loss -57.95430 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 32: loss -59.15729 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 32: loss -61.29780 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 33: loss -62.53819 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 33: loss -64.76360 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 34: loss -66.04011 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 34: loss -68.35134 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 35: loss -69.66495 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 35: loss -72.06495 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 36: loss -73.41702 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 36: loss -75.90893 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 37: loss -77.30019 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 37: loss -79.88640 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 38: loss -81.31781 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 38: loss -84.00137 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 39: loss -85.47393 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 39: loss -88.25780 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -89.77234 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 40: loss -92.65940 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -94.21661 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 41: loss -97.20971 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -98.81030 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 42: loss -101.91231 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -103.55700 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 43: loss -106.77080 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -108.46003 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 44: loss -111.78826 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -113.52217 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 45: loss -116.96725 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -118.74602 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 46: loss -122.31028 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -124.13399 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 47: loss -127.81974 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -129.68822 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 48: loss -133.49687 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -135.40794 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 49: loss -139.33909 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 50: loss -141.29208 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 50: loss -145.34615 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 51: loss -147.33820 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 51: loss -151.51417 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 52: loss -153.54516 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 52: loss -157.84500 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 53: loss -159.91453 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 53: loss -164.33893 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 54: loss -166.44713 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 54: loss -170.99853 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 55: loss -173.14598 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 55: loss -177.82651 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 56: loss -180.01349 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 56: loss -184.82550 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 57: loss -187.05281 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
Using backend: pytorch
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
[93maverage test of epoch 57: loss -191.99878 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 58: loss -194.26658 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 58: loss -199.34857 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 59: loss -201.65714 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 59: loss -206.87751 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 60: loss -209.22724 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 60: loss -214.58828 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 61: loss -216.97956 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 61: loss -222.48354 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 62: loss -224.91630 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 62: loss -230.56517 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 63: loss -233.03970 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 63: loss -238.83593 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 64: loss -241.35245 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 64: loss -247.29812 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 65: loss -249.85665 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 65: loss -255.95412 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 66: loss -258.55490 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 66: loss -264.80642 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 67: loss -267.44956 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 67: loss -273.85737 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 68: loss -276.54291 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 68: loss -283.10917 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 69: loss -285.83728 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 69: loss -292.56433 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 70: loss -295.33499 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 70: loss -302.22517 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 71: loss -305.03838 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 71: loss -312.09379 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 72: loss -314.94956 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 72: loss -322.17259 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 73: loss -325.07094 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 73: loss -332.46356 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 74: loss -335.40449 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 74: loss -342.96933 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 75: loss -345.95289 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 75: loss -353.69207 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 76: loss -356.71793 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 76: loss -364.63351 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 77: loss -367.70171 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 77: loss -375.79625 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 78: loss -378.90686 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 78: loss -387.18257 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 79: loss -390.33542 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 79: loss -398.79475 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 80: loss -401.98981 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 80: loss -410.63488 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 81: loss -413.87193 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 81: loss -422.70516 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 82: loss -425.98415 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 82: loss -435.00763 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 83: loss -438.32829 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 83: loss -447.54454 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 84: loss -450.90695 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 84: loss -460.31837 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 85: loss -463.72218 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 85: loss -473.33106 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 86: loss -476.77630 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 86: loss -486.58503 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 87: loss -490.07157 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 87: loss -500.08263 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 88: loss -503.61018 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 88: loss -513.82583 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 89: loss -517.39419 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 89: loss -527.81677 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 90: loss -531.42725 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 90: loss -542.08022 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 91: loss -545.86745 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 91: loss -556.87313 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 92: loss -560.73025 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 92: loss -571.96817 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 93: loss -575.86959 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 93: loss -587.33232 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 94: loss -591.27825 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 94: loss -602.96868 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 95: loss -607.00385 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 95: loss -619.04374 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 96: loss -623.24757 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 96: loss -635.58535 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 97: loss -639.84554 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 97: loss -652.43195 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 98: loss -656.74425 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 98: loss -669.58102 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 99: loss -673.94656 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 99: loss -687.03853 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 2)
('lr', 0.0001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.60185 ROC_AUC (avg): 0.5 PRC_AUC (avg): 0.66501 

Average forward propagation time taken(ms): 3.106155022101985
Average backward propagation time taken(ms): 0.9967157552214485

