# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-11-24-07/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-11-24-07/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 16,
 'epochs': 100,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 8,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.001,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 2,
 'num_workers': 8,
 'number_of_mlp_layer': 0,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-18-11-24-07',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 100, 'learning_rate': 0.001, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -1.56179 acc 0.66000 roc_auc 0.44680 prc_auc 0.65326[0m
[93maverage test of epoch 0: loss -2.39189 acc 0.65789 roc_auc 0.76308 prc_auc 0.89205[0m
[92maverage training of epoch 1: loss -3.02458 acc 0.66667 roc_auc 0.57640 prc_auc 0.74401[0m
[93maverage test of epoch 1: loss -3.61227 acc 0.65789 roc_auc 0.72308 prc_auc 0.86957[0m
[92maverage training of epoch 2: loss -4.21405 acc 0.66000 roc_auc 0.61260 prc_auc 0.76599[0m
[93maverage test of epoch 2: loss -4.89718 acc 0.65789 roc_auc 0.88308 prc_auc 0.94542[0m
[92maverage training of epoch 3: loss -5.56618 acc 0.75333 roc_auc 0.84020 prc_auc 0.89641[0m
[93maverage test of epoch 3: loss -6.16743 acc 0.81579 roc_auc 0.88615 prc_auc 0.94406[0m
[92maverage training of epoch 4: loss -6.78173 acc 0.78000 roc_auc 0.82060 prc_auc 0.85344[0m
[93maverage test of epoch 4: loss -7.30265 acc 0.78947 roc_auc 0.85538 prc_auc 0.92009[0m
[92maverage training of epoch 5: loss -7.93377 acc 0.81333 roc_auc 0.81620 prc_auc 0.84045[0m
[93maverage test of epoch 5: loss -8.34394 acc 0.78947 roc_auc 0.82769 prc_auc 0.90598[0m
[92maverage training of epoch 6: loss -8.99553 acc 0.82000 roc_auc 0.81180 prc_auc 0.83089[0m
[93maverage test of epoch 6: loss -9.38184 acc 0.76316 roc_auc 0.87077 prc_auc 0.93015[0m
[92maverage training of epoch 7: loss -10.03897 acc 0.81333 roc_auc 0.80560 prc_auc 0.82314[0m
[93maverage test of epoch 7: loss -10.42206 acc 0.71053 roc_auc 0.86154 prc_auc 0.91294[0m
[92maverage training of epoch 8: loss -11.10038 acc 0.81333 roc_auc 0.83640 prc_auc 0.84318[0m
[93maverage test of epoch 8: loss -11.39461 acc 0.68421 roc_auc 0.84308 prc_auc 0.91953[0m
[92maverage training of epoch 9: loss -12.09916 acc 0.68000 roc_auc 0.81260 prc_auc 0.82180[0m
[93maverage test of epoch 9: loss -12.39568 acc 0.68421 roc_auc 0.86462 prc_auc 0.92537[0m
[92maverage training of epoch 10: loss -13.08355 acc 0.66667 roc_auc 0.78660 prc_auc 0.81067[0m
[93maverage test of epoch 10: loss -13.36586 acc 0.65789 roc_auc 0.84000 prc_auc 0.87198[0m
[92maverage training of epoch 11: loss -14.08657 acc 0.66667 roc_auc 0.80740 prc_auc 0.81915[0m
[93maverage test of epoch 11: loss -14.36095 acc 0.65789 roc_auc 0.83692 prc_auc 0.85321[0m
[92maverage training of epoch 12: loss -15.05356 acc 0.66667 roc_auc 0.83310 prc_auc 0.82841[0m
[93maverage test of epoch 12: loss -15.28929 acc 0.65789 roc_auc 0.80615 prc_auc 0.84621[0m
[92maverage training of epoch 13: loss -16.02336 acc 0.66667 roc_auc 0.81000 prc_auc 0.82287[0m
[93maverage test of epoch 13: loss -16.28513 acc 0.65789 roc_auc 0.86154 prc_auc 0.92749[0m
[92maverage training of epoch 14: loss -17.02901 acc 0.66667 roc_auc 0.82620 prc_auc 0.82289[0m
[93maverage test of epoch 14: loss -17.17951 acc 0.65789 roc_auc 0.84615 prc_auc 0.91252[0m
[92maverage training of epoch 15: loss -17.94982 acc 0.66667 roc_auc 0.80720 prc_auc 0.81150[0m
[93maverage test of epoch 15: loss -18.10279 acc 0.65789 roc_auc 0.83692 prc_auc 0.89981[0m
[92maverage training of epoch 16: loss -18.91824 acc 0.66667 roc_auc 0.82400 prc_auc 0.82233[0m
[93maverage test of epoch 16: loss -19.12379 acc 0.65789 roc_auc 0.87231 prc_auc 0.93974[0m
[92maverage training of epoch 17: loss -19.87425 acc 0.66667 roc_auc 0.81840 prc_auc 0.82276[0m
[93maverage test of epoch 17: loss -20.01641 acc 0.65789 roc_auc 0.87846 prc_auc 0.94589[0m
[92maverage training of epoch 18: loss -20.88185 acc 0.66667 roc_auc 0.81140 prc_auc 0.81050[0m
[93maverage test of epoch 18: loss -20.92194 acc 0.65789 roc_auc 0.81692 prc_auc 0.86951[0m
[92maverage training of epoch 19: loss -21.80759 acc 0.66667 roc_auc 0.82350 prc_auc 0.83480[0m
[93maverage test of epoch 19: loss -21.93459 acc 0.65789 roc_auc 0.88154 prc_auc 0.94868[0m
[92maverage training of epoch 20: loss -22.78028 acc 0.66667 roc_auc 0.83800 prc_auc 0.82945[0m
[93maverage test of epoch 20: loss -22.84916 acc 0.65789 roc_auc 0.84923 prc_auc 0.90384[0m
[92maverage training of epoch 21: loss -23.69555 acc 0.66667 roc_auc 0.82520 prc_auc 0.82473[0m
[93maverage test of epoch 21: loss -23.79008 acc 0.65789 roc_auc 0.86769 prc_auc 0.92264[0m
[92maverage training of epoch 22: loss -24.65763 acc 0.66667 roc_auc 0.82640 prc_auc 0.82773[0m
[93maverage test of epoch 22: loss -24.77504 acc 0.65789 roc_auc 0.84154 prc_auc 0.88758[0m
[92maverage training of epoch 23: loss -25.59292 acc 0.66667 roc_auc 0.83550 prc_auc 0.83938[0m
[93maverage test of epoch 23: loss -25.66162 acc 0.65789 roc_auc 0.86154 prc_auc 0.89881[0m
[92maverage training of epoch 24: loss -26.56275 acc 0.66667 roc_auc 0.82390 prc_auc 0.82871[0m
[93maverage test of epoch 24: loss -26.55120 acc 0.65789 roc_auc 0.79538 prc_auc 0.85159[0m
[92maverage training of epoch 25: loss -27.52267 acc 0.66667 roc_auc 0.83110 prc_auc 0.83304[0m
[93maverage test of epoch 25: loss -27.56259 acc 0.65789 roc_auc 0.83385 prc_auc 0.88564[0m
[92maverage training of epoch 26: loss -28.54454 acc 0.66667 roc_auc 0.83190 prc_auc 0.83851[0m
[93maverage test of epoch 26: loss -28.44165 acc 0.65789 roc_auc 0.82462 prc_auc 0.87599[0m
[92maverage training of epoch 27: loss -29.33953 acc 0.66667 roc_auc 0.82950 prc_auc 0.83525[0m
[93maverage test of epoch 27: loss -29.38707 acc 0.65789 roc_auc 0.78769 prc_auc 0.84629[0m
[92maverage training of epoch 28: loss -30.39305 acc 0.66667 roc_auc 0.84240 prc_auc 0.84983[0m
[93maverage test of epoch 28: loss -30.41319 acc 0.65789 roc_auc 0.81231 prc_auc 0.85421[0m
[92maverage training of epoch 29: loss -31.37286 acc 0.66667 roc_auc 0.84030 prc_auc 0.84876[0m
[93maverage test of epoch 29: loss -31.50365 acc 0.65789 roc_auc 0.81692 prc_auc 0.85907[0m
[92maverage training of epoch 30: loss -32.37667 acc 0.66667 roc_auc 0.83000 prc_auc 0.84710[0m
[93maverage test of epoch 30: loss -32.40045 acc 0.65789 roc_auc 0.80769 prc_auc 0.85552[0m
[92maverage training of epoch 31: loss -33.29985 acc 0.66667 roc_auc 0.83190 prc_auc 0.85596[0m
[93maverage test of epoch 31: loss -33.12323 acc 0.65789 roc_auc 0.79846 prc_auc 0.85251[0m
[92maverage training of epoch 32: loss -34.27135 acc 0.66667 roc_auc 0.84690 prc_auc 0.87502[0m
[93maverage test of epoch 32: loss -34.17204 acc 0.65789 roc_auc 0.81692 prc_auc 0.85837[0m
[92maverage training of epoch 33: loss -35.22820 acc 0.66667 roc_auc 0.84570 prc_auc 0.87432[0m
[93maverage test of epoch 33: loss -35.15978 acc 0.65789 roc_auc 0.84769 prc_auc 0.88963[0m
[92maverage training of epoch 34: loss -36.05370 acc 0.66667 roc_auc 0.83000 prc_auc 0.86392[0m
[93maverage test of epoch 34: loss -36.34385 acc 0.65789 roc_auc 0.69538 prc_auc 0.75952[0m
[92maverage training of epoch 35: loss -37.00533 acc 0.66667 roc_auc 0.77840 prc_auc 0.82206[0m
[93maverage test of epoch 35: loss -37.29249 acc 0.65789 roc_auc 0.76615 prc_auc 0.81027[0m
[92maverage training of epoch 36: loss -37.87067 acc 0.66667 roc_auc 0.85760 prc_auc 0.88712[0m
[93maverage test of epoch 36: loss -38.02527 acc 0.65789 roc_auc 0.82308 prc_auc 0.86075[0m
[92maverage training of epoch 37: loss -38.99852 acc 0.66667 roc_auc 0.83240 prc_auc 0.86345[0m
[93maverage test of epoch 37: loss -39.40510 acc 0.65789 roc_auc 0.78615 prc_auc 0.81997[0m
[92maverage training of epoch 38: loss -39.90176 acc 0.66667 roc_auc 0.85890 prc_auc 0.88848[0m
[93maverage test of epoch 38: loss -40.17441 acc 0.65789 roc_auc 0.77077 prc_auc 0.80826[0m
[92maverage training of epoch 39: loss -40.88718 acc 0.66667 roc_auc 0.87890 prc_auc 0.90024[0m
[93maverage test of epoch 39: loss -40.97405 acc 0.65789 roc_auc 0.72923 prc_auc 0.77974[0m
[92maverage training of epoch 40: loss -41.85401 acc 0.66667 roc_auc 0.85490 prc_auc 0.88423[0m
[93maverage test of epoch 40: loss -41.66527 acc 0.65789 roc_auc 0.83231 prc_auc 0.86357[0m
[92maverage training of epoch 41: loss -42.82669 acc 0.66667 roc_auc 0.87740 prc_auc 0.90037[0m
[93maverage test of epoch 41: loss -42.59478 acc 0.65789 roc_auc 0.75692 prc_auc 0.80702[0m
[92maverage training of epoch 42: loss -43.80197 acc 0.66667 roc_auc 0.86840 prc_auc 0.89479[0m
[93maverage test of epoch 42: loss -43.61943 acc 0.65789 roc_auc 0.85077 prc_auc 0.87054[0m
[92maverage training of epoch 43: loss -44.76444 acc 0.66667 roc_auc 0.86140 prc_auc 0.88690[0m
[93maverage test of epoch 43: loss -44.69659 acc 0.65789 roc_auc 0.81538 prc_auc 0.84295[0m
[92maverage training of epoch 44: loss -45.62846 acc 0.66667 roc_auc 0.83480 prc_auc 0.86375[0m
[93maverage test of epoch 44: loss -45.95838 acc 0.65789 roc_auc 0.82462 prc_auc 0.84631[0m
[92maverage training of epoch 45: loss -46.74194 acc 0.66667 roc_auc 0.86340 prc_auc 0.88891[0m
[93maverage test of epoch 45: loss -46.66952 acc 0.65789 roc_auc 0.85231 prc_auc 0.87401[0m
[92maverage training of epoch 46: loss -47.66069 acc 0.66667 roc_auc 0.86670 prc_auc 0.88910[0m
[93maverage test of epoch 46: loss -47.80553 acc 0.65789 roc_auc 0.82462 prc_auc 0.84924[0m
[92maverage training of epoch 47: loss -48.72173 acc 0.66667 roc_auc 0.85880 prc_auc 0.88374[0m
[93maverage test of epoch 47: loss -48.67074 acc 0.65789 roc_auc 0.86462 prc_auc 0.87855[0m
[92maverage training of epoch 48: loss -49.63084 acc 0.66667 roc_auc 0.83630 prc_auc 0.86636[0m
[93maverage test of epoch 48: loss -49.28510 acc 0.65789 roc_auc 0.84769 prc_auc 0.86994[0m
[92maverage training of epoch 49: loss -50.54051 acc 0.66667 roc_auc 0.84590 prc_auc 0.87271[0m
[93maverage test of epoch 49: loss -50.14872 acc 0.65789 roc_auc 0.85385 prc_auc 0.87169[0m
[92maverage training of epoch 50: loss -51.39446 acc 0.66667 roc_auc 0.84180 prc_auc 0.87083[0m
[93maverage test of epoch 50: loss -50.95651 acc 0.65789 roc_auc 0.80308 prc_auc 0.83574[0m
[92maverage training of epoch 51: loss -52.49193 acc 0.66667 roc_auc 0.84040 prc_auc 0.86859[0m
[93maverage test of epoch 51: loss -52.69892 acc 0.65789 roc_auc 0.79692 prc_auc 0.82674[0m
[92maverage training of epoch 52: loss -53.41203 acc 0.66667 roc_auc 0.85720 prc_auc 0.88261[0m
[93maverage test of epoch 52: loss -53.42883 acc 0.65789 roc_auc 0.82769 prc_auc 0.85025[0m
[92maverage training of epoch 53: loss -54.19495 acc 0.66667 roc_auc 0.84600 prc_auc 0.87707[0m
[93maverage test of epoch 53: loss -53.97876 acc 0.65789 roc_auc 0.85385 prc_auc 0.87169[0m
[92maverage training of epoch 54: loss -55.42947 acc 0.66667 roc_auc 0.86080 prc_auc 0.88379[0m
[93maverage test of epoch 54: loss -55.44922 acc 0.65789 roc_auc 0.79231 prc_auc 0.82215[0m
[92maverage training of epoch 55: loss -56.25134 acc 0.66667 roc_auc 0.85400 prc_auc 0.88092[0m
[93maverage test of epoch 55: loss -55.76800 acc 0.65789 roc_auc 0.80923 prc_auc 0.83787[0m
[92maverage training of epoch 56: loss -57.28570 acc 0.66667 roc_auc 0.83150 prc_auc 0.86027[0m
[93maverage test of epoch 56: loss -56.74456 acc 0.65789 roc_auc 0.80615 prc_auc 0.83693[0m
[92maverage training of epoch 57: loss -58.11537 acc 0.66667 roc_auc 0.85620 prc_auc 0.88091[0m
[93maverage test of epoch 57: loss -58.17670 acc 0.65789 roc_auc 0.86923 prc_auc 0.88261[0m
[92maverage training of epoch 58: loss -59.14975 acc 0.66667 roc_auc 0.83600 prc_auc 0.86627[0m
[93maverage test of epoch 58: loss -58.69495 acc 0.65789 roc_auc 0.81846 prc_auc 0.84114[0m
[92maverage training of epoch 59: loss -59.97930 acc 0.66667 roc_auc 0.84360 prc_auc 0.87279[0m
[93maverage test of epoch 59: loss -59.72030 acc 0.65789 roc_auc 0.81538 prc_auc 0.84304[0m
[92maverage training of epoch 60: loss -61.03781 acc 0.66667 roc_auc 0.84720 prc_auc 0.87401[0m
[93maverage test of epoch 60: loss -60.86092 acc 0.65789 roc_auc 0.78615 prc_auc 0.81997[0m
[92maverage training of epoch 61: loss -61.95798 acc 0.66667 roc_auc 0.83300 prc_auc 0.86478[0m
[93maverage test of epoch 61: loss -61.51793 acc 0.65789 roc_auc 0.80923 prc_auc 0.84091[0m
[92maverage training of epoch 62: loss -63.02531 acc 0.66667 roc_auc 0.84920 prc_auc 0.87519[0m
[93maverage test of epoch 62: loss -62.75651 acc 0.65789 roc_auc 0.82462 prc_auc 0.84907[0m
[92maverage training of epoch 63: loss -63.90153 acc 0.66667 roc_auc 0.82870 prc_auc 0.85957[0m
[93maverage test of epoch 63: loss -63.57147 acc 0.65789 roc_auc 0.77846 prc_auc 0.81425[0m
[92maverage training of epoch 64: loss -64.99132 acc 0.66667 roc_auc 0.85790 prc_auc 0.88348[0m
[93maverage test of epoch 64: loss -64.75956 acc 0.65789 roc_auc 0.78615 prc_auc 0.82007[0m
[92maverage training of epoch 65: loss -65.90155 acc 0.66667 roc_auc 0.85130 prc_auc 0.87561[0m
[93maverage test of epoch 65: loss -65.28779 acc 0.65789 roc_auc 0.84462 prc_auc 0.86883[0m
[92maverage training of epoch 66: loss -66.89509 acc 0.66667 roc_auc 0.86600 prc_auc 0.89025[0m
[93maverage test of epoch 66: loss -66.39219 acc 0.65789 roc_auc 0.84615 prc_auc 0.87200[0m
[92maverage training of epoch 67: loss -67.80368 acc 0.66667 roc_auc 0.86320 prc_auc 0.88366[0m
[93maverage test of epoch 67: loss -67.66888 acc 0.65789 roc_auc 0.82769 prc_auc 0.85025[0m
[92maverage training of epoch 68: loss -68.96359 acc 0.66667 roc_auc 0.88180 prc_auc 0.90094[0m
[93maverage test of epoch 68: loss -68.62582 acc 0.65789 roc_auc 0.82769 prc_auc 0.85014[0m
[92maverage training of epoch 69: loss -69.81655 acc 0.66667 roc_auc 0.86890 prc_auc 0.89121[0m
[93maverage test of epoch 69: loss -69.04579 acc 0.65789 roc_auc 0.81538 prc_auc 0.84295[0m
[92maverage training of epoch 70: loss -70.72661 acc 0.66667 roc_auc 0.85160 prc_auc 0.88103[0m
[93maverage test of epoch 70: loss -70.32057 acc 0.65789 roc_auc 0.81538 prc_auc 0.84592[0m
[92maverage training of epoch 71: loss -71.78290 acc 0.66667 roc_auc 0.87010 prc_auc 0.89173[0m
[93maverage test of epoch 71: loss -71.32654 acc 0.65789 roc_auc 0.78615 prc_auc 0.81997[0m
[92maverage training of epoch 72: loss -72.77721 acc 0.66667 roc_auc 0.87540 prc_auc 0.89379[0m
[93maverage test of epoch 72: loss -72.50189 acc 0.65789 roc_auc 0.82769 prc_auc 0.85014[0m
[92maverage training of epoch 73: loss -73.61491 acc 0.66667 roc_auc 0.85580 prc_auc 0.88193[0m
[93maverage test of epoch 73: loss -72.91363 acc 0.65789 roc_auc 0.90000 prc_auc 0.93196[0m
[92maverage training of epoch 74: loss -74.72608 acc 0.66667 roc_auc 0.88300 prc_auc 0.90150[0m
[93maverage test of epoch 74: loss -74.34949 acc 0.65789 roc_auc 0.82462 prc_auc 0.84907[0m
[92maverage training of epoch 75: loss -75.56618 acc 0.66667 roc_auc 0.86750 prc_auc 0.89047[0m
[93maverage test of epoch 75: loss -74.55350 acc 0.65789 roc_auc 0.83846 prc_auc 0.86658[0m
[92maverage training of epoch 76: loss -76.59521 acc 0.66667 roc_auc 0.87140 prc_auc 0.89256[0m
[93maverage test of epoch 76: loss -75.77129 acc 0.65789 roc_auc 0.85692 prc_auc 0.87320[0m
[92maverage training of epoch 77: loss -77.42426 acc 0.66667 roc_auc 0.87280 prc_auc 0.89166[0m
[93maverage test of epoch 77: loss -76.43184 acc 0.65789 roc_auc 0.81231 prc_auc 0.83888[0m
[92maverage training of epoch 78: loss -78.59360 acc 0.66667 roc_auc 0.89000 prc_auc 0.90891[0m
[93maverage test of epoch 78: loss -77.25901 acc 0.65789 roc_auc 0.85077 prc_auc 0.87071[0m
[92maverage training of epoch 79: loss -79.41633 acc 0.66667 roc_auc 0.86680 prc_auc 0.89579[0m
[93maverage test of epoch 79: loss -78.18258 acc 0.65789 roc_auc 0.87077 prc_auc 0.89580[0m
[92maverage training of epoch 80: loss -80.50617 acc 0.66667 roc_auc 0.86950 prc_auc 0.89203[0m
[93maverage test of epoch 80: loss -79.44116 acc 0.65789 roc_auc 0.81231 prc_auc 0.84173[0m
[92maverage training of epoch 81: loss -81.23564 acc 0.66667 roc_auc 0.87670 prc_auc 0.89831[0m
[93maverage test of epoch 81: loss -79.85020 acc 0.65789 roc_auc 0.77846 prc_auc 0.82529[0m
[92maverage training of epoch 82: loss -82.39465 acc 0.66667 roc_auc 0.87220 prc_auc 0.89236[0m
[93maverage test of epoch 82: loss -81.65589 acc 0.65789 roc_auc 0.82154 prc_auc 0.84796[0m
[92maverage training of epoch 83: loss -83.38771 acc 0.66667 roc_auc 0.87950 prc_auc 0.90024[0m
[93maverage test of epoch 83: loss -81.77620 acc 0.65789 roc_auc 0.80308 prc_auc 0.83244[0m
[92maverage training of epoch 84: loss -84.19734 acc 0.66667 roc_auc 0.88610 prc_auc 0.90717[0m
[93maverage test of epoch 84: loss -82.74523 acc 0.65789 roc_auc 0.80308 prc_auc 0.83543[0m
[92maverage training of epoch 85: loss -85.34481 acc 0.66667 roc_auc 0.88650 prc_auc 0.90786[0m
[93maverage test of epoch 85: loss -83.49394 acc 0.65789 roc_auc 0.76923 prc_auc 0.80716[0m
[92maverage training of epoch 86: loss -86.39204 acc 0.66667 roc_auc 0.88780 prc_auc 0.90816[0m
[93maverage test of epoch 86: loss -84.53333 acc 0.65789 roc_auc 0.80462 prc_auc 0.83557[0m
[92maverage training of epoch 87: loss -87.21507 acc 0.66667 roc_auc 0.88470 prc_auc 0.90669[0m
[93maverage test of epoch 87: loss -85.56822 acc 0.65789 roc_auc 0.85846 prc_auc 0.89098[0m
[92maverage training of epoch 88: loss -88.33245 acc 0.66667 roc_auc 0.87570 prc_auc 0.89926[0m
[93maverage test of epoch 88: loss -86.79528 acc 0.65789 roc_auc 0.81538 prc_auc 0.83996[0m
[92maverage training of epoch 89: loss -89.06508 acc 0.66667 roc_auc 0.88560 prc_auc 0.90700[0m
[93maverage test of epoch 89: loss -87.55443 acc 0.65789 roc_auc 0.80308 prc_auc 0.83543[0m
[92maverage training of epoch 90: loss -90.07845 acc 0.66667 roc_auc 0.88650 prc_auc 0.90780[0m
[93maverage test of epoch 90: loss -88.57950 acc 0.65789 roc_auc 0.83846 prc_auc 0.86581[0m
[92maverage training of epoch 91: loss -91.07066 acc 0.66667 roc_auc 0.87570 prc_auc 0.89921[0m
[93maverage test of epoch 91: loss -89.36664 acc 0.65789 roc_auc 0.80923 prc_auc 0.83749[0m
[92maverage training of epoch 92: loss -92.13051 acc 0.66667 roc_auc 0.86550 prc_auc 0.89094[0m
[93maverage test of epoch 92: loss -90.33641 acc 0.65789 roc_auc 0.77077 prc_auc 0.80817[0m
[92maverage training of epoch 93: loss -93.08758 acc 0.66667 roc_auc 0.88450 prc_auc 0.90679[0m
[93maverage test of epoch 93: loss -91.15442 acc 0.65789 roc_auc 0.82308 prc_auc 0.85692[0m
[92maverage training of epoch 94: loss -94.05022 acc 0.66667 roc_auc 0.88890 prc_auc 0.90842[0m
[93maverage test of epoch 94: loss -92.13494 acc 0.65789 roc_auc 0.77538 prc_auc 0.80927[0m
[92maverage training of epoch 95: loss -95.08071 acc 0.66667 roc_auc 0.88690 prc_auc 0.90784[0m
[93maverage test of epoch 95: loss -93.05433 acc 0.65789 roc_auc 0.77692 prc_auc 0.81035[0m
[92maverage training of epoch 96: loss -96.08681 acc 0.66667 roc_auc 0.88850 prc_auc 0.90890[0m
[93maverage test of epoch 96: loss -94.22139 acc 0.65789 roc_auc 0.78154 prc_auc 0.81526[0m
[92maverage training of epoch 97: loss -97.09099 acc 0.66667 roc_auc 0.87940 prc_auc 0.90062[0m
[93maverage test of epoch 97: loss -95.23217 acc 0.65789 roc_auc 0.77538 prc_auc 0.81314[0m
[92maverage training of epoch 98: loss -97.81404 acc 0.66667 roc_auc 0.87600 prc_auc 0.89895[0m
[93maverage test of epoch 98: loss -95.96360 acc 0.65789 roc_auc 0.78615 prc_auc 0.82734[0m
[92maverage training of epoch 99: loss -98.94186 acc 0.66667 roc_auc 0.88710 prc_auc 0.90776[0m
[93maverage test of epoch 99: loss -96.99569 acc 0.65789 roc_auc 0.83385 prc_auc 0.86357[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -2.71550 acc 0.66667 roc_auc 0.45260 prc_auc 0.63655[0m
[93maverage test of epoch 0: loss -4.62076 acc 0.65789 roc_auc 0.39077 prc_auc 0.59293[0m
[92maverage training of epoch 1: loss -5.67087 acc 0.66667 roc_auc 0.43160 prc_auc 0.60640[0m
[93maverage test of epoch 1: loss -6.44301 acc 0.65789 roc_auc 0.32308 prc_auc 0.60405[0m
[92maverage training of epoch 2: loss -7.08485 acc 0.66667 roc_auc 0.43300 prc_auc 0.61863[0m
[93maverage test of epoch 2: loss -7.65640 acc 0.65789 roc_auc 0.29231 prc_auc 0.59733[0m
[92maverage training of epoch 3: loss -8.22963 acc 0.66667 roc_auc 0.42740 prc_auc 0.60334[0m
[93maverage test of epoch 3: loss -8.75124 acc 0.65789 roc_auc 0.52308 prc_auc 0.69351[0m
[92maverage training of epoch 4: loss -9.31305 acc 0.66667 roc_auc 0.42900 prc_auc 0.60267[0m
[93maverage test of epoch 4: loss -9.82052 acc 0.65789 roc_auc 0.57231 prc_auc 0.72351[0m
[92maverage training of epoch 5: loss -10.37549 acc 0.66667 roc_auc 0.41560 prc_auc 0.60461[0m
[93maverage test of epoch 5: loss -10.86810 acc 0.65789 roc_auc 0.54308 prc_auc 0.73717[0m
[92maverage training of epoch 6: loss -11.41525 acc 0.66667 roc_auc 0.42160 prc_auc 0.60945[0m
[93maverage test of epoch 6: loss -11.89423 acc 0.65789 roc_auc 0.40154 prc_auc 0.59284[0m
[92maverage training of epoch 7: loss -12.44840 acc 0.66667 roc_auc 0.42300 prc_auc 0.59819[0m
[93maverage test of epoch 7: loss -12.92034 acc 0.65789 roc_auc 0.61846 prc_auc 0.79410[0m
[92maverage training of epoch 8: loss -13.47009 acc 0.66667 roc_auc 0.42890 prc_auc 0.61560[0m
[93maverage test of epoch 8: loss -13.93641 acc 0.65789 roc_auc 0.37538 prc_auc 0.63135[0m
[92maverage training of epoch 9: loss -14.48918 acc 0.66667 roc_auc 0.42190 prc_auc 0.60189[0m
[93maverage test of epoch 9: loss -14.94959 acc 0.65789 roc_auc 0.45846 prc_auc 0.67033[0m
[92maverage training of epoch 10: loss -15.50269 acc 0.66667 roc_auc 0.42330 prc_auc 0.60626[0m
[93maverage test of epoch 10: loss -15.96066 acc 0.65789 roc_auc 0.54000 prc_auc 0.67760[0m
[92maverage training of epoch 11: loss -16.51137 acc 0.66667 roc_auc 0.41460 prc_auc 0.59451[0m
[93maverage test of epoch 11: loss -16.96586 acc 0.65789 roc_auc 0.49077 prc_auc 0.70924[0m
[92maverage training of epoch 12: loss -17.52089 acc 0.66667 roc_auc 0.41970 prc_auc 0.60958[0m
[93maverage test of epoch 12: loss -17.96910 acc 0.65789 roc_auc 0.46308 prc_auc 0.65858[0m
[92maverage training of epoch 13: loss -18.52591 acc 0.66667 roc_auc 0.42300 prc_auc 0.60756[0m
[93maverage test of epoch 13: loss -18.97329 acc 0.65789 roc_auc 0.50923 prc_auc 0.67467[0m
[92maverage training of epoch 14: loss -19.52968 acc 0.66667 roc_auc 0.42480 prc_auc 0.60442[0m
[93maverage test of epoch 14: loss -19.97374 acc 0.65789 roc_auc 0.42769 prc_auc 0.62854[0m
[92maverage training of epoch 15: loss -20.53221 acc 0.66667 roc_auc 0.42070 prc_auc 0.60273[0m
[93maverage test of epoch 15: loss -20.97051 acc 0.65789 roc_auc 0.45538 prc_auc 0.66761[0m
[92maverage training of epoch 16: loss -21.53217 acc 0.66667 roc_auc 0.42150 prc_auc 0.60710[0m
[93maverage test of epoch 16: loss -21.96961 acc 0.65789 roc_auc 0.40154 prc_auc 0.60178[0m
[92maverage training of epoch 17: loss -22.53408 acc 0.66667 roc_auc 0.42030 prc_auc 0.60177[0m
[93maverage test of epoch 17: loss -22.96670 acc 0.65789 roc_auc 0.44615 prc_auc 0.64664[0m
[92maverage training of epoch 18: loss -23.53294 acc 0.66667 roc_auc 0.42070 prc_auc 0.60261[0m
[93maverage test of epoch 18: loss -23.96300 acc 0.65789 roc_auc 0.61231 prc_auc 0.71393[0m
[92maverage training of epoch 19: loss -24.53128 acc 0.66667 roc_auc 0.42110 prc_auc 0.60525[0m
[93maverage test of epoch 19: loss -24.95641 acc 0.65789 roc_auc 0.34462 prc_auc 0.58570[0m
[92maverage training of epoch 20: loss -25.52884 acc 0.66667 roc_auc 0.41860 prc_auc 0.59969[0m
[93maverage test of epoch 20: loss -25.95343 acc 0.65789 roc_auc 0.51692 prc_auc 0.66836[0m
[92maverage training of epoch 21: loss -26.52638 acc 0.66667 roc_auc 0.41840 prc_auc 0.60384[0m
[93maverage test of epoch 21: loss -26.94681 acc 0.65789 roc_auc 0.57538 prc_auc 0.70167[0m
[92maverage training of epoch 22: loss -27.52337 acc 0.66667 roc_auc 0.41700 prc_auc 0.59890[0m
[93maverage test of epoch 22: loss -27.94049 acc 0.65789 roc_auc 0.43538 prc_auc 0.63069[0m
[92maverage training of epoch 23: loss -28.52015 acc 0.66667 roc_auc 0.41890 prc_auc 0.60030[0m
[93maverage test of epoch 23: loss -28.93510 acc 0.65789 roc_auc 0.48000 prc_auc 0.64902[0m
[92maverage training of epoch 24: loss -29.51651 acc 0.66667 roc_auc 0.41790 prc_auc 0.59954[0m
[93maverage test of epoch 24: loss -29.92879 acc 0.65789 roc_auc 0.59385 prc_auc 0.70346[0m
[92maverage training of epoch 25: loss -30.51281 acc 0.66667 roc_auc 0.41970 prc_auc 0.60198[0m
[93maverage test of epoch 25: loss -30.92110 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -31.50821 acc 0.66667 roc_auc 0.42100 prc_auc 0.60432[0m
[93maverage test of epoch 26: loss -31.91404 acc 0.65789 roc_auc 0.48000 prc_auc 0.64902[0m
[92maverage training of epoch 27: loss -32.50410 acc 0.66667 roc_auc 0.42270 prc_auc 0.60860[0m
[93maverage test of epoch 27: loss -32.90660 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -33.49953 acc 0.66667 roc_auc 0.42930 prc_auc 0.61370[0m
[93maverage test of epoch 28: loss -33.89901 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -34.49474 acc 0.66667 roc_auc 0.42100 prc_auc 0.60854[0m
[93maverage test of epoch 29: loss -34.89120 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -35.48970 acc 0.66667 roc_auc 0.42370 prc_auc 0.61416[0m
[93maverage test of epoch 30: loss -35.88378 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -36.48493 acc 0.66667 roc_auc 0.43080 prc_auc 0.61911[0m
[93maverage test of epoch 31: loss -36.87610 acc 0.65789 roc_auc 0.60923 prc_auc 0.71314[0m
[92maverage training of epoch 32: loss -37.47979 acc 0.66667 roc_auc 0.43040 prc_auc 0.62095[0m
[93maverage test of epoch 32: loss -37.86805 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -38.47430 acc 0.66667 roc_auc 0.44610 prc_auc 0.63476[0m
[93maverage test of epoch 33: loss -38.86007 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -39.46918 acc 0.66667 roc_auc 0.45360 prc_auc 0.64177[0m
[93maverage test of epoch 34: loss -39.85153 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -40.46391 acc 0.66667 roc_auc 0.45880 prc_auc 0.64688[0m
[93maverage test of epoch 35: loss -40.84337 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -41.45851 acc 0.66667 roc_auc 0.45320 prc_auc 0.64393[0m
[93maverage test of epoch 36: loss -41.83509 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -42.45313 acc 0.66667 roc_auc 0.47000 prc_auc 0.65376[0m
[93maverage test of epoch 37: loss -42.82709 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -43.44749 acc 0.66667 roc_auc 0.46500 prc_auc 0.65172[0m
[93maverage test of epoch 38: loss -43.81850 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -44.44194 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -44.81036 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -45.43641 acc 0.66667 roc_auc 0.48500 prc_auc 0.66008[0m
[93maverage test of epoch 40: loss -45.80115 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -46.43067 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -46.79349 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -47.42526 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -47.78468 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -48.41953 acc 0.66667 roc_auc 0.47500 prc_auc 0.65586[0m
[93maverage test of epoch 43: loss -48.77589 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -49.41398 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -49.76771 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -50.40823 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -50.75921 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -51.40239 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -51.75065 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -52.39663 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -52.74215 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -53.39101 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -53.73353 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -54.38520 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -54.72494 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 50: loss -55.37940 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 50: loss -55.71613 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 51: loss -56.37361 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 51: loss -56.70765 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 52: loss -57.36794 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 52: loss -57.69895 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 53: loss -58.36202 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 53: loss -58.69042 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 54: loss -59.35615 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 54: loss -59.68169 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 55: loss -60.35039 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 55: loss -60.67311 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 56: loss -61.34451 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 56: loss -61.66437 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 57: loss -62.33871 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 57: loss -62.65555 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 58: loss -63.33284 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 58: loss -63.64704 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 59: loss -64.32688 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 59: loss -64.63813 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 60: loss -65.32107 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 60: loss -65.62930 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 61: loss -66.31509 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 61: loss -66.62080 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 62: loss -67.30910 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 62: loss -67.61204 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 63: loss -68.30327 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 63: loss -68.60321 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 64: loss -69.29740 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 64: loss -69.59450 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 65: loss -70.29130 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 65: loss -70.58579 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 66: loss -71.28544 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 66: loss -71.57690 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 67: loss -72.27957 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 67: loss -72.56817 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 68: loss -73.27353 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 68: loss -73.55945 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 69: loss -74.26769 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 69: loss -74.55057 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 70: loss -75.26163 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 70: loss -75.54177 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 71: loss -76.25573 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 71: loss -76.53288 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 72: loss -77.24976 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 72: loss -77.52407 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 73: loss -78.24373 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 73: loss -78.51520 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 74: loss -79.23781 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 74: loss -79.50623 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 75: loss -80.23184 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 75: loss -80.49762 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 76: loss -81.22571 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 76: loss -81.48890 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 77: loss -82.21984 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 77: loss -82.48002 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 78: loss -83.21382 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 78: loss -83.47116 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 79: loss -84.20778 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 79: loss -84.46229 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 80: loss -85.20181 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 80: loss -85.45357 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 81: loss -86.19580 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 81: loss -86.44462 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 82: loss -87.18973 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 82: loss -87.43580 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 83: loss -88.18380 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 83: loss -88.42698 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 84: loss -89.17776 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 84: loss -89.41785 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 85: loss -90.17170 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 85: loss -90.40925 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 86: loss -91.16569 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 86: loss -91.40029 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 87: loss -92.15967 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 87: loss -92.39135 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 88: loss -93.15362 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 88: loss -93.38263 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 89: loss -94.14761 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 89: loss -94.37372 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -95.14155 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 90: loss -95.36487 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 91: loss -96.13550 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 91: loss -96.35599 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 92: loss -97.12947 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 92: loss -97.34705 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 93: loss -98.12335 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 93: loss -98.33829 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 94: loss -99.11733 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 94: loss -99.32930 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 95: loss -100.11125 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 95: loss -100.32041 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 96: loss -101.10520 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 96: loss -101.31151 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 97: loss -102.09910 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 97: loss -102.30251 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 98: loss -103.09304 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 98: loss -103.29362 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -104.08693 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 99: loss -104.28469 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -0.55527 acc 0.55333 roc_auc 0.39260 prc_auc 0.61515[0m
[93maverage test of epoch 0: loss -1.36207 acc 0.65789 roc_auc 0.78462 prc_auc 0.85946[0m
[92maverage training of epoch 1: loss -2.23564 acc 0.66667 roc_auc 0.38740 prc_auc 0.61380[0m
[93maverage test of epoch 1: loss -2.93854 acc 0.65789 roc_auc 0.37231 prc_auc 0.60906[0m
[92maverage training of epoch 2: loss -3.50869 acc 0.66667 roc_auc 0.41720 prc_auc 0.63335[0m
[93maverage test of epoch 2: loss -4.05066 acc 0.65789 roc_auc 0.63385 prc_auc 0.80437[0m
[92maverage training of epoch 3: loss -4.56667 acc 0.66667 roc_auc 0.39800 prc_auc 0.60814[0m
[93maverage test of epoch 3: loss -5.06517 acc 0.65789 roc_auc 0.50462 prc_auc 0.74727[0m
[92maverage training of epoch 4: loss -5.57673 acc 0.66667 roc_auc 0.35960 prc_auc 0.58738[0m
[93maverage test of epoch 4: loss -6.09255 acc 0.65789 roc_auc 0.52615 prc_auc 0.67152[0m
[92maverage training of epoch 5: loss -6.71769 acc 0.66667 roc_auc 0.45420 prc_auc 0.63391[0m
[93maverage test of epoch 5: loss -7.38257 acc 0.65789 roc_auc 0.44308 prc_auc 0.65824[0m
[92maverage training of epoch 6: loss -7.99357 acc 0.66667 roc_auc 0.38400 prc_auc 0.59163[0m
[93maverage test of epoch 6: loss -8.56426 acc 0.65789 roc_auc 0.37538 prc_auc 0.60659[0m
[92maverage training of epoch 7: loss -9.13796 acc 0.66667 roc_auc 0.37700 prc_auc 0.57557[0m
[93maverage test of epoch 7: loss -9.67789 acc 0.65789 roc_auc 0.34769 prc_auc 0.58027[0m
[92maverage training of epoch 8: loss -10.23129 acc 0.66667 roc_auc 0.37860 prc_auc 0.58399[0m
[93maverage test of epoch 8: loss -10.74907 acc 0.65789 roc_auc 0.55385 prc_auc 0.67486[0m
[92maverage training of epoch 9: loss -11.29874 acc 0.66667 roc_auc 0.37940 prc_auc 0.58284[0m
[93maverage test of epoch 9: loss -11.80215 acc 0.65789 roc_auc 0.62000 prc_auc 0.74606[0m
[92maverage training of epoch 10: loss -12.34568 acc 0.66667 roc_auc 0.37740 prc_auc 0.57475[0m
[93maverage test of epoch 10: loss -12.84155 acc 0.65789 roc_auc 0.58462 prc_auc 0.73569[0m
[92maverage training of epoch 11: loss -13.38344 acc 0.66667 roc_auc 0.37780 prc_auc 0.57642[0m
[93maverage test of epoch 11: loss -13.87379 acc 0.65789 roc_auc 0.49231 prc_auc 0.68772[0m
[92maverage training of epoch 12: loss -14.41275 acc 0.66667 roc_auc 0.37700 prc_auc 0.57294[0m
[93maverage test of epoch 12: loss -14.89489 acc 0.65789 roc_auc 0.63231 prc_auc 0.75535[0m
[92maverage training of epoch 13: loss -15.43619 acc 0.66667 roc_auc 0.37840 prc_auc 0.58127[0m
[93maverage test of epoch 13: loss -15.91227 acc 0.65789 roc_auc 0.48769 prc_auc 0.66547[0m
[92maverage training of epoch 14: loss -16.45399 acc 0.66667 roc_auc 0.37940 prc_auc 0.57746[0m
[93maverage test of epoch 14: loss -16.92512 acc 0.65789 roc_auc 0.61077 prc_auc 0.72937[0m
[92maverage training of epoch 15: loss -17.46746 acc 0.66667 roc_auc 0.37800 prc_auc 0.57670[0m
[93maverage test of epoch 15: loss -17.93442 acc 0.65789 roc_auc 0.44769 prc_auc 0.63324[0m
[92maverage training of epoch 16: loss -18.47844 acc 0.66667 roc_auc 0.37800 prc_auc 0.57572[0m
[93maverage test of epoch 16: loss -18.94129 acc 0.65789 roc_auc 0.39231 prc_auc 0.62678[0m
[92maverage training of epoch 17: loss -19.48679 acc 0.66667 roc_auc 0.37680 prc_auc 0.57990[0m
[93maverage test of epoch 17: loss -19.94549 acc 0.65789 roc_auc 0.42615 prc_auc 0.64856[0m
[92maverage training of epoch 18: loss -20.49291 acc 0.66667 roc_auc 0.37620 prc_auc 0.57437[0m
[93maverage test of epoch 18: loss -20.94665 acc 0.65789 roc_auc 0.48154 prc_auc 0.64477[0m
[92maverage training of epoch 19: loss -21.49700 acc 0.66667 roc_auc 0.37590 prc_auc 0.57886[0m
[93maverage test of epoch 19: loss -21.94732 acc 0.65789 roc_auc 0.53077 prc_auc 0.66002[0m
[92maverage training of epoch 20: loss -22.50003 acc 0.66667 roc_auc 0.37780 prc_auc 0.57462[0m
[93maverage test of epoch 20: loss -22.94708 acc 0.65789 roc_auc 0.51077 prc_auc 0.66816[0m
[92maverage training of epoch 21: loss -23.50135 acc 0.66667 roc_auc 0.37760 prc_auc 0.57533[0m
[93maverage test of epoch 21: loss -23.94489 acc 0.65789 roc_auc 0.49692 prc_auc 0.67006[0m
[92maverage training of epoch 22: loss -24.50155 acc 0.66667 roc_auc 0.37670 prc_auc 0.57550[0m
[93maverage test of epoch 22: loss -24.94191 acc 0.65789 roc_auc 0.59385 prc_auc 0.70352[0m
[92maverage training of epoch 23: loss -25.50120 acc 0.66667 roc_auc 0.37800 prc_auc 0.57834[0m
[93maverage test of epoch 23: loss -25.93857 acc 0.65789 roc_auc 0.42923 prc_auc 0.62234[0m
[92maverage training of epoch 24: loss -26.49969 acc 0.66667 roc_auc 0.37690 prc_auc 0.57517[0m
[93maverage test of epoch 24: loss -26.93369 acc 0.65789 roc_auc 0.56769 prc_auc 0.69215[0m
[92maverage training of epoch 25: loss -27.49803 acc 0.66667 roc_auc 0.37680 prc_auc 0.57568[0m
[93maverage test of epoch 25: loss -27.92886 acc 0.65789 roc_auc 0.47538 prc_auc 0.64655[0m
[92maverage training of epoch 26: loss -28.49562 acc 0.66667 roc_auc 0.37550 prc_auc 0.57817[0m
[93maverage test of epoch 26: loss -28.92339 acc 0.65789 roc_auc 0.44000 prc_auc 0.63135[0m
[92maverage training of epoch 27: loss -29.49262 acc 0.66667 roc_auc 0.37720 prc_auc 0.57769[0m
[93maverage test of epoch 27: loss -29.91792 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -30.48932 acc 0.66667 roc_auc 0.37460 prc_auc 0.57585[0m
[93maverage test of epoch 28: loss -30.91151 acc 0.65789 roc_auc 0.47077 prc_auc 0.64526[0m
[92maverage training of epoch 29: loss -31.48541 acc 0.66667 roc_auc 0.37620 prc_auc 0.57845[0m
[93maverage test of epoch 29: loss -31.90446 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -32.48164 acc 0.66667 roc_auc 0.37800 prc_auc 0.57779[0m
[93maverage test of epoch 30: loss -32.89736 acc 0.65789 roc_auc 0.43538 prc_auc 0.63069[0m
[92maverage training of epoch 31: loss -33.47723 acc 0.66667 roc_auc 0.38470 prc_auc 0.58488[0m
[93maverage test of epoch 31: loss -33.89027 acc 0.65789 roc_auc 0.53846 prc_auc 0.67568[0m
[92maverage training of epoch 32: loss -34.47307 acc 0.66667 roc_auc 0.37640 prc_auc 0.57740[0m
[93maverage test of epoch 32: loss -34.88296 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -35.46817 acc 0.66667 roc_auc 0.38300 prc_auc 0.58627[0m
[93maverage test of epoch 33: loss -35.87486 acc 0.65789 roc_auc 0.48000 prc_auc 0.64902[0m
[92maverage training of epoch 34: loss -36.46342 acc 0.66667 roc_auc 0.38720 prc_auc 0.59310[0m
[93maverage test of epoch 34: loss -36.86759 acc 0.65789 roc_auc 0.53692 prc_auc 0.67498[0m
[92maverage training of epoch 35: loss -37.45844 acc 0.66667 roc_auc 0.38740 prc_auc 0.59362[0m
[93maverage test of epoch 35: loss -37.85935 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -38.45321 acc 0.66667 roc_auc 0.38560 prc_auc 0.59135[0m
[93maverage test of epoch 36: loss -38.85164 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -39.44812 acc 0.66667 roc_auc 0.38860 prc_auc 0.59788[0m
[93maverage test of epoch 37: loss -39.84358 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -40.44279 acc 0.66667 roc_auc 0.39540 prc_auc 0.60487[0m
[93maverage test of epoch 38: loss -40.83526 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -41.43737 acc 0.66667 roc_auc 0.39360 prc_auc 0.60616[0m
[93maverage test of epoch 39: loss -41.82706 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -42.43200 acc 0.66667 roc_auc 0.39550 prc_auc 0.61114[0m
[93maverage test of epoch 40: loss -42.81890 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -43.42648 acc 0.66667 roc_auc 0.41890 prc_auc 0.62483[0m
[93maverage test of epoch 41: loss -43.81017 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -44.42084 acc 0.66667 roc_auc 0.44000 prc_auc 0.63841[0m
[93maverage test of epoch 42: loss -44.80182 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -45.41510 acc 0.66667 roc_auc 0.43690 prc_auc 0.63673[0m
[93maverage test of epoch 43: loss -45.79322 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -46.40945 acc 0.66667 roc_auc 0.44500 prc_auc 0.64357[0m
[93maverage test of epoch 44: loss -46.78482 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -47.40354 acc 0.66667 roc_auc 0.43500 prc_auc 0.63969[0m
[93maverage test of epoch 45: loss -47.77627 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -48.39812 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -48.76776 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -49.39226 acc 0.66667 roc_auc 0.47500 prc_auc 0.65578[0m
[93maverage test of epoch 47: loss -49.75913 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -50.38651 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -50.75035 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -51.38066 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -51.74184 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 50: loss -52.37481 acc 0.66667 roc_auc 0.44000 prc_auc 0.64162[0m
[93maverage test of epoch 50: loss -52.73290 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 51: loss -53.36904 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 51: loss -53.72413 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 52: loss -54.36314 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 52: loss -54.71546 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 53: loss -55.35712 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 53: loss -55.70682 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 54: loss -56.35120 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 54: loss -56.69801 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 55: loss -57.34534 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 55: loss -57.68938 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 56: loss -58.33945 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 56: loss -58.68061 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 57: loss -59.33347 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 57: loss -59.67177 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 58: loss -60.32752 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 58: loss -60.66269 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 59: loss -61.32127 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 59: loss -61.65422 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 60: loss -62.31557 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 60: loss -62.64531 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 61: loss -63.30958 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 61: loss -63.63649 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 62: loss -64.30353 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 62: loss -64.62771 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 63: loss -65.29758 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 63: loss -65.61881 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 64: loss -66.29154 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 64: loss -66.60987 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 65: loss -67.28548 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 65: loss -67.60113 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 66: loss -68.27950 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 66: loss -68.59214 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 67: loss -69.27348 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 67: loss -69.58328 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 68: loss -70.26738 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 68: loss -70.57449 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 69: loss -71.26144 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 69: loss -71.56553 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 70: loss -72.25533 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 70: loss -72.55667 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 71: loss -73.24926 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 71: loss -73.54770 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 72: loss -74.24314 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 72: loss -74.53884 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 73: loss -75.23707 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 73: loss -75.52994 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 74: loss -76.23102 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 74: loss -76.52081 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 75: loss -77.22486 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 75: loss -77.51204 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 76: loss -78.21875 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 76: loss -78.50298 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 77: loss -79.21271 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 77: loss -79.49412 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 78: loss -80.20658 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 78: loss -80.48527 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 79: loss -81.20044 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 79: loss -81.47619 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 80: loss -82.19436 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 80: loss -82.46739 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 81: loss -83.18823 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 81: loss -83.45837 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 82: loss -84.18209 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 82: loss -84.44940 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 83: loss -85.17598 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 83: loss -85.44048 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 84: loss -86.16982 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 84: loss -86.43146 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 85: loss -87.16372 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 85: loss -87.42246 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 86: loss -88.15755 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 86: loss -88.41354 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 87: loss -89.15146 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 87: loss -89.40444 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 88: loss -90.14529 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 88: loss -90.39555 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 89: loss -91.13912 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 89: loss -91.38651 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -92.13298 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 90: loss -92.37761 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 91: loss -93.12682 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 91: loss -93.36853 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 92: loss -94.12068 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 92: loss -94.35944 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 93: loss -95.11452 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 93: loss -95.35055 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 94: loss -96.10834 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 94: loss -96.34149 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 95: loss -97.10215 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 95: loss -97.33247 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 96: loss -98.09600 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 96: loss -98.32362 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 97: loss -99.08984 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 97: loss -99.31439 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 98: loss -100.08362 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 98: loss -100.30552 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -101.07744 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 99: loss -101.29653 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -0.68349 acc 0.49007 roc_auc 0.47745 prc_auc 0.66298[0m
[93maverage test of epoch 0: loss -1.84728 acc 0.67568 roc_auc 0.82000 prc_auc 0.87110[0m
[92maverage training of epoch 1: loss -2.80479 acc 0.68212 roc_auc 0.69275 prc_auc 0.80258[0m
[93maverage test of epoch 1: loss -3.58468 acc 0.67568 roc_auc 0.86667 prc_auc 0.89863[0m
[92maverage training of epoch 2: loss -4.35261 acc 0.72185 roc_auc 0.82412 prc_auc 0.87017[0m
[93maverage test of epoch 2: loss -4.93922 acc 0.67568 roc_auc 0.85333 prc_auc 0.91734[0m
[92maverage training of epoch 3: loss -5.51853 acc 0.80795 roc_auc 0.83549 prc_auc 0.86982[0m
[93maverage test of epoch 3: loss -6.03303 acc 0.67568 roc_auc 0.85333 prc_auc 0.90464[0m
[92maverage training of epoch 4: loss -6.57604 acc 0.81457 roc_auc 0.84412 prc_auc 0.85852[0m
[93maverage test of epoch 4: loss -7.07701 acc 0.72973 roc_auc 0.80167 prc_auc 0.84834[0m
[92maverage training of epoch 5: loss -7.52435 acc 0.80132 roc_auc 0.83882 prc_auc 0.85341[0m
[93maverage test of epoch 5: loss -7.90514 acc 0.67568 roc_auc 0.86167 prc_auc 0.91013[0m
[92maverage training of epoch 6: loss -8.53423 acc 0.80132 roc_auc 0.85382 prc_auc 0.86873[0m
[93maverage test of epoch 6: loss -8.93641 acc 0.70270 roc_auc 0.87167 prc_auc 0.93034[0m
[92maverage training of epoch 7: loss -9.44402 acc 0.82119 roc_auc 0.84696 prc_auc 0.85341[0m
[93maverage test of epoch 7: loss -9.76444 acc 0.72973 roc_auc 0.81500 prc_auc 0.85097[0m
[92maverage training of epoch 8: loss -10.42189 acc 0.82119 roc_auc 0.85186 prc_auc 0.85758[0m
[93maverage test of epoch 8: loss -10.60604 acc 0.75676 roc_auc 0.82833 prc_auc 0.88769[0m
[92maverage training of epoch 9: loss -11.41903 acc 0.84106 roc_auc 0.84686 prc_auc 0.85812[0m
[93maverage test of epoch 9: loss -11.64805 acc 0.75676 roc_auc 0.83333 prc_auc 0.88185[0m
[92maverage training of epoch 10: loss -12.34639 acc 0.86093 roc_auc 0.85294 prc_auc 0.86042[0m
[93maverage test of epoch 10: loss -12.49687 acc 0.75676 roc_auc 0.85333 prc_auc 0.89336[0m
[92maverage training of epoch 11: loss -13.27257 acc 0.86093 roc_auc 0.85049 prc_auc 0.86139[0m
[93maverage test of epoch 11: loss -13.26900 acc 0.78378 roc_auc 0.83167 prc_auc 0.87415[0m
[92maverage training of epoch 12: loss -14.13976 acc 0.87417 roc_auc 0.84863 prc_auc 0.86526[0m
[93maverage test of epoch 12: loss -14.10615 acc 0.75676 roc_auc 0.83167 prc_auc 0.87415[0m
[92maverage training of epoch 13: loss -15.12012 acc 0.88079 roc_auc 0.85490 prc_auc 0.87846[0m
[93maverage test of epoch 13: loss -14.90737 acc 0.72973 roc_auc 0.79333 prc_auc 0.84401[0m
[92maverage training of epoch 14: loss -16.05655 acc 0.90066 roc_auc 0.84784 prc_auc 0.87545[0m
[93maverage test of epoch 14: loss -15.80207 acc 0.72973 roc_auc 0.79000 prc_auc 0.84312[0m
[92maverage training of epoch 15: loss -16.93622 acc 0.88742 roc_auc 0.88578 prc_auc 0.90776[0m
[93maverage test of epoch 15: loss -16.57448 acc 0.72973 roc_auc 0.75500 prc_auc 0.81602[0m
[92maverage training of epoch 16: loss -17.85171 acc 0.88742 roc_auc 0.87784 prc_auc 0.89842[0m
[93maverage test of epoch 16: loss -17.38266 acc 0.75676 roc_auc 0.71333 prc_auc 0.78907[0m
[92maverage training of epoch 17: loss -18.78425 acc 0.88079 roc_auc 0.88010 prc_auc 0.90115[0m
[93maverage test of epoch 17: loss -18.23427 acc 0.72973 roc_auc 0.71333 prc_auc 0.78907[0m
[92maverage training of epoch 18: loss -19.52340 acc 0.88742 roc_auc 0.87686 prc_auc 0.90501[0m
[93maverage test of epoch 18: loss -19.04457 acc 0.72973 roc_auc 0.75500 prc_auc 0.81602[0m
[92maverage training of epoch 19: loss -20.54273 acc 0.89404 roc_auc 0.88088 prc_auc 0.90209[0m
[93maverage test of epoch 19: loss -19.82891 acc 0.72973 roc_auc 0.70667 prc_auc 0.78732[0m
[92maverage training of epoch 20: loss -21.49027 acc 0.88742 roc_auc 0.88196 prc_auc 0.90319[0m
[93maverage test of epoch 20: loss -20.67331 acc 0.72973 roc_auc 0.67500 prc_auc 0.76475[0m
[92maverage training of epoch 21: loss -22.33103 acc 0.88742 roc_auc 0.87343 prc_auc 0.89993[0m
[93maverage test of epoch 21: loss -21.94724 acc 0.78378 roc_auc 0.74833 prc_auc 0.81429[0m
[92maverage training of epoch 22: loss -23.11641 acc 0.88079 roc_auc 0.87137 prc_auc 0.89968[0m
[93maverage test of epoch 22: loss -23.10523 acc 0.81081 roc_auc 0.78000 prc_auc 0.84051[0m
[92maverage training of epoch 23: loss -24.07752 acc 0.87417 roc_auc 0.86382 prc_auc 0.88752[0m
[93maverage test of epoch 23: loss -23.47392 acc 0.75676 roc_auc 0.71333 prc_auc 0.78907[0m
[92maverage training of epoch 24: loss -25.05361 acc 0.88742 roc_auc 0.87275 prc_auc 0.89559[0m
[93maverage test of epoch 24: loss -24.34777 acc 0.75676 roc_auc 0.74500 prc_auc 0.81349[0m
[92maverage training of epoch 25: loss -25.84705 acc 0.88079 roc_auc 0.87029 prc_auc 0.89996[0m
[93maverage test of epoch 25: loss -25.73956 acc 0.81081 roc_auc 0.79000 prc_auc 0.84324[0m
[92maverage training of epoch 26: loss -26.74187 acc 0.88079 roc_auc 0.86284 prc_auc 0.88720[0m
[93maverage test of epoch 26: loss -26.26854 acc 0.78378 roc_auc 0.74833 prc_auc 0.81429[0m
[92maverage training of epoch 27: loss -27.76597 acc 0.89404 roc_auc 0.87176 prc_auc 0.89538[0m
[93maverage test of epoch 27: loss -27.23795 acc 0.78378 roc_auc 0.74500 prc_auc 0.81349[0m
[92maverage training of epoch 28: loss -28.83774 acc 0.89404 roc_auc 0.88373 prc_auc 0.90515[0m
[93maverage test of epoch 28: loss -27.81859 acc 0.78378 roc_auc 0.71000 prc_auc 0.78823[0m
[92maverage training of epoch 29: loss -29.58131 acc 0.89404 roc_auc 0.88304 prc_auc 0.90432[0m
[93maverage test of epoch 29: loss -28.86728 acc 0.78378 roc_auc 0.74167 prc_auc 0.81274[0m
[92maverage training of epoch 30: loss -30.40144 acc 0.89404 roc_auc 0.87255 prc_auc 0.89560[0m
[93maverage test of epoch 30: loss -29.91995 acc 0.81081 roc_auc 0.74500 prc_auc 0.81371[0m
[92maverage training of epoch 31: loss -31.54450 acc 0.90066 roc_auc 0.88000 prc_auc 0.89915[0m
[93maverage test of epoch 31: loss -30.92068 acc 0.81081 roc_auc 0.78333 prc_auc 0.84170[0m
[92maverage training of epoch 32: loss -32.52449 acc 0.90066 roc_auc 0.87824 prc_auc 0.89909[0m
[93maverage test of epoch 32: loss -31.67369 acc 0.81081 roc_auc 0.74833 prc_auc 0.81474[0m
[92maverage training of epoch 33: loss -33.11614 acc 0.88742 roc_auc 0.87000 prc_auc 0.89516[0m
[93maverage test of epoch 33: loss -32.68230 acc 0.81081 roc_auc 0.79667 prc_auc 0.84512[0m
[92maverage training of epoch 34: loss -34.27679 acc 0.90066 roc_auc 0.88284 prc_auc 0.90513[0m
[93maverage test of epoch 34: loss -33.69722 acc 0.83784 roc_auc 0.80000 prc_auc 0.84601[0m
[92maverage training of epoch 35: loss -35.08276 acc 0.89404 roc_auc 0.87627 prc_auc 0.89767[0m
[93maverage test of epoch 35: loss -34.61878 acc 0.83784 roc_auc 0.79333 prc_auc 0.84428[0mUsing backend: pytorch

[92maverage training of epoch 36: loss -35.69056 acc 0.89404 roc_auc 0.86686 prc_auc 0.89380[0m
[93maverage test of epoch 36: loss -35.31716 acc 0.81081 roc_auc 0.80667 prc_auc 0.84796[0m
[92maverage training of epoch 37: loss -36.82753 acc 0.89404 roc_auc 0.87941 prc_auc 0.89884[0m
[93maverage test of epoch 37: loss -36.30666 acc 0.83784 roc_auc 0.79000 prc_auc 0.84348[0m
[92maverage training of epoch 38: loss -37.92014 acc 0.90728 roc_auc 0.88010 prc_auc 0.90437[0m
[93maverage test of epoch 38: loss -37.21257 acc 0.83784 roc_auc 0.80000 prc_auc 0.84601[0m
[92maverage training of epoch 39: loss -38.82441 acc 0.90728 roc_auc 0.88010 prc_auc 0.90437[0m
[93maverage test of epoch 39: loss -37.77749 acc 0.78378 roc_auc 0.80333 prc_auc 0.84695[0m
[92maverage training of epoch 40: loss -39.19810 acc 0.88079 roc_auc 0.85647 prc_auc 0.88078[0m
[93maverage test of epoch 40: loss -38.83873 acc 0.81081 roc_auc 0.73000 prc_auc 0.79741[0m
[92maverage training of epoch 41: loss -39.83911 acc 0.86093 roc_auc 0.82922 prc_auc 0.86253[0m
[93maverage test of epoch 41: loss -39.52609 acc 0.81081 roc_auc 0.76167 prc_auc 0.81802[0m
[92maverage training of epoch 42: loss -41.05751 acc 0.88742 roc_auc 0.86882 prc_auc 0.89490[0m
[93maverage test of epoch 42: loss -40.45986 acc 0.81081 roc_auc 0.75167 prc_auc 0.81549[0m
[92maverage training of epoch 43: loss -41.99514 acc 0.89404 roc_auc 0.86431 prc_auc 0.89280[0m
[93maverage test of epoch 43: loss -41.69636 acc 0.83784 roc_auc 0.80000 prc_auc 0.84601[0m
[92maverage training of epoch 44: loss -43.19226 acc 0.90066 roc_auc 0.87647 prc_auc 0.89797[0m
[93maverage test of epoch 44: loss -42.51028 acc 0.83784 roc_auc 0.79000 prc_auc 0.84348[0m
[92maverage training of epoch 45: loss -44.12290 acc 0.90066 roc_auc 0.87706 prc_auc 0.89824[0m
[93maverage test of epoch 45: loss -42.90478 acc 0.81081 roc_auc 0.76500 prc_auc 0.81896[0m
[92maverage training of epoch 46: loss -44.93656 acc 0.90066 roc_auc 0.87471 prc_auc 0.89724[0m
[93maverage test of epoch 46: loss -43.71874 acc 0.81081 roc_auc 0.75833 prc_auc 0.81713[0m
[92maverage training of epoch 47: loss -41.28485 acc 0.78146 roc_auc 0.72176 prc_auc 0.85416[0m
[93maverage test of epoch 47: loss -27.17805 acc 0.37838 roc_auc 0.37000 prc_auc 0.64958[0m
[92maverage training of epoch 48: loss -44.83076 acc 0.84106 roc_auc 0.82627 prc_auc 0.85767[0m
[93maverage test of epoch 48: loss -45.37075 acc 0.81081 roc_auc 0.74167 prc_auc 0.81258[0m
[92maverage training of epoch 49: loss -47.57339 acc 0.90066 roc_auc 0.86412 prc_auc 0.88455[0m
[93maverage test of epoch 49: loss -46.08894 acc 0.81081 roc_auc 0.75167 prc_auc 0.81525[0m
[92maverage training of epoch 50: loss -48.82901 acc 0.91391 roc_auc 0.88412 prc_auc 0.90160[0m
[93maverage test of epoch 50: loss -46.75392 acc 0.78378 roc_auc 0.71000 prc_auc 0.78840[0m
[92maverage training of epoch 51: loss -48.03508 acc 0.88079 roc_auc 0.86039 prc_auc 0.91094[0m
[93maverage test of epoch 51: loss -48.47703 acc 0.83784 roc_auc 0.83500 prc_auc 0.87526[0m
[92maverage training of epoch 52: loss -50.54222 acc 0.90066 roc_auc 0.89275 prc_auc 0.90908[0m
[93maverage test of epoch 52: loss -48.81318 acc 0.81081 roc_auc 0.74833 prc_auc 0.81446[0m
[92maverage training of epoch 53: loss -50.21506 acc 0.87417 roc_auc 0.84902 prc_auc 0.88661[0m
[93maverage test of epoch 53: loss -50.09410 acc 0.83784 roc_auc 0.80667 prc_auc 0.84796[0m
[92maverage training of epoch 54: loss -51.46562 acc 0.89404 roc_auc 0.86294 prc_auc 0.89717[0m
[93maverage test of epoch 54: loss -51.30996 acc 0.83784 roc_auc 0.82833 prc_auc 0.87326[0m
[92maverage training of epoch 55: loss -53.10993 acc 0.90066 roc_auc 0.86941 prc_auc 0.89112[0m
[93maverage test of epoch 55: loss -51.93252 acc 0.83784 roc_auc 0.78667 prc_auc 0.84273[0m
[92maverage training of epoch 56: loss -53.69098 acc 0.90066 roc_auc 0.87176 prc_auc 0.90121[0m
[93maverage test of epoch 56: loss -52.65973 acc 0.81081 roc_auc 0.80333 prc_auc 0.84695[0m
[92maverage training of epoch 57: loss -54.70015 acc 0.90728 roc_auc 0.88314 prc_auc 0.91018[0m
[93maverage test of epoch 57: loss -54.21207 acc 0.86486 roc_auc 0.82167 prc_auc 0.87162[0m
[92maverage training of epoch 58: loss -55.17070 acc 0.89404 roc_auc 0.86520 prc_auc 0.89839[0m
[93maverage test of epoch 58: loss -54.96729 acc 0.86486 roc_auc 0.83500 prc_auc 0.87526[0m
[92maverage training of epoch 59: loss -56.76262 acc 0.91391 roc_auc 0.88412 prc_auc 0.90106[0m
[93maverage test of epoch 59: loss -56.04113 acc 0.86486 roc_auc 0.82833 prc_auc 0.87398[0m
[92maverage training of epoch 60: loss -57.08482 acc 0.90066 roc_auc 0.87980 prc_auc 0.90877[0m
[93maverage test of epoch 60: loss -56.57683 acc 0.83784 roc_auc 0.82500 prc_auc 0.87287[0m
[92maverage training of epoch 61: loss -58.28364 acc 0.90728 roc_auc 0.88765 prc_auc 0.91183[0m
[93maverage test of epoch 61: loss -56.46952 acc 0.81081 roc_auc 0.81333 prc_auc 0.86625[0m
[92maverage training of epoch 62: loss -58.98544 acc 0.89404 roc_auc 0.86618 prc_auc 0.88961[0m
[93maverage test of epoch 62: loss -57.26296 acc 0.83784 roc_auc 0.77667 prc_auc 0.83668[0m
[92maverage training of epoch 63: loss -59.93278 acc 0.90066 roc_auc 0.88157 prc_auc 0.90980[0m
[93maverage test of epoch 63: loss -58.28496 acc 0.83784 roc_auc 0.78000 prc_auc 0.83726[0m
[92maverage training of epoch 64: loss -60.76015 acc 0.90066 roc_auc 0.88059 prc_auc 0.90945[0m
[93maverage test of epoch 64: loss -59.48006 acc 0.81081 roc_auc 0.76167 prc_auc 0.81823[0m
[92maverage training of epoch 65: loss -61.87390 acc 0.90728 roc_auc 0.88882 prc_auc 0.91210[0m
[93maverage test of epoch 65: loss -60.31521 acc 0.81081 roc_auc 0.78667 prc_auc 0.84273[0m
[92maverage training of epoch 66: loss -62.45355 acc 0.90066 roc_auc 0.88039 prc_auc 0.90889[0m
[93maverage test of epoch 66: loss -58.19573 acc 0.78378 roc_auc 0.76667 prc_auc 0.84407[0m
[92maverage training of epoch 67: loss -63.58682 acc 0.92053 roc_auc 0.91931 prc_auc 0.95050[0m
[93maverage test of epoch 67: loss -61.07114 acc 0.81081 roc_auc 0.76000 prc_auc 0.83160[0m
[92maverage training of epoch 68: loss -65.36412 acc 0.93377 roc_auc 0.91667 prc_auc 0.93320[0m
[93maverage test of epoch 68: loss -60.60223 acc 0.81081 roc_auc 0.79667 prc_auc 0.85429[0m
[92maverage training of epoch 69: loss -64.83779 acc 0.90728 roc_auc 0.90941 prc_auc 0.93970[0m
[93maverage test of epoch 69: loss -62.98210 acc 0.81081 roc_auc 0.78333 prc_auc 0.83778[0m
[92maverage training of epoch 70: loss -66.59289 acc 0.92053 roc_auc 0.91520 prc_auc 0.93728[0m
[93maverage test of epoch 70: loss -64.31792 acc 0.81081 roc_auc 0.76833 prc_auc 0.82007[0m
[92maverage training of epoch 71: loss -67.77925 acc 0.92715 roc_auc 0.91863 prc_auc 0.93921[0m
[93maverage test of epoch 71: loss -62.55260 acc 0.78378 roc_auc 0.79667 prc_auc 0.85513[0m
[92maverage training of epoch 72: loss -68.68941 acc 0.93377 roc_auc 0.92951 prc_auc 0.95436[0m
[93maverage test of epoch 72: loss -66.81705 acc 0.83784 roc_auc 0.79000 prc_auc 0.84324[0m
[92maverage training of epoch 73: loss -67.89996 acc 0.90066 roc_auc 0.90765 prc_auc 0.94444[0m
[93maverage test of epoch 73: loss -67.21158 acc 0.83784 roc_auc 0.78333 prc_auc 0.84170[0m
[92maverage training of epoch 74: loss -67.43549 acc 0.87417 roc_auc 0.88667 prc_auc 0.93476[0m
[93maverage test of epoch 74: loss -63.57031 acc 0.75676 roc_auc 0.79167 prc_auc 0.84963[0m
[92maverage training of epoch 75: loss -70.74660 acc 0.92053 roc_auc 0.91961 prc_auc 0.94377[0m
[93maverage test of epoch 75: loss -68.67214 acc 0.83784 roc_auc 0.81333 prc_auc 0.86614[0m
[92maverage training of epoch 76: loss -72.63347 acc 0.93377 roc_auc 0.91990 prc_auc 0.93992[0m
[93maverage test of epoch 76: loss -70.40701 acc 0.83784 roc_auc 0.79667 prc_auc 0.84497[0m
[92maverage training of epoch 77: loss -73.55478 acc 0.93377 roc_auc 0.91951 prc_auc 0.93987[0m
[93maverage test of epoch 77: loss -70.76652 acc 0.81081 roc_auc 0.80667 prc_auc 0.84796[0m
[92maverage training of epoch 78: loss -74.63707 acc 0.93377 roc_auc 0.91667 prc_auc 0.93354[0m
[93maverage test of epoch 78: loss -71.14949 acc 0.81081 roc_auc 0.73167 prc_auc 0.81017[0m
[92maverage training of epoch 79: loss -73.23219 acc 0.86755 roc_auc 0.83804 prc_auc 0.86533[0m
[93maverage test of epoch 79: loss -72.11684 acc 0.83784 roc_auc 0.83333 prc_auc 0.87200[0m
[92maverage training of epoch 80: loss -75.14408 acc 0.90728 roc_auc 0.90843 prc_auc 0.93467[0m
[93maverage test of epoch 80: loss -74.18099 acc 0.86486 roc_auc 0.81167 prc_auc 0.86905[0m
[92maverage training of epoch 81: loss -77.18399 acc 0.92715 roc_auc 0.92598 prc_auc 0.94211[0m
[93maverage test of epoch 81: loss -74.08049 acc 0.83784 roc_auc 0.83000 prc_auc 0.87146[0m
[92maverage training of epoch 82: loss -77.82962 acc 0.92715 roc_auc 0.91078 prc_auc 0.93104[0m
[93maverage test of epoch 82: loss -74.60095 acc 0.81081 roc_auc 0.75167 prc_auc 0.81513[0m
[92maverage training of epoch 83: loss -78.97467 acc 0.93377 roc_auc 0.91931 prc_auc 0.93984[0m
[93maverage test of epoch 83: loss -75.45244 acc 0.81081 roc_auc 0.73167 prc_auc 0.81017[0m
[92maverage training of epoch 84: loss -79.70504 acc 0.92715 roc_auc 0.90941 prc_auc 0.93068[0m
[93maverage test of epoch 84: loss -76.30698 acc 0.81081 roc_auc 0.75167 prc_auc 0.81513[0m
[92maverage training of epoch 85: loss -80.51139 acc 0.92715 roc_auc 0.92569 prc_auc 0.94175[0m
[93maverage test of epoch 85: loss -77.36610 acc 0.83784 roc_auc 0.83333 prc_auc 0.87161[0m
[92maverage training of epoch 86: loss -81.72066 acc 0.93377 roc_auc 0.91853 prc_auc 0.93950[0m
[93maverage test of epoch 86: loss -77.74347 acc 0.81081 roc_auc 0.83333 prc_auc 0.87152[0m
[92maverage training of epoch 87: loss -82.17214 acc 0.92715 roc_auc 0.90843 prc_auc 0.93033[0m
[93maverage test of epoch 87: loss -77.35931 acc 0.78378 roc_auc 0.76000 prc_auc 0.81415[0m
[92maverage training of epoch 88: loss -83.66138 acc 0.93377 roc_auc 0.92578 prc_auc 0.94198[0m
[93maverage test of epoch 88: loss -80.16586 acc 0.83784 roc_auc 0.82333 prc_auc 0.86992[0m
[92maverage training of epoch 89: loss -84.49187 acc 0.93377 roc_auc 0.91951 prc_auc 0.93984[0m
[93maverage test of epoch 89: loss -80.77614 acc 0.81081 roc_auc 0.75500 prc_auc 0.81602[0m
[92maverage training of epoch 90: loss -85.46613 acc 0.93377 roc_auc 0.91912 prc_auc 0.93971[0m
[93maverage test of epoch 90: loss -81.73499 acc 0.83784 roc_auc 0.82333 prc_auc 0.86834[0m
[92maverage training of epoch 91: loss -86.29684 acc 0.93377 roc_auc 0.91686 prc_auc 0.93325[0m
[93maverage test of epoch 91: loss -82.56346 acc 0.83784 roc_auc 0.79333 prc_auc 0.86095[0m
[92maverage training of epoch 92: loss -87.31096 acc 0.93377 roc_auc 0.92657 prc_auc 0.94231[0m
[93maverage test of epoch 92: loss -82.45364 acc 0.78378 roc_auc 0.75667 prc_auc 0.81314[0m
[92maverage training of epoch 93: loss -88.22541 acc 0.93377 roc_auc 0.91892 prc_auc 0.93966[0m
[93maverage test of epoch 93: loss -84.34067 acc 0.83784 roc_auc 0.81667 prc_auc 0.86703[0m
[92maverage training of epoch 94: loss -89.34613 acc 0.93377 roc_auc 0.91745 prc_auc 0.93380[0m
[93maverage test of epoch 94: loss -85.22734 acc 0.83784 roc_auc 0.82000 prc_auc 0.86801[0m
[92maverage training of epoch 95: loss -90.07443 acc 0.93377 roc_auc 0.91931 prc_auc 0.93976[0m
[93maverage test of epoch 95: loss -82.72575 acc 0.78378 roc_auc 0.79667 prc_auc 0.85509[0m
[92maverage training of epoch 96: loss -89.88156 acc 0.92053 roc_auc 0.91588 prc_auc 0.94289[0m
[93maverage test of epoch 96: loss -88.01107 acc 0.83784 roc_auc 0.78333 prc_auc 0.84170[0m
[92maverage training of epoch 97: loss -92.17180 acc 0.94040 roc_auc 0.92627 prc_auc 0.94253[0m
[93maverage test of epoch 97: loss -89.12084 acc 0.83784 roc_auc 0.79000 prc_auc 0.84383[0m
[92maverage training of epoch 98: loss -92.81282 acc 0.93377 roc_auc 0.91873 prc_auc 0.93962[0m
[93maverage test of epoch 98: loss -89.71247 acc 0.83784 roc_auc 0.80333 prc_auc 0.84695[0m
[92maverage training of epoch 99: loss -93.28320 acc 0.93377 roc_auc 0.93196 prc_auc 0.94959[0m
[93maverage test of epoch 99: loss -91.43602 acc 0.86486 roc_auc 0.83500 prc_auc 0.87526[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -1.53225 acc 0.59603 roc_auc 0.41020 prc_auc 0.59787[0m
[93maverage test of epoch 0: loss -3.23393 acc 0.67568 roc_auc 0.48667 prc_auc 0.72205[0m
[92maverage training of epoch 1: loss -4.76027 acc 0.66225 roc_auc 0.39784 prc_auc 0.60506[0m
[93maverage test of epoch 1: loss -5.73807 acc 0.67568 roc_auc 0.50333 prc_auc 0.73577[0m
[92maverage training of epoch 2: loss -6.35975 acc 0.66225 roc_auc 0.36824 prc_auc 0.56821[0m
[93maverage test of epoch 2: loss -7.02031 acc 0.67568 roc_auc 0.81000 prc_auc 0.89830[0m
[92maverage training of epoch 3: loss -7.56544 acc 0.66225 roc_auc 0.37255 prc_auc 0.57072[0m
[93maverage test of epoch 3: loss -8.17242 acc 0.67568 roc_auc 0.56000 prc_auc 0.76661[0m
[92maverage training of epoch 4: loss -8.68054 acc 0.66225 roc_auc 0.37588 prc_auc 0.57076[0m
[93maverage test of epoch 4: loss -9.27765 acc 0.67568 roc_auc 0.46833 prc_auc 0.66331[0m
[92maverage training of epoch 5: loss -9.76587 acc 0.66225 roc_auc 0.37020 prc_auc 0.57125[0m
[93maverage test of epoch 5: loss -10.34572 acc 0.67568 roc_auc 0.46667 prc_auc 0.65851[0m
[92maverage training of epoch 6: loss -10.82376 acc 0.66225 roc_auc 0.37333 prc_auc 0.57059[0m
[93maverage test of epoch 6: loss -11.40174 acc 0.67568 roc_auc 0.59833 prc_auc 0.73530[0m
[92maverage training of epoch 7: loss -11.86993 acc 0.66225 roc_auc 0.37118 prc_auc 0.57477[0m
[93maverage test of epoch 7: loss -12.44704 acc 0.67568 roc_auc 0.47167 prc_auc 0.66549[0m
[92maverage training of epoch 8: loss -12.90377 acc 0.66225 roc_auc 0.36843 prc_auc 0.56666[0m
[93maverage test of epoch 8: loss -13.48115 acc 0.67568 roc_auc 0.57667 prc_auc 0.74737[0m
[92maverage training of epoch 9: loss -13.93078 acc 0.66225 roc_auc 0.37471 prc_auc 0.57046[0m
[93maverage test of epoch 9: loss -14.51076 acc 0.67568 roc_auc 0.53667 prc_auc 0.70121[0m
[92maverage training of epoch 10: loss -14.95281 acc 0.66225 roc_auc 0.36569 prc_auc 0.56753[0m
[93maverage test of epoch 10: loss -15.53132 acc 0.67568 roc_auc 0.54667 prc_auc 0.75437[0m
[92maverage training of epoch 11: loss -15.97118 acc 0.66225 roc_auc 0.36922 prc_auc 0.56792[0m
[93maverage test of epoch 11: loss -16.55550 acc 0.67568 roc_auc 0.54333 prc_auc 0.67967[0m
[92maverage training of epoch 12: loss -16.98755 acc 0.66225 roc_auc 0.36784 prc_auc 0.56708[0m
[93maverage test of epoch 12: loss -17.57305 acc 0.67568 roc_auc 0.38833 prc_auc 0.63394[0m
[92maverage training of epoch 13: loss -17.99991 acc 0.66225 roc_auc 0.37216 prc_auc 0.57124[0m
[93maverage test of epoch 13: loss -18.58879 acc 0.67568 roc_auc 0.47000 prc_auc 0.66774[0m
[92maverage training of epoch 14: loss -19.01070 acc 0.66225 roc_auc 0.37010 prc_auc 0.56914[0m
[93maverage test of epoch 14: loss -19.60279 acc 0.67568 roc_auc 0.57833 prc_auc 0.76747[0m
[92maverage training of epoch 15: loss -20.01912 acc 0.66225 roc_auc 0.36863 prc_auc 0.56757[0m
[93maverage test of epoch 15: loss -20.61404 acc 0.67568 roc_auc 0.36667 prc_auc 0.59574[0m
[92maverage training of epoch 16: loss -21.02573 acc 0.66225 roc_auc 0.36892 prc_auc 0.56882[0m
[93maverage test of epoch 16: loss -21.62205 acc 0.67568 roc_auc 0.42667 prc_auc 0.63077[0m
[92maverage training of epoch 17: loss -22.03169 acc 0.66225 roc_auc 0.36863 prc_auc 0.56654[0m
[93maverage test of epoch 17: loss -22.63337 acc 0.67568 roc_auc 0.53833 prc_auc 0.69075[0m
[92maverage training of epoch 18: loss -23.03639 acc 0.66225 roc_auc 0.36961 prc_auc 0.56863[0m
[93maverage test of epoch 18: loss -23.64251 acc 0.67568 roc_auc 0.37333 prc_auc 0.61512[0m
[92maverage training of epoch 19: loss -24.03965 acc 0.66225 roc_auc 0.37157 prc_auc 0.57140[0m
[93maverage test of epoch 19: loss -24.65000 acc 0.67568 roc_auc 0.40000 prc_auc 0.62895[0m
[92maverage training of epoch 20: loss -25.04327 acc 0.66225 roc_auc 0.36882 prc_auc 0.56748[0m
[93maverage test of epoch 20: loss -25.65706 acc 0.67568 roc_auc 0.57333 prc_auc 0.75069[0m
[92maverage training of epoch 21: loss -26.04580 acc 0.66225 roc_auc 0.37029 prc_auc 0.56797[0m
[93maverage test of epoch 21: loss -26.66406 acc 0.67568 roc_auc 0.54833 prc_auc 0.78048[0m
[92maverage training of epoch 22: loss -27.04752 acc 0.66225 roc_auc 0.36980 prc_auc 0.56961[0m
[93maverage test of epoch 22: loss -27.66944 acc 0.67568 roc_auc 0.51000 prc_auc 0.69354[0m
[92maverage training of epoch 23: loss -28.04873 acc 0.66225 roc_auc 0.36980 prc_auc 0.56816[0m
[93maverage test of epoch 23: loss -28.67523 acc 0.67568 roc_auc 0.55667 prc_auc 0.70603[0m
[92maverage training of epoch 24: loss -29.04999 acc 0.66225 roc_auc 0.36971 prc_auc 0.56809[0m
[93maverage test of epoch 24: loss -29.67983 acc 0.67568 roc_auc 0.48000 prc_auc 0.66677[0m
[92maverage training of epoch 25: loss -30.05093 acc 0.66225 roc_auc 0.37000 prc_auc 0.56955[0m
[93maverage test of epoch 25: loss -30.68592 acc 0.67568 roc_auc 0.62500 prc_auc 0.73529[0m
[92maverage training of epoch 26: loss -31.05094 acc 0.66225 roc_auc 0.36755 prc_auc 0.56873[0m
[93maverage test of epoch 26: loss -31.68966 acc 0.67568 roc_auc 0.56000 prc_auc 0.70630[0m
[92maverage training of epoch 27: loss -32.05177 acc 0.66225 roc_auc 0.36902 prc_auc 0.57082[0m
[93maverage test of epoch 27: loss -32.69409 acc 0.67568 roc_auc 0.38333 prc_auc 0.63027[0m
[92maverage training of epoch 28: loss -33.05171 acc 0.66225 roc_auc 0.36784 prc_auc 0.56813[0m
[93maverage test of epoch 28: loss -33.69832 acc 0.67568 roc_auc 0.54167 prc_auc 0.69444[0m
[92maverage training of epoch 29: loss -34.05136 acc 0.66225 roc_auc 0.37000 prc_auc 0.57178[0m
[93maverage test of epoch 29: loss -34.70224 acc 0.67568 roc_auc 0.54167 prc_auc 0.69444[0m
[92maverage training of epoch 30: loss -35.05121 acc 0.66225 roc_auc 0.36706 prc_auc 0.56868[0m
[93maverage test of epoch 30: loss -35.70625 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 31: loss -36.05052 acc 0.66225 roc_auc 0.37069 prc_auc 0.57543[0m
[93maverage test of epoch 31: loss -36.71006 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 32: loss -37.04994 acc 0.66225 roc_auc 0.36853 prc_auc 0.57384[0m
[93maverage test of epoch 32: loss -37.71352 acc 0.67568 roc_auc 0.54333 prc_auc 0.69527[0m
[92maverage training of epoch 33: loss -38.04929 acc 0.66225 roc_auc 0.36892 prc_auc 0.57943[0m
[93maverage test of epoch 33: loss -38.71679 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 34: loss -39.04856 acc 0.66225 roc_auc 0.37304 prc_auc 0.58619[0m
[93maverage test of epoch 34: loss -39.72061 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 35: loss -40.04768 acc 0.66225 roc_auc 0.37373 prc_auc 0.58099[0m
[93maverage test of epoch 35: loss -40.72398 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 36: loss -41.04678 acc 0.66225 roc_auc 0.38676 prc_auc 0.59411[0m
[93maverage test of epoch 36: loss -41.72701 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 37: loss -42.04578 acc 0.66225 roc_auc 0.37794 prc_auc 0.59155[0m
[93maverage test of epoch 37: loss -42.73035 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 38: loss -43.04479 acc 0.66225 roc_auc 0.38127 prc_auc 0.59755[0m
[93maverage test of epoch 38: loss -43.73326 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 39: loss -44.04352 acc 0.66225 roc_auc 0.39951 prc_auc 0.61159[0m
[93maverage test of epoch 39: loss -44.73674 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -45.04213 acc 0.66225 roc_auc 0.41853 prc_auc 0.62056[0m
[93maverage test of epoch 40: loss -45.73955 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -46.04112 acc 0.66225 roc_auc 0.41569 prc_auc 0.62313[0m
[93maverage test of epoch 41: loss -46.74262 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -47.04006 acc 0.66225 roc_auc 0.44284 prc_auc 0.63808[0m
[93maverage test of epoch 42: loss -47.74593 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -48.03895 acc 0.66225 roc_auc 0.45382 prc_auc 0.64238[0m
[93maverage test of epoch 43: loss -48.74890 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -49.03754 acc 0.66225 roc_auc 0.45363 prc_auc 0.64232[0m
[93maverage test of epoch 44: loss -49.75177 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -50.03621 acc 0.66225 roc_auc 0.38088 prc_auc 0.61893[0m
[93maverage test of epoch 45: loss -50.75471 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -51.03492 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 46: loss -51.75764 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -52.03372 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 47: loss -52.76068 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -53.03236 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 48: loss -53.76311 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -54.03085 acc 0.66225 roc_auc 0.46284 prc_auc 0.64620[0m
[93maverage test of epoch 49: loss -54.76645 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 50: loss -55.02962 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 50: loss -55.76903 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 51: loss -56.02816 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 51: loss -56.77198 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 52: loss -57.02676 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 52: loss -57.77473 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 53: loss -58.02510 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 53: loss -58.77764 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 54: loss -59.02383 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 54: loss -59.78036 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 55: loss -60.02235 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 55: loss -60.78322 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 56: loss -61.02094 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 56: loss -61.78594 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 57: loss -62.01936 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 57: loss -62.78884 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 58: loss -63.01799 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 58: loss -63.79155 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 59: loss -64.01647 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 59: loss -64.79440 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 60: loss -65.01503 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 60: loss -65.79690 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 61: loss -66.01348 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 61: loss -66.79956 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 62: loss -67.01198 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 62: loss -67.80267 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 63: loss -68.01058 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 63: loss -68.80536 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 64: loss -69.00904 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 64: loss -69.80812 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 65: loss -70.00758 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 65: loss -70.81092 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 66: loss -71.00613 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 66: loss -71.81354 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 67: loss -72.00461 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 67: loss -72.81650 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 68: loss -73.00310 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 68: loss -73.81913 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 69: loss -74.00154 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 69: loss -74.82193 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 70: loss -75.00008 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 70: loss -75.82466 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 71: loss -75.99856 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 71: loss -76.82742 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 72: loss -76.99710 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 72: loss -77.83010 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 73: loss -77.99556 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 73: loss -78.83297 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 74: loss -78.99399 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 74: loss -79.83564 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 75: loss -79.99253 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 75: loss -80.83838 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 76: loss -80.99100 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 76: loss -81.84105 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 77: loss -81.98940 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 77: loss -82.84381 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 78: loss -82.98793 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 78: loss -83.84652 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 79: loss -83.98637 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 79: loss -84.84922 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 80: loss -84.98486 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 80: loss -85.85175 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 81: loss -85.98330 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 81: loss -86.85450 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 82: loss -86.98171 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 82: loss -87.85733 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 83: loss -87.98017 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 83: loss -88.85994 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 84: loss -88.97857 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 84: loss -89.86280 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 85: loss -89.97708 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 85: loss -90.86540 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 86: loss -90.97542 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 86: loss -91.86792 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 87: loss -91.97391 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 87: loss -92.87070 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 88: loss -92.97227 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 88: loss -93.87343 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 89: loss -93.97070 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 89: loss -94.87601 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 90: loss -94.96907 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 90: loss -95.87871 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 91: loss -95.96750 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 91: loss -96.88133 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 92: loss -96.96590 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 92: loss -97.88392 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 93: loss -97.96427 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 93: loss -98.88645 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 94: loss -98.96261 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 94: loss -99.88921 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 95: loss -99.96104 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 95: loss -100.89183 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 96: loss -100.95938 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 96: loss -101.89452 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 97: loss -101.95774 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 97: loss -102.89711 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 98: loss -102.95614 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 98: loss -103.89961 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 99: loss -103.95444 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 99: loss -104.90228 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.70284 ROC_AUC (avg): 0.63377 PRC_AUC (avg): 0.74606 

Average forward propagation time taken(ms): 3.9830707297005405
Average backward propagation time taken(ms): 1.5253452937216558

