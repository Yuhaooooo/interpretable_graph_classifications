# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.0003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-18-56-45/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-18-56-45/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 16,
 'epochs': 50,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 8,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.0003,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 1,
 'num_workers': 8,
 'number_of_mlp_layer': 0,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-17-18-56-45',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 50, 'learning_rate': 0.0003, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.49520 acc 0.33333 roc_auc 0.42940 prc_auc 0.64570[0m
[93maverage test of epoch 0: loss -0.87571 acc 0.34211 roc_auc 0.20923 prc_auc 0.57119[0m
[92maverage training of epoch 1: loss -1.18115 acc 0.40667 roc_auc 0.43200 prc_auc 0.64755[0m
[93maverage test of epoch 1: loss -1.47495 acc 0.65789 roc_auc 0.22154 prc_auc 0.58214[0m
[92maverage training of epoch 2: loss -1.75409 acc 0.66667 roc_auc 0.43780 prc_auc 0.65726[0m
[93maverage test of epoch 2: loss -2.03690 acc 0.65789 roc_auc 0.44615 prc_auc 0.73768[0m
[92maverage training of epoch 3: loss -2.38653 acc 0.66667 roc_auc 0.43340 prc_auc 0.64935[0m
[93maverage test of epoch 3: loss -2.71993 acc 0.65789 roc_auc 0.87385 prc_auc 0.92052[0m
[92maverage training of epoch 4: loss -3.10665 acc 0.66667 roc_auc 0.43420 prc_auc 0.64935[0m
[93maverage test of epoch 4: loss -3.47239 acc 0.65789 roc_auc 0.87385 prc_auc 0.93448[0m
[92maverage training of epoch 5: loss -3.82743 acc 0.66667 roc_auc 0.41880 prc_auc 0.64028[0m
[93maverage test of epoch 5: loss -4.10682 acc 0.65789 roc_auc 0.87538 prc_auc 0.93448[0m
[92maverage training of epoch 6: loss -4.38619 acc 0.66667 roc_auc 0.40020 prc_auc 0.62842[0m
[93maverage test of epoch 6: loss -4.59034 acc 0.65789 roc_auc 0.87692 prc_auc 0.93781[0m
[92maverage training of epoch 7: loss -4.82671 acc 0.66667 roc_auc 0.40320 prc_auc 0.62483[0m
[93maverage test of epoch 7: loss -4.99418 acc 0.65789 roc_auc 0.87692 prc_auc 0.93811[0m
[92maverage training of epoch 8: loss -5.21036 acc 0.66667 roc_auc 0.40820 prc_auc 0.63317[0m
[93maverage test of epoch 8: loss -5.35962 acc 0.65789 roc_auc 0.87692 prc_auc 0.93811[0m
[92maverage training of epoch 9: loss -5.56540 acc 0.66667 roc_auc 0.42140 prc_auc 0.64186[0m
[93maverage test of epoch 9: loss -5.70485 acc 0.65789 roc_auc 0.87385 prc_auc 0.93633[0m
[92maverage training of epoch 10: loss -5.90522 acc 0.66667 roc_auc 0.43380 prc_auc 0.65125[0m
[93maverage test of epoch 10: loss -6.03947 acc 0.65789 roc_auc 0.86923 prc_auc 0.93534[0m
[92maverage training of epoch 11: loss -6.23733 acc 0.66667 roc_auc 0.43460 prc_auc 0.65546[0m
[93maverage test of epoch 11: loss -6.36923 acc 0.65789 roc_auc 0.86308 prc_auc 0.93340[0m
[92maverage training of epoch 12: loss -6.56628 acc 0.66667 roc_auc 0.45000 prc_auc 0.66208[0m
[93maverage test of epoch 12: loss -6.69767 acc 0.65789 roc_auc 0.86000 prc_auc 0.93174[0m
[92maverage training of epoch 13: loss -6.89486 acc 0.66667 roc_auc 0.45460 prc_auc 0.66469[0m
[93maverage test of epoch 13: loss -7.02680 acc 0.65789 roc_auc 0.86769 prc_auc 0.93768[0m
[92maverage training of epoch 14: loss -7.22447 acc 0.66667 roc_auc 0.45180 prc_auc 0.65982[0m
[93maverage test of epoch 14: loss -7.35733 acc 0.65789 roc_auc 0.86615 prc_auc 0.93768[0m
[92maverage training of epoch 15: loss -7.55529 acc 0.66667 roc_auc 0.44060 prc_auc 0.65372[0m
[93maverage test of epoch 15: loss -7.68875 acc 0.65789 roc_auc 0.86769 prc_auc 0.93768[0m
[92maverage training of epoch 16: loss -7.88649 acc 0.66667 roc_auc 0.42680 prc_auc 0.64414[0m
[93maverage test of epoch 16: loss -8.01985 acc 0.65789 roc_auc 0.86923 prc_auc 0.93768[0m
[92maverage training of epoch 17: loss -8.21679 acc 0.66667 roc_auc 0.41580 prc_auc 0.63448[0m
[93maverage test of epoch 17: loss -8.34924 acc 0.65789 roc_auc 0.87385 prc_auc 0.94200[0m
[92maverage training of epoch 18: loss -8.54503 acc 0.66667 roc_auc 0.40060 prc_auc 0.62424[0m
[93maverage test of epoch 18: loss -8.67593 acc 0.65789 roc_auc 0.87385 prc_auc 0.94034[0m
[92maverage training of epoch 19: loss -8.87046 acc 0.66667 roc_auc 0.38910 prc_auc 0.61649[0m
[93maverage test of epoch 19: loss -8.99943 acc 0.65789 roc_auc 0.87385 prc_auc 0.94114[0m
[92maverage training of epoch 20: loss -9.19280 acc 0.66667 roc_auc 0.38800 prc_auc 0.61404[0m
[93maverage test of epoch 20: loss -9.31967 acc 0.65789 roc_auc 0.87077 prc_auc 0.93849[0m
[92maverage training of epoch 21: loss -9.51208 acc 0.66667 roc_auc 0.38580 prc_auc 0.60952[0m
[93maverage test of epoch 21: loss -9.63687 acc 0.65789 roc_auc 0.87231 prc_auc 0.94021[0m
[92maverage training of epoch 22: loss -9.82855 acc 0.66667 roc_auc 0.38120 prc_auc 0.60006[0m
[93maverage test of epoch 22: loss -9.95133 acc 0.65789 roc_auc 0.89385 prc_auc 0.94201[0m
[92maverage training of epoch 23: loss -10.14252 acc 0.66667 roc_auc 0.37510 prc_auc 0.59259[0m
[93maverage test of epoch 23: loss -10.26339 acc 0.65789 roc_auc 0.88923 prc_auc 0.93711[0m
[92maverage training of epoch 24: loss -10.45430 acc 0.66667 roc_auc 0.37280 prc_auc 0.59160[0m
[93maverage test of epoch 24: loss -10.57340 acc 0.65789 roc_auc 0.89077 prc_auc 0.93958[0m
[92maverage training of epoch 25: loss -10.76420 acc 0.66667 roc_auc 0.37220 prc_auc 0.59098[0m
[93maverage test of epoch 25: loss -10.88165 acc 0.65789 roc_auc 0.85692 prc_auc 0.91376[0m
[92maverage training of epoch 26: loss -11.07249 acc 0.66667 roc_auc 0.37110 prc_auc 0.59001[0m
[93maverage test of epoch 26: loss -11.18840 acc 0.65789 roc_auc 0.90154 prc_auc 0.92847[0m
[92maverage training of epoch 27: loss -11.37941 acc 0.66667 roc_auc 0.36950 prc_auc 0.58918[0m
[93maverage test of epoch 27: loss -11.49387 acc 0.65789 roc_auc 0.84308 prc_auc 0.89911[0m
[92maverage training of epoch 28: loss -11.68514 acc 0.66667 roc_auc 0.36660 prc_auc 0.57861[0m
[93maverage test of epoch 28: loss -11.79824 acc 0.65789 roc_auc 0.84000 prc_auc 0.88766[0m
[92maverage training of epoch 29: loss -11.98988 acc 0.66667 roc_auc 0.36310 prc_auc 0.56711[0m
[93maverage test of epoch 29: loss -12.10169 acc 0.65789 roc_auc 0.81231 prc_auc 0.86834[0m
[92maverage training of epoch 30: loss -12.29375 acc 0.66667 roc_auc 0.36080 prc_auc 0.56522[0m
[93maverage test of epoch 30: loss -12.40433 acc 0.65789 roc_auc 0.72000 prc_auc 0.80842[0m
[92maverage training of epoch 31: loss -12.59688 acc 0.66667 roc_auc 0.35960 prc_auc 0.56455[0m
[93maverage test of epoch 31: loss -12.70629 acc 0.65789 roc_auc 0.72000 prc_auc 0.80842[0m
[92maverage training of epoch 32: loss -12.89938 acc 0.66667 roc_auc 0.35870 prc_auc 0.56315[0m
[93maverage test of epoch 32: loss -13.00766 acc 0.65789 roc_auc 0.81846 prc_auc 0.86456[0m
[92maverage training of epoch 33: loss -13.20134 acc 0.66667 roc_auc 0.35790 prc_auc 0.56307[0m
[93maverage test of epoch 33: loss -13.30853 acc 0.65789 roc_auc 0.72000 prc_auc 0.80842[0m
[92maverage training of epoch 34: loss -13.50282 acc 0.66667 roc_auc 0.35790 prc_auc 0.56312[0m
[93maverage test of epoch 34: loss -13.60895 acc 0.65789 roc_auc 0.64000 prc_auc 0.75368[0m
[92maverage training of epoch 35: loss -13.80389 acc 0.66667 roc_auc 0.35780 prc_auc 0.56252[0m
[93maverage test of epoch 35: loss -13.90899 acc 0.65789 roc_auc 0.52000 prc_auc 0.67158[0m
[92maverage training of epoch 36: loss -14.10462 acc 0.66667 roc_auc 0.35770 prc_auc 0.56229[0m
[93maverage test of epoch 36: loss -14.20871 acc 0.65789 roc_auc 0.52000 prc_auc 0.67158[0m
[92maverage training of epoch 37: loss -14.40503 acc 0.66667 roc_auc 0.35760 prc_auc 0.56242[0m
[93maverage test of epoch 37: loss -14.50814 acc 0.65789 roc_auc 0.52000 prc_auc 0.67158[0m
[92maverage training of epoch 38: loss -14.70518 acc 0.66667 roc_auc 0.35780 prc_auc 0.56242[0m
[93maverage test of epoch 38: loss -14.80732 acc 0.65789 roc_auc 0.76154 prc_auc 0.82566[0m
[92maverage training of epoch 39: loss -15.00510 acc 0.66667 roc_auc 0.35750 prc_auc 0.56199[0m
[93maverage test of epoch 39: loss -15.10628 acc 0.65789 roc_auc 0.52000 prc_auc 0.67158[0m
[92maverage training of epoch 40: loss -15.30482 acc 0.66667 roc_auc 0.35760 prc_auc 0.56201[0m
[93maverage test of epoch 40: loss -15.40506 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -15.60436 acc 0.66667 roc_auc 0.35730 prc_auc 0.56193[0m
[93maverage test of epoch 41: loss -15.70368 acc 0.65789 roc_auc 0.52000 prc_auc 0.67158[0m
[92maverage training of epoch 42: loss -15.90375 acc 0.66667 roc_auc 0.35740 prc_auc 0.56214[0m
[93maverage test of epoch 42: loss -16.00215 acc 0.65789 roc_auc 0.65385 prc_auc 0.73529[0m
[92maverage training of epoch 43: loss -16.20300 acc 0.66667 roc_auc 0.35720 prc_auc 0.56224[0m
[93maverage test of epoch 43: loss -16.30049 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -16.50214 acc 0.66667 roc_auc 0.35740 prc_auc 0.56225[0m
[93maverage test of epoch 44: loss -16.59873 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -16.80118 acc 0.66667 roc_auc 0.35740 prc_auc 0.56216[0m
[93maverage test of epoch 45: loss -16.89687 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -17.10012 acc 0.66667 roc_auc 0.35730 prc_auc 0.56191[0m
[93maverage test of epoch 46: loss -17.19492 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -17.39899 acc 0.66667 roc_auc 0.35730 prc_auc 0.56206[0m
[93maverage test of epoch 47: loss -17.49291 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -17.69779 acc 0.66667 roc_auc 0.35770 prc_auc 0.56200[0m
[93maverage test of epoch 48: loss -17.79083 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -17.99652 acc 0.66667 roc_auc 0.35760 prc_auc 0.56217[0m
[93maverage test of epoch 49: loss -18.08869 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.06695 acc 0.66667 roc_auc 0.46460 prc_auc 0.65895[0m
[93maverage test of epoch 0: loss -0.52892 acc 0.65789 roc_auc 0.80308 prc_auc 0.89292[0m
[92maverage training of epoch 1: loss -1.20099 acc 0.66667 roc_auc 0.47900 prc_auc 0.66081[0m
[93maverage test of epoch 1: loss -1.85957 acc 0.65789 roc_auc 0.76000 prc_auc 0.84619[0m
[92maverage training of epoch 2: loss -2.36193 acc 0.66667 roc_auc 0.47480 prc_auc 0.65975[0m
[93maverage test of epoch 2: loss -2.87421 acc 0.65789 roc_auc 0.61231 prc_auc 0.76662[0m
[92maverage training of epoch 3: loss -3.43856 acc 0.66667 roc_auc 0.47420 prc_auc 0.65981[0m
[93maverage test of epoch 3: loss -4.01289 acc 0.65789 roc_auc 0.81846 prc_auc 0.87198[0m
[92maverage training of epoch 4: loss -4.44388 acc 0.66667 roc_auc 0.45260 prc_auc 0.63544[0m
[93maverage test of epoch 4: loss -4.76711 acc 0.65789 roc_auc 0.74462 prc_auc 0.85127[0m
[92maverage training of epoch 5: loss -5.02891 acc 0.66667 roc_auc 0.43100 prc_auc 0.61896[0m
[93maverage test of epoch 5: loss -5.24476 acc 0.65789 roc_auc 0.72308 prc_auc 0.85111[0m
[92maverage training of epoch 6: loss -5.46170 acc 0.66667 roc_auc 0.42380 prc_auc 0.60979[0m
[93maverage test of epoch 6: loss -5.63926 acc 0.65789 roc_auc 0.72000 prc_auc 0.84723[0m
[92maverage training of epoch 7: loss -5.83557 acc 0.66667 roc_auc 0.42170 prc_auc 0.60891[0m
[93maverage test of epoch 7: loss -5.99317 acc 0.65789 roc_auc 0.72923 prc_auc 0.85424[0m
[92maverage training of epoch 8: loss -6.17819 acc 0.66667 roc_auc 0.42180 prc_auc 0.60957[0m
[93maverage test of epoch 8: loss -6.32390 acc 0.65789 roc_auc 0.72462 prc_auc 0.84926[0m
[92maverage training of epoch 9: loss -6.50256 acc 0.66667 roc_auc 0.42620 prc_auc 0.61420[0m
[93maverage test of epoch 9: loss -6.64139 acc 0.65789 roc_auc 0.72923 prc_auc 0.85171[0m
[92maverage training of epoch 10: loss -6.81832 acc 0.66667 roc_auc 0.43440 prc_auc 0.63302[0m
[93maverage test of epoch 10: loss -6.95678 acc 0.65789 roc_auc 0.60769 prc_auc 0.80450[0m
[92maverage training of epoch 11: loss -7.14428 acc 0.66667 roc_auc 0.44940 prc_auc 0.65206[0m
[93maverage test of epoch 11: loss -7.30078 acc 0.65789 roc_auc 0.42462 prc_auc 0.72866[0m
[92maverage training of epoch 12: loss -7.51334 acc 0.66667 roc_auc 0.35890 prc_auc 0.59229[0m
[93maverage test of epoch 12: loss -7.68568 acc 0.65789 roc_auc 0.18462 prc_auc 0.57163[0m
[92maverage training of epoch 13: loss -7.89432 acc 0.66667 roc_auc 0.39800 prc_auc 0.59977[0m
[93maverage test of epoch 13: loss -8.05790 acc 0.65789 roc_auc 0.14462 prc_auc 0.54494[0m
[92maverage training of epoch 14: loss -8.25782 acc 0.66667 roc_auc 0.40860 prc_auc 0.60131[0m
[93maverage test of epoch 14: loss -8.41173 acc 0.65789 roc_auc 0.16308 prc_auc 0.55116[0m
[92maverage training of epoch 15: loss -8.60515 acc 0.66667 roc_auc 0.41300 prc_auc 0.60172[0m
[93maverage test of epoch 15: loss -8.75165 acc 0.65789 roc_auc 0.16769 prc_auc 0.55057[0m
[92maverage training of epoch 16: loss -8.94087 acc 0.66667 roc_auc 0.41700 prc_auc 0.60420[0m
[93maverage test of epoch 16: loss -9.08190 acc 0.65789 roc_auc 0.16923 prc_auc 0.55751[0m
[92maverage training of epoch 17: loss -9.26847 acc 0.66667 roc_auc 0.41860 prc_auc 0.60821[0m
[93maverage test of epoch 17: loss -9.40534 acc 0.65789 roc_auc 0.16000 prc_auc 0.55589[0m
[92maverage training of epoch 18: loss -9.59023 acc 0.66667 roc_auc 0.41940 prc_auc 0.60997[0m
[93maverage test of epoch 18: loss -9.72379 acc 0.65789 roc_auc 0.16000 prc_auc 0.55980[0m
[92maverage training of epoch 19: loss -9.90764 acc 0.66667 roc_auc 0.42040 prc_auc 0.60799[0m
[93maverage test of epoch 19: loss -10.03846 acc 0.65789 roc_auc 0.16000 prc_auc 0.57742[0m
[92maverage training of epoch 20: loss -10.22171 acc 0.66667 roc_auc 0.42050 prc_auc 0.60802[0m
[93maverage test of epoch 20: loss -10.35019 acc 0.65789 roc_auc 0.15846 prc_auc 0.58415[0m
[92maverage training of epoch 21: loss -10.53315 acc 0.66667 roc_auc 0.42130 prc_auc 0.60933[0m
[93maverage test of epoch 21: loss -10.65959 acc 0.65789 roc_auc 0.21077 prc_auc 0.61552[0m
[92maverage training of epoch 22: loss -10.84249 acc 0.66667 roc_auc 0.42140 prc_auc 0.60976[0m
[93maverage test of epoch 22: loss -10.96712 acc 0.65789 roc_auc 0.21538 prc_auc 0.67713[0m
[92maverage training of epoch 23: loss -11.15013 acc 0.66667 roc_auc 0.42120 prc_auc 0.60908[0m
[93maverage test of epoch 23: loss -11.27310 acc 0.65789 roc_auc 0.31692 prc_auc 0.67713[0m
[92maverage training of epoch 24: loss -11.45636 acc 0.66667 roc_auc 0.42100 prc_auc 0.60758[0m
[93maverage test of epoch 24: loss -11.57782 acc 0.65789 roc_auc 0.38000 prc_auc 0.63053[0m
[92maverage training of epoch 25: loss -11.76142 acc 0.66667 roc_auc 0.42090 prc_auc 0.60663[0m
[93maverage test of epoch 25: loss -11.88148 acc 0.65789 roc_auc 0.36308 prc_auc 0.68526[0m
[92maverage training of epoch 26: loss -12.06552 acc 0.66667 roc_auc 0.42070 prc_auc 0.60595[0m
[93maverage test of epoch 26: loss -12.18425 acc 0.65789 roc_auc 0.35538 prc_auc 0.62794[0m
[92maverage training of epoch 27: loss -12.36879 acc 0.66667 roc_auc 0.42060 prc_auc 0.60551[0m
[93maverage test of epoch 27: loss -12.48628 acc 0.65789 roc_auc 0.41692 prc_auc 0.65251[0m
[92maverage training of epoch 28: loss -12.67137 acc 0.66667 roc_auc 0.42050 prc_auc 0.60510[0m
[93maverage test of epoch 28: loss -12.78767 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 29: loss -12.97336 acc 0.66667 roc_auc 0.42050 prc_auc 0.60507[0m
[93maverage test of epoch 29: loss -13.08852 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 30: loss -13.27485 acc 0.66667 roc_auc 0.42040 prc_auc 0.60491[0m
[93maverage test of epoch 30: loss -13.38891 acc 0.65789 roc_auc 0.46923 prc_auc 0.68526[0m
[92maverage training of epoch 31: loss -13.57591 acc 0.66667 roc_auc 0.42060 prc_auc 0.60502[0m
[93maverage test of epoch 31: loss -13.68891 acc 0.65789 roc_auc 0.54462 prc_auc 0.69663[0m
[92maverage training of epoch 32: loss -13.87661 acc 0.66667 roc_auc 0.42040 prc_auc 0.60495[0m
[93maverage test of epoch 32: loss -13.98857 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 33: loss -14.17699 acc 0.66667 roc_auc 0.42060 prc_auc 0.60507[0m
[93maverage test of epoch 33: loss -14.28794 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 34: loss -14.47709 acc 0.66667 roc_auc 0.42050 prc_auc 0.60507[0m
[93maverage test of epoch 34: loss -14.58706 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 35: loss -14.77697 acc 0.66667 roc_auc 0.42020 prc_auc 0.60455[0m
[93maverage test of epoch 35: loss -14.88596 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 36: loss -15.07664 acc 0.66667 roc_auc 0.42030 prc_auc 0.60455[0m
[93maverage test of epoch 36: loss -15.18468 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 37: loss -15.37613 acc 0.66667 roc_auc 0.42020 prc_auc 0.60455[0m
[93maverage test of epoch 37: loss -15.48323 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 38: loss -15.67547 acc 0.66667 roc_auc 0.42030 prc_auc 0.60458[0m
[93maverage test of epoch 38: loss -15.78164 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 39: loss -15.97468 acc 0.66667 roc_auc 0.42030 prc_auc 0.60458[0m
[93maverage test of epoch 39: loss -16.07994 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 40: loss -16.27378 acc 0.66667 roc_auc 0.42030 prc_auc 0.60458[0m
[93maverage test of epoch 40: loss -16.37812 acc 0.65789 roc_auc 0.61077 prc_auc 0.71889[0m
[92maverage training of epoch 41: loss -16.57278 acc 0.66667 roc_auc 0.42020 prc_auc 0.60497[0m
[93maverage test of epoch 41: loss -16.67622 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 42: loss -16.87169 acc 0.66667 roc_auc 0.42030 prc_auc 0.60500[0m
[93maverage test of epoch 42: loss -16.97423 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 43: loss -17.17053 acc 0.66667 roc_auc 0.42030 prc_auc 0.60500[0m
[93maverage test of epoch 43: loss -17.27218 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 44: loss -17.46929 acc 0.66667 roc_auc 0.42030 prc_auc 0.60461[0m
[93maverage test of epoch 44: loss -17.57006 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 45: loss -17.76801 acc 0.66667 roc_auc 0.42030 prc_auc 0.60458[0m
[93maverage test of epoch 45: loss -17.86789 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 46: loss -18.06667 acc 0.66667 roc_auc 0.42030 prc_auc 0.60500[0m
[93maverage test of epoch 46: loss -18.16568 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 47: loss -18.36529 acc 0.66667 roc_auc 0.42010 prc_auc 0.60499[0m
[93maverage test of epoch 47: loss -18.46342 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 48: loss -18.66387 acc 0.66667 roc_auc 0.42030 prc_auc 0.60492[0m
[93maverage test of epoch 48: loss -18.76113 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 49: loss -18.96241 acc 0.66667 roc_auc 0.42030 prc_auc 0.60494[0m
[93maverage test of epoch 49: loss -19.05881 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.65440 acc 0.66667 roc_auc 0.40820 prc_auc 0.61875[0m
[93maverage test of epoch 0: loss -0.98147 acc 0.65789 roc_auc 0.34769 prc_auc 0.67595[0m
[92maverage training of epoch 1: loss -1.36441 acc 0.66667 roc_auc 0.45960 prc_auc 0.66364[0m
[93maverage test of epoch 1: loss -1.69960 acc 0.65789 roc_auc 0.93538 prc_auc 0.97301[0m
[92maverage training of epoch 2: loss -2.01477 acc 0.66667 roc_auc 0.49500 prc_auc 0.69328[0m
[93maverage test of epoch 2: loss -2.24183 acc 0.65789 roc_auc 0.95385 prc_auc 0.97886[0m
[92maverage training of epoch 3: loss -2.52552 acc 0.66667 roc_auc 0.49300 prc_auc 0.69129[0m
[93maverage test of epoch 3: loss -2.73126 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 4: loss -3.06462 acc 0.66667 roc_auc 0.47600 prc_auc 0.67872[0m
[93maverage test of epoch 4: loss -3.33138 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 5: loss -3.69794 acc 0.66667 roc_auc 0.46730 prc_auc 0.67452[0m
[93maverage test of epoch 5: loss -3.94363 acc 0.65789 roc_auc 0.95077 prc_auc 0.97791[0m
[92maverage training of epoch 6: loss -4.26125 acc 0.66667 roc_auc 0.47030 prc_auc 0.67636[0m
[93maverage test of epoch 6: loss -4.45120 acc 0.65789 roc_auc 0.94923 prc_auc 0.97644[0m
[92maverage training of epoch 7: loss -4.73814 acc 0.66667 roc_auc 0.47230 prc_auc 0.67461[0m
[93maverage test of epoch 7: loss -4.90051 acc 0.65789 roc_auc 0.94769 prc_auc 0.97555[0m
[92maverage training of epoch 8: loss -5.18222 acc 0.66667 roc_auc 0.44890 prc_auc 0.65447[0m
[93maverage test of epoch 8: loss -5.34080 acc 0.65789 roc_auc 0.94308 prc_auc 0.97317[0m
[92maverage training of epoch 9: loss -5.61752 acc 0.66667 roc_auc 0.43710 prc_auc 0.64666[0m
[93maverage test of epoch 9: loss -5.76380 acc 0.65789 roc_auc 0.94923 prc_auc 0.97574[0m
[92maverage training of epoch 10: loss -6.02670 acc 0.66667 roc_auc 0.42860 prc_auc 0.63709[0m
[93maverage test of epoch 10: loss -6.15725 acc 0.65789 roc_auc 0.94308 prc_auc 0.97246[0m
[92maverage training of epoch 11: loss -6.40928 acc 0.66667 roc_auc 0.42030 prc_auc 0.62719[0m
[93maverage test of epoch 11: loss -6.52811 acc 0.65789 roc_auc 0.94615 prc_auc 0.97264[0m
[92maverage training of epoch 12: loss -6.77286 acc 0.66667 roc_auc 0.41030 prc_auc 0.61937[0m
[93maverage test of epoch 12: loss -6.88327 acc 0.65789 roc_auc 0.94462 prc_auc 0.96900[0m
[92maverage training of epoch 13: loss -7.12306 acc 0.66667 roc_auc 0.40490 prc_auc 0.61629[0m
[93maverage test of epoch 13: loss -7.22713 acc 0.65789 roc_auc 0.94462 prc_auc 0.96571[0m
[92maverage training of epoch 14: loss -7.46345 acc 0.66667 roc_auc 0.39890 prc_auc 0.61153[0m
[93maverage test of epoch 14: loss -7.56256 acc 0.65789 roc_auc 0.92308 prc_auc 0.94862[0m
[92maverage training of epoch 15: loss -7.79640 acc 0.66667 roc_auc 0.39600 prc_auc 0.61009[0m
[93maverage test of epoch 15: loss -7.89147 acc 0.65789 roc_auc 0.94308 prc_auc 0.95520[0m
[92maverage training of epoch 16: loss -8.12354 acc 0.66667 roc_auc 0.39360 prc_auc 0.60930[0m
[93maverage test of epoch 16: loss -8.21524 acc 0.65789 roc_auc 0.91538 prc_auc 0.92854[0m
[92maverage training of epoch 17: loss -8.44604 acc 0.66667 roc_auc 0.39400 prc_auc 0.60891[0m
[93maverage test of epoch 17: loss -8.53487 acc 0.65789 roc_auc 0.90000 prc_auc 0.93158[0m
[92maverage training of epoch 18: loss -8.76480 acc 0.66667 roc_auc 0.39000 prc_auc 0.60614[0m
[93maverage test of epoch 18: loss -8.85112 acc 0.65789 roc_auc 0.74923 prc_auc 0.79432[0m
[92maverage training of epoch 19: loss -9.08048 acc 0.66667 roc_auc 0.39040 prc_auc 0.60632[0m
[93maverage test of epoch 19: loss -9.16459 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -9.39361 acc 0.66667 roc_auc 0.38880 prc_auc 0.60317[0m
[93maverage test of epoch 20: loss -9.47573 acc 0.65789 roc_auc 0.86462 prc_auc 0.87965[0m
[92maverage training of epoch 21: loss -9.70461 acc 0.66667 roc_auc 0.38860 prc_auc 0.60522[0m
[93maverage test of epoch 21: loss -9.78493 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -10.01383 acc 0.66667 roc_auc 0.38780 prc_auc 0.60030[0m
[93maverage test of epoch 22: loss -10.09249 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -10.32153 acc 0.66667 roc_auc 0.38530 prc_auc 0.59908[0m
[93maverage test of epoch 23: loss -10.39866 acc 0.65789 roc_auc 0.58000 prc_auc 0.71263[0m
[92maverage training of epoch 24: loss -10.62794 acc 0.66667 roc_auc 0.38530 prc_auc 0.59911[0m
[93maverage test of epoch 24: loss -10.70365 acc 0.65789 roc_auc 0.84308 prc_auc 0.87222[0m
[92maverage training of epoch 25: loss -10.93326 acc 0.66667 roc_auc 0.38760 prc_auc 0.60200[0m
[93maverage test of epoch 25: loss -11.00763 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -11.23764 acc 0.66667 roc_auc 0.38760 prc_auc 0.59973[0m
[93maverage test of epoch 26: loss -11.31074 acc 0.65789 roc_auc 0.80000 prc_auc 0.86316[0m
[92maverage training of epoch 27: loss -11.54122 acc 0.66667 roc_auc 0.38210 prc_auc 0.59670[0m
[93maverage test of epoch 27: loss -11.61310 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -11.84410 acc 0.66667 roc_auc 0.38370 prc_auc 0.59793[0m
[93maverage test of epoch 28: loss -11.91482 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -12.14638 acc 0.66667 roc_auc 0.38530 prc_auc 0.60105[0m
[93maverage test of epoch 29: loss -12.21599 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -12.44816 acc 0.66667 roc_auc 0.38710 prc_auc 0.60132[0m
[93maverage test of epoch 30: loss -12.51668 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -12.74948 acc 0.66667 roc_auc 0.38400 prc_auc 0.59102[0m
[93maverage test of epoch 31: loss -12.81696 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -13.05042 acc 0.66667 roc_auc 0.39030 prc_auc 0.59789[0m
[93maverage test of epoch 32: loss -13.11687 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -13.35102 acc 0.66667 roc_auc 0.38750 prc_auc 0.59399[0m
[93maverage test of epoch 33: loss -13.41647 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -13.65133 acc 0.66667 roc_auc 0.38210 prc_auc 0.58995[0m
[93maverage test of epoch 34: loss -13.71580 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -13.95139 acc 0.66667 roc_auc 0.38780 prc_auc 0.59167[0m
[93maverage test of epoch 35: loss -14.01490 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -14.25123 acc 0.66667 roc_auc 0.38230 prc_auc 0.58814[0m
[93maverage test of epoch 36: loss -14.31379 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -14.55088 acc 0.66667 roc_auc 0.38100 prc_auc 0.58371[0m
[93maverage test of epoch 37: loss -14.61250 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -14.85035 acc 0.66667 roc_auc 0.38450 prc_auc 0.58966[0m
[93maverage test of epoch 38: loss -14.91105 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -15.14968 acc 0.66667 roc_auc 0.38300 prc_auc 0.58701[0m
[93maverage test of epoch 39: loss -15.20947 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -15.44889 acc 0.66667 roc_auc 0.37860 prc_auc 0.58720[0m
[93maverage test of epoch 40: loss -15.50777 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -15.74798 acc 0.66667 roc_auc 0.38320 prc_auc 0.58792[0m
[93maverage test of epoch 41: loss -15.80595 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -16.04697 acc 0.66667 roc_auc 0.38970 prc_auc 0.59720[0m
[93maverage test of epoch 42: loss -16.10406 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -16.34588 acc 0.66667 roc_auc 0.38550 prc_auc 0.59283[0m
[93maverage test of epoch 43: loss -16.40207 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -16.64471 acc 0.66667 roc_auc 0.38820 prc_auc 0.59474[0m
[93maverage test of epoch 44: loss -16.70002 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -16.94347 acc 0.66667 roc_auc 0.38730 prc_auc 0.59384[0m
[93maverage test of epoch 45: loss -16.99791 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -17.24218 acc 0.66667 roc_auc 0.39320 prc_auc 0.60018[0m
[93maverage test of epoch 46: loss -17.29574 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -17.54084 acc 0.66667 roc_auc 0.38750 prc_auc 0.59627[0m
[93maverage test of epoch 47: loss -17.59352 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -17.83945 acc 0.66667 roc_auc 0.38140 prc_auc 0.59165[0m
[93maverage test of epoch 48: loss -17.89126 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -18.13802 acc 0.66667 roc_auc 0.38650 prc_auc 0.59792[0m
[93maverage test of epoch 49: loss -18.18897 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.64653 acc 0.66225 roc_auc 0.43118 prc_auc 0.62663[0m
[93maverage test of epoch 0: loss -1.08938 acc 0.67568 roc_auc 0.66333 prc_auc 0.85671[0m
[92maverage training of epoch 1: loss -1.46217 acc 0.66225 roc_auc 0.43706 prc_auc 0.62413[0m
[93maverage test of epoch 1: loss -1.84194 acc 0.67568 roc_auc 0.79667 prc_auc 0.90655[0m
[92maverage training of epoch 2: loss -2.10419 acc 0.66225 roc_auc 0.42863 prc_auc 0.62295[0m
[93maverage test of epoch 2: loss -2.42127 acc 0.67568 roc_auc 0.82333 prc_auc 0.91585[0m
[92maverage training of epoch 3: loss -2.69124 acc 0.66225 roc_auc 0.44235 prc_auc 0.63723[0m
[93maverage test of epoch 3: loss -3.05843 acc 0.67568 roc_auc 0.83667 prc_auc 0.91945[0m
[92maverage training of epoch 4: loss -3.38559 acc 0.66225 roc_auc 0.44294 prc_auc 0.63072[0m
[93maverage test of epoch 4: loss -3.79624 acc 0.67568 roc_auc 0.86000 prc_auc 0.93121[0m
[92maverage training of epoch 5: loss -4.05710 acc 0.66225 roc_auc 0.43588 prc_auc 0.62341[0m
[93maverage test of epoch 5: loss -4.40587 acc 0.67568 roc_auc 0.86500 prc_auc 0.93477[0m
[92maverage training of epoch 6: loss -4.65630 acc 0.66225 roc_auc 0.45000 prc_auc 0.64599[0m
[93maverage test of epoch 6: loss -5.00944 acc 0.67568 roc_auc 0.84000 prc_auc 0.91674[0m
[92maverage training of epoch 7: loss -5.19554 acc 0.66225 roc_auc 0.43745 prc_auc 0.62393[0m
[93maverage test of epoch 7: loss -5.49018 acc 0.67568 roc_auc 0.85000 prc_auc 0.92059[0m
[92maverage training of epoch 8: loss -5.64257 acc 0.66225 roc_auc 0.42324 prc_auc 0.61045[0m
[93maverage test of epoch 8: loss -5.91447 acc 0.67568 roc_auc 0.85667 prc_auc 0.92327[0m
[92maverage training of epoch 9: loss -6.04756 acc 0.66225 roc_auc 0.41167 prc_auc 0.60105[0m
[93maverage test of epoch 9: loss -6.30657 acc 0.67568 roc_auc 0.85833 prc_auc 0.92372[0m
[92maverage training of epoch 10: loss -6.42676 acc 0.66225 roc_auc 0.40225 prc_auc 0.59374[0m
[93maverage test of epoch 10: loss -6.67766 acc 0.67568 roc_auc 0.85833 prc_auc 0.92367[0m
[92maverage training of epoch 11: loss -6.78850 acc 0.66225 roc_auc 0.39686 prc_auc 0.59136[0m
[93maverage test of epoch 11: loss -7.03402 acc 0.67568 roc_auc 0.86167 prc_auc 0.92445[0m
[92maverage training of epoch 12: loss -7.13771 acc 0.66225 roc_auc 0.39520 prc_auc 0.59000[0m
[93maverage test of epoch 12: loss -7.37958 acc 0.67568 roc_auc 0.86167 prc_auc 0.92414[0m
[92maverage training of epoch 13: loss -7.47755 acc 0.66225 roc_auc 0.39235 prc_auc 0.58871[0m
[93maverage test of epoch 13: loss -7.71694 acc 0.67568 roc_auc 0.86000 prc_auc 0.92230[0m
[92maverage training of epoch 14: loss -7.81020 acc 0.66225 roc_auc 0.38971 prc_auc 0.58711[0m
[93maverage test of epoch 14: loss -8.04793 acc 0.67568 roc_auc 0.86000 prc_auc 0.92091[0m
[92maverage training of epoch 15: loss -8.13721 acc 0.66225 roc_auc 0.38696 prc_auc 0.58504[0m
[93maverage test of epoch 15: loss -8.37388 acc 0.67568 roc_auc 0.86167 prc_auc 0.91904[0m
[92maverage training of epoch 16: loss -8.45972 acc 0.66225 roc_auc 0.38627 prc_auc 0.58454[0m
[93maverage test of epoch 16: loss -8.69579 acc 0.67568 roc_auc 0.83333 prc_auc 0.88691[0m
[92maverage training of epoch 17: loss -8.77859 acc 0.66225 roc_auc 0.38520 prc_auc 0.58431[0m
[93maverage test of epoch 17: loss -9.01440 acc 0.67568 roc_auc 0.85667 prc_auc 0.89111[0m
[92maverage training of epoch 18: loss -9.09449 acc 0.66225 roc_auc 0.38520 prc_auc 0.58440[0m
[93maverage test of epoch 18: loss -9.33031 acc 0.67568 roc_auc 0.83667 prc_auc 0.87836[0m
[92maverage training of epoch 19: loss -9.40794 acc 0.66225 roc_auc 0.38412 prc_auc 0.58365[0m
[93maverage test of epoch 19: loss -9.64399 acc 0.67568 roc_auc 0.79667 prc_auc 0.84946[0m
[92maverage training of epoch 20: loss -9.71935 acc 0.66225 roc_auc 0.38402 prc_auc 0.58357[0m
[93maverage test of epoch 20: loss -9.95579 acc 0.67568 roc_auc 0.86000 prc_auc 0.89108[0m
[92maverage training of epoch 21: loss -10.02905 acc 0.66225 roc_auc 0.38382 prc_auc 0.58358[0m
[93maverage test of epoch 21: loss -10.26603 acc 0.67568 roc_auc 0.84000 prc_auc 0.87252[0m
[92maverage training of epoch 22: loss -10.33732 acc 0.66225 roc_auc 0.38343 prc_auc 0.58403[0m
[93maverage test of epoch 22: loss -10.57496 acc 0.67568 roc_auc 0.84000 prc_auc 0.87252[0m
[92maverage training of epoch 23: loss -10.64437 acc 0.66225 roc_auc 0.38206 prc_auc 0.58329[0m
[93maverage test of epoch 23: loss -10.88276 acc 0.67568 roc_auc 0.80000 prc_auc 0.84368[0m
[92maverage training of epoch 24: loss -10.95040 acc 0.66225 roc_auc 0.38196 prc_auc 0.58270[0m
[93maverage test of epoch 24: loss -11.18961 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 25: loss -11.25556 acc 0.66225 roc_auc 0.38147 prc_auc 0.57593[0m
[93maverage test of epoch 25: loss -11.49566 acc 0.67568 roc_auc 0.64000 prc_auc 0.76649[0m
[92maverage training of epoch 26: loss -11.55996 acc 0.66225 roc_auc 0.38137 prc_auc 0.57619[0m
[93maverage test of epoch 26: loss -11.80101 acc 0.67568 roc_auc 0.82000 prc_auc 0.86604[0m
[92maverage training of epoch 27: loss -11.86372 acc 0.66225 roc_auc 0.38059 prc_auc 0.57355[0m
[93maverage test of epoch 27: loss -12.10576 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 28: loss -12.16694 acc 0.66225 roc_auc 0.37951 prc_auc 0.57214[0m
[93maverage test of epoch 28: loss -12.41000 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 29: loss -12.46967 acc 0.66225 roc_auc 0.37941 prc_auc 0.57208[0m
[93maverage test of epoch 29: loss -12.71381 acc 0.67568 roc_auc 0.60000 prc_auc 0.72571[0m
[92maverage training of epoch 30: loss -12.77200 acc 0.66225 roc_auc 0.37873 prc_auc 0.57171[0m
[93maverage test of epoch 30: loss -13.01723 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 31: loss -13.07398 acc 0.66225 roc_auc 0.37804 prc_auc 0.57114[0m
[93maverage test of epoch 31: loss -13.32033 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 32: loss -13.37566 acc 0.66225 roc_auc 0.37814 prc_auc 0.57132[0m
[93maverage test of epoch 32: loss -13.62314 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 33: loss -13.67707 acc 0.66225 roc_auc 0.37824 prc_auc 0.57112[0m
[93maverage test of epoch 33: loss -13.92571 acc 0.67568 roc_auc 0.86000 prc_auc 0.89108[0m
[92maverage training of epoch 34: loss -13.97825 acc 0.66225 roc_auc 0.37735 prc_auc 0.57008[0m
[93maverage test of epoch 34: loss -14.22806 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 35: loss -14.27923 acc 0.66225 roc_auc 0.37755 prc_auc 0.57100[0m
[93maverage test of epoch 35: loss -14.53023 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 36: loss -14.58004 acc 0.66225 roc_auc 0.37676 prc_auc 0.57131[0m
[93maverage test of epoch 36: loss -14.83224 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 37: loss -14.88070 acc 0.66225 roc_auc 0.37696 prc_auc 0.57135[0m
[93maverage test of epoch 37: loss -15.13411 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 38: loss -15.18124 acc 0.66225 roc_auc 0.37676 prc_auc 0.57155[0m
[93maverage test of epoch 38: loss -15.43586 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 39: loss -15.48165 acc 0.66225 roc_auc 0.37647 prc_auc 0.57054[0m
[93maverage test of epoch 39: loss -15.73750 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 40: loss -15.78197 acc 0.66225 roc_auc 0.37588 prc_auc 0.57054[0m
[93maverage test of epoch 40: loss -16.03904 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 41: loss -16.08220 acc 0.66225 roc_auc 0.37608 prc_auc 0.57015[0m
[93maverage test of epoch 41: loss -16.34051 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 42: loss -16.38236 acc 0.66225 roc_auc 0.37627 prc_auc 0.57162[0m
[93maverage test of epoch 42: loss -16.64191 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 43: loss -16.68245 acc 0.66225 roc_auc 0.37598 prc_auc 0.57126[0m
[93maverage test of epoch 43: loss -16.94325 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 44: loss -16.98248 acc 0.66225 roc_auc 0.37578 prc_auc 0.57205[0m
[93maverage test of epoch 44: loss -17.24453 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 45: loss -17.28246 acc 0.66225 roc_auc 0.37520 prc_auc 0.57365[0m
[93maverage test of epoch 45: loss -17.54576 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 46: loss -17.58240 acc 0.66225 roc_auc 0.37480 prc_auc 0.57176[0m
[93maverage test of epoch 46: loss -17.84695 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 47: loss -17.88230 acc 0.66225 roc_auc 0.37637 prc_auc 0.57198[0m
[93maverage test of epoch 47: loss -18.14810 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 48: loss -18.18216 acc 0.66225 roc_auc 0.37539 prc_auc 0.57029[0m
[93maverage test of epoch 48: loss -18.44923 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 49: loss -18.48200 acc 0.66225 roc_auc 0.37480 prc_auc 0.57066[0m
[93maverage test of epoch 49: loss -18.75032 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.11934 acc 0.64901 roc_auc 0.40451 prc_auc 0.63673[0m
[93maverage test of epoch 0: loss -0.35631 acc 0.67568 roc_auc 0.84333 prc_auc 0.93739[0m
[92maverage training of epoch 1: loss -0.54159 acc 0.66225 roc_auc 0.57412 prc_auc 0.76821[0m
[93maverage test of epoch 1: loss -0.77118 acc 0.67568 roc_auc 0.92667 prc_auc 0.97247[0m
[92maverage training of epoch 2: loss -0.96460 acc 0.66225 roc_auc 0.76373 prc_auc 0.87289[0m
[93maverage test of epoch 2: loss -1.22384 acc 0.67568 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 3: loss -1.44102 acc 0.66225 roc_auc 0.83196 prc_auc 0.90129[0m
[93maverage test of epoch 3: loss -1.76368 acc 0.67568 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 4: loss -2.01558 acc 0.66225 roc_auc 0.85824 prc_auc 0.92083[0m
[93maverage test of epoch 4: loss -2.40676 acc 0.67568 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 5: loss -2.66273 acc 0.81457 roc_auc 0.86549 prc_auc 0.92340[0m
[93maverage test of epoch 5: loss -3.00129 acc 0.81081 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 6: loss -3.19171 acc 0.83444 roc_auc 0.83667 prc_auc 0.89616[0m
[93maverage test of epoch 6: loss -3.37840 acc 0.81081 roc_auc 0.94333 prc_auc 0.97748[0mUsing backend: pytorch
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))

[92maverage training of epoch 7: loss -3.55924 acc 0.82781 roc_auc 0.82686 prc_auc 0.88224[0m
[93maverage test of epoch 7: loss -3.74764 acc 0.83784 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 8: loss -3.90353 acc 0.82781 roc_auc 0.81608 prc_auc 0.86922[0m
[93maverage test of epoch 8: loss -4.09866 acc 0.83784 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 9: loss -4.21820 acc 0.82781 roc_auc 0.81196 prc_auc 0.85997[0m
[93maverage test of epoch 9: loss -4.42390 acc 0.83784 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 10: loss -4.50785 acc 0.82119 roc_auc 0.82098 prc_auc 0.86429[0m
[93maverage test of epoch 10: loss -4.73822 acc 0.83784 roc_auc 0.94333 prc_auc 0.97748[0m
[92maverage training of epoch 11: loss -4.84622 acc 0.83444 roc_auc 0.80402 prc_auc 0.84603[0m
[93maverage test of epoch 11: loss -5.04492 acc 0.83784 roc_auc 0.93667 prc_auc 0.97575[0m
[92maverage training of epoch 12: loss -5.14729 acc 0.83444 roc_auc 0.78667 prc_auc 0.83531[0m
[93maverage test of epoch 12: loss -5.35490 acc 0.83784 roc_auc 0.94000 prc_auc 0.97693[0m
[92maverage training of epoch 13: loss -5.44790 acc 0.83444 roc_auc 0.77980 prc_auc 0.82952[0m
[93maverage test of epoch 13: loss -5.65927 acc 0.83784 roc_auc 0.94000 prc_auc 0.97693[0m
[92maverage training of epoch 14: loss -5.74205 acc 0.83444 roc_auc 0.77961 prc_auc 0.82838[0m
[93maverage test of epoch 14: loss -5.95956 acc 0.83784 roc_auc 0.94000 prc_auc 0.97693[0m
[92maverage training of epoch 15: loss -6.01056 acc 0.83444 roc_auc 0.79255 prc_auc 0.83094[0m
[93maverage test of epoch 15: loss -6.24921 acc 0.83784 roc_auc 0.94333 prc_auc 0.97777[0m
[92maverage training of epoch 16: loss -6.29401 acc 0.83444 roc_auc 0.80235 prc_auc 0.83991[0m
[93maverage test of epoch 16: loss -6.53425 acc 0.83784 roc_auc 0.93667 prc_auc 0.97575[0m
[92maverage training of epoch 17: loss -6.62843 acc 0.84106 roc_auc 0.76137 prc_auc 0.81265[0m
[93maverage test of epoch 17: loss -6.82540 acc 0.83784 roc_auc 0.94333 prc_auc 0.97777[0m
[92maverage training of epoch 18: loss -6.88330 acc 0.84106 roc_auc 0.76000 prc_auc 0.81144[0m
[93maverage test of epoch 18: loss -7.10935 acc 0.83784 roc_auc 0.94000 prc_auc 0.97693[0m
[92maverage training of epoch 19: loss -7.12022 acc 0.83444 roc_auc 0.79431 prc_auc 0.83431[0m
[93maverage test of epoch 19: loss -7.21836 acc 0.81081 roc_auc 0.93333 prc_auc 0.97496[0m
[92maverage training of epoch 20: loss -7.10026 acc 0.80132 roc_auc 0.78402 prc_auc 0.83431[0m
[93maverage test of epoch 20: loss -7.41137 acc 0.81081 roc_auc 0.93333 prc_auc 0.97496[0m
[92maverage training of epoch 21: loss -7.38361 acc 0.80795 roc_auc 0.78735 prc_auc 0.83525[0m
[93maverage test of epoch 21: loss -7.81506 acc 0.83784 roc_auc 0.93333 prc_auc 0.97496[0m
[92maverage training of epoch 22: loss -7.92276 acc 0.85430 roc_auc 0.81069 prc_auc 0.84043[0m
[93maverage test of epoch 22: loss -8.15831 acc 0.83784 roc_auc 0.93667 prc_auc 0.97575[0m
[92maverage training of epoch 23: loss -8.22229 acc 0.84106 roc_auc 0.75637 prc_auc 0.80765[0m
[93maverage test of epoch 23: loss -8.43201 acc 0.83784 roc_auc 0.94000 prc_auc 0.97693[0m
[92maverage training of epoch 24: loss -8.48978 acc 0.84106 roc_auc 0.75804 prc_auc 0.80922[0m
[93maverage test of epoch 24: loss -8.70310 acc 0.83784 roc_auc 0.93667 prc_auc 0.97614[0m
[92maverage training of epoch 25: loss -8.75524 acc 0.84106 roc_auc 0.75578 prc_auc 0.80557[0m
[93maverage test of epoch 25: loss -8.97276 acc 0.83784 roc_auc 0.93500 prc_auc 0.97440[0m
[92maverage training of epoch 26: loss -9.01932 acc 0.84106 roc_auc 0.75520 prc_auc 0.80548[0m
[93maverage test of epoch 26: loss -9.24100 acc 0.83784 roc_auc 0.93667 prc_auc 0.97635[0m
[92maverage training of epoch 27: loss -9.28207 acc 0.84106 roc_auc 0.75451 prc_auc 0.80279[0m
[93maverage test of epoch 27: loss -9.50793 acc 0.83784 roc_auc 0.94667 prc_auc 0.97635[0m
[92maverage training of epoch 28: loss -9.46223 acc 0.83444 roc_auc 0.77147 prc_auc 0.81900[0m
[93maverage test of epoch 28: loss -9.66530 acc 0.83784 roc_auc 0.94000 prc_auc 0.97659[0m
[92maverage training of epoch 29: loss -9.65631 acc 0.82781 roc_auc 0.77039 prc_auc 0.82006[0m
[93maverage test of epoch 29: loss -9.78416 acc 0.81081 roc_auc 0.94000 prc_auc 0.97659[0m
[92maverage training of epoch 30: loss -9.95549 acc 0.82781 roc_auc 0.76363 prc_auc 0.81955[0m
[93maverage test of epoch 30: loss -10.17726 acc 0.83784 roc_auc 0.93833 prc_auc 0.97485[0m
[92maverage training of epoch 31: loss -10.29361 acc 0.85430 roc_auc 0.78853 prc_auc 0.81989[0m
[93maverage test of epoch 31: loss -10.54579 acc 0.83784 roc_auc 0.94333 prc_auc 0.96608[0m
[92maverage training of epoch 32: loss -10.57149 acc 0.84106 roc_auc 0.77235 prc_auc 0.82034[0m
[93maverage test of epoch 32: loss -10.77656 acc 0.83784 roc_auc 0.93667 prc_auc 0.97133[0m
[92maverage training of epoch 33: loss -10.81620 acc 0.84106 roc_auc 0.75569 prc_auc 0.79653[0m
[93maverage test of epoch 33: loss -11.06430 acc 0.83784 roc_auc 0.90000 prc_auc 0.92745[0m
[92maverage training of epoch 34: loss -11.06994 acc 0.84106 roc_auc 0.75480 prc_auc 0.79631[0m
[93maverage test of epoch 34: loss -11.32236 acc 0.83784 roc_auc 0.84000 prc_auc 0.87996[0m
[92maverage training of epoch 35: loss -11.32307 acc 0.84106 roc_auc 0.75343 prc_auc 0.80087[0m
[93maverage test of epoch 35: loss -11.57992 acc 0.83784 roc_auc 0.95667 prc_auc 0.97651[0m
[92maverage training of epoch 36: loss -11.57588 acc 0.84106 roc_auc 0.75176 prc_auc 0.79382[0m
[93maverage test of epoch 36: loss -11.83706 acc 0.83784 roc_auc 0.77333 prc_auc 0.82479[0m
[92maverage training of epoch 37: loss -11.82820 acc 0.84106 roc_auc 0.75216 prc_auc 0.79373[0m
[93maverage test of epoch 37: loss -12.09376 acc 0.83784 roc_auc 0.77333 prc_auc 0.82479[0m
[92maverage training of epoch 38: loss -12.08009 acc 0.84106 roc_auc 0.75127 prc_auc 0.79810[0m
[93maverage test of epoch 38: loss -12.35004 acc 0.83784 roc_auc 0.95667 prc_auc 0.97651[0m
[92maverage training of epoch 39: loss -11.93864 acc 0.78146 roc_auc 0.66559 prc_auc 0.75800[0m
[93maverage test of epoch 39: loss -12.43659 acc 0.83784 roc_auc 0.93833 prc_auc 0.97268[0m
[92maverage training of epoch 40: loss -12.49081 acc 0.85430 roc_auc 0.79431 prc_auc 0.82986[0m
[93maverage test of epoch 40: loss -12.85084 acc 0.83784 roc_auc 0.94833 prc_auc 0.96961[0m
[92maverage training of epoch 41: loss -12.65073 acc 0.82781 roc_auc 0.74657 prc_auc 0.80487[0m
[93maverage test of epoch 41: loss -13.10045 acc 0.83784 roc_auc 0.77333 prc_auc 0.82479[0m
[92maverage training of epoch 42: loss -13.10840 acc 0.84768 roc_auc 0.77578 prc_auc 0.82017[0m
[93maverage test of epoch 42: loss -13.00974 acc 0.81081 roc_auc 0.76500 prc_auc 0.81912[0m
[92maverage training of epoch 43: loss -13.31729 acc 0.84106 roc_auc 0.74500 prc_auc 0.79368[0m
[93maverage test of epoch 43: loss -13.60834 acc 0.83784 roc_auc 0.77333 prc_auc 0.82479[0m
[92maverage training of epoch 44: loss -13.60807 acc 0.84768 roc_auc 0.76598 prc_auc 0.81265[0m
[93maverage test of epoch 44: loss -13.66945 acc 0.83784 roc_auc 0.80333 prc_auc 0.84711[0m
[92maverage training of epoch 45: loss -13.66243 acc 0.85430 roc_auc 0.81402 prc_auc 0.85323[0m
[93maverage test of epoch 45: loss -13.91243 acc 0.83784 roc_auc 0.88333 prc_auc 0.92242[0m
[92maverage training of epoch 46: loss -13.57246 acc 0.82781 roc_auc 0.82961 prc_auc 0.87234[0m
[93maverage test of epoch 46: loss -14.16142 acc 0.81081 roc_auc 0.93667 prc_auc 0.97549[0m
[92maverage training of epoch 47: loss -14.00173 acc 0.84106 roc_auc 0.83373 prc_auc 0.86867[0m
[93maverage test of epoch 47: loss -14.20649 acc 0.81081 roc_auc 0.86167 prc_auc 0.90041[0m
[92maverage training of epoch 48: loss -14.50061 acc 0.86755 roc_auc 0.83971 prc_auc 0.87436[0m
[93maverage test of epoch 48: loss -14.83089 acc 0.83784 roc_auc 0.76167 prc_auc 0.81823[0m
[92maverage training of epoch 49: loss -14.79829 acc 0.86755 roc_auc 0.84451 prc_auc 0.88135[0m
[93maverage test of epoch 49: loss -15.05483 acc 0.83784 roc_auc 0.75833 prc_auc 0.81739[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.0003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.69744 ROC_AUC (avg): 0.56367 PRC_AUC (avg): 0.70142 

Average forward propagation time taken(ms): 2.4913376830926945
Average backward propagation time taken(ms): 0.8773007669433057

