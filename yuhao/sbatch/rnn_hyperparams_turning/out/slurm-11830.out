# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.0001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-17-25-05/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-17-25-05/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 8,
 'epochs': 50,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 8,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.0001,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 1,
 'num_workers': 8,
 'number_of_mlp_layer': 0,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-17-17-25-05',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 50, 'learning_rate': 0.0001, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss 0.25362 acc 0.36000 roc_auc 0.54040 prc_auc 0.75097[0m
[93maverage test of epoch 0: loss 0.18429 acc 0.39474 roc_auc 0.87385 prc_auc 0.94095[0m
[92maverage training of epoch 1: loss 0.12361 acc 0.38667 roc_auc 0.56920 prc_auc 0.76993[0m
[93maverage test of epoch 1: loss 0.05473 acc 0.42105 roc_auc 0.86769 prc_auc 0.93902[0m
[92maverage training of epoch 2: loss -0.00732 acc 0.50667 roc_auc 0.57520 prc_auc 0.77667[0m
[93maverage test of epoch 2: loss -0.07645 acc 0.73684 roc_auc 0.86769 prc_auc 0.93902[0m
[92maverage training of epoch 3: loss -0.14087 acc 0.63333 roc_auc 0.57520 prc_auc 0.77512[0m
[93maverage test of epoch 3: loss -0.21142 acc 0.65789 roc_auc 0.87385 prc_auc 0.94085[0m
[92maverage training of epoch 4: loss -0.28031 acc 0.66667 roc_auc 0.57000 prc_auc 0.77288[0m
[93maverage test of epoch 4: loss -0.35499 acc 0.65789 roc_auc 0.87692 prc_auc 0.94174[0m
[92maverage training of epoch 5: loss -0.43306 acc 0.66667 roc_auc 0.54560 prc_auc 0.75386[0m
[93maverage test of epoch 5: loss -0.51802 acc 0.65789 roc_auc 0.87077 prc_auc 0.93581[0m
[92maverage training of epoch 6: loss -0.61567 acc 0.66667 roc_auc 0.51080 prc_auc 0.71869[0m
[93maverage test of epoch 6: loss -0.72300 acc 0.65789 roc_auc 0.86154 prc_auc 0.92141[0m
[92maverage training of epoch 7: loss -0.85167 acc 0.66667 roc_auc 0.42040 prc_auc 0.62418[0m
[93maverage test of epoch 7: loss -0.98798 acc 0.65789 roc_auc 0.60923 prc_auc 0.75761[0m
[92maverage training of epoch 8: loss -1.13445 acc 0.66667 roc_auc 0.35800 prc_auc 0.59096[0m
[93maverage test of epoch 8: loss -1.27766 acc 0.65789 roc_auc 0.24615 prc_auc 0.59794[0m
[92maverage training of epoch 9: loss -1.40328 acc 0.66667 roc_auc 0.34700 prc_auc 0.59263[0m
[93maverage test of epoch 9: loss -1.51772 acc 0.65789 roc_auc 0.25077 prc_auc 0.62901[0m
[92maverage training of epoch 10: loss -1.61218 acc 0.66667 roc_auc 0.38220 prc_auc 0.60919[0m
[93maverage test of epoch 10: loss -1.69968 acc 0.65789 roc_auc 0.24769 prc_auc 0.60570[0m
[92maverage training of epoch 11: loss -1.77720 acc 0.66667 roc_auc 0.42300 prc_auc 0.63270[0m
[93maverage test of epoch 11: loss -1.85130 acc 0.65789 roc_auc 0.24000 prc_auc 0.60265[0m
[92maverage training of epoch 12: loss -1.92098 acc 0.66667 roc_auc 0.46540 prc_auc 0.67208[0m
[93maverage test of epoch 12: loss -1.98901 acc 0.65789 roc_auc 0.25538 prc_auc 0.62341[0m
[92maverage training of epoch 13: loss -2.05482 acc 0.66667 roc_auc 0.50260 prc_auc 0.71314[0m
[93maverage test of epoch 13: loss -2.12009 acc 0.65789 roc_auc 0.70769 prc_auc 0.85829[0m
[92maverage training of epoch 14: loss -2.18371 acc 0.66667 roc_auc 0.53140 prc_auc 0.73902[0m
[93maverage test of epoch 14: loss -2.24765 acc 0.65789 roc_auc 0.82462 prc_auc 0.90298[0m
[92maverage training of epoch 15: loss -2.30965 acc 0.66667 roc_auc 0.54880 prc_auc 0.75197[0m
[93maverage test of epoch 15: loss -2.37272 acc 0.65789 roc_auc 0.86154 prc_auc 0.92386[0m
[92maverage training of epoch 16: loss -2.43320 acc 0.66667 roc_auc 0.56000 prc_auc 0.75779[0m
[93maverage test of epoch 16: loss -2.49541 acc 0.65789 roc_auc 0.87385 prc_auc 0.92576[0m
[92maverage training of epoch 17: loss -2.55432 acc 0.66667 roc_auc 0.56680 prc_auc 0.76375[0m
[93maverage test of epoch 17: loss -2.61557 acc 0.65789 roc_auc 0.86769 prc_auc 0.92373[0m
[92maverage training of epoch 18: loss -2.67291 acc 0.60667 roc_auc 0.56600 prc_auc 0.76427[0m
[93maverage test of epoch 18: loss -2.73317 acc 0.42105 roc_auc 0.86154 prc_auc 0.92126[0m
[92maverage training of epoch 19: loss -2.78901 acc 0.36000 roc_auc 0.56600 prc_auc 0.76411[0m
[93maverage test of epoch 19: loss -2.84836 acc 0.36842 roc_auc 0.85385 prc_auc 0.91866[0m
[92maverage training of epoch 20: loss -2.90286 acc 0.34000 roc_auc 0.56280 prc_auc 0.76014[0m
[93maverage test of epoch 20: loss -2.96145 acc 0.34211 roc_auc 0.84923 prc_auc 0.91705[0m
[92maverage training of epoch 21: loss -3.01479 acc 0.33333 roc_auc 0.56000 prc_auc 0.75901[0m
[93maverage test of epoch 21: loss -3.07281 acc 0.34211 roc_auc 0.85231 prc_auc 0.91839[0m
[92maverage training of epoch 22: loss -3.12519 acc 0.33333 roc_auc 0.56000 prc_auc 0.75918[0m
[93maverage test of epoch 22: loss -3.18285 acc 0.34211 roc_auc 0.87077 prc_auc 0.93575[0m
[92maverage training of epoch 23: loss -3.23444 acc 0.33333 roc_auc 0.56240 prc_auc 0.76190[0m
[93maverage test of epoch 23: loss -3.29198 acc 0.34211 roc_auc 0.87385 prc_auc 0.93727[0m
[92maverage training of epoch 24: loss -3.34296 acc 0.33333 roc_auc 0.56980 prc_auc 0.76710[0m
[93maverage test of epoch 24: loss -3.40059 acc 0.34211 roc_auc 0.87385 prc_auc 0.93727[0m
[92maverage training of epoch 25: loss -3.45111 acc 0.33333 roc_auc 0.57820 prc_auc 0.77416[0m
[93maverage test of epoch 25: loss -3.50904 acc 0.34211 roc_auc 0.87077 prc_auc 0.93622[0m
[92maverage training of epoch 26: loss -3.55925 acc 0.33333 roc_auc 0.58600 prc_auc 0.77995[0m
[93maverage test of epoch 26: loss -3.61768 acc 0.34211 roc_auc 0.87077 prc_auc 0.93637[0m
[92maverage training of epoch 27: loss -3.66769 acc 0.33333 roc_auc 0.59200 prc_auc 0.78375[0m
[93maverage test of epoch 27: loss -3.72679 acc 0.34211 roc_auc 0.87385 prc_auc 0.93705[0m
[92maverage training of epoch 28: loss -3.77671 acc 0.33333 roc_auc 0.60600 prc_auc 0.79606[0m
[93maverage test of epoch 28: loss -3.83660 acc 0.34211 roc_auc 0.87692 prc_auc 0.93712[0m
[92maverage training of epoch 29: loss -3.88648 acc 0.33333 roc_auc 0.61760 prc_auc 0.80634[0m
[93maverage test of epoch 29: loss -3.94725 acc 0.34211 roc_auc 0.87692 prc_auc 0.93712[0m
[92maverage training of epoch 30: loss -3.99710 acc 0.33333 roc_auc 0.62740 prc_auc 0.81352[0m
[93maverage test of epoch 30: loss -4.05873 acc 0.34211 roc_auc 0.87077 prc_auc 0.93516[0m
[92maverage training of epoch 31: loss -4.10851 acc 0.33333 roc_auc 0.63280 prc_auc 0.81710[0m
[93maverage test of epoch 31: loss -4.17094 acc 0.34211 roc_auc 0.86769 prc_auc 0.93415[0m
[92maverage training of epoch 32: loss -4.22058 acc 0.33333 roc_auc 0.64200 prc_auc 0.82224[0m
[93maverage test of epoch 32: loss -4.28376 acc 0.34211 roc_auc 0.86769 prc_auc 0.93415[0m
[92maverage training of epoch 33: loss -4.33319 acc 0.33333 roc_auc 0.66440 prc_auc 0.82948[0m
[93maverage test of epoch 33: loss -4.39715 acc 0.34211 roc_auc 0.86462 prc_auc 0.93326[0m
[92maverage training of epoch 34: loss -4.44649 acc 0.33333 roc_auc 0.71580 prc_auc 0.85447[0m
[93maverage test of epoch 34: loss -4.51155 acc 0.34211 roc_auc 0.86154 prc_auc 0.93235[0m
[92maverage training of epoch 35: loss -4.56122 acc 0.33333 roc_auc 0.75880 prc_auc 0.87532[0m
[93maverage test of epoch 35: loss -4.62810 acc 0.34211 roc_auc 0.85846 prc_auc 0.93142[0m
[92maverage training of epoch 36: loss -4.67872 acc 0.33333 roc_auc 0.78540 prc_auc 0.88860[0m
[93maverage test of epoch 36: loss -4.74762 acc 0.34211 roc_auc 0.85846 prc_auc 0.93142[0m
[92maverage training of epoch 37: loss -4.79911 acc 0.33333 roc_auc 0.82800 prc_auc 0.90547[0m
[93maverage test of epoch 37: loss -4.86820 acc 0.34211 roc_auc 0.85846 prc_auc 0.93142[0m
[92maverage training of epoch 38: loss -4.91995 acc 0.33333 roc_auc 0.86560 prc_auc 0.92205[0m
[93maverage test of epoch 38: loss -4.98726 acc 0.34211 roc_auc 0.86154 prc_auc 0.93450[0m
[92maverage training of epoch 39: loss -5.03937 acc 0.33333 roc_auc 0.87120 prc_auc 0.92561[0m
[93maverage test of epoch 39: loss -5.10452 acc 0.34211 roc_auc 0.86462 prc_auc 0.93736[0m
[92maverage training of epoch 40: loss -5.15734 acc 0.33333 roc_auc 0.87980 prc_auc 0.92980[0m
[93maverage test of epoch 40: loss -5.22054 acc 0.34211 roc_auc 0.86462 prc_auc 0.93736[0m
[92maverage training of epoch 41: loss -5.27433 acc 0.33333 roc_auc 0.88300 prc_auc 0.93123[0m
[93maverage test of epoch 41: loss -5.33570 acc 0.34211 roc_auc 0.86462 prc_auc 0.93736[0m
[92maverage training of epoch 42: loss -5.39064 acc 0.33333 roc_auc 0.88580 prc_auc 0.93205[0m
[93maverage test of epoch 42: loss -5.45011 acc 0.34211 roc_auc 0.86769 prc_auc 0.93837[0m
[92maverage training of epoch 43: loss -5.50634 acc 0.52000 roc_auc 0.88700 prc_auc 0.93141[0m
[93maverage test of epoch 43: loss -5.56362 acc 0.65789 roc_auc 0.86769 prc_auc 0.93837[0m
[92maverage training of epoch 44: loss -5.62123 acc 0.67333 roc_auc 0.88680 prc_auc 0.93003[0m
[93maverage test of epoch 44: loss -5.67608 acc 0.73684 roc_auc 0.86769 prc_auc 0.93837[0m
[92maverage training of epoch 45: loss -5.73528 acc 0.73333 roc_auc 0.88700 prc_auc 0.92893[0m
[93maverage test of epoch 45: loss -5.78752 acc 0.73684 roc_auc 0.86769 prc_auc 0.93837[0m
[92maverage training of epoch 46: loss -5.84852 acc 0.76000 roc_auc 0.88620 prc_auc 0.92654[0m
[93maverage test of epoch 46: loss -5.89799 acc 0.78947 roc_auc 0.86769 prc_auc 0.93837[0m
[92maverage training of epoch 47: loss -5.96094 acc 0.84000 roc_auc 0.88340 prc_auc 0.92256[0m
[93maverage test of epoch 47: loss -6.00750 acc 0.81579 roc_auc 0.86769 prc_auc 0.93837[0m
[92maverage training of epoch 48: loss -6.07254 acc 0.86000 roc_auc 0.88140 prc_auc 0.91818[0m
[93maverage test of epoch 48: loss -6.11607 acc 0.81579 roc_auc 0.86769 prc_auc 0.93837[0m
[92maverage training of epoch 49: loss -6.18333 acc 0.86667 roc_auc 0.87960 prc_auc 0.91188[0m
[93maverage test of epoch 49: loss -6.22374 acc 0.81579 roc_auc 0.86769 prc_auc 0.93837[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.14601 acc 0.66667 roc_auc 0.35580 prc_auc 0.57218[0m
[93maverage test of epoch 0: loss -0.28116 acc 0.65789 roc_auc 0.21231 prc_auc 0.56568[0m
[92maverage training of epoch 1: loss -0.42088 acc 0.66667 roc_auc 0.33840 prc_auc 0.56418[0m
[93maverage test of epoch 1: loss -0.55135 acc 0.65789 roc_auc 0.16308 prc_auc 0.49895[0m
[92maverage training of epoch 2: loss -0.68435 acc 0.66667 roc_auc 0.33140 prc_auc 0.55907[0m
[93maverage test of epoch 2: loss -0.80516 acc 0.65789 roc_auc 0.15385 prc_auc 0.49597[0m
[92maverage training of epoch 3: loss -0.92876 acc 0.66667 roc_auc 0.32830 prc_auc 0.55495[0m
[93maverage test of epoch 3: loss -1.03891 acc 0.65789 roc_auc 0.15077 prc_auc 0.49502[0m
[92maverage training of epoch 4: loss -1.15530 acc 0.66667 roc_auc 0.32540 prc_auc 0.55254[0m
[93maverage test of epoch 4: loss -1.25903 acc 0.65789 roc_auc 0.15077 prc_auc 0.49502[0m
[92maverage training of epoch 5: loss -1.37516 acc 0.66667 roc_auc 0.32130 prc_auc 0.55037[0m
[93maverage test of epoch 5: loss -1.48267 acc 0.65789 roc_auc 0.15077 prc_auc 0.49502[0m
[92maverage training of epoch 6: loss -1.61252 acc 0.66667 roc_auc 0.29620 prc_auc 0.54096[0m
[93maverage test of epoch 6: loss -1.74509 acc 0.65789 roc_auc 0.15077 prc_auc 0.49518[0m
[92maverage training of epoch 7: loss -1.91076 acc 0.66667 roc_auc 0.23740 prc_auc 0.51780[0m
[93maverage test of epoch 7: loss -2.08714 acc 0.65789 roc_auc 0.13538 prc_auc 0.49075[0m
[92maverage training of epoch 8: loss -2.26058 acc 0.66667 roc_auc 0.31220 prc_auc 0.54844[0m
[93maverage test of epoch 8: loss -2.42263 acc 0.65789 roc_auc 0.13231 prc_auc 0.48948[0m
[92maverage training of epoch 9: loss -2.57081 acc 0.66667 roc_auc 0.36880 prc_auc 0.58047[0m
[93maverage test of epoch 9: loss -2.70467 acc 0.65789 roc_auc 0.12615 prc_auc 0.48735[0m
[92maverage training of epoch 10: loss -2.84613 acc 0.66667 roc_auc 0.38560 prc_auc 0.58694[0m
[93maverage test of epoch 10: loss -2.98100 acc 0.65789 roc_auc 0.13846 prc_auc 0.49076[0m
[92maverage training of epoch 11: loss -3.12278 acc 0.66667 roc_auc 0.39220 prc_auc 0.59967[0m
[93maverage test of epoch 11: loss -3.24966 acc 0.65789 roc_auc 0.23077 prc_auc 0.57029[0m
[92maverage training of epoch 12: loss -3.36918 acc 0.66667 roc_auc 0.39880 prc_auc 0.60183[0m
[93maverage test of epoch 12: loss -3.47523 acc 0.65789 roc_auc 0.22769 prc_auc 0.56924[0m
[92maverage training of epoch 13: loss -3.57957 acc 0.66667 roc_auc 0.40060 prc_auc 0.60045[0m
[93maverage test of epoch 13: loss -3.67336 acc 0.65789 roc_auc 0.23077 prc_auc 0.57010[0m
[92maverage training of epoch 14: loss -3.76914 acc 0.66667 roc_auc 0.40600 prc_auc 0.60442[0m
[93maverage test of epoch 14: loss -3.85459 acc 0.65789 roc_auc 0.23385 prc_auc 0.57115[0m
[92maverage training of epoch 15: loss -3.94477 acc 0.66667 roc_auc 0.41060 prc_auc 0.60667[0m
[93maverage test of epoch 15: loss -4.02351 acc 0.65789 roc_auc 0.25846 prc_auc 0.57798[0m
[92maverage training of epoch 16: loss -4.10969 acc 0.66667 roc_auc 0.41500 prc_auc 0.60896[0m
[93maverage test of epoch 16: loss -4.18268 acc 0.65789 roc_auc 0.30769 prc_auc 0.63391[0m
[92maverage training of epoch 17: loss -4.26585 acc 0.66667 roc_auc 0.41920 prc_auc 0.61159[0m
[93maverage test of epoch 17: loss -4.33379 acc 0.65789 roc_auc 0.34615 prc_auc 0.66219[0m
[92maverage training of epoch 18: loss -4.41463 acc 0.66667 roc_auc 0.42060 prc_auc 0.61593[0m
[93maverage test of epoch 18: loss -4.47810 acc 0.65789 roc_auc 0.36923 prc_auc 0.68531[0m
[92maverage training of epoch 19: loss -4.55713 acc 0.66667 roc_auc 0.42060 prc_auc 0.61705[0m
[93maverage test of epoch 19: loss -4.61662 acc 0.65789 roc_auc 0.54462 prc_auc 0.79920[0m
[92maverage training of epoch 20: loss -4.69423 acc 0.66667 roc_auc 0.42440 prc_auc 0.61702[0m
[93maverage test of epoch 20: loss -4.75017 acc 0.65789 roc_auc 0.69538 prc_auc 0.86642[0m
[92maverage training of epoch 21: loss -4.82670 acc 0.66667 roc_auc 0.42900 prc_auc 0.61771[0m
[93maverage test of epoch 21: loss -4.87948 acc 0.65789 roc_auc 0.76308 prc_auc 0.90000[0m
[92maverage training of epoch 22: loss -4.95518 acc 0.66667 roc_auc 0.43140 prc_auc 0.62463[0m
[93maverage test of epoch 22: loss -5.00515 acc 0.65789 roc_auc 0.82462 prc_auc 0.92544[0m
[92maverage training of epoch 23: loss -5.08025 acc 0.66667 roc_auc 0.43460 prc_auc 0.62820[0m
[93maverage test of epoch 23: loss -5.12773 acc 0.65789 roc_auc 0.87692 prc_auc 0.94170[0m
[92maverage training of epoch 24: loss -5.20241 acc 0.66667 roc_auc 0.43780 prc_auc 0.63029[0m
[93maverage test of epoch 24: loss -5.24767 acc 0.65789 roc_auc 0.90769 prc_auc 0.95015[0m
[92maverage training of epoch 25: loss -5.32209 acc 0.66667 roc_auc 0.44180 prc_auc 0.63377[0m
[93maverage test of epoch 25: loss -5.36537 acc 0.65789 roc_auc 0.91385 prc_auc 0.95410[0m
[92maverage training of epoch 26: loss -5.43968 acc 0.66667 roc_auc 0.44430 prc_auc 0.64204[0m
[93maverage test of epoch 26: loss -5.48120 acc 0.65789 roc_auc 0.90769 prc_auc 0.94923[0m
[92maverage training of epoch 27: loss -5.55550 acc 0.66667 roc_auc 0.44720 prc_auc 0.64813[0m
[93maverage test of epoch 27: loss -5.59543 acc 0.65789 roc_auc 0.90462 prc_auc 0.94549[0m
[92maverage training of epoch 28: loss -5.66982 acc 0.66667 roc_auc 0.44880 prc_auc 0.64900[0m
[93maverage test of epoch 28: loss -5.70833 acc 0.65789 roc_auc 0.90462 prc_auc 0.94549[0m
[92maverage training of epoch 29: loss -5.78288 acc 0.66667 roc_auc 0.45360 prc_auc 0.65425[0m
[93maverage test of epoch 29: loss -5.82012 acc 0.65789 roc_auc 0.90462 prc_auc 0.94549[0m
[92maverage training of epoch 30: loss -5.89490 acc 0.66667 roc_auc 0.45410 prc_auc 0.65554[0m
[93maverage test of epoch 30: loss -5.93099 acc 0.65789 roc_auc 0.90462 prc_auc 0.94549[0m
[92maverage training of epoch 31: loss -6.00605 acc 0.66667 roc_auc 0.45480 prc_auc 0.65704[0m
[93maverage test of epoch 31: loss -6.04111 acc 0.65789 roc_auc 0.90462 prc_auc 0.94549[0m
[92maverage training of epoch 32: loss -6.11649 acc 0.66667 roc_auc 0.45380 prc_auc 0.65521[0m
[93maverage test of epoch 32: loss -6.15062 acc 0.65789 roc_auc 0.90462 prc_auc 0.94549[0m
[92maverage training of epoch 33: loss -6.22636 acc 0.66667 roc_auc 0.45220 prc_auc 0.65338[0m
[93maverage test of epoch 33: loss -6.25966 acc 0.65789 roc_auc 0.90769 prc_auc 0.94707[0m
[92maverage training of epoch 34: loss -6.33578 acc 0.66667 roc_auc 0.44980 prc_auc 0.65176[0m
[93maverage test of epoch 34: loss -6.36834 acc 0.65789 roc_auc 0.90769 prc_auc 0.94720[0m
[92maverage training of epoch 35: loss -6.44485 acc 0.66667 roc_auc 0.44520 prc_auc 0.64897[0m
[93maverage test of epoch 35: loss -6.47675 acc 0.65789 roc_auc 0.90769 prc_auc 0.94707[0m
[92maverage training of epoch 36: loss -6.55367 acc 0.66667 roc_auc 0.44380 prc_auc 0.64689[0m
[93maverage test of epoch 36: loss -6.58499 acc 0.65789 roc_auc 0.90769 prc_auc 0.94707[0m
[92maverage training of epoch 37: loss -6.66230 acc 0.66667 roc_auc 0.44130 prc_auc 0.64536[0m
[93maverage test of epoch 37: loss -6.69310 acc 0.65789 roc_auc 0.90769 prc_auc 0.94748[0m
[92maverage training of epoch 38: loss -6.77081 acc 0.66667 roc_auc 0.43920 prc_auc 0.64371[0m
[93maverage test of epoch 38: loss -6.80115 acc 0.65789 roc_auc 0.90923 prc_auc 0.94722[0m
[92maverage training of epoch 39: loss -6.87923 acc 0.66667 roc_auc 0.43700 prc_auc 0.64221[0m
[93maverage test of epoch 39: loss -6.90914 acc 0.65789 roc_auc 0.90923 prc_auc 0.94723[0m
[92maverage training of epoch 40: loss -6.98759 acc 0.66667 roc_auc 0.43500 prc_auc 0.63573[0m
[93maverage test of epoch 40: loss -7.01710 acc 0.65789 roc_auc 0.90615 prc_auc 0.94443[0m
[92maverage training of epoch 41: loss -7.09587 acc 0.66667 roc_auc 0.43160 prc_auc 0.62851[0m
[93maverage test of epoch 41: loss -7.12502 acc 0.65789 roc_auc 0.90769 prc_auc 0.94748[0m
[92maverage training of epoch 42: loss -7.20409 acc 0.66667 roc_auc 0.42900 prc_auc 0.62528[0m
[93maverage test of epoch 42: loss -7.23287 acc 0.65789 roc_auc 0.90615 prc_auc 0.94375[0m
[92maverage training of epoch 43: loss -7.31221 acc 0.66667 roc_auc 0.42550 prc_auc 0.60848[0m
[93maverage test of epoch 43: loss -7.34063 acc 0.65789 roc_auc 0.90923 prc_auc 0.94635[0m
[92maverage training of epoch 44: loss -7.42020 acc 0.66667 roc_auc 0.42070 prc_auc 0.60336[0m
[93maverage test of epoch 44: loss -7.44825 acc 0.65789 roc_auc 0.82923 prc_auc 0.90908[0m
[92maverage training of epoch 45: loss -7.52803 acc 0.66667 roc_auc 0.41720 prc_auc 0.59961[0m
[93maverage test of epoch 45: loss -7.55570 acc 0.65789 roc_auc 0.82923 prc_auc 0.90769[0m
[92maverage training of epoch 46: loss -7.63565 acc 0.66667 roc_auc 0.41460 prc_auc 0.59806[0m
[93maverage test of epoch 46: loss -7.66294 acc 0.65789 roc_auc 0.83231 prc_auc 0.91029[0m
[92maverage training of epoch 47: loss -7.74304 acc 0.66667 roc_auc 0.41280 prc_auc 0.59611[0m
[93maverage test of epoch 47: loss -7.76993 acc 0.65789 roc_auc 0.82462 prc_auc 0.90165[0m
[92maverage training of epoch 48: loss -7.85016 acc 0.66667 roc_auc 0.41280 prc_auc 0.59561[0m
[93maverage test of epoch 48: loss -7.87663 acc 0.65789 roc_auc 0.81846 prc_auc 0.89864[0m
[92maverage training of epoch 49: loss -7.95697 acc 0.66667 roc_auc 0.41170 prc_auc 0.59502[0m
[93maverage test of epoch 49: loss -7.98301 acc 0.65789 roc_auc 0.82308 prc_auc 0.89763[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.21316 acc 0.66667 roc_auc 0.45420 prc_auc 0.65581[0m
[93maverage test of epoch 0: loss -0.38728 acc 0.65789 roc_auc 0.90769 prc_auc 0.96098[0m
[92maverage training of epoch 1: loss -0.56288 acc 0.66667 roc_auc 0.43300 prc_auc 0.63888[0m
[93maverage test of epoch 1: loss -0.73599 acc 0.65789 roc_auc 0.75077 prc_auc 0.89971[0m
[92maverage training of epoch 2: loss -0.90878 acc 0.66667 roc_auc 0.42000 prc_auc 0.62845[0m
[93maverage test of epoch 2: loss -1.07407 acc 0.65789 roc_auc 0.43077 prc_auc 0.72678[0m
[92maverage training of epoch 3: loss -1.23647 acc 0.66667 roc_auc 0.41580 prc_auc 0.62056[0m
[93maverage test of epoch 3: loss -1.38802 acc 0.65789 roc_auc 0.16923 prc_auc 0.56408[0m
[92maverage training of epoch 4: loss -1.53928 acc 0.66667 roc_auc 0.41860 prc_auc 0.62712[0m
[93maverage test of epoch 4: loss -1.67942 acc 0.65789 roc_auc 0.40615 prc_auc 0.71420[0m
[92maverage training of epoch 5: loss -1.82720 acc 0.66667 roc_auc 0.42350 prc_auc 0.62994[0m
[93maverage test of epoch 5: loss -1.96616 acc 0.65789 roc_auc 0.86769 prc_auc 0.94761[0m
[92maverage training of epoch 6: loss -2.12430 acc 0.66667 roc_auc 0.42380 prc_auc 0.63130[0m
[93maverage test of epoch 6: loss -2.27681 acc 0.65789 roc_auc 0.92462 prc_auc 0.97079[0m
[92maverage training of epoch 7: loss -2.45542 acc 0.66667 roc_auc 0.43180 prc_auc 0.63847[0m
[93maverage test of epoch 7: loss -2.62718 acc 0.65789 roc_auc 0.96000 prc_auc 0.98266[0m
[92maverage training of epoch 8: loss -2.82299 acc 0.66667 roc_auc 0.43440 prc_auc 0.63990[0m
[93maverage test of epoch 8: loss -3.00958 acc 0.65789 roc_auc 0.95077 prc_auc 0.97769[0m
[92maverage training of epoch 9: loss -3.22574 acc 0.66667 roc_auc 0.43940 prc_auc 0.64197[0m
[93maverage test of epoch 9: loss -3.43354 acc 0.65789 roc_auc 0.95231 prc_auc 0.97791[0m
[92maverage training of epoch 10: loss -3.67725 acc 0.66667 roc_auc 0.44780 prc_auc 0.64955[0m
[93maverage test of epoch 10: loss -3.90466 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 11: loss -4.15811 acc 0.66667 roc_auc 0.45880 prc_auc 0.65692[0m
[93maverage test of epoch 11: loss -4.37781 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 12: loss -4.60535 acc 0.66667 roc_auc 0.46940 prc_auc 0.66145[0m
[93maverage test of epoch 12: loss -4.78210 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 13: loss -4.96119 acc 0.66667 roc_auc 0.46820 prc_auc 0.66120[0m
[93maverage test of epoch 13: loss -5.08838 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 14: loss -5.23181 acc 0.66667 roc_auc 0.45740 prc_auc 0.65191[0m
[93maverage test of epoch 14: loss -5.32792 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 15: loss -5.45156 acc 0.66667 roc_auc 0.44720 prc_auc 0.64213[0m
[93maverage test of epoch 15: loss -5.53003 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 16: loss -5.64211 acc 0.66667 roc_auc 0.43610 prc_auc 0.63287[0m
[93maverage test of epoch 16: loss -5.70957 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 17: loss -5.81417 acc 0.66667 roc_auc 0.42740 prc_auc 0.62710[0m
[93maverage test of epoch 17: loss -5.87404 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 18: loss -5.97338 acc 0.66667 roc_auc 0.42120 prc_auc 0.62633[0m
[93maverage test of epoch 18: loss -6.02762 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 19: loss -6.12306 acc 0.66667 roc_auc 0.41820 prc_auc 0.62520[0m
[93maverage test of epoch 19: loss -6.17293 acc 0.65789 roc_auc 0.95538 prc_auc 0.97933[0m
[92maverage training of epoch 20: loss -6.26538 acc 0.66667 roc_auc 0.41610 prc_auc 0.62513[0m
[93maverage test of epoch 20: loss -6.31175 acc 0.65789 roc_auc 0.95538 prc_auc 0.97933[0m
[92maverage training of epoch 21: loss -6.40183 acc 0.66667 roc_auc 0.41320 prc_auc 0.62428[0m
[93maverage test of epoch 21: loss -6.44531 acc 0.65789 roc_auc 0.95538 prc_auc 0.97933[0m
[92maverage training of epoch 22: loss -6.53350 acc 0.66667 roc_auc 0.40980 prc_auc 0.62129[0m
[93maverage test of epoch 22: loss -6.57456 acc 0.65789 roc_auc 0.95538 prc_auc 0.97933[0m
[92maverage training of epoch 23: loss -6.66121 acc 0.66667 roc_auc 0.40680 prc_auc 0.61684[0m
[93maverage test of epoch 23: loss -6.70020 acc 0.65789 roc_auc 0.95538 prc_auc 0.97933[0m
[92maverage training of epoch 24: loss -6.78560 acc 0.66667 roc_auc 0.40380 prc_auc 0.61508[0m
[93maverage test of epoch 24: loss -6.82280 acc 0.65789 roc_auc 0.95385 prc_auc 0.97808[0m
[92maverage training of epoch 25: loss -6.90716 acc 0.66667 roc_auc 0.40210 prc_auc 0.61374[0m
[93maverage test of epoch 25: loss -6.94280 acc 0.65789 roc_auc 0.95538 prc_auc 0.97933[0m
[92maverage training of epoch 26: loss -7.02631 acc 0.66667 roc_auc 0.39950 prc_auc 0.61085[0m
[93maverage test of epoch 26: loss -7.06057 acc 0.65789 roc_auc 0.95538 prc_auc 0.97946[0m
[92maverage training of epoch 27: loss -7.14336 acc 0.66667 roc_auc 0.39640 prc_auc 0.60892[0m
[93maverage test of epoch 27: loss -7.17639 acc 0.65789 roc_auc 0.95385 prc_auc 0.97808[0m
[92maverage training of epoch 28: loss -7.25859 acc 0.66667 roc_auc 0.39500 prc_auc 0.60838[0m
[93maverage test of epoch 28: loss -7.29052 acc 0.65789 roc_auc 0.95385 prc_auc 0.97808[0m
[92maverage training of epoch 29: loss -7.37224 acc 0.66667 roc_auc 0.39360 prc_auc 0.60702[0m
[93maverage test of epoch 29: loss -7.40317 acc 0.65789 roc_auc 0.95231 prc_auc 0.97697[0m
[92maverage training of epoch 30: loss -7.48449 acc 0.66667 roc_auc 0.39240 prc_auc 0.60631[0m
[93maverage test of epoch 30: loss -7.51450 acc 0.65789 roc_auc 0.95231 prc_auc 0.97697[0m
[92maverage training of epoch 31: loss -7.59550 acc 0.66667 roc_auc 0.39220 prc_auc 0.60578[0m
[93maverage test of epoch 31: loss -7.62468 acc 0.65789 roc_auc 0.95231 prc_auc 0.97697[0m
[92maverage training of epoch 32: loss -7.70543 acc 0.66667 roc_auc 0.39160 prc_auc 0.60563[0m
[93maverage test of epoch 32: loss -7.73383 acc 0.65789 roc_auc 0.95077 prc_auc 0.97663[0m
[92maverage training of epoch 33: loss -7.81437 acc 0.66667 roc_auc 0.39060 prc_auc 0.60513[0m
[93maverage test of epoch 33: loss -7.84206 acc 0.65789 roc_auc 0.95231 prc_auc 0.97697[0m
[92maverage training of epoch 34: loss -7.92245 acc 0.66667 roc_auc 0.38960 prc_auc 0.60448[0m
[93maverage test of epoch 34: loss -7.94947 acc 0.65789 roc_auc 0.95385 prc_auc 0.97697[0m
[92maverage training of epoch 35: loss -8.02974 acc 0.66667 roc_auc 0.38910 prc_auc 0.60395[0m
[93maverage test of epoch 35: loss -8.05614 acc 0.65789 roc_auc 0.95385 prc_auc 0.97697[0m
[92maverage training of epoch 36: loss -8.13634 acc 0.66667 roc_auc 0.38870 prc_auc 0.60418[0m
[93maverage test of epoch 36: loss -8.16214 acc 0.65789 roc_auc 0.95077 prc_auc 0.97663[0m
[92maverage training of epoch 37: loss -8.24231 acc 0.66667 roc_auc 0.38840 prc_auc 0.60366[0m
[93maverage test of epoch 37: loss -8.26755 acc 0.65789 roc_auc 0.95385 prc_auc 0.97697[0m
[92maverage training of epoch 38: loss -8.34771 acc 0.66667 roc_auc 0.38750 prc_auc 0.60271[0m
[93maverage test of epoch 38: loss -8.37242 acc 0.65789 roc_auc 0.95538 prc_auc 0.97808[0m
[92maverage training of epoch 39: loss -8.45259 acc 0.66667 roc_auc 0.38730 prc_auc 0.60287[0m
[93maverage test of epoch 39: loss -8.47680 acc 0.65789 roc_auc 0.95692 prc_auc 0.97946[0m
[92maverage training of epoch 40: loss -8.55701 acc 0.66667 roc_auc 0.38690 prc_auc 0.60247[0m
[93maverage test of epoch 40: loss -8.58074 acc 0.65789 roc_auc 0.95846 prc_auc 0.97697[0m
[92maverage training of epoch 41: loss -8.66101 acc 0.66667 roc_auc 0.38640 prc_auc 0.60242[0m
[93maverage test of epoch 41: loss -8.68427 acc 0.65789 roc_auc 0.95846 prc_auc 0.97693[0m
[92maverage training of epoch 42: loss -8.76462 acc 0.66667 roc_auc 0.38640 prc_auc 0.60205[0m
[93maverage test of epoch 42: loss -8.78744 acc 0.65789 roc_auc 0.96308 prc_auc 0.97697[0m
[92maverage training of epoch 43: loss -8.86788 acc 0.66667 roc_auc 0.38620 prc_auc 0.60217[0m
[93maverage test of epoch 43: loss -8.89027 acc 0.65789 roc_auc 0.94462 prc_auc 0.97298[0m
[92maverage training of epoch 44: loss -8.97083 acc 0.66667 roc_auc 0.38560 prc_auc 0.60017[0m
[93maverage test of epoch 44: loss -8.99281 acc 0.65789 roc_auc 0.95538 prc_auc 0.97363[0m
[92maverage training of epoch 45: loss -9.07348 acc 0.66667 roc_auc 0.38530 prc_auc 0.60038[0m
[93maverage test of epoch 45: loss -9.09506 acc 0.65789 roc_auc 0.96769 prc_auc 0.97697[0m
[92maverage training of epoch 46: loss -9.17587 acc 0.66667 roc_auc 0.38550 prc_auc 0.59784[0m
[93maverage test of epoch 46: loss -9.19706 acc 0.65789 roc_auc 0.95692 prc_auc 0.97298[0m
[92maverage training of epoch 47: loss -9.27802 acc 0.66667 roc_auc 0.38510 prc_auc 0.59787[0m
[93maverage test of epoch 47: loss -9.29883 acc 0.65789 roc_auc 0.94769 prc_auc 0.96111[0m
[92maverage training of epoch 48: loss -9.37995 acc 0.66667 roc_auc 0.38490 prc_auc 0.59743[0m
[93maverage test of epoch 48: loss -9.40038 acc 0.65789 roc_auc 0.94000 prc_auc 0.95822[0m
[92maverage training of epoch 49: loss -9.48168 acc 0.66667 roc_auc 0.38450 prc_auc 0.59682[0m
[93maverage test of epoch 49: loss -9.50174 acc 0.65789 roc_auc 0.93538 prc_auc 0.95965[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.16745 acc 0.66225 roc_auc 0.37510 prc_auc 0.57691[0m
[93maverage test of epoch 0: loss -0.32981 acc 0.67568 roc_auc 0.17333 prc_auc 0.54929[0m
[92maverage training of epoch 1: loss -0.44420 acc 0.66225 roc_auc 0.39255 prc_auc 0.59233[0m
[93maverage test of epoch 1: loss -0.62590 acc 0.67568 roc_auc 0.21000 prc_auc 0.57302[0m
[92maverage training of epoch 2: loss -0.79184 acc 0.66225 roc_auc 0.42608 prc_auc 0.62290[0m
[93maverage test of epoch 2: loss -1.04417 acc 0.67568 roc_auc 0.50667 prc_auc 0.78701[0m
[92maverage training of epoch 3: loss -1.23053 acc 0.66225 roc_auc 0.45314 prc_auc 0.64613[0m
[93maverage test of epoch 3: loss -1.45912 acc 0.67568 roc_auc 0.81333 prc_auc 0.91420[0m
[92maverage training of epoch 4: loss -1.58112 acc 0.66225 roc_auc 0.48039 prc_auc 0.69305[0m
[93maverage test of epoch 4: loss -1.75305 acc 0.67568 roc_auc 0.84000 prc_auc 0.92200[0m
[92maverage training of epoch 5: loss -1.83765 acc 0.66225 roc_auc 0.48667 prc_auc 0.69828[0m
[93maverage test of epoch 5: loss -1.98311 acc 0.67568 roc_auc 0.83000 prc_auc 0.91346[0m
[92maverage training of epoch 6: loss -2.04771 acc 0.66225 roc_auc 0.46294 prc_auc 0.67735[0m
[93maverage test of epoch 6: loss -2.17962 acc 0.67568 roc_auc 0.82667 prc_auc 0.91099[0m
[92maverage training of epoch 7: loss -2.23147 acc 0.66225 roc_auc 0.44941 prc_auc 0.65590[0m
[93maverage test of epoch 7: loss -2.35530 acc 0.67568 roc_auc 0.82667 prc_auc 0.91099[0m
[92maverage training of epoch 8: loss -2.39824 acc 0.66225 roc_auc 0.44294 prc_auc 0.63730[0m
[93maverage test of epoch 8: loss -2.51713 acc 0.67568 roc_auc 0.83333 prc_auc 0.91580[0m
[92maverage training of epoch 9: loss -2.55350 acc 0.66225 roc_auc 0.44627 prc_auc 0.63491[0m
[93maverage test of epoch 9: loss -2.66944 acc 0.67568 roc_auc 0.87333 prc_auc 0.93239[0m
[92maverage training of epoch 10: loss -2.70074 acc 0.66225 roc_auc 0.45471 prc_auc 0.64674[0m
[93maverage test of epoch 10: loss -2.81504 acc 0.67568 roc_auc 0.87333 prc_auc 0.93239[0m
[92maverage training of epoch 11: loss -2.84225 acc 0.66225 roc_auc 0.46157 prc_auc 0.65186[0m
[93maverage test of epoch 11: loss -2.95577 acc 0.67568 roc_auc 0.87167 prc_auc 0.93097[0m
[92maverage training of epoch 12: loss -2.97957 acc 0.66225 roc_auc 0.46392 prc_auc 0.65830[0m
[93maverage test of epoch 12: loss -3.09285 acc 0.67568 roc_auc 0.87000 prc_auc 0.93112[0m
[92maverage training of epoch 13: loss -3.11370 acc 0.66225 roc_auc 0.46490 prc_auc 0.65836[0m
[93maverage test of epoch 13: loss -3.22713 acc 0.67568 roc_auc 0.87000 prc_auc 0.93097[0m
[92maverage training of epoch 14: loss -3.24537 acc 0.66225 roc_auc 0.46392 prc_auc 0.65786[0m
[93maverage test of epoch 14: loss -3.35919 acc 0.67568 roc_auc 0.87000 prc_auc 0.93097[0m
[92maverage training of epoch 15: loss -3.37507 acc 0.66225 roc_auc 0.46275 prc_auc 0.65739[0m
[93maverage test of epoch 15: loss -3.48943 acc 0.67568 roc_auc 0.86667 prc_auc 0.92877[0m
[92maverage training of epoch 16: loss -3.50314 acc 0.66225 roc_auc 0.46196 prc_auc 0.65689[0m
[93maverage test of epoch 16: loss -3.61814 acc 0.67568 roc_auc 0.86500 prc_auc 0.92774[0m
[92maverage training of epoch 17: loss -3.62984 acc 0.66225 roc_auc 0.46039 prc_auc 0.65574[0m
[93maverage test of epoch 17: loss -3.74553 acc 0.67568 roc_auc 0.86500 prc_auc 0.92774[0m
[92maverage training of epoch 18: loss -3.75535 acc 0.66225 roc_auc 0.46020 prc_auc 0.65551[0m
[93maverage test of epoch 18: loss -3.87173 acc 0.67568 roc_auc 0.86333 prc_auc 0.92540[0m
[92maverage training of epoch 19: loss -3.87978 acc 0.66225 roc_auc 0.45765 prc_auc 0.65353[0m
[93maverage test of epoch 19: loss -3.99685 acc 0.67568 roc_auc 0.86500 prc_auc 0.92918[0m
[92maverage training of epoch 20: loss -4.00321 acc 0.66225 roc_auc 0.45608 prc_auc 0.65224[0m
[93maverage test of epoch 20: loss -4.12095 acc 0.67568 roc_auc 0.86500 prc_auc 0.92904[0m
[92maverage training of epoch 21: loss -4.12571 acc 0.66225 roc_auc 0.45255 prc_auc 0.64897[0m
[93maverage test of epoch 21: loss -4.24406 acc 0.67568 roc_auc 0.86667 prc_auc 0.92925[0m
[92maverage training of epoch 22: loss -4.24729 acc 0.66225 roc_auc 0.44882 prc_auc 0.64432[0m
[93maverage test of epoch 22: loss -4.36622 acc 0.67568 roc_auc 0.86667 prc_auc 0.92925[0m
[92maverage training of epoch 23: loss -4.36798 acc 0.66225 roc_auc 0.44627 prc_auc 0.64232[0m
[93maverage test of epoch 23: loss -4.48743 acc 0.67568 roc_auc 0.86500 prc_auc 0.92564[0m
[92maverage training of epoch 24: loss -4.48778 acc 0.66225 roc_auc 0.44294 prc_auc 0.64025[0m
[93maverage test of epoch 24: loss -4.60771 acc 0.67568 roc_auc 0.86667 prc_auc 0.92969[0m
[92maverage training of epoch 25: loss -4.60670 acc 0.66225 roc_auc 0.43922 prc_auc 0.63726[0m
[93maverage test of epoch 25: loss -4.72706 acc 0.67568 roc_auc 0.86667 prc_auc 0.93040[0m
[92maverage training of epoch 26: loss -4.72473 acc 0.66225 roc_auc 0.43520 prc_auc 0.63109[0m
[93maverage test of epoch 26: loss -4.84548 acc 0.67568 roc_auc 0.86500 prc_auc 0.92587[0m
[92maverage training of epoch 27: loss -4.84188 acc 0.66225 roc_auc 0.43206 prc_auc 0.62825[0m
[93maverage test of epoch 27: loss -4.96298 acc 0.67568 roc_auc 0.86667 prc_auc 0.92951[0m
[92maverage training of epoch 28: loss -4.95816 acc 0.66225 roc_auc 0.42794 prc_auc 0.62565[0m
[93maverage test of epoch 28: loss -5.07958 acc 0.67568 roc_auc 0.86833 prc_auc 0.92779[0m
[92maverage training of epoch 29: loss -5.07358 acc 0.66225 roc_auc 0.42382 prc_auc 0.62123[0m
[93maverage test of epoch 29: loss -5.19530 acc 0.67568 roc_auc 0.86833 prc_auc 0.92691[0m
[92maverage training of epoch 30: loss -5.18816 acc 0.66225 roc_auc 0.42206 prc_auc 0.61847[0m
[93maverage test of epoch 30: loss -5.31014 acc 0.67568 roc_auc 0.86500 prc_auc 0.92676[0m
[92maverage training of epoch 31: loss -5.30190 acc 0.66225 roc_auc 0.41971 prc_auc 0.61675[0m
[93maverage test of epoch 31: loss -5.42414 acc 0.67568 roc_auc 0.86833 prc_auc 0.93071[0m
[92maverage training of epoch 32: loss -5.41485 acc 0.66225 roc_auc 0.41725 prc_auc 0.61481[0m
[93maverage test of epoch 32: loss -5.53733 acc 0.67568 roc_auc 0.86833 prc_auc 0.92691[0m
[92maverage training of epoch 33: loss -5.52701 acc 0.66225 roc_auc 0.41441 prc_auc 0.61319[0m
[93maverage test of epoch 33: loss -5.64974 acc 0.67568 roc_auc 0.86667 prc_auc 0.92659[0m
[92maverage training of epoch 34: loss -5.63844 acc 0.66225 roc_auc 0.41225 prc_auc 0.61061[0m
[93maverage test of epoch 34: loss -5.76140 acc 0.67568 roc_auc 0.86833 prc_auc 0.92834[0m
[92maverage training of epoch 35: loss -5.74915 acc 0.66225 roc_auc 0.41088 prc_auc 0.60868[0m
[93maverage test of epoch 35: loss -5.87234 acc 0.67568 roc_auc 0.86833 prc_auc 0.93118[0m
[92maverage training of epoch 36: loss -5.85917 acc 0.66225 roc_auc 0.40833 prc_auc 0.60611[0m
[93maverage test of epoch 36: loss -5.98260 acc 0.67568 roc_auc 0.86833 prc_auc 0.92834[0m
[92maverage training of epoch 37: loss -5.96855 acc 0.66225 roc_auc 0.40647 prc_auc 0.60521[0m
[93maverage test of epoch 37: loss -6.09221 acc 0.67568 roc_auc 0.86667 prc_auc 0.92487[0m
[92maverage training of epoch 38: loss -6.07732 acc 0.66225 roc_auc 0.40471 prc_auc 0.60404[0m
[93maverage test of epoch 38: loss -6.20121 acc 0.67568 roc_auc 0.86333 prc_auc 0.92317[0m
[92maverage training of epoch 39: loss -6.18550 acc 0.66225 roc_auc 0.40304 prc_auc 0.60317[0m
[93maverage test of epoch 39: loss -6.30964 acc 0.67568 roc_auc 0.87333 prc_auc 0.92316[0m
[92maverage training of epoch 40: loss -6.29314 acc 0.66225 roc_auc 0.40157 prc_auc 0.60250[0m
[93maverage test of epoch 40: loss -6.41753 acc 0.67568 roc_auc 0.86500 prc_auc 0.92113[0m
[92maverage training of epoch 41: loss -6.40026 acc 0.66225 roc_auc 0.40127 prc_auc 0.60212[0m
[93maverage test of epoch 41: loss -6.52491 acc 0.67568 roc_auc 0.86167 prc_auc 0.92814[0m
[92maverage training of epoch 42: loss -6.50690 acc 0.66225 roc_auc 0.40108 prc_auc 0.60207[0m
[93maverage test of epoch 42: loss -6.63181 acc 0.67568 roc_auc 0.86833 prc_auc 0.92874[0m
[92maverage training of epoch 43: loss -6.61308 acc 0.66225 roc_auc 0.40029 prc_auc 0.60084[0m
[93maverage test of epoch 43: loss -6.73826 acc 0.67568 roc_auc 0.87333 prc_auc 0.92319[0m
[92maverage training of epoch 44: loss -6.71883 acc 0.66225 roc_auc 0.39912 prc_auc 0.59999[0m
[93maverage test of epoch 44: loss -6.84428 acc 0.67568 roc_auc 0.85667 prc_auc 0.91459[0m
[92maverage training of epoch 45: loss -6.82418 acc 0.66225 roc_auc 0.39843 prc_auc 0.59967[0m
[93maverage test of epoch 45: loss -6.94992 acc 0.67568 roc_auc 0.88333 prc_auc 0.93208[0m
[92maverage training of epoch 46: loss -6.92916 acc 0.66225 roc_auc 0.39882 prc_auc 0.60038[0m
[93maverage test of epoch 46: loss -7.05518 acc 0.67568 roc_auc 0.88333 prc_auc 0.92072[0m
[92maverage training of epoch 47: loss -7.03378 acc 0.66225 roc_auc 0.39814 prc_auc 0.59995[0m
[93maverage test of epoch 47: loss -7.16010 acc 0.67568 roc_auc 0.87833 prc_auc 0.91988[0m
[92maverage training of epoch 48: loss -7.13808 acc 0.66225 roc_auc 0.39745 prc_auc 0.59920[0m
[93maverage test of epoch 48: loss -7.26470 acc 0.67568 roc_auc 0.85000 prc_auc 0.90123[0m
[92maverage training of epoch 49: loss -7.24207 acc 0.66225 roc_auc 0.39667 prc_auc 0.59833[0m
[93maverage test of epoch 49: loss -7.36900 acc 0.67568 roc_auc 0.86500 prc_auc 0.89299[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.62024 acc 0.33775 roc_auc 0.36686 prc_auc 0.57833[0m
[93maverage test of epoch 0: loss -0.73949 acc 0.32432 roc_auc 0.67000 prc_auc 0.87304[0m
[92maverage training of epoch 1: loss -0.84325 acc 0.33775 roc_auc 0.37980 prc_auc 0.58578[0m
[93maverage test of epoch 1: loss -0.96469 acc 0.32432 roc_auc 0.64333 prc_auc 0.86150[0m
[92maverage training of epoch 2: loss -1.07282 acc 0.47020 roc_auc 0.39667 prc_auc 0.59772[0m
[93maverage test of epoch 2: loss -1.19988 acc 0.67568 roc_auc 0.62000 prc_auc 0.84230[0m
[92maverage training of epoch 3: loss -1.31834 acc 0.65563 roc_auc 0.42078 prc_auc 0.63161[0m
[93maverage test of epoch 3: loss -1.45944 acc 0.67568 roc_auc 0.68667 prc_auc 0.87984[0m
[92maverage training of epoch 4: loss -1.60053 acc 0.66225 roc_auc 0.44882 prc_auc 0.65035[0m
[93maverage test of epoch 4: loss -1.77490 acc 0.67568 roc_auc 0.84667 prc_auc 0.93857[0m
[92maverage training of epoch 5: loss -1.95377 acc 0.66225 roc_auc 0.46961 prc_auc 0.66707[0m
[93maverage test of epoch 5: loss -2.17853 acc 0.67568 roc_auc 0.93333 prc_auc 0.97438[0m
[92maverage training of epoch 6: loss -2.37614 acc 0.66225 roc_auc 0.48294 prc_auc 0.67591[0m
[93maverage test of epoch 6: loss -2.61415 acc 0.67568 roc_auc 0.92333 prc_auc 0.96958[0m
[92maverage training of epoch 7: loss -2.77851 acc 0.66225 roc_auc 0.49137 prc_auc 0.68571[0mUsing backend: pytorch
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))

[93maverage test of epoch 7: loss -2.98158 acc 0.67568 roc_auc 0.92333 prc_auc 0.96958[0m
[92maverage training of epoch 8: loss -3.10174 acc 0.66225 roc_auc 0.49314 prc_auc 0.69203[0m
[93maverage test of epoch 8: loss -3.26955 acc 0.67568 roc_auc 0.94000 prc_auc 0.97574[0m
[92maverage training of epoch 9: loss -3.35793 acc 0.66225 roc_auc 0.49412 prc_auc 0.69334[0m
[93maverage test of epoch 9: loss -3.50306 acc 0.67568 roc_auc 0.94333 prc_auc 0.97669[0m
[92maverage training of epoch 10: loss -3.57078 acc 0.66225 roc_auc 0.49863 prc_auc 0.69712[0m
[93maverage test of epoch 10: loss -3.70220 acc 0.67568 roc_auc 0.94667 prc_auc 0.97770[0m
[92maverage training of epoch 11: loss -3.75621 acc 0.66225 roc_auc 0.50039 prc_auc 0.70238[0m
[93maverage test of epoch 11: loss -3.87917 acc 0.67568 roc_auc 0.94667 prc_auc 0.97770[0m
[92maverage training of epoch 12: loss -3.92370 acc 0.66225 roc_auc 0.49706 prc_auc 0.69849[0m
[93maverage test of epoch 12: loss -4.04143 acc 0.67568 roc_auc 0.94667 prc_auc 0.97770[0m
[92maverage training of epoch 13: loss -4.07936 acc 0.66225 roc_auc 0.49196 prc_auc 0.69171[0m
[93maverage test of epoch 13: loss -4.19421 acc 0.67568 roc_auc 0.94667 prc_auc 0.97770[0m
[92maverage training of epoch 14: loss -4.22805 acc 0.66225 roc_auc 0.48902 prc_auc 0.68902[0m
[93maverage test of epoch 14: loss -4.34248 acc 0.67568 roc_auc 0.94667 prc_auc 0.97787[0m
[92maverage training of epoch 15: loss -4.37533 acc 0.66225 roc_auc 0.48137 prc_auc 0.68458[0m
[93maverage test of epoch 15: loss -4.49294 acc 0.67568 roc_auc 0.95333 prc_auc 0.97995[0m
[92maverage training of epoch 16: loss -4.52884 acc 0.66225 roc_auc 0.48010 prc_auc 0.68442[0m
[93maverage test of epoch 16: loss -4.65403 acc 0.67568 roc_auc 0.95333 prc_auc 0.97995[0m
[92maverage training of epoch 17: loss -4.69422 acc 0.66225 roc_auc 0.49069 prc_auc 0.69373[0m
[93maverage test of epoch 17: loss -4.82634 acc 0.67568 roc_auc 0.95000 prc_auc 0.97888[0m
[92maverage training of epoch 18: loss -4.86377 acc 0.66225 roc_auc 0.51078 prc_auc 0.70963[0m
[93maverage test of epoch 18: loss -4.99487 acc 0.67568 roc_auc 0.93667 prc_auc 0.97464[0m
[92maverage training of epoch 19: loss -5.02443 acc 0.66225 roc_auc 0.51922 prc_auc 0.71616[0m
[93maverage test of epoch 19: loss -5.15135 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 20: loss -5.17416 acc 0.66225 roc_auc 0.51510 prc_auc 0.71305[0m
[93maverage test of epoch 20: loss -5.29800 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 21: loss -5.31583 acc 0.66225 roc_auc 0.50382 prc_auc 0.70106[0m
[93maverage test of epoch 21: loss -5.43773 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 22: loss -5.45167 acc 0.66225 roc_auc 0.49039 prc_auc 0.68951[0m
[93maverage test of epoch 22: loss -5.57229 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 23: loss -5.58304 acc 0.66225 roc_auc 0.47824 prc_auc 0.67792[0m
[93maverage test of epoch 23: loss -5.70278 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 24: loss -5.71079 acc 0.66225 roc_auc 0.46922 prc_auc 0.67088[0m
[93maverage test of epoch 24: loss -5.82992 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 25: loss -5.83551 acc 0.66225 roc_auc 0.46324 prc_auc 0.66561[0m
[93maverage test of epoch 25: loss -5.95421 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 26: loss -5.95764 acc 0.66225 roc_auc 0.45667 prc_auc 0.65927[0m
[93maverage test of epoch 26: loss -6.07606 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 27: loss -6.07753 acc 0.66225 roc_auc 0.44578 prc_auc 0.65031[0m
[93maverage test of epoch 27: loss -6.19578 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 28: loss -6.19547 acc 0.66225 roc_auc 0.43814 prc_auc 0.64462[0m
[93maverage test of epoch 28: loss -6.31363 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 29: loss -6.31168 acc 0.66225 roc_auc 0.43069 prc_auc 0.63950[0m
[93maverage test of epoch 29: loss -6.42983 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 30: loss -6.42636 acc 0.66225 roc_auc 0.42490 prc_auc 0.63582[0m
[93maverage test of epoch 30: loss -6.54456 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 31: loss -6.53969 acc 0.66225 roc_auc 0.42000 prc_auc 0.63271[0m
[93maverage test of epoch 31: loss -6.65798 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 32: loss -6.65179 acc 0.66225 roc_auc 0.41333 prc_auc 0.62699[0m
[93maverage test of epoch 32: loss -6.77023 acc 0.67568 roc_auc 0.93000 prc_auc 0.97264[0m
[92maverage training of epoch 33: loss -6.76281 acc 0.66225 roc_auc 0.41059 prc_auc 0.62618[0m
[93maverage test of epoch 33: loss -6.88142 acc 0.67568 roc_auc 0.93000 prc_auc 0.97294[0m
[92maverage training of epoch 34: loss -6.87285 acc 0.66225 roc_auc 0.40637 prc_auc 0.62408[0m
[93maverage test of epoch 34: loss -6.99166 acc 0.67568 roc_auc 0.92833 prc_auc 0.97135[0m
[92maverage training of epoch 35: loss -6.98200 acc 0.66225 roc_auc 0.40216 prc_auc 0.62036[0m
[93maverage test of epoch 35: loss -7.10105 acc 0.67568 roc_auc 0.92500 prc_auc 0.96853[0m
[92maverage training of epoch 36: loss -7.09035 acc 0.66225 roc_auc 0.39931 prc_auc 0.61873[0m
[93maverage test of epoch 36: loss -7.20966 acc 0.67568 roc_auc 0.92833 prc_auc 0.97135[0m
[92maverage training of epoch 37: loss -7.19798 acc 0.66225 roc_auc 0.39706 prc_auc 0.61737[0m
[93maverage test of epoch 37: loss -7.31757 acc 0.67568 roc_auc 0.92500 prc_auc 0.96853[0m
[92maverage training of epoch 38: loss -7.30496 acc 0.66225 roc_auc 0.39667 prc_auc 0.61679[0m
[93maverage test of epoch 38: loss -7.42484 acc 0.67568 roc_auc 0.92500 prc_auc 0.96853[0m
[92maverage training of epoch 39: loss -7.41134 acc 0.66225 roc_auc 0.39569 prc_auc 0.61684[0m
[93maverage test of epoch 39: loss -7.53153 acc 0.67568 roc_auc 0.92500 prc_auc 0.96853[0m
[92maverage training of epoch 40: loss -7.51718 acc 0.66225 roc_auc 0.39294 prc_auc 0.61252[0m
[93maverage test of epoch 40: loss -7.63769 acc 0.67568 roc_auc 0.92500 prc_auc 0.96822[0m
[92maverage training of epoch 41: loss -7.62252 acc 0.66225 roc_auc 0.39108 prc_auc 0.61008[0m
[93maverage test of epoch 41: loss -7.74337 acc 0.67568 roc_auc 0.93667 prc_auc 0.97294[0m
[92maverage training of epoch 42: loss -7.72742 acc 0.66225 roc_auc 0.38892 prc_auc 0.60667[0m
[93maverage test of epoch 42: loss -7.84861 acc 0.67568 roc_auc 0.92667 prc_auc 0.96853[0m
[92maverage training of epoch 43: loss -7.83190 acc 0.66225 roc_auc 0.38814 prc_auc 0.60411[0m
[93maverage test of epoch 43: loss -7.95345 acc 0.67568 roc_auc 0.93333 prc_auc 0.97135[0m
[92maverage training of epoch 44: loss -7.93601 acc 0.66225 roc_auc 0.38784 prc_auc 0.60378[0m
[93maverage test of epoch 44: loss -8.05792 acc 0.67568 roc_auc 0.93000 prc_auc 0.96958[0m
[92maverage training of epoch 45: loss -8.03978 acc 0.66225 roc_auc 0.38412 prc_auc 0.59480[0m
[93maverage test of epoch 45: loss -8.16205 acc 0.67568 roc_auc 0.93333 prc_auc 0.96875[0m
[92maverage training of epoch 46: loss -8.14323 acc 0.66225 roc_auc 0.38255 prc_auc 0.59277[0m
[93maverage test of epoch 46: loss -8.26588 acc 0.67568 roc_auc 0.93333 prc_auc 0.96875[0m
[92maverage training of epoch 47: loss -8.24640 acc 0.66225 roc_auc 0.38157 prc_auc 0.59120[0m
[93maverage test of epoch 47: loss -8.36943 acc 0.67568 roc_auc 0.92667 prc_auc 0.96512[0m
[92maverage training of epoch 48: loss -8.34930 acc 0.66225 roc_auc 0.38127 prc_auc 0.59139[0m
[93maverage test of epoch 48: loss -8.47271 acc 0.67568 roc_auc 0.94333 prc_auc 0.96875[0m
[92maverage training of epoch 49: loss -8.45196 acc 0.66225 roc_auc 0.38049 prc_auc 0.59115[0m
[93maverage test of epoch 49: loss -8.57576 acc 0.67568 roc_auc 0.92500 prc_auc 0.96330[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.0001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.69659 ROC_AUC (avg): 0.88323 PRC_AUC (avg): 0.93039 

Average forward propagation time taken(ms): 2.4810344659875057
Average backward propagation time taken(ms): 0.8747222952194361

