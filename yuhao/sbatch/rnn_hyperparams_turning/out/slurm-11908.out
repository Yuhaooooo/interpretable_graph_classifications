# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-21-49-31/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-21-49-31/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 16,
 'epochs': 50,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 4,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.003,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 2,
 'num_workers': 8,
 'number_of_mlp_layer': 0,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-17-21-49-31',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 50, 'learning_rate': 0.003, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.003
[92maverage training of epoch 0: loss -1.13455 acc 0.66667 roc_auc 0.37520 prc_auc 0.57753[0m
[93maverage test of epoch 0: loss -2.74505 acc 0.65789 roc_auc 0.62462 prc_auc 0.81835[0m
[92maverage training of epoch 1: loss -3.84968 acc 0.66667 roc_auc 0.38310 prc_auc 0.58574[0m
[93maverage test of epoch 1: loss -4.89377 acc 0.65789 roc_auc 0.57692 prc_auc 0.72470[0m
[92maverage training of epoch 2: loss -5.88824 acc 0.66667 roc_auc 0.36440 prc_auc 0.57130[0m
[93maverage test of epoch 2: loss -6.80975 acc 0.65789 roc_auc 0.30923 prc_auc 0.59815[0m
[92maverage training of epoch 3: loss -7.74588 acc 0.66667 roc_auc 0.36040 prc_auc 0.56533[0m
[93maverage test of epoch 3: loss -8.61225 acc 0.65789 roc_auc 0.61077 prc_auc 0.74007[0m
[92maverage training of epoch 4: loss -9.52469 acc 0.66667 roc_auc 0.35900 prc_auc 0.56529[0m
[93maverage test of epoch 4: loss -10.36468 acc 0.65789 roc_auc 0.35077 prc_auc 0.58151[0m
[92maverage training of epoch 5: loss -11.26690 acc 0.66667 roc_auc 0.35640 prc_auc 0.56451[0m
[93maverage test of epoch 5: loss -12.09103 acc 0.65789 roc_auc 0.43077 prc_auc 0.62876[0m
[92maverage training of epoch 6: loss -12.98717 acc 0.66667 roc_auc 0.35770 prc_auc 0.56280[0m
[93maverage test of epoch 6: loss -13.79772 acc 0.65789 roc_auc 0.56308 prc_auc 0.68233[0m
[92maverage training of epoch 7: loss -14.69412 acc 0.66667 roc_auc 0.35530 prc_auc 0.56092[0m
[93maverage test of epoch 7: loss -15.49510 acc 0.65789 roc_auc 0.39538 prc_auc 0.60307[0m
[92maverage training of epoch 8: loss -16.38997 acc 0.66667 roc_auc 0.35860 prc_auc 0.56408[0m
[93maverage test of epoch 8: loss -17.18050 acc 0.65789 roc_auc 0.56308 prc_auc 0.69566[0m
[92maverage training of epoch 9: loss -18.07805 acc 0.66667 roc_auc 0.36020 prc_auc 0.56474[0m
[93maverage test of epoch 9: loss -18.86155 acc 0.65789 roc_auc 0.57538 prc_auc 0.70367[0m
[92maverage training of epoch 10: loss -19.76125 acc 0.66667 roc_auc 0.35850 prc_auc 0.56303[0m
[93maverage test of epoch 10: loss -20.53601 acc 0.65789 roc_auc 0.54000 prc_auc 0.68084[0m
[92maverage training of epoch 11: loss -21.43845 acc 0.66667 roc_auc 0.35620 prc_auc 0.56167[0m
[93maverage test of epoch 11: loss -22.20833 acc 0.65789 roc_auc 0.57692 prc_auc 0.69496[0m
[92maverage training of epoch 12: loss -23.11317 acc 0.66667 roc_auc 0.35840 prc_auc 0.56410[0m
[93maverage test of epoch 12: loss -23.87533 acc 0.65789 roc_auc 0.48000 prc_auc 0.64902[0m
[92maverage training of epoch 13: loss -24.78447 acc 0.66667 roc_auc 0.35840 prc_auc 0.56688[0m
[93maverage test of epoch 13: loss -25.54107 acc 0.65789 roc_auc 0.42000 prc_auc 0.62298[0m
[92maverage training of epoch 14: loss -26.45343 acc 0.66667 roc_auc 0.35790 prc_auc 0.56790[0m
[93maverage test of epoch 14: loss -27.20393 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 15: loss -28.12082 acc 0.66667 roc_auc 0.35900 prc_auc 0.57481[0m
[93maverage test of epoch 15: loss -28.86590 acc 0.65789 roc_auc 0.48000 prc_auc 0.64902[0m
[92maverage training of epoch 16: loss -29.78635 acc 0.66667 roc_auc 0.36290 prc_auc 0.57566[0m
[93maverage test of epoch 16: loss -30.52504 acc 0.65789 roc_auc 0.59231 prc_auc 0.70301[0m
[92maverage training of epoch 17: loss -31.45050 acc 0.66667 roc_auc 0.36670 prc_auc 0.58611[0m
[93maverage test of epoch 17: loss -32.18419 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 18: loss -33.11358 acc 0.66667 roc_auc 0.37170 prc_auc 0.59700[0m
[93maverage test of epoch 18: loss -33.84208 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -34.77503 acc 0.66667 roc_auc 0.37960 prc_auc 0.60686[0m
[93maverage test of epoch 19: loss -35.49900 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -36.43711 acc 0.66667 roc_auc 0.34650 prc_auc 0.60189[0m
[93maverage test of epoch 20: loss -37.15519 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -38.09734 acc 0.66667 roc_auc 0.44000 prc_auc 0.64144[0m
[93maverage test of epoch 21: loss -38.81080 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -39.75711 acc 0.66667 roc_auc 0.37360 prc_auc 0.63116[0m
[93maverage test of epoch 22: loss -40.46555 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -41.41683 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 23: loss -42.11992 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -43.07576 acc 0.66667 roc_auc 0.41500 prc_auc 0.65359[0m
[93maverage test of epoch 24: loss -43.77424 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -44.73430 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 25: loss -45.42771 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -46.39266 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 26: loss -47.08132 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -48.05084 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 27: loss -48.73443 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -49.70862 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 28: loss -50.38738 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -51.36619 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 29: loss -52.04006 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -53.02338 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 30: loss -53.69289 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -54.68065 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 31: loss -55.34515 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -56.33794 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 32: loss -56.99742 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -57.99488 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 33: loss -58.64944 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -59.65168 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -60.30182 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -61.30834 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -61.95359 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -62.96511 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -63.60532 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -64.62175 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -65.25744 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -66.27829 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -66.90888 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -67.93477 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -68.56072 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -69.59109 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -70.21244 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -71.24739 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -71.86363 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -72.90369 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -73.51544 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -74.55986 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -75.16710 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -76.21605 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -76.81837 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -77.87218 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -78.46974 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -79.52828 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -80.12096 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -81.18423 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -81.77244 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -82.84034 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -83.42371 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -84.49626 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -85.07508 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.003
[92maverage training of epoch 0: loss -1.26394 acc 0.52667 roc_auc 0.46420 prc_auc 0.65147[0m
[93maverage test of epoch 0: loss -3.16871 acc 0.65789 roc_auc 0.41846 prc_auc 0.61207[0m
[92maverage training of epoch 1: loss -4.16711 acc 0.66667 roc_auc 0.45140 prc_auc 0.62984[0m
[93maverage test of epoch 1: loss -5.32795 acc 0.65789 roc_auc 0.67385 prc_auc 0.85026[0m
[92maverage training of epoch 2: loss -6.50265 acc 0.66667 roc_auc 0.41760 prc_auc 0.59471[0m
[93maverage test of epoch 2: loss -7.53787 acc 0.65789 roc_auc 0.36000 prc_auc 0.61895[0m
[92maverage training of epoch 3: loss -8.51165 acc 0.66667 roc_auc 0.42100 prc_auc 0.60762[0m
[93maverage test of epoch 3: loss -9.41485 acc 0.65789 roc_auc 0.37077 prc_auc 0.61475[0m
[92maverage training of epoch 4: loss -10.35300 acc 0.66667 roc_auc 0.42280 prc_auc 0.60199[0m
[93maverage test of epoch 4: loss -11.21775 acc 0.65789 roc_auc 0.62923 prc_auc 0.68910[0m
[92maverage training of epoch 5: loss -12.13105 acc 0.66667 roc_auc 0.42220 prc_auc 0.60452[0m
[93maverage test of epoch 5: loss -12.96571 acc 0.65789 roc_auc 0.37692 prc_auc 0.60818[0m
[92maverage training of epoch 6: loss -13.87861 acc 0.66667 roc_auc 0.42220 prc_auc 0.60357[0m
[93maverage test of epoch 6: loss -14.69834 acc 0.65789 roc_auc 0.47538 prc_auc 0.65586[0m
[92maverage training of epoch 7: loss -15.60175 acc 0.66667 roc_auc 0.42230 prc_auc 0.60429[0m
[93maverage test of epoch 7: loss -16.40815 acc 0.65789 roc_auc 0.49692 prc_auc 0.64977[0m
[92maverage training of epoch 8: loss -17.31087 acc 0.66667 roc_auc 0.42000 prc_auc 0.60470[0m
[93maverage test of epoch 8: loss -18.11001 acc 0.65789 roc_auc 0.43692 prc_auc 0.61635[0m
[92maverage training of epoch 9: loss -19.01073 acc 0.66667 roc_auc 0.41830 prc_auc 0.59702[0m
[93maverage test of epoch 9: loss -19.79958 acc 0.65789 roc_auc 0.48769 prc_auc 0.64095[0m
[92maverage training of epoch 10: loss -20.70315 acc 0.66667 roc_auc 0.42130 prc_auc 0.60722[0m
[93maverage test of epoch 10: loss -21.48215 acc 0.65789 roc_auc 0.44615 prc_auc 0.64690[0m
[92maverage training of epoch 11: loss -22.38822 acc 0.66667 roc_auc 0.42210 prc_auc 0.60403[0m
[93maverage test of epoch 11: loss -23.16035 acc 0.65789 roc_auc 0.44308 prc_auc 0.62715[0m
[92maverage training of epoch 12: loss -24.06805 acc 0.66667 roc_auc 0.41850 prc_auc 0.60168[0m
[93maverage test of epoch 12: loss -24.83340 acc 0.65789 roc_auc 0.34000 prc_auc 0.58816[0m
[92maverage training of epoch 13: loss -25.74480 acc 0.66667 roc_auc 0.42170 prc_auc 0.60350[0m
[93maverage test of epoch 13: loss -26.50325 acc 0.65789 roc_auc 0.49385 prc_auc 0.65540[0m
[92maverage training of epoch 14: loss -27.41780 acc 0.66667 roc_auc 0.42030 prc_auc 0.60127[0m
[93maverage test of epoch 14: loss -28.17070 acc 0.65789 roc_auc 0.49846 prc_auc 0.65720[0m
[92maverage training of epoch 15: loss -29.08829 acc 0.66667 roc_auc 0.42020 prc_auc 0.60288[0m
[93maverage test of epoch 15: loss -29.83557 acc 0.65789 roc_auc 0.45692 prc_auc 0.63923[0m
[92maverage training of epoch 16: loss -30.75751 acc 0.66667 roc_auc 0.42050 prc_auc 0.60610[0m
[93maverage test of epoch 16: loss -31.49824 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 17: loss -32.42371 acc 0.66667 roc_auc 0.42230 prc_auc 0.60593[0m
[93maverage test of epoch 17: loss -33.15757 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 18: loss -34.08904 acc 0.66667 roc_auc 0.43470 prc_auc 0.61673[0m
[93maverage test of epoch 18: loss -34.81960 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -35.75300 acc 0.66667 roc_auc 0.44130 prc_auc 0.62727[0m
[93maverage test of epoch 19: loss -36.47707 acc 0.65789 roc_auc 0.53846 prc_auc 0.67568[0m
[92maverage training of epoch 20: loss -37.41616 acc 0.66667 roc_auc 0.44800 prc_auc 0.63589[0m
[93maverage test of epoch 20: loss -38.13523 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -39.07759 acc 0.66667 roc_auc 0.46000 prc_auc 0.64403[0m
[93maverage test of epoch 21: loss -39.79210 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -40.73903 acc 0.66667 roc_auc 0.44280 prc_auc 0.63853[0m
[93maverage test of epoch 22: loss -41.44828 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -42.39959 acc 0.66667 roc_auc 0.45500 prc_auc 0.64810[0m
[93maverage test of epoch 23: loss -43.10370 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -44.05921 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 24: loss -44.75895 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -45.71885 acc 0.66667 roc_auc 0.44000 prc_auc 0.64267[0m
[93maverage test of epoch 25: loss -46.41312 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -47.37781 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 26: loss -48.06731 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -49.03645 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 27: loss -49.72030 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -50.69471 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 28: loss -51.37440 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -52.35278 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 29: loss -53.02768 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -54.01080 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 30: loss -54.68084 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -55.66830 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 31: loss -56.33339 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -57.32572 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 32: loss -57.98598 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -58.98305 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 33: loss -59.63852 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -60.64023 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -61.29087 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -62.29723 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -62.94319 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -63.95414 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -64.59533 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -65.61089 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -66.24733 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -67.26760 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -67.89929 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -68.92434 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -69.55113 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -70.58092 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -71.20283 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -72.23735 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -72.85459 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -73.89386 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -74.50645 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -75.55014 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -76.15795 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -77.20646 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -77.80933 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -78.86273 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -79.46099 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -80.51905 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -81.11257 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -82.17522 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -82.76415 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -83.83145 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -84.41552 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -85.48753 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -86.06686 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.003
[92maverage training of epoch 0: loss -2.65385 acc 0.66667 roc_auc 0.43210 prc_auc 0.63489[0m
[93maverage test of epoch 0: loss -4.59222 acc 0.65789 roc_auc 0.60000 prc_auc 0.75312[0m
[92maverage training of epoch 1: loss -5.66579 acc 0.66667 roc_auc 0.42270 prc_auc 0.63168[0m
[93maverage test of epoch 1: loss -6.62830 acc 0.65789 roc_auc 0.56462 prc_auc 0.72968[0m
[92maverage training of epoch 2: loss -7.56838 acc 0.66667 roc_auc 0.37780 prc_auc 0.57314[0m
[93maverage test of epoch 2: loss -8.43518 acc 0.65789 roc_auc 0.31846 prc_auc 0.56440[0m
[92maverage training of epoch 3: loss -9.34880 acc 0.66667 roc_auc 0.38300 prc_auc 0.58397[0m
[93maverage test of epoch 3: loss -10.18701 acc 0.65789 roc_auc 0.41077 prc_auc 0.60805[0m
[92maverage training of epoch 4: loss -11.08883 acc 0.66667 roc_auc 0.38260 prc_auc 0.58031[0m
[93maverage test of epoch 4: loss -11.90216 acc 0.65789 roc_auc 0.55385 prc_auc 0.69899[0m
[92maverage training of epoch 5: loss -12.79924 acc 0.66667 roc_auc 0.38520 prc_auc 0.58496[0m
[93maverage test of epoch 5: loss -13.60518 acc 0.65789 roc_auc 0.66769 prc_auc 0.75129[0m
[92maverage training of epoch 6: loss -14.49938 acc 0.66667 roc_auc 0.37460 prc_auc 0.57992[0m
[93maverage test of epoch 6: loss -15.29224 acc 0.65789 roc_auc 0.54308 prc_auc 0.70857[0m
[92maverage training of epoch 7: loss -16.19075 acc 0.66667 roc_auc 0.37760 prc_auc 0.57535[0m
[93maverage test of epoch 7: loss -16.97547 acc 0.65789 roc_auc 0.50000 prc_auc 0.69371[0m
[92maverage training of epoch 8: loss -17.87546 acc 0.66667 roc_auc 0.38060 prc_auc 0.58315[0m
[93maverage test of epoch 8: loss -18.65172 acc 0.65789 roc_auc 0.44923 prc_auc 0.62580[0m
[92maverage training of epoch 9: loss -19.55254 acc 0.66667 roc_auc 0.37900 prc_auc 0.57815[0m
[93maverage test of epoch 9: loss -20.32321 acc 0.65789 roc_auc 0.41846 prc_auc 0.61952[0m
[92maverage training of epoch 10: loss -21.22810 acc 0.66667 roc_auc 0.37610 prc_auc 0.57302[0m
[93maverage test of epoch 10: loss -21.99071 acc 0.65789 roc_auc 0.49692 prc_auc 0.66079[0m
[92maverage training of epoch 11: loss -22.89733 acc 0.66667 roc_auc 0.37830 prc_auc 0.57561[0m
[93maverage test of epoch 11: loss -23.65581 acc 0.65789 roc_auc 0.57538 prc_auc 0.69518[0m
[92maverage training of epoch 12: loss -24.56769 acc 0.66667 roc_auc 0.37890 prc_auc 0.57947[0m
[93maverage test of epoch 12: loss -25.32100 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 13: loss -26.23528 acc 0.66667 roc_auc 0.37770 prc_auc 0.58038[0m
[93maverage test of epoch 13: loss -26.98151 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 14: loss -27.90022 acc 0.66667 roc_auc 0.37970 prc_auc 0.58314[0m
[93maverage test of epoch 14: loss -28.64116 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 15: loss -29.56423 acc 0.66667 roc_auc 0.37800 prc_auc 0.58621[0m
[93maverage test of epoch 15: loss -30.29906 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 16: loss -31.22642 acc 0.66667 roc_auc 0.38370 prc_auc 0.59405[0m
[93maverage test of epoch 16: loss -31.95690 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 17: loss -32.88896 acc 0.66667 roc_auc 0.38860 prc_auc 0.60382[0m
[93maverage test of epoch 17: loss -33.61408 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 18: loss -34.54940 acc 0.66667 roc_auc 0.40570 prc_auc 0.61538[0m
[93maverage test of epoch 18: loss -35.27040 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -36.21018 acc 0.66667 roc_auc 0.39160 prc_auc 0.61469[0m
[93maverage test of epoch 19: loss -36.92492 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -37.87029 acc 0.66667 roc_auc 0.43500 prc_auc 0.63969[0m
[93maverage test of epoch 20: loss -38.58003 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -39.52929 acc 0.66667 roc_auc 0.44500 prc_auc 0.64357[0m
[93maverage test of epoch 21: loss -40.23411 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -41.18861 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 22: loss -41.88834 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -42.84697 acc 0.66667 roc_auc 0.44000 prc_auc 0.64162[0m
[93maverage test of epoch 23: loss -43.54185 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -44.50512 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 24: loss -45.19575 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -46.16308 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 25: loss -46.84865 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -47.82074 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 26: loss -48.50127 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -49.47840 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 27: loss -50.15332 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -51.13548 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 28: loss -51.80670 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -52.79298 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 29: loss -53.45871 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -54.44987 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 30: loss -55.11153 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -56.10692 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 31: loss -56.76352 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -57.76400 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 32: loss -58.41464 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -59.42064 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 33: loss -60.06755 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -61.07716 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -61.71935 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -62.73372 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -63.37124 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -64.39019 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -65.02247 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -66.04655 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -66.67458 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -67.70315 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -68.32614 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -69.35932 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -69.97760 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -71.01553 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -71.62923 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -72.67173 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -73.28072 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -74.32800 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -74.93207 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -75.98424 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -76.58361 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -77.64035 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -78.23500 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -79.29648 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -79.88629 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -80.95242 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -81.53751 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -82.60844 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -83.18876 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -84.26440 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -84.84008 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -85.92029 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -86.49121 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.003
[92maverage training of epoch 0: loss -1.78193 acc 0.55629 roc_auc 0.54608 prc_auc 0.70235[0m
[93maverage test of epoch 0: loss -2.95578 acc 0.67568 roc_auc 0.79000 prc_auc 0.85220[0m
[92maverage training of epoch 1: loss -4.06481 acc 0.70861 roc_auc 0.76824 prc_auc 0.81400[0m
[93maverage test of epoch 1: loss -4.80700 acc 0.67568 roc_auc 0.87333 prc_auc 0.94467[0m
[92maverage training of epoch 2: loss -5.82246 acc 0.81457 roc_auc 0.80216 prc_auc 0.83733[0m
[93maverage test of epoch 2: loss -6.57772 acc 0.75676 roc_auc 0.83667 prc_auc 0.88351[0m
[92maverage training of epoch 3: loss -7.37473 acc 0.81457 roc_auc 0.76765 prc_auc 0.80450[0m
[93maverage test of epoch 3: loss -7.96377 acc 0.67568 roc_auc 0.83167 prc_auc 0.90053[0m
[92maverage training of epoch 4: loss -8.94445 acc 0.82119 roc_auc 0.81020 prc_auc 0.81173[0m
[93maverage test of epoch 4: loss -9.42781 acc 0.67568 roc_auc 0.79667 prc_auc 0.86304[0m
[92maverage training of epoch 5: loss -10.27875 acc 0.79470 roc_auc 0.81255 prc_auc 0.83570[0m
[93maverage test of epoch 5: loss -11.00129 acc 0.67568 roc_auc 0.84000 prc_auc 0.89047[0m
[92maverage training of epoch 6: loss -11.93196 acc 0.76159 roc_auc 0.84569 prc_auc 0.85852[0m
[93maverage test of epoch 6: loss -12.61914 acc 0.67568 roc_auc 0.83833 prc_auc 0.88802[0m
[92maverage training of epoch 7: loss -13.54737 acc 0.70199 roc_auc 0.78784 prc_auc 0.80189[0m
[93maverage test of epoch 7: loss -14.21163 acc 0.67568 roc_auc 0.74333 prc_auc 0.83389[0m
[92maverage training of epoch 8: loss -15.15519 acc 0.66225 roc_auc 0.78392 prc_auc 0.79857[0m
[93maverage test of epoch 8: loss -15.76315 acc 0.67568 roc_auc 0.87833 prc_auc 0.91491[0m
[92maverage training of epoch 9: loss -16.75989 acc 0.66225 roc_auc 0.79441 prc_auc 0.81942[0m
[93maverage test of epoch 9: loss -17.83284 acc 0.67568 roc_auc 0.88000 prc_auc 0.92335[0m
[92maverage training of epoch 10: loss -18.36641 acc 0.66225 roc_auc 0.80275 prc_auc 0.81796[0m
[93maverage test of epoch 10: loss -18.67325 acc 0.67568 roc_auc 0.64333 prc_auc 0.74778[0m
[92maverage training of epoch 11: loss -19.84842 acc 0.66225 roc_auc 0.82088 prc_auc 0.84829[0m
[93maverage test of epoch 11: loss -20.68514 acc 0.67568 roc_auc 0.82500 prc_auc 0.87287[0m
[92maverage training of epoch 12: loss -21.24651 acc 0.66225 roc_auc 0.80647 prc_auc 0.84147[0m
[93maverage test of epoch 12: loss -21.80585 acc 0.67568 roc_auc 0.62833 prc_auc 0.73945[0m
[92maverage training of epoch 13: loss -22.95556 acc 0.66225 roc_auc 0.85637 prc_auc 0.88851[0m
[93maverage test of epoch 13: loss -23.51992 acc 0.67568 roc_auc 0.70667 prc_auc 0.78765[0m
[92maverage training of epoch 14: loss -24.60605 acc 0.66225 roc_auc 0.83510 prc_auc 0.87099[0m
[93maverage test of epoch 14: loss -25.19738 acc 0.67568 roc_auc 0.82500 prc_auc 0.87242[0m
[92maverage training of epoch 15: loss -26.13365 acc 0.66225 roc_auc 0.86029 prc_auc 0.89385[0m
[93maverage test of epoch 15: loss -26.76283 acc 0.67568 roc_auc 0.83500 prc_auc 0.87512[0m
[92maverage training of epoch 16: loss -27.44129 acc 0.66225 roc_auc 0.84235 prc_auc 0.88052[0m
[93maverage test of epoch 16: loss -28.20603 acc 0.67568 roc_auc 0.74833 prc_auc 0.81446[0m
[92maverage training of epoch 17: loss -29.18708 acc 0.66225 roc_auc 0.84333 prc_auc 0.88437[0m
[93maverage test of epoch 17: loss -29.95566 acc 0.67568 roc_auc 0.78667 prc_auc 0.83907[0m
[92maverage training of epoch 18: loss -30.66407 acc 0.66225 roc_auc 0.85912 prc_auc 0.88907[0m
[93maverage test of epoch 18: loss -30.95678 acc 0.67568 roc_auc 0.63667 prc_auc 0.74199[0m
[92maverage training of epoch 19: loss -32.21626 acc 0.66225 roc_auc 0.85020 prc_auc 0.88585[0m
[93maverage test of epoch 19: loss -32.77133 acc 0.67568 roc_auc 0.73833 prc_auc 0.81183[0m
[92maverage training of epoch 20: loss -33.86235 acc 0.66225 roc_auc 0.83392 prc_auc 0.87254[0m
[93maverage test of epoch 20: loss -34.33102 acc 0.67568 roc_auc 0.74167 prc_auc 0.81274[0m
[92maverage training of epoch 21: loss -35.39853 acc 0.66225 roc_auc 0.84069 prc_auc 0.87913[0m
[93maverage test of epoch 21: loss -35.75496 acc 0.67568 roc_auc 0.71667 prc_auc 0.78996[0m
[92maverage training of epoch 22: loss -36.76177 acc 0.66225 roc_auc 0.82902 prc_auc 0.86896[0m
[93maverage test of epoch 22: loss -37.33849 acc 0.67568 roc_auc 0.79667 prc_auc 0.84194[0m
[92maverage training of epoch 23: loss -38.42209 acc 0.66225 roc_auc 0.86020 prc_auc 0.88974[0m
[93maverage test of epoch 23: loss -38.67585 acc 0.67568 roc_auc 0.71333 prc_auc 0.78919[0m
[92maverage training of epoch 24: loss -40.14898 acc 0.66225 roc_auc 0.85902 prc_auc 0.89135[0m
[93maverage test of epoch 24: loss -40.25900 acc 0.67568 roc_auc 0.71667 prc_auc 0.78996[0m
[92maverage training of epoch 25: loss -41.48301 acc 0.66225 roc_auc 0.83922 prc_auc 0.87825[0m
[93maverage test of epoch 25: loss -41.75879 acc 0.67568 roc_auc 0.70333 prc_auc 0.78652[0m
[92maverage training of epoch 26: loss -42.98989 acc 0.66225 roc_auc 0.83765 prc_auc 0.87305[0m
[93maverage test of epoch 26: loss -43.32094 acc 0.67568 roc_auc 0.71667 prc_auc 0.78996[0m
[92maverage training of epoch 27: loss -44.59612 acc 0.66225 roc_auc 0.83176 prc_auc 0.87196[0m
[93maverage test of epoch 27: loss -44.55589 acc 0.67568 roc_auc 0.76167 prc_auc 0.81793[0m
[92maverage training of epoch 28: loss -46.30642 acc 0.66225 roc_auc 0.84637 prc_auc 0.88210[0m
[93maverage test of epoch 28: loss -46.38402 acc 0.67568 roc_auc 0.74167 prc_auc 0.81274[0m
[92maverage training of epoch 29: loss -47.86951 acc 0.66225 roc_auc 0.84461 prc_auc 0.88166[0m
[93maverage test of epoch 29: loss -47.37801 acc 0.67568 roc_auc 0.76333 prc_auc 0.82953[0m
[92maverage training of epoch 30: loss -49.08651 acc 0.66225 roc_auc 0.84814 prc_auc 0.88149[0m
[93maverage test of epoch 30: loss -49.09039 acc 0.67568 roc_auc 0.71667 prc_auc 0.79003[0m
[92maverage training of epoch 31: loss -50.93429 acc 0.66225 roc_auc 0.86098 prc_auc 0.89176[0m
[93maverage test of epoch 31: loss -50.51117 acc 0.67568 roc_auc 0.78333 prc_auc 0.83785[0m
[92maverage training of epoch 32: loss -52.46629 acc 0.66225 roc_auc 0.85186 prc_auc 0.88387[0m
[93maverage test of epoch 32: loss -52.70884 acc 0.67568 roc_auc 0.80000 prc_auc 0.84601[0m
[92maverage training of epoch 33: loss -53.93206 acc 0.66225 roc_auc 0.85588 prc_auc 0.88962[0m
[93maverage test of epoch 33: loss -53.79581 acc 0.67568 roc_auc 0.71000 prc_auc 0.78816[0m
[92maverage training of epoch 34: loss -55.37353 acc 0.66225 roc_auc 0.85471 prc_auc 0.88868[0m
[93maverage test of epoch 34: loss -55.44328 acc 0.67568 roc_auc 0.73000 prc_auc 0.80591[0m
[92maverage training of epoch 35: loss -56.69054 acc 0.66225 roc_auc 0.83912 prc_auc 0.88768[0m
[93maverage test of epoch 35: loss -56.51702 acc 0.67568 roc_auc 0.73667 prc_auc 0.80733[0m
[92maverage training of epoch 36: loss -58.29373 acc 0.66225 roc_auc 0.86157 prc_auc 0.90066[0m
[93maverage test of epoch 36: loss -57.92939 acc 0.67568 roc_auc 0.76333 prc_auc 0.82917[0m
[92maverage training of epoch 37: loss -60.21489 acc 0.66225 roc_auc 0.86353 prc_auc 0.89759[0m
[93maverage test of epoch 37: loss -59.15132 acc 0.67568 roc_auc 0.72500 prc_auc 0.80012[0m
[92maverage training of epoch 38: loss -61.64228 acc 0.66225 roc_auc 0.86902 prc_auc 0.89945[0m
[93maverage test of epoch 38: loss -60.57412 acc 0.67568 roc_auc 0.65333 prc_auc 0.75528[0m
[92maverage training of epoch 39: loss -63.15326 acc 0.66225 roc_auc 0.85520 prc_auc 0.89418[0m
[93maverage test of epoch 39: loss -62.20179 acc 0.67568 roc_auc 0.69333 prc_auc 0.78018[0m
[92maverage training of epoch 40: loss -64.77593 acc 0.66225 roc_auc 0.85725 prc_auc 0.89534[0m
[93maverage test of epoch 40: loss -64.17007 acc 0.67568 roc_auc 0.73667 prc_auc 0.80733[0m
[92maverage training of epoch 41: loss -66.31760 acc 0.68874 roc_auc 0.86392 prc_auc 0.89758[0m
[93maverage test of epoch 41: loss -65.11819 acc 0.72973 roc_auc 0.69000 prc_auc 0.77896[0m
[92maverage training of epoch 42: loss -67.86536 acc 0.74834 roc_auc 0.86549 prc_auc 0.89814[0m
[93maverage test of epoch 42: loss -66.26694 acc 0.75676 roc_auc 0.61333 prc_auc 0.73204[0m
[92maverage training of epoch 43: loss -69.18657 acc 0.79470 roc_auc 0.86353 prc_auc 0.90191[0m
[93maverage test of epoch 43: loss -68.32636 acc 0.72973 roc_auc 0.73667 prc_auc 0.80733[0m
[92maverage training of epoch 44: loss -71.14881 acc 0.86755 roc_auc 0.87588 prc_auc 0.91253[0m
[93maverage test of epoch 44: loss -69.83406 acc 0.75676 roc_auc 0.75333 prc_auc 0.82553[0m
[92maverage training of epoch 45: loss -72.45776 acc 0.87417 roc_auc 0.86392 prc_auc 0.89774[0m
[93maverage test of epoch 45: loss -71.73602 acc 0.78378 roc_auc 0.79333 prc_auc 0.84072[0m
[92maverage training of epoch 46: loss -73.85638 acc 0.86755 roc_auc 0.85157 prc_auc 0.88780[0m
[93maverage test of epoch 46: loss -72.69777 acc 0.78378 roc_auc 0.73333 prc_auc 0.80642[0m
[92maverage training of epoch 47: loss -75.50608 acc 0.88079 roc_auc 0.85353 prc_auc 0.88915[0m
[93maverage test of epoch 47: loss -73.71126 acc 0.78378 roc_auc 0.76333 prc_auc 0.82441[0m
[92maverage training of epoch 48: loss -77.27983 acc 0.89404 roc_auc 0.87216 prc_auc 0.90562[0m
[93maverage test of epoch 48: loss -75.81117 acc 0.75676 roc_auc 0.68667 prc_auc 0.77871[0m
[92maverage training of epoch 49: loss -78.71347 acc 0.88079 roc_auc 0.85941 prc_auc 0.89620[0m
[93maverage test of epoch 49: loss -77.26762 acc 0.81081 roc_auc 0.75000 prc_auc 0.82563[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.003
[92maverage training of epoch 0: loss -1.75346 acc 0.54967 roc_auc 0.37686 prc_auc 0.60243[0m
[93maverage test of epoch 0: loss -2.87399 acc 0.67568 roc_auc 0.54667 prc_auc 0.73808[0m
[92maverage training of epoch 1: loss -3.89959 acc 0.66225 roc_auc 0.37059 prc_auc 0.57461[0m
[93maverage test of epoch 1: loss -4.95315 acc 0.67568 roc_auc 0.73000 prc_auc 0.86239[0m
[92maverage training of epoch 2: loss -5.85598 acc 0.66225 roc_auc 0.36902 prc_auc 0.56774[0m
[93maverage test of epoch 2: loss -6.81748 acc 0.67568 roc_auc 0.56500 prc_auc 0.71825[0m
[92maverage training of epoch 3: loss -7.67006 acc 0.66225 roc_auc 0.36980 prc_auc 0.57228[0m
[93maverage test of epoch 3: loss -8.60956 acc 0.67568 roc_auc 0.53833 prc_auc 0.75561[0m
[92maverage training of epoch 4: loss -9.43195 acc 0.66225 roc_auc 0.36706 prc_auc 0.56924[0m
[93maverage test of epoch 4: loss -10.35826 acc 0.67568 roc_auc 0.65333 prc_auc 0.81380[0mUsing backend: pytorch

[92maverage training of epoch 5: loss -11.16591 acc 0.66225 roc_auc 0.36902 prc_auc 0.56946[0m
[93maverage test of epoch 5: loss -12.08937 acc 0.67568 roc_auc 0.62000 prc_auc 0.78338[0m
[92maverage training of epoch 6: loss -12.88328 acc 0.66225 roc_auc 0.36922 prc_auc 0.56855[0m
[93maverage test of epoch 6: loss -13.80491 acc 0.67568 roc_auc 0.52500 prc_auc 0.68602[0m
[92maverage training of epoch 7: loss -14.58716 acc 0.66225 roc_auc 0.36843 prc_auc 0.56760[0m
[93maverage test of epoch 7: loss -15.50931 acc 0.67568 roc_auc 0.52167 prc_auc 0.70472[0m
[92maverage training of epoch 8: loss -16.28341 acc 0.66225 roc_auc 0.36863 prc_auc 0.56811[0m
[93maverage test of epoch 8: loss -17.21191 acc 0.67568 roc_auc 0.44000 prc_auc 0.65596[0m
[92maverage training of epoch 9: loss -17.97328 acc 0.66225 roc_auc 0.36922 prc_auc 0.56830[0m
[93maverage test of epoch 9: loss -18.90588 acc 0.67568 roc_auc 0.45000 prc_auc 0.64850[0m
[92maverage training of epoch 10: loss -19.65829 acc 0.66225 roc_auc 0.37059 prc_auc 0.56909[0m
[93maverage test of epoch 10: loss -20.59784 acc 0.67568 roc_auc 0.49833 prc_auc 0.67366[0m
[92maverage training of epoch 11: loss -21.33954 acc 0.66225 roc_auc 0.37118 prc_auc 0.56988[0m
[93maverage test of epoch 11: loss -22.28408 acc 0.67568 roc_auc 0.40000 prc_auc 0.63600[0m
[92maverage training of epoch 12: loss -23.01851 acc 0.66225 roc_auc 0.37098 prc_auc 0.56932[0m
[93maverage test of epoch 12: loss -23.96889 acc 0.67568 roc_auc 0.55000 prc_auc 0.69767[0m
[92maverage training of epoch 13: loss -24.69476 acc 0.66225 roc_auc 0.36971 prc_auc 0.56885[0m
[93maverage test of epoch 13: loss -25.65202 acc 0.67568 roc_auc 0.56500 prc_auc 0.71091[0m
[92maverage training of epoch 14: loss -26.36922 acc 0.66225 roc_auc 0.37029 prc_auc 0.56846[0m
[93maverage test of epoch 14: loss -27.33263 acc 0.67568 roc_auc 0.64000 prc_auc 0.74985[0m
[92maverage training of epoch 15: loss -28.04226 acc 0.66225 roc_auc 0.36863 prc_auc 0.56837[0m
[93maverage test of epoch 15: loss -29.01152 acc 0.67568 roc_auc 0.62333 prc_auc 0.73704[0m
[92maverage training of epoch 16: loss -29.71358 acc 0.66225 roc_auc 0.36980 prc_auc 0.56887[0m
[93maverage test of epoch 16: loss -30.68942 acc 0.67568 roc_auc 0.50167 prc_auc 0.67641[0m
[92maverage training of epoch 17: loss -31.38378 acc 0.66225 roc_auc 0.36971 prc_auc 0.57069[0m
[93maverage test of epoch 17: loss -32.36539 acc 0.67568 roc_auc 0.55167 prc_auc 0.69911[0m
[92maverage training of epoch 18: loss -33.05309 acc 0.66225 roc_auc 0.37059 prc_auc 0.57098[0m
[93maverage test of epoch 18: loss -34.04159 acc 0.67568 roc_auc 0.52167 prc_auc 0.68531[0m
[92maverage training of epoch 19: loss -34.72153 acc 0.66225 roc_auc 0.36980 prc_auc 0.57087[0m
[93maverage test of epoch 19: loss -35.71729 acc 0.67568 roc_auc 0.36667 prc_auc 0.62763[0m
[92maverage training of epoch 20: loss -36.38998 acc 0.66225 roc_auc 0.36441 prc_auc 0.56740[0m
[93maverage test of epoch 20: loss -37.39143 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 21: loss -38.05746 acc 0.66225 roc_auc 0.37069 prc_auc 0.57246[0m
[93maverage test of epoch 21: loss -39.06514 acc 0.67568 roc_auc 0.48000 prc_auc 0.66703[0m
[92maverage training of epoch 22: loss -39.72392 acc 0.66225 roc_auc 0.37216 prc_auc 0.57589[0m
[93maverage test of epoch 22: loss -40.74037 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 23: loss -41.39060 acc 0.66225 roc_auc 0.36490 prc_auc 0.57598[0m
[93maverage test of epoch 23: loss -42.41359 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 24: loss -43.05620 acc 0.66225 roc_auc 0.36873 prc_auc 0.58666[0m
[93maverage test of epoch 24: loss -44.08641 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 25: loss -44.72245 acc 0.66225 roc_auc 0.37520 prc_auc 0.59508[0m
[93maverage test of epoch 25: loss -45.75890 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 26: loss -46.38771 acc 0.66225 roc_auc 0.36735 prc_auc 0.59873[0m
[93maverage test of epoch 26: loss -47.43151 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 27: loss -48.05286 acc 0.66225 roc_auc 0.41902 prc_auc 0.62672[0m
[93maverage test of epoch 27: loss -49.10328 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 28: loss -49.71823 acc 0.66225 roc_auc 0.39353 prc_auc 0.62662[0m
[93maverage test of epoch 28: loss -50.77591 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 29: loss -51.38308 acc 0.66225 roc_auc 0.48461 prc_auc 0.65544[0m
[93maverage test of epoch 29: loss -52.44758 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 30: loss -53.04765 acc 0.66225 roc_auc 0.46078 prc_auc 0.66225[0m
[93maverage test of epoch 30: loss -54.11911 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 31: loss -54.71233 acc 0.66225 roc_auc 0.47882 prc_auc 0.65294[0m
[93maverage test of epoch 31: loss -55.79049 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 32: loss -56.37645 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 32: loss -57.46230 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 33: loss -58.04106 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 33: loss -59.13339 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 34: loss -59.70514 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 34: loss -60.80488 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 35: loss -61.36949 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 35: loss -62.47601 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 36: loss -63.03334 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 36: loss -64.14741 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 37: loss -64.69753 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 37: loss -65.81844 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 38: loss -66.36147 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 38: loss -67.48891 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 39: loss -68.02525 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 39: loss -69.16039 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -69.68907 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 40: loss -70.83074 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -71.35282 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 41: loss -72.50213 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -73.01649 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 42: loss -74.17268 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -74.68027 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 43: loss -75.84354 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -76.34386 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 44: loss -77.51435 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -78.00756 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 45: loss -79.18489 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -79.67099 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 46: loss -80.85564 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -81.33457 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 47: loss -82.52619 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -82.99788 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 48: loss -84.19676 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -84.66151 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 49: loss -85.86729 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.69203 ROC_AUC (avg): 0.55 PRC_AUC (avg): 0.695 

Average forward propagation time taken(ms): 3.9776860015675686
Average backward propagation time taken(ms): 1.5219044853946726

