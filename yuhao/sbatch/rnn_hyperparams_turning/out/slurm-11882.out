# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 1)
('lr', 0.001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-20-05-27/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-20-05-27/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 8,
 'epochs': 50,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 4,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.001,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 2,
 'num_workers': 8,
 'number_of_mlp_layer': 1,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-17-20-05-27',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 50, 'learning_rate': 0.001, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -0.01970 acc 0.33333 roc_auc 0.41520 prc_auc 0.61593[0m
[93maverage test of epoch 0: loss -0.12488 acc 0.34211 roc_auc 0.48769 prc_auc 0.65495[0m
[92maverage training of epoch 1: loss -0.17563 acc 0.33333 roc_auc 0.35340 prc_auc 0.56567[0m
[93maverage test of epoch 1: loss -0.23675 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 2: loss -0.28623 acc 0.33333 roc_auc 0.36060 prc_auc 0.56544[0m
[93maverage test of epoch 2: loss -0.34695 acc 0.34211 roc_auc 0.53846 prc_auc 0.67568[0m
[92maverage training of epoch 3: loss -0.39666 acc 0.33333 roc_auc 0.38100 prc_auc 0.57454[0m
[93maverage test of epoch 3: loss -0.45681 acc 0.34211 roc_auc 0.48000 prc_auc 0.64902[0m
[92maverage training of epoch 4: loss -0.50693 acc 0.33333 roc_auc 0.35780 prc_auc 0.56296[0m
[93maverage test of epoch 4: loss -0.56690 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 5: loss -0.61733 acc 0.33333 roc_auc 0.35800 prc_auc 0.56285[0m
[93maverage test of epoch 5: loss -0.67701 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 6: loss -0.72777 acc 0.33333 roc_auc 0.35780 prc_auc 0.56257[0m
[93maverage test of epoch 6: loss -0.78713 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 7: loss -0.83821 acc 0.33333 roc_auc 0.35760 prc_auc 0.56233[0m
[93maverage test of epoch 7: loss -0.89725 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 8: loss -0.94865 acc 0.33333 roc_auc 0.35760 prc_auc 0.56226[0m
[93maverage test of epoch 8: loss -1.00739 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 9: loss -1.05910 acc 0.33333 roc_auc 0.35760 prc_auc 0.56226[0m
[93maverage test of epoch 9: loss -1.11753 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 10: loss -1.16954 acc 0.33333 roc_auc 0.35700 prc_auc 0.56196[0m
[93maverage test of epoch 10: loss -1.22767 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 11: loss -1.28001 acc 0.33333 roc_auc 0.35740 prc_auc 0.56208[0m
[93maverage test of epoch 11: loss -1.33781 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 12: loss -1.39047 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 12: loss -1.44796 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 13: loss -1.50093 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 13: loss -1.55811 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 14: loss -1.61139 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 14: loss -1.66826 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 15: loss -1.72185 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 15: loss -1.77841 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 16: loss -1.83232 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 16: loss -1.88856 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 17: loss -1.94278 acc 0.62667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 17: loss -1.99871 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 18: loss -2.05325 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 18: loss -2.10886 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -2.16372 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 19: loss -2.21901 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -2.27418 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 20: loss -2.32916 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -2.38465 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 21: loss -2.43931 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -2.49511 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 22: loss -2.54946 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -2.60558 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 23: loss -2.65962 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -2.71605 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 24: loss -2.76977 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -2.82651 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 25: loss -2.87992 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -2.93698 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 26: loss -2.99000 acc 0.65789 roc_auc 0.52000 prc_auc 0.67158[0m
[92maverage training of epoch 27: loss -3.04744 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 27: loss -3.10022 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -3.15791 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 28: loss -3.21037 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -3.26837 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 29: loss -3.32052 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -3.37883 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 30: loss -3.43066 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -3.48930 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 31: loss -3.54081 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -3.59976 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 32: loss -3.65096 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -3.71022 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 33: loss -3.76111 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -3.82068 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 34: loss -3.87125 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -3.93115 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 35: loss -3.98140 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -4.04161 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 36: loss -4.09145 acc 0.65789 roc_auc 0.48000 prc_auc 0.64902[0m
[92maverage training of epoch 37: loss -4.15204 acc 0.66667 roc_auc 0.35600 prc_auc 0.56157[0m
[93maverage test of epoch 37: loss -4.20169 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -4.26253 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 38: loss -4.31184 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -4.37299 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 39: loss -4.42198 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -4.48345 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 40: loss -4.53212 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -4.59390 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 41: loss -4.64227 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -4.70436 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 42: loss -4.75241 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -4.81672 acc 0.66667 roc_auc 0.37540 prc_auc 0.58411[0m
[93maverage test of epoch 43: loss -4.91171 acc 0.65789 roc_auc 0.51077 prc_auc 0.67275[0m
[92maverage training of epoch 44: loss -6.17319 acc 0.66667 roc_auc 0.40420 prc_auc 0.61040[0m
[93maverage test of epoch 44: loss -7.67220 acc 0.65789 roc_auc 0.50000 prc_auc 0.72660[0m
[92maverage training of epoch 45: loss -9.25329 acc 0.66667 roc_auc 0.40040 prc_auc 0.60664[0m
[93maverage test of epoch 45: loss -10.86961 acc 0.65789 roc_auc 0.44615 prc_auc 0.63785[0m
[92maverage training of epoch 46: loss -12.53425 acc 0.66667 roc_auc 0.39920 prc_auc 0.60454[0m
[93maverage test of epoch 46: loss -14.18721 acc 0.65789 roc_auc 0.48000 prc_auc 0.63006[0m
[92maverage training of epoch 47: loss -15.87066 acc 0.66667 roc_auc 0.39640 prc_auc 0.60314[0m
[93maverage test of epoch 47: loss -17.53828 acc 0.65789 roc_auc 0.62308 prc_auc 0.73074[0m
[92maverage training of epoch 48: loss -19.26797 acc 0.66667 roc_auc 0.39730 prc_auc 0.60372[0m
[93maverage test of epoch 48: loss -20.97075 acc 0.65789 roc_auc 0.48923 prc_auc 0.65320[0m
[92maverage training of epoch 49: loss -22.74277 acc 0.66667 roc_auc 0.39520 prc_auc 0.60154[0m
[93maverage test of epoch 49: loss -24.46829 acc 0.65789 roc_auc 0.36769 prc_auc 0.59181[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -1.41447 acc 0.33333 roc_auc 0.52940 prc_auc 0.67517[0m
[93maverage test of epoch 0: loss -2.58881 acc 0.34211 roc_auc 0.56923 prc_auc 0.72148[0m
[92maverage training of epoch 1: loss -3.82669 acc 0.33333 roc_auc 0.52740 prc_auc 0.66445[0m
[93maverage test of epoch 1: loss -5.18975 acc 0.34211 roc_auc 0.53538 prc_auc 0.76959[0m
[92maverage training of epoch 2: loss -6.52320 acc 0.33333 roc_auc 0.53160 prc_auc 0.66701[0m
[93maverage test of epoch 2: loss -7.95629 acc 0.34211 roc_auc 0.68923 prc_auc 0.82134[0m
[92maverage training of epoch 3: loss -9.45808 acc 0.33333 roc_auc 0.52680 prc_auc 0.68111[0m
[93maverage test of epoch 3: loss -11.09359 acc 0.34211 roc_auc 0.45385 prc_auc 0.61385[0m
[92maverage training of epoch 4: loss -12.74424 acc 0.33333 roc_auc 0.53040 prc_auc 0.67058[0m
[93maverage test of epoch 4: loss -14.55664 acc 0.34211 roc_auc 0.61077 prc_auc 0.80384[0m
[92maverage training of epoch 5: loss -16.36187 acc 0.33333 roc_auc 0.48800 prc_auc 0.63552[0m
[93maverage test of epoch 5: loss -18.33369 acc 0.34211 roc_auc 0.59231 prc_auc 0.74045[0m
[92maverage training of epoch 6: loss -20.28345 acc 0.33333 roc_auc 0.40380 prc_auc 0.59377[0m
[93maverage test of epoch 6: loss -22.39030 acc 0.34211 roc_auc 0.50154 prc_auc 0.67440[0m
[92maverage training of epoch 7: loss -24.47577 acc 0.33333 roc_auc 0.40360 prc_auc 0.60327[0m
[93maverage test of epoch 7: loss -26.76585 acc 0.34211 roc_auc 0.43846 prc_auc 0.65534[0m
[92maverage training of epoch 8: loss -28.99256 acc 0.33333 roc_auc 0.40020 prc_auc 0.60125[0m
[93maverage test of epoch 8: loss -31.43294 acc 0.34211 roc_auc 0.52308 prc_auc 0.68224[0m
[92maverage training of epoch 9: loss -33.81363 acc 0.33333 roc_auc 0.41180 prc_auc 0.61046[0m
[93maverage test of epoch 9: loss -36.40912 acc 0.34211 roc_auc 0.62462 prc_auc 0.81335[0m
[92maverage training of epoch 10: loss -38.95294 acc 0.33333 roc_auc 0.41820 prc_auc 0.60894[0m
[93maverage test of epoch 10: loss -41.71382 acc 0.34211 roc_auc 0.34000 prc_auc 0.55843[0m
[92maverage training of epoch 11: loss -44.41138 acc 0.33333 roc_auc 0.41520 prc_auc 0.59746[0m
[93maverage test of epoch 11: loss -47.32028 acc 0.34211 roc_auc 0.37538 prc_auc 0.61543[0m
[92maverage training of epoch 12: loss -50.19481 acc 0.33333 roc_auc 0.41580 prc_auc 0.60002[0m
[93maverage test of epoch 12: loss -53.25587 acc 0.34211 roc_auc 0.59692 prc_auc 0.74484[0m
[92maverage training of epoch 13: loss -56.29974 acc 0.33333 roc_auc 0.41300 prc_auc 0.59492[0m
[93maverage test of epoch 13: loss -59.52380 acc 0.34211 roc_auc 0.42154 prc_auc 0.65278[0m
[92maverage training of epoch 14: loss -62.72055 acc 0.33333 roc_auc 0.41520 prc_auc 0.59485[0m
[93maverage test of epoch 14: loss -66.10476 acc 0.34211 roc_auc 0.35538 prc_auc 0.61258[0m
[92maverage training of epoch 15: loss -69.46959 acc 0.33333 roc_auc 0.41520 prc_auc 0.59583[0m
[93maverage test of epoch 15: loss -73.01572 acc 0.34211 roc_auc 0.59385 prc_auc 0.74007[0m
[92maverage training of epoch 16: loss -76.55139 acc 0.33333 roc_auc 0.41380 prc_auc 0.59345[0m
[93maverage test of epoch 16: loss -80.24773 acc 0.34211 roc_auc 0.29538 prc_auc 0.60631[0m
[92maverage training of epoch 17: loss -83.95130 acc 0.33333 roc_auc 0.41640 prc_auc 0.59559[0m
[93maverage test of epoch 17: loss -87.80643 acc 0.34211 roc_auc 0.30923 prc_auc 0.58327[0m
[92maverage training of epoch 18: loss -91.68167 acc 0.48667 roc_auc 0.41780 prc_auc 0.60027[0m
[93maverage test of epoch 18: loss -95.68502 acc 0.65789 roc_auc 0.56308 prc_auc 0.74969[0m
[92maverage training of epoch 19: loss -99.73431 acc 0.66667 roc_auc 0.41960 prc_auc 0.60417[0m
[93maverage test of epoch 19: loss -103.89866 acc 0.65789 roc_auc 0.48308 prc_auc 0.64244[0m
[92maverage training of epoch 20: loss -108.11669 acc 0.66667 roc_auc 0.42200 prc_auc 0.60834[0m
[93maverage test of epoch 20: loss -112.43474 acc 0.65789 roc_auc 0.55692 prc_auc 0.73228[0m
[92maverage training of epoch 21: loss -116.82803 acc 0.66667 roc_auc 0.42400 prc_auc 0.60758[0m
[93maverage test of epoch 21: loss -121.29633 acc 0.65789 roc_auc 0.50923 prc_auc 0.69706[0m
[92maverage training of epoch 22: loss -125.87045 acc 0.66667 roc_auc 0.42730 prc_auc 0.61093[0m
[93maverage test of epoch 22: loss -130.49355 acc 0.65789 roc_auc 0.62769 prc_auc 0.74845[0m
[92maverage training of epoch 23: loss -135.23672 acc 0.66667 roc_auc 0.42910 prc_auc 0.61303[0m
[93maverage test of epoch 23: loss -140.00718 acc 0.65789 roc_auc 0.71385 prc_auc 0.77647[0m
[92maverage training of epoch 24: loss -144.93411 acc 0.66667 roc_auc 0.43190 prc_auc 0.61525[0m
[93maverage test of epoch 24: loss -149.85675 acc 0.65789 roc_auc 0.51846 prc_auc 0.66632[0m
[92maverage training of epoch 25: loss -154.95780 acc 0.66667 roc_auc 0.43060 prc_auc 0.61259[0m
[93maverage test of epoch 25: loss -160.03640 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -165.31533 acc 0.66667 roc_auc 0.43570 prc_auc 0.61900[0m
[93maverage test of epoch 26: loss -170.54132 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -176.00022 acc 0.66667 roc_auc 0.44370 prc_auc 0.62863[0m
[93maverage test of epoch 27: loss -181.36758 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -187.01312 acc 0.66667 roc_auc 0.46000 prc_auc 0.64962[0m
[93maverage test of epoch 28: loss -192.53669 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -198.35799 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 29: loss -204.02733 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -210.03277 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 30: loss -215.84635 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -222.03785 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 31: loss -227.99235 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -234.37241 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 32: loss -240.47593 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -247.03762 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 33: loss -253.28127 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -260.03364 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -266.42102 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -273.36081 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -279.88853 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -287.01785 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -293.68571 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -301.00656 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -307.81342 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -315.32444 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -322.26694 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -329.97466 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -337.05914 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -344.95477 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -352.17679 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -360.26724 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -367.62471 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -375.91096 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -383.40282 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -391.88517 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -399.51115 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -408.18989 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -415.94827 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -424.82590 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -432.71563 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -441.79240 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -449.81314 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -459.09002 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -467.24118 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -476.71962 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -484.99945 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -494.68014 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -503.08928 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -1.82300 acc 0.33333 roc_auc 0.54200 prc_auc 0.68496[0m
[93maverage test of epoch 0: loss -2.79685 acc 0.34211 roc_auc 0.45231 prc_auc 0.71219[0m
[92maverage training of epoch 1: loss -3.71284 acc 0.33333 roc_auc 0.53080 prc_auc 0.69344[0m
[93maverage test of epoch 1: loss -4.82497 acc 0.34211 roc_auc 0.52000 prc_auc 0.72467[0m
[92maverage training of epoch 2: loss -6.19132 acc 0.33333 roc_auc 0.54560 prc_auc 0.66939[0m
[93maverage test of epoch 2: loss -7.89327 acc 0.34211 roc_auc 0.46462 prc_auc 0.69401[0m
[92maverage training of epoch 3: loss -9.71717 acc 0.33333 roc_auc 0.54760 prc_auc 0.68388[0m
[93maverage test of epoch 3: loss -11.72677 acc 0.34211 roc_auc 0.50154 prc_auc 0.70783[0m
[92maverage training of epoch 4: loss -13.76617 acc 0.33333 roc_auc 0.50700 prc_auc 0.65482[0m
[93maverage test of epoch 4: loss -16.05747 acc 0.34211 roc_auc 0.61077 prc_auc 0.80708[0m
[92maverage training of epoch 5: loss -18.35745 acc 0.33333 roc_auc 0.48700 prc_auc 0.64021[0m
[93maverage test of epoch 5: loss -20.90559 acc 0.34211 roc_auc 0.39385 prc_auc 0.65321[0m
[92maverage training of epoch 6: loss -23.49541 acc 0.33333 roc_auc 0.46940 prc_auc 0.63434[0m
[93maverage test of epoch 6: loss -26.35730 acc 0.34211 roc_auc 0.40769 prc_auc 0.62295[0m
[92maverage training of epoch 7: loss -29.21559 acc 0.33333 roc_auc 0.45980 prc_auc 0.63658[0m
[93maverage test of epoch 7: loss -32.34138 acc 0.34211 roc_auc 0.50462 prc_auc 0.69265[0m
[92maverage training of epoch 8: loss -35.45713 acc 0.33333 roc_auc 0.44360 prc_auc 0.63461[0m
[93maverage test of epoch 8: loss -38.85939 acc 0.34211 roc_auc 0.43385 prc_auc 0.71312[0m
[92maverage training of epoch 9: loss -42.23564 acc 0.33333 roc_auc 0.41720 prc_auc 0.61512[0m
[93maverage test of epoch 9: loss -45.92481 acc 0.34211 roc_auc 0.43846 prc_auc 0.61429[0m
[92maverage training of epoch 10: loss -49.56846 acc 0.33333 roc_auc 0.39060 prc_auc 0.60090[0m
[93maverage test of epoch 10: loss -53.51090 acc 0.34211 roc_auc 0.55538 prc_auc 0.71944[0m
[92maverage training of epoch 11: loss -57.38976 acc 0.33333 roc_auc 0.38940 prc_auc 0.59545[0m
[93maverage test of epoch 11: loss -61.57682 acc 0.34211 roc_auc 0.50615 prc_auc 0.64503[0m
[92maverage training of epoch 12: loss -65.67268 acc 0.33333 roc_auc 0.38680 prc_auc 0.59311[0m
[93maverage test of epoch 12: loss -70.07635 acc 0.34211 roc_auc 0.33846 prc_auc 0.58115[0m
[92maverage training of epoch 13: loss -74.40908 acc 0.33333 roc_auc 0.38110 prc_auc 0.59506[0m
[93maverage test of epoch 13: loss -79.05446 acc 0.34211 roc_auc 0.61231 prc_auc 0.78058[0m
[92maverage training of epoch 14: loss -83.61989 acc 0.33333 roc_auc 0.37770 prc_auc 0.58327[0m
[93maverage test of epoch 14: loss -88.49430 acc 0.34211 roc_auc 0.52000 prc_auc 0.75788[0m
[92maverage training of epoch 15: loss -93.29733 acc 0.33333 roc_auc 0.37800 prc_auc 0.58148[0m
[93maverage test of epoch 15: loss -98.40498 acc 0.34211 roc_auc 0.50923 prc_auc 0.66642[0m
[92maverage training of epoch 16: loss -103.45233 acc 0.33333 roc_auc 0.37840 prc_auc 0.57871[0m
[93maverage test of epoch 16: loss -108.78700 acc 0.34211 roc_auc 0.32769 prc_auc 0.57546[0m
[92maverage training of epoch 17: loss -114.08011 acc 0.33333 roc_auc 0.37720 prc_auc 0.57497[0m
[93maverage test of epoch 17: loss -119.65291 acc 0.34211 roc_auc 0.48615 prc_auc 0.69094[0m
[92maverage training of epoch 18: loss -125.18881 acc 0.33333 roc_auc 0.37530 prc_auc 0.57322[0m
[93maverage test of epoch 18: loss -130.98817 acc 0.34211 roc_auc 0.50769 prc_auc 0.68397[0m
[92maverage training of epoch 19: loss -136.77770 acc 0.33333 roc_auc 0.37540 prc_auc 0.57215[0m
[93maverage test of epoch 19: loss -142.80184 acc 0.34211 roc_auc 0.56154 prc_auc 0.73384[0m
[92maverage training of epoch 20: loss -148.84876 acc 0.52000 roc_auc 0.37580 prc_auc 0.57112[0m
[93maverage test of epoch 20: loss -155.11388 acc 0.65789 roc_auc 0.54462 prc_auc 0.73129[0m
[92maverage training of epoch 21: loss -161.40694 acc 0.66667 roc_auc 0.37620 prc_auc 0.57438[0m
[93maverage test of epoch 21: loss -167.89695 acc 0.65789 roc_auc 0.38000 prc_auc 0.60496[0m
[92maverage training of epoch 22: loss -174.45105 acc 0.66667 roc_auc 0.37880 prc_auc 0.57802[0m
[93maverage test of epoch 22: loss -181.16589 acc 0.65789 roc_auc 0.51231 prc_auc 0.66716[0m
[92maverage training of epoch 23: loss -187.97780 acc 0.66667 roc_auc 0.37880 prc_auc 0.57822[0m
[93maverage test of epoch 23: loss -194.92251 acc 0.65789 roc_auc 0.40462 prc_auc 0.61583[0m
[92maverage training of epoch 24: loss -201.99455 acc 0.66667 roc_auc 0.38190 prc_auc 0.58183[0m
[93maverage test of epoch 24: loss -209.16285 acc 0.65789 roc_auc 0.46000 prc_auc 0.64041[0m
[92maverage training of epoch 25: loss -216.49850 acc 0.66667 roc_auc 0.38410 prc_auc 0.58738[0m
[93maverage test of epoch 25: loss -223.89624 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -231.49336 acc 0.66667 roc_auc 0.39570 prc_auc 0.60760[0m
[93maverage test of epoch 26: loss -239.11215 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -246.97583 acc 0.66667 roc_auc 0.46500 prc_auc 0.65161[0m
[93maverage test of epoch 27: loss -254.81161 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -262.95293 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 28: loss -271.01556 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -279.41665 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 29: loss -287.70300 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -296.37529 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 30: loss -304.87913 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -313.86840 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 31: loss -322.94391 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -333.42136 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 32: loss -343.73994 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -354.70734 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 33: loss -365.38493 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -376.73561 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -387.69011 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -399.34902 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -410.53926 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -422.52738 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -433.96125 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -446.27206 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -457.94100 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -470.59108 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -482.50828 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -495.50139 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -507.67107 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -521.01560 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -533.43837 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -547.14081 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -559.82060 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -573.88573 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -586.82290 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -601.25323 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -614.44818 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -629.24891 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -642.70261 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -657.87688 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -671.58773 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -687.13904 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -701.10873 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -717.04039 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -731.26624 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -747.58165 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -762.06588 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -778.76722 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -793.50671 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -0.59201 acc 0.58940 roc_auc 0.55627 prc_auc 0.68731[0m
[93maverage test of epoch 0: loss -1.28168 acc 0.32432 roc_auc 0.42333 prc_auc 0.68247[0m
[92maverage training of epoch 1: loss -2.56599 acc 0.33775 roc_auc 0.55745 prc_auc 0.70106[0m
[93maverage test of epoch 1: loss -3.68114 acc 0.32432 roc_auc 0.16000 prc_auc 0.51091[0m
[92maverage training of epoch 2: loss -4.96432 acc 0.33775 roc_auc 0.54667 prc_auc 0.68454[0m
[93maverage test of epoch 2: loss -6.15801 acc 0.32432 roc_auc 0.58667 prc_auc 0.79923[0m
[92maverage training of epoch 3: loss -7.56951 acc 0.33775 roc_auc 0.52725 prc_auc 0.65246[0m
[93maverage test of epoch 3: loss -8.94403 acc 0.32432 roc_auc 0.70000 prc_auc 0.83385[0m
[92maverage training of epoch 4: loss -10.58078 acc 0.33775 roc_auc 0.54608 prc_auc 0.67728[0m
[93maverage test of epoch 4: loss -12.15993 acc 0.32432 roc_auc 0.37000 prc_auc 0.65855[0m
[92maverage training of epoch 5: loss -14.03834 acc 0.33775 roc_auc 0.50098 prc_auc 0.64273[0m
[93maverage test of epoch 5: loss -15.84270 acc 0.32432 roc_auc 0.41667 prc_auc 0.68423[0m
[92maverage training of epoch 6: loss -17.95086 acc 0.33775 roc_auc 0.48902 prc_auc 0.65242[0m
[93maverage test of epoch 6: loss -19.96519 acc 0.32432 roc_auc 0.43833 prc_auc 0.64382[0m
[92maverage training of epoch 7: loss -22.28809 acc 0.33775 roc_auc 0.43196 prc_auc 0.62602[0m
[93maverage test of epoch 7: loss -24.46411 acc 0.32432 roc_auc 0.48333 prc_auc 0.70484[0m
[92maverage training of epoch 8: loss -26.92325 acc 0.33775 roc_auc 0.40706 prc_auc 0.60352[0m
[93maverage test of epoch 8: loss -29.23541 acc 0.32432 roc_auc 0.63167 prc_auc 0.79575[0m
[92maverage training of epoch 9: loss -31.83709 acc 0.33775 roc_auc 0.36882 prc_auc 0.58543[0m
[93maverage test of epoch 9: loss -34.29838 acc 0.32432 roc_auc 0.34333 prc_auc 0.60422[0m
[92maverage training of epoch 10: loss -37.05120 acc 0.33775 roc_auc 0.37961 prc_auc 0.58873[0m
[93maverage test of epoch 10: loss -39.67302 acc 0.32432 roc_auc 0.42167 prc_auc 0.63746[0m
[92maverage training of epoch 11: loss -42.56832 acc 0.33775 roc_auc 0.37000 prc_auc 0.58265[0m
[93maverage test of epoch 11: loss -45.35510 acc 0.32432 roc_auc 0.41667 prc_auc 0.63947[0m
[92maverage training of epoch 12: loss -48.40268 acc 0.33775 roc_auc 0.36431 prc_auc 0.57670[0m
[93maverage test of epoch 12: loss -51.34715 acc 0.32432 roc_auc 0.26167 prc_auc 0.57294[0m
[92maverage training of epoch 13: loss -54.54873 acc 0.33775 roc_auc 0.36353 prc_auc 0.57775[0m
[93maverage test of epoch 13: loss -57.66310 acc 0.32432 roc_auc 0.53167 prc_auc 0.65147[0m
[92maverage training of epoch 14: loss -61.00978 acc 0.33775 roc_auc 0.36412 prc_auc 0.57574[0m
[93maverage test of epoch 14: loss -64.29902 acc 0.32432 roc_auc 0.37833 prc_auc 0.63325[0m
[92maverage training of epoch 15: loss -67.79054 acc 0.33775 roc_auc 0.36608 prc_auc 0.57534[0m
[93maverage test of epoch 15: loss -71.25233 acc 0.32432 roc_auc 0.47333 prc_auc 0.69776[0m
[92maverage training of epoch 16: loss -74.89653 acc 0.33775 roc_auc 0.37059 prc_auc 0.58569[0m
[93maverage test of epoch 16: loss -78.53640 acc 0.32432 roc_auc 0.46167 prc_auc 0.73642[0m
[92maverage training of epoch 17: loss -82.32807 acc 0.33775 roc_auc 0.37137 prc_auc 0.57377[0m
[93maverage test of epoch 17: loss -86.14322 acc 0.32432 roc_auc 0.47667 prc_auc 0.69450[0m
[92maverage training of epoch 18: loss -90.07992 acc 0.33775 roc_auc 0.37412 prc_auc 0.57381[0m
[93maverage test of epoch 18: loss -94.07553 acc 0.32432 roc_auc 0.43667 prc_auc 0.62651[0m
[92maverage training of epoch 19: loss -98.15781 acc 0.33775 roc_auc 0.37549 prc_auc 0.57283[0m
[93maverage test of epoch 19: loss -102.33528 acc 0.32432 roc_auc 0.49333 prc_auc 0.71384[0m
[92maverage training of epoch 20: loss -106.56339 acc 0.33775 roc_auc 0.37275 prc_auc 0.56707[0m
[93maverage test of epoch 20: loss -110.92404 acc 0.32432 roc_auc 0.35500 prc_auc 0.62116[0m
[92maverage training of epoch 21: loss -115.29606 acc 0.47682 roc_auc 0.37412 prc_auc 0.56777[0m
[93maverage test of epoch 21: loss -119.84255 acc 0.67568 roc_auc 0.70167 prc_auc 0.82565[0m
[92maverage training of epoch 22: loss -124.35639 acc 0.66225 roc_auc 0.37510 prc_auc 0.56947[0m
[93maverage test of epoch 22: loss -129.08869 acc 0.67568 roc_auc 0.49333 prc_auc 0.66830[0m
[92maverage training of epoch 23: loss -133.74545 acc 0.66225 roc_auc 0.37608 prc_auc 0.57012[0m
[93maverage test of epoch 23: loss -138.66665 acc 0.67568 roc_auc 0.63000 prc_auc 0.78137[0m
[92maverage training of epoch 24: loss -143.46387 acc 0.66225 roc_auc 0.37667 prc_auc 0.57029[0m
[93maverage test of epoch 24: loss -148.57675 acc 0.67568 roc_auc 0.72667 prc_auc 0.83507[0m
[92maverage training of epoch 25: loss -153.51333 acc 0.66225 roc_auc 0.37794 prc_auc 0.57054[0m
[93maverage test of epoch 25: loss -158.81762 acc 0.67568 roc_auc 0.42667 prc_auc 0.64118[0m
[92maverage training of epoch 26: loss -163.89051 acc 0.66225 roc_auc 0.37824 prc_auc 0.57113[0m
[93maverage test of epoch 26: loss -169.38854 acc 0.67568 roc_auc 0.44000 prc_auc 0.64982[0m
[92maverage training of epoch 27: loss -174.60212 acc 0.66225 roc_auc 0.37990 prc_auc 0.57203[0m
[93maverage test of epoch 27: loss -180.29423 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 28: loss -185.64300 acc 0.66225 roc_auc 0.38206 prc_auc 0.57640[0m
[93maverage test of epoch 28: loss -191.53367 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 29: loss -197.01563 acc 0.66225 roc_auc 0.39686 prc_auc 0.60027[0m
[93maverage test of epoch 29: loss -203.10590 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 30: loss -208.72138 acc 0.66225 roc_auc 0.45902 prc_auc 0.64021[0m
[93maverage test of epoch 30: loss -215.01146 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 31: loss -220.75840 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 31: loss -227.25035 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 32: loss -233.12874 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 32: loss -239.82126 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 33: loss -245.83182 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 33: loss -252.73138 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 34: loss -258.86733 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 34: loss -265.97386 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 35: loss -272.23670 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 35: loss -279.54963 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 36: loss -285.93820 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 36: loss -293.46405 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 37: loss -300.37792 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 37: loss -309.12657 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 38: loss -317.11193 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 38: loss -326.54220 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 39: loss -334.76993 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 39: loss -344.54434 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -352.92520 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 40: loss -362.96125 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -371.48099 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 41: loss -381.79653 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -390.65882 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 42: loss -402.02399 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -412.18548 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 43: loss -424.53980 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -434.98091 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 44: loss -447.76158 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -458.40443 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 45: loss -471.53399 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -482.33803 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 46: loss -495.82310 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -506.81171 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 47: loss -520.66305 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -531.82742 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 48: loss -546.04380 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -557.39267 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 49: loss -571.98858 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -1.67144 acc 0.50993 roc_auc 0.41235 prc_auc 0.60718[0m
[93maverage test of epoch 0: loss -4.04027 acc 0.67568 roc_auc 0.71333 prc_auc 0.82082[0m
[92maverage training of epoch 1: loss -5.58390 acc 0.66225 roc_auc 0.42118 prc_auc 0.61801[0m
[93maverage test of epoch 1: loss -7.33684 acc 0.67568 roc_auc 0.46667 prc_auc 0.70390[0m
[92maverage training of epoch 2: loss -9.04831 acc 0.66225 roc_auc 0.42392 prc_auc 0.62095[0m
[93maverage test of epoch 2: loss -11.06044 acc 0.67568 roc_auc 0.62333 prc_auc 0.79638[0mUsing backend: pytorch

[92maverage training of epoch 3: loss -13.01817 acc 0.66225 roc_auc 0.40882 prc_auc 0.60638[0m
[93maverage test of epoch 3: loss -15.36187 acc 0.67568 roc_auc 0.37500 prc_auc 0.61895[0m
[92maverage training of epoch 4: loss -17.60291 acc 0.66225 roc_auc 0.40804 prc_auc 0.60730[0m
[93maverage test of epoch 4: loss -20.30941 acc 0.67568 roc_auc 0.52667 prc_auc 0.68615[0m
[92maverage training of epoch 5: loss -22.83348 acc 0.66225 roc_auc 0.41010 prc_auc 0.60659[0m
[93maverage test of epoch 5: loss -25.88235 acc 0.67568 roc_auc 0.66000 prc_auc 0.76203[0m
[92maverage training of epoch 6: loss -28.65292 acc 0.66225 roc_auc 0.40245 prc_auc 0.60178[0m
[93maverage test of epoch 6: loss -32.02808 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 7: loss -34.99469 acc 0.66225 roc_auc 0.44284 prc_auc 0.63808[0m
[93maverage test of epoch 7: loss -38.66930 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 8: loss -41.84539 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 8: loss -45.80595 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 9: loss -49.18127 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 9: loss -53.43037 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 10: loss -57.01767 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 10: loss -61.55928 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 11: loss -65.35278 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 11: loss -70.21721 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 12: loss -74.20411 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 12: loss -79.35967 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 13: loss -83.53852 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 13: loss -88.98146 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 14: loss -93.35456 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 14: loss -99.09830 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 15: loss -103.64407 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 15: loss -109.69344 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 16: loss -114.42624 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 16: loss -120.77780 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 17: loss -125.69362 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 17: loss -132.34983 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 18: loss -137.44840 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 18: loss -144.41550 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 19: loss -149.69143 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 19: loss -156.96876 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 20: loss -162.42553 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 20: loss -170.01801 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 21: loss -175.65257 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 21: loss -183.55960 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 22: loss -189.37246 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 22: loss -197.59859 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 23: loss -203.58688 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 23: loss -212.13570 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 24: loss -218.29663 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 24: loss -227.16901 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 25: loss -233.50206 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 25: loss -242.70266 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 26: loss -249.20131 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 26: loss -258.73133 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 27: loss -265.40058 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 27: loss -275.26251 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 28: loss -282.09669 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 28: loss -292.29267 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 29: loss -299.29109 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 29: loss -309.82282 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 30: loss -316.98281 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 30: loss -327.85483 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 31: loss -335.17496 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 31: loss -346.38957 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 32: loss -353.86477 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 32: loss -365.42356 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 33: loss -373.05716 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 33: loss -384.95995 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 34: loss -392.74731 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 34: loss -404.99944 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 35: loss -412.93765 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 35: loss -425.54103 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 36: loss -433.62858 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 36: loss -446.58527 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 37: loss -454.82251 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 37: loss -468.13294 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 38: loss -476.51503 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 38: loss -490.18209 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 39: loss -498.70918 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 39: loss -512.73502 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -521.40568 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 40: loss -535.79414 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -544.84623 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 41: loss -560.44524 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -570.74943 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 42: loss -587.35128 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -597.92105 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 43: loss -615.02689 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -625.77464 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 44: loss -643.30027 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -654.19069 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 45: loss -672.14430 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -683.19367 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 46: loss -701.58174 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -712.77918 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 47: loss -731.59839 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -742.95201 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 48: loss -762.21518 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -773.72872 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 49: loss -793.44484 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 1)
('lr', 0.001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.66501 ROC_AUC (avg): 0.47354 PRC_AUC (avg): 0.65179 

Average forward propagation time taken(ms): 4.335451356742951
Average backward propagation time taken(ms): 1.593809465749506

