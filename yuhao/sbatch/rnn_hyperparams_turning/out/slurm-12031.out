# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 1)
('lr', 0.0003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-09-56-29/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-09-56-29/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 16,
 'epochs': 100,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 4,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.0003,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 2,
 'num_workers': 8,
 'number_of_mlp_layer': 1,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-18-09-56-29',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 100, 'learning_rate': 0.0003, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss 1.21900 acc 0.33333 roc_auc 0.41900 prc_auc 0.61098[0m
[93maverage test of epoch 0: loss 0.97011 acc 0.34211 roc_auc 0.45538 prc_auc 0.69722[0m
[92maverage training of epoch 1: loss 0.87054 acc 0.33333 roc_auc 0.42620 prc_auc 0.62353[0m
[93maverage test of epoch 1: loss 0.69103 acc 0.34211 roc_auc 0.34462 prc_auc 0.63314[0m
[92maverage training of epoch 2: loss 0.56910 acc 0.33333 roc_auc 0.46060 prc_auc 0.67469[0m
[93maverage test of epoch 2: loss 0.37570 acc 0.34211 roc_auc 0.65846 prc_auc 0.79366[0m
[92maverage training of epoch 3: loss 0.36580 acc 0.33333 roc_auc 0.41980 prc_auc 0.64887[0m
[93maverage test of epoch 3: loss 0.30345 acc 0.34211 roc_auc 0.40615 prc_auc 0.62339[0m
[92maverage training of epoch 4: loss 0.19584 acc 0.33333 roc_auc 0.50440 prc_auc 0.69019[0m
[93maverage test of epoch 4: loss 0.10728 acc 0.34211 roc_auc 0.50154 prc_auc 0.72586[0m
[92maverage training of epoch 5: loss 0.03887 acc 0.33333 roc_auc 0.57260 prc_auc 0.74033[0m
[93maverage test of epoch 5: loss -0.00420 acc 0.34211 roc_auc 0.61846 prc_auc 0.80631[0m
[92maverage training of epoch 6: loss -0.04220 acc 0.33333 roc_auc 0.52940 prc_auc 0.69380[0m
[93maverage test of epoch 6: loss -0.11289 acc 0.34211 roc_auc 0.66769 prc_auc 0.83951[0m
[92maverage training of epoch 7: loss -0.13916 acc 0.42667 roc_auc 0.60300 prc_auc 0.73946[0m
[93maverage test of epoch 7: loss -0.18563 acc 0.52632 roc_auc 0.66462 prc_auc 0.80682[0m
[92maverage training of epoch 8: loss -0.21235 acc 0.56000 roc_auc 0.68880 prc_auc 0.79733[0m
[93maverage test of epoch 8: loss -0.22451 acc 0.55263 roc_auc 0.65538 prc_auc 0.83262[0m
[92maverage training of epoch 9: loss -0.29044 acc 0.60000 roc_auc 0.74620 prc_auc 0.82592[0m
[93maverage test of epoch 9: loss -0.38485 acc 0.57895 roc_auc 0.85231 prc_auc 0.89737[0m
[92maverage training of epoch 10: loss -0.40407 acc 0.67333 roc_auc 0.82240 prc_auc 0.90002[0m
[93maverage test of epoch 10: loss -0.43238 acc 0.55263 roc_auc 0.84923 prc_auc 0.90615[0m
[92maverage training of epoch 11: loss -0.57794 acc 0.71333 roc_auc 0.85440 prc_auc 0.90205[0m
[93maverage test of epoch 11: loss -0.71524 acc 0.68421 roc_auc 0.88000 prc_auc 0.93164[0m
[92maverage training of epoch 12: loss -0.95033 acc 0.75333 roc_auc 0.84000 prc_auc 0.87648[0m
[93maverage test of epoch 12: loss -1.24471 acc 0.81579 roc_auc 0.85846 prc_auc 0.93188[0m
[92maverage training of epoch 13: loss -1.50057 acc 0.84000 roc_auc 0.86400 prc_auc 0.89278[0m
[93maverage test of epoch 13: loss -1.75246 acc 0.81579 roc_auc 0.84000 prc_auc 0.92513[0m
[92maverage training of epoch 14: loss -2.09068 acc 0.84667 roc_auc 0.87280 prc_auc 0.91526[0m
[93maverage test of epoch 14: loss -2.43980 acc 0.78947 roc_auc 0.86462 prc_auc 0.94094[0m
[92maverage training of epoch 15: loss -2.81578 acc 0.84667 roc_auc 0.86140 prc_auc 0.88879[0m
[93maverage test of epoch 15: loss -3.20074 acc 0.81579 roc_auc 0.85231 prc_auc 0.90538[0m
[92maverage training of epoch 16: loss -3.54827 acc 0.85333 roc_auc 0.85940 prc_auc 0.88712[0m
[93maverage test of epoch 16: loss -3.93759 acc 0.78947 roc_auc 0.81231 prc_auc 0.86384[0m
[92maverage training of epoch 17: loss -4.39039 acc 0.84000 roc_auc 0.87660 prc_auc 0.89176[0m
[93maverage test of epoch 17: loss -4.58238 acc 0.78947 roc_auc 0.84923 prc_auc 0.92318[0m
[92maverage training of epoch 18: loss -5.05543 acc 0.83333 roc_auc 0.86920 prc_auc 0.86294[0m
[93maverage test of epoch 18: loss -5.25155 acc 0.76316 roc_auc 0.87385 prc_auc 0.92293[0m
[92maverage training of epoch 19: loss -5.78521 acc 0.84667 roc_auc 0.85180 prc_auc 0.87345[0m
[93maverage test of epoch 19: loss -6.21503 acc 0.81579 roc_auc 0.82154 prc_auc 0.88834[0m
[92maverage training of epoch 20: loss -6.66870 acc 0.83333 roc_auc 0.89180 prc_auc 0.90471[0m
[93maverage test of epoch 20: loss -6.77485 acc 0.81579 roc_auc 0.81846 prc_auc 0.86375[0m
[92maverage training of epoch 21: loss -7.43422 acc 0.84000 roc_auc 0.91020 prc_auc 0.95364[0m
[93maverage test of epoch 21: loss -7.61659 acc 0.81579 roc_auc 0.84000 prc_auc 0.91002[0m
[92maverage training of epoch 22: loss -8.18909 acc 0.83333 roc_auc 0.90780 prc_auc 0.93794[0m
[93maverage test of epoch 22: loss -8.26365 acc 0.78947 roc_auc 0.90462 prc_auc 0.95175[0m
[92maverage training of epoch 23: loss -8.80605 acc 0.84667 roc_auc 0.87180 prc_auc 0.89374[0m
[93maverage test of epoch 23: loss -8.86265 acc 0.84211 roc_auc 0.85538 prc_auc 0.91484[0m
[92maverage training of epoch 24: loss -9.44964 acc 0.83333 roc_auc 0.89460 prc_auc 0.93520[0m
[93maverage test of epoch 24: loss -9.51831 acc 0.78947 roc_auc 0.89231 prc_auc 0.95364[0m
[92maverage training of epoch 25: loss -10.34478 acc 0.87333 roc_auc 0.90860 prc_auc 0.92770[0m
[93maverage test of epoch 25: loss -10.34045 acc 0.86842 roc_auc 0.85846 prc_auc 0.85949[0m
[92maverage training of epoch 26: loss -11.02338 acc 0.88000 roc_auc 0.92260 prc_auc 0.96202[0m
[93maverage test of epoch 26: loss -11.05917 acc 0.78947 roc_auc 0.90769 prc_auc 0.95570[0m
[92maverage training of epoch 27: loss -11.76709 acc 0.86667 roc_auc 0.91140 prc_auc 0.93569[0m
[93maverage test of epoch 27: loss -11.92113 acc 0.81579 roc_auc 0.92615 prc_auc 0.96567[0m
[92maverage training of epoch 28: loss -12.52301 acc 0.85333 roc_auc 0.90320 prc_auc 0.91886[0m
[93maverage test of epoch 28: loss -12.57461 acc 0.81579 roc_auc 0.88923 prc_auc 0.95480[0m
[92maverage training of epoch 29: loss -13.42220 acc 0.90000 roc_auc 0.91640 prc_auc 0.95075[0m
[93maverage test of epoch 29: loss -13.57030 acc 0.86842 roc_auc 0.89231 prc_auc 0.95600[0m
[92maverage training of epoch 30: loss -14.03125 acc 0.86667 roc_auc 0.90240 prc_auc 0.91397[0m
[93maverage test of epoch 30: loss -14.38137 acc 0.84211 roc_auc 0.90462 prc_auc 0.96003[0m
[92maverage training of epoch 31: loss -14.81409 acc 0.86667 roc_auc 0.92660 prc_auc 0.96055[0m
[93maverage test of epoch 31: loss -14.81731 acc 0.81579 roc_auc 0.87077 prc_auc 0.94876[0m
[92maverage training of epoch 32: loss -15.59883 acc 0.86000 roc_auc 0.91920 prc_auc 0.94613[0m
[93maverage test of epoch 32: loss -15.82164 acc 0.81579 roc_auc 0.88000 prc_auc 0.95345[0m
[92maverage training of epoch 33: loss -16.56811 acc 0.89333 roc_auc 0.92100 prc_auc 0.94578[0m
[93maverage test of epoch 33: loss -16.65648 acc 0.81579 roc_auc 0.90154 prc_auc 0.95930[0m
[92maverage training of epoch 34: loss -17.43807 acc 0.86667 roc_auc 0.91360 prc_auc 0.93608[0m
[93maverage test of epoch 34: loss -17.82671 acc 0.81579 roc_auc 0.92923 prc_auc 0.96826[0m
[92maverage training of epoch 35: loss -18.34985 acc 0.89333 roc_auc 0.92720 prc_auc 0.93554[0m
[93maverage test of epoch 35: loss -18.44057 acc 0.84211 roc_auc 0.89231 prc_auc 0.95484[0m
[92maverage training of epoch 36: loss -19.20795 acc 0.88000 roc_auc 0.91460 prc_auc 0.93498[0m
[93maverage test of epoch 36: loss -19.47383 acc 0.81579 roc_auc 0.92615 prc_auc 0.96636[0m
[92maverage training of epoch 37: loss -20.25089 acc 0.90000 roc_auc 0.91460 prc_auc 0.92628[0m
[93maverage test of epoch 37: loss -20.10848 acc 0.84211 roc_auc 0.89538 prc_auc 0.95790[0m
[92maverage training of epoch 38: loss -21.25526 acc 0.88667 roc_auc 0.92080 prc_auc 0.95748[0m
[93maverage test of epoch 38: loss -21.50956 acc 0.86842 roc_auc 0.89538 prc_auc 0.95853[0m
[92maverage training of epoch 39: loss -22.01412 acc 0.88667 roc_auc 0.88200 prc_auc 0.89424[0m
[93maverage test of epoch 39: loss -22.31435 acc 0.84211 roc_auc 0.90769 prc_auc 0.96178[0m
[92maverage training of epoch 40: loss -23.11142 acc 0.88000 roc_auc 0.91200 prc_auc 0.93088[0m
[93maverage test of epoch 40: loss -23.37734 acc 0.81579 roc_auc 0.90769 prc_auc 0.96144[0m
[92maverage training of epoch 41: loss -23.92228 acc 0.86000 roc_auc 0.89570 prc_auc 0.92044[0m
[93maverage test of epoch 41: loss -24.43189 acc 0.84211 roc_auc 0.89231 prc_auc 0.95742[0m
[92maverage training of epoch 42: loss -25.15374 acc 0.88667 roc_auc 0.88230 prc_auc 0.87948[0m
[93maverage test of epoch 42: loss -25.00252 acc 0.84211 roc_auc 0.88615 prc_auc 0.95604[0m
[92maverage training of epoch 43: loss -26.17815 acc 0.88000 roc_auc 0.91920 prc_auc 0.95231[0m
[93maverage test of epoch 43: loss -26.49613 acc 0.84211 roc_auc 0.89077 prc_auc 0.95450[0m
[92maverage training of epoch 44: loss -27.31054 acc 0.86667 roc_auc 0.89420 prc_auc 0.89939[0m
[93maverage test of epoch 44: loss -27.35430 acc 0.84211 roc_auc 0.90462 prc_auc 0.96038[0m
[92maverage training of epoch 45: loss -28.46372 acc 0.89333 roc_auc 0.89680 prc_auc 0.90679[0m
[93maverage test of epoch 45: loss -28.71746 acc 0.86842 roc_auc 0.90154 prc_auc 0.96006[0m
[92maverage training of epoch 46: loss -29.54227 acc 0.88000 roc_auc 0.91470 prc_auc 0.95240[0m
[93maverage test of epoch 46: loss -29.74224 acc 0.81579 roc_auc 0.88923 prc_auc 0.95551[0m
[92maverage training of epoch 47: loss -30.72163 acc 0.90000 roc_auc 0.89900 prc_auc 0.93332[0m
[93maverage test of epoch 47: loss -31.07796 acc 0.84211 roc_auc 0.86923 prc_auc 0.93470[0m
[92maverage training of epoch 48: loss -31.78907 acc 0.87333 roc_auc 0.91480 prc_auc 0.95148[0m
[93maverage test of epoch 48: loss -31.69125 acc 0.81579 roc_auc 0.89538 prc_auc 0.95440[0m
[92maverage training of epoch 49: loss -33.17140 acc 0.90000 roc_auc 0.91300 prc_auc 0.93104[0m
[93maverage test of epoch 49: loss -33.26014 acc 0.84211 roc_auc 0.89538 prc_auc 0.95736[0m
[92maverage training of epoch 50: loss -34.29526 acc 0.89333 roc_auc 0.90110 prc_auc 0.92461[0m
[93maverage test of epoch 50: loss -34.64475 acc 0.81579 roc_auc 0.90154 prc_auc 0.95989[0m
[92maverage training of epoch 51: loss -35.27719 acc 0.88667 roc_auc 0.88390 prc_auc 0.89383[0m
[93maverage test of epoch 51: loss -35.85489 acc 0.84211 roc_auc 0.88000 prc_auc 0.95280[0m
[92maverage training of epoch 52: loss -36.80153 acc 0.88667 roc_auc 0.88870 prc_auc 0.91088[0m
[93maverage test of epoch 52: loss -37.08344 acc 0.86842 roc_auc 0.91077 prc_auc 0.96236[0m
[92maverage training of epoch 53: loss -37.93528 acc 0.87333 roc_auc 0.89160 prc_auc 0.91353[0m
[93maverage test of epoch 53: loss -37.85392 acc 0.84211 roc_auc 0.86000 prc_auc 0.94151[0m
[92maverage training of epoch 54: loss -39.43438 acc 0.88000 roc_auc 0.89940 prc_auc 0.92342[0m
[93maverage test of epoch 54: loss -39.50431 acc 0.84211 roc_auc 0.88000 prc_auc 0.95394[0m
[92maverage training of epoch 55: loss -40.54559 acc 0.90000 roc_auc 0.89180 prc_auc 0.91302[0m
[93maverage test of epoch 55: loss -41.09616 acc 0.84211 roc_auc 0.91385 prc_auc 0.96339[0m
[92maverage training of epoch 56: loss -42.10693 acc 0.89333 roc_auc 0.88380 prc_auc 0.90209[0m
[93maverage test of epoch 56: loss -42.37740 acc 0.84211 roc_auc 0.89231 prc_auc 0.95793[0m
[92maverage training of epoch 57: loss -43.42674 acc 0.88000 roc_auc 0.88580 prc_auc 0.90015[0m
[93maverage test of epoch 57: loss -43.87260 acc 0.86842 roc_auc 0.88769 prc_auc 0.95017[0m
[92maverage training of epoch 58: loss -44.90498 acc 0.88667 roc_auc 0.89530 prc_auc 0.91650[0m
[93maverage test of epoch 58: loss -45.38921 acc 0.84211 roc_auc 0.92000 prc_auc 0.96724[0m
[92maverage training of epoch 59: loss -46.21407 acc 0.88667 roc_auc 0.89820 prc_auc 0.92369[0m
[93maverage test of epoch 59: loss -46.34005 acc 0.84211 roc_auc 0.91692 prc_auc 0.96393[0m
[92maverage training of epoch 60: loss -47.64363 acc 0.88667 roc_auc 0.88070 prc_auc 0.89756[0m
[93maverage test of epoch 60: loss -48.11193 acc 0.86842 roc_auc 0.90462 prc_auc 0.96216[0m
[92maverage training of epoch 61: loss -49.20786 acc 0.90000 roc_auc 0.88020 prc_auc 0.90101[0m
[93maverage test of epoch 61: loss -49.19050 acc 0.84211 roc_auc 0.88000 prc_auc 0.95286[0m
[92maverage training of epoch 62: loss -50.91101 acc 0.90667 roc_auc 0.88690 prc_auc 0.90402[0m
[93maverage test of epoch 62: loss -50.90964 acc 0.84211 roc_auc 0.88615 prc_auc 0.95642[0m
[92maverage training of epoch 63: loss -52.46074 acc 0.90667 roc_auc 0.89370 prc_auc 0.91601[0m
[93maverage test of epoch 63: loss -52.13560 acc 0.84211 roc_auc 0.90154 prc_auc 0.94501[0m
[92maverage training of epoch 64: loss -53.81698 acc 0.88667 roc_auc 0.88610 prc_auc 0.91320[0m
[93maverage test of epoch 64: loss -53.87303 acc 0.86842 roc_auc 0.89231 prc_auc 0.95650[0m
[92maverage training of epoch 65: loss -55.49236 acc 0.90000 roc_auc 0.89200 prc_auc 0.91347[0m
[93maverage test of epoch 65: loss -55.17342 acc 0.86842 roc_auc 0.85846 prc_auc 0.91586[0m
[92maverage training of epoch 66: loss -56.82615 acc 0.89333 roc_auc 0.90510 prc_auc 0.93108[0m
[93maverage test of epoch 66: loss -56.99893 acc 0.81579 roc_auc 0.85538 prc_auc 0.91802[0m
[92maverage training of epoch 67: loss -58.45854 acc 0.89333 roc_auc 0.90320 prc_auc 0.92698[0m
[93maverage test of epoch 67: loss -59.00469 acc 0.89474 roc_auc 0.89538 prc_auc 0.95855[0m
[92maverage training of epoch 68: loss -60.06579 acc 0.90000 roc_auc 0.90670 prc_auc 0.93224[0m
[93maverage test of epoch 68: loss -60.27493 acc 0.86842 roc_auc 0.86462 prc_auc 0.92143[0m
[92maverage training of epoch 69: loss -61.76488 acc 0.90000 roc_auc 0.89120 prc_auc 0.92108[0m
[93maverage test of epoch 69: loss -62.05807 acc 0.81579 roc_auc 0.86769 prc_auc 0.92117[0m
[92maverage training of epoch 70: loss -63.76773 acc 0.90667 roc_auc 0.89860 prc_auc 0.92147[0m
[93maverage test of epoch 70: loss -63.63921 acc 0.84211 roc_auc 0.89538 prc_auc 0.92955[0m
[92maverage training of epoch 71: loss -65.42756 acc 0.90667 roc_auc 0.90300 prc_auc 0.92527[0m
[93maverage test of epoch 71: loss -65.42221 acc 0.86842 roc_auc 0.93231 prc_auc 0.97071[0m
[92maverage training of epoch 72: loss -66.88711 acc 0.91333 roc_auc 0.90020 prc_auc 0.92356[0m
[93maverage test of epoch 72: loss -67.59733 acc 0.89474 roc_auc 0.92923 prc_auc 0.96933[0m
[92maverage training of epoch 73: loss -68.71612 acc 0.89333 roc_auc 0.90720 prc_auc 0.92804[0m
[93maverage test of epoch 73: loss -69.07838 acc 0.84211 roc_auc 0.87385 prc_auc 0.92330[0m
[92maverage training of epoch 74: loss -70.38005 acc 0.89333 roc_auc 0.90120 prc_auc 0.92588[0m
[93maverage test of epoch 74: loss -70.73961 acc 0.86842 roc_auc 0.89692 prc_auc 0.92942[0m
[92maverage training of epoch 75: loss -72.32418 acc 0.91333 roc_auc 0.89720 prc_auc 0.92476[0m
[93maverage test of epoch 75: loss -72.77473 acc 0.84211 roc_auc 0.89385 prc_auc 0.93074[0m
[92maverage training of epoch 76: loss -74.13128 acc 0.90000 roc_auc 0.90440 prc_auc 0.92577[0m
[93maverage test of epoch 76: loss -73.94369 acc 0.84211 roc_auc 0.89538 prc_auc 0.95880[0m
[92maverage training of epoch 77: loss -75.90718 acc 0.90667 roc_auc 0.89760 prc_auc 0.92470[0m
[93maverage test of epoch 77: loss -76.05591 acc 0.84211 roc_auc 0.86769 prc_auc 0.92184[0m
[92maverage training of epoch 78: loss -77.73387 acc 0.90667 roc_auc 0.90420 prc_auc 0.92741[0m
[93maverage test of epoch 78: loss -77.70238 acc 0.86842 roc_auc 0.85846 prc_auc 0.91997[0m
[92maverage training of epoch 79: loss -79.52762 acc 0.90000 roc_auc 0.89880 prc_auc 0.92532[0m
[93maverage test of epoch 79: loss -79.95395 acc 0.86842 roc_auc 0.89692 prc_auc 0.93271[0m
[92maverage training of epoch 80: loss -81.59821 acc 0.91333 roc_auc 0.89220 prc_auc 0.92277[0m
[93maverage test of epoch 80: loss -82.54662 acc 0.89474 roc_auc 0.87077 prc_auc 0.92311[0m
[92maverage training of epoch 81: loss -83.57888 acc 0.90000 roc_auc 0.90280 prc_auc 0.92662[0m
[93maverage test of epoch 81: loss -83.89557 acc 0.84211 roc_auc 0.87077 prc_auc 0.92158[0m
[92maverage training of epoch 82: loss -85.77495 acc 0.90667 roc_auc 0.90240 prc_auc 0.92578[0m
[93maverage test of epoch 82: loss -85.89624 acc 0.86842 roc_auc 0.87846 prc_auc 0.92431[0m
[92maverage training of epoch 83: loss -87.79281 acc 0.91333 roc_auc 0.90540 prc_auc 0.92871[0m
[93maverage test of epoch 83: loss -87.76294 acc 0.86842 roc_auc 0.89231 prc_auc 0.93172[0m
[92maverage training of epoch 84: loss -89.73235 acc 0.90667 roc_auc 0.90040 prc_auc 0.92637[0m
[93maverage test of epoch 84: loss -90.18582 acc 0.86842 roc_auc 0.88923 prc_auc 0.92914[0m
[92maverage training of epoch 85: loss -91.78525 acc 0.90000 roc_auc 0.90410 prc_auc 0.93297[0m
[93maverage test of epoch 85: loss -92.41246 acc 0.89474 roc_auc 0.88923 prc_auc 0.92887[0m
[92maverage training of epoch 86: loss -93.92471 acc 0.90000 roc_auc 0.90420 prc_auc 0.92785[0m
[93maverage test of epoch 86: loss -94.17156 acc 0.86842 roc_auc 0.86154 prc_auc 0.91980[0m
[92maverage training of epoch 87: loss -96.07222 acc 0.91333 roc_auc 0.89880 prc_auc 0.92556[0m
[93maverage test of epoch 87: loss -96.97557 acc 0.89474 roc_auc 0.88615 prc_auc 0.92929[0m
[92maverage training of epoch 88: loss -98.52499 acc 0.90667 roc_auc 0.90260 prc_auc 0.92712[0m
[93maverage test of epoch 88: loss -98.77636 acc 0.84211 roc_auc 0.90154 prc_auc 0.93215[0m
[92maverage training of epoch 89: loss -100.82920 acc 0.90667 roc_auc 0.89820 prc_auc 0.92572[0m
[93maverage test of epoch 89: loss -101.03831 acc 0.84211 roc_auc 0.88000 prc_auc 0.92535[0m
[92maverage training of epoch 90: loss -103.15525 acc 0.90667 roc_auc 0.89840 prc_auc 0.92572[0m
[93maverage test of epoch 90: loss -104.11926 acc 0.89474 roc_auc 0.90308 prc_auc 0.93402[0m
[92maverage training of epoch 91: loss -105.51885 acc 0.91333 roc_auc 0.91200 prc_auc 0.93006[0m
[93maverage test of epoch 91: loss -105.61866 acc 0.84211 roc_auc 0.84000 prc_auc 0.88745[0m
[92maverage training of epoch 92: loss -108.07107 acc 0.91333 roc_auc 0.90410 prc_auc 0.93371[0m
[93maverage test of epoch 92: loss -108.80252 acc 0.84211 roc_auc 0.87077 prc_auc 0.92347[0m
[92maverage training of epoch 93: loss -110.62016 acc 0.91333 roc_auc 0.89640 prc_auc 0.92493[0m
[93maverage test of epoch 93: loss -110.91576 acc 0.84211 roc_auc 0.86462 prc_auc 0.92111[0m
[92maverage training of epoch 94: loss -113.03715 acc 0.91333 roc_auc 0.89900 prc_auc 0.92619[0m
[93maverage test of epoch 94: loss -113.19626 acc 0.84211 roc_auc 0.88462 prc_auc 0.92852[0m
[92maverage training of epoch 95: loss -115.85218 acc 0.91333 roc_auc 0.89980 prc_auc 0.92598[0m
[93maverage test of epoch 95: loss -116.23603 acc 0.84211 roc_auc 0.88308 prc_auc 0.92734[0m
[92maverage training of epoch 96: loss -117.98954 acc 0.90667 roc_auc 0.90140 prc_auc 0.92636[0m
[93maverage test of epoch 96: loss -118.84147 acc 0.84211 roc_auc 0.88769 prc_auc 0.92959[0m
[92maverage training of epoch 97: loss -121.07434 acc 0.90000 roc_auc 0.90890 prc_auc 0.93509[0m
[93maverage test of epoch 97: loss -121.74280 acc 0.86842 roc_auc 0.86308 prc_auc 0.92169[0m
[92maverage training of epoch 98: loss -123.81480 acc 0.91333 roc_auc 0.89800 prc_auc 0.92528[0m
[93maverage test of epoch 98: loss -124.19336 acc 0.86842 roc_auc 0.89846 prc_auc 0.93105[0m
[92maverage training of epoch 99: loss -126.47823 acc 0.91333 roc_auc 0.90080 prc_auc 0.92631[0m
[93maverage test of epoch 99: loss -127.44208 acc 0.86842 roc_auc 0.92308 prc_auc 0.96724[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -1.47610 acc 0.66667 roc_auc 0.45480 prc_auc 0.65884[0m
[93maverage test of epoch 0: loss -2.00779 acc 0.65789 roc_auc 0.62462 prc_auc 0.72101[0m
[92maverage training of epoch 1: loss -2.40488 acc 0.66667 roc_auc 0.44920 prc_auc 0.63638[0m
[93maverage test of epoch 1: loss -2.76136 acc 0.65789 roc_auc 0.44923 prc_auc 0.62825[0m
[92maverage training of epoch 2: loss -3.11157 acc 0.66667 roc_auc 0.49700 prc_auc 0.67400[0m
[93maverage test of epoch 2: loss -3.38146 acc 0.65789 roc_auc 0.49231 prc_auc 0.72515[0m
[92maverage training of epoch 3: loss -3.68092 acc 0.66667 roc_auc 0.46180 prc_auc 0.65893[0m
[93maverage test of epoch 3: loss -3.96522 acc 0.65789 roc_auc 0.66462 prc_auc 0.78939[0m
[92maverage training of epoch 4: loss -4.27098 acc 0.66667 roc_auc 0.51640 prc_auc 0.69594[0m
[93maverage test of epoch 4: loss -4.53105 acc 0.65789 roc_auc 0.32615 prc_auc 0.56284[0m
[92maverage training of epoch 5: loss -4.89468 acc 0.66667 roc_auc 0.49760 prc_auc 0.67127[0m
[93maverage test of epoch 5: loss -5.18352 acc 0.65789 roc_auc 0.59692 prc_auc 0.77674[0m
[92maverage training of epoch 6: loss -5.55256 acc 0.66667 roc_auc 0.45180 prc_auc 0.64964[0m
[93maverage test of epoch 6: loss -5.87767 acc 0.65789 roc_auc 0.54462 prc_auc 0.71971[0m
[92maverage training of epoch 7: loss -6.25496 acc 0.66667 roc_auc 0.48820 prc_auc 0.66796[0m
[93maverage test of epoch 7: loss -6.56785 acc 0.65789 roc_auc 0.37692 prc_auc 0.64689[0m
[92maverage training of epoch 8: loss -6.99207 acc 0.66667 roc_auc 0.48320 prc_auc 0.65163[0m
[93maverage test of epoch 8: loss -7.32166 acc 0.65789 roc_auc 0.58000 prc_auc 0.74334[0m
[92maverage training of epoch 9: loss -7.75341 acc 0.66667 roc_auc 0.44420 prc_auc 0.62687[0m
[93maverage test of epoch 9: loss -8.11296 acc 0.65789 roc_auc 0.47538 prc_auc 0.68850[0m
[92maverage training of epoch 10: loss -8.53386 acc 0.66667 roc_auc 0.48140 prc_auc 0.65664[0m
[93maverage test of epoch 10: loss -8.90743 acc 0.65789 roc_auc 0.51385 prc_auc 0.69456[0m
[92maverage training of epoch 11: loss -9.34291 acc 0.66667 roc_auc 0.44700 prc_auc 0.64506[0m
[93maverage test of epoch 11: loss -9.73298 acc 0.65789 roc_auc 0.50000 prc_auc 0.71238[0m
[92maverage training of epoch 12: loss -10.20045 acc 0.66667 roc_auc 0.47020 prc_auc 0.65727[0m
[93maverage test of epoch 12: loss -10.59847 acc 0.65789 roc_auc 0.31231 prc_auc 0.61814[0m
[92maverage training of epoch 13: loss -11.08635 acc 0.66667 roc_auc 0.44240 prc_auc 0.62564[0m
[93maverage test of epoch 13: loss -11.47276 acc 0.65789 roc_auc 0.51692 prc_auc 0.64491[0m
[92maverage training of epoch 14: loss -11.99450 acc 0.66667 roc_auc 0.44640 prc_auc 0.63816[0m
[93maverage test of epoch 14: loss -12.40522 acc 0.65789 roc_auc 0.53077 prc_auc 0.67513[0m
[92maverage training of epoch 15: loss -12.92395 acc 0.66667 roc_auc 0.45730 prc_auc 0.63805[0m
[93maverage test of epoch 15: loss -13.33620 acc 0.65789 roc_auc 0.26462 prc_auc 0.54617[0m
[92maverage training of epoch 16: loss -13.89874 acc 0.66667 roc_auc 0.45130 prc_auc 0.63564[0m
[93maverage test of epoch 16: loss -14.33329 acc 0.65789 roc_auc 0.70615 prc_auc 0.78273[0m
[92maverage training of epoch 17: loss -14.88726 acc 0.66667 roc_auc 0.44170 prc_auc 0.63086[0m
[93maverage test of epoch 17: loss -15.32769 acc 0.65789 roc_auc 0.39231 prc_auc 0.60846[0m
[92maverage training of epoch 18: loss -15.91801 acc 0.66667 roc_auc 0.45300 prc_auc 0.64486[0m
[93maverage test of epoch 18: loss -16.37000 acc 0.65789 roc_auc 0.51231 prc_auc 0.70261[0m
[92maverage training of epoch 19: loss -16.96294 acc 0.66667 roc_auc 0.45800 prc_auc 0.63323[0m
[93maverage test of epoch 19: loss -17.43291 acc 0.65789 roc_auc 0.48769 prc_auc 0.66425[0m
[92maverage training of epoch 20: loss -18.06789 acc 0.66667 roc_auc 0.46740 prc_auc 0.65329[0m
[93maverage test of epoch 20: loss -18.53446 acc 0.65789 roc_auc 0.47231 prc_auc 0.64368[0m
[92maverage training of epoch 21: loss -19.17645 acc 0.66667 roc_auc 0.46830 prc_auc 0.65414[0m
[93maverage test of epoch 21: loss -19.66878 acc 0.65789 roc_auc 0.38769 prc_auc 0.61721[0m
[92maverage training of epoch 22: loss -20.33409 acc 0.66667 roc_auc 0.46800 prc_auc 0.65984[0m
[93maverage test of epoch 22: loss -20.82987 acc 0.65789 roc_auc 0.43077 prc_auc 0.61735[0m
[92maverage training of epoch 23: loss -21.49737 acc 0.66667 roc_auc 0.45540 prc_auc 0.64283[0m
[93maverage test of epoch 23: loss -22.00510 acc 0.65789 roc_auc 0.46308 prc_auc 0.63719[0m
[92maverage training of epoch 24: loss -22.69834 acc 0.66667 roc_auc 0.46340 prc_auc 0.65481[0m
[93maverage test of epoch 24: loss -23.21049 acc 0.65789 roc_auc 0.51231 prc_auc 0.66598[0m
[92maverage training of epoch 25: loss -23.92350 acc 0.66667 roc_auc 0.46160 prc_auc 0.64135[0m
[93maverage test of epoch 25: loss -24.44387 acc 0.65789 roc_auc 0.41231 prc_auc 0.62005[0m
[92maverage training of epoch 26: loss -25.17184 acc 0.66667 roc_auc 0.46000 prc_auc 0.64780[0m
[93maverage test of epoch 26: loss -25.70492 acc 0.65789 roc_auc 0.49692 prc_auc 0.65651[0m
[92maverage training of epoch 27: loss -26.45257 acc 0.66667 roc_auc 0.46320 prc_auc 0.64256[0m
[93maverage test of epoch 27: loss -26.99694 acc 0.65789 roc_auc 0.51846 prc_auc 0.66632[0m
[92maverage training of epoch 28: loss -27.76070 acc 0.66667 roc_auc 0.47930 prc_auc 0.65578[0m
[93maverage test of epoch 28: loss -28.31453 acc 0.65789 roc_auc 0.48000 prc_auc 0.64902[0m
[92maverage training of epoch 29: loss -29.09638 acc 0.66667 roc_auc 0.44340 prc_auc 0.63184[0m
[93maverage test of epoch 29: loss -29.66088 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -30.45885 acc 0.66667 roc_auc 0.45210 prc_auc 0.64340[0m
[93maverage test of epoch 30: loss -31.03775 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -31.85846 acc 0.66667 roc_auc 0.46670 prc_auc 0.65112[0m
[93maverage test of epoch 31: loss -32.44433 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -33.28309 acc 0.66667 roc_auc 0.46500 prc_auc 0.65244[0m
[93maverage test of epoch 32: loss -33.87827 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -34.73491 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 33: loss -35.34139 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -36.21917 acc 0.66667 roc_auc 0.42500 prc_auc 0.63772[0m
[93maverage test of epoch 34: loss -36.83249 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -37.73447 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -38.35957 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -39.27536 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -39.91318 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -40.85048 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -41.49317 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -42.45459 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -43.10986 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -44.08488 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -44.74761 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -45.74433 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -46.41427 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -47.42993 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -48.11148 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -49.14660 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -49.83118 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -50.88875 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -51.58898 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -52.66430 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -53.36649 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -54.46443 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -55.18165 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -56.29631 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -57.01971 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -58.15616 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -58.88756 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -60.04457 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -60.78367 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -61.96272 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -62.71033 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 50: loss -63.90946 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 50: loss -64.66015 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 51: loss -65.88498 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 51: loss -66.64804 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 52: loss -67.89092 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 52: loss -68.66441 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 53: loss -69.92604 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 53: loss -70.70663 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 54: loss -71.99092 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 54: loss -72.77911 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 55: loss -74.08493 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 55: loss -74.87970 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 56: loss -76.20698 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 56: loss -77.01352 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 57: loss -78.36202 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 57: loss -79.17323 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 58: loss -80.54543 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 58: loss -81.36568 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 59: loss -82.75742 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 59: loss -83.58593 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 60: loss -85.00011 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 60: loss -85.83699 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 61: loss -87.27291 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 61: loss -88.11598 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 62: loss -89.57353 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 62: loss -90.42503 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 63: loss -91.90559 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 63: loss -92.76357 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 64: loss -94.26516 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 64: loss -95.13433 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 65: loss -96.65730 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 65: loss -97.53209 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 66: loss -99.07836 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 66: loss -99.95923 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 67: loss -101.52797 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 67: loss -102.41755 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 68: loss -104.00951 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 68: loss -104.90425 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 69: loss -106.51878 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 69: loss -107.42186 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 70: loss -109.05881 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 70: loss -109.96729 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 71: loss -111.62882 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 71: loss -112.54377 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 72: loss -114.22778 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 72: loss -115.14995 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 73: loss -116.85635 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 73: loss -117.78627 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 74: loss -119.51585 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 74: loss -120.45128 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 75: loss -122.20483 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 75: loss -123.14768 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 76: loss -124.92296 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 76: loss -125.87249 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 77: loss -127.67162 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 77: loss -128.62712 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 78: loss -130.54287 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 78: loss -131.64474 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 79: loss -133.65305 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 79: loss -134.82554 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 80: loss -136.99729 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 80: loss -138.28445 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 81: loss -140.49717 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 81: loss -141.79680 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 82: loss -144.04363 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 82: loss -145.35810 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 83: loss -147.64191 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 83: loss -148.97232 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 84: loss -151.29374 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 84: loss -152.64039 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 85: loss -155.00019 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 85: loss -156.36365 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 86: loss -158.76236 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 86: loss -160.14275 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 87: loss -162.58215 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 87: loss -163.97911 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 88: loss -166.45837 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 88: loss -167.87148 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 89: loss -170.39251 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 89: loss -171.82394 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -174.38465 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 90: loss -175.83322 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 91: loss -178.43588 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 91: loss -179.90178 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 92: loss -182.54570 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 92: loss -184.02948 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 93: loss -186.71476 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 93: loss -188.21583 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 94: loss -190.94322 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 94: loss -192.46111 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 95: loss -195.23068 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 95: loss -196.76400 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 96: loss -199.57311 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 96: loss -201.12051 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 97: loss -203.96822 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 97: loss -205.52791 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 98: loss -208.41415 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 98: loss -209.98618 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -212.91206 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 99: loss -214.49709 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss 0.44401 acc 0.33333 roc_auc 0.42860 prc_auc 0.64055[0m
[93maverage test of epoch 0: loss 0.06805 acc 0.34211 roc_auc 0.31077 prc_auc 0.55617[0m
[92maverage training of epoch 1: loss -0.13782 acc 0.47333 roc_auc 0.43380 prc_auc 0.62993[0m
[93maverage test of epoch 1: loss -0.32117 acc 0.65789 roc_auc 0.48923 prc_auc 0.66779[0m
[92maverage training of epoch 2: loss -0.52551 acc 0.66667 roc_auc 0.43500 prc_auc 0.63436[0m
[93maverage test of epoch 2: loss -0.73576 acc 0.65789 roc_auc 0.52000 prc_auc 0.73493[0m
[92maverage training of epoch 3: loss -0.93288 acc 0.66667 roc_auc 0.41660 prc_auc 0.62562[0m
[93maverage test of epoch 3: loss -1.13525 acc 0.65789 roc_auc 0.56923 prc_auc 0.71711[0m
[92maverage training of epoch 4: loss -1.28444 acc 0.66667 roc_auc 0.45840 prc_auc 0.63611[0m
[93maverage test of epoch 4: loss -1.44107 acc 0.65789 roc_auc 0.65846 prc_auc 0.77823[0m
[92maverage training of epoch 5: loss -1.61957 acc 0.66667 roc_auc 0.42420 prc_auc 0.62711[0m
[93maverage test of epoch 5: loss -1.81256 acc 0.65789 roc_auc 0.58769 prc_auc 0.75132[0m
[92maverage training of epoch 6: loss -2.05816 acc 0.66667 roc_auc 0.46880 prc_auc 0.64095[0m
[93maverage test of epoch 6: loss -2.31273 acc 0.65789 roc_auc 0.32923 prc_auc 0.61217[0m
[92maverage training of epoch 7: loss -2.67530 acc 0.66667 roc_auc 0.44100 prc_auc 0.65359[0m
[93maverage test of epoch 7: loss -3.22218 acc 0.65789 roc_auc 0.52308 prc_auc 0.70633[0m
[92maverage training of epoch 8: loss -3.78938 acc 0.66667 roc_auc 0.43760 prc_auc 0.64229[0m
[93maverage test of epoch 8: loss -4.28670 acc 0.65789 roc_auc 0.48308 prc_auc 0.68241[0m
[92maverage training of epoch 9: loss -4.77238 acc 0.66667 roc_auc 0.45780 prc_auc 0.65541[0m
[93maverage test of epoch 9: loss -5.21910 acc 0.65789 roc_auc 0.52308 prc_auc 0.69871[0m
[92maverage training of epoch 10: loss -5.64880 acc 0.66667 roc_auc 0.42020 prc_auc 0.61971[0m
[93maverage test of epoch 10: loss -6.06602 acc 0.65789 roc_auc 0.48923 prc_auc 0.68891[0m
[92maverage training of epoch 11: loss -6.50627 acc 0.66667 roc_auc 0.41680 prc_auc 0.62421[0m
[93maverage test of epoch 11: loss -6.90575 acc 0.65789 roc_auc 0.52615 prc_auc 0.72458[0m
[92maverage training of epoch 12: loss -7.37130 acc 0.66667 roc_auc 0.43140 prc_auc 0.63982[0m
[93maverage test of epoch 12: loss -7.76721 acc 0.65789 roc_auc 0.60615 prc_auc 0.75639[0m
[92maverage training of epoch 13: loss -8.23600 acc 0.66667 roc_auc 0.41020 prc_auc 0.60972[0m
[93maverage test of epoch 13: loss -8.62902 acc 0.65789 roc_auc 0.36000 prc_auc 0.58052[0m
[92maverage training of epoch 14: loss -9.11837 acc 0.66667 roc_auc 0.45190 prc_auc 0.64393[0m
[93maverage test of epoch 14: loss -9.52304 acc 0.65789 roc_auc 0.30308 prc_auc 0.58064[0m
[92maverage training of epoch 15: loss -10.01388 acc 0.66667 roc_auc 0.41240 prc_auc 0.62217[0m
[93maverage test of epoch 15: loss -10.42444 acc 0.65789 roc_auc 0.66000 prc_auc 0.76606[0m
[92maverage training of epoch 16: loss -10.93808 acc 0.66667 roc_auc 0.43920 prc_auc 0.64306[0m
[93maverage test of epoch 16: loss -11.35593 acc 0.65789 roc_auc 0.36000 prc_auc 0.63801[0m
[92maverage training of epoch 17: loss -11.86238 acc 0.66667 roc_auc 0.43920 prc_auc 0.65212[0m
[93maverage test of epoch 17: loss -12.29247 acc 0.65789 roc_auc 0.43846 prc_auc 0.64302[0m
[92maverage training of epoch 18: loss -12.83603 acc 0.66667 roc_auc 0.43520 prc_auc 0.64266[0m
[93maverage test of epoch 18: loss -13.27698 acc 0.65789 roc_auc 0.53077 prc_auc 0.69012[0m
[92maverage training of epoch 19: loss -13.82095 acc 0.66667 roc_auc 0.43910 prc_auc 0.63925[0m
[93maverage test of epoch 19: loss -14.26011 acc 0.65789 roc_auc 0.44769 prc_auc 0.62025[0m
[92maverage training of epoch 20: loss -14.83310 acc 0.66667 roc_auc 0.42920 prc_auc 0.63493[0m
[93maverage test of epoch 20: loss -15.29566 acc 0.65789 roc_auc 0.44615 prc_auc 0.65965[0m
[92maverage training of epoch 21: loss -15.88687 acc 0.66667 roc_auc 0.43570 prc_auc 0.64314[0m
[93maverage test of epoch 21: loss -16.33912 acc 0.65789 roc_auc 0.43385 prc_auc 0.62651[0m
[92maverage training of epoch 22: loss -16.95382 acc 0.66667 roc_auc 0.42620 prc_auc 0.62421[0m
[93maverage test of epoch 22: loss -17.43184 acc 0.65789 roc_auc 0.51692 prc_auc 0.67705[0m
[92maverage training of epoch 23: loss -18.06141 acc 0.66667 roc_auc 0.43510 prc_auc 0.63455[0m
[93maverage test of epoch 23: loss -18.53894 acc 0.65789 roc_auc 0.48769 prc_auc 0.65386[0m
[92maverage training of epoch 24: loss -19.18779 acc 0.66667 roc_auc 0.44410 prc_auc 0.65064[0m
[93maverage test of epoch 24: loss -19.68913 acc 0.65789 roc_auc 0.28462 prc_auc 0.56188[0m
[92maverage training of epoch 25: loss -20.35219 acc 0.66667 roc_auc 0.44430 prc_auc 0.64415[0m
[93maverage test of epoch 25: loss -20.85029 acc 0.65789 roc_auc 0.44154 prc_auc 0.63206[0m
[92maverage training of epoch 26: loss -21.54074 acc 0.66667 roc_auc 0.44230 prc_auc 0.63653[0m
[93maverage test of epoch 26: loss -22.05471 acc 0.65789 roc_auc 0.50154 prc_auc 0.65957[0m
[92maverage training of epoch 27: loss -22.75448 acc 0.66667 roc_auc 0.43830 prc_auc 0.62773[0m
[93maverage test of epoch 27: loss -23.27702 acc 0.65789 roc_auc 0.52308 prc_auc 0.66847[0m
[92maverage training of epoch 28: loss -24.00103 acc 0.66667 roc_auc 0.43370 prc_auc 0.62588[0m
[93maverage test of epoch 28: loss -24.53955 acc 0.65789 roc_auc 0.42000 prc_auc 0.62409[0m
[92maverage training of epoch 29: loss -25.27797 acc 0.66667 roc_auc 0.43600 prc_auc 0.62954[0m
[93maverage test of epoch 29: loss -25.81518 acc 0.65789 roc_auc 0.55538 prc_auc 0.68395[0m
[92maverage training of epoch 30: loss -26.58424 acc 0.66667 roc_auc 0.44940 prc_auc 0.64769[0m
[93maverage test of epoch 30: loss -27.13124 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -27.91366 acc 0.66667 roc_auc 0.41290 prc_auc 0.62171[0m
[93maverage test of epoch 31: loss -28.47251 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -29.27676 acc 0.66667 roc_auc 0.43090 prc_auc 0.63558[0m
[93maverage test of epoch 32: loss -29.84819 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -30.66685 acc 0.66667 roc_auc 0.43000 prc_auc 0.63780[0m
[93maverage test of epoch 33: loss -31.24936 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -32.08919 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -32.67612 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -33.54005 acc 0.66667 roc_auc 0.48000 prc_auc 0.65792[0m
[93maverage test of epoch 35: loss -34.14362 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -35.02127 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -35.63035 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -36.53492 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -37.15231 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -38.07760 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -38.70133 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -39.64584 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -40.28019 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -41.24378 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -41.88364 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -42.86825 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -43.51280 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -44.52002 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -45.17845 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -46.19824 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -46.86463 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -47.90583 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -48.57809 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -49.64135 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -50.32373 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -51.40725 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -52.09314 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -53.19938 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -53.89929 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -55.02198 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -55.72704 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -56.87276 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -57.58037 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 50: loss -58.75311 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 50: loss -59.47144 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 51: loss -60.66178 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 51: loss -61.39058 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 52: loss -62.59938 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 52: loss -63.33484 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 53: loss -64.56909 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 53: loss -65.31311 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 54: loss -66.56588 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 54: loss -67.31732 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 55: loss -68.59190 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 55: loss -69.35313 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 56: loss -70.64892 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 56: loss -71.41496 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 57: loss -72.73446 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 57: loss -73.50971 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 58: loss -74.84921 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 58: loss -75.62984 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 59: loss -76.99359 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 59: loss -77.78504 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 60: loss -79.16916 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 60: loss -79.96490 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 61: loss -81.37297 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 61: loss -82.17757 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 62: loss -83.60672 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 62: loss -84.41803 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 63: loss -85.87038 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 63: loss -86.68645 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 64: loss -88.16311 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 64: loss -88.98855 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 65: loss -90.48557 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 65: loss -91.31753 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 66: loss -92.83813 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 66: loss -93.67838 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 67: loss -95.22042 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 67: loss -96.06754 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 68: loss -97.63225 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 68: loss -98.48565 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 69: loss -100.07375 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 69: loss -100.93301 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 70: loss -102.54577 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 70: loss -103.41255 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 71: loss -105.04576 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 71: loss -105.91934 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 72: loss -107.57705 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 72: loss -108.45768 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 73: loss -110.13922 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 73: loss -111.02348 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 74: loss -112.72951 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 74: loss -113.62139 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 75: loss -115.34970 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 75: loss -116.24826 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 76: loss -117.99986 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 76: loss -118.90250 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 77: loss -120.67952 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 77: loss -121.58979 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 78: loss -123.38858 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 78: loss -124.30510 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 79: loss -126.12814 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 79: loss -127.05055 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 80: loss -128.89742 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 80: loss -129.82509 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 81: loss -131.69642 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 81: loss -132.62992 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 82: loss -134.52464 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 82: loss -135.46390 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 83: loss -137.38378 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 83: loss -138.32791 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 84: loss -140.27217 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 84: loss -141.22194 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 85: loss -143.19024 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 85: loss -144.14481 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 86: loss -146.13829 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 86: loss -147.09882 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 87: loss -149.11558 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 87: loss -150.08136 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 88: loss -152.12375 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 88: loss -153.09461 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 89: loss -155.16123 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 89: loss -156.13675 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -158.22825 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 90: loss -159.20896 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 91: loss -161.32544 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 91: loss -162.31070 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 92: loss -164.45219 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 92: loss -165.44240 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 93: loss -167.60898 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 93: loss -168.60395 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 94: loss -170.79554 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 94: loss -171.79430 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 95: loss -174.01199 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 95: loss -175.01570 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 96: loss -177.25793 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 96: loss -178.26608 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 97: loss -180.53391 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 97: loss -181.54636 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 98: loss -183.83969 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 98: loss -184.85636 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -187.17512 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 99: loss -188.19627 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.18408 acc 0.66225 roc_auc 0.43725 prc_auc 0.62073[0m
[93maverage test of epoch 0: loss -0.67907 acc 0.67568 roc_auc 0.41667 prc_auc 0.66330[0m
[92maverage training of epoch 1: loss -1.35656 acc 0.66225 roc_auc 0.41922 prc_auc 0.62708[0m
[93maverage test of epoch 1: loss -2.34123 acc 0.67568 roc_auc 0.51333 prc_auc 0.75220[0m
[92maverage training of epoch 2: loss -3.28153 acc 0.66225 roc_auc 0.45078 prc_auc 0.64251[0m
[93maverage test of epoch 2: loss -4.36598 acc 0.67568 roc_auc 0.51667 prc_auc 0.73826[0m
[92maverage training of epoch 3: loss -5.12364 acc 0.66225 roc_auc 0.43686 prc_auc 0.61888[0m
[93maverage test of epoch 3: loss -6.03532 acc 0.67568 roc_auc 0.68000 prc_auc 0.83490[0m
[92maverage training of epoch 4: loss -6.59967 acc 0.66225 roc_auc 0.44196 prc_auc 0.63482[0m
[93maverage test of epoch 4: loss -7.44569 acc 0.67568 roc_auc 0.70667 prc_auc 0.86801[0m
[92maverage training of epoch 5: loss -7.95102 acc 0.66225 roc_auc 0.42471 prc_auc 0.61380[0m
[93maverage test of epoch 5: loss -8.73212 acc 0.67568 roc_auc 0.49000 prc_auc 0.68941[0m
[92maverage training of epoch 6: loss -9.19220 acc 0.66225 roc_auc 0.39618 prc_auc 0.59177[0m
[93maverage test of epoch 6: loss -9.98620 acc 0.67568 roc_auc 0.59500 prc_auc 0.73503[0m
[92maverage training of epoch 7: loss -10.41700 acc 0.66225 roc_auc 0.40706 prc_auc 0.60339[0m
[93maverage test of epoch 7: loss -11.18683 acc 0.67568 roc_auc 0.54500 prc_auc 0.72282[0m
[92maverage training of epoch 8: loss -11.61394 acc 0.66225 roc_auc 0.40353 prc_auc 0.59466[0m
[93maverage test of epoch 8: loss -12.40700 acc 0.67568 roc_auc 0.49000 prc_auc 0.68662[0m
[92maverage training of epoch 9: loss -12.83196 acc 0.66225 roc_auc 0.45549 prc_auc 0.62929[0m
[93maverage test of epoch 9: loss -13.62708 acc 0.67568 roc_auc 0.50500 prc_auc 0.68513[0m
[92maverage training of epoch 10: loss -14.03800 acc 0.66225 roc_auc 0.44020 prc_auc 0.62770[0m
[93maverage test of epoch 10: loss -14.85462 acc 0.67568 roc_auc 0.52667 prc_auc 0.68827[0m
[92maverage training of epoch 11: loss -15.29502 acc 0.66225 roc_auc 0.43627 prc_auc 0.62638[0m
[93maverage test of epoch 11: loss -16.12301 acc 0.67568 roc_auc 0.54667 prc_auc 0.69698[0m
[92maverage training of epoch 12: loss -16.54834 acc 0.66225 roc_auc 0.44049 prc_auc 0.63349[0m
[93maverage test of epoch 12: loss -17.41646 acc 0.67568 roc_auc 0.50167 prc_auc 0.67641[0m
[92maverage training of epoch 13: loss -17.84943 acc 0.66225 roc_auc 0.51490 prc_auc 0.66905[0m
[93maverage test of epoch 13: loss -18.73914 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 14: loss -19.17227 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 14: loss -20.06472 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 15: loss -20.52098 acc 0.66225 roc_auc 0.47324 prc_auc 0.65055[0m
[93maverage test of epoch 15: loss -21.45774 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 16: loss -21.92668 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 16: loss -22.89778 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 17: loss -23.36544 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 17: loss -24.36270 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 18: loss -24.84419 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 18: loss -25.85017 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 19: loss -26.35852 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 19: loss -27.42088 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 20: loss -27.91236 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 20: loss -29.01780 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 21: loss -29.52161 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 21: loss -30.64749 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 22: loss -31.16476 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 22: loss -32.32502 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 23: loss -32.85694 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 23: loss -34.03712 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 24: loss -34.58817 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 24: loss -35.81214 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 25: loss -36.36461 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 25: loss -37.63334 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 26: loss -38.19222 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 26: loss -39.48215 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 27: loss -40.05818 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 27: loss -41.39340 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 28: loss -41.97759 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 28: loss -43.34827 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 29: loss -43.94007 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 29: loss -45.34946 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 30: loss -45.95529 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 30: loss -47.40239 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 31: loss -48.01380 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 31: loss -49.49226 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 32: loss -50.11697 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 32: loss -51.63781 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 33: loss -52.27529 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 33: loss -53.82096 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 34: loss -54.46857 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 34: loss -56.06496 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 35: loss -56.72696 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 35: loss -58.36199 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 36: loss -59.02353 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 36: loss -60.70235 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 37: loss -61.37276 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 37: loss -63.08305 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 38: loss -63.76531 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 38: loss -65.51607 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 39: loss -66.20443 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 39: loss -67.99047 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -68.68869 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 40: loss -70.51891 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -71.22241 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 41: loss -73.09061 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -73.79705 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 42: loss -75.71338 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -76.42672 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 43: loss -78.37289 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -79.09431 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 44: loss -81.08488 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -81.81462 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 45: loss -83.84483 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -84.58022 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 46: loss -86.65022 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -87.39146 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 47: loss -89.50438 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -90.25025 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 48: loss -92.40618 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -93.15827 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 49: loss -95.35505 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 50: loss -96.11125 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 50: loss -98.34923 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 51: loss -99.11366 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 51: loss -101.39489 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 52: loss -102.16166 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 52: loss -104.48638 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 53: loss -105.25912 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 53: loss -107.62592 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 54: loss -108.40114 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 54: loss -110.81107 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 55: loss -111.59173 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 55: loss -114.04237 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 56: loss -114.83100 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 56: loss -117.32392 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 57: loss -118.11385 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 57: loss -120.65393 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 58: loss -121.44623 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 58: loss -124.02995 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 59: loss -124.82486 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 59: loss -127.45105 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 60: loss -128.25090 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 60: loss -130.91944 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 61: loss -131.72257 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 61: loss -134.43704 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 62: loss -135.24082 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 62: loss -137.99995 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 63: loss -138.80770 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 63: loss -141.60841 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 64: loss -142.41993 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 64: loss -145.26161 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 65: loss -146.07385 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 65: loss -148.96164 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 66: loss -149.77093 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 66: loss -152.70056 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 67: loss -153.51079 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 67: loss -156.48303 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 68: loss -157.29210 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 68: loss -160.30818 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 69: loss -161.11612 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 69: loss -164.17344 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 70: loss -164.98485 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 70: loss -168.08674 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 71: loss -168.89555 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 71: loss -172.04253 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 72: loss -172.85086 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 72: loss -176.04222 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 73: loss -176.84943 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 73: loss -180.08512 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 74: loss -180.89263 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 74: loss -184.17304 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 75: loss -184.97925 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 75: loss -188.30451 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 76: loss -189.11132 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 76: loss -192.48080 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 77: loss -193.28657 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 77: loss -196.70305 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 78: loss -197.50752 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 78: loss -200.96967 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 79: loss -201.77296 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 79: loss -205.28081 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 80: loss -206.08259 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 80: loss -209.63726 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 81: loss -210.43716 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 81: loss -214.03697 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 82: loss -214.83676 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 82: loss -218.48460 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 83: loss -219.28154 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 83: loss -222.97654 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 84: loss -223.77102 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 84: loss -227.51289 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 85: loss -228.30554 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 85: loss -232.09448 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 86: loss -232.88498 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 86: loss -236.72120 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 87: loss -237.50928 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 87: loss -241.39403 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 88: loss -242.17914 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 88: loss -246.11196 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 89: loss -246.89402 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 89: loss -250.87494 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 90: loss -251.65408 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 90: loss -255.68353 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 91: loss -256.45969 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 91: loss -260.53784 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 92: loss -261.31023 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 92: loss -265.43702 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 93: loss -266.20616 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 93: loss -270.38144 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 94: loss -271.14605 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 94: loss -275.37034 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 95: loss -276.13146 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 95: loss -280.40519 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 96: loss -281.16173 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 96: loss -285.48518 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 97: loss -286.23737 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 97: loss -290.61036 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 98: loss -291.35844 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 98: loss -295.78082 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 99: loss -296.52391 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 99: loss -300.99691 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss 0.18777 acc 0.33775 roc_auc 0.57529 prc_auc 0.71520[0m
[93maverage test of epoch 0: loss 0.11966 acc 0.32432 roc_auc 0.39333 prc_auc 0.66705[0m
[92maverage training of epoch 1: loss 0.01168 acc 0.33775 roc_auc 0.53882 prc_auc 0.67075[0m
[93maverage test of epoch 1: loss -0.07623 acc 0.32432 roc_auc 0.51667 prc_auc 0.72684[0m
[92maverage training of epoch 2: loss -0.21769 acc 0.33775 roc_auc 0.57255 prc_auc 0.69485[0m
[93maverage test of epoch 2: loss -0.35917 acc 0.32432 roc_auc 0.43000 prc_auc 0.73993[0m
[92maverage training of epoch 3: loss -0.53689 acc 0.33775 roc_auc 0.57765 prc_auc 0.72275[0m
[93maverage test of epoch 3: loss -0.68863 acc 0.32432 roc_auc 0.59667 prc_auc 0.77680[0m
[92maverage training of epoch 4: loss -0.91929 acc 0.33775 roc_auc 0.57373 prc_auc 0.68754[0m
[93maverage test of epoch 4: loss -1.09001 acc 0.32432 roc_auc 0.39000 prc_auc 0.62347[0m
[92maverage training of epoch 5: loss -1.39937 acc 0.33775 roc_auc 0.41647 prc_auc 0.63476[0m
[93maverage test of epoch 5: loss -1.62178 acc 0.32432 roc_auc 0.50667 prc_auc 0.65758[0m
[92maverage training of epoch 6: loss -1.86902 acc 0.33775 roc_auc 0.41314 prc_auc 0.61263[0m
[93maverage test of epoch 6: loss -2.07433 acc 0.32432 roc_auc 0.44667 prc_auc 0.63433[0m
[92maverage training of epoch 7: loss -2.34666 acc 0.33775 roc_auc 0.44078 prc_auc 0.63252[0m
[93maverage test of epoch 7: loss -2.58629 acc 0.32432 roc_auc 0.57333 prc_auc 0.77507[0m
[92maverage training of epoch 8: loss -2.86604 acc 0.33775 roc_auc 0.50235 prc_auc 0.68206[0m
[93maverage test of epoch 8: loss -3.13443 acc 0.32432 roc_auc 0.51667 prc_auc 0.75479[0m
[92maverage training of epoch 9: loss -3.44883 acc 0.33775 roc_auc 0.46627 prc_auc 0.68249[0m
[93maverage test of epoch 9: loss -3.74577 acc 0.32432 roc_auc 0.53333 prc_auc 0.70062[0m
[92maverage training of epoch 10: loss -4.09255 acc 0.33775 roc_auc 0.40922 prc_auc 0.61531[0m
[93maverage test of epoch 10: loss -4.40797 acc 0.32432 roc_auc 0.42000 prc_auc 0.66247[0m
[92maverage training of epoch 11: loss -4.79768 acc 0.33775 roc_auc 0.41961 prc_auc 0.60849[0m
[93maverage test of epoch 11: loss -5.14205 acc 0.32432 roc_auc 0.43333 prc_auc 0.64287[0m
[92maverage training of epoch 12: loss -5.55869 acc 0.33775 roc_auc 0.56059 prc_auc 0.72035[0m
[93maverage test of epoch 12: loss -5.92072 acc 0.32432 roc_auc 0.47333 prc_auc 0.73791[0m
[92maverage training of epoch 13: loss -6.34942 acc 0.33775 roc_auc 0.45863 prc_auc 0.63706[0m
[93maverage test of epoch 13: loss -6.73847 acc 0.32432 roc_auc 0.31333 prc_auc 0.57662[0m
[92maverage training of epoch 14: loss -7.18544 acc 0.33775 roc_auc 0.43912 prc_auc 0.60795[0m
[93maverage test of epoch 14: loss -7.60040 acc 0.32432 roc_auc 0.49333 prc_auc 0.70000[0m
[92maverage training of epoch 15: loss -8.06720 acc 0.33775 roc_auc 0.44608 prc_auc 0.64221[0m
[93maverage test of epoch 15: loss -8.50485 acc 0.32432 roc_auc 0.35000 prc_auc 0.63583[0m
[92maverage training of epoch 16: loss -8.99064 acc 0.33775 roc_auc 0.46059 prc_auc 0.67139[0m
[93maverage test of epoch 16: loss -9.44024 acc 0.32432 roc_auc 0.41833 prc_auc 0.62385[0m
[92maverage training of epoch 17: loss -9.96066 acc 0.33775 roc_auc 0.38961 prc_auc 0.60491[0m
[93maverage test of epoch 17: loss -10.43441 acc 0.32432 roc_auc 0.62333 prc_auc 0.76587[0m
[92maverage training of epoch 18: loss -10.97497 acc 0.33775 roc_auc 0.40902 prc_auc 0.61668[0m
[93maverage test of epoch 18: loss -11.48060 acc 0.32432 roc_auc 0.09333 prc_auc 0.49319[0m
[92maverage training of epoch 19: loss -12.03310 acc 0.33775 roc_auc 0.39216 prc_auc 0.59348[0m
[93maverage test of epoch 19: loss -12.55735 acc 0.32432 roc_auc 0.54000 prc_auc 0.77838[0m
[92maverage training of epoch 20: loss -13.13696 acc 0.33775 roc_auc 0.38431 prc_auc 0.58810[0m
[93maverage test of epoch 20: loss -13.68571 acc 0.32432 roc_auc 0.47333 prc_auc 0.73012[0m
[92maverage training of epoch 21: loss -14.29035 acc 0.33775 roc_auc 0.38941 prc_auc 0.59524[0m
[93maverage test of epoch 21: loss -14.85199 acc 0.32432 roc_auc 0.52333 prc_auc 0.73247[0m
[92maverage training of epoch 22: loss -15.48368 acc 0.33775 roc_auc 0.38176 prc_auc 0.58920[0m
[93maverage test of epoch 22: loss -16.07739 acc 0.32432 roc_auc 0.57500 prc_auc 0.73374[0m
[92maverage training of epoch 23: loss -16.71842 acc 0.33775 roc_auc 0.37725 prc_auc 0.57603[0m
[93maverage test of epoch 23: loss -17.33581 acc 0.32432 roc_auc 0.52000 prc_auc 0.69794[0m
[92maverage training of epoch 24: loss -17.99339 acc 0.33775 roc_auc 0.37706 prc_auc 0.57644[0m
[93maverage test of epoch 24: loss -18.64061 acc 0.32432 roc_auc 0.58667 prc_auc 0.72996[0m
[92maverage training of epoch 25: loss -19.31061 acc 0.33775 roc_auc 0.36069 prc_auc 0.56319[0m
[93maverage test of epoch 25: loss -19.97885 acc 0.32432 roc_auc 0.40167 prc_auc 0.63496[0m
[92maverage training of epoch 26: loss -20.66991 acc 0.33775 roc_auc 0.36804 prc_auc 0.57361[0m
[93maverage test of epoch 26: loss -21.36441 acc 0.32432 roc_auc 0.58667 prc_auc 0.75313[0m
[92maverage training of epoch 27: loss -22.07190 acc 0.33775 roc_auc 0.36098 prc_auc 0.56176[0m
[93maverage test of epoch 27: loss -22.78752 acc 0.32432 roc_auc 0.38333 prc_auc 0.65170[0m
[92maverage training of epoch 28: loss -23.51873 acc 0.33775 roc_auc 0.36353 prc_auc 0.56066[0m
[93maverage test of epoch 28: loss -24.26286 acc 0.32432 roc_auc 0.64833 prc_auc 0.81970[0m
[92maverage training of epoch 29: loss -25.00675 acc 0.53642 roc_auc 0.36765 prc_auc 0.57229[0m
[93maverage test of epoch 29: loss -25.76973 acc 0.67568 roc_auc 0.43500 prc_auc 0.63715[0m
[92maverage training of epoch 30: loss -26.53083 acc 0.66225 roc_auc 0.36814 prc_auc 0.58019[0m
[93maverage test of epoch 30: loss -27.32723 acc 0.67568 roc_auc 0.62167 prc_auc 0.74815[0m
[92maverage training of epoch 31: loss -28.09978 acc 0.66225 roc_auc 0.36745 prc_auc 0.56897[0m
[93maverage test of epoch 31: loss -28.91894 acc 0.67568 roc_auc 0.36333 prc_auc 0.59759[0m
[92maverage training of epoch 32: loss -29.70701 acc 0.66225 roc_auc 0.36941 prc_auc 0.56980[0m
[93maverage test of epoch 32: loss -30.55444 acc 0.67568 roc_auc 0.55833 prc_auc 0.68620[0m
[92maverage training of epoch 33: loss -31.35625 acc 0.66225 roc_auc 0.37098 prc_auc 0.57059[0m
[93maverage test of epoch 33: loss -32.22540 acc 0.67568 roc_auc 0.40667 prc_auc 0.64044[0m
[92maverage training of epoch 34: loss -33.04509 acc 0.66225 roc_auc 0.37255 prc_auc 0.57445[0m
[93maverage test of epoch 34: loss -33.93904 acc 0.67568 roc_auc 0.54333 prc_auc 0.70350[0m
[92maverage training of epoch 35: loss -34.77511 acc 0.66225 roc_auc 0.37451 prc_auc 0.57535[0m
[93maverage test of epoch 35: loss -35.70167 acc 0.67568 roc_auc 0.51667 prc_auc 0.69320[0m
[92maverage training of epoch 36: loss -36.54834 acc 0.66225 roc_auc 0.37637 prc_auc 0.57639[0m
[93maverage test of epoch 36: loss -37.50376 acc 0.67568 roc_auc 0.44167 prc_auc 0.66044[0m
[92maverage training of epoch 37: loss -38.36462 acc 0.66225 roc_auc 0.37882 prc_auc 0.57832[0m
[93maverage test of epoch 37: loss -39.34650 acc 0.67568 roc_auc 0.35167 prc_auc 0.65300[0m
[92maverage training of epoch 38: loss -40.22761 acc 0.66225 roc_auc 0.38078 prc_auc 0.58008[0m
[93maverage test of epoch 38: loss -41.23898 acc 0.67568 roc_auc 0.65000 prc_auc 0.77880[0m
[92maverage training of epoch 39: loss -42.13536 acc 0.66225 roc_auc 0.38147 prc_auc 0.57926[0m
[93maverage test of epoch 39: loss -43.17644 acc 0.67568 roc_auc 0.56500 prc_auc 0.73007[0m
[92maverage training of epoch 40: loss -44.18389 acc 0.66225 roc_auc 0.38471 prc_auc 0.58271[0m
[93maverage test of epoch 40: loss -45.40246 acc 0.67568 roc_auc 0.41167 prc_auc 0.62735[0m
[92maverage training of epoch 41: loss -46.47935 acc 0.66225 roc_auc 0.38529 prc_auc 0.58498[0m
[93maverage test of epoch 41: loss -47.74418 acc 0.67568 roc_auc 0.46000 prc_auc 0.65967[0m
[92maverage training of epoch 42: loss -48.83542 acc 0.66225 roc_auc 0.38353 prc_auc 0.58364[0m
[93maverage test of epoch 42: loss -50.13824 acc 0.67568 roc_auc 0.56500 prc_auc 0.72838[0m
[92maverage training of epoch 43: loss -51.24922 acc 0.66225 roc_auc 0.38578 prc_auc 0.58554[0m
[93maverage test of epoch 43: loss -52.58897 acc 0.67568 roc_auc 0.67333 prc_auc 0.77742[0m
[92maverage training of epoch 44: loss -53.71971 acc 0.66225 roc_auc 0.38588 prc_auc 0.58585[0m
[93maverage test of epoch 44: loss -55.09987 acc 0.67568 roc_auc 0.47000 prc_auc 0.65969[0m
[92maverage training of epoch 45: loss -56.24902 acc 0.66225 roc_auc 0.38569 prc_auc 0.59154[0m
[93maverage test of epoch 45: loss -57.67098 acc 0.67568 roc_auc 0.44167 prc_auc 0.64794[0m
[92maverage training of epoch 46: loss -58.83899 acc 0.66225 roc_auc 0.38539 prc_auc 0.58451[0m
[93maverage test of epoch 46: loss -60.30333 acc 0.67568 roc_auc 0.54333 prc_auc 0.69527[0m
[92maverage training of epoch 47: loss -61.48897 acc 0.66225 roc_auc 0.38843 prc_auc 0.58577[0m
[93maverage test of epoch 47: loss -62.99483 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -64.19967 acc 0.66225 roc_auc 0.38598 prc_auc 0.58324[0m
[93maverage test of epoch 48: loss -65.74670 acc 0.67568 roc_auc 0.52500 prc_auc 0.68686[0m
[92maverage training of epoch 49: loss -66.97229 acc 0.66225 roc_auc 0.39431 prc_auc 0.58779[0m
[93maverage test of epoch 49: loss -68.56412 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 50: loss -69.80619 acc 0.66225 roc_auc 0.40343 prc_auc 0.59541[0m
[93maverage test of epoch 50: loss -71.44161 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 51: loss -72.70307 acc 0.66225 roc_auc 0.40284 prc_auc 0.60447[0m
[93maverage test of epoch 51: loss -74.38041 acc 0.67568 roc_auc 0.42333 prc_auc 0.64436[0m
[92maverage training of epoch 52: loss -75.66193 acc 0.66225 roc_auc 0.39794 prc_auc 0.60726[0m
[93maverage test of epoch 52: loss -77.38456 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 53: loss -78.68477 acc 0.66225 roc_auc 0.41020 prc_auc 0.62092[0m
[93maverage test of epoch 53: loss -80.45265 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 54: loss -81.76869 acc 0.66225 roc_auc 0.48559 prc_auc 0.65738[0m
[93maverage test of epoch 54: loss -83.58208 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 55: loss -84.91597 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 55: loss -86.77374 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 56: loss -88.12760 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 56: loss -90.03081 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 57: loss -91.40010 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 57: loss -93.34947 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 58: loss -94.73186 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 58: loss -96.72521 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 59: loss -98.12156 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 59: loss -100.15760 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0mUsing backend: pytorch

[92maverage training of epoch 60: loss -101.57164 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 60: loss -103.65550 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 61: loss -105.08056 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 61: loss -107.21035 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 62: loss -108.65070 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 62: loss -110.82755 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 63: loss -112.28165 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 63: loss -114.50526 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 64: loss -115.97430 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 64: loss -118.24686 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 65: loss -119.72853 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 65: loss -122.04621 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 66: loss -123.54378 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 66: loss -125.91143 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 67: loss -127.42202 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 67: loss -129.83723 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 68: loss -131.36069 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 68: loss -133.82501 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 69: loss -135.35978 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 69: loss -137.87214 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 70: loss -139.41858 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 70: loss -141.97881 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 71: loss -143.53695 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 71: loss -146.14589 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 72: loss -147.71596 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 72: loss -150.37413 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 73: loss -151.95481 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 73: loss -154.66223 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 74: loss -156.25381 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 74: loss -159.01090 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 75: loss -160.61351 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 75: loss -163.41922 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 76: loss -165.03086 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 76: loss -167.88400 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 77: loss -169.50297 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 77: loss -172.40404 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 78: loss -174.03130 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 78: loss -176.98079 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 79: loss -178.61673 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 79: loss -181.61416 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 80: loss -183.25894 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 80: loss -186.30633 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 81: loss -187.95896 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 81: loss -191.05627 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 82: loss -192.71716 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 82: loss -195.86400 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 83: loss -197.53367 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 83: loss -200.73085 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 84: loss -202.40793 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 84: loss -205.65708 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 85: loss -207.34215 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 85: loss -210.64158 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 86: loss -212.33490 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 86: loss -215.68581 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 87: loss -217.38674 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 87: loss -220.78950 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 88: loss -222.49824 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 88: loss -225.95332 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 89: loss -227.66894 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 89: loss -231.17604 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 90: loss -232.89918 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 90: loss -236.45949 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 91: loss -238.18927 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 91: loss -241.80264 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 92: loss -243.53896 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 92: loss -247.20561 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 93: loss -248.94844 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 93: loss -252.66819 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 94: loss -254.41758 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 94: loss -258.19177 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 95: loss -259.94714 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 95: loss -263.77555 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 96: loss -265.53646 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 96: loss -269.41895 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 97: loss -271.18569 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 97: loss -275.12318 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 98: loss -276.89484 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 98: loss -280.88755 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 99: loss -282.66427 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 99: loss -286.71229 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 1)
('lr', 0.0003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.70711 ROC_AUC (avg): 0.58462 PRC_AUC (avg): 0.72688 

Average forward propagation time taken(ms): 4.271714753611318
Average backward propagation time taken(ms): 1.57896010064004

