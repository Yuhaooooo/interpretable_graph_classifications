# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 1)
('lr', 0.0003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-22-01-09/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-22-01-09/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 16,
 'epochs': 50,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 4,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.0003,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 2,
 'num_workers': 8,
 'number_of_mlp_layer': 1,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-17-22-01-09',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 50, 'learning_rate': 0.0003, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss 1.21900 acc 0.33333 roc_auc 0.41900 prc_auc 0.61098[0m
[93maverage test of epoch 0: loss 0.97011 acc 0.34211 roc_auc 0.45538 prc_auc 0.69722[0m
[92maverage training of epoch 1: loss 0.87054 acc 0.33333 roc_auc 0.42620 prc_auc 0.62353[0m
[93maverage test of epoch 1: loss 0.69103 acc 0.34211 roc_auc 0.34462 prc_auc 0.63314[0m
[92maverage training of epoch 2: loss 0.56910 acc 0.33333 roc_auc 0.46060 prc_auc 0.67469[0m
[93maverage test of epoch 2: loss 0.37570 acc 0.34211 roc_auc 0.65846 prc_auc 0.79366[0m
[92maverage training of epoch 3: loss 0.36580 acc 0.33333 roc_auc 0.41980 prc_auc 0.64887[0m
[93maverage test of epoch 3: loss 0.30345 acc 0.34211 roc_auc 0.40615 prc_auc 0.62339[0m
[92maverage training of epoch 4: loss 0.19584 acc 0.33333 roc_auc 0.50440 prc_auc 0.69019[0m
[93maverage test of epoch 4: loss 0.10728 acc 0.34211 roc_auc 0.50154 prc_auc 0.72586[0m
[92maverage training of epoch 5: loss 0.03887 acc 0.33333 roc_auc 0.57260 prc_auc 0.74033[0m
[93maverage test of epoch 5: loss -0.00420 acc 0.34211 roc_auc 0.61846 prc_auc 0.80631[0m
[92maverage training of epoch 6: loss -0.04220 acc 0.33333 roc_auc 0.52940 prc_auc 0.69380[0m
[93maverage test of epoch 6: loss -0.11289 acc 0.34211 roc_auc 0.66769 prc_auc 0.83951[0m
[92maverage training of epoch 7: loss -0.13916 acc 0.42667 roc_auc 0.60300 prc_auc 0.73946[0m
[93maverage test of epoch 7: loss -0.18563 acc 0.52632 roc_auc 0.66462 prc_auc 0.80682[0m
[92maverage training of epoch 8: loss -0.21235 acc 0.56000 roc_auc 0.68880 prc_auc 0.79733[0m
[93maverage test of epoch 8: loss -0.22451 acc 0.55263 roc_auc 0.65538 prc_auc 0.83262[0m
[92maverage training of epoch 9: loss -0.29044 acc 0.60000 roc_auc 0.74620 prc_auc 0.82592[0m
[93maverage test of epoch 9: loss -0.38485 acc 0.57895 roc_auc 0.85231 prc_auc 0.89737[0m
[92maverage training of epoch 10: loss -0.40407 acc 0.67333 roc_auc 0.82240 prc_auc 0.90002[0m
[93maverage test of epoch 10: loss -0.43238 acc 0.55263 roc_auc 0.84923 prc_auc 0.90615[0m
[92maverage training of epoch 11: loss -0.57794 acc 0.71333 roc_auc 0.85440 prc_auc 0.90205[0m
[93maverage test of epoch 11: loss -0.71524 acc 0.68421 roc_auc 0.88000 prc_auc 0.93164[0m
[92maverage training of epoch 12: loss -0.95033 acc 0.75333 roc_auc 0.84000 prc_auc 0.87648[0m
[93maverage test of epoch 12: loss -1.24471 acc 0.81579 roc_auc 0.85846 prc_auc 0.93188[0m
[92maverage training of epoch 13: loss -1.50057 acc 0.84000 roc_auc 0.86400 prc_auc 0.89278[0m
[93maverage test of epoch 13: loss -1.75246 acc 0.81579 roc_auc 0.84000 prc_auc 0.92513[0m
[92maverage training of epoch 14: loss -2.09068 acc 0.84667 roc_auc 0.87280 prc_auc 0.91526[0m
[93maverage test of epoch 14: loss -2.43980 acc 0.78947 roc_auc 0.86462 prc_auc 0.94094[0m
[92maverage training of epoch 15: loss -2.81578 acc 0.84667 roc_auc 0.86140 prc_auc 0.88879[0m
[93maverage test of epoch 15: loss -3.20074 acc 0.81579 roc_auc 0.85231 prc_auc 0.90538[0m
[92maverage training of epoch 16: loss -3.54827 acc 0.85333 roc_auc 0.85940 prc_auc 0.88712[0m
[93maverage test of epoch 16: loss -3.93759 acc 0.78947 roc_auc 0.81231 prc_auc 0.86384[0m
[92maverage training of epoch 17: loss -4.39039 acc 0.84000 roc_auc 0.87660 prc_auc 0.89176[0m
[93maverage test of epoch 17: loss -4.58238 acc 0.78947 roc_auc 0.84923 prc_auc 0.92318[0m
[92maverage training of epoch 18: loss -5.05543 acc 0.83333 roc_auc 0.86920 prc_auc 0.86294[0m
[93maverage test of epoch 18: loss -5.25155 acc 0.76316 roc_auc 0.87385 prc_auc 0.92293[0m
[92maverage training of epoch 19: loss -5.78521 acc 0.84667 roc_auc 0.85180 prc_auc 0.87345[0m
[93maverage test of epoch 19: loss -6.21503 acc 0.81579 roc_auc 0.82154 prc_auc 0.88834[0m
[92maverage training of epoch 20: loss -6.66870 acc 0.83333 roc_auc 0.89180 prc_auc 0.90471[0m
[93maverage test of epoch 20: loss -6.77485 acc 0.81579 roc_auc 0.81846 prc_auc 0.86375[0m
[92maverage training of epoch 21: loss -7.43422 acc 0.84000 roc_auc 0.91020 prc_auc 0.95364[0m
[93maverage test of epoch 21: loss -7.61659 acc 0.81579 roc_auc 0.84000 prc_auc 0.91002[0m
[92maverage training of epoch 22: loss -8.18909 acc 0.83333 roc_auc 0.90780 prc_auc 0.93794[0m
[93maverage test of epoch 22: loss -8.26365 acc 0.78947 roc_auc 0.90462 prc_auc 0.95175[0m
[92maverage training of epoch 23: loss -8.80605 acc 0.84667 roc_auc 0.87180 prc_auc 0.89374[0m
[93maverage test of epoch 23: loss -8.86265 acc 0.84211 roc_auc 0.85538 prc_auc 0.91484[0m
[92maverage training of epoch 24: loss -9.44964 acc 0.83333 roc_auc 0.89460 prc_auc 0.93520[0m
[93maverage test of epoch 24: loss -9.51831 acc 0.78947 roc_auc 0.89231 prc_auc 0.95364[0m
[92maverage training of epoch 25: loss -10.34478 acc 0.87333 roc_auc 0.90860 prc_auc 0.92770[0m
[93maverage test of epoch 25: loss -10.34045 acc 0.86842 roc_auc 0.85846 prc_auc 0.85949[0m
[92maverage training of epoch 26: loss -11.02338 acc 0.88000 roc_auc 0.92260 prc_auc 0.96202[0m
[93maverage test of epoch 26: loss -11.05917 acc 0.78947 roc_auc 0.90769 prc_auc 0.95570[0m
[92maverage training of epoch 27: loss -11.76709 acc 0.86667 roc_auc 0.91140 prc_auc 0.93569[0m
[93maverage test of epoch 27: loss -11.92113 acc 0.81579 roc_auc 0.92615 prc_auc 0.96567[0m
[92maverage training of epoch 28: loss -12.52301 acc 0.85333 roc_auc 0.90320 prc_auc 0.91886[0m
[93maverage test of epoch 28: loss -12.57461 acc 0.81579 roc_auc 0.88923 prc_auc 0.95480[0m
[92maverage training of epoch 29: loss -13.42220 acc 0.90000 roc_auc 0.91640 prc_auc 0.95075[0m
[93maverage test of epoch 29: loss -13.57030 acc 0.86842 roc_auc 0.89231 prc_auc 0.95600[0m
[92maverage training of epoch 30: loss -14.03125 acc 0.86667 roc_auc 0.90240 prc_auc 0.91397[0m
[93maverage test of epoch 30: loss -14.38137 acc 0.84211 roc_auc 0.90462 prc_auc 0.96003[0m
[92maverage training of epoch 31: loss -14.81409 acc 0.86667 roc_auc 0.92660 prc_auc 0.96055[0m
[93maverage test of epoch 31: loss -14.81731 acc 0.81579 roc_auc 0.87077 prc_auc 0.94876[0m
[92maverage training of epoch 32: loss -15.59883 acc 0.86000 roc_auc 0.91920 prc_auc 0.94613[0m
[93maverage test of epoch 32: loss -15.82164 acc 0.81579 roc_auc 0.88000 prc_auc 0.95345[0m
[92maverage training of epoch 33: loss -16.56811 acc 0.89333 roc_auc 0.92100 prc_auc 0.94578[0m
[93maverage test of epoch 33: loss -16.65648 acc 0.81579 roc_auc 0.90154 prc_auc 0.95930[0m
[92maverage training of epoch 34: loss -17.43807 acc 0.86667 roc_auc 0.91360 prc_auc 0.93608[0m
[93maverage test of epoch 34: loss -17.82671 acc 0.81579 roc_auc 0.92923 prc_auc 0.96826[0m
[92maverage training of epoch 35: loss -18.34985 acc 0.89333 roc_auc 0.92720 prc_auc 0.93554[0m
[93maverage test of epoch 35: loss -18.44057 acc 0.84211 roc_auc 0.89231 prc_auc 0.95484[0m
[92maverage training of epoch 36: loss -19.20795 acc 0.88000 roc_auc 0.91460 prc_auc 0.93498[0m
[93maverage test of epoch 36: loss -19.47383 acc 0.81579 roc_auc 0.92615 prc_auc 0.96636[0m
[92maverage training of epoch 37: loss -20.25089 acc 0.90000 roc_auc 0.91460 prc_auc 0.92628[0m
[93maverage test of epoch 37: loss -20.10848 acc 0.84211 roc_auc 0.89538 prc_auc 0.95790[0m
[92maverage training of epoch 38: loss -21.25526 acc 0.88667 roc_auc 0.92080 prc_auc 0.95748[0m
[93maverage test of epoch 38: loss -21.50956 acc 0.86842 roc_auc 0.89538 prc_auc 0.95853[0m
[92maverage training of epoch 39: loss -22.01412 acc 0.88667 roc_auc 0.88200 prc_auc 0.89424[0m
[93maverage test of epoch 39: loss -22.31435 acc 0.84211 roc_auc 0.90769 prc_auc 0.96178[0m
[92maverage training of epoch 40: loss -23.11142 acc 0.88000 roc_auc 0.91200 prc_auc 0.93088[0m
[93maverage test of epoch 40: loss -23.37734 acc 0.81579 roc_auc 0.90769 prc_auc 0.96144[0m
[92maverage training of epoch 41: loss -23.92228 acc 0.86000 roc_auc 0.89570 prc_auc 0.92044[0m
[93maverage test of epoch 41: loss -24.43189 acc 0.84211 roc_auc 0.89231 prc_auc 0.95742[0m
[92maverage training of epoch 42: loss -25.15374 acc 0.88667 roc_auc 0.88230 prc_auc 0.87948[0m
[93maverage test of epoch 42: loss -25.00252 acc 0.84211 roc_auc 0.88615 prc_auc 0.95604[0m
[92maverage training of epoch 43: loss -26.17815 acc 0.88000 roc_auc 0.91920 prc_auc 0.95231[0m
[93maverage test of epoch 43: loss -26.49613 acc 0.84211 roc_auc 0.89077 prc_auc 0.95450[0m
[92maverage training of epoch 44: loss -27.31054 acc 0.86667 roc_auc 0.89420 prc_auc 0.89939[0m
[93maverage test of epoch 44: loss -27.35430 acc 0.84211 roc_auc 0.90462 prc_auc 0.96038[0m
[92maverage training of epoch 45: loss -28.46372 acc 0.89333 roc_auc 0.89680 prc_auc 0.90679[0m
[93maverage test of epoch 45: loss -28.71746 acc 0.86842 roc_auc 0.90154 prc_auc 0.96006[0m
[92maverage training of epoch 46: loss -29.54227 acc 0.88000 roc_auc 0.91470 prc_auc 0.95240[0m
[93maverage test of epoch 46: loss -29.74224 acc 0.81579 roc_auc 0.88923 prc_auc 0.95551[0m
[92maverage training of epoch 47: loss -30.72163 acc 0.90000 roc_auc 0.89900 prc_auc 0.93332[0m
[93maverage test of epoch 47: loss -31.07796 acc 0.84211 roc_auc 0.86923 prc_auc 0.93470[0m
[92maverage training of epoch 48: loss -31.78907 acc 0.87333 roc_auc 0.91480 prc_auc 0.95148[0m
[93maverage test of epoch 48: loss -31.69125 acc 0.81579 roc_auc 0.89538 prc_auc 0.95440[0m
[92maverage training of epoch 49: loss -33.17140 acc 0.90000 roc_auc 0.91300 prc_auc 0.93104[0m
[93maverage test of epoch 49: loss -33.26014 acc 0.84211 roc_auc 0.89538 prc_auc 0.95736[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -1.48980 acc 0.66667 roc_auc 0.44240 prc_auc 0.63949[0m
[93maverage test of epoch 0: loss -1.97685 acc 0.65789 roc_auc 0.36923 prc_auc 0.60834[0m
[92maverage training of epoch 1: loss -2.42016 acc 0.66667 roc_auc 0.44480 prc_auc 0.63359[0m
[93maverage test of epoch 1: loss -2.80641 acc 0.65789 roc_auc 0.60923 prc_auc 0.71333[0m
[92maverage training of epoch 2: loss -3.10461 acc 0.66667 roc_auc 0.47740 prc_auc 0.66100[0m
[93maverage test of epoch 2: loss -3.40194 acc 0.65789 roc_auc 0.48615 prc_auc 0.69771[0m
[92maverage training of epoch 3: loss -3.69009 acc 0.66667 roc_auc 0.46160 prc_auc 0.66039[0m
[93maverage test of epoch 3: loss -3.95956 acc 0.65789 roc_auc 0.52923 prc_auc 0.65656[0m
[92maverage training of epoch 4: loss -4.26621 acc 0.66667 roc_auc 0.42120 prc_auc 0.61085[0m
[93maverage test of epoch 4: loss -4.58116 acc 0.65789 roc_auc 0.62154 prc_auc 0.80042[0m
[92maverage training of epoch 5: loss -4.89064 acc 0.66667 roc_auc 0.43760 prc_auc 0.63357[0m
[93maverage test of epoch 5: loss -5.20706 acc 0.65789 roc_auc 0.57846 prc_auc 0.74783[0m
[92maverage training of epoch 6: loss -5.56905 acc 0.66667 roc_auc 0.44940 prc_auc 0.66471[0m
[93maverage test of epoch 6: loss -5.87434 acc 0.65789 roc_auc 0.48308 prc_auc 0.67062[0m
[92maverage training of epoch 7: loss -6.27035 acc 0.66667 roc_auc 0.45880 prc_auc 0.65742[0m
[93maverage test of epoch 7: loss -6.60656 acc 0.65789 roc_auc 0.66769 prc_auc 0.81924[0m
[92maverage training of epoch 8: loss -6.99842 acc 0.66667 roc_auc 0.45580 prc_auc 0.63470[0m
[93maverage test of epoch 8: loss -7.33443 acc 0.65789 roc_auc 0.54769 prc_auc 0.74731[0m
[92maverage training of epoch 9: loss -7.75837 acc 0.66667 roc_auc 0.48310 prc_auc 0.67087[0m
[93maverage test of epoch 9: loss -8.09187 acc 0.65789 roc_auc 0.56154 prc_auc 0.72020[0m
[92maverage training of epoch 10: loss -8.53955 acc 0.66667 roc_auc 0.45420 prc_auc 0.64191[0m
[93maverage test of epoch 10: loss -8.89109 acc 0.65789 roc_auc 0.49692 prc_auc 0.65362[0m
[92maverage training of epoch 11: loss -9.34743 acc 0.66667 roc_auc 0.45030 prc_auc 0.64925[0m
[93maverage test of epoch 11: loss -9.72922 acc 0.65789 roc_auc 0.61692 prc_auc 0.77394[0m
[92maverage training of epoch 12: loss -10.19591 acc 0.66667 roc_auc 0.45900 prc_auc 0.65769[0m
[93maverage test of epoch 12: loss -10.59279 acc 0.65789 roc_auc 0.43846 prc_auc 0.66475[0m
[92maverage training of epoch 13: loss -11.06725 acc 0.66667 roc_auc 0.47340 prc_auc 0.65036[0m
[93maverage test of epoch 13: loss -11.46825 acc 0.65789 roc_auc 0.68769 prc_auc 0.82983[0m
[92maverage training of epoch 14: loss -11.98070 acc 0.66667 roc_auc 0.47610 prc_auc 0.65026[0m
[93maverage test of epoch 14: loss -12.39528 acc 0.65789 roc_auc 0.43692 prc_auc 0.61570[0m
[92maverage training of epoch 15: loss -12.92189 acc 0.66667 roc_auc 0.46200 prc_auc 0.63654[0m
[93maverage test of epoch 15: loss -13.33900 acc 0.65789 roc_auc 0.54615 prc_auc 0.70965[0m
[92maverage training of epoch 16: loss -13.87804 acc 0.66667 roc_auc 0.46250 prc_auc 0.63883[0m
[93maverage test of epoch 16: loss -14.31898 acc 0.65789 roc_auc 0.49846 prc_auc 0.68080[0m
[92maverage training of epoch 17: loss -14.88224 acc 0.66667 roc_auc 0.46460 prc_auc 0.64936[0m
[93maverage test of epoch 17: loss -15.32042 acc 0.65789 roc_auc 0.52462 prc_auc 0.67684[0m
[92maverage training of epoch 18: loss -15.90431 acc 0.66667 roc_auc 0.45880 prc_auc 0.63414[0m
[93maverage test of epoch 18: loss -16.36503 acc 0.65789 roc_auc 0.56769 prc_auc 0.70861[0m
[92maverage training of epoch 19: loss -16.95930 acc 0.66667 roc_auc 0.46670 prc_auc 0.65585[0m
[93maverage test of epoch 19: loss -17.42144 acc 0.65789 roc_auc 0.40769 prc_auc 0.62479[0m
[92maverage training of epoch 20: loss -18.04678 acc 0.66667 roc_auc 0.46260 prc_auc 0.63644[0m
[93maverage test of epoch 20: loss -18.52381 acc 0.65789 roc_auc 0.47231 prc_auc 0.64217[0m
[92maverage training of epoch 21: loss -19.16292 acc 0.66667 roc_auc 0.47160 prc_auc 0.67174[0m
[93maverage test of epoch 21: loss -19.65357 acc 0.65789 roc_auc 0.48462 prc_auc 0.66494[0m
[92maverage training of epoch 22: loss -20.30913 acc 0.66667 roc_auc 0.47290 prc_auc 0.64646[0m
[93maverage test of epoch 22: loss -20.80660 acc 0.65789 roc_auc 0.41077 prc_auc 0.60656[0m
[92maverage training of epoch 23: loss -21.47668 acc 0.66667 roc_auc 0.46000 prc_auc 0.64279[0m
[93maverage test of epoch 23: loss -21.98228 acc 0.65789 roc_auc 0.50615 prc_auc 0.65835[0m
[92maverage training of epoch 24: loss -22.67564 acc 0.66667 roc_auc 0.46440 prc_auc 0.64970[0m
[93maverage test of epoch 24: loss -23.18944 acc 0.65789 roc_auc 0.46462 prc_auc 0.64682[0m
[92maverage training of epoch 25: loss -23.90093 acc 0.66667 roc_auc 0.46260 prc_auc 0.63353[0m
[93maverage test of epoch 25: loss -24.42735 acc 0.65789 roc_auc 0.57231 prc_auc 0.69767[0m
[92maverage training of epoch 26: loss -25.14792 acc 0.66667 roc_auc 0.47020 prc_auc 0.66197[0m
[93maverage test of epoch 26: loss -25.67700 acc 0.65789 roc_auc 0.44462 prc_auc 0.63298[0m
[92maverage training of epoch 27: loss -26.42703 acc 0.66667 roc_auc 0.47000 prc_auc 0.64580[0m
[93maverage test of epoch 27: loss -26.97634 acc 0.65789 roc_auc 0.51846 prc_auc 0.66632[0m
[92maverage training of epoch 28: loss -27.73154 acc 0.66667 roc_auc 0.44700 prc_auc 0.63245[0m
[93maverage test of epoch 28: loss -28.29386 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -29.06869 acc 0.66667 roc_auc 0.47430 prc_auc 0.65103[0m
[93maverage test of epoch 29: loss -29.63001 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -30.43282 acc 0.66667 roc_auc 0.45500 prc_auc 0.64028[0m
[93maverage test of epoch 30: loss -31.00852 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -31.82799 acc 0.66667 roc_auc 0.50490 prc_auc 0.66775[0m
[93maverage test of epoch 31: loss -32.41151 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -33.25298 acc 0.66667 roc_auc 0.45000 prc_auc 0.64654[0m
[93maverage test of epoch 32: loss -33.84723 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -34.70728 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 33: loss -35.31123 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -36.18953 acc 0.66667 roc_auc 0.45000 prc_auc 0.64624[0m
[93maverage test of epoch 34: loss -36.80476 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -37.70156 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -38.32816 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -39.24400 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -39.88103 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -40.81752 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -41.45873 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -42.42036 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -43.07665 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -44.05300 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -44.71437 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -45.70994 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -46.38252 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -47.39541 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -48.07338 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -49.11305 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -49.79759 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -50.85695 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -51.55301 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -52.62717 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -53.33029 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -54.42982 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -55.14338 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -56.25934 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -56.98244 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -58.11909 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -58.84905 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -60.00670 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -60.74494 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -61.92423 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -62.66531 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss 0.45481 acc 0.33333 roc_auc 0.41920 prc_auc 0.62465[0m
[93maverage test of epoch 0: loss 0.06906 acc 0.34211 roc_auc 0.48308 prc_auc 0.66501[0m
[92maverage training of epoch 1: loss -0.12398 acc 0.41333 roc_auc 0.42520 prc_auc 0.66765[0m
[93maverage test of epoch 1: loss -0.31073 acc 0.65789 roc_auc 0.52923 prc_auc 0.66533[0m
[92maverage training of epoch 2: loss -0.51818 acc 0.66667 roc_auc 0.43540 prc_auc 0.62476[0m
[93maverage test of epoch 2: loss -0.72007 acc 0.65789 roc_auc 0.49231 prc_auc 0.66001[0m
[92maverage training of epoch 3: loss -0.92658 acc 0.66667 roc_auc 0.43780 prc_auc 0.65258[0m
[93maverage test of epoch 3: loss -1.11723 acc 0.65789 roc_auc 0.68615 prc_auc 0.84013[0m
[92maverage training of epoch 4: loss -1.28128 acc 0.66667 roc_auc 0.42260 prc_auc 0.62467[0m
[93maverage test of epoch 4: loss -1.42037 acc 0.65789 roc_auc 0.35077 prc_auc 0.57820[0m
[92maverage training of epoch 5: loss -1.62089 acc 0.66667 roc_auc 0.44300 prc_auc 0.61917[0m
[93maverage test of epoch 5: loss -1.81211 acc 0.65789 roc_auc 0.45231 prc_auc 0.69952[0m
[92maverage training of epoch 6: loss -2.05813 acc 0.66667 roc_auc 0.44540 prc_auc 0.64049[0m
[93maverage test of epoch 6: loss -2.31357 acc 0.65789 roc_auc 0.70769 prc_auc 0.84706[0m
[92maverage training of epoch 7: loss -2.66533 acc 0.66667 roc_auc 0.46400 prc_auc 0.65095[0m
[93maverage test of epoch 7: loss -3.20802 acc 0.65789 roc_auc 0.53538 prc_auc 0.72255[0m
[92maverage training of epoch 8: loss -3.78742 acc 0.66667 roc_auc 0.44860 prc_auc 0.64789[0m
[93maverage test of epoch 8: loss -4.26707 acc 0.65789 roc_auc 0.56000 prc_auc 0.73182[0m
[92maverage training of epoch 9: loss -4.75545 acc 0.66667 roc_auc 0.45920 prc_auc 0.65509[0m
[93maverage test of epoch 9: loss -5.19860 acc 0.65789 roc_auc 0.53846 prc_auc 0.66776[0m
[92maverage training of epoch 10: loss -5.62721 acc 0.66667 roc_auc 0.44570 prc_auc 0.64640[0m
[93maverage test of epoch 10: loss -6.03712 acc 0.65789 roc_auc 0.51692 prc_auc 0.72442[0m
[92maverage training of epoch 11: loss -6.47360 acc 0.66667 roc_auc 0.42620 prc_auc 0.62276[0m
[93maverage test of epoch 11: loss -6.87364 acc 0.65789 roc_auc 0.44308 prc_auc 0.65337[0m
[92maverage training of epoch 12: loss -7.33331 acc 0.66667 roc_auc 0.42260 prc_auc 0.60542[0m
[93maverage test of epoch 12: loss -7.74032 acc 0.65789 roc_auc 0.45231 prc_auc 0.65811[0m
[92maverage training of epoch 13: loss -8.20725 acc 0.66667 roc_auc 0.44300 prc_auc 0.64193[0m
[93maverage test of epoch 13: loss -8.58782 acc 0.65789 roc_auc 0.66769 prc_auc 0.81106[0m
[92maverage training of epoch 14: loss -9.08053 acc 0.66667 roc_auc 0.44430 prc_auc 0.64208[0m
[93maverage test of epoch 14: loss -9.48277 acc 0.65789 roc_auc 0.43077 prc_auc 0.62124[0m
[92maverage training of epoch 15: loss -9.96586 acc 0.66667 roc_auc 0.43220 prc_auc 0.63913[0m
[93maverage test of epoch 15: loss -10.37147 acc 0.65789 roc_auc 0.49385 prc_auc 0.70567[0m
[92maverage training of epoch 16: loss -10.88872 acc 0.66667 roc_auc 0.43940 prc_auc 0.63204[0m
[93maverage test of epoch 16: loss -11.30215 acc 0.65789 roc_auc 0.59231 prc_auc 0.74259[0m
[92maverage training of epoch 17: loss -11.81825 acc 0.66667 roc_auc 0.43180 prc_auc 0.63087[0m
[93maverage test of epoch 17: loss -12.24102 acc 0.65789 roc_auc 0.54615 prc_auc 0.65632[0m
[92maverage training of epoch 18: loss -12.78184 acc 0.66667 roc_auc 0.43580 prc_auc 0.63486[0m
[93maverage test of epoch 18: loss -13.21345 acc 0.65789 roc_auc 0.61692 prc_auc 0.75318[0m
[92maverage training of epoch 19: loss -13.75688 acc 0.66667 roc_auc 0.43110 prc_auc 0.63065[0m
[93maverage test of epoch 19: loss -14.20510 acc 0.65789 roc_auc 0.53077 prc_auc 0.67685[0m
[92maverage training of epoch 20: loss -14.78842 acc 0.66667 roc_auc 0.43470 prc_auc 0.63414[0m
[93maverage test of epoch 20: loss -15.22302 acc 0.65789 roc_auc 0.39692 prc_auc 0.60087[0m
[92maverage training of epoch 21: loss -15.82303 acc 0.66667 roc_auc 0.44400 prc_auc 0.64581[0m
[93maverage test of epoch 21: loss -16.28594 acc 0.65789 roc_auc 0.39231 prc_auc 0.60132[0m
[92maverage training of epoch 22: loss -16.90134 acc 0.66667 roc_auc 0.44580 prc_auc 0.63666[0m
[93maverage test of epoch 22: loss -17.37011 acc 0.65789 roc_auc 0.64923 prc_auc 0.74969[0m
[92maverage training of epoch 23: loss -17.99255 acc 0.66667 roc_auc 0.43920 prc_auc 0.63220[0m
[93maverage test of epoch 23: loss -18.47006 acc 0.65789 roc_auc 0.64462 prc_auc 0.74739[0m
[92maverage training of epoch 24: loss -19.12220 acc 0.66667 roc_auc 0.43790 prc_auc 0.63028[0m
[93maverage test of epoch 24: loss -19.60886 acc 0.65789 roc_auc 0.33846 prc_auc 0.57965[0m
[92maverage training of epoch 25: loss -20.28012 acc 0.66667 roc_auc 0.44130 prc_auc 0.63908[0m
[93maverage test of epoch 25: loss -20.77807 acc 0.65789 roc_auc 0.48154 prc_auc 0.65050[0m
[92maverage training of epoch 26: loss -21.46391 acc 0.66667 roc_auc 0.44310 prc_auc 0.63955[0m
[93maverage test of epoch 26: loss -21.97227 acc 0.65789 roc_auc 0.43231 prc_auc 0.62848[0m
[92maverage training of epoch 27: loss -22.67934 acc 0.66667 roc_auc 0.43180 prc_auc 0.62523[0m
[93maverage test of epoch 27: loss -23.19949 acc 0.65789 roc_auc 0.55538 prc_auc 0.68465[0m
[92maverage training of epoch 28: loss -23.92162 acc 0.66667 roc_auc 0.43350 prc_auc 0.62867[0m
[93maverage test of epoch 28: loss -24.45092 acc 0.65789 roc_auc 0.45692 prc_auc 0.63870[0m
[92maverage training of epoch 29: loss -25.19402 acc 0.66667 roc_auc 0.43830 prc_auc 0.63532[0m
[93maverage test of epoch 29: loss -25.73379 acc 0.65789 roc_auc 0.42000 prc_auc 0.62409[0m
[92maverage training of epoch 30: loss -26.49152 acc 0.66667 roc_auc 0.43900 prc_auc 0.64103[0m
[93maverage test of epoch 30: loss -27.04486 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -27.82552 acc 0.66667 roc_auc 0.42290 prc_auc 0.62712[0m
[93maverage test of epoch 31: loss -28.38449 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -29.18548 acc 0.66667 roc_auc 0.44610 prc_auc 0.64195[0m
[93maverage test of epoch 32: loss -29.75521 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -30.57211 acc 0.66667 roc_auc 0.45000 prc_auc 0.64561[0m
[93maverage test of epoch 33: loss -31.15243 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -31.99203 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -32.57764 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -33.44298 acc 0.66667 roc_auc 0.47000 prc_auc 0.65366[0m
[93maverage test of epoch 35: loss -34.03966 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -34.91843 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -35.52828 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -36.42890 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -37.04264 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -37.96919 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -38.59702 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -39.53550 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -40.16938 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -41.13017 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -41.77140 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -42.75264 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -43.40215 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -44.40277 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -45.05708 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -46.07942 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -46.74688 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -47.78698 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -48.45682 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -49.51950 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -50.20274 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -51.28308 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -51.97385 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -53.07421 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -53.77231 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -54.89433 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -55.59836 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -56.74374 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -57.45617 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.22104 acc 0.66225 roc_auc 0.44333 prc_auc 0.64579[0m
[93maverage test of epoch 0: loss -0.67143 acc 0.67568 roc_auc 0.36667 prc_auc 0.64640[0m
[92maverage training of epoch 1: loss -1.49031 acc 0.66225 roc_auc 0.45157 prc_auc 0.64119[0m
[93maverage test of epoch 1: loss -2.49713 acc 0.67568 roc_auc 0.62000 prc_auc 0.77000[0m
[92maverage training of epoch 2: loss -3.42823 acc 0.66225 roc_auc 0.43667 prc_auc 0.63051[0m
[93maverage test of epoch 2: loss -4.57431 acc 0.67568 roc_auc 0.48000 prc_auc 0.71069[0m
[92maverage training of epoch 3: loss -5.25630 acc 0.66225 roc_auc 0.43529 prc_auc 0.62639[0m
[93maverage test of epoch 3: loss -6.17519 acc 0.67568 roc_auc 0.61167 prc_auc 0.70783[0m
[92maverage training of epoch 4: loss -6.72250 acc 0.66225 roc_auc 0.43255 prc_auc 0.61513[0m
[93maverage test of epoch 4: loss -7.52625 acc 0.67568 roc_auc 0.50333 prc_auc 0.65905[0m
[92maverage training of epoch 5: loss -8.04462 acc 0.66225 roc_auc 0.40500 prc_auc 0.61767[0m
[93maverage test of epoch 5: loss -8.84117 acc 0.67568 roc_auc 0.52667 prc_auc 0.68935[0m
[92maverage training of epoch 6: loss -9.28741 acc 0.66225 roc_auc 0.46539 prc_auc 0.64834[0m
[93maverage test of epoch 6: loss -10.07460 acc 0.67568 roc_auc 0.74667 prc_auc 0.87009[0m
[92maverage training of epoch 7: loss -10.48824 acc 0.66225 roc_auc 0.43412 prc_auc 0.62235[0m
[93maverage test of epoch 7: loss -11.26977 acc 0.67568 roc_auc 0.62833 prc_auc 0.75587[0m
[92maverage training of epoch 8: loss -11.68750 acc 0.66225 roc_auc 0.45245 prc_auc 0.62475[0m
[93maverage test of epoch 8: loss -12.46712 acc 0.67568 roc_auc 0.66333 prc_auc 0.79034[0m
[92maverage training of epoch 9: loss -12.87951 acc 0.66225 roc_auc 0.44245 prc_auc 0.62521[0m
[93maverage test of epoch 9: loss -13.66343 acc 0.67568 roc_auc 0.38000 prc_auc 0.61971[0m
[92maverage training of epoch 10: loss -14.08845 acc 0.66225 roc_auc 0.42196 prc_auc 0.61758[0m
[93maverage test of epoch 10: loss -14.91724 acc 0.67568 roc_auc 0.56000 prc_auc 0.70581[0m
[92maverage training of epoch 11: loss -15.35133 acc 0.66225 roc_auc 0.43176 prc_auc 0.62884[0m
[93maverage test of epoch 11: loss -16.16897 acc 0.67568 roc_auc 0.50667 prc_auc 0.67862[0m
[92maverage training of epoch 12: loss -16.60865 acc 0.66225 roc_auc 0.45706 prc_auc 0.64008[0m
[93maverage test of epoch 12: loss -17.44735 acc 0.67568 roc_auc 0.48000 prc_auc 0.66703[0m
[92maverage training of epoch 13: loss -17.90746 acc 0.66225 roc_auc 0.42500 prc_auc 0.63124[0m
[93maverage test of epoch 13: loss -18.79415 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 14: loss -19.21585 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 14: loss -20.16644 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 15: loss -20.59229 acc 0.66225 roc_auc 0.49863 prc_auc 0.66164[0m
[93maverage test of epoch 15: loss -21.54078 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 16: loss -21.99107 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 16: loss -22.94077 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 17: loss -23.42194 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 17: loss -24.43840 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 18: loss -24.91275 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 18: loss -25.93319 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 19: loss -26.41520 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 19: loss -27.49042 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 20: loss -27.98352 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 20: loss -29.07295 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 21: loss -29.59684 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 21: loss -30.70673 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 22: loss -31.23350 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 22: loss -32.38558 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 23: loss -32.91933 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 23: loss -34.11926 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 24: loss -34.65935 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 24: loss -35.87835 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 25: loss -36.44139 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 25: loss -37.70378 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 26: loss -38.26249 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 26: loss -39.56363 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 27: loss -40.13755 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 27: loss -41.46828 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 28: loss -42.05266 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 28: loss -43.41589 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 29: loss -44.01876 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 29: loss -45.42354 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 30: loss -46.03053 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 30: loss -47.47667 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 31: loss -48.09211 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 31: loss -49.57630 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 32: loss -50.19422 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 32: loss -51.71743 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 33: loss -52.35230 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 33: loss -53.91335 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 34: loss -54.55665 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 34: loss -56.15733 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 35: loss -56.80825 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 35: loss -58.44765 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 36: loss -59.10747 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 36: loss -60.78434 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 37: loss -61.46014 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 37: loss -63.17074 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 38: loss -63.85264 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 38: loss -65.59567 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 39: loss -66.29295 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 39: loss -68.08219 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -68.77612 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 40: loss -70.60607 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -71.31254 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 41: loss -73.18478 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -73.89136 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 42: loss -75.80748 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -76.51881 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 43: loss -78.47168 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -79.18944 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 44: loss -81.17874 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -81.91007 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 45: loss -83.94460 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -84.67702 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 46: loss -86.74750 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -87.48998 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 47: loss -89.60584 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -90.35244 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 48: loss -92.51037 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -93.26150 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 49: loss -95.45750 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss 0.18841 acc 0.33775 roc_auc 0.56098 prc_auc 0.69284[0m
[93maverage test of epoch 0: loss 0.11811 acc 0.32432 roc_auc 0.58333 prc_auc 0.76564[0m
[92maverage training of epoch 1: loss 0.01055 acc 0.33775 roc_auc 0.54235 prc_auc 0.69446[0m
[93maverage test of epoch 1: loss -0.08158 acc 0.32432 roc_auc 0.44667 prc_auc 0.63757[0m
[92maverage training of epoch 2: loss -0.21789 acc 0.33775 roc_auc 0.56020 prc_auc 0.69826[0m
[93maverage test of epoch 2: loss -0.35175 acc 0.32432 roc_auc 0.72667 prc_auc 0.86699[0m
[92maverage training of epoch 3: loss -0.53863 acc 0.33775 roc_auc 0.56000 prc_auc 0.70320[0m
[93maverage test of epoch 3: loss -0.70929 acc 0.32432 roc_auc 0.47333 prc_auc 0.72309[0mUsing backend: pytorch

[92maverage training of epoch 4: loss -0.92027 acc 0.33775 roc_auc 0.54000 prc_auc 0.69425[0m
[93maverage test of epoch 4: loss -1.11886 acc 0.32432 roc_auc 0.36333 prc_auc 0.60995[0m
[92maverage training of epoch 5: loss -1.38028 acc 0.33775 roc_auc 0.47529 prc_auc 0.67628[0m
[93maverage test of epoch 5: loss -1.57555 acc 0.32432 roc_auc 0.44333 prc_auc 0.67653[0m
[92maverage training of epoch 6: loss -1.82949 acc 0.33775 roc_auc 0.45451 prc_auc 0.64807[0m
[93maverage test of epoch 6: loss -2.05163 acc 0.32432 roc_auc 0.56667 prc_auc 0.77477[0m
[92maverage training of epoch 7: loss -2.31295 acc 0.33775 roc_auc 0.43118 prc_auc 0.61669[0m
[93maverage test of epoch 7: loss -2.55629 acc 0.32432 roc_auc 0.55667 prc_auc 0.78977[0m
[92maverage training of epoch 8: loss -2.86702 acc 0.33775 roc_auc 0.50510 prc_auc 0.67478[0m
[93maverage test of epoch 8: loss -3.12002 acc 0.32432 roc_auc 0.35333 prc_auc 0.59043[0m
[92maverage training of epoch 9: loss -3.47104 acc 0.33775 roc_auc 0.42804 prc_auc 0.65939[0m
[93maverage test of epoch 9: loss -3.76939 acc 0.32432 roc_auc 0.46667 prc_auc 0.73403[0m
[92maverage training of epoch 10: loss -4.13099 acc 0.33775 roc_auc 0.45000 prc_auc 0.63692[0m
[93maverage test of epoch 10: loss -4.45241 acc 0.32432 roc_auc 0.54333 prc_auc 0.71076[0m
[92maverage training of epoch 11: loss -4.84998 acc 0.33775 roc_auc 0.45157 prc_auc 0.63775[0m
[93maverage test of epoch 11: loss -5.19994 acc 0.32432 roc_auc 0.60667 prc_auc 0.80544[0m
[92maverage training of epoch 12: loss -5.61768 acc 0.33775 roc_auc 0.44490 prc_auc 0.60759[0m
[93maverage test of epoch 12: loss -5.98932 acc 0.32432 roc_auc 0.50667 prc_auc 0.74214[0m
[92maverage training of epoch 13: loss -6.42217 acc 0.33775 roc_auc 0.42000 prc_auc 0.63174[0m
[93maverage test of epoch 13: loss -6.80741 acc 0.32432 roc_auc 0.41333 prc_auc 0.70373[0m
[92maverage training of epoch 14: loss -7.27455 acc 0.33775 roc_auc 0.39863 prc_auc 0.60222[0m
[93maverage test of epoch 14: loss -7.68758 acc 0.32432 roc_auc 0.52000 prc_auc 0.71169[0m
[92maverage training of epoch 15: loss -8.17175 acc 0.33775 roc_auc 0.44765 prc_auc 0.63236[0m
[93maverage test of epoch 15: loss -8.59118 acc 0.32432 roc_auc 0.50667 prc_auc 0.70143[0m
[92maverage training of epoch 16: loss -9.11452 acc 0.33775 roc_auc 0.44078 prc_auc 0.61720[0m
[93maverage test of epoch 16: loss -9.55996 acc 0.32432 roc_auc 0.65000 prc_auc 0.83398[0m
[92maverage training of epoch 17: loss -10.08470 acc 0.33775 roc_auc 0.39020 prc_auc 0.61433[0m
[93maverage test of epoch 17: loss -10.56380 acc 0.32432 roc_auc 0.36667 prc_auc 0.63310[0m
[92maverage training of epoch 18: loss -11.11580 acc 0.33775 roc_auc 0.38098 prc_auc 0.58395[0m
[93maverage test of epoch 18: loss -11.62301 acc 0.32432 roc_auc 0.55000 prc_auc 0.72010[0m
[92maverage training of epoch 19: loss -12.18796 acc 0.33775 roc_auc 0.42275 prc_auc 0.61638[0m
[93maverage test of epoch 19: loss -12.70370 acc 0.32432 roc_auc 0.35333 prc_auc 0.60763[0m
[92maverage training of epoch 20: loss -13.30466 acc 0.33775 roc_auc 0.36922 prc_auc 0.56762[0m
[93maverage test of epoch 20: loss -13.85936 acc 0.32432 roc_auc 0.41667 prc_auc 0.70394[0m
[92maverage training of epoch 21: loss -14.47520 acc 0.33775 roc_auc 0.37922 prc_auc 0.57518[0m
[93maverage test of epoch 21: loss -15.04385 acc 0.32432 roc_auc 0.63333 prc_auc 0.77234[0m
[92maverage training of epoch 22: loss -15.68385 acc 0.33775 roc_auc 0.39000 prc_auc 0.60909[0m
[93maverage test of epoch 22: loss -16.28473 acc 0.32432 roc_auc 0.57167 prc_auc 0.76006[0m
[92maverage training of epoch 23: loss -16.93999 acc 0.33775 roc_auc 0.37824 prc_auc 0.58981[0m
[93maverage test of epoch 23: loss -17.55855 acc 0.32432 roc_auc 0.51833 prc_auc 0.67496[0m
[92maverage training of epoch 24: loss -18.22716 acc 0.33775 roc_auc 0.35451 prc_auc 0.56269[0m
[93maverage test of epoch 24: loss -18.88352 acc 0.32432 roc_auc 0.49000 prc_auc 0.73451[0m
[92maverage training of epoch 25: loss -19.56642 acc 0.33775 roc_auc 0.36588 prc_auc 0.56388[0m
[93maverage test of epoch 25: loss -20.23209 acc 0.32432 roc_auc 0.37500 prc_auc 0.60031[0m
[92maverage training of epoch 26: loss -20.94320 acc 0.33775 roc_auc 0.37314 prc_auc 0.57888[0m
[93maverage test of epoch 26: loss -21.63764 acc 0.32432 roc_auc 0.46333 prc_auc 0.65497[0m
[92maverage training of epoch 27: loss -22.36189 acc 0.33775 roc_auc 0.36627 prc_auc 0.57639[0m
[93maverage test of epoch 27: loss -23.08386 acc 0.32432 roc_auc 0.38167 prc_auc 0.66996[0m
[92maverage training of epoch 28: loss -23.82456 acc 0.33775 roc_auc 0.35902 prc_auc 0.55897[0m
[93maverage test of epoch 28: loss -24.57809 acc 0.32432 roc_auc 0.47333 prc_auc 0.70972[0m
[92maverage training of epoch 29: loss -25.33359 acc 0.33775 roc_auc 0.36255 prc_auc 0.56076[0m
[93maverage test of epoch 29: loss -26.10068 acc 0.32432 roc_auc 0.53333 prc_auc 0.70868[0m
[92maverage training of epoch 30: loss -26.88104 acc 0.48344 roc_auc 0.36961 prc_auc 0.57085[0m
[93maverage test of epoch 30: loss -27.67428 acc 0.67568 roc_auc 0.56833 prc_auc 0.75180[0m
[92maverage training of epoch 31: loss -28.46331 acc 0.66225 roc_auc 0.36608 prc_auc 0.56720[0m
[93maverage test of epoch 31: loss -29.28460 acc 0.67568 roc_auc 0.49333 prc_auc 0.67777[0m
[92maverage training of epoch 32: loss -30.08734 acc 0.66225 roc_auc 0.37333 prc_auc 0.58010[0m
[93maverage test of epoch 32: loss -30.93668 acc 0.67568 roc_auc 0.48333 prc_auc 0.67162[0m
[92maverage training of epoch 33: loss -31.75195 acc 0.66225 roc_auc 0.37294 prc_auc 0.57497[0m
[93maverage test of epoch 33: loss -32.63048 acc 0.67568 roc_auc 0.34833 prc_auc 0.59810[0m
[92maverage training of epoch 34: loss -33.45978 acc 0.66225 roc_auc 0.37569 prc_auc 0.57631[0m
[93maverage test of epoch 34: loss -34.36041 acc 0.67568 roc_auc 0.43500 prc_auc 0.67062[0m
[92maverage training of epoch 35: loss -35.21046 acc 0.66225 roc_auc 0.37549 prc_auc 0.57514[0m
[93maverage test of epoch 35: loss -36.14396 acc 0.67568 roc_auc 0.43833 prc_auc 0.67646[0m
[92maverage training of epoch 36: loss -37.00315 acc 0.66225 roc_auc 0.37725 prc_auc 0.57617[0m
[93maverage test of epoch 36: loss -37.96326 acc 0.67568 roc_auc 0.46333 prc_auc 0.69385[0m
[92maverage training of epoch 37: loss -38.84317 acc 0.66225 roc_auc 0.37961 prc_auc 0.58000[0m
[93maverage test of epoch 37: loss -39.83050 acc 0.67568 roc_auc 0.44833 prc_auc 0.67561[0m
[92maverage training of epoch 38: loss -40.72663 acc 0.66225 roc_auc 0.38196 prc_auc 0.58056[0m
[93maverage test of epoch 38: loss -41.74437 acc 0.67568 roc_auc 0.39167 prc_auc 0.68447[0m
[92maverage training of epoch 39: loss -42.65422 acc 0.66225 roc_auc 0.38167 prc_auc 0.57970[0m
[93maverage test of epoch 39: loss -43.70419 acc 0.67568 roc_auc 0.45500 prc_auc 0.66901[0m
[92maverage training of epoch 40: loss -44.72798 acc 0.66225 roc_auc 0.38549 prc_auc 0.58460[0m
[93maverage test of epoch 40: loss -45.95067 acc 0.67568 roc_auc 0.55667 prc_auc 0.68856[0m
[92maverage training of epoch 41: loss -47.04297 acc 0.66225 roc_auc 0.38480 prc_auc 0.58474[0m
[93maverage test of epoch 41: loss -48.31269 acc 0.67568 roc_auc 0.42333 prc_auc 0.64974[0m
[92maverage training of epoch 42: loss -49.42416 acc 0.66225 roc_auc 0.38529 prc_auc 0.58298[0m
[93maverage test of epoch 42: loss -50.73376 acc 0.67568 roc_auc 0.57000 prc_auc 0.71755[0m
[92maverage training of epoch 43: loss -51.85790 acc 0.66225 roc_auc 0.38539 prc_auc 0.58551[0m
[93maverage test of epoch 43: loss -53.20808 acc 0.67568 roc_auc 0.51667 prc_auc 0.69108[0m
[92maverage training of epoch 44: loss -54.35116 acc 0.66225 roc_auc 0.38745 prc_auc 0.58647[0m
[93maverage test of epoch 44: loss -55.73883 acc 0.67568 roc_auc 0.53000 prc_auc 0.69478[0m
[92maverage training of epoch 45: loss -56.90286 acc 0.66225 roc_auc 0.38569 prc_auc 0.58543[0m
[93maverage test of epoch 45: loss -58.33307 acc 0.67568 roc_auc 0.58333 prc_auc 0.72698[0m
[92maverage training of epoch 46: loss -59.51684 acc 0.66225 roc_auc 0.38647 prc_auc 0.58495[0m
[93maverage test of epoch 46: loss -60.98535 acc 0.67568 roc_auc 0.54500 prc_auc 0.69794[0m
[92maverage training of epoch 47: loss -62.18869 acc 0.66225 roc_auc 0.38735 prc_auc 0.58631[0m
[93maverage test of epoch 47: loss -63.70300 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -64.92260 acc 0.66225 roc_auc 0.39010 prc_auc 0.58757[0m
[93maverage test of epoch 48: loss -66.47781 acc 0.67568 roc_auc 0.52167 prc_auc 0.68531[0m
[92maverage training of epoch 49: loss -67.71838 acc 0.66225 roc_auc 0.38990 prc_auc 0.58498[0m
[93maverage test of epoch 49: loss -69.31189 acc 0.67568 roc_auc 0.58333 prc_auc 0.71429[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 1)
('lr', 0.0003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.70185 ROC_AUC (avg): 0.59574 PRC_AUC (avg): 0.73262 

Average forward propagation time taken(ms): 4.293664292488452
Average backward propagation time taken(ms): 1.5830323976654948

