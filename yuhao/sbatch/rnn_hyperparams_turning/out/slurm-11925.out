# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 1)
('lr', 0.0001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-22-57-12/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-22-57-12/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 16,
 'epochs': 50,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 8,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.0001,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 2,
 'num_workers': 8,
 'number_of_mlp_layer': 1,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-17-22-57-12',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 50, 'learning_rate': 0.0001, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.91447 acc 0.66667 roc_auc 0.44800 prc_auc 0.68504[0m
[93maverage test of epoch 0: loss -1.15586 acc 0.65789 roc_auc 0.44615 prc_auc 0.61568[0m
[92maverage training of epoch 1: loss -1.50143 acc 0.66667 roc_auc 0.42780 prc_auc 0.65579[0m
[93maverage test of epoch 1: loss -1.87607 acc 0.65789 roc_auc 0.40000 prc_auc 0.61859[0m
[92maverage training of epoch 2: loss -2.26885 acc 0.66667 roc_auc 0.42080 prc_auc 0.64313[0m
[93maverage test of epoch 2: loss -2.66284 acc 0.65789 roc_auc 0.48615 prc_auc 0.68366[0m
[92maverage training of epoch 3: loss -3.06046 acc 0.66667 roc_auc 0.42360 prc_auc 0.61779[0m
[93maverage test of epoch 3: loss -3.34971 acc 0.65789 roc_auc 0.64923 prc_auc 0.80553[0m
[92maverage training of epoch 4: loss -3.73265 acc 0.66667 roc_auc 0.45760 prc_auc 0.66310[0m
[93maverage test of epoch 4: loss -4.11549 acc 0.65789 roc_auc 0.29538 prc_auc 0.57258[0m
[92maverage training of epoch 5: loss -4.58503 acc 0.66667 roc_auc 0.39440 prc_auc 0.62166[0m
[93maverage test of epoch 5: loss -4.98128 acc 0.65789 roc_auc 0.62769 prc_auc 0.79300[0m
[92maverage training of epoch 6: loss -5.38778 acc 0.66667 roc_auc 0.42160 prc_auc 0.62407[0m
[93maverage test of epoch 6: loss -5.72121 acc 0.65789 roc_auc 0.26769 prc_auc 0.54481[0m
[92maverage training of epoch 7: loss -6.18061 acc 0.66667 roc_auc 0.42670 prc_auc 0.60803[0m
[93maverage test of epoch 7: loss -6.51261 acc 0.65789 roc_auc 0.53846 prc_auc 0.69913[0m
[92maverage training of epoch 8: loss -6.98837 acc 0.66667 roc_auc 0.40330 prc_auc 0.60775[0m
[93maverage test of epoch 8: loss -7.34289 acc 0.65789 roc_auc 0.35692 prc_auc 0.57376[0m
[92maverage training of epoch 9: loss -7.85089 acc 0.66667 roc_auc 0.47150 prc_auc 0.69567[0m
[93maverage test of epoch 9: loss -8.24297 acc 0.65789 roc_auc 0.42462 prc_auc 0.60896[0m
[92maverage training of epoch 10: loss -8.71651 acc 0.66667 roc_auc 0.41000 prc_auc 0.61807[0m
[93maverage test of epoch 10: loss -9.07020 acc 0.65789 roc_auc 0.51385 prc_auc 0.71442[0m
[92maverage training of epoch 11: loss -9.50638 acc 0.66667 roc_auc 0.35430 prc_auc 0.57954[0m
[93maverage test of epoch 11: loss -9.88017 acc 0.65789 roc_auc 0.56923 prc_auc 0.69612[0m
[92maverage training of epoch 12: loss -10.29580 acc 0.66667 roc_auc 0.41600 prc_auc 0.65843[0m
[93maverage test of epoch 12: loss -10.65954 acc 0.65789 roc_auc 0.49538 prc_auc 0.63890[0m
[92maverage training of epoch 13: loss -11.08023 acc 0.66667 roc_auc 0.40130 prc_auc 0.61693[0m
[93maverage test of epoch 13: loss -11.39271 acc 0.65789 roc_auc 0.55077 prc_auc 0.71567[0m
[92maverage training of epoch 14: loss -11.86648 acc 0.66667 roc_auc 0.45540 prc_auc 0.65222[0m
[93maverage test of epoch 14: loss -12.19395 acc 0.65789 roc_auc 0.67231 prc_auc 0.79440[0m
[92maverage training of epoch 15: loss -12.63512 acc 0.66667 roc_auc 0.44490 prc_auc 0.65851[0m
[93maverage test of epoch 15: loss -12.95699 acc 0.65789 roc_auc 0.47231 prc_auc 0.67782[0m
[92maverage training of epoch 16: loss -13.42138 acc 0.66667 roc_auc 0.43170 prc_auc 0.64112[0m
[93maverage test of epoch 16: loss -13.72547 acc 0.65789 roc_auc 0.46923 prc_auc 0.67834[0m
[92maverage training of epoch 17: loss -14.20549 acc 0.66667 roc_auc 0.43080 prc_auc 0.64588[0m
[93maverage test of epoch 17: loss -14.51888 acc 0.65789 roc_auc 0.56308 prc_auc 0.75883[0m
[92maverage training of epoch 18: loss -14.99710 acc 0.66667 roc_auc 0.40940 prc_auc 0.61836[0m
[93maverage test of epoch 18: loss -15.32905 acc 0.65789 roc_auc 0.50462 prc_auc 0.66941[0m
[92maverage training of epoch 19: loss -15.81141 acc 0.66667 roc_auc 0.41860 prc_auc 0.63983[0m
[93maverage test of epoch 19: loss -16.14739 acc 0.65789 roc_auc 0.62769 prc_auc 0.80044[0m
[92maverage training of epoch 20: loss -16.61611 acc 0.66667 roc_auc 0.40920 prc_auc 0.60955[0m
[93maverage test of epoch 20: loss -16.94199 acc 0.65789 roc_auc 0.40615 prc_auc 0.63599[0m
[92maverage training of epoch 21: loss -17.44295 acc 0.66667 roc_auc 0.39810 prc_auc 0.63541[0m
[93maverage test of epoch 21: loss -17.76070 acc 0.65789 roc_auc 0.48308 prc_auc 0.64716[0m
[92maverage training of epoch 22: loss -18.27519 acc 0.66667 roc_auc 0.40870 prc_auc 0.60705[0m
[93maverage test of epoch 22: loss -18.60082 acc 0.65789 roc_auc 0.50154 prc_auc 0.69769[0m
[92maverage training of epoch 23: loss -19.10921 acc 0.66667 roc_auc 0.45000 prc_auc 0.64195[0m
[93maverage test of epoch 23: loss -19.43886 acc 0.65789 roc_auc 0.54923 prc_auc 0.69334[0m
[92maverage training of epoch 24: loss -19.96413 acc 0.66667 roc_auc 0.40010 prc_auc 0.62214[0m
[93maverage test of epoch 24: loss -20.28605 acc 0.65789 roc_auc 0.46000 prc_auc 0.65436[0m
[92maverage training of epoch 25: loss -20.82474 acc 0.66667 roc_auc 0.41180 prc_auc 0.61969[0m
[93maverage test of epoch 25: loss -21.15850 acc 0.65789 roc_auc 0.52615 prc_auc 0.70178[0m
[92maverage training of epoch 26: loss -21.69050 acc 0.66667 roc_auc 0.40430 prc_auc 0.60869[0m
[93maverage test of epoch 26: loss -22.03591 acc 0.65789 roc_auc 0.42154 prc_auc 0.62036[0m
[92maverage training of epoch 27: loss -22.57298 acc 0.66667 roc_auc 0.40210 prc_auc 0.61702[0m
[93maverage test of epoch 27: loss -22.91328 acc 0.65789 roc_auc 0.41692 prc_auc 0.62104[0m
[92maverage training of epoch 28: loss -23.46469 acc 0.66667 roc_auc 0.42030 prc_auc 0.63478[0m
[93maverage test of epoch 28: loss -23.79727 acc 0.65789 roc_auc 0.52154 prc_auc 0.66775[0m
[92maverage training of epoch 29: loss -24.37330 acc 0.66667 roc_auc 0.40700 prc_auc 0.62051[0m
[93maverage test of epoch 29: loss -24.69939 acc 0.65789 roc_auc 0.42462 prc_auc 0.62567[0m
[92maverage training of epoch 30: loss -25.29331 acc 0.66667 roc_auc 0.42110 prc_auc 0.62789[0m
[93maverage test of epoch 30: loss -25.63917 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -26.22009 acc 0.66667 roc_auc 0.42390 prc_auc 0.63325[0m
[93maverage test of epoch 31: loss -26.57311 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -27.16039 acc 0.66667 roc_auc 0.39000 prc_auc 0.62310[0m
[93maverage test of epoch 32: loss -27.49728 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -28.12423 acc 0.66667 roc_auc 0.42000 prc_auc 0.63401[0m
[93maverage test of epoch 33: loss -28.46415 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -29.09274 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -29.44487 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -30.06699 acc 0.66667 roc_auc 0.40000 prc_auc 0.62951[0m
[93maverage test of epoch 35: loss -30.42461 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -31.06286 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -31.42362 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -32.07485 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -32.43115 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -33.09469 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -33.46101 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -34.13013 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -34.49601 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -35.17523 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -35.54719 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -36.24386 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -36.60997 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -37.32582 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -37.70181 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -38.41859 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -38.80043 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -39.52448 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -39.90771 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -40.64226 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -41.03246 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -41.78483 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -42.17563 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -42.93613 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -43.32646 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -44.09971 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -44.49239 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -45.28695 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -45.68086 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss 0.15520 acc 0.66667 roc_auc 0.49700 prc_auc 0.66281[0m
[93maverage test of epoch 0: loss -0.11465 acc 0.65789 roc_auc 0.51077 prc_auc 0.66618[0m
[92maverage training of epoch 1: loss -0.44880 acc 0.66667 roc_auc 0.53760 prc_auc 0.70748[0m
[93maverage test of epoch 1: loss -0.68221 acc 0.65789 roc_auc 0.78769 prc_auc 0.89346[0m
[92maverage training of epoch 2: loss -0.89426 acc 0.66667 roc_auc 0.59680 prc_auc 0.76081[0m
[93maverage test of epoch 2: loss -1.09412 acc 0.65789 roc_auc 0.76923 prc_auc 0.85265[0m
[92maverage training of epoch 3: loss -1.26932 acc 0.66667 roc_auc 0.55160 prc_auc 0.72296[0m
[93maverage test of epoch 3: loss -1.45914 acc 0.65789 roc_auc 0.87077 prc_auc 0.93505[0m
[92maverage training of epoch 4: loss -1.61642 acc 0.66667 roc_auc 0.69000 prc_auc 0.84055[0m
[93maverage test of epoch 4: loss -1.75308 acc 0.65789 roc_auc 0.79385 prc_auc 0.89293[0m
[92maverage training of epoch 5: loss -1.91861 acc 0.66667 roc_auc 0.76700 prc_auc 0.88879[0m
[93maverage test of epoch 5: loss -2.02464 acc 0.65789 roc_auc 0.76923 prc_auc 0.84053[0m
[92maverage training of epoch 6: loss -2.21079 acc 0.66667 roc_auc 0.77680 prc_auc 0.89340[0m
[93maverage test of epoch 6: loss -2.37143 acc 0.65789 roc_auc 0.86462 prc_auc 0.93154[0m
[92maverage training of epoch 7: loss -2.54049 acc 0.66667 roc_auc 0.86280 prc_auc 0.93417[0m
[93maverage test of epoch 7: loss -2.66091 acc 0.65789 roc_auc 0.87692 prc_auc 0.92784[0m
[92maverage training of epoch 8: loss -2.83309 acc 0.66667 roc_auc 0.86620 prc_auc 0.93069[0m
[93maverage test of epoch 8: loss -2.95593 acc 0.65789 roc_auc 0.85538 prc_auc 0.92285[0m
[92maverage training of epoch 9: loss -3.17384 acc 0.66667 roc_auc 0.85640 prc_auc 0.92311[0m
[93maverage test of epoch 9: loss -3.27781 acc 0.65789 roc_auc 0.84308 prc_auc 0.93120[0m
[92maverage training of epoch 10: loss -3.54126 acc 0.66667 roc_auc 0.88600 prc_auc 0.94127[0m
[93maverage test of epoch 10: loss -3.63543 acc 0.65789 roc_auc 0.88000 prc_auc 0.93999[0m
[92maverage training of epoch 11: loss -3.91282 acc 0.66667 roc_auc 0.88800 prc_auc 0.94454[0m
[93maverage test of epoch 11: loss -4.04886 acc 0.65789 roc_auc 0.89538 prc_auc 0.94275[0m
[92maverage training of epoch 12: loss -4.29335 acc 0.66667 roc_auc 0.88700 prc_auc 0.94498[0m
[93maverage test of epoch 12: loss -4.44252 acc 0.65789 roc_auc 0.87692 prc_auc 0.93153[0m
[92maverage training of epoch 13: loss -4.65431 acc 0.66667 roc_auc 0.88000 prc_auc 0.93798[0m
[93maverage test of epoch 13: loss -4.83356 acc 0.65789 roc_auc 0.89538 prc_auc 0.94203[0m
[92maverage training of epoch 14: loss -5.08495 acc 0.66667 roc_auc 0.87860 prc_auc 0.94703[0m
[93maverage test of epoch 14: loss -5.18653 acc 0.65789 roc_auc 0.85231 prc_auc 0.92313[0m
[92maverage training of epoch 15: loss -5.52476 acc 0.66667 roc_auc 0.87560 prc_auc 0.94340[0m
[93maverage test of epoch 15: loss -5.59221 acc 0.65789 roc_auc 0.87692 prc_auc 0.92902[0m
[92maverage training of epoch 16: loss -5.93636 acc 0.66667 roc_auc 0.87700 prc_auc 0.92700[0m
[93maverage test of epoch 16: loss -6.04724 acc 0.65789 roc_auc 0.90154 prc_auc 0.94903[0m
[92maverage training of epoch 17: loss -6.39671 acc 0.66667 roc_auc 0.89440 prc_auc 0.94078[0m
[93maverage test of epoch 17: loss -6.52795 acc 0.65789 roc_auc 0.90769 prc_auc 0.94494[0m
[92maverage training of epoch 18: loss -6.83293 acc 0.66667 roc_auc 0.88240 prc_auc 0.89311[0m
[93maverage test of epoch 18: loss -6.99117 acc 0.65789 roc_auc 0.85231 prc_auc 0.90258[0m
[92maverage training of epoch 19: loss -7.25809 acc 0.66667 roc_auc 0.87640 prc_auc 0.91163[0m
[93maverage test of epoch 19: loss -7.36114 acc 0.65789 roc_auc 0.88000 prc_auc 0.93091[0m
[92maverage training of epoch 20: loss -7.66688 acc 0.66667 roc_auc 0.87620 prc_auc 0.92612[0m
[93maverage test of epoch 20: loss -7.81839 acc 0.65789 roc_auc 0.84923 prc_auc 0.90063[0m
[92maverage training of epoch 21: loss -8.07321 acc 0.66667 roc_auc 0.85990 prc_auc 0.91165[0m
[93maverage test of epoch 21: loss -8.15112 acc 0.65789 roc_auc 0.86154 prc_auc 0.89421[0m
[92maverage training of epoch 22: loss -8.45858 acc 0.66667 roc_auc 0.87380 prc_auc 0.90353[0m
[93maverage test of epoch 22: loss -8.56828 acc 0.65789 roc_auc 0.74769 prc_auc 0.77876[0m
[92maverage training of epoch 23: loss -8.85487 acc 0.66667 roc_auc 0.86140 prc_auc 0.86654[0m
[93maverage test of epoch 23: loss -8.98285 acc 0.65789 roc_auc 0.78308 prc_auc 0.79712[0m
[92maverage training of epoch 24: loss -9.28415 acc 0.66667 roc_auc 0.87300 prc_auc 0.91118[0m
[93maverage test of epoch 24: loss -9.36329 acc 0.65789 roc_auc 0.78462 prc_auc 0.83108[0m
[92maverage training of epoch 25: loss -9.63169 acc 0.66667 roc_auc 0.85800 prc_auc 0.88935[0m
[93maverage test of epoch 25: loss -9.81536 acc 0.65789 roc_auc 0.79538 prc_auc 0.82323[0m
[92maverage training of epoch 26: loss -10.07069 acc 0.66667 roc_auc 0.85240 prc_auc 0.88742[0m
[93maverage test of epoch 26: loss -10.14633 acc 0.65789 roc_auc 0.81077 prc_auc 0.83058[0m
[92maverage training of epoch 27: loss -10.46726 acc 0.66667 roc_auc 0.87040 prc_auc 0.89077[0m
[93maverage test of epoch 27: loss -10.56522 acc 0.65789 roc_auc 0.81692 prc_auc 0.83789[0m
[92maverage training of epoch 28: loss -10.87280 acc 0.66667 roc_auc 0.85650 prc_auc 0.89253[0m
[93maverage test of epoch 28: loss -11.03476 acc 0.65789 roc_auc 0.78462 prc_auc 0.83103[0m
[92maverage training of epoch 29: loss -11.28736 acc 0.66667 roc_auc 0.86310 prc_auc 0.88860[0m
[93maverage test of epoch 29: loss -11.40214 acc 0.65789 roc_auc 0.79538 prc_auc 0.82693[0m
[92maverage training of epoch 30: loss -11.70605 acc 0.66667 roc_auc 0.86460 prc_auc 0.89698[0m
[93maverage test of epoch 30: loss -11.77513 acc 0.65789 roc_auc 0.73692 prc_auc 0.78366[0m
[92maverage training of epoch 31: loss -12.09903 acc 0.66667 roc_auc 0.87550 prc_auc 0.88992[0m
[93maverage test of epoch 31: loss -12.20452 acc 0.65789 roc_auc 0.91231 prc_auc 0.94738[0m
[92maverage training of epoch 32: loss -12.51803 acc 0.66667 roc_auc 0.86240 prc_auc 0.87584[0m
[93maverage test of epoch 32: loss -12.55319 acc 0.65789 roc_auc 0.86769 prc_auc 0.88736[0m
[92maverage training of epoch 33: loss -12.92994 acc 0.66667 roc_auc 0.86320 prc_auc 0.88806[0m
[93maverage test of epoch 33: loss -13.10973 acc 0.65789 roc_auc 0.85692 prc_auc 0.88420[0m
[92maverage training of epoch 34: loss -13.38874 acc 0.66667 roc_auc 0.87420 prc_auc 0.90386[0m
[93maverage test of epoch 34: loss -13.56341 acc 0.65789 roc_auc 0.84769 prc_auc 0.88832[0m
[92maverage training of epoch 35: loss -13.81923 acc 0.66667 roc_auc 0.84160 prc_auc 0.87401[0m
[93maverage test of epoch 35: loss -14.01611 acc 0.65789 roc_auc 0.78154 prc_auc 0.80120[0m
[92maverage training of epoch 36: loss -14.28179 acc 0.66667 roc_auc 0.85520 prc_auc 0.90101[0m
[93maverage test of epoch 36: loss -14.42022 acc 0.65789 roc_auc 0.81538 prc_auc 0.81346[0m
[92maverage training of epoch 37: loss -14.72407 acc 0.66667 roc_auc 0.88340 prc_auc 0.91750[0m
[93maverage test of epoch 37: loss -14.87034 acc 0.65789 roc_auc 0.90923 prc_auc 0.93961[0m
[92maverage training of epoch 38: loss -15.17467 acc 0.66667 roc_auc 0.86650 prc_auc 0.89213[0m
[93maverage test of epoch 38: loss -15.33960 acc 0.65789 roc_auc 0.90923 prc_auc 0.91444[0m
[92maverage training of epoch 39: loss -15.64906 acc 0.66667 roc_auc 0.86940 prc_auc 0.89964[0m
[93maverage test of epoch 39: loss -15.84330 acc 0.65789 roc_auc 0.86615 prc_auc 0.87992[0m
[92maverage training of epoch 40: loss -16.11315 acc 0.66667 roc_auc 0.85720 prc_auc 0.89543[0m
[93maverage test of epoch 40: loss -16.24339 acc 0.65789 roc_auc 0.85846 prc_auc 0.87637[0m
[92maverage training of epoch 41: loss -16.59097 acc 0.66667 roc_auc 0.87170 prc_auc 0.90456[0m
[93maverage test of epoch 41: loss -16.75978 acc 0.65789 roc_auc 0.79077 prc_auc 0.82218[0m
[92maverage training of epoch 42: loss -17.07751 acc 0.66667 roc_auc 0.85810 prc_auc 0.89915[0m
[93maverage test of epoch 42: loss -17.18500 acc 0.65789 roc_auc 0.84000 prc_auc 0.85734[0m
[92maverage training of epoch 43: loss -17.54799 acc 0.66667 roc_auc 0.86040 prc_auc 0.90765[0m
[93maverage test of epoch 43: loss -17.79657 acc 0.65789 roc_auc 0.84615 prc_auc 0.86207[0m
[92maverage training of epoch 44: loss -18.08644 acc 0.66667 roc_auc 0.87250 prc_auc 0.91017[0m
[93maverage test of epoch 44: loss -18.21035 acc 0.65789 roc_auc 0.84615 prc_auc 0.86207[0m
[92maverage training of epoch 45: loss -18.55877 acc 0.66667 roc_auc 0.87380 prc_auc 0.91280[0m
[93maverage test of epoch 45: loss -18.77199 acc 0.65789 roc_auc 0.83538 prc_auc 0.85386[0m
[92maverage training of epoch 46: loss -19.10101 acc 0.66667 roc_auc 0.87920 prc_auc 0.92417[0m
[93maverage test of epoch 46: loss -19.30419 acc 0.65789 roc_auc 0.84615 prc_auc 0.86207[0m
[92maverage training of epoch 47: loss -19.60463 acc 0.66667 roc_auc 0.88620 prc_auc 0.92983[0m
[93maverage test of epoch 47: loss -19.83606 acc 0.65789 roc_auc 0.84615 prc_auc 0.86207[0m
[92maverage training of epoch 48: loss -20.16564 acc 0.66667 roc_auc 0.88300 prc_auc 0.92350[0m
[93maverage test of epoch 48: loss -20.35522 acc 0.65789 roc_auc 0.76923 prc_auc 0.80769[0m
[92maverage training of epoch 49: loss -20.64216 acc 0.66667 roc_auc 0.88890 prc_auc 0.92571[0m
[93maverage test of epoch 49: loss -20.90410 acc 0.65789 roc_auc 0.84615 prc_auc 0.86207[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.45030 acc 0.58000 roc_auc 0.49380 prc_auc 0.66843[0m
[93maverage test of epoch 0: loss -0.59109 acc 0.65789 roc_auc 0.72000 prc_auc 0.83413[0m
[92maverage training of epoch 1: loss -0.68430 acc 0.66667 roc_auc 0.51120 prc_auc 0.69108[0m
[93maverage test of epoch 1: loss -0.81172 acc 0.65789 roc_auc 0.65846 prc_auc 0.80152[0m
[92maverage training of epoch 2: loss -0.92139 acc 0.66667 roc_auc 0.58300 prc_auc 0.72680[0m
[93maverage test of epoch 2: loss -1.03015 acc 0.65789 roc_auc 0.70462 prc_auc 0.85697[0m
[92maverage training of epoch 3: loss -1.18086 acc 0.66667 roc_auc 0.66920 prc_auc 0.75975[0m
[93maverage test of epoch 3: loss -1.31025 acc 0.65789 roc_auc 0.86769 prc_auc 0.92538[0m
[92maverage training of epoch 4: loss -1.43984 acc 0.66667 roc_auc 0.75680 prc_auc 0.80768[0m
[93maverage test of epoch 4: loss -1.63134 acc 0.65789 roc_auc 0.88000 prc_auc 0.94249[0m
[92maverage training of epoch 5: loss -1.81214 acc 0.66667 roc_auc 0.80620 prc_auc 0.87755[0m
[93maverage test of epoch 5: loss -1.98558 acc 0.65789 roc_auc 0.87385 prc_auc 0.94864[0m
[92maverage training of epoch 6: loss -2.22067 acc 0.66667 roc_auc 0.79860 prc_auc 0.84368[0m
[93maverage test of epoch 6: loss -2.42220 acc 0.65789 roc_auc 0.85231 prc_auc 0.90813[0m
[92maverage training of epoch 7: loss -2.66033 acc 0.66667 roc_auc 0.79660 prc_auc 0.83236[0m
[93maverage test of epoch 7: loss -2.95176 acc 0.65789 roc_auc 0.88615 prc_auc 0.93572[0m
[92maverage training of epoch 8: loss -3.16964 acc 0.66667 roc_auc 0.79200 prc_auc 0.81236[0m
[93maverage test of epoch 8: loss -3.51936 acc 0.65789 roc_auc 0.89231 prc_auc 0.87446[0m
[92maverage training of epoch 9: loss -3.68078 acc 0.66667 roc_auc 0.81160 prc_auc 0.84827[0m
[93maverage test of epoch 9: loss -3.97062 acc 0.65789 roc_auc 0.90154 prc_auc 0.94743[0m
[92maverage training of epoch 10: loss -4.16959 acc 0.66667 roc_auc 0.80820 prc_auc 0.83243[0m
[93maverage test of epoch 10: loss -4.44121 acc 0.65789 roc_auc 0.93231 prc_auc 0.96312[0m
[92maverage training of epoch 11: loss -4.64083 acc 0.66667 roc_auc 0.79180 prc_auc 0.84583[0m
[93maverage test of epoch 11: loss -4.87972 acc 0.65789 roc_auc 0.92000 prc_auc 0.94490[0m
[92maverage training of epoch 12: loss -5.10714 acc 0.66667 roc_auc 0.81000 prc_auc 0.86155[0m
[93maverage test of epoch 12: loss -5.32571 acc 0.65789 roc_auc 0.93538 prc_auc 0.96199[0m
[92maverage training of epoch 13: loss -5.56888 acc 0.66667 roc_auc 0.79230 prc_auc 0.86306[0m
[93maverage test of epoch 13: loss -5.76117 acc 0.65789 roc_auc 0.89231 prc_auc 0.93533[0m
[92maverage training of epoch 14: loss -6.08087 acc 0.66667 roc_auc 0.74050 prc_auc 0.80420[0m
[93maverage test of epoch 14: loss -6.24361 acc 0.65789 roc_auc 0.80923 prc_auc 0.88056[0m
[92maverage training of epoch 15: loss -6.56577 acc 0.66667 roc_auc 0.55740 prc_auc 0.72102[0m
[93maverage test of epoch 15: loss -6.76718 acc 0.65789 roc_auc 0.65231 prc_auc 0.78706[0m
[92maverage training of epoch 16: loss -7.09456 acc 0.66667 roc_auc 0.51950 prc_auc 0.68452[0m
[93maverage test of epoch 16: loss -7.31385 acc 0.65789 roc_auc 0.74462 prc_auc 0.88154[0m
[92maverage training of epoch 17: loss -7.61495 acc 0.66667 roc_auc 0.50850 prc_auc 0.69989[0m
[93maverage test of epoch 17: loss -7.81475 acc 0.65789 roc_auc 0.66923 prc_auc 0.83830[0m
[92maverage training of epoch 18: loss -8.13608 acc 0.66667 roc_auc 0.43760 prc_auc 0.62722[0m
[93maverage test of epoch 18: loss -8.32786 acc 0.65789 roc_auc 0.45231 prc_auc 0.72511[0m
[92maverage training of epoch 19: loss -8.69668 acc 0.66667 roc_auc 0.54760 prc_auc 0.70738[0m
[93maverage test of epoch 19: loss -8.87436 acc 0.65789 roc_auc 0.60923 prc_auc 0.77587[0m
[92maverage training of epoch 20: loss -9.25503 acc 0.66667 roc_auc 0.47320 prc_auc 0.66495[0m
[93maverage test of epoch 20: loss -9.44885 acc 0.65789 roc_auc 0.51077 prc_auc 0.66532[0m
[92maverage training of epoch 21: loss -9.79914 acc 0.66667 roc_auc 0.43770 prc_auc 0.66902[0m
[93maverage test of epoch 21: loss -9.99867 acc 0.65789 roc_auc 0.46615 prc_auc 0.68429[0m
[92maverage training of epoch 22: loss -10.37952 acc 0.66667 roc_auc 0.47890 prc_auc 0.68345[0m
[93maverage test of epoch 22: loss -10.57383 acc 0.65789 roc_auc 0.74154 prc_auc 0.85961[0m
[92maverage training of epoch 23: loss -10.94571 acc 0.66667 roc_auc 0.44250 prc_auc 0.64115[0m
[93maverage test of epoch 23: loss -11.15925 acc 0.65789 roc_auc 0.47077 prc_auc 0.69324[0m
[92maverage training of epoch 24: loss -11.51793 acc 0.66667 roc_auc 0.45090 prc_auc 0.65847[0m
[93maverage test of epoch 24: loss -11.73623 acc 0.65789 roc_auc 0.56923 prc_auc 0.67731[0m
[92maverage training of epoch 25: loss -12.10936 acc 0.66667 roc_auc 0.43540 prc_auc 0.61185[0m
[93maverage test of epoch 25: loss -12.32424 acc 0.65789 roc_auc 0.76923 prc_auc 0.86758[0m
[92maverage training of epoch 26: loss -12.69520 acc 0.66667 roc_auc 0.42250 prc_auc 0.63080[0m
[93maverage test of epoch 26: loss -12.90180 acc 0.65789 roc_auc 0.65385 prc_auc 0.74042[0m
[92maverage training of epoch 27: loss -13.30957 acc 0.66667 roc_auc 0.46610 prc_auc 0.65800[0m
[93maverage test of epoch 27: loss -13.48742 acc 0.65789 roc_auc 0.55385 prc_auc 0.72277[0m
[92maverage training of epoch 28: loss -13.90297 acc 0.66667 roc_auc 0.39710 prc_auc 0.62555[0m
[93maverage test of epoch 28: loss -14.11001 acc 0.65789 roc_auc 0.49538 prc_auc 0.65786[0m
[92maverage training of epoch 29: loss -14.54129 acc 0.66667 roc_auc 0.41270 prc_auc 0.61744[0m
[93maverage test of epoch 29: loss -14.73673 acc 0.65789 roc_auc 0.65692 prc_auc 0.75376[0m
[92maverage training of epoch 30: loss -15.15656 acc 0.66667 roc_auc 0.43980 prc_auc 0.63542[0m
[93maverage test of epoch 30: loss -15.36702 acc 0.65789 roc_auc 0.38000 prc_auc 0.60914[0m
[92maverage training of epoch 31: loss -15.79910 acc 0.66667 roc_auc 0.40170 prc_auc 0.62116[0m
[93maverage test of epoch 31: loss -16.00794 acc 0.65789 roc_auc 0.44000 prc_auc 0.63209[0m
[92maverage training of epoch 32: loss -16.45518 acc 0.66667 roc_auc 0.46500 prc_auc 0.65165[0m
[93maverage test of epoch 32: loss -16.64767 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -17.09426 acc 0.66667 roc_auc 0.46500 prc_auc 0.65159[0m
[93maverage test of epoch 33: loss -17.30683 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -17.75961 acc 0.66667 roc_auc 0.45500 prc_auc 0.64763[0m
[93maverage test of epoch 34: loss -17.95887 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -18.42595 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -18.62578 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -19.10368 acc 0.66667 roc_auc 0.48000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -19.30868 acc 0.65789 roc_auc 0.47077 prc_auc 0.64526[0m
[92maverage training of epoch 37: loss -19.80562 acc 0.66667 roc_auc 0.48000 prc_auc 0.65790[0m
[93maverage test of epoch 37: loss -20.00551 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -20.49326 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -20.71930 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -21.20887 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -21.41351 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -21.93399 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -22.14425 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -22.66181 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -22.87208 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -23.41016 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -23.61807 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -24.16035 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -24.37566 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -24.92765 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -25.15958 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -25.70790 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -25.92781 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -26.50113 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -26.72435 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -27.29293 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -27.52250 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -28.11449 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -28.33474 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -28.93870 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -29.16250 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss 0.16145 acc 0.33775 roc_auc 0.52608 prc_auc 0.67513[0m
[93maverage test of epoch 0: loss -0.13361 acc 0.32432 roc_auc 0.51000 prc_auc 0.73390[0m
[92maverage training of epoch 1: loss -0.27882 acc 0.33775 roc_auc 0.46647 prc_auc 0.65136[0m
[93maverage test of epoch 1: loss -0.38845 acc 0.32432 roc_auc 0.47000 prc_auc 0.64373[0m
[92maverage training of epoch 2: loss -0.49678 acc 0.33775 roc_auc 0.43059 prc_auc 0.63350[0m
[93maverage test of epoch 2: loss -0.59242 acc 0.32432 roc_auc 0.57667 prc_auc 0.74139[0m
[92maverage training of epoch 3: loss -0.72649 acc 0.33775 roc_auc 0.41745 prc_auc 0.63181[0m
[93maverage test of epoch 3: loss -0.92645 acc 0.32432 roc_auc 0.41667 prc_auc 0.62040[0m
[92maverage training of epoch 4: loss -1.16734 acc 0.33775 roc_auc 0.43353 prc_auc 0.63080[0m
[93maverage test of epoch 4: loss -1.39046 acc 0.32432 roc_auc 0.46000 prc_auc 0.63844[0m
[92maverage training of epoch 5: loss -1.63831 acc 0.34437 roc_auc 0.44098 prc_auc 0.63068[0m
[93maverage test of epoch 5: loss -1.87509 acc 0.45946 roc_auc 0.55667 prc_auc 0.74735[0m
[92maverage training of epoch 6: loss -2.11231 acc 0.60927 roc_auc 0.41902 prc_auc 0.61620[0m
[93maverage test of epoch 6: loss -2.35968 acc 0.67568 roc_auc 0.52667 prc_auc 0.70946[0m
[92maverage training of epoch 7: loss -2.57223 acc 0.66225 roc_auc 0.42196 prc_auc 0.60879[0m
[93maverage test of epoch 7: loss -2.78552 acc 0.67568 roc_auc 0.44667 prc_auc 0.67068[0m
[92maverage training of epoch 8: loss -2.97187 acc 0.66225 roc_auc 0.46784 prc_auc 0.65100[0m
[93maverage test of epoch 8: loss -3.15744 acc 0.67568 roc_auc 0.52000 prc_auc 0.72618[0m
[92maverage training of epoch 9: loss -3.33464 acc 0.66225 roc_auc 0.39980 prc_auc 0.59427[0m
[93maverage test of epoch 9: loss -3.51468 acc 0.67568 roc_auc 0.46000 prc_auc 0.66909[0m
[92maverage training of epoch 10: loss -3.68161 acc 0.66225 roc_auc 0.40078 prc_auc 0.60396[0m
[93maverage test of epoch 10: loss -3.85470 acc 0.67568 roc_auc 0.55667 prc_auc 0.71204[0m
[92maverage training of epoch 11: loss -4.01730 acc 0.66225 roc_auc 0.40961 prc_auc 0.60522[0m
[93maverage test of epoch 11: loss -4.18041 acc 0.67568 roc_auc 0.48333 prc_auc 0.70360[0m
[92maverage training of epoch 12: loss -4.34940 acc 0.66225 roc_auc 0.34961 prc_auc 0.56200[0m
[93maverage test of epoch 12: loss -4.52216 acc 0.67568 roc_auc 0.39667 prc_auc 0.64189[0m
[92maverage training of epoch 13: loss -4.68562 acc 0.66225 roc_auc 0.45353 prc_auc 0.64336[0m
[93maverage test of epoch 13: loss -4.85907 acc 0.67568 roc_auc 0.41667 prc_auc 0.62628[0m
[92maverage training of epoch 14: loss -5.01422 acc 0.66225 roc_auc 0.42157 prc_auc 0.61562[0m
[93maverage test of epoch 14: loss -5.18366 acc 0.67568 roc_auc 0.66000 prc_auc 0.84862[0m
[92maverage training of epoch 15: loss -5.34065 acc 0.66225 roc_auc 0.46902 prc_auc 0.64177[0m
[93maverage test of epoch 15: loss -5.51381 acc 0.67568 roc_auc 0.50333 prc_auc 0.72871[0m
[92maverage training of epoch 16: loss -5.67008 acc 0.66225 roc_auc 0.44961 prc_auc 0.65078[0m
[93maverage test of epoch 16: loss -5.85006 acc 0.67568 roc_auc 0.54000 prc_auc 0.69372[0m
[92maverage training of epoch 17: loss -6.00736 acc 0.66225 roc_auc 0.41922 prc_auc 0.61989[0m
[93maverage test of epoch 17: loss -6.19552 acc 0.67568 roc_auc 0.54667 prc_auc 0.77583[0m
[92maverage training of epoch 18: loss -6.35094 acc 0.66225 roc_auc 0.43216 prc_auc 0.65777[0m
[93maverage test of epoch 18: loss -6.53651 acc 0.67568 roc_auc 0.34000 prc_auc 0.58054[0m
[92maverage training of epoch 19: loss -6.70685 acc 0.66225 roc_auc 0.40922 prc_auc 0.60620[0m
[93maverage test of epoch 19: loss -6.91514 acc 0.67568 roc_auc 0.62667 prc_auc 0.73632[0m
[92maverage training of epoch 20: loss -7.09088 acc 0.66225 roc_auc 0.41725 prc_auc 0.61419[0m
[93maverage test of epoch 20: loss -7.30946 acc 0.67568 roc_auc 0.46000 prc_auc 0.68482[0m
[92maverage training of epoch 21: loss -7.48765 acc 0.66225 roc_auc 0.41608 prc_auc 0.61801[0m
[93maverage test of epoch 21: loss -7.70225 acc 0.67568 roc_auc 0.47000 prc_auc 0.65884[0m
[92maverage training of epoch 22: loss -7.88429 acc 0.66225 roc_auc 0.42902 prc_auc 0.61061[0m
[93maverage test of epoch 22: loss -8.09744 acc 0.67568 roc_auc 0.65000 prc_auc 0.78445[0m
[92maverage training of epoch 23: loss -8.27030 acc 0.66225 roc_auc 0.42176 prc_auc 0.60822[0m
[93maverage test of epoch 23: loss -8.48120 acc 0.67568 roc_auc 0.34333 prc_auc 0.63775[0m
[92maverage training of epoch 24: loss -8.65658 acc 0.66225 roc_auc 0.39353 prc_auc 0.60159[0m
[93maverage test of epoch 24: loss -8.87648 acc 0.67568 roc_auc 0.51000 prc_auc 0.71209[0m
[92maverage training of epoch 25: loss -9.04287 acc 0.66225 roc_auc 0.42608 prc_auc 0.61164[0m
[93maverage test of epoch 25: loss -9.25994 acc 0.67568 roc_auc 0.29667 prc_auc 0.59606[0m
[92maverage training of epoch 26: loss -9.43639 acc 0.66225 roc_auc 0.41824 prc_auc 0.60464[0m
[93maverage test of epoch 26: loss -9.66379 acc 0.67568 roc_auc 0.66667 prc_auc 0.79690[0m
[92maverage training of epoch 27: loss -9.82877 acc 0.66225 roc_auc 0.39431 prc_auc 0.58626[0m
[93maverage test of epoch 27: loss -10.05780 acc 0.67568 roc_auc 0.64667 prc_auc 0.78421[0m
[92maverage training of epoch 28: loss -10.23118 acc 0.66225 roc_auc 0.41412 prc_auc 0.60859[0m
[93maverage test of epoch 28: loss -10.46462 acc 0.67568 roc_auc 0.40667 prc_auc 0.68232[0m
[92maverage training of epoch 29: loss -10.63617 acc 0.66225 roc_auc 0.42176 prc_auc 0.60789[0m
[93maverage test of epoch 29: loss -10.86519 acc 0.67568 roc_auc 0.50667 prc_auc 0.71231[0m
[92maverage training of epoch 30: loss -11.04577 acc 0.66225 roc_auc 0.41333 prc_auc 0.59642[0m
[93maverage test of epoch 30: loss -11.28027 acc 0.67568 roc_auc 0.65333 prc_auc 0.79545[0m
[92maverage training of epoch 31: loss -11.45793 acc 0.66225 roc_auc 0.41373 prc_auc 0.59606[0m
[93maverage test of epoch 31: loss -11.70155 acc 0.67568 roc_auc 0.49000 prc_auc 0.69419[0m
[92maverage training of epoch 32: loss -11.87768 acc 0.66225 roc_auc 0.41961 prc_auc 0.60404[0m
[93maverage test of epoch 32: loss -12.12207 acc 0.67568 roc_auc 0.41667 prc_auc 0.68748[0m
[92maverage training of epoch 33: loss -12.29727 acc 0.66225 roc_auc 0.41451 prc_auc 0.59923[0m
[93maverage test of epoch 33: loss -12.54736 acc 0.67568 roc_auc 0.39167 prc_auc 0.60591[0m
[92maverage training of epoch 34: loss -12.72741 acc 0.66225 roc_auc 0.41245 prc_auc 0.59902[0m
[93maverage test of epoch 34: loss -12.97830 acc 0.67568 roc_auc 0.29333 prc_auc 0.59270[0m
[92maverage training of epoch 35: loss -13.15751 acc 0.66225 roc_auc 0.44529 prc_auc 0.62517[0m
[93maverage test of epoch 35: loss -13.41606 acc 0.67568 roc_auc 0.42833 prc_auc 0.62539[0m
[92maverage training of epoch 36: loss -13.59568 acc 0.66225 roc_auc 0.41529 prc_auc 0.60685[0m
[93maverage test of epoch 36: loss -13.86114 acc 0.67568 roc_auc 0.48667 prc_auc 0.68224[0m
[92maverage training of epoch 37: loss -14.04071 acc 0.66225 roc_auc 0.42343 prc_auc 0.61133[0m
[93maverage test of epoch 37: loss -14.30559 acc 0.67568 roc_auc 0.55000 prc_auc 0.73658[0m
[92maverage training of epoch 38: loss -14.48792 acc 0.66225 roc_auc 0.42588 prc_auc 0.61286[0m
[93maverage test of epoch 38: loss -14.75490 acc 0.67568 roc_auc 0.41833 prc_auc 0.66627[0m
[92maverage training of epoch 39: loss -14.93999 acc 0.66225 roc_auc 0.41569 prc_auc 0.60251[0m
[93maverage test of epoch 39: loss -15.21473 acc 0.67568 roc_auc 0.53333 prc_auc 0.71069[0m
[92maverage training of epoch 40: loss -15.39538 acc 0.66225 roc_auc 0.41373 prc_auc 0.60173[0m
[93maverage test of epoch 40: loss -15.67394 acc 0.67568 roc_auc 0.45000 prc_auc 0.66832[0m
[92maverage training of epoch 41: loss -15.85791 acc 0.66225 roc_auc 0.41667 prc_auc 0.60713[0m
[93maverage test of epoch 41: loss -16.14026 acc 0.67568 roc_auc 0.54333 prc_auc 0.69631[0m
[92maverage training of epoch 42: loss -16.32599 acc 0.66225 roc_auc 0.41667 prc_auc 0.60053[0m
[93maverage test of epoch 42: loss -16.61027 acc 0.67568 roc_auc 0.54500 prc_auc 0.72458[0m
[92maverage training of epoch 43: loss -16.79776 acc 0.66225 roc_auc 0.41431 prc_auc 0.60299[0m
[93maverage test of epoch 43: loss -17.08886 acc 0.67568 roc_auc 0.68333 prc_auc 0.85892[0m
[92maverage training of epoch 44: loss -17.27218 acc 0.66225 roc_auc 0.41784 prc_auc 0.60707[0m
[93maverage test of epoch 44: loss -17.56727 acc 0.67568 roc_auc 0.45167 prc_auc 0.72653[0m
[92maverage training of epoch 45: loss -17.75584 acc 0.66225 roc_auc 0.41882 prc_auc 0.60374[0m
[93maverage test of epoch 45: loss -18.05382 acc 0.67568 roc_auc 0.57333 prc_auc 0.77052[0m
[92maverage training of epoch 46: loss -18.24151 acc 0.66225 roc_auc 0.41863 prc_auc 0.60167[0m
[93maverage test of epoch 46: loss -18.54515 acc 0.67568 roc_auc 0.38167 prc_auc 0.60745[0m
[92maverage training of epoch 47: loss -18.73547 acc 0.66225 roc_auc 0.42098 prc_auc 0.60704[0m
[93maverage test of epoch 47: loss -19.03974 acc 0.67568 roc_auc 0.69833 prc_auc 0.85356[0m
[92maverage training of epoch 48: loss -19.23413 acc 0.66225 roc_auc 0.41549 prc_auc 0.60307[0m
[93maverage test of epoch 48: loss -19.54694 acc 0.67568 roc_auc 0.47667 prc_auc 0.65781[0m
[92maverage training of epoch 49: loss -19.73734 acc 0.66225 roc_auc 0.42863 prc_auc 0.61016[0m
[93maverage test of epoch 49: loss -20.05558 acc 0.67568 roc_auc 0.55500 prc_auc 0.75685[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=8, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss 1.52320 acc 0.33775 roc_auc 0.61824 prc_auc 0.74633[0m
[93maverage test of epoch 0: loss 1.06996 acc 0.32432 roc_auc 0.36667 prc_auc 0.63986[0m
[92maverage training of epoch 1: loss 0.47478 acc 0.33775 roc_auc 0.42451 prc_auc 0.63205[0m
[93maverage test of epoch 1: loss 0.21684 acc 0.32432 roc_auc 0.52333 prc_auc 0.74093[0m
[92maverage training of epoch 2: loss 0.15100 acc 0.33775 roc_auc 0.44216 prc_auc 0.61333[0m
[93maverage test of epoch 2: loss 0.11160 acc 0.32432 roc_auc 0.49000 prc_auc 0.67810[0m
[92maverage training of epoch 3: loss 0.09030 acc 0.33775 roc_auc 0.42216 prc_auc 0.60293[0m
[93maverage test of epoch 3: loss 0.08414 acc 0.32432 roc_auc 0.40333 prc_auc 0.66442[0m
[92maverage training of epoch 4: loss 0.05951 acc 0.33775 roc_auc 0.50529 prc_auc 0.68051[0mUsing backend: pytorch

[93maverage test of epoch 4: loss 0.05904 acc 0.32432 roc_auc 0.41333 prc_auc 0.64145[0m
[92maverage training of epoch 5: loss 0.03920 acc 0.33775 roc_auc 0.41039 prc_auc 0.62281[0m
[93maverage test of epoch 5: loss 0.02716 acc 0.32432 roc_auc 0.51333 prc_auc 0.72250[0m
[92maverage training of epoch 6: loss 0.01344 acc 0.33775 roc_auc 0.55020 prc_auc 0.72655[0m
[93maverage test of epoch 6: loss 0.01789 acc 0.32432 roc_auc 0.32667 prc_auc 0.61651[0m
[92maverage training of epoch 7: loss -0.00898 acc 0.33775 roc_auc 0.53549 prc_auc 0.68904[0m
[93maverage test of epoch 7: loss -0.00787 acc 0.32432 roc_auc 0.44667 prc_auc 0.70974[0m
[92maverage training of epoch 8: loss -0.02313 acc 0.33775 roc_auc 0.43451 prc_auc 0.64120[0m
[93maverage test of epoch 8: loss -0.02348 acc 0.32432 roc_auc 0.44000 prc_auc 0.65652[0m
[92maverage training of epoch 9: loss -0.04389 acc 0.33775 roc_auc 0.52176 prc_auc 0.67711[0m
[93maverage test of epoch 9: loss -0.03372 acc 0.32432 roc_auc 0.36333 prc_auc 0.65470[0m
[92maverage training of epoch 10: loss -0.06533 acc 0.33775 roc_auc 0.54745 prc_auc 0.71163[0m
[93maverage test of epoch 10: loss -0.05061 acc 0.32432 roc_auc 0.28333 prc_auc 0.57081[0m
[92maverage training of epoch 11: loss -0.08268 acc 0.33775 roc_auc 0.52078 prc_auc 0.67580[0m
[93maverage test of epoch 11: loss -0.08500 acc 0.32432 roc_auc 0.51000 prc_auc 0.72714[0m
[92maverage training of epoch 12: loss -0.09983 acc 0.33775 roc_auc 0.51627 prc_auc 0.69040[0m
[93maverage test of epoch 12: loss -0.11309 acc 0.32432 roc_auc 0.65000 prc_auc 0.82662[0m
[92maverage training of epoch 13: loss -0.11665 acc 0.33775 roc_auc 0.51863 prc_auc 0.67217[0m
[93maverage test of epoch 13: loss -0.12395 acc 0.32432 roc_auc 0.59667 prc_auc 0.78195[0m
[92maverage training of epoch 14: loss -0.13542 acc 0.33775 roc_auc 0.49980 prc_auc 0.69691[0m
[93maverage test of epoch 14: loss -0.13682 acc 0.32432 roc_auc 0.45333 prc_auc 0.66947[0m
[92maverage training of epoch 15: loss -0.15475 acc 0.33775 roc_auc 0.53529 prc_auc 0.67739[0m
[93maverage test of epoch 15: loss -0.16178 acc 0.32432 roc_auc 0.57333 prc_auc 0.77633[0m
[92maverage training of epoch 16: loss -0.17742 acc 0.33775 roc_auc 0.59510 prc_auc 0.74197[0m
[93maverage test of epoch 16: loss -0.17239 acc 0.32432 roc_auc 0.46333 prc_auc 0.66762[0m
[92maverage training of epoch 17: loss -0.20131 acc 0.33775 roc_auc 0.63314 prc_auc 0.77928[0m
[93maverage test of epoch 17: loss -0.19499 acc 0.32432 roc_auc 0.45667 prc_auc 0.69070[0m
[92maverage training of epoch 18: loss -0.21707 acc 0.33775 roc_auc 0.52098 prc_auc 0.71526[0m
[93maverage test of epoch 18: loss -0.22907 acc 0.32432 roc_auc 0.70333 prc_auc 0.82083[0m
[92maverage training of epoch 19: loss -0.24604 acc 0.33775 roc_auc 0.61137 prc_auc 0.77311[0m
[93maverage test of epoch 19: loss -0.25165 acc 0.32432 roc_auc 0.63667 prc_auc 0.78809[0m
[92maverage training of epoch 20: loss -0.26960 acc 0.33775 roc_auc 0.59000 prc_auc 0.75601[0m
[93maverage test of epoch 20: loss -0.27763 acc 0.32432 roc_auc 0.66000 prc_auc 0.84413[0m
[92maverage training of epoch 21: loss -0.29471 acc 0.33775 roc_auc 0.56118 prc_auc 0.73811[0m
[93maverage test of epoch 21: loss -0.31307 acc 0.32432 roc_auc 0.75333 prc_auc 0.87808[0m
[92maverage training of epoch 22: loss -0.32849 acc 0.33775 roc_auc 0.64843 prc_auc 0.80176[0m
[93maverage test of epoch 22: loss -0.33565 acc 0.32432 roc_auc 0.66000 prc_auc 0.81945[0m
[92maverage training of epoch 23: loss -0.36049 acc 0.33775 roc_auc 0.60216 prc_auc 0.79052[0m
[93maverage test of epoch 23: loss -0.36847 acc 0.32432 roc_auc 0.69333 prc_auc 0.83477[0m
[92maverage training of epoch 24: loss -0.39708 acc 0.33775 roc_auc 0.66157 prc_auc 0.81022[0m
[93maverage test of epoch 24: loss -0.41061 acc 0.32432 roc_auc 0.75667 prc_auc 0.89939[0m
[92maverage training of epoch 25: loss -0.43367 acc 0.33775 roc_auc 0.67137 prc_auc 0.80971[0m
[93maverage test of epoch 25: loss -0.43665 acc 0.32432 roc_auc 0.69333 prc_auc 0.87407[0m
[92maverage training of epoch 26: loss -0.47772 acc 0.33775 roc_auc 0.71706 prc_auc 0.84707[0m
[93maverage test of epoch 26: loss -0.49043 acc 0.32432 roc_auc 0.78667 prc_auc 0.90123[0m
[92maverage training of epoch 27: loss -0.54243 acc 0.33775 roc_auc 0.81686 prc_auc 0.91051[0m
[93maverage test of epoch 27: loss -0.54325 acc 0.32432 roc_auc 0.71667 prc_auc 0.87100[0m
[92maverage training of epoch 28: loss -0.61181 acc 0.33775 roc_auc 0.83706 prc_auc 0.91803[0m
[93maverage test of epoch 28: loss -0.63655 acc 0.32432 roc_auc 0.86333 prc_auc 0.93925[0m
[92maverage training of epoch 29: loss -0.67065 acc 0.33775 roc_auc 0.82902 prc_auc 0.89915[0m
[93maverage test of epoch 29: loss -0.67997 acc 0.32432 roc_auc 0.83333 prc_auc 0.92399[0m
[92maverage training of epoch 30: loss -0.73787 acc 0.33775 roc_auc 0.85667 prc_auc 0.93032[0m
[93maverage test of epoch 30: loss -0.75752 acc 0.32432 roc_auc 0.85333 prc_auc 0.93729[0m
[92maverage training of epoch 31: loss -0.79674 acc 0.33775 roc_auc 0.85118 prc_auc 0.92057[0m
[93maverage test of epoch 31: loss -0.82468 acc 0.32432 roc_auc 0.85667 prc_auc 0.94076[0m
[92maverage training of epoch 32: loss -0.87559 acc 0.33775 roc_auc 0.86275 prc_auc 0.93368[0m
[93maverage test of epoch 32: loss -0.91441 acc 0.32432 roc_auc 0.90000 prc_auc 0.95586[0m
[92maverage training of epoch 33: loss -0.95290 acc 0.33775 roc_auc 0.87627 prc_auc 0.94340[0m
[93maverage test of epoch 33: loss -0.94478 acc 0.32432 roc_auc 0.86667 prc_auc 0.93907[0m
[92maverage training of epoch 34: loss -1.03029 acc 0.33775 roc_auc 0.89882 prc_auc 0.94920[0m
[93maverage test of epoch 34: loss -1.03112 acc 0.32432 roc_auc 0.88000 prc_auc 0.94963[0m
[92maverage training of epoch 35: loss -1.06818 acc 0.33775 roc_auc 0.87275 prc_auc 0.92763[0m
[93maverage test of epoch 35: loss -1.05870 acc 0.32432 roc_auc 0.84667 prc_auc 0.93632[0m
[92maverage training of epoch 36: loss -1.14303 acc 0.33775 roc_auc 0.86490 prc_auc 0.93501[0m
[93maverage test of epoch 36: loss -1.19990 acc 0.32432 roc_auc 0.92667 prc_auc 0.96764[0m
[92maverage training of epoch 37: loss -1.22066 acc 0.33775 roc_auc 0.87353 prc_auc 0.93673[0m
[93maverage test of epoch 37: loss -1.23522 acc 0.32432 roc_auc 0.90333 prc_auc 0.95501[0m
[92maverage training of epoch 38: loss -1.25533 acc 0.33775 roc_auc 0.89784 prc_auc 0.95003[0m
[93maverage test of epoch 38: loss -1.26800 acc 0.32432 roc_auc 0.88333 prc_auc 0.94979[0m
[92maverage training of epoch 39: loss -1.32885 acc 0.33775 roc_auc 0.88529 prc_auc 0.94181[0m
[93maverage test of epoch 39: loss -1.40822 acc 0.32432 roc_auc 0.85667 prc_auc 0.94459[0m
[92maverage training of epoch 40: loss -1.44199 acc 0.33775 roc_auc 0.88314 prc_auc 0.94690[0m
[93maverage test of epoch 40: loss -1.43544 acc 0.32432 roc_auc 0.87333 prc_auc 0.94193[0m
[92maverage training of epoch 41: loss -1.52269 acc 0.33775 roc_auc 0.86275 prc_auc 0.93650[0m
[93maverage test of epoch 41: loss -1.55284 acc 0.32432 roc_auc 0.89333 prc_auc 0.95081[0m
[92maverage training of epoch 42: loss -1.58627 acc 0.33775 roc_auc 0.89157 prc_auc 0.94532[0m
[93maverage test of epoch 42: loss -1.64825 acc 0.32432 roc_auc 0.90667 prc_auc 0.96158[0m
[92maverage training of epoch 43: loss -1.66326 acc 0.33775 roc_auc 0.85275 prc_auc 0.93328[0m
[93maverage test of epoch 43: loss -1.72188 acc 0.32432 roc_auc 0.82333 prc_auc 0.92784[0m
[92maverage training of epoch 44: loss -1.74903 acc 0.33775 roc_auc 0.91059 prc_auc 0.95494[0m
[93maverage test of epoch 44: loss -1.85702 acc 0.32432 roc_auc 0.93667 prc_auc 0.97693[0m
[92maverage training of epoch 45: loss -1.84324 acc 0.33775 roc_auc 0.89725 prc_auc 0.94582[0m
[93maverage test of epoch 45: loss -1.85666 acc 0.32432 roc_auc 0.91000 prc_auc 0.96426[0m
[92maverage training of epoch 46: loss -1.95270 acc 0.33775 roc_auc 0.89725 prc_auc 0.95321[0m
[93maverage test of epoch 46: loss -1.99761 acc 0.32432 roc_auc 0.84000 prc_auc 0.93333[0m
[92maverage training of epoch 47: loss -2.01914 acc 0.33775 roc_auc 0.91784 prc_auc 0.95371[0m
[93maverage test of epoch 47: loss -2.04430 acc 0.32432 roc_auc 0.86000 prc_auc 0.94330[0m
[92maverage training of epoch 48: loss -2.10815 acc 0.33775 roc_auc 0.86902 prc_auc 0.93895[0m
[93maverage test of epoch 48: loss -2.15755 acc 0.32432 roc_auc 0.92333 prc_auc 0.96812[0m
[92maverage training of epoch 49: loss -2.25183 acc 0.33775 roc_auc 0.88588 prc_auc 0.94491[0m
[93maverage test of epoch 49: loss -2.28072 acc 0.32432 roc_auc 0.73667 prc_auc 0.89808[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 1)
('lr', 0.0001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.59474 ROC_AUC (avg): 0.62756 PRC_AUC (avg): 0.76656 

Average forward propagation time taken(ms): 4.3125791354009495
Average backward propagation time taken(ms): 1.5902284471291808

