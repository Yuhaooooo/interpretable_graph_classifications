# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-16-45-47/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-16-45-47/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 8,
 'epochs': 50,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 4,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.001,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 1,
 'num_workers': 8,
 'number_of_mlp_layer': 0,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-17-16-45-47',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 50, 'learning_rate': 0.001, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -0.48516 acc 0.34000 roc_auc 0.43960 prc_auc 0.66327[0m
[93maverage test of epoch 0: loss -1.06520 acc 0.39474 roc_auc 0.85846 prc_auc 0.93214[0m
[92maverage training of epoch 1: loss -1.52699 acc 0.57333 roc_auc 0.51780 prc_auc 0.73812[0m
[93maverage test of epoch 1: loss -2.00794 acc 0.65789 roc_auc 0.86462 prc_auc 0.93401[0m
[92maverage training of epoch 2: loss -2.44974 acc 0.66667 roc_auc 0.52320 prc_auc 0.71548[0m
[93maverage test of epoch 2: loss -2.90928 acc 0.65789 roc_auc 0.86462 prc_auc 0.93401[0m
[92maverage training of epoch 3: loss -3.38212 acc 0.66667 roc_auc 0.47340 prc_auc 0.66894[0m
[93maverage test of epoch 3: loss -3.80363 acc 0.65789 roc_auc 0.86462 prc_auc 0.93435[0m
[92maverage training of epoch 4: loss -4.20315 acc 0.66667 roc_auc 0.41960 prc_auc 0.62761[0m
[93maverage test of epoch 4: loss -4.55213 acc 0.65789 roc_auc 0.86462 prc_auc 0.93401[0m
[92maverage training of epoch 5: loss -4.91378 acc 0.66667 roc_auc 0.39840 prc_auc 0.61771[0m
[93maverage test of epoch 5: loss -5.22825 acc 0.65789 roc_auc 0.86462 prc_auc 0.93401[0m
[92maverage training of epoch 6: loss -5.57145 acc 0.66667 roc_auc 0.38660 prc_auc 0.60615[0m
[93maverage test of epoch 6: loss -5.86682 acc 0.65789 roc_auc 0.86462 prc_auc 0.93401[0m
[92maverage training of epoch 7: loss -6.19974 acc 0.66667 roc_auc 0.37680 prc_auc 0.59532[0m
[93maverage test of epoch 7: loss -6.48279 acc 0.65789 roc_auc 0.86462 prc_auc 0.93440[0m
[92maverage training of epoch 8: loss -6.80951 acc 0.66667 roc_auc 0.37260 prc_auc 0.59227[0m
[93maverage test of epoch 8: loss -7.08378 acc 0.65789 roc_auc 0.86462 prc_auc 0.93483[0m
[92maverage training of epoch 9: loss -7.40666 acc 0.66667 roc_auc 0.37000 prc_auc 0.59022[0m
[93maverage test of epoch 9: loss -7.67423 acc 0.65789 roc_auc 0.86769 prc_auc 0.93518[0m
[92maverage training of epoch 10: loss -7.99472 acc 0.66667 roc_auc 0.36520 prc_auc 0.56984[0m
[93maverage test of epoch 10: loss -8.25691 acc 0.65789 roc_auc 0.86615 prc_auc 0.93259[0m
[92maverage training of epoch 11: loss -8.57599 acc 0.66667 roc_auc 0.36190 prc_auc 0.56552[0m
[93maverage test of epoch 11: loss -8.83370 acc 0.65789 roc_auc 0.85077 prc_auc 0.90545[0m
[92maverage training of epoch 12: loss -9.15203 acc 0.66667 roc_auc 0.35980 prc_auc 0.56379[0m
[93maverage test of epoch 12: loss -9.40590 acc 0.65789 roc_auc 0.85077 prc_auc 0.90729[0m
[92maverage training of epoch 13: loss -9.72399 acc 0.66667 roc_auc 0.35920 prc_auc 0.56333[0m
[93maverage test of epoch 13: loss -9.97447 acc 0.65789 roc_auc 0.85385 prc_auc 0.91137[0m
[92maverage training of epoch 14: loss -10.29267 acc 0.66667 roc_auc 0.35860 prc_auc 0.56280[0m
[93maverage test of epoch 14: loss -10.54013 acc 0.65789 roc_auc 0.88000 prc_auc 0.93330[0m
[92maverage training of epoch 15: loss -10.85871 acc 0.66667 roc_auc 0.35850 prc_auc 0.56274[0m
[93maverage test of epoch 15: loss -11.10340 acc 0.65789 roc_auc 0.88154 prc_auc 0.91315[0m
[92maverage training of epoch 16: loss -11.42258 acc 0.66667 roc_auc 0.35810 prc_auc 0.56325[0m
[93maverage test of epoch 16: loss -11.66473 acc 0.65789 roc_auc 0.79077 prc_auc 0.82325[0m
[92maverage training of epoch 17: loss -11.98468 acc 0.66667 roc_auc 0.35790 prc_auc 0.56247[0m
[93maverage test of epoch 17: loss -12.22444 acc 0.65789 roc_auc 0.61231 prc_auc 0.71354[0m
[92maverage training of epoch 18: loss -12.54529 acc 0.66667 roc_auc 0.35760 prc_auc 0.56222[0m
[93maverage test of epoch 18: loss -12.78280 acc 0.65789 roc_auc 0.80462 prc_auc 0.84026[0m
[92maverage training of epoch 19: loss -13.10467 acc 0.66667 roc_auc 0.35750 prc_auc 0.56236[0m
[93maverage test of epoch 19: loss -13.34004 acc 0.65789 roc_auc 0.80462 prc_auc 0.84026[0m
[92maverage training of epoch 20: loss -13.66301 acc 0.66667 roc_auc 0.35730 prc_auc 0.56219[0m
[93maverage test of epoch 20: loss -13.89632 acc 0.65789 roc_auc 0.65385 prc_auc 0.73529[0m
[92maverage training of epoch 21: loss -14.22047 acc 0.66667 roc_auc 0.35700 prc_auc 0.56205[0m
[93maverage test of epoch 21: loss -14.45180 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -14.77719 acc 0.66667 roc_auc 0.35720 prc_auc 0.56197[0m
[93maverage test of epoch 22: loss -15.00661 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -15.33328 acc 0.66667 roc_auc 0.35720 prc_auc 0.56188[0m
[93maverage test of epoch 23: loss -15.56083 acc 0.65789 roc_auc 0.65385 prc_auc 0.73529[0m
[92maverage training of epoch 24: loss -15.88884 acc 0.66667 roc_auc 0.35700 prc_auc 0.56168[0m
[93maverage test of epoch 24: loss -16.11456 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -16.44394 acc 0.66667 roc_auc 0.35720 prc_auc 0.56172[0m
[93maverage test of epoch 25: loss -16.66788 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -16.99865 acc 0.66667 roc_auc 0.35720 prc_auc 0.56166[0m
[93maverage test of epoch 26: loss -17.22083 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -17.55302 acc 0.66667 roc_auc 0.35720 prc_auc 0.56162[0m
[93maverage test of epoch 27: loss -17.77347 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -18.10710 acc 0.66667 roc_auc 0.35720 prc_auc 0.56164[0m
[93maverage test of epoch 28: loss -18.32584 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -18.66094 acc 0.66667 roc_auc 0.35710 prc_auc 0.56192[0m
[93maverage test of epoch 29: loss -18.87800 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -19.21457 acc 0.66667 roc_auc 0.35740 prc_auc 0.56213[0m
[93maverage test of epoch 30: loss -19.42995 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -19.76802 acc 0.66667 roc_auc 0.35730 prc_auc 0.56311[0m
[93maverage test of epoch 31: loss -19.98174 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -20.32131 acc 0.66667 roc_auc 0.35770 prc_auc 0.56250[0m
[93maverage test of epoch 32: loss -20.53338 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -20.87447 acc 0.66667 roc_auc 0.35810 prc_auc 0.56292[0m
[93maverage test of epoch 33: loss -21.08490 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -21.42750 acc 0.66667 roc_auc 0.35820 prc_auc 0.56374[0m
[93maverage test of epoch 34: loss -21.63630 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -21.98044 acc 0.66667 roc_auc 0.35730 prc_auc 0.56244[0m
[93maverage test of epoch 35: loss -22.18762 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -22.53328 acc 0.66667 roc_auc 0.35790 prc_auc 0.56323[0m
[93maverage test of epoch 36: loss -22.73885 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -23.08605 acc 0.66667 roc_auc 0.35840 prc_auc 0.56478[0m
[93maverage test of epoch 37: loss -23.29000 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -23.63876 acc 0.66667 roc_auc 0.35750 prc_auc 0.56429[0m
[93maverage test of epoch 38: loss -23.84110 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -24.19141 acc 0.66667 roc_auc 0.35820 prc_auc 0.56390[0m
[93maverage test of epoch 39: loss -24.39215 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -24.74400 acc 0.66667 roc_auc 0.35910 prc_auc 0.56472[0m
[93maverage test of epoch 40: loss -24.94314 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -25.29655 acc 0.66667 roc_auc 0.36060 prc_auc 0.56588[0m
[93maverage test of epoch 41: loss -25.49410 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -25.84907 acc 0.66667 roc_auc 0.35880 prc_auc 0.56669[0m
[93maverage test of epoch 42: loss -26.04503 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -26.40156 acc 0.66667 roc_auc 0.35770 prc_auc 0.56595[0m
[93maverage test of epoch 43: loss -26.59592 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -26.95401 acc 0.66667 roc_auc 0.35900 prc_auc 0.56872[0m
[93maverage test of epoch 44: loss -27.14678 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -27.50643 acc 0.66667 roc_auc 0.35940 prc_auc 0.56759[0m
[93maverage test of epoch 45: loss -27.69762 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -28.05884 acc 0.66667 roc_auc 0.35890 prc_auc 0.57252[0m
[93maverage test of epoch 46: loss -28.24844 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -28.61122 acc 0.66667 roc_auc 0.36190 prc_auc 0.57058[0m
[93maverage test of epoch 47: loss -28.79924 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -29.16359 acc 0.66667 roc_auc 0.35770 prc_auc 0.56955[0m
[93maverage test of epoch 48: loss -29.35002 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -29.71594 acc 0.66667 roc_auc 0.36330 prc_auc 0.57566[0m
[93maverage test of epoch 49: loss -29.90079 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -0.07824 acc 0.33333 roc_auc 0.52760 prc_auc 0.67237[0m
[93maverage test of epoch 0: loss -0.68015 acc 0.34211 roc_auc 0.12000 prc_auc 0.48608[0m
[92maverage training of epoch 1: loss -1.51303 acc 0.33333 roc_auc 0.46300 prc_auc 0.63589[0m
[93maverage test of epoch 1: loss -2.19935 acc 0.34211 roc_auc 0.11385 prc_auc 0.48417[0m
[92maverage training of epoch 2: loss -2.60504 acc 0.33333 roc_auc 0.35640 prc_auc 0.57409[0m
[93maverage test of epoch 2: loss -3.03373 acc 0.34211 roc_auc 0.11385 prc_auc 0.48417[0m
[92maverage training of epoch 3: loss -3.33888 acc 0.33333 roc_auc 0.40020 prc_auc 0.58672[0m
[93maverage test of epoch 3: loss -3.68987 acc 0.34211 roc_auc 0.13231 prc_auc 0.48998[0m
[92maverage training of epoch 4: loss -3.95100 acc 0.33333 roc_auc 0.41220 prc_auc 0.59278[0m
[93maverage test of epoch 4: loss -4.26275 acc 0.34211 roc_auc 0.20615 prc_auc 0.56410[0m
[92maverage training of epoch 5: loss -4.50467 acc 0.33333 roc_auc 0.42460 prc_auc 0.61722[0m
[93maverage test of epoch 5: loss -4.79874 acc 0.34211 roc_auc 0.27231 prc_auc 0.60465[0m
[92maverage training of epoch 6: loss -5.04680 acc 0.33333 roc_auc 0.44440 prc_auc 0.63630[0m
[93maverage test of epoch 6: loss -5.37095 acc 0.34211 roc_auc 0.40769 prc_auc 0.70733[0m
[92maverage training of epoch 7: loss -5.79170 acc 0.33333 roc_auc 0.49040 prc_auc 0.68177[0m
[93maverage test of epoch 7: loss -6.28586 acc 0.34211 roc_auc 0.88923 prc_auc 0.93807[0m
[92maverage training of epoch 8: loss -6.64488 acc 0.33333 roc_auc 0.45520 prc_auc 0.63331[0m
[93maverage test of epoch 8: loss -7.01193 acc 0.34211 roc_auc 0.88923 prc_auc 0.93807[0m
[92maverage training of epoch 9: loss -7.33478 acc 0.33333 roc_auc 0.43360 prc_auc 0.61966[0m
[93maverage test of epoch 9: loss -7.66888 acc 0.34211 roc_auc 0.88615 prc_auc 0.93236[0m
[92maverage training of epoch 10: loss -7.97688 acc 0.33333 roc_auc 0.42600 prc_auc 0.61150[0m
[93maverage test of epoch 10: loss -8.29418 acc 0.34211 roc_auc 0.86308 prc_auc 0.90090[0m
[92maverage training of epoch 11: loss -8.59434 acc 0.58667 roc_auc 0.42380 prc_auc 0.61152[0m
[93maverage test of epoch 11: loss -8.90088 acc 0.65789 roc_auc 0.88000 prc_auc 0.92352[0m
[92maverage training of epoch 12: loss -9.19645 acc 0.66667 roc_auc 0.42300 prc_auc 0.61000[0m
[93maverage test of epoch 12: loss -9.49523 acc 0.65789 roc_auc 0.85231 prc_auc 0.87498[0m
[92maverage training of epoch 13: loss -9.78804 acc 0.66667 roc_auc 0.42160 prc_auc 0.60653[0m
[93maverage test of epoch 13: loss -10.08079 acc 0.65789 roc_auc 0.79385 prc_auc 0.84843[0m
[92maverage training of epoch 14: loss -10.37196 acc 0.66667 roc_auc 0.42100 prc_auc 0.60548[0m
[93maverage test of epoch 14: loss -10.65980 acc 0.65789 roc_auc 0.82769 prc_auc 0.85556[0m
[92maverage training of epoch 15: loss -10.95008 acc 0.66667 roc_auc 0.42080 prc_auc 0.60544[0m
[93maverage test of epoch 15: loss -11.23377 acc 0.65789 roc_auc 0.82462 prc_auc 0.85500[0m
[92maverage training of epoch 16: loss -11.52369 acc 0.66667 roc_auc 0.42080 prc_auc 0.60544[0m
[93maverage test of epoch 16: loss -11.80377 acc 0.65789 roc_auc 0.78769 prc_auc 0.83074[0m
[92maverage training of epoch 17: loss -12.09373 acc 0.66667 roc_auc 0.42040 prc_auc 0.60492[0m
[93maverage test of epoch 17: loss -12.37060 acc 0.65789 roc_auc 0.82462 prc_auc 0.84889[0m
[92maverage training of epoch 18: loss -12.66088 acc 0.66667 roc_auc 0.42020 prc_auc 0.60463[0m
[93maverage test of epoch 18: loss -12.93484 acc 0.65789 roc_auc 0.82000 prc_auc 0.84667[0m
[92maverage training of epoch 19: loss -13.22569 acc 0.66667 roc_auc 0.42020 prc_auc 0.60463[0m
[93maverage test of epoch 19: loss -13.49698 acc 0.65789 roc_auc 0.85538 prc_auc 0.87275[0m
[92maverage training of epoch 20: loss -13.78856 acc 0.66667 roc_auc 0.42000 prc_auc 0.60455[0m
[93maverage test of epoch 20: loss -14.05738 acc 0.65789 roc_auc 0.86154 prc_auc 0.88000[0m
[92maverage training of epoch 21: loss -14.34983 acc 0.66667 roc_auc 0.42020 prc_auc 0.60463[0m
[93maverage test of epoch 21: loss -14.61631 acc 0.65789 roc_auc 0.81538 prc_auc 0.84978[0m
[92maverage training of epoch 22: loss -14.90976 acc 0.66667 roc_auc 0.42010 prc_auc 0.60455[0m
[93maverage test of epoch 22: loss -15.17403 acc 0.65789 roc_auc 0.78462 prc_auc 0.83067[0m
[92maverage training of epoch 23: loss -15.46856 acc 0.66667 roc_auc 0.42010 prc_auc 0.60455[0m
[93maverage test of epoch 23: loss -15.73073 acc 0.65789 roc_auc 0.80000 prc_auc 0.83185[0m
[92maverage training of epoch 24: loss -16.02642 acc 0.66667 roc_auc 0.42020 prc_auc 0.60463[0m
[93maverage test of epoch 24: loss -16.28656 acc 0.65789 roc_auc 0.61077 prc_auc 0.71889[0m
[92maverage training of epoch 25: loss -16.58348 acc 0.66667 roc_auc 0.42010 prc_auc 0.60455[0m
[93maverage test of epoch 25: loss -16.84166 acc 0.65789 roc_auc 0.84000 prc_auc 0.86007[0m
[92maverage training of epoch 26: loss -17.13985 acc 0.66667 roc_auc 0.42010 prc_auc 0.60455[0m
[93maverage test of epoch 26: loss -17.39614 acc 0.65789 roc_auc 0.78000 prc_auc 0.82263[0m
[92maverage training of epoch 27: loss -17.69565 acc 0.66667 roc_auc 0.42010 prc_auc 0.60455[0m
[93maverage test of epoch 27: loss -17.95009 acc 0.65789 roc_auc 0.46923 prc_auc 0.68526[0m
[92maverage training of epoch 28: loss -18.25096 acc 0.66667 roc_auc 0.42000 prc_auc 0.60455[0m
[93maverage test of epoch 28: loss -18.50359 acc 0.65789 roc_auc 0.71538 prc_auc 0.78441[0m
[92maverage training of epoch 29: loss -18.80585 acc 0.66667 roc_auc 0.42000 prc_auc 0.60455[0m
[93maverage test of epoch 29: loss -19.05670 acc 0.65789 roc_auc 0.71231 prc_auc 0.77663[0m
[92maverage training of epoch 30: loss -19.36038 acc 0.66667 roc_auc 0.42020 prc_auc 0.60463[0m
[93maverage test of epoch 30: loss -19.60948 acc 0.65789 roc_auc 0.64615 prc_auc 0.73714[0m
[92maverage training of epoch 31: loss -19.91460 acc 0.66667 roc_auc 0.42010 prc_auc 0.60455[0m
[93maverage test of epoch 31: loss -20.16197 acc 0.65789 roc_auc 0.57077 prc_auc 0.70087[0m
[92maverage training of epoch 32: loss -20.46855 acc 0.66667 roc_auc 0.42010 prc_auc 0.60455[0m
[93maverage test of epoch 32: loss -20.71423 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 33: loss -21.02229 acc 0.66667 roc_auc 0.42010 prc_auc 0.60455[0m
[93maverage test of epoch 33: loss -21.26627 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 34: loss -21.57583 acc 0.66667 roc_auc 0.42010 prc_auc 0.60455[0m
[93maverage test of epoch 34: loss -21.81814 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 35: loss -22.12919 acc 0.66667 roc_auc 0.42010 prc_auc 0.60455[0m
[93maverage test of epoch 35: loss -22.36985 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 36: loss -22.68242 acc 0.66667 roc_auc 0.42010 prc_auc 0.60455[0m
[93maverage test of epoch 36: loss -22.92143 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 37: loss -23.23551 acc 0.66667 roc_auc 0.42010 prc_auc 0.60455[0m
[93maverage test of epoch 37: loss -23.47289 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 38: loss -23.78850 acc 0.66667 roc_auc 0.42020 prc_auc 0.60458[0m
[93maverage test of epoch 38: loss -24.02425 acc 0.65789 roc_auc 0.64615 prc_auc 0.73714[0m
[92maverage training of epoch 39: loss -24.34140 acc 0.66667 roc_auc 0.42020 prc_auc 0.60455[0m
[93maverage test of epoch 39: loss -24.57553 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 40: loss -24.89422 acc 0.66667 roc_auc 0.42020 prc_auc 0.60455[0m
[93maverage test of epoch 40: loss -25.12674 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 41: loss -25.44697 acc 0.66667 roc_auc 0.42030 prc_auc 0.60455[0m
[93maverage test of epoch 41: loss -25.67788 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 42: loss -25.99966 acc 0.66667 roc_auc 0.42020 prc_auc 0.60455[0m
[93maverage test of epoch 42: loss -26.22896 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 43: loss -26.55229 acc 0.66667 roc_auc 0.42030 prc_auc 0.60500[0m
[93maverage test of epoch 43: loss -26.77998 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 44: loss -27.10487 acc 0.66667 roc_auc 0.42030 prc_auc 0.60455[0m
[93maverage test of epoch 44: loss -27.33097 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 45: loss -27.65742 acc 0.66667 roc_auc 0.42030 prc_auc 0.60461[0m
[93maverage test of epoch 45: loss -27.88192 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 46: loss -28.20993 acc 0.66667 roc_auc 0.42020 prc_auc 0.60500[0m
[93maverage test of epoch 46: loss -28.43284 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 47: loss -28.76242 acc 0.66667 roc_auc 0.42010 prc_auc 0.60477[0m
[93maverage test of epoch 47: loss -28.98374 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 48: loss -29.31487 acc 0.66667 roc_auc 0.42020 prc_auc 0.60453[0m
[93maverage test of epoch 48: loss -29.53461 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -29.86731 acc 0.66667 roc_auc 0.42040 prc_auc 0.60486[0m
[93maverage test of epoch 49: loss -30.08546 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -1.21966 acc 0.42667 roc_auc 0.44560 prc_auc 0.65047[0m
[93maverage test of epoch 0: loss -1.86072 acc 0.65789 roc_auc 0.91385 prc_auc 0.96638[0m
[92maverage training of epoch 1: loss -2.71453 acc 0.66667 roc_auc 0.42760 prc_auc 0.63519[0m
[93maverage test of epoch 1: loss -3.39197 acc 0.65789 roc_auc 0.95385 prc_auc 0.97933[0m
[92maverage training of epoch 2: loss -3.82090 acc 0.66667 roc_auc 0.40960 prc_auc 0.62483[0m
[93maverage test of epoch 2: loss -4.18399 acc 0.65789 roc_auc 0.95692 prc_auc 0.98005[0m
[92maverage training of epoch 3: loss -4.53874 acc 0.66667 roc_auc 0.40660 prc_auc 0.62636[0m
[93maverage test of epoch 3: loss -4.85871 acc 0.65789 roc_auc 0.93538 prc_auc 0.96781[0m
[92maverage training of epoch 4: loss -5.20243 acc 0.66667 roc_auc 0.39820 prc_auc 0.62198[0m
[93maverage test of epoch 4: loss -5.51507 acc 0.65789 roc_auc 0.90462 prc_auc 0.95369[0m
[92maverage training of epoch 5: loss -5.85210 acc 0.66667 roc_auc 0.38880 prc_auc 0.60323[0m
[93maverage test of epoch 5: loss -6.15530 acc 0.65789 roc_auc 0.85846 prc_auc 0.93427[0m
[92maverage training of epoch 6: loss -6.48371 acc 0.66667 roc_auc 0.38400 prc_auc 0.59447[0m
[93maverage test of epoch 6: loss -6.77587 acc 0.65789 roc_auc 0.83846 prc_auc 0.92226[0m
[92maverage training of epoch 7: loss -7.09743 acc 0.66667 roc_auc 0.38240 prc_auc 0.59156[0m
[93maverage test of epoch 7: loss -7.38032 acc 0.65789 roc_auc 0.79538 prc_auc 0.89277[0m
[92maverage training of epoch 8: loss -7.69729 acc 0.66667 roc_auc 0.37950 prc_auc 0.57489[0m
[93maverage test of epoch 8: loss -7.97291 acc 0.65789 roc_auc 0.78769 prc_auc 0.86789[0m
[92maverage training of epoch 9: loss -8.28699 acc 0.66667 roc_auc 0.37900 prc_auc 0.57647[0m
[93maverage test of epoch 9: loss -8.55683 acc 0.65789 roc_auc 0.60769 prc_auc 0.74718[0m
[92maverage training of epoch 10: loss -8.86918 acc 0.66667 roc_auc 0.37780 prc_auc 0.57551[0m
[93maverage test of epoch 10: loss -9.13429 acc 0.65789 roc_auc 0.52000 prc_auc 0.67158[0m
[92maverage training of epoch 11: loss -9.44571 acc 0.66667 roc_auc 0.37780 prc_auc 0.57536[0m
[93maverage test of epoch 11: loss -9.70683 acc 0.65789 roc_auc 0.60308 prc_auc 0.71560[0m
[92maverage training of epoch 12: loss -10.01788 acc 0.66667 roc_auc 0.37720 prc_auc 0.57494[0m
[93maverage test of epoch 12: loss -10.27551 acc 0.65789 roc_auc 0.51692 prc_auc 0.66561[0m
[92maverage training of epoch 13: loss -10.58661 acc 0.66667 roc_auc 0.37690 prc_auc 0.57456[0m
[93maverage test of epoch 13: loss -10.84116 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 14: loss -11.15260 acc 0.66667 roc_auc 0.37690 prc_auc 0.57456[0m
[93maverage test of epoch 14: loss -11.40437 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 15: loss -11.71639 acc 0.66667 roc_auc 0.37690 prc_auc 0.57456[0m
[93maverage test of epoch 15: loss -11.96558 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 16: loss -12.27836 acc 0.66667 roc_auc 0.37690 prc_auc 0.57456[0m
[93maverage test of epoch 16: loss -12.52516 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 17: loss -12.83884 acc 0.66667 roc_auc 0.37690 prc_auc 0.57465[0m
[93maverage test of epoch 17: loss -13.08339 acc 0.65789 roc_auc 0.58462 prc_auc 0.70243[0m
[92maverage training of epoch 18: loss -13.39809 acc 0.66667 roc_auc 0.37680 prc_auc 0.57447[0m
[93maverage test of epoch 18: loss -13.64049 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -13.95630 acc 0.66667 roc_auc 0.37680 prc_auc 0.57450[0m
[93maverage test of epoch 19: loss -14.19666 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -14.51364 acc 0.66667 roc_auc 0.37680 prc_auc 0.57453[0m
[93maverage test of epoch 20: loss -14.75203 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -15.07025 acc 0.66667 roc_auc 0.37670 prc_auc 0.57453[0m
[93maverage test of epoch 21: loss -15.30672 acc 0.65789 roc_auc 0.47538 prc_auc 0.64707[0m
[92maverage training of epoch 22: loss -15.62624 acc 0.66667 roc_auc 0.37670 prc_auc 0.57442[0m
[93maverage test of epoch 22: loss -15.86085 acc 0.65789 roc_auc 0.72462 prc_auc 0.78853[0m
[92maverage training of epoch 23: loss -16.18170 acc 0.66667 roc_auc 0.37680 prc_auc 0.57453[0m
[93maverage test of epoch 23: loss -16.41449 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -16.73672 acc 0.66667 roc_auc 0.37660 prc_auc 0.57448[0m
[93maverage test of epoch 24: loss -16.96773 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -17.29135 acc 0.66667 roc_auc 0.37690 prc_auc 0.57442[0m
[93maverage test of epoch 25: loss -17.52060 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -17.84566 acc 0.66667 roc_auc 0.37650 prc_auc 0.57445[0m
[93maverage test of epoch 26: loss -18.07318 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -18.39968 acc 0.66667 roc_auc 0.37690 prc_auc 0.57498[0m
[93maverage test of epoch 27: loss -18.62550 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -18.95346 acc 0.66667 roc_auc 0.37690 prc_auc 0.57467[0m
[93maverage test of epoch 28: loss -19.17759 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -19.50704 acc 0.66667 roc_auc 0.37690 prc_auc 0.57500[0m
[93maverage test of epoch 29: loss -19.72950 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -20.06044 acc 0.66667 roc_auc 0.37660 prc_auc 0.57530[0m
[93maverage test of epoch 30: loss -20.28124 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -20.61368 acc 0.66667 roc_auc 0.37650 prc_auc 0.57514[0m
[93maverage test of epoch 31: loss -20.83284 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -21.16680 acc 0.66667 roc_auc 0.37690 prc_auc 0.57543[0m
[93maverage test of epoch 32: loss -21.38431 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -21.71979 acc 0.66667 roc_auc 0.37690 prc_auc 0.57623[0m
[93maverage test of epoch 33: loss -21.93568 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -22.27269 acc 0.66667 roc_auc 0.37660 prc_auc 0.57540[0m
[93maverage test of epoch 34: loss -22.48695 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -22.82550 acc 0.66667 roc_auc 0.37690 prc_auc 0.57732[0m
[93maverage test of epoch 35: loss -23.03815 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -23.37824 acc 0.66667 roc_auc 0.37700 prc_auc 0.57669[0m
[93maverage test of epoch 36: loss -23.58928 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -23.93092 acc 0.66667 roc_auc 0.37760 prc_auc 0.57612[0m
[93maverage test of epoch 37: loss -24.14035 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -24.48354 acc 0.66667 roc_auc 0.37700 prc_auc 0.57675[0m
[93maverage test of epoch 38: loss -24.69137 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -25.03611 acc 0.66667 roc_auc 0.37650 prc_auc 0.57557[0m
[93maverage test of epoch 39: loss -25.24235 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -25.58864 acc 0.66667 roc_auc 0.37840 prc_auc 0.57533[0m
[93maverage test of epoch 40: loss -25.79328 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -26.14113 acc 0.66667 roc_auc 0.37660 prc_auc 0.57981[0m
[93maverage test of epoch 41: loss -26.34418 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -26.69359 acc 0.66667 roc_auc 0.37760 prc_auc 0.57798[0m
[93maverage test of epoch 42: loss -26.89504 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -27.24602 acc 0.66667 roc_auc 0.37760 prc_auc 0.57851[0m
[93maverage test of epoch 43: loss -27.44588 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -27.79842 acc 0.66667 roc_auc 0.37830 prc_auc 0.57605[0m
[93maverage test of epoch 44: loss -27.99670 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -28.35080 acc 0.66667 roc_auc 0.37690 prc_auc 0.57717[0m
[93maverage test of epoch 45: loss -28.54749 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -28.90317 acc 0.66667 roc_auc 0.37790 prc_auc 0.57933[0m
[93maverage test of epoch 46: loss -29.09828 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -29.45552 acc 0.66667 roc_auc 0.37590 prc_auc 0.57899[0m
[93maverage test of epoch 47: loss -29.64904 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -30.00785 acc 0.66667 roc_auc 0.37430 prc_auc 0.58031[0m
[93maverage test of epoch 48: loss -30.19979 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -30.56016 acc 0.66667 roc_auc 0.37870 prc_auc 0.58229[0m
[93maverage test of epoch 49: loss -30.75052 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -0.39524 acc 0.33775 roc_auc 0.47725 prc_auc 0.63454[0m
[93maverage test of epoch 0: loss -0.74829 acc 0.32432 roc_auc 0.55000 prc_auc 0.78165[0m
[92maverage training of epoch 1: loss -1.16625 acc 0.33775 roc_auc 0.54961 prc_auc 0.69181[0m
[93maverage test of epoch 1: loss -1.56473 acc 0.32432 roc_auc 0.84667 prc_auc 0.91092[0m
[92maverage training of epoch 2: loss -2.08477 acc 0.33775 roc_auc 0.61863 prc_auc 0.79751[0m
[93maverage test of epoch 2: loss -2.52156 acc 0.32432 roc_auc 0.85000 prc_auc 0.91082[0m
[92maverage training of epoch 3: loss -2.94378 acc 0.33775 roc_auc 0.38078 prc_auc 0.58964[0m
[93maverage test of epoch 3: loss -3.28664 acc 0.32432 roc_auc 0.27000 prc_auc 0.61633[0m
[92maverage training of epoch 4: loss -3.65581 acc 0.33775 roc_auc 0.37333 prc_auc 0.57191[0m
[93maverage test of epoch 4: loss -3.96311 acc 0.32432 roc_auc 0.09333 prc_auc 0.49729[0m
[92maverage training of epoch 5: loss -4.30841 acc 0.33775 roc_auc 0.37196 prc_auc 0.56605[0m
[93maverage test of epoch 5: loss -4.60033 acc 0.32432 roc_auc 0.08333 prc_auc 0.49532[0m
[92maverage training of epoch 6: loss -4.93140 acc 0.33775 roc_auc 0.37333 prc_auc 0.56753[0m
[93maverage test of epoch 6: loss -5.21547 acc 0.32432 roc_auc 0.08667 prc_auc 0.50226[0m
[92maverage training of epoch 7: loss -5.53671 acc 0.33775 roc_auc 0.37431 prc_auc 0.56869[0m
[93maverage test of epoch 7: loss -5.81657 acc 0.32432 roc_auc 0.09167 prc_auc 0.49944[0m
[92maverage training of epoch 8: loss -6.13036 acc 0.33775 roc_auc 0.37529 prc_auc 0.56892[0m
[93maverage test of epoch 8: loss -6.40804 acc 0.32432 roc_auc 0.10667 prc_auc 0.50868[0m
[92maverage training of epoch 9: loss -6.71580 acc 0.33775 roc_auc 0.37569 prc_auc 0.56987[0m
[93maverage test of epoch 9: loss -6.99255 acc 0.32432 roc_auc 0.12167 prc_auc 0.51891[0m
[92maverage training of epoch 10: loss -7.29522 acc 0.33775 roc_auc 0.37569 prc_auc 0.56989[0m
[93maverage test of epoch 10: loss -7.57187 acc 0.32432 roc_auc 0.10000 prc_auc 0.51129[0m
[92maverage training of epoch 11: loss -7.87007 acc 0.33775 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 11: loss -8.14718 acc 0.32432 roc_auc 0.10333 prc_auc 0.51227[0m
[92maverage training of epoch 12: loss -8.44136 acc 0.33775 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 12: loss -8.71934 acc 0.32432 roc_auc 0.12833 prc_auc 0.52425[0m
[92maverage training of epoch 13: loss -9.00985 acc 0.33775 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 13: loss -9.28900 acc 0.32432 roc_auc 0.11000 prc_auc 0.54354[0m
[92maverage training of epoch 14: loss -9.57608 acc 0.33775 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 14: loss -9.85663 acc 0.32432 roc_auc 0.12667 prc_auc 0.57116[0m
[92maverage training of epoch 15: loss -10.14047 acc 0.33775 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 15: loss -10.42259 acc 0.32432 roc_auc 0.17000 prc_auc 0.57836[0m
[92maverage training of epoch 16: loss -10.70336 acc 0.33775 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 16: loss -10.98719 acc 0.32432 roc_auc 0.17167 prc_auc 0.55716[0m
[92maverage training of epoch 17: loss -11.26500 acc 0.33775 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 17: loss -11.55066 acc 0.32432 roc_auc 0.40333 prc_auc 0.65018[0m
[92maverage training of epoch 18: loss -11.82561 acc 0.52318 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 18: loss -12.11317 acc 0.67568 roc_auc 0.58000 prc_auc 0.71530[0m
[92maverage training of epoch 19: loss -12.38534 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 19: loss -12.67489 acc 0.67568 roc_auc 0.29500 prc_auc 0.62655[0m
[92maverage training of epoch 20: loss -12.94434 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 20: loss -13.23594 acc 0.67568 roc_auc 0.20667 prc_auc 0.58938[0m
[92maverage training of epoch 21: loss -13.50273 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 21: loss -13.79642 acc 0.67568 roc_auc 0.39167 prc_auc 0.63022[0m
[92maverage training of epoch 22: loss -14.06060 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 22: loss -14.35641 acc 0.67568 roc_auc 0.40000 prc_auc 0.63392[0m
[92maverage training of epoch 23: loss -14.61802 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 23: loss -14.91600 acc 0.67568 roc_auc 0.46000 prc_auc 0.65828[0m
[92maverage training of epoch 24: loss -15.17506 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 24: loss -15.47524 acc 0.67568 roc_auc 0.60000 prc_auc 0.73472[0m
[92maverage training of epoch 25: loss -15.73178 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 25: loss -16.03418 acc 0.67568 roc_auc 0.25667 prc_auc 0.60474[0m
[92maverage training of epoch 26: loss -16.28823 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 26: loss -16.59287 acc 0.67568 roc_auc 0.32000 prc_auc 0.64541[0m
[92maverage training of epoch 27: loss -16.84444 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 27: loss -17.15133 acc 0.67568 roc_auc 0.70000 prc_auc 0.79751[0m
[92maverage training of epoch 28: loss -17.40044 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 28: loss -17.70961 acc 0.67568 roc_auc 0.48000 prc_auc 0.68865[0m
[92maverage training of epoch 29: loss -17.95628 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 29: loss -18.26773 acc 0.67568 roc_auc 0.46000 prc_auc 0.66724[0m
[92maverage training of epoch 30: loss -18.51196 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 30: loss -18.82571 acc 0.67568 roc_auc 0.31333 prc_auc 0.63335[0m
[92maverage training of epoch 31: loss -19.06752 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 31: loss -19.38357 acc 0.67568 roc_auc 0.24333 prc_auc 0.63566[0m
[92maverage training of epoch 32: loss -19.62296 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 32: loss -19.94132 acc 0.67568 roc_auc 0.52167 prc_auc 0.76662[0m
[92maverage training of epoch 33: loss -20.17831 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 33: loss -20.49900 acc 0.67568 roc_auc 0.42000 prc_auc 0.65946[0m
[92maverage training of epoch 34: loss -20.73357 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 34: loss -21.05659 acc 0.67568 roc_auc 0.38000 prc_auc 0.64278[0m
[92maverage training of epoch 35: loss -21.28877 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 35: loss -21.61411 acc 0.67568 roc_auc 0.70000 prc_auc 0.79751[0m
[92maverage training of epoch 36: loss -21.84390 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 36: loss -22.17158 acc 0.67568 roc_auc 0.50167 prc_auc 0.77246[0m
[92maverage training of epoch 37: loss -22.39898 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 37: loss -22.72900 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 38: loss -22.95402 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 38: loss -23.28637 acc 0.67568 roc_auc 0.84000 prc_auc 0.87252[0m
[92maverage training of epoch 39: loss -23.50901 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 39: loss -23.84371 acc 0.67568 roc_auc 0.46000 prc_auc 0.66546[0m
[92maverage training of epoch 40: loss -24.06397 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 40: loss -24.40102 acc 0.67568 roc_auc 0.46000 prc_auc 0.66633[0m
[92maverage training of epoch 41: loss -24.61890 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 41: loss -24.95829 acc 0.67568 roc_auc 0.72000 prc_auc 0.80439[0m
[92maverage training of epoch 42: loss -25.17379 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 42: loss -25.51554 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 43: loss -25.72867 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 43: loss -26.07277 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 44: loss -26.28353 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 44: loss -26.62998 acc 0.67568 roc_auc 0.50000 prc_auc 0.68036[0m
[92maverage training of epoch 45: loss -26.83837 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 45: loss -27.18717 acc 0.67568 roc_auc 0.34000 prc_auc 0.67305[0m
[92maverage training of epoch 46: loss -27.39320 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 46: loss -27.74436 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 47: loss -27.94801 acc 0.66225 roc_auc 0.37578 prc_auc 0.56962[0m
[93maverage test of epoch 47: loss -28.30152 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 48: loss -28.50281 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 48: loss -28.85868 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 49: loss -29.05760 acc 0.66225 roc_auc 0.37569 prc_auc 0.56962[0m
[93maverage test of epoch 49: loss -29.41583 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -0.73089 acc 0.66225 roc_auc 0.41078 prc_auc 0.60651[0m
[93maverage test of epoch 0: loss -1.62705 acc 0.67568 roc_auc 0.69333 prc_auc 0.86826[0m
[92maverage training of epoch 1: loss -2.14871 acc 0.66225 roc_auc 0.41941 prc_auc 0.62187[0m
[93maverage test of epoch 1: loss -2.78731 acc 0.67568 roc_auc 0.93333 prc_auc 0.97438[0m
[92maverage training of epoch 2: loss -3.21393 acc 0.66225 roc_auc 0.39314 prc_auc 0.60336[0m
[93maverage test of epoch 2: loss -3.70954 acc 0.67568 roc_auc 0.90667 prc_auc 0.95653[0m
[92maverage training of epoch 3: loss -4.00806 acc 0.66225 roc_auc 0.37725 prc_auc 0.59034[0m
[93maverage test of epoch 3: loss -4.42664 acc 0.67568 roc_auc 0.90667 prc_auc 0.94712[0m
[92maverage training of epoch 4: loss -4.68440 acc 0.66225 roc_auc 0.37275 prc_auc 0.58227[0m
[93maverage test of epoch 4: loss -5.07893 acc 0.67568 roc_auc 0.83500 prc_auc 0.89339[0m
[92maverage training of epoch 5: loss -5.31681 acc 0.66225 roc_auc 0.37667 prc_auc 0.58747[0m
[93maverage test of epoch 5: loss -5.70084 acc 0.67568 roc_auc 0.79333 prc_auc 0.85211[0m
[92maverage training of epoch 6: loss -5.92639 acc 0.66225 roc_auc 0.37667 prc_auc 0.58950[0mUsing backend: pytorch
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))

[93maverage test of epoch 6: loss -6.30522 acc 0.67568 roc_auc 0.58000 prc_auc 0.72757[0m
[92maverage training of epoch 7: loss -6.52205 acc 0.66225 roc_auc 0.37608 prc_auc 0.58203[0m
[93maverage test of epoch 7: loss -6.89832 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 8: loss -7.10842 acc 0.66225 roc_auc 0.37578 prc_auc 0.57428[0m
[93maverage test of epoch 8: loss -7.48362 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 9: loss -7.68821 acc 0.66225 roc_auc 0.37333 prc_auc 0.57151[0m
[93maverage test of epoch 9: loss -8.06326 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 10: loss -8.26315 acc 0.66225 roc_auc 0.37275 prc_auc 0.57108[0m
[93maverage test of epoch 10: loss -8.63867 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 11: loss -8.83439 acc 0.66225 roc_auc 0.37255 prc_auc 0.57054[0m
[93maverage test of epoch 11: loss -9.21081 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 12: loss -9.40275 acc 0.66225 roc_auc 0.37137 prc_auc 0.56893[0m
[93maverage test of epoch 12: loss -9.78038 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 13: loss -9.96882 acc 0.66225 roc_auc 0.37098 prc_auc 0.56877[0m
[93maverage test of epoch 13: loss -10.34789 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 14: loss -10.53306 acc 0.66225 roc_auc 0.37098 prc_auc 0.56914[0m
[93maverage test of epoch 14: loss -10.91373 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 15: loss -11.09580 acc 0.66225 roc_auc 0.37029 prc_auc 0.56851[0m
[93maverage test of epoch 15: loss -11.47822 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 16: loss -11.65731 acc 0.66225 roc_auc 0.37029 prc_auc 0.56818[0m
[93maverage test of epoch 16: loss -12.04158 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 17: loss -12.21779 acc 0.66225 roc_auc 0.37049 prc_auc 0.56965[0m
[93maverage test of epoch 17: loss -12.60400 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 18: loss -12.77743 acc 0.66225 roc_auc 0.37010 prc_auc 0.56958[0m
[93maverage test of epoch 18: loss -13.16565 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 19: loss -13.33636 acc 0.66225 roc_auc 0.37010 prc_auc 0.56838[0m
[93maverage test of epoch 19: loss -13.72663 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 20: loss -13.89468 acc 0.66225 roc_auc 0.36971 prc_auc 0.56934[0m
[93maverage test of epoch 20: loss -14.28707 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 21: loss -14.45250 acc 0.66225 roc_auc 0.37020 prc_auc 0.56925[0m
[93maverage test of epoch 21: loss -14.84704 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 22: loss -15.00989 acc 0.66225 roc_auc 0.36971 prc_auc 0.56957[0m
[93maverage test of epoch 22: loss -15.40660 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 23: loss -15.56691 acc 0.66225 roc_auc 0.36971 prc_auc 0.56914[0m
[93maverage test of epoch 23: loss -15.96583 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 24: loss -16.12362 acc 0.66225 roc_auc 0.37010 prc_auc 0.57103[0m
[93maverage test of epoch 24: loss -16.52477 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 25: loss -16.68006 acc 0.66225 roc_auc 0.36971 prc_auc 0.57063[0m
[93maverage test of epoch 25: loss -17.08345 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 26: loss -17.23627 acc 0.66225 roc_auc 0.36971 prc_auc 0.57169[0m
[93maverage test of epoch 26: loss -17.64193 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 27: loss -17.79229 acc 0.66225 roc_auc 0.37020 prc_auc 0.57270[0m
[93maverage test of epoch 27: loss -18.20023 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 28: loss -18.34813 acc 0.66225 roc_auc 0.36892 prc_auc 0.57016[0m
[93maverage test of epoch 28: loss -18.75836 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 29: loss -18.90384 acc 0.66225 roc_auc 0.36882 prc_auc 0.57066[0m
[93maverage test of epoch 29: loss -19.31636 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 30: loss -19.45942 acc 0.66225 roc_auc 0.36833 prc_auc 0.57035[0m
[93maverage test of epoch 30: loss -19.87425 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 31: loss -20.01489 acc 0.66225 roc_auc 0.36735 prc_auc 0.57128[0m
[93maverage test of epoch 31: loss -20.43203 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 32: loss -20.57026 acc 0.66225 roc_auc 0.36990 prc_auc 0.57229[0m
[93maverage test of epoch 32: loss -20.98973 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 33: loss -21.12556 acc 0.66225 roc_auc 0.36284 prc_auc 0.56719[0m
[93maverage test of epoch 33: loss -21.54735 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 34: loss -21.68078 acc 0.66225 roc_auc 0.36696 prc_auc 0.56876[0m
[93maverage test of epoch 34: loss -22.10491 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 35: loss -22.23595 acc 0.66225 roc_auc 0.36755 prc_auc 0.57042[0m
[93maverage test of epoch 35: loss -22.66241 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 36: loss -22.79106 acc 0.66225 roc_auc 0.36824 prc_auc 0.57315[0m
[93maverage test of epoch 36: loss -23.21985 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 37: loss -23.34612 acc 0.66225 roc_auc 0.37265 prc_auc 0.58006[0m
[93maverage test of epoch 37: loss -23.77727 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 38: loss -23.90115 acc 0.66225 roc_auc 0.36412 prc_auc 0.57256[0m
[93maverage test of epoch 38: loss -24.33464 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 39: loss -24.45615 acc 0.66225 roc_auc 0.36549 prc_auc 0.57521[0m
[93maverage test of epoch 39: loss -24.89198 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -25.01111 acc 0.66225 roc_auc 0.37127 prc_auc 0.57892[0m
[93maverage test of epoch 40: loss -25.44929 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -25.56605 acc 0.66225 roc_auc 0.37510 prc_auc 0.58309[0m
[93maverage test of epoch 41: loss -26.00658 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -26.12096 acc 0.66225 roc_auc 0.36784 prc_auc 0.57919[0m
[93maverage test of epoch 42: loss -26.56384 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -26.67586 acc 0.66225 roc_auc 0.37108 prc_auc 0.58553[0m
[93maverage test of epoch 43: loss -27.12109 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -27.23073 acc 0.66225 roc_auc 0.37245 prc_auc 0.58604[0m
[93maverage test of epoch 44: loss -27.67832 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -27.78560 acc 0.66225 roc_auc 0.37588 prc_auc 0.59144[0m
[93maverage test of epoch 45: loss -28.23554 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -28.34045 acc 0.66225 roc_auc 0.37941 prc_auc 0.59585[0m
[93maverage test of epoch 46: loss -28.79274 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -28.89528 acc 0.66225 roc_auc 0.37794 prc_auc 0.59628[0m
[93maverage test of epoch 47: loss -29.34993 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -29.45010 acc 0.66225 roc_auc 0.38833 prc_auc 0.60481[0m
[93maverage test of epoch 48: loss -29.90711 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -30.00491 acc 0.66225 roc_auc 0.38186 prc_auc 0.60362[0m
[93maverage test of epoch 49: loss -30.46427 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.66501 ROC_AUC (avg): 0.504 PRC_AUC (avg): 0.6676 

Average forward propagation time taken(ms): 2.460900791516448
Average backward propagation time taken(ms): 0.8722991581279247

