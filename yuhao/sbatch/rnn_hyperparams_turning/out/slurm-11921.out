# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.0003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-22-42-02/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-22-42-02/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 16,
 'epochs': 50,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 8,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.0003,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 2,
 'num_workers': 8,
 'number_of_mlp_layer': 0,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-17-22-42-02',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 50, 'learning_rate': 0.0003, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.97409 acc 0.64000 roc_auc 0.44720 prc_auc 0.66707[0m
[93maverage test of epoch 0: loss -1.29280 acc 0.65789 roc_auc 0.63385 prc_auc 0.79511[0m
[92maverage training of epoch 1: loss -1.56708 acc 0.66667 roc_auc 0.55940 prc_auc 0.76638[0m
[93maverage test of epoch 1: loss -1.89190 acc 0.65789 roc_auc 0.78154 prc_auc 0.89351[0m
[92maverage training of epoch 2: loss -2.15401 acc 0.66667 roc_auc 0.63680 prc_auc 0.78026[0m
[93maverage test of epoch 2: loss -2.41906 acc 0.65789 roc_auc 0.84615 prc_auc 0.92579[0m
[92maverage training of epoch 3: loss -2.63657 acc 0.66667 roc_auc 0.75300 prc_auc 0.86129[0m
[93maverage test of epoch 3: loss -2.90024 acc 0.65789 roc_auc 0.89846 prc_auc 0.93860[0m
[92maverage training of epoch 4: loss -3.08817 acc 0.72000 roc_auc 0.82960 prc_auc 0.89404[0m
[93maverage test of epoch 4: loss -3.30672 acc 0.71053 roc_auc 0.87692 prc_auc 0.93611[0m
[92maverage training of epoch 5: loss -3.51639 acc 0.81333 roc_auc 0.85620 prc_auc 0.89944[0m
[93maverage test of epoch 5: loss -3.70995 acc 0.78947 roc_auc 0.85538 prc_auc 0.92466[0m
[92maverage training of epoch 6: loss -3.90643 acc 0.83333 roc_auc 0.85860 prc_auc 0.90245[0m
[93maverage test of epoch 6: loss -4.08221 acc 0.81579 roc_auc 0.87385 prc_auc 0.93624[0m
[92maverage training of epoch 7: loss -4.25172 acc 0.83333 roc_auc 0.86580 prc_auc 0.92758[0m
[93maverage test of epoch 7: loss -4.45194 acc 0.81579 roc_auc 0.88000 prc_auc 0.94575[0m
[92maverage training of epoch 8: loss -4.60170 acc 0.86000 roc_auc 0.85260 prc_auc 0.89339[0m
[93maverage test of epoch 8: loss -4.67377 acc 0.78947 roc_auc 0.82154 prc_auc 0.87615[0m
[92maverage training of epoch 9: loss -4.91517 acc 0.86000 roc_auc 0.83280 prc_auc 0.86085[0m
[93maverage test of epoch 9: loss -4.98002 acc 0.81579 roc_auc 0.87077 prc_auc 0.94136[0m
[92maverage training of epoch 10: loss -5.12349 acc 0.80000 roc_auc 0.82800 prc_auc 0.89819[0m
[93maverage test of epoch 10: loss -5.30026 acc 0.81579 roc_auc 0.80615 prc_auc 0.87557[0m
[92maverage training of epoch 11: loss -5.40200 acc 0.79333 roc_auc 0.82380 prc_auc 0.89976[0m
[93maverage test of epoch 11: loss -5.69692 acc 0.84211 roc_auc 0.88308 prc_auc 0.92080[0m
[92maverage training of epoch 12: loss -5.82819 acc 0.86667 roc_auc 0.85640 prc_auc 0.89446[0m
[93maverage test of epoch 12: loss -5.84207 acc 0.81579 roc_auc 0.82462 prc_auc 0.87725[0m
[92maverage training of epoch 13: loss -6.05388 acc 0.83333 roc_auc 0.80940 prc_auc 0.89007[0m
[93maverage test of epoch 13: loss -6.20529 acc 0.81579 roc_auc 0.90462 prc_auc 0.94909[0m
[92maverage training of epoch 14: loss -6.35719 acc 0.84000 roc_auc 0.77640 prc_auc 0.80837[0m
[93maverage test of epoch 14: loss -6.57528 acc 0.84211 roc_auc 0.84923 prc_auc 0.87459[0m
[92maverage training of epoch 15: loss -6.65949 acc 0.83333 roc_auc 0.80480 prc_auc 0.86505[0m
[93maverage test of epoch 15: loss -6.87727 acc 0.84211 roc_auc 0.90462 prc_auc 0.95374[0m
[92maverage training of epoch 16: loss -6.93132 acc 0.82000 roc_auc 0.77640 prc_auc 0.82250[0m
[93maverage test of epoch 16: loss -7.18164 acc 0.84211 roc_auc 0.88000 prc_auc 0.94929[0m
[92maverage training of epoch 17: loss -7.25322 acc 0.83333 roc_auc 0.82060 prc_auc 0.88299[0m
[93maverage test of epoch 17: loss -7.45836 acc 0.84211 roc_auc 0.81538 prc_auc 0.87638[0m
[92maverage training of epoch 18: loss -7.54164 acc 0.83333 roc_auc 0.81160 prc_auc 0.87528[0m
[93maverage test of epoch 18: loss -7.69996 acc 0.84211 roc_auc 0.83692 prc_auc 0.92180[0m
[92maverage training of epoch 19: loss -7.78624 acc 0.84667 roc_auc 0.77520 prc_auc 0.82239[0m
[93maverage test of epoch 19: loss -7.82778 acc 0.81579 roc_auc 0.78154 prc_auc 0.87942[0m
[92maverage training of epoch 20: loss -8.12760 acc 0.83333 roc_auc 0.81660 prc_auc 0.84455[0m
[93maverage test of epoch 20: loss -8.16382 acc 0.78947 roc_auc 0.87692 prc_auc 0.94285[0m
[92maverage training of epoch 21: loss -8.42046 acc 0.83333 roc_auc 0.85000 prc_auc 0.87452[0m
[93maverage test of epoch 21: loss -8.46301 acc 0.84211 roc_auc 0.80615 prc_auc 0.90672[0m
[92maverage training of epoch 22: loss -8.71368 acc 0.84667 roc_auc 0.83200 prc_auc 0.87001[0m
[93maverage test of epoch 22: loss -8.74332 acc 0.84211 roc_auc 0.86769 prc_auc 0.93652[0m
[92maverage training of epoch 23: loss -8.91569 acc 0.84667 roc_auc 0.77130 prc_auc 0.81357[0m
[93maverage test of epoch 23: loss -8.85695 acc 0.81579 roc_auc 0.68923 prc_auc 0.74590[0m
[92maverage training of epoch 24: loss -9.16164 acc 0.82000 roc_auc 0.82460 prc_auc 0.86497[0m
[93maverage test of epoch 24: loss -9.41013 acc 0.84211 roc_auc 0.85692 prc_auc 0.92323[0m
[92maverage training of epoch 25: loss -9.51640 acc 0.82667 roc_auc 0.84190 prc_auc 0.88769[0m
[93maverage test of epoch 25: loss -9.53913 acc 0.84211 roc_auc 0.87385 prc_auc 0.94702[0m
[92maverage training of epoch 26: loss -9.81273 acc 0.84000 roc_auc 0.82640 prc_auc 0.84660[0m
[93maverage test of epoch 26: loss -9.79334 acc 0.81579 roc_auc 0.88308 prc_auc 0.92899[0m
[92maverage training of epoch 27: loss -10.03310 acc 0.83333 roc_auc 0.79430 prc_auc 0.82668[0m
[93maverage test of epoch 27: loss -10.22875 acc 0.84211 roc_auc 0.84615 prc_auc 0.93399[0m
[92maverage training of epoch 28: loss -10.34887 acc 0.84000 roc_auc 0.82770 prc_auc 0.89116[0m
[93maverage test of epoch 28: loss -10.29906 acc 0.78947 roc_auc 0.84000 prc_auc 0.92384[0m
[92maverage training of epoch 29: loss -10.67250 acc 0.85333 roc_auc 0.81860 prc_auc 0.83121[0m
[93maverage test of epoch 29: loss -10.61673 acc 0.81579 roc_auc 0.74308 prc_auc 0.77435[0m
[92maverage training of epoch 30: loss -10.81666 acc 0.84000 roc_auc 0.77090 prc_auc 0.81573[0m
[93maverage test of epoch 30: loss -11.02648 acc 0.84211 roc_auc 0.79077 prc_auc 0.84007[0m
[92maverage training of epoch 31: loss -11.14484 acc 0.84000 roc_auc 0.81720 prc_auc 0.84334[0m
[93maverage test of epoch 31: loss -11.24170 acc 0.84211 roc_auc 0.82462 prc_auc 0.90736[0m
[92maverage training of epoch 32: loss -11.40200 acc 0.82667 roc_auc 0.80380 prc_auc 0.85626[0m
[93maverage test of epoch 32: loss -11.50051 acc 0.84211 roc_auc 0.88000 prc_auc 0.93949[0m
[92maverage training of epoch 33: loss -11.55119 acc 0.82000 roc_auc 0.79470 prc_auc 0.83484[0m
[93maverage test of epoch 33: loss -11.64690 acc 0.81579 roc_auc 0.89538 prc_auc 0.95302[0m
[92maverage training of epoch 34: loss -11.97107 acc 0.84667 roc_auc 0.81720 prc_auc 0.82254[0m
[93maverage test of epoch 34: loss -11.76230 acc 0.81579 roc_auc 0.76769 prc_auc 0.80344[0m
[92maverage training of epoch 35: loss -12.13926 acc 0.81333 roc_auc 0.80800 prc_auc 0.85170[0m
[93maverage test of epoch 35: loss -12.29251 acc 0.84211 roc_auc 0.84000 prc_auc 0.92966[0m
[92maverage training of epoch 36: loss -12.51498 acc 0.84000 roc_auc 0.82840 prc_auc 0.87052[0m
[93maverage test of epoch 36: loss -12.61833 acc 0.84211 roc_auc 0.88308 prc_auc 0.94953[0m
[92maverage training of epoch 37: loss -12.80879 acc 0.85333 roc_auc 0.82740 prc_auc 0.85590[0m
[93maverage test of epoch 37: loss -12.68809 acc 0.78947 roc_auc 0.88000 prc_auc 0.92020[0m
[92maverage training of epoch 38: loss -13.09129 acc 0.84667 roc_auc 0.83090 prc_auc 0.85445[0m
[93maverage test of epoch 38: loss -13.03729 acc 0.81579 roc_auc 0.87077 prc_auc 0.93824[0m
[92maverage training of epoch 39: loss -13.38841 acc 0.85333 roc_auc 0.80990 prc_auc 0.83663[0m
[93maverage test of epoch 39: loss -13.33949 acc 0.84211 roc_auc 0.83538 prc_auc 0.89882[0m
[92maverage training of epoch 40: loss -13.58612 acc 0.86000 roc_auc 0.80220 prc_auc 0.81230[0m
[93maverage test of epoch 40: loss -13.61830 acc 0.78947 roc_auc 0.85538 prc_auc 0.92602[0m
[92maverage training of epoch 41: loss -13.90010 acc 0.84000 roc_auc 0.81580 prc_auc 0.86007[0m
[93maverage test of epoch 41: loss -13.83900 acc 0.81579 roc_auc 0.85077 prc_auc 0.91089[0m
[92maverage training of epoch 42: loss -14.12873 acc 0.84000 roc_auc 0.81350 prc_auc 0.84575[0m
[93maverage test of epoch 42: loss -14.13234 acc 0.84211 roc_auc 0.87077 prc_auc 0.94683[0m
[92maverage training of epoch 43: loss -14.36457 acc 0.84000 roc_auc 0.83130 prc_auc 0.86803[0m
[93maverage test of epoch 43: loss -14.38618 acc 0.81579 roc_auc 0.90769 prc_auc 0.95239[0m
[92maverage training of epoch 44: loss -14.71822 acc 0.84667 roc_auc 0.81130 prc_auc 0.84193[0m
[93maverage test of epoch 44: loss -14.64359 acc 0.81579 roc_auc 0.89846 prc_auc 0.95119[0m
[92maverage training of epoch 45: loss -14.89521 acc 0.84667 roc_auc 0.83880 prc_auc 0.85548[0m
[93maverage test of epoch 45: loss -14.90955 acc 0.84211 roc_auc 0.85538 prc_auc 0.93203[0m
[92maverage training of epoch 46: loss -15.24369 acc 0.84667 roc_auc 0.83220 prc_auc 0.85556[0m
[93maverage test of epoch 46: loss -15.18936 acc 0.84211 roc_auc 0.84000 prc_auc 0.90377[0m
[92maverage training of epoch 47: loss -15.43766 acc 0.83333 roc_auc 0.81880 prc_auc 0.83648[0m
[93maverage test of epoch 47: loss -15.57812 acc 0.84211 roc_auc 0.84154 prc_auc 0.91025[0m
[92maverage training of epoch 48: loss -15.80152 acc 0.86000 roc_auc 0.80400 prc_auc 0.82699[0m
[93maverage test of epoch 48: loss -15.56802 acc 0.81579 roc_auc 0.85385 prc_auc 0.89487[0m
[92maverage training of epoch 49: loss -16.01923 acc 0.84667 roc_auc 0.82180 prc_auc 0.85159[0m
[93maverage test of epoch 49: loss -15.94491 acc 0.81579 roc_auc 0.85846 prc_auc 0.89912[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -1.31241 acc 0.66667 roc_auc 0.45000 prc_auc 0.63831[0m
[93maverage test of epoch 0: loss -1.92157 acc 0.65789 roc_auc 0.32308 prc_auc 0.56333[0m
[92maverage training of epoch 1: loss -2.84415 acc 0.66667 roc_auc 0.47100 prc_auc 0.64451[0m
[93maverage test of epoch 1: loss -3.65837 acc 0.65789 roc_auc 0.59692 prc_auc 0.69394[0m
[92maverage training of epoch 2: loss -4.18978 acc 0.66667 roc_auc 0.36340 prc_auc 0.58374[0m
[93maverage test of epoch 2: loss -4.64095 acc 0.65789 roc_auc 0.55692 prc_auc 0.69024[0m
[92maverage training of epoch 3: loss -5.00891 acc 0.66667 roc_auc 0.51480 prc_auc 0.67981[0m
[93maverage test of epoch 3: loss -5.28769 acc 0.65789 roc_auc 0.40923 prc_auc 0.61604[0m
[92maverage training of epoch 4: loss -5.58421 acc 0.66667 roc_auc 0.46460 prc_auc 0.64748[0m
[93maverage test of epoch 4: loss -5.81236 acc 0.65789 roc_auc 0.56000 prc_auc 0.70173[0m
[92maverage training of epoch 5: loss -6.03907 acc 0.66667 roc_auc 0.45580 prc_auc 0.64762[0m
[93maverage test of epoch 5: loss -6.22768 acc 0.65789 roc_auc 0.38769 prc_auc 0.58270[0m
[92maverage training of epoch 6: loss -6.44068 acc 0.66667 roc_auc 0.42200 prc_auc 0.60709[0m
[93maverage test of epoch 6: loss -6.61661 acc 0.65789 roc_auc 0.59692 prc_auc 0.72911[0m
[92maverage training of epoch 7: loss -6.82041 acc 0.66667 roc_auc 0.46000 prc_auc 0.64678[0m
[93maverage test of epoch 7: loss -6.97008 acc 0.65789 roc_auc 0.46769 prc_auc 0.65494[0m
[92maverage training of epoch 8: loss -7.16993 acc 0.66667 roc_auc 0.48820 prc_auc 0.65043[0m
[93maverage test of epoch 8: loss -7.31139 acc 0.65789 roc_auc 0.53538 prc_auc 0.74086[0m
[92maverage training of epoch 9: loss -7.50671 acc 0.66667 roc_auc 0.42700 prc_auc 0.62173[0m
[93maverage test of epoch 9: loss -7.65210 acc 0.65789 roc_auc 0.62154 prc_auc 0.79219[0m
[92maverage training of epoch 10: loss -7.84365 acc 0.66667 roc_auc 0.46020 prc_auc 0.62607[0m
[93maverage test of epoch 10: loss -7.98256 acc 0.65789 roc_auc 0.71692 prc_auc 0.78989[0m
[92maverage training of epoch 11: loss -8.16178 acc 0.66667 roc_auc 0.42940 prc_auc 0.62193[0m
[93maverage test of epoch 11: loss -8.29776 acc 0.65789 roc_auc 0.65231 prc_auc 0.83002[0m
[92maverage training of epoch 12: loss -8.48839 acc 0.66667 roc_auc 0.43870 prc_auc 0.61385[0m
[93maverage test of epoch 12: loss -8.61083 acc 0.65789 roc_auc 0.49231 prc_auc 0.68613[0m
[92maverage training of epoch 13: loss -8.80257 acc 0.66667 roc_auc 0.42940 prc_auc 0.62046[0m
[93maverage test of epoch 13: loss -8.92924 acc 0.65789 roc_auc 0.48308 prc_auc 0.72022[0m
[92maverage training of epoch 14: loss -9.11695 acc 0.66667 roc_auc 0.44640 prc_auc 0.66372[0m
[93maverage test of epoch 14: loss -9.23590 acc 0.65789 roc_auc 0.38154 prc_auc 0.59181[0m
[92maverage training of epoch 15: loss -9.43023 acc 0.66667 roc_auc 0.44940 prc_auc 0.62781[0m
[93maverage test of epoch 15: loss -9.55149 acc 0.65789 roc_auc 0.32462 prc_auc 0.61888[0m
[92maverage training of epoch 16: loss -9.73831 acc 0.66667 roc_auc 0.43460 prc_auc 0.61765[0m
[93maverage test of epoch 16: loss -9.85203 acc 0.65789 roc_auc 0.43077 prc_auc 0.64424[0m
[92maverage training of epoch 17: loss -10.04731 acc 0.66667 roc_auc 0.42080 prc_auc 0.62563[0m
[93maverage test of epoch 17: loss -10.16365 acc 0.65789 roc_auc 0.32000 prc_auc 0.56029[0m
[92maverage training of epoch 18: loss -10.35423 acc 0.66667 roc_auc 0.42630 prc_auc 0.60783[0m
[93maverage test of epoch 18: loss -10.47401 acc 0.65789 roc_auc 0.72308 prc_auc 0.78647[0m
[92maverage training of epoch 19: loss -10.66081 acc 0.66667 roc_auc 0.44280 prc_auc 0.62375[0m
[93maverage test of epoch 19: loss -10.77348 acc 0.65789 roc_auc 0.59692 prc_auc 0.73922[0m
[92maverage training of epoch 20: loss -10.96412 acc 0.66667 roc_auc 0.42060 prc_auc 0.59730[0m
[93maverage test of epoch 20: loss -11.08020 acc 0.65789 roc_auc 0.55231 prc_auc 0.71076[0m
[92maverage training of epoch 21: loss -11.26864 acc 0.66667 roc_auc 0.42750 prc_auc 0.60646[0m
[93maverage test of epoch 21: loss -11.37724 acc 0.65789 roc_auc 0.34615 prc_auc 0.60365[0m
[92maverage training of epoch 22: loss -11.57057 acc 0.66667 roc_auc 0.42780 prc_auc 0.60141[0m
[93maverage test of epoch 22: loss -11.68492 acc 0.65789 roc_auc 0.40923 prc_auc 0.60269[0m
[92maverage training of epoch 23: loss -11.87283 acc 0.66667 roc_auc 0.42440 prc_auc 0.60409[0m
[93maverage test of epoch 23: loss -11.98222 acc 0.65789 roc_auc 0.52154 prc_auc 0.72808[0m
[92maverage training of epoch 24: loss -12.17636 acc 0.66667 roc_auc 0.43100 prc_auc 0.60089[0m
[93maverage test of epoch 24: loss -12.28979 acc 0.65789 roc_auc 0.67077 prc_auc 0.82630[0m
[92maverage training of epoch 25: loss -12.47784 acc 0.66667 roc_auc 0.42620 prc_auc 0.60453[0m
[93maverage test of epoch 25: loss -12.58715 acc 0.65789 roc_auc 0.50615 prc_auc 0.66386[0m
[92maverage training of epoch 26: loss -12.77977 acc 0.66667 roc_auc 0.41800 prc_auc 0.60031[0m
[93maverage test of epoch 26: loss -12.88504 acc 0.65789 roc_auc 0.55077 prc_auc 0.72187[0m
[92maverage training of epoch 27: loss -13.07975 acc 0.66667 roc_auc 0.42940 prc_auc 0.63726[0m
[93maverage test of epoch 27: loss -13.18822 acc 0.65789 roc_auc 0.49385 prc_auc 0.69947[0m
[92maverage training of epoch 28: loss -13.38033 acc 0.66667 roc_auc 0.41580 prc_auc 0.60437[0m
[93maverage test of epoch 28: loss -13.48715 acc 0.65789 roc_auc 0.38000 prc_auc 0.59295[0m
[92maverage training of epoch 29: loss -13.68088 acc 0.66667 roc_auc 0.42440 prc_auc 0.61448[0m
[93maverage test of epoch 29: loss -13.78758 acc 0.65789 roc_auc 0.44154 prc_auc 0.63234[0m
[92maverage training of epoch 30: loss -13.98105 acc 0.66667 roc_auc 0.41790 prc_auc 0.59859[0m
[93maverage test of epoch 30: loss -14.08477 acc 0.65789 roc_auc 0.51077 prc_auc 0.69377[0m
[92maverage training of epoch 31: loss -14.28087 acc 0.66667 roc_auc 0.41590 prc_auc 0.59500[0m
[93maverage test of epoch 31: loss -14.38235 acc 0.65789 roc_auc 0.28000 prc_auc 0.53842[0m
[92maverage training of epoch 32: loss -14.58012 acc 0.66667 roc_auc 0.41950 prc_auc 0.59528[0m
[93maverage test of epoch 32: loss -14.68411 acc 0.65789 roc_auc 0.61846 prc_auc 0.72933[0m
[92maverage training of epoch 33: loss -14.88005 acc 0.66667 roc_auc 0.41830 prc_auc 0.60163[0m
[93maverage test of epoch 33: loss -14.98132 acc 0.65789 roc_auc 0.48154 prc_auc 0.66809[0m
[92maverage training of epoch 34: loss -15.17961 acc 0.66667 roc_auc 0.42920 prc_auc 0.60797[0m
[93maverage test of epoch 34: loss -15.28192 acc 0.65789 roc_auc 0.42923 prc_auc 0.61836[0m
[92maverage training of epoch 35: loss -15.47886 acc 0.66667 roc_auc 0.41990 prc_auc 0.60831[0m
[93maverage test of epoch 35: loss -15.57891 acc 0.65789 roc_auc 0.56000 prc_auc 0.71112[0m
[92maverage training of epoch 36: loss -15.77920 acc 0.66667 roc_auc 0.41640 prc_auc 0.59597[0m
[93maverage test of epoch 36: loss -15.87581 acc 0.65789 roc_auc 0.48154 prc_auc 0.70377[0m
[92maverage training of epoch 37: loss -16.07790 acc 0.66667 roc_auc 0.42930 prc_auc 0.60807[0m
[93maverage test of epoch 37: loss -16.17517 acc 0.65789 roc_auc 0.49846 prc_auc 0.67186[0m
[92maverage training of epoch 38: loss -16.37724 acc 0.66667 roc_auc 0.42330 prc_auc 0.60456[0m
[93maverage test of epoch 38: loss -16.47411 acc 0.65789 roc_auc 0.42923 prc_auc 0.60836[0m
[92maverage training of epoch 39: loss -16.67646 acc 0.66667 roc_auc 0.42230 prc_auc 0.59912[0m
[93maverage test of epoch 39: loss -16.77140 acc 0.65789 roc_auc 0.73692 prc_auc 0.80437[0m
[92maverage training of epoch 40: loss -16.97460 acc 0.66667 roc_auc 0.42000 prc_auc 0.59588[0m
[93maverage test of epoch 40: loss -17.06862 acc 0.65789 roc_auc 0.52462 prc_auc 0.67715[0m
[92maverage training of epoch 41: loss -17.27355 acc 0.66667 roc_auc 0.41930 prc_auc 0.59974[0m
[93maverage test of epoch 41: loss -17.36753 acc 0.65789 roc_auc 0.42154 prc_auc 0.64805[0m
[92maverage training of epoch 42: loss -17.57202 acc 0.66667 roc_auc 0.41780 prc_auc 0.60146[0m
[93maverage test of epoch 42: loss -17.66615 acc 0.65789 roc_auc 0.54923 prc_auc 0.67506[0m
[92maverage training of epoch 43: loss -17.87100 acc 0.66667 roc_auc 0.41930 prc_auc 0.59755[0m
[93maverage test of epoch 43: loss -17.96311 acc 0.65789 roc_auc 0.39846 prc_auc 0.58965[0m
[92maverage training of epoch 44: loss -18.17000 acc 0.66667 roc_auc 0.41920 prc_auc 0.59736[0m
[93maverage test of epoch 44: loss -18.26024 acc 0.65789 roc_auc 0.40000 prc_auc 0.60587[0m
[92maverage training of epoch 45: loss -18.46881 acc 0.66667 roc_auc 0.41400 prc_auc 0.59443[0m
[93maverage test of epoch 45: loss -18.55916 acc 0.65789 roc_auc 0.69077 prc_auc 0.77261[0m
[92maverage training of epoch 46: loss -18.76734 acc 0.66667 roc_auc 0.41520 prc_auc 0.60213[0m
[93maverage test of epoch 46: loss -18.85603 acc 0.65789 roc_auc 0.53231 prc_auc 0.68936[0m
[92maverage training of epoch 47: loss -19.06608 acc 0.66667 roc_auc 0.42030 prc_auc 0.59745[0m
[93maverage test of epoch 47: loss -19.15474 acc 0.65789 roc_auc 0.28308 prc_auc 0.55500[0m
[92maverage training of epoch 48: loss -19.36459 acc 0.66667 roc_auc 0.42020 prc_auc 0.60769[0m
[93maverage test of epoch 48: loss -19.45244 acc 0.65789 roc_auc 0.48769 prc_auc 0.70283[0m
[92maverage training of epoch 49: loss -19.66314 acc 0.66667 roc_auc 0.42170 prc_auc 0.60987[0m
[93maverage test of epoch 49: loss -19.75035 acc 0.65789 roc_auc 0.45692 prc_auc 0.63588[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.08500 acc 0.44000 roc_auc 0.45000 prc_auc 0.66310[0m
[93maverage test of epoch 0: loss -0.34544 acc 0.68421 roc_auc 0.49846 prc_auc 0.71516[0m
[92maverage training of epoch 1: loss -0.56458 acc 0.66667 roc_auc 0.46760 prc_auc 0.67266[0m
[93maverage test of epoch 1: loss -0.79276 acc 0.65789 roc_auc 0.68615 prc_auc 0.83121[0m
[92maverage training of epoch 2: loss -1.02442 acc 0.66667 roc_auc 0.51700 prc_auc 0.69685[0m
[93maverage test of epoch 2: loss -1.25944 acc 0.65789 roc_auc 0.45846 prc_auc 0.72585[0m
[92maverage training of epoch 3: loss -1.60099 acc 0.66667 roc_auc 0.51300 prc_auc 0.72864[0m
[93maverage test of epoch 3: loss -1.93219 acc 0.65789 roc_auc 0.63077 prc_auc 0.78254[0m
[92maverage training of epoch 4: loss -2.17435 acc 0.66667 roc_auc 0.50460 prc_auc 0.68230[0m
[93maverage test of epoch 4: loss -2.38116 acc 0.65789 roc_auc 0.49846 prc_auc 0.66426[0m
[92maverage training of epoch 5: loss -2.57921 acc 0.66667 roc_auc 0.43520 prc_auc 0.62747[0m
[93maverage test of epoch 5: loss -2.74275 acc 0.65789 roc_auc 0.44923 prc_auc 0.66887[0m
[92maverage training of epoch 6: loss -2.92866 acc 0.66667 roc_auc 0.42380 prc_auc 0.63207[0m
[93maverage test of epoch 6: loss -3.08767 acc 0.65789 roc_auc 0.55385 prc_auc 0.76260[0m
[92maverage training of epoch 7: loss -3.27007 acc 0.66667 roc_auc 0.48860 prc_auc 0.68474[0m
[93maverage test of epoch 7: loss -3.41793 acc 0.65789 roc_auc 0.53231 prc_auc 0.73659[0m
[92maverage training of epoch 8: loss -3.60482 acc 0.66667 roc_auc 0.38840 prc_auc 0.57551[0m
[93maverage test of epoch 8: loss -3.77111 acc 0.65789 roc_auc 0.52308 prc_auc 0.71512[0m
[92maverage training of epoch 9: loss -3.98626 acc 0.66667 roc_auc 0.38990 prc_auc 0.58682[0m
[93maverage test of epoch 9: loss -4.16969 acc 0.65789 roc_auc 0.69538 prc_auc 0.78301[0m
[92maverage training of epoch 10: loss -4.39625 acc 0.66667 roc_auc 0.39940 prc_auc 0.58868[0m
[93maverage test of epoch 10: loss -4.56431 acc 0.65789 roc_auc 0.36308 prc_auc 0.58766[0m
[92maverage training of epoch 11: loss -4.77417 acc 0.66667 roc_auc 0.42000 prc_auc 0.61313[0m
[93maverage test of epoch 11: loss -4.92666 acc 0.65789 roc_auc 0.45538 prc_auc 0.64748[0m
[92maverage training of epoch 12: loss -5.13351 acc 0.66667 roc_auc 0.35220 prc_auc 0.57033[0m
[93maverage test of epoch 12: loss -5.27619 acc 0.65789 roc_auc 0.41846 prc_auc 0.63613[0m
[92maverage training of epoch 13: loss -5.47915 acc 0.66667 roc_auc 0.40300 prc_auc 0.59989[0m
[93maverage test of epoch 13: loss -5.62259 acc 0.65789 roc_auc 0.45231 prc_auc 0.61320[0m
[92maverage training of epoch 14: loss -5.81481 acc 0.66667 roc_auc 0.37800 prc_auc 0.58789[0m
[93maverage test of epoch 14: loss -5.95210 acc 0.65789 roc_auc 0.45231 prc_auc 0.71450[0m
[92maverage training of epoch 15: loss -6.14352 acc 0.66667 roc_auc 0.41200 prc_auc 0.60133[0m
[93maverage test of epoch 15: loss -6.27218 acc 0.65789 roc_auc 0.35692 prc_auc 0.60883[0m
[92maverage training of epoch 16: loss -6.46405 acc 0.66667 roc_auc 0.35480 prc_auc 0.55989[0m
[93maverage test of epoch 16: loss -6.59612 acc 0.65789 roc_auc 0.62154 prc_auc 0.73323[0m
[92maverage training of epoch 17: loss -6.78655 acc 0.66667 roc_auc 0.40340 prc_auc 0.60091[0m
[93maverage test of epoch 17: loss -6.91231 acc 0.65789 roc_auc 0.57538 prc_auc 0.72153[0m
[92maverage training of epoch 18: loss -7.10118 acc 0.66667 roc_auc 0.39040 prc_auc 0.58643[0m
[93maverage test of epoch 18: loss -7.22507 acc 0.65789 roc_auc 0.50000 prc_auc 0.69076[0m
[92maverage training of epoch 19: loss -7.41390 acc 0.66667 roc_auc 0.38530 prc_auc 0.58636[0m
[93maverage test of epoch 19: loss -7.53423 acc 0.65789 roc_auc 0.70308 prc_auc 0.76947[0m
[92maverage training of epoch 20: loss -7.72490 acc 0.66667 roc_auc 0.40840 prc_auc 0.62394[0m
[93maverage test of epoch 20: loss -7.84702 acc 0.65789 roc_auc 0.48615 prc_auc 0.67530[0m
[92maverage training of epoch 21: loss -8.03362 acc 0.66667 roc_auc 0.39840 prc_auc 0.60847[0m
[93maverage test of epoch 21: loss -8.15061 acc 0.65789 roc_auc 0.34769 prc_auc 0.62970[0m
[92maverage training of epoch 22: loss -8.33938 acc 0.66667 roc_auc 0.38710 prc_auc 0.59266[0m
[93maverage test of epoch 22: loss -8.45750 acc 0.65789 roc_auc 0.54615 prc_auc 0.68225[0m
[92maverage training of epoch 23: loss -8.64727 acc 0.66667 roc_auc 0.38430 prc_auc 0.58197[0m
[93maverage test of epoch 23: loss -8.76577 acc 0.65789 roc_auc 0.65846 prc_auc 0.81292[0m
[92maverage training of epoch 24: loss -8.95165 acc 0.66667 roc_auc 0.36860 prc_auc 0.57179[0m
[93maverage test of epoch 24: loss -9.06833 acc 0.65789 roc_auc 0.50308 prc_auc 0.68898[0m
[92maverage training of epoch 25: loss -9.25743 acc 0.66667 roc_auc 0.39520 prc_auc 0.58612[0m
[93maverage test of epoch 25: loss -9.36940 acc 0.65789 roc_auc 0.51385 prc_auc 0.73557[0m
[92maverage training of epoch 26: loss -9.55977 acc 0.66667 roc_auc 0.38630 prc_auc 0.59729[0m
[93maverage test of epoch 26: loss -9.67219 acc 0.65789 roc_auc 0.42154 prc_auc 0.66014[0m
[92maverage training of epoch 27: loss -9.86261 acc 0.66667 roc_auc 0.38560 prc_auc 0.60599[0m
[93maverage test of epoch 27: loss -9.97374 acc 0.65789 roc_auc 0.42769 prc_auc 0.64677[0m
[92maverage training of epoch 28: loss -10.16546 acc 0.66667 roc_auc 0.36670 prc_auc 0.57069[0m
[93maverage test of epoch 28: loss -10.27378 acc 0.65789 roc_auc 0.48000 prc_auc 0.70138[0m
[92maverage training of epoch 29: loss -10.46700 acc 0.66667 roc_auc 0.38660 prc_auc 0.58332[0m
[93maverage test of epoch 29: loss -10.57551 acc 0.65789 roc_auc 0.43846 prc_auc 0.64112[0m
[92maverage training of epoch 30: loss -10.76828 acc 0.66667 roc_auc 0.37790 prc_auc 0.57513[0m
[93maverage test of epoch 30: loss -10.87593 acc 0.65789 roc_auc 0.56000 prc_auc 0.69551[0m
[92maverage training of epoch 31: loss -11.06954 acc 0.66667 roc_auc 0.38580 prc_auc 0.58583[0m
[93maverage test of epoch 31: loss -11.17693 acc 0.65789 roc_auc 0.48154 prc_auc 0.67640[0m
[92maverage training of epoch 32: loss -11.37004 acc 0.66667 roc_auc 0.38660 prc_auc 0.58977[0m
[93maverage test of epoch 32: loss -11.47639 acc 0.65789 roc_auc 0.54923 prc_auc 0.74143[0m
[92maverage training of epoch 33: loss -11.66997 acc 0.66667 roc_auc 0.38710 prc_auc 0.58029[0m
[93maverage test of epoch 33: loss -11.77498 acc 0.65789 roc_auc 0.47231 prc_auc 0.67672[0m
[92maverage training of epoch 34: loss -11.97015 acc 0.66667 roc_auc 0.37310 prc_auc 0.57404[0m
[93maverage test of epoch 34: loss -12.07478 acc 0.65789 roc_auc 0.38769 prc_auc 0.61472[0m
[92maverage training of epoch 35: loss -12.27020 acc 0.66667 roc_auc 0.37390 prc_auc 0.56898[0m
[93maverage test of epoch 35: loss -12.37363 acc 0.65789 roc_auc 0.41538 prc_auc 0.61976[0m
[92maverage training of epoch 36: loss -12.57003 acc 0.66667 roc_auc 0.37960 prc_auc 0.57486[0m
[93maverage test of epoch 36: loss -12.67124 acc 0.65789 roc_auc 0.43692 prc_auc 0.64161[0m
[92maverage training of epoch 37: loss -12.86996 acc 0.66667 roc_auc 0.38850 prc_auc 0.59109[0m
[93maverage test of epoch 37: loss -12.97088 acc 0.65789 roc_auc 0.61231 prc_auc 0.76091[0m
[92maverage training of epoch 38: loss -13.16904 acc 0.66667 roc_auc 0.38290 prc_auc 0.57840[0m
[93maverage test of epoch 38: loss -13.26965 acc 0.65789 roc_auc 0.52154 prc_auc 0.63884[0m
[92maverage training of epoch 39: loss -13.46838 acc 0.66667 roc_auc 0.38390 prc_auc 0.58606[0m
[93maverage test of epoch 39: loss -13.56816 acc 0.65789 roc_auc 0.52000 prc_auc 0.68163[0m
[92maverage training of epoch 40: loss -13.76727 acc 0.66667 roc_auc 0.37960 prc_auc 0.57753[0m
[93maverage test of epoch 40: loss -13.86476 acc 0.65789 roc_auc 0.55231 prc_auc 0.66676[0m
[92maverage training of epoch 41: loss -14.06591 acc 0.66667 roc_auc 0.37450 prc_auc 0.57418[0m
[93maverage test of epoch 41: loss -14.16465 acc 0.65789 roc_auc 0.43846 prc_auc 0.63578[0m
[92maverage training of epoch 42: loss -14.36582 acc 0.66667 roc_auc 0.37720 prc_auc 0.57645[0m
[93maverage test of epoch 42: loss -14.46197 acc 0.65789 roc_auc 0.52615 prc_auc 0.71700[0m
[92maverage training of epoch 43: loss -14.66436 acc 0.66667 roc_auc 0.37960 prc_auc 0.57592[0m
[93maverage test of epoch 43: loss -14.75938 acc 0.65789 roc_auc 0.57385 prc_auc 0.71348[0m
[92maverage training of epoch 44: loss -14.96367 acc 0.66667 roc_auc 0.38790 prc_auc 0.59315[0m
[93maverage test of epoch 44: loss -15.05780 acc 0.65789 roc_auc 0.40769 prc_auc 0.59542[0m
[92maverage training of epoch 45: loss -15.26217 acc 0.66667 roc_auc 0.38020 prc_auc 0.58285[0m
[93maverage test of epoch 45: loss -15.35619 acc 0.65789 roc_auc 0.39846 prc_auc 0.59331[0m
[92maverage training of epoch 46: loss -15.56065 acc 0.66667 roc_auc 0.37810 prc_auc 0.58343[0m
[93maverage test of epoch 46: loss -15.65394 acc 0.65789 roc_auc 0.37846 prc_auc 0.61892[0m
[92maverage training of epoch 47: loss -15.85924 acc 0.66667 roc_auc 0.38040 prc_auc 0.58175[0m
[93maverage test of epoch 47: loss -15.95211 acc 0.65789 roc_auc 0.48615 prc_auc 0.70467[0m
[92maverage training of epoch 48: loss -16.15822 acc 0.66667 roc_auc 0.37760 prc_auc 0.57116[0m
[93maverage test of epoch 48: loss -16.24950 acc 0.65789 roc_auc 0.60923 prc_auc 0.75809[0m
[92maverage training of epoch 49: loss -16.45670 acc 0.66667 roc_auc 0.37850 prc_auc 0.58178[0m
[93maverage test of epoch 49: loss -16.54740 acc 0.65789 roc_auc 0.47846 prc_auc 0.64497[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss 0.10695 acc 0.33775 roc_auc 0.46353 prc_auc 0.67971[0m
[93maverage test of epoch 0: loss -0.49449 acc 0.32432 roc_auc 0.63667 prc_auc 0.84419[0m
[92maverage training of epoch 1: loss -0.86389 acc 0.60265 roc_auc 0.64000 prc_auc 0.81509[0m
[93maverage test of epoch 1: loss -1.23379 acc 0.81081 roc_auc 0.92667 prc_auc 0.96475[0m
[92maverage training of epoch 2: loss -1.60295 acc 0.77483 roc_auc 0.83333 prc_auc 0.88727[0m
[93maverage test of epoch 2: loss -2.02047 acc 0.67568 roc_auc 0.85000 prc_auc 0.91549[0m
[92maverage training of epoch 3: loss -2.41717 acc 0.70861 roc_auc 0.82804 prc_auc 0.88470[0m
[93maverage test of epoch 3: loss -2.79832 acc 0.67568 roc_auc 0.86000 prc_auc 0.92527[0m
[92maverage training of epoch 4: loss -3.11242 acc 0.77483 roc_auc 0.85510 prc_auc 0.89387[0m
[93maverage test of epoch 4: loss -3.25109 acc 0.72973 roc_auc 0.87000 prc_auc 0.92331[0m
[92maverage training of epoch 5: loss -3.57334 acc 0.81457 roc_auc 0.84059 prc_auc 0.88681[0m
[93maverage test of epoch 5: loss -3.65381 acc 0.78378 roc_auc 0.84667 prc_auc 0.92249[0m
[92maverage training of epoch 6: loss -4.02668 acc 0.82119 roc_auc 0.85490 prc_auc 0.89900[0m
[93maverage test of epoch 6: loss -3.95783 acc 0.75676 roc_auc 0.83000 prc_auc 0.89312[0m
[92maverage training of epoch 7: loss -4.40526 acc 0.84106 roc_auc 0.85412 prc_auc 0.89994[0m
[93maverage test of epoch 7: loss -4.35868 acc 0.78378 roc_auc 0.84000 prc_auc 0.87339[0m
[92maverage training of epoch 8: loss -4.72562 acc 0.84106 roc_auc 0.84627 prc_auc 0.86484[0m
[93maverage test of epoch 8: loss -4.58553 acc 0.75676 roc_auc 0.71333 prc_auc 0.80317[0m
[92maverage training of epoch 9: loss -5.03502 acc 0.84106 roc_auc 0.81941 prc_auc 0.87160[0m
[93maverage test of epoch 9: loss -5.00149 acc 0.78378 roc_auc 0.79667 prc_auc 0.88628[0m
[92maverage training of epoch 10: loss -5.34658 acc 0.84106 roc_auc 0.82304 prc_auc 0.85860[0m
[93maverage test of epoch 10: loss -5.23665 acc 0.78378 roc_auc 0.80333 prc_auc 0.90719[0m
[92maverage training of epoch 11: loss -5.68647 acc 0.85430 roc_auc 0.83510 prc_auc 0.85272[0m
[93maverage test of epoch 11: loss -5.54744 acc 0.78378 roc_auc 0.77667 prc_auc 0.86790[0m
[92maverage training of epoch 12: loss -5.96100 acc 0.84768 roc_auc 0.81990 prc_auc 0.83596[0m
[93maverage test of epoch 12: loss -5.91305 acc 0.81081 roc_auc 0.82333 prc_auc 0.89126[0m
[92maverage training of epoch 13: loss -6.28230 acc 0.86093 roc_auc 0.83598 prc_auc 0.87008[0m
[93maverage test of epoch 13: loss -6.01155 acc 0.78378 roc_auc 0.72000 prc_auc 0.81609[0m
[92maverage training of epoch 14: loss -6.47524 acc 0.84106 roc_auc 0.81490 prc_auc 0.83928[0m
[93maverage test of epoch 14: loss -6.42097 acc 0.78378 roc_auc 0.78000 prc_auc 0.87011[0m
[92maverage training of epoch 15: loss -6.81545 acc 0.85430 roc_auc 0.83500 prc_auc 0.86907[0m
[93maverage test of epoch 15: loss -6.69010 acc 0.81081 roc_auc 0.65500 prc_auc 0.74751[0m
[92maverage training of epoch 16: loss -6.97745 acc 0.84106 roc_auc 0.81971 prc_auc 0.85247[0m
[93maverage test of epoch 16: loss -6.99409 acc 0.81081 roc_auc 0.70167 prc_auc 0.81846[0m
[92maverage training of epoch 17: loss -7.33121 acc 0.85430 roc_auc 0.83794 prc_auc 0.88047[0m
[93maverage test of epoch 17: loss -7.27945 acc 0.81081 roc_auc 0.83833 prc_auc 0.90959[0m
[92maverage training of epoch 18: loss -7.37214 acc 0.82781 roc_auc 0.82422 prc_auc 0.87198[0m
[93maverage test of epoch 18: loss -7.44801 acc 0.81081 roc_auc 0.85333 prc_auc 0.93743[0m
[92maverage training of epoch 19: loss -7.54884 acc 0.82119 roc_auc 0.82392 prc_auc 0.85848[0m
[93maverage test of epoch 19: loss -7.74947 acc 0.81081 roc_auc 0.77667 prc_auc 0.84579[0m
[92maverage training of epoch 20: loss -8.11160 acc 0.85430 roc_auc 0.80373 prc_auc 0.82878[0m
[93maverage test of epoch 20: loss -7.90583 acc 0.78378 roc_auc 0.73667 prc_auc 0.80846[0m
[92maverage training of epoch 21: loss -8.20625 acc 0.82781 roc_auc 0.77373 prc_auc 0.81108[0m
[93maverage test of epoch 21: loss -8.01061 acc 0.78378 roc_auc 0.69500 prc_auc 0.76298[0m
[92maverage training of epoch 22: loss -8.50595 acc 0.84768 roc_auc 0.81029 prc_auc 0.86999[0m
[93maverage test of epoch 22: loss -8.51682 acc 0.81081 roc_auc 0.74833 prc_auc 0.81841[0m
[92maverage training of epoch 23: loss -8.57367 acc 0.83444 roc_auc 0.81539 prc_auc 0.88031[0m
[93maverage test of epoch 23: loss -8.51434 acc 0.81081 roc_auc 0.82000 prc_auc 0.88283[0m
[92maverage training of epoch 24: loss -8.91872 acc 0.84768 roc_auc 0.82716 prc_auc 0.87699[0m
[93maverage test of epoch 24: loss -8.74847 acc 0.81081 roc_auc 0.84167 prc_auc 0.90187[0m
[92maverage training of epoch 25: loss -9.60963 acc 0.88079 roc_auc 0.82775 prc_auc 0.84633[0m
[93maverage test of epoch 25: loss -8.95557 acc 0.78378 roc_auc 0.82000 prc_auc 0.88240[0m
[92maverage training of epoch 26: loss -9.74581 acc 0.86093 roc_auc 0.81725 prc_auc 0.85227[0m
[93maverage test of epoch 26: loss -9.19164 acc 0.78378 roc_auc 0.67333 prc_auc 0.76535[0m
[92maverage training of epoch 27: loss -9.83900 acc 0.84768 roc_auc 0.79255 prc_auc 0.85005[0m
[93maverage test of epoch 27: loss -9.69805 acc 0.81081 roc_auc 0.76000 prc_auc 0.83593[0m
[92maverage training of epoch 28: loss -10.25052 acc 0.86755 roc_auc 0.83853 prc_auc 0.86218[0m
[93maverage test of epoch 28: loss -9.69160 acc 0.78378 roc_auc 0.79333 prc_auc 0.85120[0m
[92maverage training of epoch 29: loss -10.42677 acc 0.85430 roc_auc 0.81490 prc_auc 0.84579[0m
[93maverage test of epoch 29: loss -10.21434 acc 0.81081 roc_auc 0.87500 prc_auc 0.91868[0m
[92maverage training of epoch 30: loss -10.79119 acc 0.86755 roc_auc 0.82392 prc_auc 0.84938[0m
[93maverage test of epoch 30: loss -10.36282 acc 0.81081 roc_auc 0.74667 prc_auc 0.81044[0m
[92maverage training of epoch 31: loss -10.88135 acc 0.85430 roc_auc 0.81176 prc_auc 0.84495[0m
[93maverage test of epoch 31: loss -10.40003 acc 0.78378 roc_auc 0.72167 prc_auc 0.79635[0m
[92maverage training of epoch 32: loss -11.10856 acc 0.86093 roc_auc 0.85373 prc_auc 0.87300[0m
[93maverage test of epoch 32: loss -10.65228 acc 0.78378 roc_auc 0.81000 prc_auc 0.86112[0m
[92maverage training of epoch 33: loss -11.60454 acc 0.88079 roc_auc 0.84755 prc_auc 0.88134[0m
[93maverage test of epoch 33: loss -10.91850 acc 0.78378 roc_auc 0.81000 prc_auc 0.86525[0m
[92maverage training of epoch 34: loss -11.69387 acc 0.86755 roc_auc 0.84451 prc_auc 0.87281[0m
[93maverage test of epoch 34: loss -11.38994 acc 0.81081 roc_auc 0.75000 prc_auc 0.81587[0m
[92maverage training of epoch 35: loss -11.92273 acc 0.86093 roc_auc 0.83922 prc_auc 0.87797[0m
[93maverage test of epoch 35: loss -11.35683 acc 0.78378 roc_auc 0.79000 prc_auc 0.83999[0m
[92maverage training of epoch 36: loss -12.33376 acc 0.88079 roc_auc 0.86186 prc_auc 0.88335[0m
[93maverage test of epoch 36: loss -11.57788 acc 0.78378 roc_auc 0.79000 prc_auc 0.83978[0m
[92maverage training of epoch 37: loss -12.57734 acc 0.88079 roc_auc 0.83510 prc_auc 0.87454[0m
[93maverage test of epoch 37: loss -11.81315 acc 0.78378 roc_auc 0.82000 prc_auc 0.86739[0m
[92maverage training of epoch 38: loss -12.68179 acc 0.86755 roc_auc 0.83784 prc_auc 0.87676[0m
[93maverage test of epoch 38: loss -12.24031 acc 0.81081 roc_auc 0.79333 prc_auc 0.85996[0m
[92maverage training of epoch 39: loss -12.72234 acc 0.84768 roc_auc 0.85676 prc_auc 0.89203[0m
[93maverage test of epoch 39: loss -12.50670 acc 0.81081 roc_auc 0.78333 prc_auc 0.83778[0m
[92maverage training of epoch 40: loss -13.23891 acc 0.87417 roc_auc 0.85363 prc_auc 0.89193[0m
[93maverage test of epoch 40: loss -12.58872 acc 0.78378 roc_auc 0.77000 prc_auc 0.83378[0m
[92maverage training of epoch 41: loss -13.30931 acc 0.86755 roc_auc 0.84500 prc_auc 0.88844[0m
[93maverage test of epoch 41: loss -12.78723 acc 0.78378 roc_auc 0.79667 prc_auc 0.84173[0m
[92maverage training of epoch 42: loss -13.77410 acc 0.87417 roc_auc 0.85049 prc_auc 0.88438[0m
[93maverage test of epoch 42: loss -12.97236 acc 0.78378 roc_auc 0.75667 prc_auc 0.83080[0m
[92maverage training of epoch 43: loss -13.92945 acc 0.86093 roc_auc 0.83059 prc_auc 0.86150[0m
[93maverage test of epoch 43: loss -13.20641 acc 0.78378 roc_auc 0.72333 prc_auc 0.80345[0m
[92maverage training of epoch 44: loss -14.34248 acc 0.88079 roc_auc 0.86431 prc_auc 0.89614[0m
[93maverage test of epoch 44: loss -13.44784 acc 0.78378 roc_auc 0.76667 prc_auc 0.81633[0m
[92maverage training of epoch 45: loss -14.43965 acc 0.86755 roc_auc 0.85882 prc_auc 0.88964[0m
[93maverage test of epoch 45: loss -13.83448 acc 0.78378 roc_auc 0.76667 prc_auc 0.83315[0m
[92maverage training of epoch 46: loss -14.73512 acc 0.87417 roc_auc 0.85461 prc_auc 0.88847[0m
[93maverage test of epoch 46: loss -14.08206 acc 0.78378 roc_auc 0.83333 prc_auc 0.88978[0m
[92maverage training of epoch 47: loss -14.79341 acc 0.85430 roc_auc 0.84490 prc_auc 0.87969[0m
[93maverage test of epoch 47: loss -14.19452 acc 0.78378 roc_auc 0.77000 prc_auc 0.83370[0m
[92maverage training of epoch 48: loss -15.23443 acc 0.87417 roc_auc 0.84941 prc_auc 0.89084[0m
[93maverage test of epoch 48: loss -14.44939 acc 0.78378 roc_auc 0.82667 prc_auc 0.86977[0m
[92maverage training of epoch 49: loss -15.42897 acc 0.86093 roc_auc 0.83137 prc_auc 0.86640[0m
[93maverage test of epoch 49: loss -14.62200 acc 0.78378 roc_auc 0.74667 prc_auc 0.81020[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.59528 acc 0.47020 roc_auc 0.42765 prc_auc 0.61378[0m
[93maverage test of epoch 0: loss -1.08944 acc 0.67568 roc_auc 0.57000 prc_auc 0.71630[0m
[92maverage training of epoch 1: loss -1.46229 acc 0.66225 roc_auc 0.41922 prc_auc 0.61340[0m
[93maverage test of epoch 1: loss -1.86199 acc 0.67568 roc_auc 0.53667 prc_auc 0.75276[0m
[92maverage training of epoch 2: loss -2.46469 acc 0.66225 roc_auc 0.42863 prc_auc 0.61858[0m
[93maverage test of epoch 2: loss -3.22762 acc 0.67568 roc_auc 0.40333 prc_auc 0.61785[0m
[92maverage training of epoch 3: loss -3.90468 acc 0.66225 roc_auc 0.42627 prc_auc 0.63614[0m
[93maverage test of epoch 3: loss -4.43193 acc 0.67568 roc_auc 0.40000 prc_auc 0.62946[0m
[92maverage training of epoch 4: loss -4.76770 acc 0.66225 roc_auc 0.41980 prc_auc 0.59675[0m
[93maverage test of epoch 4: loss -5.06801 acc 0.67568 roc_auc 0.56333 prc_auc 0.79031[0m
[92maverage training of epoch 5: loss -5.27415 acc 0.66225 roc_auc 0.37176 prc_auc 0.58731[0m
[93maverage test of epoch 5: loss -5.52913 acc 0.67568 roc_auc 0.54667 prc_auc 0.68741[0m
[92maverage training of epoch 6: loss -5.71410 acc 0.66225 roc_auc 0.38490 prc_auc 0.57418[0m
[93maverage test of epoch 6: loss -5.93295 acc 0.67568 roc_auc 0.57667 prc_auc 0.72744[0mUsing backend: pytorch

[92maverage training of epoch 7: loss -6.10611 acc 0.66225 roc_auc 0.39627 prc_auc 0.59050[0m
[93maverage test of epoch 7: loss -6.31772 acc 0.67568 roc_auc 0.24667 prc_auc 0.53931[0m
[92maverage training of epoch 8: loss -6.47650 acc 0.66225 roc_auc 0.38961 prc_auc 0.58307[0m
[93maverage test of epoch 8: loss -6.67433 acc 0.67568 roc_auc 0.34000 prc_auc 0.58231[0m
[92maverage training of epoch 9: loss -6.82569 acc 0.66225 roc_auc 0.41608 prc_auc 0.59976[0m
[93maverage test of epoch 9: loss -7.02688 acc 0.67568 roc_auc 0.61667 prc_auc 0.78133[0m
[92maverage training of epoch 10: loss -7.16048 acc 0.66225 roc_auc 0.36843 prc_auc 0.56668[0m
[93maverage test of epoch 10: loss -7.35763 acc 0.67568 roc_auc 0.52000 prc_auc 0.67594[0m
[92maverage training of epoch 11: loss -7.49204 acc 0.66225 roc_auc 0.38333 prc_auc 0.58222[0m
[93maverage test of epoch 11: loss -7.69629 acc 0.67568 roc_auc 0.64667 prc_auc 0.82592[0m
[92maverage training of epoch 12: loss -7.81742 acc 0.66225 roc_auc 0.38275 prc_auc 0.58838[0m
[93maverage test of epoch 12: loss -8.01122 acc 0.67568 roc_auc 0.56667 prc_auc 0.76867[0m
[92maverage training of epoch 13: loss -8.13960 acc 0.66225 roc_auc 0.38137 prc_auc 0.57600[0m
[93maverage test of epoch 13: loss -8.33477 acc 0.67568 roc_auc 0.64667 prc_auc 0.77986[0m
[92maverage training of epoch 14: loss -8.45776 acc 0.66225 roc_auc 0.36745 prc_auc 0.56586[0m
[93maverage test of epoch 14: loss -8.64994 acc 0.67568 roc_auc 0.46000 prc_auc 0.72445[0m
[92maverage training of epoch 15: loss -8.77197 acc 0.66225 roc_auc 0.38549 prc_auc 0.58333[0m
[93maverage test of epoch 15: loss -8.96618 acc 0.67568 roc_auc 0.57333 prc_auc 0.76193[0m
[92maverage training of epoch 16: loss -9.08382 acc 0.66225 roc_auc 0.37902 prc_auc 0.57577[0m
[93maverage test of epoch 16: loss -9.27939 acc 0.67568 roc_auc 0.43667 prc_auc 0.70042[0m
[92maverage training of epoch 17: loss -9.39651 acc 0.66225 roc_auc 0.38255 prc_auc 0.57786[0m
[93maverage test of epoch 17: loss -9.58937 acc 0.67568 roc_auc 0.48000 prc_auc 0.68835[0m
[92maverage training of epoch 18: loss -9.70451 acc 0.66225 roc_auc 0.36157 prc_auc 0.57418[0m
[93maverage test of epoch 18: loss -9.89882 acc 0.67568 roc_auc 0.45167 prc_auc 0.65354[0m
[92maverage training of epoch 19: loss -10.01236 acc 0.66225 roc_auc 0.35647 prc_auc 0.56289[0m
[93maverage test of epoch 19: loss -10.20469 acc 0.67568 roc_auc 0.71833 prc_auc 0.82488[0m
[92maverage training of epoch 20: loss -10.32048 acc 0.66225 roc_auc 0.36490 prc_auc 0.56820[0m
[93maverage test of epoch 20: loss -10.51526 acc 0.67568 roc_auc 0.50333 prc_auc 0.66420[0m
[92maverage training of epoch 21: loss -10.62545 acc 0.66225 roc_auc 0.36706 prc_auc 0.56421[0m
[93maverage test of epoch 21: loss -10.82161 acc 0.67568 roc_auc 0.30333 prc_auc 0.59255[0m
[92maverage training of epoch 22: loss -10.92917 acc 0.66225 roc_auc 0.36784 prc_auc 0.57615[0m
[93maverage test of epoch 22: loss -11.12544 acc 0.67568 roc_auc 0.57333 prc_auc 0.69681[0m
[92maverage training of epoch 23: loss -11.23397 acc 0.66225 roc_auc 0.36725 prc_auc 0.58538[0m
[93maverage test of epoch 23: loss -11.43243 acc 0.67568 roc_auc 0.33167 prc_auc 0.65765[0m
[92maverage training of epoch 24: loss -11.53736 acc 0.66225 roc_auc 0.36353 prc_auc 0.56121[0m
[93maverage test of epoch 24: loss -11.73716 acc 0.67568 roc_auc 0.36833 prc_auc 0.63358[0m
[92maverage training of epoch 25: loss -11.84103 acc 0.66225 roc_auc 0.37333 prc_auc 0.57127[0m
[93maverage test of epoch 25: loss -12.04207 acc 0.67568 roc_auc 0.53833 prc_auc 0.67369[0m
[92maverage training of epoch 26: loss -12.14390 acc 0.66225 roc_auc 0.36902 prc_auc 0.56951[0m
[93maverage test of epoch 26: loss -12.34610 acc 0.67568 roc_auc 0.49000 prc_auc 0.66267[0m
[92maverage training of epoch 27: loss -12.44578 acc 0.66225 roc_auc 0.37157 prc_auc 0.58336[0m
[93maverage test of epoch 27: loss -12.65063 acc 0.67568 roc_auc 0.37500 prc_auc 0.62030[0m
[92maverage training of epoch 28: loss -12.74838 acc 0.66225 roc_auc 0.36873 prc_auc 0.57539[0m
[93maverage test of epoch 28: loss -12.95463 acc 0.67568 roc_auc 0.54000 prc_auc 0.72581[0m
[92maverage training of epoch 29: loss -13.04965 acc 0.66225 roc_auc 0.37137 prc_auc 0.57125[0m
[93maverage test of epoch 29: loss -13.25586 acc 0.67568 roc_auc 0.35167 prc_auc 0.63807[0m
[92maverage training of epoch 30: loss -13.35176 acc 0.66225 roc_auc 0.37333 prc_auc 0.57409[0m
[93maverage test of epoch 30: loss -13.55851 acc 0.67568 roc_auc 0.62500 prc_auc 0.76239[0m
[92maverage training of epoch 31: loss -13.65264 acc 0.66225 roc_auc 0.37412 prc_auc 0.57062[0m
[93maverage test of epoch 31: loss -13.86068 acc 0.67568 roc_auc 0.40833 prc_auc 0.65414[0m
[92maverage training of epoch 32: loss -13.95483 acc 0.66225 roc_auc 0.36706 prc_auc 0.56787[0m
[93maverage test of epoch 32: loss -14.16405 acc 0.67568 roc_auc 0.51500 prc_auc 0.70234[0m
[92maverage training of epoch 33: loss -14.25460 acc 0.66225 roc_auc 0.36618 prc_auc 0.57415[0m
[93maverage test of epoch 33: loss -14.46413 acc 0.67568 roc_auc 0.49333 prc_auc 0.73151[0m
[92maverage training of epoch 34: loss -14.55630 acc 0.66225 roc_auc 0.36716 prc_auc 0.56548[0m
[93maverage test of epoch 34: loss -14.76801 acc 0.67568 roc_auc 0.59333 prc_auc 0.75106[0m
[92maverage training of epoch 35: loss -14.85670 acc 0.66225 roc_auc 0.36510 prc_auc 0.56782[0m
[93maverage test of epoch 35: loss -15.06858 acc 0.67568 roc_auc 0.53333 prc_auc 0.75968[0m
[92maverage training of epoch 36: loss -15.15656 acc 0.66225 roc_auc 0.37441 prc_auc 0.57413[0m
[93maverage test of epoch 36: loss -15.37142 acc 0.67568 roc_auc 0.58500 prc_auc 0.74768[0m
[92maverage training of epoch 37: loss -15.45774 acc 0.66225 roc_auc 0.36814 prc_auc 0.56716[0m
[93maverage test of epoch 37: loss -15.67319 acc 0.67568 roc_auc 0.53500 prc_auc 0.67853[0m
[92maverage training of epoch 38: loss -15.75780 acc 0.66225 roc_auc 0.36667 prc_auc 0.56692[0m
[93maverage test of epoch 38: loss -15.97405 acc 0.67568 roc_auc 0.34000 prc_auc 0.62708[0m
[92maverage training of epoch 39: loss -16.05805 acc 0.66225 roc_auc 0.36588 prc_auc 0.56619[0m
[93maverage test of epoch 39: loss -16.27593 acc 0.67568 roc_auc 0.37000 prc_auc 0.62827[0m
[92maverage training of epoch 40: loss -16.35860 acc 0.66225 roc_auc 0.37245 prc_auc 0.57085[0m
[93maverage test of epoch 40: loss -16.57795 acc 0.67568 roc_auc 0.56333 prc_auc 0.72869[0m
[92maverage training of epoch 41: loss -16.65896 acc 0.66225 roc_auc 0.37127 prc_auc 0.57040[0m
[93maverage test of epoch 41: loss -16.87842 acc 0.67568 roc_auc 0.47333 prc_auc 0.68936[0m
[92maverage training of epoch 42: loss -16.95890 acc 0.66225 roc_auc 0.37069 prc_auc 0.57154[0m
[93maverage test of epoch 42: loss -17.18003 acc 0.67568 roc_auc 0.62167 prc_auc 0.77198[0m
[92maverage training of epoch 43: loss -17.25887 acc 0.66225 roc_auc 0.37216 prc_auc 0.57061[0m
[93maverage test of epoch 43: loss -17.48106 acc 0.67568 roc_auc 0.52500 prc_auc 0.68239[0m
[92maverage training of epoch 44: loss -17.55855 acc 0.66225 roc_auc 0.36725 prc_auc 0.57486[0m
[93maverage test of epoch 44: loss -17.78260 acc 0.67568 roc_auc 0.53333 prc_auc 0.69230[0m
[92maverage training of epoch 45: loss -17.85815 acc 0.66225 roc_auc 0.36598 prc_auc 0.56620[0m
[93maverage test of epoch 45: loss -18.08402 acc 0.67568 roc_auc 0.59167 prc_auc 0.72292[0m
[92maverage training of epoch 46: loss -18.15888 acc 0.66225 roc_auc 0.36755 prc_auc 0.56961[0m
[93maverage test of epoch 46: loss -18.38565 acc 0.67568 roc_auc 0.61500 prc_auc 0.76643[0m
[92maverage training of epoch 47: loss -18.45859 acc 0.66225 roc_auc 0.37078 prc_auc 0.57132[0m
[93maverage test of epoch 47: loss -18.68674 acc 0.67568 roc_auc 0.54000 prc_auc 0.70761[0m
[92maverage training of epoch 48: loss -18.75865 acc 0.66225 roc_auc 0.36990 prc_auc 0.57176[0m
[93maverage test of epoch 48: loss -18.98747 acc 0.67568 roc_auc 0.60333 prc_auc 0.71221[0m
[92maverage training of epoch 49: loss -19.05844 acc 0.66225 roc_auc 0.36971 prc_auc 0.57019[0m
[93maverage test of epoch 49: loss -19.28903 acc 0.67568 roc_auc 0.36333 prc_auc 0.63620[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.0003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.71821 ROC_AUC (avg): 0.58077 PRC_AUC (avg): 0.72527 

Average forward propagation time taken(ms): 3.9606746526979415
Average backward propagation time taken(ms): 1.511278658610076

