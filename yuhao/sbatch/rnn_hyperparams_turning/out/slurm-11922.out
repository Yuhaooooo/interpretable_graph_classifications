# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-22-45-47/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-22-45-47/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 16,
 'epochs': 50,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 8,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.001,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 2,
 'num_workers': 8,
 'number_of_mlp_layer': 0,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-17-22-45-47',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 50, 'learning_rate': 0.001, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -1.56179 acc 0.66000 roc_auc 0.44680 prc_auc 0.65326[0m
[93maverage test of epoch 0: loss -2.39189 acc 0.65789 roc_auc 0.76308 prc_auc 0.89205[0m
[92maverage training of epoch 1: loss -3.02458 acc 0.66667 roc_auc 0.57640 prc_auc 0.74401[0m
[93maverage test of epoch 1: loss -3.61227 acc 0.65789 roc_auc 0.72308 prc_auc 0.86957[0m
[92maverage training of epoch 2: loss -4.21405 acc 0.66000 roc_auc 0.61260 prc_auc 0.76599[0m
[93maverage test of epoch 2: loss -4.89718 acc 0.65789 roc_auc 0.88308 prc_auc 0.94542[0m
[92maverage training of epoch 3: loss -5.56618 acc 0.75333 roc_auc 0.84020 prc_auc 0.89641[0m
[93maverage test of epoch 3: loss -6.16743 acc 0.81579 roc_auc 0.88615 prc_auc 0.94406[0m
[92maverage training of epoch 4: loss -6.78173 acc 0.78000 roc_auc 0.82060 prc_auc 0.85344[0m
[93maverage test of epoch 4: loss -7.30265 acc 0.78947 roc_auc 0.85538 prc_auc 0.92009[0m
[92maverage training of epoch 5: loss -7.93377 acc 0.81333 roc_auc 0.81620 prc_auc 0.84045[0m
[93maverage test of epoch 5: loss -8.34394 acc 0.78947 roc_auc 0.82769 prc_auc 0.90598[0m
[92maverage training of epoch 6: loss -8.99553 acc 0.82000 roc_auc 0.81180 prc_auc 0.83089[0m
[93maverage test of epoch 6: loss -9.38184 acc 0.76316 roc_auc 0.87077 prc_auc 0.93015[0m
[92maverage training of epoch 7: loss -10.03897 acc 0.81333 roc_auc 0.80560 prc_auc 0.82314[0m
[93maverage test of epoch 7: loss -10.42206 acc 0.71053 roc_auc 0.86154 prc_auc 0.91294[0m
[92maverage training of epoch 8: loss -11.10038 acc 0.81333 roc_auc 0.83640 prc_auc 0.84318[0m
[93maverage test of epoch 8: loss -11.39461 acc 0.68421 roc_auc 0.84308 prc_auc 0.91953[0m
[92maverage training of epoch 9: loss -12.09916 acc 0.68000 roc_auc 0.81260 prc_auc 0.82180[0m
[93maverage test of epoch 9: loss -12.39568 acc 0.68421 roc_auc 0.86462 prc_auc 0.92537[0m
[92maverage training of epoch 10: loss -13.08355 acc 0.66667 roc_auc 0.78660 prc_auc 0.81067[0m
[93maverage test of epoch 10: loss -13.36586 acc 0.65789 roc_auc 0.84000 prc_auc 0.87198[0m
[92maverage training of epoch 11: loss -14.08657 acc 0.66667 roc_auc 0.80740 prc_auc 0.81915[0m
[93maverage test of epoch 11: loss -14.36095 acc 0.65789 roc_auc 0.83692 prc_auc 0.85321[0m
[92maverage training of epoch 12: loss -15.05356 acc 0.66667 roc_auc 0.83310 prc_auc 0.82841[0m
[93maverage test of epoch 12: loss -15.28929 acc 0.65789 roc_auc 0.80615 prc_auc 0.84621[0m
[92maverage training of epoch 13: loss -16.02336 acc 0.66667 roc_auc 0.81000 prc_auc 0.82287[0m
[93maverage test of epoch 13: loss -16.28513 acc 0.65789 roc_auc 0.86154 prc_auc 0.92749[0m
[92maverage training of epoch 14: loss -17.02901 acc 0.66667 roc_auc 0.82620 prc_auc 0.82289[0m
[93maverage test of epoch 14: loss -17.17951 acc 0.65789 roc_auc 0.84615 prc_auc 0.91252[0m
[92maverage training of epoch 15: loss -17.94982 acc 0.66667 roc_auc 0.80720 prc_auc 0.81150[0m
[93maverage test of epoch 15: loss -18.10279 acc 0.65789 roc_auc 0.83692 prc_auc 0.89981[0m
[92maverage training of epoch 16: loss -18.91824 acc 0.66667 roc_auc 0.82400 prc_auc 0.82233[0m
[93maverage test of epoch 16: loss -19.12379 acc 0.65789 roc_auc 0.87231 prc_auc 0.93974[0m
[92maverage training of epoch 17: loss -19.87425 acc 0.66667 roc_auc 0.81840 prc_auc 0.82276[0m
[93maverage test of epoch 17: loss -20.01641 acc 0.65789 roc_auc 0.87846 prc_auc 0.94589[0m
[92maverage training of epoch 18: loss -20.88185 acc 0.66667 roc_auc 0.81140 prc_auc 0.81050[0m
[93maverage test of epoch 18: loss -20.92194 acc 0.65789 roc_auc 0.81692 prc_auc 0.86951[0m
[92maverage training of epoch 19: loss -21.80759 acc 0.66667 roc_auc 0.82350 prc_auc 0.83480[0m
[93maverage test of epoch 19: loss -21.93459 acc 0.65789 roc_auc 0.88154 prc_auc 0.94868[0m
[92maverage training of epoch 20: loss -22.78028 acc 0.66667 roc_auc 0.83800 prc_auc 0.82945[0m
[93maverage test of epoch 20: loss -22.84916 acc 0.65789 roc_auc 0.84923 prc_auc 0.90384[0m
[92maverage training of epoch 21: loss -23.69555 acc 0.66667 roc_auc 0.82520 prc_auc 0.82473[0m
[93maverage test of epoch 21: loss -23.79008 acc 0.65789 roc_auc 0.86769 prc_auc 0.92264[0m
[92maverage training of epoch 22: loss -24.65763 acc 0.66667 roc_auc 0.82640 prc_auc 0.82773[0m
[93maverage test of epoch 22: loss -24.77504 acc 0.65789 roc_auc 0.84154 prc_auc 0.88758[0m
[92maverage training of epoch 23: loss -25.59292 acc 0.66667 roc_auc 0.83550 prc_auc 0.83938[0m
[93maverage test of epoch 23: loss -25.66162 acc 0.65789 roc_auc 0.86154 prc_auc 0.89881[0m
[92maverage training of epoch 24: loss -26.56275 acc 0.66667 roc_auc 0.82390 prc_auc 0.82871[0m
[93maverage test of epoch 24: loss -26.55120 acc 0.65789 roc_auc 0.79538 prc_auc 0.85159[0m
[92maverage training of epoch 25: loss -27.52267 acc 0.66667 roc_auc 0.83110 prc_auc 0.83304[0m
[93maverage test of epoch 25: loss -27.56259 acc 0.65789 roc_auc 0.83385 prc_auc 0.88564[0m
[92maverage training of epoch 26: loss -28.54454 acc 0.66667 roc_auc 0.83190 prc_auc 0.83851[0m
[93maverage test of epoch 26: loss -28.44165 acc 0.65789 roc_auc 0.82462 prc_auc 0.87599[0m
[92maverage training of epoch 27: loss -29.33953 acc 0.66667 roc_auc 0.82950 prc_auc 0.83525[0m
[93maverage test of epoch 27: loss -29.38707 acc 0.65789 roc_auc 0.78769 prc_auc 0.84629[0m
[92maverage training of epoch 28: loss -30.39305 acc 0.66667 roc_auc 0.84240 prc_auc 0.84983[0m
[93maverage test of epoch 28: loss -30.41319 acc 0.65789 roc_auc 0.81231 prc_auc 0.85421[0m
[92maverage training of epoch 29: loss -31.37286 acc 0.66667 roc_auc 0.84030 prc_auc 0.84876[0m
[93maverage test of epoch 29: loss -31.50365 acc 0.65789 roc_auc 0.81692 prc_auc 0.85907[0m
[92maverage training of epoch 30: loss -32.37667 acc 0.66667 roc_auc 0.83000 prc_auc 0.84710[0m
[93maverage test of epoch 30: loss -32.40045 acc 0.65789 roc_auc 0.80769 prc_auc 0.85552[0m
[92maverage training of epoch 31: loss -33.29985 acc 0.66667 roc_auc 0.83190 prc_auc 0.85596[0m
[93maverage test of epoch 31: loss -33.12323 acc 0.65789 roc_auc 0.79846 prc_auc 0.85251[0m
[92maverage training of epoch 32: loss -34.27135 acc 0.66667 roc_auc 0.84690 prc_auc 0.87502[0m
[93maverage test of epoch 32: loss -34.17204 acc 0.65789 roc_auc 0.81692 prc_auc 0.85837[0m
[92maverage training of epoch 33: loss -35.22820 acc 0.66667 roc_auc 0.84570 prc_auc 0.87432[0m
[93maverage test of epoch 33: loss -35.15978 acc 0.65789 roc_auc 0.84769 prc_auc 0.88963[0m
[92maverage training of epoch 34: loss -36.05370 acc 0.66667 roc_auc 0.83000 prc_auc 0.86392[0m
[93maverage test of epoch 34: loss -36.34385 acc 0.65789 roc_auc 0.69538 prc_auc 0.75952[0m
[92maverage training of epoch 35: loss -37.00533 acc 0.66667 roc_auc 0.77840 prc_auc 0.82206[0m
[93maverage test of epoch 35: loss -37.29249 acc 0.65789 roc_auc 0.76615 prc_auc 0.81027[0m
[92maverage training of epoch 36: loss -37.87067 acc 0.66667 roc_auc 0.85760 prc_auc 0.88712[0m
[93maverage test of epoch 36: loss -38.02527 acc 0.65789 roc_auc 0.82308 prc_auc 0.86075[0m
[92maverage training of epoch 37: loss -38.99852 acc 0.66667 roc_auc 0.83240 prc_auc 0.86345[0m
[93maverage test of epoch 37: loss -39.40510 acc 0.65789 roc_auc 0.78615 prc_auc 0.81997[0m
[92maverage training of epoch 38: loss -39.90176 acc 0.66667 roc_auc 0.85890 prc_auc 0.88848[0m
[93maverage test of epoch 38: loss -40.17441 acc 0.65789 roc_auc 0.77077 prc_auc 0.80826[0m
[92maverage training of epoch 39: loss -40.88718 acc 0.66667 roc_auc 0.87890 prc_auc 0.90024[0m
[93maverage test of epoch 39: loss -40.97405 acc 0.65789 roc_auc 0.72923 prc_auc 0.77974[0m
[92maverage training of epoch 40: loss -41.85401 acc 0.66667 roc_auc 0.85490 prc_auc 0.88423[0m
[93maverage test of epoch 40: loss -41.66527 acc 0.65789 roc_auc 0.83231 prc_auc 0.86357[0m
[92maverage training of epoch 41: loss -42.82669 acc 0.66667 roc_auc 0.87740 prc_auc 0.90037[0m
[93maverage test of epoch 41: loss -42.59478 acc 0.65789 roc_auc 0.75692 prc_auc 0.80702[0m
[92maverage training of epoch 42: loss -43.80197 acc 0.66667 roc_auc 0.86840 prc_auc 0.89479[0m
[93maverage test of epoch 42: loss -43.61943 acc 0.65789 roc_auc 0.85077 prc_auc 0.87054[0m
[92maverage training of epoch 43: loss -44.76444 acc 0.66667 roc_auc 0.86140 prc_auc 0.88690[0m
[93maverage test of epoch 43: loss -44.69659 acc 0.65789 roc_auc 0.81538 prc_auc 0.84295[0m
[92maverage training of epoch 44: loss -45.62846 acc 0.66667 roc_auc 0.83480 prc_auc 0.86375[0m
[93maverage test of epoch 44: loss -45.95838 acc 0.65789 roc_auc 0.82462 prc_auc 0.84631[0m
[92maverage training of epoch 45: loss -46.74194 acc 0.66667 roc_auc 0.86340 prc_auc 0.88891[0m
[93maverage test of epoch 45: loss -46.66952 acc 0.65789 roc_auc 0.85231 prc_auc 0.87401[0m
[92maverage training of epoch 46: loss -47.66069 acc 0.66667 roc_auc 0.86670 prc_auc 0.88910[0m
[93maverage test of epoch 46: loss -47.80553 acc 0.65789 roc_auc 0.82462 prc_auc 0.84924[0m
[92maverage training of epoch 47: loss -48.72173 acc 0.66667 roc_auc 0.85880 prc_auc 0.88374[0m
[93maverage test of epoch 47: loss -48.67074 acc 0.65789 roc_auc 0.86462 prc_auc 0.87855[0m
[92maverage training of epoch 48: loss -49.63084 acc 0.66667 roc_auc 0.83630 prc_auc 0.86636[0m
[93maverage test of epoch 48: loss -49.28510 acc 0.65789 roc_auc 0.84769 prc_auc 0.86994[0m
[92maverage training of epoch 49: loss -50.54051 acc 0.66667 roc_auc 0.84590 prc_auc 0.87271[0m
[93maverage test of epoch 49: loss -50.14872 acc 0.65789 roc_auc 0.85385 prc_auc 0.87169[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -2.74471 acc 0.66667 roc_auc 0.45120 prc_auc 0.63348[0m
[93maverage test of epoch 0: loss -4.64568 acc 0.65789 roc_auc 0.28923 prc_auc 0.56933[0m
[92maverage training of epoch 1: loss -5.67833 acc 0.66667 roc_auc 0.44700 prc_auc 0.61607[0m
[93maverage test of epoch 1: loss -6.44910 acc 0.65789 roc_auc 0.49846 prc_auc 0.63974[0m
[92maverage training of epoch 2: loss -7.09040 acc 0.66667 roc_auc 0.39600 prc_auc 0.58515[0m
[93maverage test of epoch 2: loss -7.65852 acc 0.65789 roc_auc 0.53846 prc_auc 0.68041[0m
[92maverage training of epoch 3: loss -8.23764 acc 0.66667 roc_auc 0.43940 prc_auc 0.61730[0m
[93maverage test of epoch 3: loss -8.75994 acc 0.65789 roc_auc 0.43538 prc_auc 0.64584[0m
[92maverage training of epoch 4: loss -9.32734 acc 0.66667 roc_auc 0.42440 prc_auc 0.60008[0m
[93maverage test of epoch 4: loss -9.83168 acc 0.65789 roc_auc 0.59385 prc_auc 0.78878[0m
[92maverage training of epoch 5: loss -10.38311 acc 0.66667 roc_auc 0.41760 prc_auc 0.60787[0m
[93maverage test of epoch 5: loss -10.87733 acc 0.65789 roc_auc 0.39077 prc_auc 0.57848[0m
[92maverage training of epoch 6: loss -11.42533 acc 0.66667 roc_auc 0.43060 prc_auc 0.61781[0m
[93maverage test of epoch 6: loss -11.90909 acc 0.65789 roc_auc 0.61846 prc_auc 0.71673[0m
[92maverage training of epoch 7: loss -12.45669 acc 0.66667 roc_auc 0.42270 prc_auc 0.60206[0m
[93maverage test of epoch 7: loss -12.93112 acc 0.65789 roc_auc 0.38462 prc_auc 0.62572[0m
[92maverage training of epoch 8: loss -13.47978 acc 0.66667 roc_auc 0.43500 prc_auc 0.61686[0m
[93maverage test of epoch 8: loss -13.94824 acc 0.65789 roc_auc 0.54769 prc_auc 0.70378[0m
[92maverage training of epoch 9: loss -14.49657 acc 0.66667 roc_auc 0.41690 prc_auc 0.59515[0m
[93maverage test of epoch 9: loss -14.96224 acc 0.65789 roc_auc 0.61077 prc_auc 0.77786[0m
[92maverage training of epoch 10: loss -15.51189 acc 0.66667 roc_auc 0.42280 prc_auc 0.60352[0m
[93maverage test of epoch 10: loss -15.97230 acc 0.65789 roc_auc 0.73692 prc_auc 0.85350[0m
[92maverage training of epoch 11: loss -16.51979 acc 0.66667 roc_auc 0.42540 prc_auc 0.60943[0m
[93maverage test of epoch 11: loss -16.97677 acc 0.65789 roc_auc 0.57692 prc_auc 0.76252[0m
[92maverage training of epoch 12: loss -17.52960 acc 0.66667 roc_auc 0.41990 prc_auc 0.60657[0m
[93maverage test of epoch 12: loss -17.97814 acc 0.65789 roc_auc 0.48615 prc_auc 0.65178[0m
[92maverage training of epoch 13: loss -18.53452 acc 0.66667 roc_auc 0.41790 prc_auc 0.60023[0m
[93maverage test of epoch 13: loss -18.98171 acc 0.65789 roc_auc 0.43077 prc_auc 0.65676[0m
[92maverage training of epoch 14: loss -19.53812 acc 0.66667 roc_auc 0.42350 prc_auc 0.61351[0m
[93maverage test of epoch 14: loss -19.98022 acc 0.65789 roc_auc 0.37231 prc_auc 0.60178[0m
[92maverage training of epoch 15: loss -20.54095 acc 0.66667 roc_auc 0.42220 prc_auc 0.60517[0m
[93maverage test of epoch 15: loss -20.98091 acc 0.65789 roc_auc 0.38154 prc_auc 0.58890[0m
[92maverage training of epoch 16: loss -21.54169 acc 0.66667 roc_auc 0.41880 prc_auc 0.60022[0m
[93maverage test of epoch 16: loss -21.97651 acc 0.65789 roc_auc 0.40615 prc_auc 0.61504[0m
[92maverage training of epoch 17: loss -22.54212 acc 0.66667 roc_auc 0.41840 prc_auc 0.60169[0m
[93maverage test of epoch 17: loss -22.97475 acc 0.65789 roc_auc 0.40000 prc_auc 0.61555[0m
[92maverage training of epoch 18: loss -23.54151 acc 0.66667 roc_auc 0.41810 prc_auc 0.60205[0m
[93maverage test of epoch 18: loss -23.97213 acc 0.65789 roc_auc 0.70154 prc_auc 0.76788[0m
[92maverage training of epoch 19: loss -24.54027 acc 0.66667 roc_auc 0.42180 prc_auc 0.60491[0m
[93maverage test of epoch 19: loss -24.96618 acc 0.65789 roc_auc 0.60308 prc_auc 0.71553[0m
[92maverage training of epoch 20: loss -25.53789 acc 0.66667 roc_auc 0.42250 prc_auc 0.60378[0m
[93maverage test of epoch 20: loss -25.96224 acc 0.65789 roc_auc 0.53692 prc_auc 0.67946[0m
[92maverage training of epoch 21: loss -26.53560 acc 0.66667 roc_auc 0.41800 prc_auc 0.59648[0m
[93maverage test of epoch 21: loss -26.95446 acc 0.65789 roc_auc 0.37077 prc_auc 0.59870[0m
[92maverage training of epoch 22: loss -27.53217 acc 0.66667 roc_auc 0.41750 prc_auc 0.60156[0m
[93maverage test of epoch 22: loss -27.95051 acc 0.65789 roc_auc 0.49692 prc_auc 0.65651[0m
[92maverage training of epoch 23: loss -28.52872 acc 0.66667 roc_auc 0.42140 prc_auc 0.60274[0m
[93maverage test of epoch 23: loss -28.94287 acc 0.65789 roc_auc 0.50154 prc_auc 0.65911[0m
[92maverage training of epoch 24: loss -29.52557 acc 0.66667 roc_auc 0.42020 prc_auc 0.60072[0m
[93maverage test of epoch 24: loss -29.93800 acc 0.65789 roc_auc 0.49846 prc_auc 0.65720[0m
[92maverage training of epoch 25: loss -30.52152 acc 0.66667 roc_auc 0.42030 prc_auc 0.60017[0m
[93maverage test of epoch 25: loss -30.93031 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -31.51767 acc 0.66667 roc_auc 0.42390 prc_auc 0.60795[0m
[93maverage test of epoch 26: loss -31.92243 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -32.51285 acc 0.66667 roc_auc 0.42550 prc_auc 0.60781[0m
[93maverage test of epoch 27: loss -32.91605 acc 0.65789 roc_auc 0.48000 prc_auc 0.64902[0m
[92maverage training of epoch 28: loss -33.50826 acc 0.66667 roc_auc 0.42460 prc_auc 0.60738[0m
[93maverage test of epoch 28: loss -33.90823 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -34.50359 acc 0.66667 roc_auc 0.42540 prc_auc 0.61312[0m
[93maverage test of epoch 29: loss -34.90097 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -35.49873 acc 0.66667 roc_auc 0.42660 prc_auc 0.61382[0m
[93maverage test of epoch 30: loss -35.89253 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -36.49368 acc 0.66667 roc_auc 0.44200 prc_auc 0.62841[0m
[93maverage test of epoch 31: loss -36.88399 acc 0.65789 roc_auc 0.53846 prc_auc 0.67568[0m
[92maverage training of epoch 32: loss -37.48831 acc 0.66667 roc_auc 0.43300 prc_auc 0.62372[0m
[93maverage test of epoch 32: loss -37.87714 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -38.48335 acc 0.66667 roc_auc 0.45410 prc_auc 0.63883[0m
[93maverage test of epoch 33: loss -38.86855 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -39.47812 acc 0.66667 roc_auc 0.45040 prc_auc 0.63908[0m
[93maverage test of epoch 34: loss -39.86108 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -40.47272 acc 0.66667 roc_auc 0.46490 prc_auc 0.64963[0m
[93maverage test of epoch 35: loss -40.85247 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -41.46760 acc 0.66667 roc_auc 0.45980 prc_auc 0.64690[0m
[93maverage test of epoch 36: loss -41.84379 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -42.46198 acc 0.66667 roc_auc 0.46000 prc_auc 0.64965[0m
[93maverage test of epoch 37: loss -42.83580 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -43.45657 acc 0.66667 roc_auc 0.47000 prc_auc 0.65378[0m
[93maverage test of epoch 38: loss -43.82767 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -44.45112 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -44.81902 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -45.44526 acc 0.66667 roc_auc 0.49000 prc_auc 0.66226[0m
[93maverage test of epoch 40: loss -45.81029 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -46.43975 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -46.80218 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -47.43397 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -47.79389 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -48.42840 acc 0.66667 roc_auc 0.47000 prc_auc 0.65376[0m
[93maverage test of epoch 43: loss -48.78512 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -49.42282 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -49.77628 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -50.41717 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -50.76812 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -51.41140 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -51.75918 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -52.40569 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -52.75103 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -53.39991 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -53.74246 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -54.39414 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -54.73391 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -0.55687 acc 0.54000 roc_auc 0.41740 prc_auc 0.64151[0m
[93maverage test of epoch 0: loss -1.33323 acc 0.65789 roc_auc 0.67077 prc_auc 0.79557[0m
[92maverage training of epoch 1: loss -2.22783 acc 0.66667 roc_auc 0.40240 prc_auc 0.59565[0m
[93maverage test of epoch 1: loss -2.95253 acc 0.65789 roc_auc 0.48923 prc_auc 0.65333[0m
[92maverage training of epoch 2: loss -3.52077 acc 0.66667 roc_auc 0.42140 prc_auc 0.61270[0m
[93maverage test of epoch 2: loss -4.04763 acc 0.65789 roc_auc 0.34154 prc_auc 0.60545[0m
[92maverage training of epoch 3: loss -4.58227 acc 0.66667 roc_auc 0.39740 prc_auc 0.62221[0m
[93maverage test of epoch 3: loss -5.11686 acc 0.65789 roc_auc 0.62000 prc_auc 0.71948[0m
[92maverage training of epoch 4: loss -5.76432 acc 0.66667 roc_auc 0.38420 prc_auc 0.59513[0m
[93maverage test of epoch 4: loss -6.42356 acc 0.65789 roc_auc 0.39077 prc_auc 0.58826[0m
[92maverage training of epoch 5: loss -7.04118 acc 0.66667 roc_auc 0.37650 prc_auc 0.57548[0m
[93maverage test of epoch 5: loss -7.59888 acc 0.65789 roc_auc 0.59077 prc_auc 0.72509[0m
[92maverage training of epoch 6: loss -8.17852 acc 0.66667 roc_auc 0.38620 prc_auc 0.58679[0m
[93maverage test of epoch 6: loss -8.69786 acc 0.65789 roc_auc 0.37846 prc_auc 0.59997[0m
[92maverage training of epoch 7: loss -9.27087 acc 0.66667 roc_auc 0.38420 prc_auc 0.57977[0m
[93maverage test of epoch 7: loss -9.77292 acc 0.65789 roc_auc 0.62769 prc_auc 0.76087[0m
[92maverage training of epoch 8: loss -10.33513 acc 0.66667 roc_auc 0.38340 prc_auc 0.57937[0m
[93maverage test of epoch 8: loss -10.82532 acc 0.65789 roc_auc 0.50769 prc_auc 0.68626[0m
[92maverage training of epoch 9: loss -11.38559 acc 0.66667 roc_auc 0.37820 prc_auc 0.57667[0m
[93maverage test of epoch 9: loss -11.86400 acc 0.65789 roc_auc 0.70769 prc_auc 0.82011[0m
[92maverage training of epoch 10: loss -12.42317 acc 0.66667 roc_auc 0.37660 prc_auc 0.57473[0m
[93maverage test of epoch 10: loss -12.89668 acc 0.65789 roc_auc 0.51692 prc_auc 0.70050[0m
[92maverage training of epoch 11: loss -13.45143 acc 0.66667 roc_auc 0.38350 prc_auc 0.58554[0m
[93maverage test of epoch 11: loss -13.91808 acc 0.65789 roc_auc 0.46000 prc_auc 0.66699[0m
[92maverage training of epoch 12: loss -14.47540 acc 0.66667 roc_auc 0.37110 prc_auc 0.56707[0m
[93maverage test of epoch 12: loss -14.93548 acc 0.65789 roc_auc 0.48923 prc_auc 0.67092[0m
[92maverage training of epoch 13: loss -15.49297 acc 0.66667 roc_auc 0.37580 prc_auc 0.57082[0m
[93maverage test of epoch 13: loss -15.95078 acc 0.65789 roc_auc 0.67231 prc_auc 0.76504[0m
[92maverage training of epoch 14: loss -16.50790 acc 0.66667 roc_auc 0.37420 prc_auc 0.57234[0m
[93maverage test of epoch 14: loss -16.96021 acc 0.65789 roc_auc 0.32308 prc_auc 0.57368[0m
[92maverage training of epoch 15: loss -17.51868 acc 0.66667 roc_auc 0.38130 prc_auc 0.58412[0m
[93maverage test of epoch 15: loss -17.96552 acc 0.65789 roc_auc 0.44462 prc_auc 0.64212[0m
[92maverage training of epoch 16: loss -18.52612 acc 0.66667 roc_auc 0.37450 prc_auc 0.57176[0m
[93maverage test of epoch 16: loss -18.97062 acc 0.65789 roc_auc 0.60923 prc_auc 0.71656[0m
[92maverage training of epoch 17: loss -19.53334 acc 0.66667 roc_auc 0.37610 prc_auc 0.57435[0m
[93maverage test of epoch 17: loss -19.97309 acc 0.65789 roc_auc 0.59846 prc_auc 0.72747[0m
[92maverage training of epoch 18: loss -20.53731 acc 0.66667 roc_auc 0.37630 prc_auc 0.57406[0m
[93maverage test of epoch 18: loss -20.97349 acc 0.65789 roc_auc 0.47692 prc_auc 0.65236[0m
[92maverage training of epoch 19: loss -21.53982 acc 0.66667 roc_auc 0.37830 prc_auc 0.57695[0m
[93maverage test of epoch 19: loss -21.97250 acc 0.65789 roc_auc 0.68308 prc_auc 0.77022[0m
[92maverage training of epoch 20: loss -22.54140 acc 0.66667 roc_auc 0.37870 prc_auc 0.58246[0m
[93maverage test of epoch 20: loss -22.97153 acc 0.65789 roc_auc 0.48154 prc_auc 0.64925[0m
[92maverage training of epoch 21: loss -23.54187 acc 0.66667 roc_auc 0.37780 prc_auc 0.58454[0m
[93maverage test of epoch 21: loss -23.96793 acc 0.65789 roc_auc 0.39846 prc_auc 0.61621[0m
[92maverage training of epoch 22: loss -24.54106 acc 0.66667 roc_auc 0.37840 prc_auc 0.57790[0m
[93maverage test of epoch 22: loss -24.96407 acc 0.65789 roc_auc 0.59231 prc_auc 0.70510[0m
[92maverage training of epoch 23: loss -25.54022 acc 0.66667 roc_auc 0.37780 prc_auc 0.57476[0m
[93maverage test of epoch 23: loss -25.96053 acc 0.65789 roc_auc 0.51846 prc_auc 0.66632[0m
[92maverage training of epoch 24: loss -26.53821 acc 0.66667 roc_auc 0.37810 prc_auc 0.57817[0m
[93maverage test of epoch 24: loss -26.95520 acc 0.65789 roc_auc 0.49077 prc_auc 0.65379[0m
[92maverage training of epoch 25: loss -27.53601 acc 0.66667 roc_auc 0.38280 prc_auc 0.58239[0m
[93maverage test of epoch 25: loss -27.94933 acc 0.65789 roc_auc 0.49846 prc_auc 0.65720[0m
[92maverage training of epoch 26: loss -28.53282 acc 0.66667 roc_auc 0.37820 prc_auc 0.57995[0m
[93maverage test of epoch 26: loss -28.94353 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -29.52958 acc 0.66667 roc_auc 0.38430 prc_auc 0.58884[0m
[93maverage test of epoch 27: loss -29.93704 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -30.52599 acc 0.66667 roc_auc 0.38700 prc_auc 0.59195[0m
[93maverage test of epoch 28: loss -30.93012 acc 0.65789 roc_auc 0.51846 prc_auc 0.66632[0m
[92maverage training of epoch 29: loss -31.52191 acc 0.66667 roc_auc 0.38810 prc_auc 0.59408[0m
[93maverage test of epoch 29: loss -31.92345 acc 0.65789 roc_auc 0.52308 prc_auc 0.66917[0m
[92maverage training of epoch 30: loss -32.51770 acc 0.66667 roc_auc 0.39010 prc_auc 0.59574[0m
[93maverage test of epoch 30: loss -32.91628 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -33.51336 acc 0.66667 roc_auc 0.38540 prc_auc 0.59721[0m
[93maverage test of epoch 31: loss -33.90907 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -34.50868 acc 0.66667 roc_auc 0.39560 prc_auc 0.60572[0m
[93maverage test of epoch 32: loss -34.90144 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -35.50374 acc 0.66667 roc_auc 0.39230 prc_auc 0.60602[0m
[93maverage test of epoch 33: loss -35.89361 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -36.49877 acc 0.66667 roc_auc 0.39690 prc_auc 0.61167[0m
[93maverage test of epoch 34: loss -36.88578 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -37.49369 acc 0.66667 roc_auc 0.43620 prc_auc 0.63371[0m
[93maverage test of epoch 35: loss -37.87776 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -38.48854 acc 0.66667 roc_auc 0.44140 prc_auc 0.63884[0m
[93maverage test of epoch 36: loss -38.86938 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -39.48329 acc 0.66667 roc_auc 0.43040 prc_auc 0.63377[0m
[93maverage test of epoch 37: loss -39.86153 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -40.47782 acc 0.66667 roc_auc 0.45000 prc_auc 0.64554[0m
[93maverage test of epoch 38: loss -40.85330 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -41.47238 acc 0.66667 roc_auc 0.43500 prc_auc 0.63969[0m
[93maverage test of epoch 39: loss -41.84505 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -42.46682 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -42.83610 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -43.46116 acc 0.66667 roc_auc 0.48000 prc_auc 0.65792[0m
[93maverage test of epoch 41: loss -43.82824 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -44.45577 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -44.81955 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -45.45001 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -45.81080 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -46.44441 acc 0.66667 roc_auc 0.44500 prc_auc 0.64357[0m
[93maverage test of epoch 44: loss -46.80244 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -47.43861 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -47.79396 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -48.43276 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -48.78533 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -49.42697 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -49.77678 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -50.42126 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -50.76802 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -51.41537 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -51.75938 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -0.69525 acc 0.51656 roc_auc 0.49314 prc_auc 0.68510[0m
[93maverage test of epoch 0: loss -1.85213 acc 0.67568 roc_auc 0.81000 prc_auc 0.90007[0m
[92maverage training of epoch 1: loss -2.83664 acc 0.68874 roc_auc 0.70882 prc_auc 0.81409[0m
[93maverage test of epoch 1: loss -3.61781 acc 0.67568 roc_auc 0.93000 prc_auc 0.97142[0m
[92maverage training of epoch 2: loss -4.38457 acc 0.74172 roc_auc 0.82784 prc_auc 0.87324[0m
[93maverage test of epoch 2: loss -4.95054 acc 0.67568 roc_auc 0.80667 prc_auc 0.87027[0m
[92maverage training of epoch 3: loss -5.51815 acc 0.80132 roc_auc 0.83392 prc_auc 0.87271[0m
[93maverage test of epoch 3: loss -6.08764 acc 0.72973 roc_auc 0.87333 prc_auc 0.92152[0m
[92maverage training of epoch 4: loss -6.57123 acc 0.80795 roc_auc 0.84176 prc_auc 0.86102[0m
[93maverage test of epoch 4: loss -7.05132 acc 0.72973 roc_auc 0.87000 prc_auc 0.93470[0m
[92maverage training of epoch 5: loss -7.53592 acc 0.82119 roc_auc 0.84569 prc_auc 0.85175[0m
[93maverage test of epoch 5: loss -7.86741 acc 0.72973 roc_auc 0.81500 prc_auc 0.85807[0m
[92maverage training of epoch 6: loss -8.50287 acc 0.83444 roc_auc 0.84755 prc_auc 0.86705[0m
[93maverage test of epoch 6: loss -8.84067 acc 0.67568 roc_auc 0.85333 prc_auc 0.91149[0m
[92maverage training of epoch 7: loss -9.38039 acc 0.81457 roc_auc 0.84843 prc_auc 0.86935[0m
[93maverage test of epoch 7: loss -9.80333 acc 0.72973 roc_auc 0.82000 prc_auc 0.86288[0m
[92maverage training of epoch 8: loss -10.34644 acc 0.82781 roc_auc 0.84892 prc_auc 0.85548[0m
[93maverage test of epoch 8: loss -10.62632 acc 0.70270 roc_auc 0.81833 prc_auc 0.85155[0m
[92maverage training of epoch 9: loss -10.94967 acc 0.78146 roc_auc 0.83922 prc_auc 0.87039[0m
[93maverage test of epoch 9: loss -11.64515 acc 0.72973 roc_auc 0.81333 prc_auc 0.86304[0m
[92maverage training of epoch 10: loss -12.13811 acc 0.84106 roc_auc 0.85255 prc_auc 0.85918[0m
[93maverage test of epoch 10: loss -12.31134 acc 0.72973 roc_auc 0.83000 prc_auc 0.87839[0m
[92maverage training of epoch 11: loss -12.99006 acc 0.82781 roc_auc 0.84588 prc_auc 0.86134[0m
[93maverage test of epoch 11: loss -13.30865 acc 0.75676 roc_auc 0.88000 prc_auc 0.92090[0m
[92maverage training of epoch 12: loss -13.82280 acc 0.82781 roc_auc 0.84980 prc_auc 0.86748[0m
[93maverage test of epoch 12: loss -14.12146 acc 0.70270 roc_auc 0.83667 prc_auc 0.88221[0m
[92maverage training of epoch 13: loss -14.69552 acc 0.82119 roc_auc 0.84716 prc_auc 0.86847[0m
[93maverage test of epoch 13: loss -15.29323 acc 0.75676 roc_auc 0.84667 prc_auc 0.89603[0m
[92maverage training of epoch 14: loss -15.57959 acc 0.83444 roc_auc 0.86608 prc_auc 0.89445[0m
[93maverage test of epoch 14: loss -16.05115 acc 0.70270 roc_auc 0.82500 prc_auc 0.87235[0m
[92maverage training of epoch 15: loss -16.49239 acc 0.84106 roc_auc 0.87824 prc_auc 0.90899[0m
[93maverage test of epoch 15: loss -16.96909 acc 0.75676 roc_auc 0.82333 prc_auc 0.86920[0m
[92maverage training of epoch 16: loss -17.47429 acc 0.84106 roc_auc 0.85255 prc_auc 0.87681[0m
[93maverage test of epoch 16: loss -17.63221 acc 0.72973 roc_auc 0.82167 prc_auc 0.87151[0m
[92maverage training of epoch 17: loss -18.24108 acc 0.83444 roc_auc 0.86922 prc_auc 0.89773[0m
[93maverage test of epoch 17: loss -18.77887 acc 0.78378 roc_auc 0.83833 prc_auc 0.87606[0m
[92maverage training of epoch 18: loss -19.12490 acc 0.84768 roc_auc 0.87588 prc_auc 0.90175[0m
[93maverage test of epoch 18: loss -19.65967 acc 0.78378 roc_auc 0.84167 prc_auc 0.87710[0m
[92maverage training of epoch 19: loss -20.04320 acc 0.84106 roc_auc 0.87353 prc_auc 0.90114[0m
[93maverage test of epoch 19: loss -20.27543 acc 0.75676 roc_auc 0.82833 prc_auc 0.87326[0m
[92maverage training of epoch 20: loss -20.85413 acc 0.84768 roc_auc 0.87588 prc_auc 0.90263[0m
[93maverage test of epoch 20: loss -21.20920 acc 0.75676 roc_auc 0.83833 prc_auc 0.87606[0m
[92maverage training of epoch 21: loss -21.89515 acc 0.82781 roc_auc 0.87696 prc_auc 0.89841[0m
[93maverage test of epoch 21: loss -21.78967 acc 0.75676 roc_auc 0.75500 prc_auc 0.81602[0m
[92maverage training of epoch 22: loss -22.53214 acc 0.82781 roc_auc 0.87824 prc_auc 0.90315[0m
[93maverage test of epoch 22: loss -22.91921 acc 0.78378 roc_auc 0.72333 prc_auc 0.79196[0m
[92maverage training of epoch 23: loss -23.59823 acc 0.84106 roc_auc 0.88000 prc_auc 0.90567[0m
[93maverage test of epoch 23: loss -23.87898 acc 0.72973 roc_auc 0.79333 prc_auc 0.84401[0m
[92maverage training of epoch 24: loss -24.53502 acc 0.88742 roc_auc 0.88196 prc_auc 0.90567[0m
[93maverage test of epoch 24: loss -24.51916 acc 0.72973 roc_auc 0.75500 prc_auc 0.81609[0m
[92maverage training of epoch 25: loss -25.34247 acc 0.86755 roc_auc 0.88137 prc_auc 0.90568[0m
[93maverage test of epoch 25: loss -25.55909 acc 0.78378 roc_auc 0.79333 prc_auc 0.84401[0m
[92maverage training of epoch 26: loss -26.17704 acc 0.86755 roc_auc 0.87882 prc_auc 0.90433[0m
[93maverage test of epoch 26: loss -26.10519 acc 0.72973 roc_auc 0.78333 prc_auc 0.84148[0m
[92maverage training of epoch 27: loss -27.11237 acc 0.86093 roc_auc 0.88529 prc_auc 0.90799[0m
[93maverage test of epoch 27: loss -26.95584 acc 0.72973 roc_auc 0.75500 prc_auc 0.81602[0m
[92maverage training of epoch 28: loss -27.98329 acc 0.87417 roc_auc 0.87824 prc_auc 0.89956[0m
[93maverage test of epoch 28: loss -27.78002 acc 0.72973 roc_auc 0.75167 prc_auc 0.81513[0m
[92maverage training of epoch 29: loss -28.93514 acc 0.88742 roc_auc 0.88255 prc_auc 0.90725[0m
[93maverage test of epoch 29: loss -28.64698 acc 0.78378 roc_auc 0.71333 prc_auc 0.78907[0m
[92maverage training of epoch 30: loss -29.68726 acc 0.89404 roc_auc 0.87618 prc_auc 0.89966[0m
[93maverage test of epoch 30: loss -29.74371 acc 0.75676 roc_auc 0.83167 prc_auc 0.87415[0m
[92maverage training of epoch 31: loss -30.65810 acc 0.88079 roc_auc 0.87471 prc_auc 0.89965[0m
[93maverage test of epoch 31: loss -30.24804 acc 0.72973 roc_auc 0.71667 prc_auc 0.78996[0m
[92maverage training of epoch 32: loss -31.45530 acc 0.89404 roc_auc 0.88686 prc_auc 0.90802[0m
[93maverage test of epoch 32: loss -31.12318 acc 0.75676 roc_auc 0.74833 prc_auc 0.81429[0m
[92maverage training of epoch 33: loss -32.71020 acc 0.89404 roc_auc 0.88353 prc_auc 0.90486[0m
[93maverage test of epoch 33: loss -32.11051 acc 0.78378 roc_auc 0.71333 prc_auc 0.78919[0m
[92maverage training of epoch 34: loss -33.25456 acc 0.88079 roc_auc 0.87980 prc_auc 0.90136[0m
[93maverage test of epoch 34: loss -33.04532 acc 0.75676 roc_auc 0.74833 prc_auc 0.81429[0m
[92maverage training of epoch 35: loss -34.01302 acc 0.86755 roc_auc 0.87412 prc_auc 0.89883[0m
[93maverage test of epoch 35: loss -33.85043 acc 0.75676 roc_auc 0.75167 prc_auc 0.81525[0m
[92maverage training of epoch 36: loss -35.06696 acc 0.88742 roc_auc 0.87863 prc_auc 0.90092[0m
[93maverage test of epoch 36: loss -34.66479 acc 0.75676 roc_auc 0.75167 prc_auc 0.81513[0m
[92maverage training of epoch 37: loss -35.93368 acc 0.86755 roc_auc 0.87686 prc_auc 0.90150[0m
[93maverage test of epoch 37: loss -35.55420 acc 0.78378 roc_auc 0.75167 prc_auc 0.81525[0m
[92maverage training of epoch 38: loss -36.90372 acc 0.87417 roc_auc 0.88137 prc_auc 0.90306[0m
[93maverage test of epoch 38: loss -35.92491 acc 0.75676 roc_auc 0.66833 prc_auc 0.76311[0m
[92maverage training of epoch 39: loss -37.83890 acc 0.87417 roc_auc 0.88265 prc_auc 0.90396[0m
[93maverage test of epoch 39: loss -37.27944 acc 0.75676 roc_auc 0.75167 prc_auc 0.81525[0m
[92maverage training of epoch 40: loss -38.62077 acc 0.88079 roc_auc 0.88157 prc_auc 0.90312[0m
[93maverage test of epoch 40: loss -37.72976 acc 0.75676 roc_auc 0.70667 prc_auc 0.78732[0m
[92maverage training of epoch 41: loss -39.36326 acc 0.87417 roc_auc 0.87961 prc_auc 0.90233[0m
[93maverage test of epoch 41: loss -38.58352 acc 0.75676 roc_auc 0.71000 prc_auc 0.78823[0m
[92maverage training of epoch 42: loss -40.11665 acc 0.86093 roc_auc 0.87039 prc_auc 0.89333[0m
[93maverage test of epoch 42: loss -39.85766 acc 0.75676 roc_auc 0.75167 prc_auc 0.81525[0m
[92maverage training of epoch 43: loss -41.19356 acc 0.88079 roc_auc 0.87157 prc_auc 0.89448[0m
[93maverage test of epoch 43: loss -40.45444 acc 0.75676 roc_auc 0.71333 prc_auc 0.78919[0m
[92maverage training of epoch 44: loss -42.23210 acc 0.89404 roc_auc 0.88235 prc_auc 0.90339[0m
[93maverage test of epoch 44: loss -41.57844 acc 0.78378 roc_auc 0.71667 prc_auc 0.79023[0m
[92maverage training of epoch 45: loss -42.94966 acc 0.88079 roc_auc 0.88882 prc_auc 0.91017[0m
[93maverage test of epoch 45: loss -42.49353 acc 0.81081 roc_auc 0.75500 prc_auc 0.81609[0m
[92maverage training of epoch 46: loss -43.97892 acc 0.88079 roc_auc 0.87529 prc_auc 0.89575[0m
[93maverage test of epoch 46: loss -43.12362 acc 0.78378 roc_auc 0.74833 prc_auc 0.81429[0m
[92maverage training of epoch 47: loss -44.72881 acc 0.88079 roc_auc 0.88225 prc_auc 0.90279[0m
[93maverage test of epoch 47: loss -43.87049 acc 0.75676 roc_auc 0.71000 prc_auc 0.78840[0m
[92maverage training of epoch 48: loss -45.69538 acc 0.88742 roc_auc 0.89696 prc_auc 0.91861[0m
[93maverage test of epoch 48: loss -44.12014 acc 0.78378 roc_auc 0.72667 prc_auc 0.80429[0m
[92maverage training of epoch 49: loss -46.93956 acc 0.90066 roc_auc 0.90500 prc_auc 0.92246[0m
[93maverage test of epoch 49: loss -45.17654 acc 0.75676 roc_auc 0.74333 prc_auc 0.80933[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -1.52506 acc 0.58940 roc_auc 0.41843 prc_auc 0.62027[0m
[93maverage test of epoch 0: loss -3.17759 acc 0.67568 roc_auc 0.64333 prc_auc 0.79264[0m
[92maverage training of epoch 1: loss -4.73365 acc 0.66225 roc_auc 0.37490 prc_auc 0.57689[0m
[93maverage test of epoch 1: loss -5.71315 acc 0.67568 roc_auc 0.40667 prc_auc 0.65841[0m
[92maverage training of epoch 2: loss -6.35137 acc 0.66225 roc_auc 0.38039 prc_auc 0.57656[0m
[93maverage test of epoch 2: loss -7.00928 acc 0.67568 roc_auc 0.40667 prc_auc 0.63533[0m
[92maverage training of epoch 3: loss -7.55876 acc 0.66225 roc_auc 0.37333 prc_auc 0.58042[0m
[93maverage test of epoch 3: loss -8.16411 acc 0.67568 roc_auc 0.50333 prc_auc 0.66655[0m
[92maverage training of epoch 4: loss -8.68367 acc 0.66225 roc_auc 0.37157 prc_auc 0.57040[0m
[93maverage test of epoch 4: loss -9.27421 acc 0.67568 roc_auc 0.37667 prc_auc 0.63511[0mUsing backend: pytorch

[92maverage training of epoch 5: loss -9.76144 acc 0.66225 roc_auc 0.36078 prc_auc 0.56322[0m
[93maverage test of epoch 5: loss -10.34617 acc 0.67568 roc_auc 0.52333 prc_auc 0.70808[0m
[92maverage training of epoch 6: loss -10.82301 acc 0.66225 roc_auc 0.36902 prc_auc 0.56911[0m
[93maverage test of epoch 6: loss -11.39887 acc 0.67568 roc_auc 0.68333 prc_auc 0.83404[0m
[92maverage training of epoch 7: loss -11.86756 acc 0.66225 roc_auc 0.36843 prc_auc 0.56751[0m
[93maverage test of epoch 7: loss -12.44458 acc 0.67568 roc_auc 0.37167 prc_auc 0.61788[0m
[92maverage training of epoch 8: loss -12.90365 acc 0.66225 roc_auc 0.37333 prc_auc 0.57002[0m
[93maverage test of epoch 8: loss -13.47897 acc 0.67568 roc_auc 0.52333 prc_auc 0.75920[0m
[92maverage training of epoch 9: loss -13.93235 acc 0.66225 roc_auc 0.37078 prc_auc 0.56927[0m
[93maverage test of epoch 9: loss -14.51016 acc 0.67568 roc_auc 0.62333 prc_auc 0.75469[0m
[92maverage training of epoch 10: loss -14.95334 acc 0.66225 roc_auc 0.36549 prc_auc 0.56555[0m
[93maverage test of epoch 10: loss -15.53384 acc 0.67568 roc_auc 0.58000 prc_auc 0.71702[0m
[92maverage training of epoch 11: loss -15.97242 acc 0.66225 roc_auc 0.36843 prc_auc 0.56801[0m
[93maverage test of epoch 11: loss -16.55715 acc 0.67568 roc_auc 0.57000 prc_auc 0.73168[0m
[92maverage training of epoch 12: loss -16.98768 acc 0.66225 roc_auc 0.37020 prc_auc 0.56880[0m
[93maverage test of epoch 12: loss -17.57224 acc 0.67568 roc_auc 0.60500 prc_auc 0.74980[0m
[92maverage training of epoch 13: loss -18.00052 acc 0.66225 roc_auc 0.37088 prc_auc 0.57169[0m
[93maverage test of epoch 13: loss -18.58914 acc 0.67568 roc_auc 0.66333 prc_auc 0.78839[0m
[92maverage training of epoch 14: loss -19.01100 acc 0.66225 roc_auc 0.37000 prc_auc 0.56790[0m
[93maverage test of epoch 14: loss -19.60235 acc 0.67568 roc_auc 0.41000 prc_auc 0.65787[0m
[92maverage training of epoch 15: loss -20.01943 acc 0.66225 roc_auc 0.37029 prc_auc 0.56868[0m
[93maverage test of epoch 15: loss -20.61475 acc 0.67568 roc_auc 0.50000 prc_auc 0.68804[0m
[92maverage training of epoch 16: loss -21.02637 acc 0.66225 roc_auc 0.37010 prc_auc 0.56845[0m
[93maverage test of epoch 16: loss -21.62578 acc 0.67568 roc_auc 0.50500 prc_auc 0.70973[0m
[92maverage training of epoch 17: loss -22.03261 acc 0.66225 roc_auc 0.37088 prc_auc 0.56848[0m
[93maverage test of epoch 17: loss -22.63505 acc 0.67568 roc_auc 0.48333 prc_auc 0.68541[0m
[92maverage training of epoch 18: loss -23.03714 acc 0.66225 roc_auc 0.36892 prc_auc 0.56829[0m
[93maverage test of epoch 18: loss -23.64298 acc 0.67568 roc_auc 0.49500 prc_auc 0.66439[0m
[92maverage training of epoch 19: loss -24.04101 acc 0.66225 roc_auc 0.36882 prc_auc 0.56733[0m
[93maverage test of epoch 19: loss -24.65060 acc 0.67568 roc_auc 0.69333 prc_auc 0.79730[0m
[92maverage training of epoch 20: loss -25.04446 acc 0.66225 roc_auc 0.36853 prc_auc 0.56721[0m
[93maverage test of epoch 20: loss -25.65816 acc 0.67568 roc_auc 0.48833 prc_auc 0.66818[0m
[92maverage training of epoch 21: loss -26.04674 acc 0.66225 roc_auc 0.37000 prc_auc 0.56836[0m
[93maverage test of epoch 21: loss -26.66473 acc 0.67568 roc_auc 0.32333 prc_auc 0.59655[0m
[92maverage training of epoch 22: loss -27.04827 acc 0.66225 roc_auc 0.36912 prc_auc 0.57011[0m
[93maverage test of epoch 22: loss -27.66994 acc 0.67568 roc_auc 0.60167 prc_auc 0.73170[0m
[92maverage training of epoch 23: loss -28.05003 acc 0.66225 roc_auc 0.37020 prc_auc 0.57007[0m
[93maverage test of epoch 23: loss -28.67619 acc 0.67568 roc_auc 0.32667 prc_auc 0.60192[0m
[92maverage training of epoch 24: loss -29.05102 acc 0.66225 roc_auc 0.36990 prc_auc 0.56827[0m
[93maverage test of epoch 24: loss -29.68104 acc 0.67568 roc_auc 0.36000 prc_auc 0.62258[0m
[92maverage training of epoch 25: loss -30.05190 acc 0.66225 roc_auc 0.36873 prc_auc 0.57102[0m
[93maverage test of epoch 25: loss -30.68623 acc 0.67568 roc_auc 0.50833 prc_auc 0.67988[0m
[92maverage training of epoch 26: loss -31.05248 acc 0.66225 roc_auc 0.36980 prc_auc 0.57270[0m
[93maverage test of epoch 26: loss -31.69098 acc 0.67568 roc_auc 0.44167 prc_auc 0.65126[0m
[92maverage training of epoch 27: loss -32.05252 acc 0.66225 roc_auc 0.36882 prc_auc 0.57131[0m
[93maverage test of epoch 27: loss -32.69564 acc 0.67568 roc_auc 0.38667 prc_auc 0.63312[0m
[92maverage training of epoch 28: loss -33.05269 acc 0.66225 roc_auc 0.37069 prc_auc 0.57202[0m
[93maverage test of epoch 28: loss -33.69992 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 29: loss -34.05233 acc 0.66225 roc_auc 0.36892 prc_auc 0.57131[0m
[93maverage test of epoch 29: loss -34.70352 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 30: loss -35.05219 acc 0.66225 roc_auc 0.36676 prc_auc 0.57214[0m
[93maverage test of epoch 30: loss -35.70733 acc 0.67568 roc_auc 0.54500 prc_auc 0.69611[0m
[92maverage training of epoch 31: loss -36.05160 acc 0.66225 roc_auc 0.36500 prc_auc 0.56936[0m
[93maverage test of epoch 31: loss -36.71101 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 32: loss -37.05131 acc 0.66225 roc_auc 0.37020 prc_auc 0.57751[0m
[93maverage test of epoch 32: loss -37.71489 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 33: loss -38.05032 acc 0.66225 roc_auc 0.36265 prc_auc 0.56993[0m
[93maverage test of epoch 33: loss -38.71774 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 34: loss -39.04972 acc 0.66225 roc_auc 0.37108 prc_auc 0.58073[0m
[93maverage test of epoch 34: loss -39.72171 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 35: loss -40.04879 acc 0.66225 roc_auc 0.36618 prc_auc 0.57909[0m
[93maverage test of epoch 35: loss -40.72476 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 36: loss -41.04765 acc 0.66225 roc_auc 0.38167 prc_auc 0.59038[0m
[93maverage test of epoch 36: loss -41.72825 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 37: loss -42.04685 acc 0.66225 roc_auc 0.38235 prc_auc 0.59363[0m
[93maverage test of epoch 37: loss -42.73154 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 38: loss -43.04573 acc 0.66225 roc_auc 0.38716 prc_auc 0.60004[0m
[93maverage test of epoch 38: loss -43.73453 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 39: loss -44.04462 acc 0.66225 roc_auc 0.39098 prc_auc 0.60844[0m
[93maverage test of epoch 39: loss -44.73775 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -45.04356 acc 0.66225 roc_auc 0.41961 prc_auc 0.62105[0m
[93maverage test of epoch 40: loss -45.74095 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -46.04241 acc 0.66225 roc_auc 0.41029 prc_auc 0.62141[0m
[93maverage test of epoch 41: loss -46.74372 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -47.04116 acc 0.66225 roc_auc 0.44784 prc_auc 0.64007[0m
[93maverage test of epoch 42: loss -47.74686 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -48.03986 acc 0.66225 roc_auc 0.45382 prc_auc 0.64238[0m
[93maverage test of epoch 43: loss -48.74975 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -49.03853 acc 0.66225 roc_auc 0.45863 prc_auc 0.64438[0m
[93maverage test of epoch 44: loss -49.75285 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -50.03712 acc 0.66225 roc_auc 0.39588 prc_auc 0.62295[0m
[93maverage test of epoch 45: loss -50.75587 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -51.03608 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 46: loss -51.75891 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -52.03469 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 47: loss -52.76180 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -53.03339 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 48: loss -53.76457 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -54.03199 acc 0.66225 roc_auc 0.46284 prc_auc 0.64620[0m
[93maverage test of epoch 49: loss -54.76756 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.68122 ROC_AUC (avg): 0.61944 PRC_AUC (avg): 0.7345 

Average forward propagation time taken(ms): 3.950756519112253
Average backward propagation time taken(ms): 1.5124859585355614

