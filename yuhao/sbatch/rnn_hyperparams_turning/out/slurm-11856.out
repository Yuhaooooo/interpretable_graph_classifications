# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 2)
('lr', 0.0003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-18-41-20/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-18-41-20/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 16,
 'epochs': 50,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 4,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.0003,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 1,
 'num_workers': 8,
 'number_of_mlp_layer': 2,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-17-18-41-20',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 50, 'learning_rate': 0.0003, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=4, bias=True)
    (ReLU1): ReLU()
    (Linear2): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.25543 acc 0.33333 roc_auc 0.45360 prc_auc 0.61302[0m
[93maverage test of epoch 0: loss -0.51489 acc 0.34211 roc_auc 0.26154 prc_auc 0.60814[0m
[92maverage training of epoch 1: loss -0.79502 acc 0.33333 roc_auc 0.56140 prc_auc 0.71292[0m
[93maverage test of epoch 1: loss -1.15800 acc 0.34211 roc_auc 0.34462 prc_auc 0.68345[0m
[92maverage training of epoch 2: loss -1.60249 acc 0.33333 roc_auc 0.54360 prc_auc 0.70554[0m
[93maverage test of epoch 2: loss -2.14338 acc 0.34211 roc_auc 0.12923 prc_auc 0.48907[0m
[92maverage training of epoch 3: loss -2.64553 acc 0.33333 roc_auc 0.44200 prc_auc 0.63482[0m
[93maverage test of epoch 3: loss -3.18346 acc 0.34211 roc_auc 0.13231 prc_auc 0.49041[0m
[92maverage training of epoch 4: loss -3.63927 acc 0.33333 roc_auc 0.28140 prc_auc 0.53184[0m
[93maverage test of epoch 4: loss -4.16956 acc 0.34211 roc_auc 0.13538 prc_auc 0.49114[0m
[92maverage training of epoch 5: loss -4.71176 acc 0.33333 roc_auc 0.32260 prc_auc 0.55966[0m
[93maverage test of epoch 5: loss -5.38005 acc 0.34211 roc_auc 0.13231 prc_auc 0.49044[0m
[92maverage training of epoch 6: loss -6.09755 acc 0.33333 roc_auc 0.39060 prc_auc 0.60052[0m
[93maverage test of epoch 6: loss -6.88742 acc 0.34211 roc_auc 0.13231 prc_auc 0.49044[0m
[92maverage training of epoch 7: loss -7.62472 acc 0.33333 roc_auc 0.41220 prc_auc 0.61912[0m
[93maverage test of epoch 7: loss -8.42514 acc 0.34211 roc_auc 0.13538 prc_auc 0.49593[0m
[92maverage training of epoch 8: loss -9.18084 acc 0.33333 roc_auc 0.41940 prc_auc 0.62519[0m
[93maverage test of epoch 8: loss -9.99656 acc 0.34211 roc_auc 0.16462 prc_auc 0.50505[0m
[92maverage training of epoch 9: loss -10.79400 acc 0.49333 roc_auc 0.42000 prc_auc 0.62565[0m
[93maverage test of epoch 9: loss -11.64391 acc 0.65789 roc_auc 0.86000 prc_auc 0.93322[0m
[92maverage training of epoch 10: loss -12.48677 acc 0.66667 roc_auc 0.42040 prc_auc 0.62600[0m
[93maverage test of epoch 10: loss -13.36977 acc 0.65789 roc_auc 0.85846 prc_auc 0.93058[0m
[92maverage training of epoch 11: loss -14.26373 acc 0.66667 roc_auc 0.42080 prc_auc 0.62688[0m
[93maverage test of epoch 11: loss -15.18377 acc 0.65789 roc_auc 0.86769 prc_auc 0.93448[0m
[92maverage training of epoch 12: loss -16.13227 acc 0.66667 roc_auc 0.42080 prc_auc 0.62688[0m
[93maverage test of epoch 12: loss -17.08969 acc 0.65789 roc_auc 0.85846 prc_auc 0.91949[0m
[92maverage training of epoch 13: loss -18.09698 acc 0.66667 roc_auc 0.42080 prc_auc 0.62688[0m
[93maverage test of epoch 13: loss -19.09468 acc 0.65789 roc_auc 0.87846 prc_auc 0.89847[0m
[92maverage training of epoch 14: loss -20.16463 acc 0.66667 roc_auc 0.42090 prc_auc 0.62688[0m
[93maverage test of epoch 14: loss -21.20406 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 15: loss -22.34014 acc 0.66667 roc_auc 0.42080 prc_auc 0.62635[0m
[93maverage test of epoch 15: loss -23.42640 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 16: loss -24.63072 acc 0.66667 roc_auc 0.42060 prc_auc 0.62600[0m
[93maverage test of epoch 16: loss -25.76260 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 17: loss -27.04231 acc 0.66667 roc_auc 0.41950 prc_auc 0.62224[0m
[93maverage test of epoch 17: loss -28.22502 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 18: loss -29.58250 acc 0.66667 roc_auc 0.41730 prc_auc 0.62287[0m
[93maverage test of epoch 18: loss -30.81792 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -32.26090 acc 0.66667 roc_auc 0.41050 prc_auc 0.62038[0m
[93maverage test of epoch 19: loss -33.55369 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -35.08440 acc 0.66667 roc_auc 0.45000 prc_auc 0.64543[0m
[93maverage test of epoch 20: loss -36.43860 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -38.07450 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 21: loss -39.50904 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -41.27243 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 22: loss -42.80376 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -44.70800 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 23: loss -46.35060 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -48.41474 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 24: loss -50.19072 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -52.43550 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 25: loss -54.36734 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -56.81448 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 26: loss -58.92525 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -61.58166 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 27: loss -63.86805 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -66.69243 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 28: loss -69.12525 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -72.10184 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 29: loss -74.66711 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -77.78731 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 30: loss -80.48544 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -83.75485 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 31: loss -86.59035 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -90.01433 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 32: loss -92.99137 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -96.57461 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 33: loss -99.69723 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -103.44523 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -106.71784 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -110.63536 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -114.06179 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -118.15375 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -121.73791 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -126.00914 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -129.75487 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -134.21016 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -138.12120 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -142.76534 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -146.84533 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -151.68292 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -155.93536 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -160.97126 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -165.40008 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -170.63926 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -175.24799 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -180.69482 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -185.48656 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -191.14555 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -196.12396 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -202.00047 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -207.16939 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -213.26818 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -218.63082 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -224.95622 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -230.51584 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -237.07314 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -242.83334 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -249.62717 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -255.59119 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=4, bias=True)
    (ReLU1): ReLU()
    (Linear2): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.18140 acc 0.56000 roc_auc 0.46960 prc_auc 0.65716[0m
[93maverage test of epoch 0: loss -0.52813 acc 0.65789 roc_auc 0.55692 prc_auc 0.81185[0m
[92maverage training of epoch 1: loss -0.92827 acc 0.66667 roc_auc 0.47060 prc_auc 0.65589[0m
[93maverage test of epoch 1: loss -1.44195 acc 0.65789 roc_auc 0.68923 prc_auc 0.86658[0m
[92maverage training of epoch 2: loss -1.93015 acc 0.66667 roc_auc 0.47480 prc_auc 0.65819[0m
[93maverage test of epoch 2: loss -2.45924 acc 0.65789 roc_auc 0.87077 prc_auc 0.92629[0m
[92maverage training of epoch 3: loss -3.00550 acc 0.66667 roc_auc 0.47460 prc_auc 0.65836[0m
[93maverage test of epoch 3: loss -3.57659 acc 0.65789 roc_auc 0.86308 prc_auc 0.92055[0m
[92maverage training of epoch 4: loss -4.30737 acc 0.66667 roc_auc 0.47530 prc_auc 0.66443[0m
[93maverage test of epoch 4: loss -5.08958 acc 0.65789 roc_auc 0.86154 prc_auc 0.92077[0m
[92maverage training of epoch 5: loss -6.06041 acc 0.66667 roc_auc 0.50710 prc_auc 0.68780[0m
[93maverage test of epoch 5: loss -6.82938 acc 0.65789 roc_auc 0.83538 prc_auc 0.86599[0m
[92maverage training of epoch 6: loss -7.70569 acc 0.66667 roc_auc 0.51650 prc_auc 0.67880[0m
[93maverage test of epoch 6: loss -8.38348 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 7: loss -9.32601 acc 0.66667 roc_auc 0.50500 prc_auc 0.66890[0m
[93maverage test of epoch 7: loss -10.03263 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 8: loss -11.04832 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 8: loss -11.78853 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 9: loss -12.88393 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 9: loss -13.66117 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 10: loss -14.83269 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 10: loss -15.63509 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 11: loss -16.88013 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 11: loss -17.71873 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 12: loss -19.05889 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 12: loss -19.94687 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 13: loss -21.39179 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 13: loss -22.33639 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 14: loss -23.89597 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 14: loss -24.90450 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 15: loss -26.58908 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 15: loss -27.66901 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 16: loss -29.48931 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 16: loss -30.64820 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 17: loss -32.61527 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 17: loss -33.86068 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 18: loss -35.98851 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 18: loss -37.33378 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -39.63902 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 19: loss -41.09078 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -43.57434 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 20: loss -45.12853 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -47.80111 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 21: loss -49.46525 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -52.37630 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 22: loss -54.25793 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -57.50345 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 23: loss -59.58508 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -63.11338 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 24: loss -65.38809 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -69.22150 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 25: loss -71.70568 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -75.86763 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 26: loss -78.57687 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -83.08973 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 27: loss -86.03778 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -90.91732 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 28: loss -94.09731 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -99.32266 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 29: loss -102.70745 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -108.27755 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 30: loss -111.85749 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -117.76439 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 31: loss -121.51674 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -127.75221 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 32: loss -131.67321 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -138.24798 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 33: loss -142.34185 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -149.25575 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -153.50883 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -160.76170 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -165.17514 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -172.77709 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -177.35565 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -185.31670 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -190.06480 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -198.39497 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -203.31693 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -212.02593 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -217.12573 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -226.22346 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -231.50502 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -241.00123 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -246.46822 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -256.37272 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -262.02890 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -272.35112 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -278.19987 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -288.94988 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -294.99433 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -306.18165 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -312.42534 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -324.05997 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -330.50630 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -342.59724 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -349.24870 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -361.80631 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -368.66625 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -381.70013 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -388.77178 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=4, bias=True)
    (ReLU1): ReLU()
    (Linear2): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -1.32134 acc 0.33333 roc_auc 0.33340 prc_auc 0.55127[0m
[93maverage test of epoch 0: loss -1.82077 acc 0.34211 roc_auc 0.05538 prc_auc 0.46519[0m
[92maverage training of epoch 1: loss -2.38476 acc 0.33333 roc_auc 0.35880 prc_auc 0.57602[0m
[93maverage test of epoch 1: loss -3.09046 acc 0.34211 roc_auc 0.36923 prc_auc 0.71235[0m
[92maverage training of epoch 2: loss -3.85358 acc 0.33333 roc_auc 0.38180 prc_auc 0.59634[0m
[93maverage test of epoch 2: loss -4.62747 acc 0.34211 roc_auc 0.08615 prc_auc 0.50256[0m
[92maverage training of epoch 3: loss -5.29704 acc 0.33333 roc_auc 0.38840 prc_auc 0.58951[0m
[93maverage test of epoch 3: loss -5.98997 acc 0.34211 roc_auc 0.44923 prc_auc 0.74117[0m
[92maverage training of epoch 4: loss -6.65350 acc 0.33333 roc_auc 0.39180 prc_auc 0.59769[0m
[93maverage test of epoch 4: loss -7.34728 acc 0.34211 roc_auc 0.86923 prc_auc 0.94063[0m
[92maverage training of epoch 5: loss -8.03605 acc 0.33333 roc_auc 0.39480 prc_auc 0.60032[0m
[93maverage test of epoch 5: loss -8.75383 acc 0.34211 roc_auc 0.61231 prc_auc 0.82761[0m
[92maverage training of epoch 6: loss -9.48022 acc 0.60667 roc_auc 0.39440 prc_auc 0.60041[0m
[93maverage test of epoch 6: loss -10.23390 acc 0.65789 roc_auc 0.89846 prc_auc 0.94787[0m
[92maverage training of epoch 7: loss -11.00780 acc 0.66667 roc_auc 0.39580 prc_auc 0.60078[0m
[93maverage test of epoch 7: loss -11.80644 acc 0.65789 roc_auc 0.87846 prc_auc 0.92961[0m
[92maverage training of epoch 8: loss -12.63609 acc 0.66667 roc_auc 0.39680 prc_auc 0.60198[0m
[93maverage test of epoch 8: loss -13.48820 acc 0.65789 roc_auc 0.85385 prc_auc 0.91874[0m
[92maverage training of epoch 9: loss -14.38167 acc 0.66667 roc_auc 0.39900 prc_auc 0.60519[0m
[93maverage test of epoch 9: loss -15.29541 acc 0.65789 roc_auc 0.80000 prc_auc 0.86602[0m
[92maverage training of epoch 10: loss -16.26239 acc 0.66667 roc_auc 0.40080 prc_auc 0.60672[0m
[93maverage test of epoch 10: loss -17.24764 acc 0.65789 roc_auc 0.54154 prc_auc 0.68065[0m
[92maverage training of epoch 11: loss -18.30208 acc 0.66667 roc_auc 0.40360 prc_auc 0.60818[0m
[93maverage test of epoch 11: loss -19.37781 acc 0.65789 roc_auc 0.23231 prc_auc 0.53649[0m
[92maverage training of epoch 12: loss -20.54743 acc 0.66667 roc_auc 0.41120 prc_auc 0.61480[0m
[93maverage test of epoch 12: loss -21.73851 acc 0.65789 roc_auc 0.13385 prc_auc 0.49928[0m
[92maverage training of epoch 13: loss -23.02574 acc 0.66667 roc_auc 0.42140 prc_auc 0.62176[0m
[93maverage test of epoch 13: loss -24.32357 acc 0.65789 roc_auc 0.11846 prc_auc 0.52740[0m
[92maverage training of epoch 14: loss -25.71496 acc 0.66667 roc_auc 0.42620 prc_auc 0.62644[0m
[93maverage test of epoch 14: loss -27.10775 acc 0.65789 roc_auc 0.22769 prc_auc 0.56442[0m
[92maverage training of epoch 15: loss -28.60135 acc 0.66667 roc_auc 0.42940 prc_auc 0.62920[0m
[93maverage test of epoch 15: loss -30.08949 acc 0.65789 roc_auc 0.34462 prc_auc 0.60262[0m
[92maverage training of epoch 16: loss -31.69071 acc 0.66667 roc_auc 0.43290 prc_auc 0.63239[0m
[93maverage test of epoch 16: loss -33.27912 acc 0.65789 roc_auc 0.50000 prc_auc 0.66307[0m
[92maverage training of epoch 17: loss -34.99445 acc 0.66667 roc_auc 0.43820 prc_auc 0.63733[0m
[93maverage test of epoch 17: loss -36.68809 acc 0.65789 roc_auc 0.48000 prc_auc 0.64902[0m
[92maverage training of epoch 18: loss -38.52337 acc 0.66667 roc_auc 0.44150 prc_auc 0.63990[0m
[93maverage test of epoch 18: loss -40.32575 acc 0.65789 roc_auc 0.58000 prc_auc 0.71263[0m
[92maverage training of epoch 19: loss -42.27886 acc 0.66667 roc_auc 0.44160 prc_auc 0.63984[0m
[93maverage test of epoch 19: loss -44.18050 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -46.24910 acc 0.66667 roc_auc 0.44180 prc_auc 0.64017[0m
[93maverage test of epoch 20: loss -48.25000 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -50.43829 acc 0.66667 roc_auc 0.44220 prc_auc 0.63864[0m
[93maverage test of epoch 21: loss -52.54150 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -54.85355 acc 0.66667 roc_auc 0.44490 prc_auc 0.63819[0m
[93maverage test of epoch 22: loss -57.06179 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -59.50150 acc 0.66667 roc_auc 0.43450 prc_auc 0.62744[0m
[93maverage test of epoch 23: loss -61.81746 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -64.38883 acc 0.66667 roc_auc 0.43550 prc_auc 0.62928[0m
[93maverage test of epoch 24: loss -66.81523 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -69.52200 acc 0.66667 roc_auc 0.45640 prc_auc 0.64823[0m
[93maverage test of epoch 25: loss -72.06109 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -74.90726 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 26: loss -77.56161 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -80.55101 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 27: loss -83.32313 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -86.45953 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 28: loss -89.35177 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -92.63926 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 29: loss -95.65408 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -99.09643 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 30: loss -102.23610 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -105.83725 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 31: loss -109.10401 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -112.86766 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 32: loss -116.26372 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -120.19382 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 33: loss -123.72144 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -127.82160 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -131.48255 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -135.75640 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -139.55275 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -144.00429 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -147.93834 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -152.57139 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -156.64497 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -161.53100 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -165.94708 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -171.23295 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -175.87908 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -181.37437 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -186.18287 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -191.89835 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -196.87556 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -202.81721 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -207.96656 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -214.14060 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -219.46600 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -225.87752 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -231.38177 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -238.03675 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -243.72355 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -250.62719 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -256.49898 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -263.65658 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -269.71671 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -277.13374 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -283.38487 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -291.06701 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -297.51240 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=4, bias=True)
    (ReLU1): ReLU()
    (Linear2): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss -0.67432 acc 0.66225 roc_auc 0.39255 prc_auc 0.57786[0m
[93maverage test of epoch 0: loss -0.79370 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 1: loss -0.87660 acc 0.66225 roc_auc 0.38696 prc_auc 0.57771[0m
[93maverage test of epoch 1: loss -1.00046 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 2: loss -1.08732 acc 0.66225 roc_auc 0.38725 prc_auc 0.57859[0m
[93maverage test of epoch 2: loss -1.21682 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 3: loss -1.30799 acc 0.66225 roc_auc 0.38961 prc_auc 0.58076[0m
[93maverage test of epoch 3: loss -1.44355 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 4: loss -1.53932 acc 0.66225 roc_auc 0.39157 prc_auc 0.58316[0m
[93maverage test of epoch 4: loss -1.68137 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 5: loss -1.78202 acc 0.66225 roc_auc 0.39392 prc_auc 0.58463[0m
[93maverage test of epoch 5: loss -1.93094 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 6: loss -2.03673 acc 0.66225 roc_auc 0.39608 prc_auc 0.58620[0m
[93maverage test of epoch 6: loss -2.19292 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 7: loss -2.30412 acc 0.66225 roc_auc 0.39824 prc_auc 0.58774[0m
[93maverage test of epoch 7: loss -2.46794 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 8: loss -2.82133 acc 0.66225 roc_auc 0.43373 prc_auc 0.62178[0m
[93maverage test of epoch 8: loss -4.11539 acc 0.67568 roc_auc 0.86000 prc_auc 0.92282[0m
[92maverage training of epoch 9: loss -5.86681 acc 0.66225 roc_auc 0.44157 prc_auc 0.62385[0m
[93maverage test of epoch 9: loss -8.03881 acc 0.67568 roc_auc 0.84833 prc_auc 0.91331[0m
[92maverage training of epoch 10: loss -10.37601 acc 0.66225 roc_auc 0.44078 prc_auc 0.62365[0m
[93maverage test of epoch 10: loss -12.85376 acc 0.67568 roc_auc 0.85333 prc_auc 0.90138[0m
[92maverage training of epoch 11: loss -14.91033 acc 0.66225 roc_auc 0.44078 prc_auc 0.62359[0m
[93maverage test of epoch 11: loss -17.19044 acc 0.67568 roc_auc 0.66000 prc_auc 0.75703[0m
[92maverage training of epoch 12: loss -19.16715 acc 0.66225 roc_auc 0.44059 prc_auc 0.62354[0m
[93maverage test of epoch 12: loss -21.46671 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 13: loss -23.47759 acc 0.66225 roc_auc 0.44039 prc_auc 0.62344[0m
[93maverage test of epoch 13: loss -25.87957 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 14: loss -27.96835 acc 0.66225 roc_auc 0.43912 prc_auc 0.62322[0m
[93maverage test of epoch 14: loss -30.51043 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 15: loss -32.69930 acc 0.66225 roc_auc 0.43245 prc_auc 0.62816[0m
[93maverage test of epoch 15: loss -35.40345 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 16: loss -37.70625 acc 0.66225 roc_auc 0.48608 prc_auc 0.66150[0m
[93maverage test of epoch 16: loss -40.58817 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 17: loss -43.01494 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 17: loss -46.08739 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 18: loss -48.64617 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 18: loss -51.92039 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 19: loss -54.61808 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 19: loss -58.10445 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 20: loss -60.94721 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 20: loss -64.65560 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 21: loss -67.64913 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 21: loss -71.58905 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 22: loss -74.73872 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 22: loss -78.91959 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 23: loss -82.23047 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 23: loss -86.66152 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 24: loss -90.13848 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 24: loss -94.82887 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 25: loss -98.47664 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 25: loss -103.43540 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 26: loss -107.25828 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 26: loss -112.49429 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 27: loss -116.49673 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 27: loss -122.01913 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 28: loss -126.20552 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 28: loss -132.02346 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 29: loss -136.39811 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 29: loss -142.52079 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 30: loss -147.08787 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 30: loss -153.52447 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 31: loss -158.28803 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 31: loss -165.04774 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 32: loss -170.01176 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 32: loss -177.10377 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 33: loss -182.27204 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 33: loss -189.70535 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 34: loss -195.08150 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 34: loss -202.86528 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 35: loss -208.45308 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 35: loss -216.59669 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 36: loss -222.39978 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 36: loss -230.91255 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 37: loss -236.93463 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 37: loss -245.82596 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 38: loss -252.07049 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 38: loss -261.34995 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 39: loss -267.82008 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 39: loss -277.49680 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -284.19655 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 40: loss -294.28002 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -301.21197 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 41: loss -311.71235 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -318.88001 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 42: loss -329.80546 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -337.21195 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 43: loss -348.57375 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -356.22309 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 44: loss -368.03005 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -375.92256 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 45: loss -388.18316 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -396.32410 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 46: loss -409.05011 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -417.44294 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 47: loss -430.64452 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -439.29100 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 48: loss -452.97550 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -461.87575 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 49: loss -476.05192 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=4, bias=True)
    (ReLU1): ReLU()
    (Linear2): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0003
[92maverage training of epoch 0: loss 0.39574 acc 0.33775 roc_auc 0.41392 prc_auc 0.61836[0mUsing backend: pytorch
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))

[93maverage test of epoch 0: loss 0.23570 acc 0.32432 roc_auc 0.57333 prc_auc 0.82018[0m
[92maverage training of epoch 1: loss 0.08449 acc 0.33775 roc_auc 0.42098 prc_auc 0.61716[0m
[93maverage test of epoch 1: loss -0.05681 acc 0.32432 roc_auc 0.67333 prc_auc 0.87042[0m
[92maverage training of epoch 2: loss -0.10746 acc 0.55629 roc_auc 0.41510 prc_auc 0.61415[0m
[93maverage test of epoch 2: loss -0.15850 acc 0.67568 roc_auc 0.69333 prc_auc 0.88157[0m
[92maverage training of epoch 3: loss -0.19619 acc 0.66225 roc_auc 0.41275 prc_auc 0.61685[0m
[93maverage test of epoch 3: loss -0.24752 acc 0.67568 roc_auc 0.68000 prc_auc 0.87654[0m
[92maverage training of epoch 4: loss -0.28237 acc 0.66225 roc_auc 0.41588 prc_auc 0.61904[0m
[93maverage test of epoch 4: loss -0.33951 acc 0.67568 roc_auc 0.81333 prc_auc 0.92929[0m
[92maverage training of epoch 5: loss -0.37178 acc 0.66225 roc_auc 0.37696 prc_auc 0.57014[0m
[93maverage test of epoch 5: loss -0.41538 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 6: loss -0.41974 acc 0.66225 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 6: loss -0.44880 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 7: loss -0.45302 acc 0.66225 roc_auc 0.36980 prc_auc 0.56834[0m
[93maverage test of epoch 7: loss -0.48222 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 8: loss -0.48631 acc 0.66225 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 8: loss -0.51565 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 9: loss -0.51959 acc 0.66225 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 9: loss -0.54908 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 10: loss -0.55288 acc 0.66225 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 10: loss -0.58251 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 11: loss -0.58617 acc 0.66225 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 11: loss -0.61594 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 12: loss -0.61946 acc 0.66225 roc_auc 0.36980 prc_auc 0.56840[0m
[93maverage test of epoch 12: loss -0.64937 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 13: loss -0.65275 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 13: loss -0.68280 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 14: loss -0.68604 acc 0.66225 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 14: loss -0.71623 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 15: loss -0.71933 acc 0.66225 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 15: loss -0.74966 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 16: loss -0.75262 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 16: loss -0.78310 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 17: loss -0.78591 acc 0.66225 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 17: loss -0.81653 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 18: loss -0.81920 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 18: loss -0.84996 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 19: loss -0.85250 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 19: loss -0.88340 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 20: loss -0.88579 acc 0.66225 roc_auc 0.36980 prc_auc 0.56827[0m
[93maverage test of epoch 20: loss -0.91683 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 21: loss -0.91908 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 21: loss -0.95027 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 22: loss -0.95238 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 22: loss -0.98370 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 23: loss -0.98567 acc 0.66225 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 23: loss -1.01714 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 24: loss -1.01896 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 24: loss -1.05057 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 25: loss -1.05226 acc 0.66225 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 25: loss -1.08401 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 26: loss -1.08555 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 26: loss -1.11744 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 27: loss -1.11884 acc 0.66225 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 27: loss -1.15088 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 28: loss -1.15214 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 28: loss -1.18431 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 29: loss -1.18543 acc 0.66225 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 29: loss -1.21775 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 30: loss -1.21872 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 30: loss -1.25118 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 31: loss -1.25202 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 31: loss -1.28462 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 32: loss -1.28531 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 32: loss -1.31805 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 33: loss -1.31860 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 33: loss -1.35149 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 34: loss -1.35190 acc 0.66225 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 34: loss -1.38492 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 35: loss -1.38519 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 35: loss -1.41836 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 36: loss -1.41848 acc 0.66225 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 36: loss -1.45179 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 37: loss -1.45177 acc 0.66225 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 37: loss -1.48523 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 38: loss -1.48507 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 38: loss -1.51866 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 39: loss -1.51836 acc 0.66225 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 39: loss -1.55210 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -1.55165 acc 0.66225 roc_auc 0.36980 prc_auc 0.56821[0m
[93maverage test of epoch 40: loss -1.58553 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -1.58495 acc 0.66225 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 41: loss -1.61896 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -1.61824 acc 0.66225 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 42: loss -1.65240 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -1.65153 acc 0.66225 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 43: loss -1.68583 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -1.68482 acc 0.66225 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 44: loss -1.71926 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -1.71811 acc 0.66225 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 45: loss -1.75270 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -1.75141 acc 0.66225 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 46: loss -1.78613 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -1.78470 acc 0.66225 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 47: loss -1.81956 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -1.81799 acc 0.66225 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 48: loss -1.85300 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -1.85128 acc 0.66225 roc_auc 0.36980 prc_auc 0.56819[0m
[93maverage test of epoch 49: loss -1.88643 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 2)
('lr', 0.0003)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.66501 ROC_AUC (avg): 0.5 PRC_AUC (avg): 0.66501 

Average forward propagation time taken(ms): 3.1275887790729366
Average backward propagation time taken(ms): 1.0027324074044597

