# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.0001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-20-38-14/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-20-38-14/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 8,
 'epochs': 50,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 8,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.0001,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 2,
 'num_workers': 8,
 'number_of_mlp_layer': 0,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-17-20-38-14',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 50, 'learning_rate': 0.0001, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.12739 acc 0.66667 roc_auc 0.44740 prc_auc 0.65238[0m
[93maverage test of epoch 0: loss -0.28430 acc 0.63158 roc_auc 0.57231 prc_auc 0.68445[0m
[92maverage training of epoch 1: loss -0.43357 acc 0.66667 roc_auc 0.44480 prc_auc 0.62778[0m
[93maverage test of epoch 1: loss -0.59226 acc 0.65789 roc_auc 0.46154 prc_auc 0.64997[0m
[92maverage training of epoch 2: loss -0.76330 acc 0.66667 roc_auc 0.50420 prc_auc 0.68480[0m
[93maverage test of epoch 2: loss -0.90786 acc 0.65789 roc_auc 0.49538 prc_auc 0.70125[0m
[92maverage training of epoch 3: loss -1.07066 acc 0.66667 roc_auc 0.53400 prc_auc 0.73282[0m
[93maverage test of epoch 3: loss -1.20854 acc 0.65789 roc_auc 0.42154 prc_auc 0.64390[0m
[92maverage training of epoch 4: loss -1.39953 acc 0.66667 roc_auc 0.50600 prc_auc 0.70823[0m
[93maverage test of epoch 4: loss -1.58100 acc 0.65789 roc_auc 0.73846 prc_auc 0.84184[0m
[92maverage training of epoch 5: loss -1.77055 acc 0.66667 roc_auc 0.45120 prc_auc 0.65141[0m
[93maverage test of epoch 5: loss -1.95634 acc 0.65789 roc_auc 0.81231 prc_auc 0.86930[0m
[92maverage training of epoch 6: loss -2.08520 acc 0.66667 roc_auc 0.48100 prc_auc 0.66975[0m
[93maverage test of epoch 6: loss -2.20783 acc 0.65789 roc_auc 0.42462 prc_auc 0.61896[0m
[92maverage training of epoch 7: loss -2.32466 acc 0.66667 roc_auc 0.43940 prc_auc 0.62479[0m
[93maverage test of epoch 7: loss -2.43085 acc 0.65789 roc_auc 0.46769 prc_auc 0.62358[0m
[92maverage training of epoch 8: loss -2.54556 acc 0.66667 roc_auc 0.51720 prc_auc 0.68728[0m
[93maverage test of epoch 8: loss -2.62603 acc 0.65789 roc_auc 0.75077 prc_auc 0.85865[0m
[92maverage training of epoch 9: loss -2.72903 acc 0.66667 roc_auc 0.47680 prc_auc 0.68729[0m
[93maverage test of epoch 9: loss -2.79389 acc 0.65789 roc_auc 0.48308 prc_auc 0.64002[0m
[92maverage training of epoch 10: loss -2.89087 acc 0.66667 roc_auc 0.45540 prc_auc 0.64432[0m
[93maverage test of epoch 10: loss -2.94477 acc 0.65789 roc_auc 0.36000 prc_auc 0.60945[0m
[92maverage training of epoch 11: loss -3.04560 acc 0.66667 roc_auc 0.47680 prc_auc 0.65052[0m
[93maverage test of epoch 11: loss -3.10344 acc 0.65789 roc_auc 0.48615 prc_auc 0.70973[0m
[92maverage training of epoch 12: loss -3.18601 acc 0.66667 roc_auc 0.47160 prc_auc 0.65659[0m
[93maverage test of epoch 12: loss -3.22337 acc 0.65789 roc_auc 0.30769 prc_auc 0.57172[0m
[92maverage training of epoch 13: loss -3.31059 acc 0.66667 roc_auc 0.50540 prc_auc 0.68040[0m
[93maverage test of epoch 13: loss -3.35925 acc 0.65789 roc_auc 0.46462 prc_auc 0.62261[0m
[92maverage training of epoch 14: loss -3.43381 acc 0.66667 roc_auc 0.46460 prc_auc 0.66272[0m
[93maverage test of epoch 14: loss -3.48692 acc 0.65789 roc_auc 0.57231 prc_auc 0.76085[0m
[92maverage training of epoch 15: loss -3.55043 acc 0.66667 roc_auc 0.48340 prc_auc 0.67101[0m
[93maverage test of epoch 15: loss -3.59523 acc 0.65789 roc_auc 0.35385 prc_auc 0.59421[0m
[92maverage training of epoch 16: loss -3.67802 acc 0.66667 roc_auc 0.48660 prc_auc 0.66948[0m
[93maverage test of epoch 16: loss -3.72152 acc 0.65789 roc_auc 0.60923 prc_auc 0.75410[0m
[92maverage training of epoch 17: loss -3.80038 acc 0.66667 roc_auc 0.45680 prc_auc 0.65686[0m
[93maverage test of epoch 17: loss -3.84708 acc 0.65789 roc_auc 0.47077 prc_auc 0.70437[0m
[92maverage training of epoch 18: loss -3.93714 acc 0.66667 roc_auc 0.43420 prc_auc 0.64185[0m
[93maverage test of epoch 18: loss -3.98929 acc 0.65789 roc_auc 0.43692 prc_auc 0.66430[0m
[92maverage training of epoch 19: loss -4.07169 acc 0.66667 roc_auc 0.46620 prc_auc 0.66782[0m
[93maverage test of epoch 19: loss -4.11295 acc 0.65789 roc_auc 0.40615 prc_auc 0.63766[0m
[92maverage training of epoch 20: loss -4.19429 acc 0.66667 roc_auc 0.47200 prc_auc 0.68089[0m
[93maverage test of epoch 20: loss -4.22920 acc 0.65789 roc_auc 0.58769 prc_auc 0.76269[0m
[92maverage training of epoch 21: loss -4.32150 acc 0.66667 roc_auc 0.49900 prc_auc 0.67348[0m
[93maverage test of epoch 21: loss -4.36765 acc 0.65789 roc_auc 0.69538 prc_auc 0.75804[0m
[92maverage training of epoch 22: loss -4.43634 acc 0.66667 roc_auc 0.45460 prc_auc 0.65351[0m
[93maverage test of epoch 22: loss -4.48376 acc 0.65789 roc_auc 0.68923 prc_auc 0.84973[0m
[92maverage training of epoch 23: loss -4.56082 acc 0.66667 roc_auc 0.53160 prc_auc 0.68266[0m
[93maverage test of epoch 23: loss -4.60166 acc 0.65789 roc_auc 0.59077 prc_auc 0.80570[0m
[92maverage training of epoch 24: loss -4.67022 acc 0.66667 roc_auc 0.43900 prc_auc 0.64184[0m
[93maverage test of epoch 24: loss -4.69650 acc 0.65789 roc_auc 0.44308 prc_auc 0.62077[0m
[92maverage training of epoch 25: loss -4.78228 acc 0.66667 roc_auc 0.39220 prc_auc 0.62187[0m
[93maverage test of epoch 25: loss -4.82486 acc 0.65789 roc_auc 0.61538 prc_auc 0.79299[0m
[92maverage training of epoch 26: loss -4.90126 acc 0.66667 roc_auc 0.50000 prc_auc 0.72152[0m
[93maverage test of epoch 26: loss -4.92751 acc 0.65789 roc_auc 0.47385 prc_auc 0.63020[0m
[92maverage training of epoch 27: loss -5.00463 acc 0.66667 roc_auc 0.39880 prc_auc 0.60857[0m
[93maverage test of epoch 27: loss -5.04189 acc 0.65789 roc_auc 0.37846 prc_auc 0.61167[0m
[92maverage training of epoch 28: loss -5.12516 acc 0.66667 roc_auc 0.48040 prc_auc 0.65384[0m
[93maverage test of epoch 28: loss -5.15903 acc 0.65789 roc_auc 0.64615 prc_auc 0.80398[0m
[92maverage training of epoch 29: loss -5.23441 acc 0.66667 roc_auc 0.54380 prc_auc 0.67965[0m
[93maverage test of epoch 29: loss -5.26671 acc 0.65789 roc_auc 0.56923 prc_auc 0.77029[0m
[92maverage training of epoch 30: loss -5.34237 acc 0.66667 roc_auc 0.46900 prc_auc 0.64060[0m
[93maverage test of epoch 30: loss -5.36933 acc 0.65789 roc_auc 0.28923 prc_auc 0.54357[0m
[92maverage training of epoch 31: loss -5.45248 acc 0.66667 roc_auc 0.47120 prc_auc 0.65309[0m
[93maverage test of epoch 31: loss -5.48853 acc 0.65789 roc_auc 0.50462 prc_auc 0.70349[0m
[92maverage training of epoch 32: loss -5.56184 acc 0.66667 roc_auc 0.47040 prc_auc 0.65599[0m
[93maverage test of epoch 32: loss -5.58792 acc 0.65789 roc_auc 0.55385 prc_auc 0.76159[0m
[92maverage training of epoch 33: loss -5.66473 acc 0.66667 roc_auc 0.40880 prc_auc 0.60552[0m
[93maverage test of epoch 33: loss -5.69749 acc 0.65789 roc_auc 0.50462 prc_auc 0.69607[0m
[92maverage training of epoch 34: loss -5.77382 acc 0.66667 roc_auc 0.39500 prc_auc 0.59524[0m
[93maverage test of epoch 34: loss -5.80164 acc 0.65789 roc_auc 0.52308 prc_auc 0.69769[0m
[92maverage training of epoch 35: loss -5.88298 acc 0.66667 roc_auc 0.46360 prc_auc 0.62597[0m
[93maverage test of epoch 35: loss -5.91346 acc 0.65789 roc_auc 0.51692 prc_auc 0.69441[0m
[92maverage training of epoch 36: loss -5.99213 acc 0.66667 roc_auc 0.49740 prc_auc 0.67729[0m
[93maverage test of epoch 36: loss -6.01793 acc 0.65789 roc_auc 0.38154 prc_auc 0.61952[0m
[92maverage training of epoch 37: loss -6.09474 acc 0.66667 roc_auc 0.45200 prc_auc 0.66031[0m
[93maverage test of epoch 37: loss -6.12680 acc 0.65789 roc_auc 0.63385 prc_auc 0.72753[0m
[92maverage training of epoch 38: loss -6.20507 acc 0.66667 roc_auc 0.47660 prc_auc 0.65989[0m
[93maverage test of epoch 38: loss -6.23654 acc 0.65789 roc_auc 0.72000 prc_auc 0.80739[0m
[92maverage training of epoch 39: loss -6.30589 acc 0.66667 roc_auc 0.48700 prc_auc 0.66332[0m
[93maverage test of epoch 39: loss -6.32694 acc 0.65789 roc_auc 0.50769 prc_auc 0.72285[0m
[92maverage training of epoch 40: loss -6.40927 acc 0.66667 roc_auc 0.43800 prc_auc 0.62424[0m
[93maverage test of epoch 40: loss -6.43664 acc 0.65789 roc_auc 0.64615 prc_auc 0.78848[0m
[92maverage training of epoch 41: loss -6.51630 acc 0.66667 roc_auc 0.46880 prc_auc 0.63287[0m
[93maverage test of epoch 41: loss -6.54693 acc 0.65789 roc_auc 0.65231 prc_auc 0.80787[0m
[92maverage training of epoch 42: loss -6.62139 acc 0.66667 roc_auc 0.44080 prc_auc 0.61310[0m
[93maverage test of epoch 42: loss -6.63651 acc 0.65789 roc_auc 0.43077 prc_auc 0.63568[0m
[92maverage training of epoch 43: loss -6.72071 acc 0.66667 roc_auc 0.38380 prc_auc 0.60228[0m
[93maverage test of epoch 43: loss -6.74296 acc 0.65789 roc_auc 0.48615 prc_auc 0.66840[0m
[92maverage training of epoch 44: loss -6.82710 acc 0.66667 roc_auc 0.44440 prc_auc 0.63438[0m
[93maverage test of epoch 44: loss -6.85020 acc 0.65789 roc_auc 0.58462 prc_auc 0.78655[0m
[92maverage training of epoch 45: loss -6.93198 acc 0.66667 roc_auc 0.41100 prc_auc 0.59465[0m
[93maverage test of epoch 45: loss -6.95495 acc 0.65789 roc_auc 0.54769 prc_auc 0.69951[0m
[92maverage training of epoch 46: loss -7.03840 acc 0.66667 roc_auc 0.45220 prc_auc 0.62727[0m
[93maverage test of epoch 46: loss -7.05443 acc 0.65789 roc_auc 0.51077 prc_auc 0.66986[0m
[92maverage training of epoch 47: loss -7.13782 acc 0.66667 roc_auc 0.41700 prc_auc 0.60841[0m
[93maverage test of epoch 47: loss -7.15680 acc 0.65789 roc_auc 0.47385 prc_auc 0.63217[0m
[92maverage training of epoch 48: loss -7.24460 acc 0.66667 roc_auc 0.46600 prc_auc 0.64901[0m
[93maverage test of epoch 48: loss -7.26268 acc 0.65789 roc_auc 0.60923 prc_auc 0.79356[0m
[92maverage training of epoch 49: loss -7.34461 acc 0.66667 roc_auc 0.34460 prc_auc 0.59386[0m
[93maverage test of epoch 49: loss -7.35752 acc 0.65789 roc_auc 0.52308 prc_auc 0.73835[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.32861 acc 0.42667 roc_auc 0.56560 prc_auc 0.72074[0m
[93maverage test of epoch 0: loss -0.52392 acc 0.63158 roc_auc 0.57231 prc_auc 0.74159[0m
[92maverage training of epoch 1: loss -0.68447 acc 0.68000 roc_auc 0.49340 prc_auc 0.66566[0m
[93maverage test of epoch 1: loss -0.87194 acc 0.65789 roc_auc 0.64000 prc_auc 0.77186[0m
[92maverage training of epoch 2: loss -1.04014 acc 0.66667 roc_auc 0.43760 prc_auc 0.66212[0m
[93maverage test of epoch 2: loss -1.22169 acc 0.65789 roc_auc 0.46769 prc_auc 0.67745[0m
[92maverage training of epoch 3: loss -1.41426 acc 0.66667 roc_auc 0.51560 prc_auc 0.68208[0m
[93maverage test of epoch 3: loss -1.61252 acc 0.65789 roc_auc 0.49846 prc_auc 0.69442[0m
[92maverage training of epoch 4: loss -1.83747 acc 0.66667 roc_auc 0.50980 prc_auc 0.67378[0m
[93maverage test of epoch 4: loss -2.05576 acc 0.65789 roc_auc 0.58462 prc_auc 0.73089[0m
[92maverage training of epoch 5: loss -2.31186 acc 0.66667 roc_auc 0.48040 prc_auc 0.66327[0m
[93maverage test of epoch 5: loss -2.50970 acc 0.65789 roc_auc 0.52923 prc_auc 0.73252[0m
[92maverage training of epoch 6: loss -2.73250 acc 0.66667 roc_auc 0.45260 prc_auc 0.63996[0m
[93maverage test of epoch 6: loss -2.88963 acc 0.65789 roc_auc 0.47077 prc_auc 0.69558[0m
[92maverage training of epoch 7: loss -3.07291 acc 0.66667 roc_auc 0.42400 prc_auc 0.62487[0m
[93maverage test of epoch 7: loss -3.21948 acc 0.65789 roc_auc 0.66769 prc_auc 0.81678[0m
[92maverage training of epoch 8: loss -3.35527 acc 0.66667 roc_auc 0.44660 prc_auc 0.62443[0m
[93maverage test of epoch 8: loss -3.45171 acc 0.65789 roc_auc 0.35692 prc_auc 0.57818[0m
[92maverage training of epoch 9: loss -3.59016 acc 0.66667 roc_auc 0.48260 prc_auc 0.70182[0m
[93maverage test of epoch 9: loss -3.67243 acc 0.65789 roc_auc 0.50154 prc_auc 0.73484[0m
[92maverage training of epoch 10: loss -3.78720 acc 0.66667 roc_auc 0.45200 prc_auc 0.66516[0m
[93maverage test of epoch 10: loss -3.84671 acc 0.65789 roc_auc 0.38769 prc_auc 0.66962[0m
[92maverage training of epoch 11: loss -3.98410 acc 0.66667 roc_auc 0.50560 prc_auc 0.67536[0m
[93maverage test of epoch 11: loss -4.04188 acc 0.65789 roc_auc 0.56615 prc_auc 0.69510[0m
[92maverage training of epoch 12: loss -4.16492 acc 0.66667 roc_auc 0.51080 prc_auc 0.69343[0m
[93maverage test of epoch 12: loss -4.23361 acc 0.65789 roc_auc 0.56615 prc_auc 0.68933[0m
[92maverage training of epoch 13: loss -4.35189 acc 0.66667 roc_auc 0.47440 prc_auc 0.67327[0m
[93maverage test of epoch 13: loss -4.41541 acc 0.65789 roc_auc 0.34462 prc_auc 0.58093[0m
[92maverage training of epoch 14: loss -4.55840 acc 0.66667 roc_auc 0.50520 prc_auc 0.70899[0m
[93maverage test of epoch 14: loss -4.61988 acc 0.65789 roc_auc 0.46154 prc_auc 0.63855[0m
[92maverage training of epoch 15: loss -4.75400 acc 0.66667 roc_auc 0.40100 prc_auc 0.63233[0m
[93maverage test of epoch 15: loss -4.82342 acc 0.65789 roc_auc 0.44308 prc_auc 0.69621[0m
[92maverage training of epoch 16: loss -4.94530 acc 0.66667 roc_auc 0.43210 prc_auc 0.61374[0m
[93maverage test of epoch 16: loss -5.00161 acc 0.65789 roc_auc 0.69538 prc_auc 0.82284[0m
[92maverage training of epoch 17: loss -5.10929 acc 0.66667 roc_auc 0.48370 prc_auc 0.65117[0m
[93maverage test of epoch 17: loss -5.14955 acc 0.65789 roc_auc 0.52308 prc_auc 0.72187[0m
[92maverage training of epoch 18: loss -5.26407 acc 0.66667 roc_auc 0.47460 prc_auc 0.63928[0m
[93maverage test of epoch 18: loss -5.29007 acc 0.65789 roc_auc 0.60923 prc_auc 0.73622[0m
[92maverage training of epoch 19: loss -5.39889 acc 0.66667 roc_auc 0.49740 prc_auc 0.66624[0m
[93maverage test of epoch 19: loss -5.43926 acc 0.65789 roc_auc 0.48308 prc_auc 0.69276[0m
[92maverage training of epoch 20: loss -5.52901 acc 0.66667 roc_auc 0.44640 prc_auc 0.62900[0m
[93maverage test of epoch 20: loss -5.55218 acc 0.65789 roc_auc 0.48000 prc_auc 0.62252[0m
[92maverage training of epoch 21: loss -5.65263 acc 0.66667 roc_auc 0.50210 prc_auc 0.63973[0m
[93maverage test of epoch 21: loss -5.67818 acc 0.65789 roc_auc 0.54769 prc_auc 0.73587[0m
[92maverage training of epoch 22: loss -5.77275 acc 0.66667 roc_auc 0.46660 prc_auc 0.65084[0m
[93maverage test of epoch 22: loss -5.79861 acc 0.65789 roc_auc 0.46154 prc_auc 0.62505[0m
[92maverage training of epoch 23: loss -5.88877 acc 0.66667 roc_auc 0.42580 prc_auc 0.63420[0m
[93maverage test of epoch 23: loss -5.91250 acc 0.65789 roc_auc 0.43385 prc_auc 0.67661[0m
[92maverage training of epoch 24: loss -6.00846 acc 0.66667 roc_auc 0.47290 prc_auc 0.63425[0m
[93maverage test of epoch 24: loss -6.03553 acc 0.65789 roc_auc 0.65538 prc_auc 0.79640[0m
[92maverage training of epoch 25: loss -6.12601 acc 0.66667 roc_auc 0.45160 prc_auc 0.63491[0m
[93maverage test of epoch 25: loss -6.13465 acc 0.65789 roc_auc 0.52154 prc_auc 0.69787[0m
[92maverage training of epoch 26: loss -6.23752 acc 0.66667 roc_auc 0.53650 prc_auc 0.72919[0m
[93maverage test of epoch 26: loss -6.24611 acc 0.65789 roc_auc 0.69231 prc_auc 0.79800[0m
[92maverage training of epoch 27: loss -6.34921 acc 0.66667 roc_auc 0.40950 prc_auc 0.62297[0m
[93maverage test of epoch 27: loss -6.35854 acc 0.65789 roc_auc 0.32923 prc_auc 0.62674[0m
[92maverage training of epoch 28: loss -6.45903 acc 0.66667 roc_auc 0.50460 prc_auc 0.69106[0m
[93maverage test of epoch 28: loss -6.47449 acc 0.65789 roc_auc 0.68615 prc_auc 0.78446[0m
[92maverage training of epoch 29: loss -6.56972 acc 0.66667 roc_auc 0.47520 prc_auc 0.66609[0m
[93maverage test of epoch 29: loss -6.57914 acc 0.65789 roc_auc 0.40154 prc_auc 0.62397[0m
[92maverage training of epoch 30: loss -6.67665 acc 0.66667 roc_auc 0.50900 prc_auc 0.66577[0m
[93maverage test of epoch 30: loss -6.69030 acc 0.65789 roc_auc 0.61692 prc_auc 0.71678[0m
[92maverage training of epoch 31: loss -6.78093 acc 0.66667 roc_auc 0.44540 prc_auc 0.62270[0m
[93maverage test of epoch 31: loss -6.79368 acc 0.65789 roc_auc 0.37846 prc_auc 0.58924[0m
[92maverage training of epoch 32: loss -6.88970 acc 0.66667 roc_auc 0.46640 prc_auc 0.66603[0m
[93maverage test of epoch 32: loss -6.89676 acc 0.65789 roc_auc 0.43385 prc_auc 0.61950[0m
[92maverage training of epoch 33: loss -6.99055 acc 0.66667 roc_auc 0.47180 prc_auc 0.64271[0m
[93maverage test of epoch 33: loss -7.00532 acc 0.65789 roc_auc 0.47077 prc_auc 0.62990[0m
[92maverage training of epoch 34: loss -7.09463 acc 0.66667 roc_auc 0.44640 prc_auc 0.62706[0m
[93maverage test of epoch 34: loss -7.11217 acc 0.65789 roc_auc 0.41846 prc_auc 0.60186[0m
[92maverage training of epoch 35: loss -7.20066 acc 0.66667 roc_auc 0.42740 prc_auc 0.61071[0m
[93maverage test of epoch 35: loss -7.21124 acc 0.65789 roc_auc 0.35385 prc_auc 0.62010[0m
[92maverage training of epoch 36: loss -7.30536 acc 0.66667 roc_auc 0.44720 prc_auc 0.63957[0m
[93maverage test of epoch 36: loss -7.31765 acc 0.65789 roc_auc 0.53231 prc_auc 0.70337[0m
[92maverage training of epoch 37: loss -7.41003 acc 0.66667 roc_auc 0.41970 prc_auc 0.60697[0m
[93maverage test of epoch 37: loss -7.41460 acc 0.65789 roc_auc 0.68615 prc_auc 0.76151[0m
[92maverage training of epoch 38: loss -7.51348 acc 0.66667 roc_auc 0.48300 prc_auc 0.64771[0m
[93maverage test of epoch 38: loss -7.52213 acc 0.65789 roc_auc 0.55077 prc_auc 0.72966[0m
[92maverage training of epoch 39: loss -7.61474 acc 0.66667 roc_auc 0.43180 prc_auc 0.62365[0m
[93maverage test of epoch 39: loss -7.62170 acc 0.65789 roc_auc 0.52000 prc_auc 0.66491[0m
[92maverage training of epoch 40: loss -7.71697 acc 0.66667 roc_auc 0.41560 prc_auc 0.64154[0m
[93maverage test of epoch 40: loss -7.72326 acc 0.65789 roc_auc 0.45846 prc_auc 0.66376[0m
[92maverage training of epoch 41: loss -7.81917 acc 0.66667 roc_auc 0.47910 prc_auc 0.65809[0m
[93maverage test of epoch 41: loss -7.82724 acc 0.65789 roc_auc 0.61846 prc_auc 0.77428[0m
[92maverage training of epoch 42: loss -7.92310 acc 0.66667 roc_auc 0.49820 prc_auc 0.65577[0m
[93maverage test of epoch 42: loss -7.93000 acc 0.65789 roc_auc 0.55692 prc_auc 0.74159[0m
[92maverage training of epoch 43: loss -8.02519 acc 0.66667 roc_auc 0.46000 prc_auc 0.64546[0m
[93maverage test of epoch 43: loss -8.03121 acc 0.65789 roc_auc 0.50615 prc_auc 0.70880[0m
[92maverage training of epoch 44: loss -8.12517 acc 0.66667 roc_auc 0.43930 prc_auc 0.61224[0m
[93maverage test of epoch 44: loss -8.13313 acc 0.65789 roc_auc 0.38462 prc_auc 0.61116[0m
[92maverage training of epoch 45: loss -8.22686 acc 0.66667 roc_auc 0.42440 prc_auc 0.59698[0m
[93maverage test of epoch 45: loss -8.23031 acc 0.65789 roc_auc 0.32154 prc_auc 0.57292[0m
[92maverage training of epoch 46: loss -8.32863 acc 0.66667 roc_auc 0.45790 prc_auc 0.62762[0m
[93maverage test of epoch 46: loss -8.33187 acc 0.65789 roc_auc 0.63538 prc_auc 0.80734[0m
[92maverage training of epoch 47: loss -8.43062 acc 0.66667 roc_auc 0.42200 prc_auc 0.60592[0m
[93maverage test of epoch 47: loss -8.43163 acc 0.65789 roc_auc 0.50615 prc_auc 0.69798[0m
[92maverage training of epoch 48: loss -8.52976 acc 0.66667 roc_auc 0.45890 prc_auc 0.63826[0m
[93maverage test of epoch 48: loss -8.53398 acc 0.65789 roc_auc 0.51538 prc_auc 0.71421[0m
[92maverage training of epoch 49: loss -8.63099 acc 0.66667 roc_auc 0.45280 prc_auc 0.63025[0m
[93maverage test of epoch 49: loss -8.63587 acc 0.65789 roc_auc 0.36923 prc_auc 0.59009[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss 0.55071 acc 0.42000 roc_auc 0.45900 prc_auc 0.68722[0m
[93maverage test of epoch 0: loss 0.35856 acc 0.57895 roc_auc 0.63385 prc_auc 0.76388[0m
[92maverage training of epoch 1: loss 0.14385 acc 0.66667 roc_auc 0.47480 prc_auc 0.65548[0m
[93maverage test of epoch 1: loss -0.10544 acc 0.65789 roc_auc 0.72923 prc_auc 0.81399[0m
[92maverage training of epoch 2: loss -0.32733 acc 0.66667 roc_auc 0.51240 prc_auc 0.72065[0m
[93maverage test of epoch 2: loss -0.55246 acc 0.65789 roc_auc 0.68923 prc_auc 0.82954[0m
[92maverage training of epoch 3: loss -0.75708 acc 0.66667 roc_auc 0.48160 prc_auc 0.68139[0m
[93maverage test of epoch 3: loss -0.94925 acc 0.65789 roc_auc 0.64308 prc_auc 0.80512[0m
[92maverage training of epoch 4: loss -1.13098 acc 0.66667 roc_auc 0.47840 prc_auc 0.67076[0m
[93maverage test of epoch 4: loss -1.29765 acc 0.65789 roc_auc 0.54154 prc_auc 0.71847[0m
[92maverage training of epoch 5: loss -1.49141 acc 0.66667 roc_auc 0.50720 prc_auc 0.71488[0m
[93maverage test of epoch 5: loss -1.67226 acc 0.65789 roc_auc 0.52000 prc_auc 0.70365[0m
[92maverage training of epoch 6: loss -1.90584 acc 0.66667 roc_auc 0.46080 prc_auc 0.64455[0m
[93maverage test of epoch 6: loss -2.15058 acc 0.65789 roc_auc 0.58769 prc_auc 0.76595[0m
[92maverage training of epoch 7: loss -2.37388 acc 0.66667 roc_auc 0.44840 prc_auc 0.63732[0m
[93maverage test of epoch 7: loss -2.57016 acc 0.65789 roc_auc 0.44000 prc_auc 0.64990[0m
[92maverage training of epoch 8: loss -2.75496 acc 0.66667 roc_auc 0.44320 prc_auc 0.61575[0m
[93maverage test of epoch 8: loss -2.91621 acc 0.65789 roc_auc 0.39077 prc_auc 0.59998[0m
[92maverage training of epoch 9: loss -3.07379 acc 0.66667 roc_auc 0.40240 prc_auc 0.59544[0m
[93maverage test of epoch 9: loss -3.19453 acc 0.65789 roc_auc 0.44615 prc_auc 0.62094[0m
[92maverage training of epoch 10: loss -3.33179 acc 0.66667 roc_auc 0.43600 prc_auc 0.61060[0m
[93maverage test of epoch 10: loss -3.41522 acc 0.65789 roc_auc 0.56923 prc_auc 0.78612[0m
[92maverage training of epoch 11: loss -3.54944 acc 0.66667 roc_auc 0.48060 prc_auc 0.67404[0m
[93maverage test of epoch 11: loss -3.60616 acc 0.65789 roc_auc 0.49538 prc_auc 0.68532[0m
[92maverage training of epoch 12: loss -3.72418 acc 0.66667 roc_auc 0.55680 prc_auc 0.70368[0m
[93maverage test of epoch 12: loss -3.75870 acc 0.65789 roc_auc 0.39385 prc_auc 0.65316[0m
[92maverage training of epoch 13: loss -3.86294 acc 0.66667 roc_auc 0.47080 prc_auc 0.66947[0m
[93maverage test of epoch 13: loss -3.90791 acc 0.65789 roc_auc 0.44615 prc_auc 0.67700[0m
[92maverage training of epoch 14: loss -4.00308 acc 0.66667 roc_auc 0.39000 prc_auc 0.57905[0m
[93maverage test of epoch 14: loss -4.05768 acc 0.65789 roc_auc 0.59077 prc_auc 0.69117[0m
[92maverage training of epoch 15: loss -4.15305 acc 0.66667 roc_auc 0.50480 prc_auc 0.68455[0m
[93maverage test of epoch 15: loss -4.19061 acc 0.65789 roc_auc 0.63385 prc_auc 0.78005[0m
[92maverage training of epoch 16: loss -4.26876 acc 0.66667 roc_auc 0.43840 prc_auc 0.65204[0m
[93maverage test of epoch 16: loss -4.33018 acc 0.65789 roc_auc 0.58154 prc_auc 0.70128[0m
[92maverage training of epoch 17: loss -4.41907 acc 0.66667 roc_auc 0.47260 prc_auc 0.65907[0m
[93maverage test of epoch 17: loss -4.45728 acc 0.65789 roc_auc 0.34769 prc_auc 0.58602[0m
[92maverage training of epoch 18: loss -4.56263 acc 0.66667 roc_auc 0.46660 prc_auc 0.62965[0m
[93maverage test of epoch 18: loss -4.59804 acc 0.65789 roc_auc 0.45231 prc_auc 0.69981[0m
[92maverage training of epoch 19: loss -4.73262 acc 0.66667 roc_auc 0.53660 prc_auc 0.68459[0m
[93maverage test of epoch 19: loss -4.79499 acc 0.65789 roc_auc 0.54769 prc_auc 0.74772[0m
[92maverage training of epoch 20: loss -4.89769 acc 0.66667 roc_auc 0.37860 prc_auc 0.59598[0m
[93maverage test of epoch 20: loss -4.97086 acc 0.65789 roc_auc 0.67385 prc_auc 0.76517[0m
[92maverage training of epoch 21: loss -5.08387 acc 0.66667 roc_auc 0.50340 prc_auc 0.67495[0m
[93maverage test of epoch 21: loss -5.14134 acc 0.65789 roc_auc 0.45846 prc_auc 0.62062[0m
[92maverage training of epoch 22: loss -5.25986 acc 0.66667 roc_auc 0.50560 prc_auc 0.68195[0m
[93maverage test of epoch 22: loss -5.30083 acc 0.65789 roc_auc 0.21846 prc_auc 0.58618[0m
[92maverage training of epoch 23: loss -5.43878 acc 0.66667 roc_auc 0.52700 prc_auc 0.68554[0m
[93maverage test of epoch 23: loss -5.47716 acc 0.65789 roc_auc 0.51692 prc_auc 0.73291[0m
[92maverage training of epoch 24: loss -5.57763 acc 0.66667 roc_auc 0.40130 prc_auc 0.59732[0m
[93maverage test of epoch 24: loss -5.61902 acc 0.65789 roc_auc 0.48308 prc_auc 0.68075[0m
[92maverage training of epoch 25: loss -5.73086 acc 0.66667 roc_auc 0.57120 prc_auc 0.69744[0m
[93maverage test of epoch 25: loss -5.75028 acc 0.65789 roc_auc 0.54462 prc_auc 0.66058[0m
[92maverage training of epoch 26: loss -5.86054 acc 0.66667 roc_auc 0.42400 prc_auc 0.63029[0m
[93maverage test of epoch 26: loss -5.87640 acc 0.65789 roc_auc 0.35077 prc_auc 0.57070[0m
[92maverage training of epoch 27: loss -5.97721 acc 0.66667 roc_auc 0.48020 prc_auc 0.66776[0m
[93maverage test of epoch 27: loss -6.01230 acc 0.65789 roc_auc 0.55692 prc_auc 0.67087[0m
[92maverage training of epoch 28: loss -6.10437 acc 0.66667 roc_auc 0.50420 prc_auc 0.68672[0m
[93maverage test of epoch 28: loss -6.13006 acc 0.65789 roc_auc 0.53846 prc_auc 0.71113[0m
[92maverage training of epoch 29: loss -6.21627 acc 0.66667 roc_auc 0.42920 prc_auc 0.62344[0m
[93maverage test of epoch 29: loss -6.23086 acc 0.65789 roc_auc 0.51385 prc_auc 0.69163[0m
[92maverage training of epoch 30: loss -6.33137 acc 0.66667 roc_auc 0.43580 prc_auc 0.63090[0m
[93maverage test of epoch 30: loss -6.35849 acc 0.65789 roc_auc 0.48923 prc_auc 0.64014[0m
[92maverage training of epoch 31: loss -6.43378 acc 0.66667 roc_auc 0.44500 prc_auc 0.63844[0m
[93maverage test of epoch 31: loss -6.46567 acc 0.65789 roc_auc 0.55385 prc_auc 0.68282[0m
[92maverage training of epoch 32: loss -6.53907 acc 0.66667 roc_auc 0.43390 prc_auc 0.62050[0m
[93maverage test of epoch 32: loss -6.56516 acc 0.65789 roc_auc 0.55077 prc_auc 0.67891[0m
[92maverage training of epoch 33: loss -6.64511 acc 0.66667 roc_auc 0.49220 prc_auc 0.67431[0m
[93maverage test of epoch 33: loss -6.66302 acc 0.65789 roc_auc 0.56308 prc_auc 0.66968[0m
[92maverage training of epoch 34: loss -6.74423 acc 0.66667 roc_auc 0.43480 prc_auc 0.62366[0m
[93maverage test of epoch 34: loss -6.76048 acc 0.65789 roc_auc 0.47692 prc_auc 0.70832[0m
[92maverage training of epoch 35: loss -6.84140 acc 0.66667 roc_auc 0.47540 prc_auc 0.65800[0m
[93maverage test of epoch 35: loss -6.85497 acc 0.65789 roc_auc 0.52923 prc_auc 0.73591[0m
[92maverage training of epoch 36: loss -6.94660 acc 0.66667 roc_auc 0.54280 prc_auc 0.73983[0m
[93maverage test of epoch 36: loss -6.96272 acc 0.65789 roc_auc 0.46154 prc_auc 0.62748[0m
[92maverage training of epoch 37: loss -7.04968 acc 0.66667 roc_auc 0.55210 prc_auc 0.72424[0m
[93maverage test of epoch 37: loss -7.06802 acc 0.65789 roc_auc 0.55077 prc_auc 0.70007[0m
[92maverage training of epoch 38: loss -7.14985 acc 0.66667 roc_auc 0.45440 prc_auc 0.64197[0m
[93maverage test of epoch 38: loss -7.15789 acc 0.65789 roc_auc 0.45538 prc_auc 0.67731[0m
[92maverage training of epoch 39: loss -7.24797 acc 0.66667 roc_auc 0.53460 prc_auc 0.71739[0m
[93maverage test of epoch 39: loss -7.26202 acc 0.65789 roc_auc 0.54462 prc_auc 0.73290[0m
[92maverage training of epoch 40: loss -7.34221 acc 0.66667 roc_auc 0.44270 prc_auc 0.63142[0m
[93maverage test of epoch 40: loss -7.36654 acc 0.65789 roc_auc 0.57846 prc_auc 0.74849[0m
[92maverage training of epoch 41: loss -7.44855 acc 0.66667 roc_auc 0.55680 prc_auc 0.71575[0m
[93maverage test of epoch 41: loss -7.46275 acc 0.65789 roc_auc 0.59077 prc_auc 0.76246[0m
[92maverage training of epoch 42: loss -7.54091 acc 0.66667 roc_auc 0.43980 prc_auc 0.63698[0m
[93maverage test of epoch 42: loss -7.55808 acc 0.65789 roc_auc 0.46462 prc_auc 0.70006[0m
[92maverage training of epoch 43: loss -7.64541 acc 0.66667 roc_auc 0.50960 prc_auc 0.69343[0m
[93maverage test of epoch 43: loss -7.65917 acc 0.65789 roc_auc 0.46769 prc_auc 0.62129[0m
[92maverage training of epoch 44: loss -7.74407 acc 0.66667 roc_auc 0.52610 prc_auc 0.66872[0m
[93maverage test of epoch 44: loss -7.76419 acc 0.65789 roc_auc 0.53231 prc_auc 0.67761[0m
[92maverage training of epoch 45: loss -7.84820 acc 0.66667 roc_auc 0.57660 prc_auc 0.70540[0m
[93maverage test of epoch 45: loss -7.86586 acc 0.65789 roc_auc 0.54462 prc_auc 0.71122[0m
[92maverage training of epoch 46: loss -7.94124 acc 0.66667 roc_auc 0.41940 prc_auc 0.63620[0m
[93maverage test of epoch 46: loss -7.96079 acc 0.65789 roc_auc 0.38462 prc_auc 0.66166[0m
[92maverage training of epoch 47: loss -8.04712 acc 0.66667 roc_auc 0.49620 prc_auc 0.66803[0m
[93maverage test of epoch 47: loss -8.05973 acc 0.65789 roc_auc 0.44308 prc_auc 0.65233[0m
[92maverage training of epoch 48: loss -8.15290 acc 0.66667 roc_auc 0.50260 prc_auc 0.68066[0m
[93maverage test of epoch 48: loss -8.16910 acc 0.65789 roc_auc 0.55692 prc_auc 0.69963[0m
[92maverage training of epoch 49: loss -8.25421 acc 0.66667 roc_auc 0.55420 prc_auc 0.69656[0m
[93maverage test of epoch 49: loss -8.27687 acc 0.65789 roc_auc 0.58769 prc_auc 0.68515[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.06000 acc 0.33775 roc_auc 0.42490 prc_auc 0.61394[0m
[93maverage test of epoch 0: loss -0.13218 acc 0.32432 roc_auc 0.36667 prc_auc 0.68085[0m
[92maverage training of epoch 1: loss -0.23126 acc 0.33775 roc_auc 0.44451 prc_auc 0.63033[0m
[93maverage test of epoch 1: loss -0.30115 acc 0.32432 roc_auc 0.48667 prc_auc 0.70444[0m
[92maverage training of epoch 2: loss -0.38230 acc 0.34437 roc_auc 0.48039 prc_auc 0.65736[0m
[93maverage test of epoch 2: loss -0.45661 acc 0.35135 roc_auc 0.57000 prc_auc 0.73082[0m
[92maverage training of epoch 3: loss -0.51534 acc 0.38411 roc_auc 0.49980 prc_auc 0.66327[0m
[93maverage test of epoch 3: loss -0.56505 acc 0.27027 roc_auc 0.48667 prc_auc 0.68980[0m
[92maverage training of epoch 4: loss -0.64388 acc 0.62252 roc_auc 0.55137 prc_auc 0.69439[0m
[93maverage test of epoch 4: loss -0.69830 acc 0.64865 roc_auc 0.55000 prc_auc 0.74767[0m
[92maverage training of epoch 5: loss -0.74716 acc 0.61589 roc_auc 0.48549 prc_auc 0.69478[0m
[93maverage test of epoch 5: loss -0.79110 acc 0.62162 roc_auc 0.38667 prc_auc 0.66837[0m
[92maverage training of epoch 6: loss -0.88131 acc 0.66225 roc_auc 0.50882 prc_auc 0.67427[0m
[93maverage test of epoch 6: loss -0.96612 acc 0.67568 roc_auc 0.58000 prc_auc 0.76816[0m
[92maverage training of epoch 7: loss -1.03400 acc 0.66225 roc_auc 0.50431 prc_auc 0.69925[0m
[93maverage test of epoch 7: loss -1.10787 acc 0.67568 roc_auc 0.50333 prc_auc 0.76028[0m
[92maverage training of epoch 8: loss -1.19294 acc 0.66225 roc_auc 0.54863 prc_auc 0.72092[0m
[93maverage test of epoch 8: loss -1.27838 acc 0.67568 roc_auc 0.51000 prc_auc 0.75989[0m
[92maverage training of epoch 9: loss -1.37556 acc 0.66225 roc_auc 0.58686 prc_auc 0.74514[0m
[93maverage test of epoch 9: loss -1.46773 acc 0.67568 roc_auc 0.54667 prc_auc 0.77417[0m
[92maverage training of epoch 10: loss -1.54289 acc 0.66225 roc_auc 0.61882 prc_auc 0.77185[0m
[93maverage test of epoch 10: loss -1.65343 acc 0.67568 roc_auc 0.61000 prc_auc 0.77742[0m
[92maverage training of epoch 11: loss -1.72829 acc 0.66225 roc_auc 0.65765 prc_auc 0.79963[0m
[93maverage test of epoch 11: loss -1.85027 acc 0.67568 roc_auc 0.67667 prc_auc 0.82771[0m
[92maverage training of epoch 12: loss -1.88306 acc 0.66225 roc_auc 0.64451 prc_auc 0.76379[0m
[93maverage test of epoch 12: loss -1.92948 acc 0.67568 roc_auc 0.48667 prc_auc 0.71768[0m
[92maverage training of epoch 13: loss -1.99582 acc 0.66225 roc_auc 0.54647 prc_auc 0.69999[0m
[93maverage test of epoch 13: loss -2.14184 acc 0.67568 roc_auc 0.67667 prc_auc 0.82676[0m
[92maverage training of epoch 14: loss -2.15729 acc 0.66225 roc_auc 0.57000 prc_auc 0.73270[0m
[93maverage test of epoch 14: loss -2.29281 acc 0.67568 roc_auc 0.68333 prc_auc 0.85037[0m
[92maverage training of epoch 15: loss -2.30085 acc 0.66225 roc_auc 0.64314 prc_auc 0.78214[0m
[93maverage test of epoch 15: loss -2.44154 acc 0.67568 roc_auc 0.68333 prc_auc 0.81382[0m
[92maverage training of epoch 16: loss -2.44324 acc 0.66225 roc_auc 0.66549 prc_auc 0.80413[0m
[93maverage test of epoch 16: loss -2.57943 acc 0.67568 roc_auc 0.75333 prc_auc 0.87612[0m
[92maverage training of epoch 17: loss -2.62667 acc 0.66225 roc_auc 0.81490 prc_auc 0.89206[0m
[93maverage test of epoch 17: loss -2.69730 acc 0.67568 roc_auc 0.69000 prc_auc 0.86698[0m
[92maverage training of epoch 18: loss -2.70943 acc 0.66225 roc_auc 0.67863 prc_auc 0.81371[0m
[93maverage test of epoch 18: loss -2.86505 acc 0.67568 roc_auc 0.76333 prc_auc 0.82816[0m
[92maverage training of epoch 19: loss -2.87004 acc 0.66225 roc_auc 0.80294 prc_auc 0.87976[0m
[93maverage test of epoch 19: loss -3.00122 acc 0.67568 roc_auc 0.75667 prc_auc 0.86337[0m
[92maverage training of epoch 20: loss -3.04796 acc 0.66225 roc_auc 0.82373 prc_auc 0.89810[0m
[93maverage test of epoch 20: loss -3.15789 acc 0.67568 roc_auc 0.74000 prc_auc 0.86676[0m
[92maverage training of epoch 21: loss -3.22140 acc 0.66225 roc_auc 0.83588 prc_auc 0.88871[0m
[93maverage test of epoch 21: loss -3.37530 acc 0.67568 roc_auc 0.80667 prc_auc 0.89031[0m
[92maverage training of epoch 22: loss -3.43705 acc 0.66225 roc_auc 0.88824 prc_auc 0.94848[0m
[93maverage test of epoch 22: loss -3.57540 acc 0.67568 roc_auc 0.82667 prc_auc 0.89773[0m
[92maverage training of epoch 23: loss -3.68579 acc 0.66225 roc_auc 0.91725 prc_auc 0.96209[0m
[93maverage test of epoch 23: loss -3.72813 acc 0.67568 roc_auc 0.84667 prc_auc 0.92384[0m
[92maverage training of epoch 24: loss -3.84786 acc 0.66887 roc_auc 0.89373 prc_auc 0.94572[0m
[93maverage test of epoch 24: loss -3.97569 acc 0.67568 roc_auc 0.88333 prc_auc 0.93432[0m
[92maverage training of epoch 25: loss -4.04047 acc 0.69536 roc_auc 0.89471 prc_auc 0.94383[0m
[93maverage test of epoch 25: loss -4.10799 acc 0.67568 roc_auc 0.85000 prc_auc 0.92058[0m
[92maverage training of epoch 26: loss -4.28901 acc 0.72848 roc_auc 0.92000 prc_auc 0.96027[0m
[93maverage test of epoch 26: loss -4.34142 acc 0.64865 roc_auc 0.87667 prc_auc 0.93683[0m
[92maverage training of epoch 27: loss -4.44317 acc 0.80132 roc_auc 0.91471 prc_auc 0.95262[0m
[93maverage test of epoch 27: loss -4.58412 acc 0.83784 roc_auc 0.89333 prc_auc 0.93590[0m
[92maverage training of epoch 28: loss -4.57557 acc 0.82119 roc_auc 0.91961 prc_auc 0.95446[0m
[93maverage test of epoch 28: loss -4.60639 acc 0.72973 roc_auc 0.83333 prc_auc 0.90918[0m
[92maverage training of epoch 29: loss -4.70101 acc 0.82781 roc_auc 0.92098 prc_auc 0.96249[0m
[93maverage test of epoch 29: loss -4.69023 acc 0.83784 roc_auc 0.88000 prc_auc 0.94404[0m
[92maverage training of epoch 30: loss -4.87295 acc 0.84768 roc_auc 0.92706 prc_auc 0.96558[0m
[93maverage test of epoch 30: loss -4.82888 acc 0.86486 roc_auc 0.84000 prc_auc 0.91697[0m
[92maverage training of epoch 31: loss -5.02515 acc 0.85430 roc_auc 0.92627 prc_auc 0.96458[0m
[93maverage test of epoch 31: loss -4.98582 acc 0.83784 roc_auc 0.83667 prc_auc 0.90978[0m
[92maverage training of epoch 32: loss -5.14549 acc 0.84768 roc_auc 0.92824 prc_auc 0.96230[0m
[93maverage test of epoch 32: loss -5.13266 acc 0.83784 roc_auc 0.82667 prc_auc 0.89584[0m
[92maverage training of epoch 33: loss -5.23949 acc 0.85430 roc_auc 0.93471 prc_auc 0.97074[0m
[93maverage test of epoch 33: loss -5.25844 acc 0.86486 roc_auc 0.85333 prc_auc 0.91981[0m
[92maverage training of epoch 34: loss -5.35904 acc 0.86755 roc_auc 0.93235 prc_auc 0.96901[0m
[93maverage test of epoch 34: loss -5.30407 acc 0.83784 roc_auc 0.83667 prc_auc 0.91349[0m
[92maverage training of epoch 35: loss -5.46728 acc 0.86093 roc_auc 0.92373 prc_auc 0.96858[0m
[93maverage test of epoch 35: loss -5.39739 acc 0.83784 roc_auc 0.80333 prc_auc 0.85323[0m
[92maverage training of epoch 36: loss -5.64210 acc 0.86093 roc_auc 0.93010 prc_auc 0.96802[0m
[93maverage test of epoch 36: loss -5.66947 acc 0.86486 roc_auc 0.84000 prc_auc 0.88372[0m
[92maverage training of epoch 37: loss -5.75146 acc 0.87417 roc_auc 0.92529 prc_auc 0.96697[0m
[93maverage test of epoch 37: loss -5.73801 acc 0.86486 roc_auc 0.83667 prc_auc 0.89527[0m
[92maverage training of epoch 38: loss -5.91893 acc 0.86755 roc_auc 0.93353 prc_auc 0.97000[0m
[93maverage test of epoch 38: loss -5.86422 acc 0.86486 roc_auc 0.81000 prc_auc 0.87356[0m
[92maverage training of epoch 39: loss -5.92874 acc 0.85430 roc_auc 0.92686 prc_auc 0.96558[0m
[93maverage test of epoch 39: loss -6.01548 acc 0.83784 roc_auc 0.89333 prc_auc 0.94056[0m
[92maverage training of epoch 40: loss -6.14065 acc 0.88079 roc_auc 0.94039 prc_auc 0.97366[0m
[93maverage test of epoch 40: loss -5.87838 acc 0.83784 roc_auc 0.83333 prc_auc 0.91390[0m
[92maverage training of epoch 41: loss -6.19146 acc 0.87417 roc_auc 0.93608 prc_auc 0.97417[0m
[93maverage test of epoch 41: loss -5.95423 acc 0.83784 roc_auc 0.87333 prc_auc 0.94272[0m
[92maverage training of epoch 42: loss -6.36229 acc 0.88079 roc_auc 0.92961 prc_auc 0.97116[0m
[93maverage test of epoch 42: loss -6.08044 acc 0.81081 roc_auc 0.83000 prc_auc 0.90616[0m
[92maverage training of epoch 43: loss -6.43803 acc 0.88742 roc_auc 0.93559 prc_auc 0.96506[0m
[93maverage test of epoch 43: loss -6.33907 acc 0.83784 roc_auc 0.87000 prc_auc 0.93815[0m
[92maverage training of epoch 44: loss -6.61377 acc 0.88742 roc_auc 0.95686 prc_auc 0.98160[0m
[93maverage test of epoch 44: loss -6.37027 acc 0.83784 roc_auc 0.87333 prc_auc 0.93827[0m
[92maverage training of epoch 45: loss -6.67254 acc 0.88742 roc_auc 0.93706 prc_auc 0.97239[0m
[93maverage test of epoch 45: loss -6.51031 acc 0.83784 roc_auc 0.79667 prc_auc 0.87407[0m
[92maverage training of epoch 46: loss -6.74905 acc 0.87417 roc_auc 0.94941 prc_auc 0.97192[0m
[93maverage test of epoch 46: loss -6.58466 acc 0.83784 roc_auc 0.82833 prc_auc 0.89324[0m
[92maverage training of epoch 47: loss -6.93188 acc 0.90728 roc_auc 0.94569 prc_auc 0.97793[0m
[93maverage test of epoch 47: loss -6.67834 acc 0.81081 roc_auc 0.90333 prc_auc 0.95684[0m
[92maverage training of epoch 48: loss -7.01897 acc 0.89404 roc_auc 0.93294 prc_auc 0.96179[0m
[93maverage test of epoch 48: loss -6.61602 acc 0.83784 roc_auc 0.80500 prc_auc 0.88786[0m
[92maverage training of epoch 49: loss -7.10650 acc 0.90728 roc_auc 0.96039 prc_auc 0.98171[0m
[93maverage test of epoch 49: loss -6.80520 acc 0.83784 roc_auc 0.86667 prc_auc 0.93848[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 8, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=8, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss 0.44140 acc 0.45033 roc_auc 0.47588 prc_auc 0.66368[0m
[93maverage test of epoch 0: loss 0.16635 acc 0.67568 roc_auc 0.32333 prc_auc 0.57096[0m
[92maverage training of epoch 1: loss -0.15909 acc 0.66225 roc_auc 0.45235 prc_auc 0.62185[0m
[93maverage test of epoch 1: loss -0.44620 acc 0.67568 roc_auc 0.25000 prc_auc 0.56975[0m
[92maverage training of epoch 2: loss -0.64141 acc 0.66225 roc_auc 0.51824 prc_auc 0.67510[0m
[93maverage test of epoch 2: loss -0.84228 acc 0.67568 roc_auc 0.35333 prc_auc 0.67552[0m
[92maverage training of epoch 3: loss -0.99974 acc 0.66225 roc_auc 0.41196 prc_auc 0.61481[0m
[93maverage test of epoch 3: loss -1.17824 acc 0.67568 roc_auc 0.62333 prc_auc 0.76538[0m
[92maverage training of epoch 4: loss -1.24889 acc 0.66225 roc_auc 0.44980 prc_auc 0.62024[0m
[93maverage test of epoch 4: loss -1.41237 acc 0.67568 roc_auc 0.55667 prc_auc 0.71083[0m
[92maverage training of epoch 5: loss -1.48218 acc 0.66225 roc_auc 0.57176 prc_auc 0.73441[0m
[93maverage test of epoch 5: loss -1.57021 acc 0.67568 roc_auc 0.41667 prc_auc 0.65676[0m
[92maverage training of epoch 6: loss -1.66788 acc 0.66225 roc_auc 0.46588 prc_auc 0.67047[0m
[93maverage test of epoch 6: loss -1.80632 acc 0.67568 roc_auc 0.58667 prc_auc 0.74944[0m
[92maverage training of epoch 7: loss -1.84573 acc 0.66225 roc_auc 0.56098 prc_auc 0.71426[0mUsing backend: pytorch

[93maverage test of epoch 7: loss -1.96749 acc 0.67568 roc_auc 0.56000 prc_auc 0.74476[0m
[92maverage training of epoch 8: loss -2.03665 acc 0.66225 roc_auc 0.47706 prc_auc 0.65233[0m
[93maverage test of epoch 8: loss -2.17043 acc 0.67568 roc_auc 0.61667 prc_auc 0.81660[0m
[92maverage training of epoch 9: loss -2.22479 acc 0.66225 roc_auc 0.45686 prc_auc 0.63275[0m
[93maverage test of epoch 9: loss -2.34682 acc 0.67568 roc_auc 0.36667 prc_auc 0.57863[0m
[92maverage training of epoch 10: loss -2.43106 acc 0.66225 roc_auc 0.51157 prc_auc 0.66177[0m
[93maverage test of epoch 10: loss -2.55433 acc 0.67568 roc_auc 0.53667 prc_auc 0.75719[0m
[92maverage training of epoch 11: loss -2.61236 acc 0.66225 roc_auc 0.46490 prc_auc 0.64440[0m
[93maverage test of epoch 11: loss -2.73947 acc 0.67568 roc_auc 0.32000 prc_auc 0.62542[0m
[92maverage training of epoch 12: loss -2.80121 acc 0.66225 roc_auc 0.58304 prc_auc 0.75036[0m
[93maverage test of epoch 12: loss -2.90754 acc 0.67568 roc_auc 0.37333 prc_auc 0.64219[0m
[92maverage training of epoch 13: loss -2.96094 acc 0.66225 roc_auc 0.45137 prc_auc 0.65433[0m
[93maverage test of epoch 13: loss -3.07742 acc 0.67568 roc_auc 0.51000 prc_auc 0.76294[0m
[92maverage training of epoch 14: loss -3.12186 acc 0.66225 roc_auc 0.44059 prc_auc 0.60944[0m
[93maverage test of epoch 14: loss -3.26310 acc 0.67568 roc_auc 0.71333 prc_auc 0.86974[0m
[92maverage training of epoch 15: loss -3.28913 acc 0.66225 roc_auc 0.44137 prc_auc 0.64294[0m
[93maverage test of epoch 15: loss -3.44031 acc 0.67568 roc_auc 0.49000 prc_auc 0.67081[0m
[92maverage training of epoch 16: loss -3.44753 acc 0.66225 roc_auc 0.41549 prc_auc 0.60231[0m
[93maverage test of epoch 16: loss -3.59060 acc 0.67568 roc_auc 0.62000 prc_auc 0.81396[0m
[92maverage training of epoch 17: loss -3.61959 acc 0.66225 roc_auc 0.42745 prc_auc 0.61288[0m
[93maverage test of epoch 17: loss -3.75635 acc 0.67568 roc_auc 0.49333 prc_auc 0.68537[0m
[92maverage training of epoch 18: loss -3.78650 acc 0.66225 roc_auc 0.44373 prc_auc 0.62664[0m
[93maverage test of epoch 18: loss -3.93626 acc 0.67568 roc_auc 0.48000 prc_auc 0.67410[0m
[92maverage training of epoch 19: loss -3.98004 acc 0.66225 roc_auc 0.42745 prc_auc 0.62580[0m
[93maverage test of epoch 19: loss -4.11768 acc 0.67568 roc_auc 0.50333 prc_auc 0.65569[0m
[92maverage training of epoch 20: loss -4.13645 acc 0.66225 roc_auc 0.49363 prc_auc 0.66817[0m
[93maverage test of epoch 20: loss -4.26583 acc 0.67568 roc_auc 0.57333 prc_auc 0.74565[0m
[92maverage training of epoch 21: loss -4.28990 acc 0.66225 roc_auc 0.44922 prc_auc 0.60355[0m
[93maverage test of epoch 21: loss -4.39534 acc 0.67568 roc_auc 0.37667 prc_auc 0.60127[0m
[92maverage training of epoch 22: loss -4.43128 acc 0.66225 roc_auc 0.44392 prc_auc 0.60403[0m
[93maverage test of epoch 22: loss -4.56824 acc 0.67568 roc_auc 0.58333 prc_auc 0.79086[0m
[92maverage training of epoch 23: loss -4.58352 acc 0.66225 roc_auc 0.51294 prc_auc 0.68472[0m
[93maverage test of epoch 23: loss -4.70809 acc 0.67568 roc_auc 0.59333 prc_auc 0.74433[0m
[92maverage training of epoch 24: loss -4.71014 acc 0.66225 roc_auc 0.48157 prc_auc 0.62856[0m
[93maverage test of epoch 24: loss -4.83601 acc 0.67568 roc_auc 0.51667 prc_auc 0.73755[0m
[92maverage training of epoch 25: loss -4.83694 acc 0.66225 roc_auc 0.40843 prc_auc 0.61823[0m
[93maverage test of epoch 25: loss -4.96892 acc 0.67568 roc_auc 0.49333 prc_auc 0.70919[0m
[92maverage training of epoch 26: loss -4.97569 acc 0.66225 roc_auc 0.49451 prc_auc 0.65187[0m
[93maverage test of epoch 26: loss -5.08821 acc 0.67568 roc_auc 0.43000 prc_auc 0.68019[0m
[92maverage training of epoch 27: loss -5.09481 acc 0.66225 roc_auc 0.48088 prc_auc 0.67049[0m
[93maverage test of epoch 27: loss -5.22673 acc 0.67568 roc_auc 0.70333 prc_auc 0.83285[0m
[92maverage training of epoch 28: loss -5.22063 acc 0.66225 roc_auc 0.49510 prc_auc 0.68526[0m
[93maverage test of epoch 28: loss -5.33017 acc 0.67568 roc_auc 0.60333 prc_auc 0.77088[0m
[92maverage training of epoch 29: loss -5.33552 acc 0.66225 roc_auc 0.44765 prc_auc 0.60833[0m
[93maverage test of epoch 29: loss -5.45266 acc 0.67568 roc_auc 0.68667 prc_auc 0.83594[0m
[92maverage training of epoch 30: loss -5.45092 acc 0.66225 roc_auc 0.36706 prc_auc 0.59138[0m
[93maverage test of epoch 30: loss -5.56550 acc 0.67568 roc_auc 0.40667 prc_auc 0.65927[0m
[92maverage training of epoch 31: loss -5.57216 acc 0.66225 roc_auc 0.50059 prc_auc 0.67195[0m
[93maverage test of epoch 31: loss -5.68946 acc 0.67568 roc_auc 0.63333 prc_auc 0.75728[0m
[92maverage training of epoch 32: loss -5.68485 acc 0.66225 roc_auc 0.44020 prc_auc 0.62243[0m
[93maverage test of epoch 32: loss -5.78761 acc 0.67568 roc_auc 0.46333 prc_auc 0.69634[0m
[92maverage training of epoch 33: loss -5.79321 acc 0.66225 roc_auc 0.48118 prc_auc 0.65914[0m
[93maverage test of epoch 33: loss -5.91214 acc 0.67568 roc_auc 0.64333 prc_auc 0.80567[0m
[92maverage training of epoch 34: loss -5.90187 acc 0.66225 roc_auc 0.41804 prc_auc 0.63446[0m
[93maverage test of epoch 34: loss -6.02282 acc 0.67568 roc_auc 0.66000 prc_auc 0.80730[0m
[92maverage training of epoch 35: loss -6.01678 acc 0.66225 roc_auc 0.45804 prc_auc 0.63438[0m
[93maverage test of epoch 35: loss -6.12085 acc 0.67568 roc_auc 0.51333 prc_auc 0.74018[0m
[92maverage training of epoch 36: loss -6.12842 acc 0.66225 roc_auc 0.45431 prc_auc 0.63088[0m
[93maverage test of epoch 36: loss -6.23423 acc 0.67568 roc_auc 0.38667 prc_auc 0.60528[0m
[92maverage training of epoch 37: loss -6.23650 acc 0.66225 roc_auc 0.46941 prc_auc 0.64125[0m
[93maverage test of epoch 37: loss -6.35424 acc 0.67568 roc_auc 0.41333 prc_auc 0.65097[0m
[92maverage training of epoch 38: loss -6.34426 acc 0.66225 roc_auc 0.48902 prc_auc 0.63135[0m
[93maverage test of epoch 38: loss -6.44389 acc 0.67568 roc_auc 0.38000 prc_auc 0.71475[0m
[92maverage training of epoch 39: loss -6.44881 acc 0.66225 roc_auc 0.49059 prc_auc 0.65184[0m
[93maverage test of epoch 39: loss -6.56230 acc 0.67568 roc_auc 0.54667 prc_auc 0.73104[0m
[92maverage training of epoch 40: loss -6.55165 acc 0.66225 roc_auc 0.43569 prc_auc 0.62748[0m
[93maverage test of epoch 40: loss -6.66604 acc 0.67568 roc_auc 0.45333 prc_auc 0.69097[0m
[92maverage training of epoch 41: loss -6.65762 acc 0.66225 roc_auc 0.44225 prc_auc 0.63756[0m
[93maverage test of epoch 41: loss -6.76806 acc 0.67568 roc_auc 0.53500 prc_auc 0.71754[0m
[92maverage training of epoch 42: loss -6.76633 acc 0.66225 roc_auc 0.52608 prc_auc 0.67600[0m
[93maverage test of epoch 42: loss -6.87162 acc 0.67568 roc_auc 0.42000 prc_auc 0.66534[0m
[92maverage training of epoch 43: loss -6.86925 acc 0.66225 roc_auc 0.46108 prc_auc 0.63091[0m
[93maverage test of epoch 43: loss -6.98113 acc 0.67568 roc_auc 0.54667 prc_auc 0.73408[0m
[92maverage training of epoch 44: loss -6.97290 acc 0.66225 roc_auc 0.39922 prc_auc 0.58779[0m
[93maverage test of epoch 44: loss -7.08409 acc 0.67568 roc_auc 0.64167 prc_auc 0.76398[0m
[92maverage training of epoch 45: loss -7.07663 acc 0.66225 roc_auc 0.35824 prc_auc 0.56335[0m
[93maverage test of epoch 45: loss -7.19273 acc 0.67568 roc_auc 0.45333 prc_auc 0.72832[0m
[92maverage training of epoch 46: loss -7.18112 acc 0.66225 roc_auc 0.43235 prc_auc 0.62208[0m
[93maverage test of epoch 46: loss -7.29555 acc 0.67568 roc_auc 0.38333 prc_auc 0.62459[0m
[92maverage training of epoch 47: loss -7.28182 acc 0.66225 roc_auc 0.38392 prc_auc 0.59546[0m
[93maverage test of epoch 47: loss -7.39729 acc 0.67568 roc_auc 0.49000 prc_auc 0.75584[0m
[92maverage training of epoch 48: loss -7.38643 acc 0.66225 roc_auc 0.39598 prc_auc 0.60784[0m
[93maverage test of epoch 48: loss -7.50132 acc 0.67568 roc_auc 0.37500 prc_auc 0.61723[0m
[92maverage training of epoch 49: loss -7.49229 acc 0.66225 roc_auc 0.35784 prc_auc 0.56507[0m
[93maverage test of epoch 49: loss -7.60341 acc 0.67568 roc_auc 0.61000 prc_auc 0.80601[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 8)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.0001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.69744 ROC_AUC (avg): 0.59133 PRC_AUC (avg): 0.75161 

Average forward propagation time taken(ms): 3.9931934003063203
Average backward propagation time taken(ms): 1.523450969903591

