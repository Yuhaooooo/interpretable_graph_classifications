# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 2)
('lr', 0.0001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-06-35-42/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-18-06-35-42/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 8,
 'epochs': 100,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 4,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.0001,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 2,
 'num_workers': 8,
 'number_of_mlp_layer': 2,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-18-06-35-42',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 100, 'learning_rate': 0.0001, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=4, bias=True)
    (ReLU1): ReLU()
    (Linear2): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.09306 acc 0.36667 roc_auc 0.43800 prc_auc 0.62491[0m
[93maverage test of epoch 0: loss -0.23819 acc 0.57895 roc_auc 0.33231 prc_auc 0.56518[0m
[92maverage training of epoch 1: loss -0.33514 acc 0.59333 roc_auc 0.44680 prc_auc 0.64342[0m
[93maverage test of epoch 1: loss -0.47594 acc 0.68421 roc_auc 0.40308 prc_auc 0.62033[0m
[92maverage training of epoch 2: loss -0.59450 acc 0.65333 roc_auc 0.35540 prc_auc 0.57964[0m
[93maverage test of epoch 2: loss -0.70110 acc 0.65789 roc_auc 0.44000 prc_auc 0.63844[0m
[92maverage training of epoch 3: loss -0.87831 acc 0.66667 roc_auc 0.43660 prc_auc 0.62960[0m
[93maverage test of epoch 3: loss -1.02279 acc 0.65789 roc_auc 0.46769 prc_auc 0.64751[0m
[92maverage training of epoch 4: loss -1.16598 acc 0.66667 roc_auc 0.34580 prc_auc 0.56998[0m
[93maverage test of epoch 4: loss -1.31866 acc 0.65789 roc_auc 0.52308 prc_auc 0.69194[0m
[92maverage training of epoch 5: loss -1.52485 acc 0.66667 roc_auc 0.49320 prc_auc 0.65935[0m
[93maverage test of epoch 5: loss -1.64598 acc 0.65789 roc_auc 0.46154 prc_auc 0.70075[0m
[92maverage training of epoch 6: loss -1.88553 acc 0.66667 roc_auc 0.44800 prc_auc 0.65430[0m
[93maverage test of epoch 6: loss -2.03269 acc 0.65789 roc_auc 0.48615 prc_auc 0.70225[0m
[92maverage training of epoch 7: loss -2.28514 acc 0.66667 roc_auc 0.38980 prc_auc 0.61166[0m
[93maverage test of epoch 7: loss -2.49454 acc 0.65789 roc_auc 0.53231 prc_auc 0.70271[0m
[92maverage training of epoch 8: loss -2.74303 acc 0.66667 roc_auc 0.41900 prc_auc 0.63023[0m
[93maverage test of epoch 8: loss -2.94404 acc 0.65789 roc_auc 0.46154 prc_auc 0.64821[0m
[92maverage training of epoch 9: loss -3.19561 acc 0.66667 roc_auc 0.43060 prc_auc 0.67316[0m
[93maverage test of epoch 9: loss -3.38210 acc 0.65789 roc_auc 0.64000 prc_auc 0.76285[0m
[92maverage training of epoch 10: loss -3.62321 acc 0.66667 roc_auc 0.39600 prc_auc 0.63014[0m
[93maverage test of epoch 10: loss -3.80493 acc 0.65789 roc_auc 0.51692 prc_auc 0.67154[0m
[92maverage training of epoch 11: loss -4.03090 acc 0.66667 roc_auc 0.40800 prc_auc 0.61360[0m
[93maverage test of epoch 11: loss -4.19926 acc 0.65789 roc_auc 0.30154 prc_auc 0.59606[0m
[92maverage training of epoch 12: loss -4.46091 acc 0.66667 roc_auc 0.46750 prc_auc 0.67435[0m
[93maverage test of epoch 12: loss -4.62326 acc 0.65789 roc_auc 0.43077 prc_auc 0.67874[0m
[92maverage training of epoch 13: loss -4.88599 acc 0.66667 roc_auc 0.43960 prc_auc 0.61896[0m
[93maverage test of epoch 13: loss -5.06453 acc 0.65789 roc_auc 0.37231 prc_auc 0.61800[0m
[92maverage training of epoch 14: loss -5.34993 acc 0.66667 roc_auc 0.45200 prc_auc 0.65280[0m
[93maverage test of epoch 14: loss -5.51317 acc 0.65789 roc_auc 0.39385 prc_auc 0.66974[0m
[92maverage training of epoch 15: loss -5.81616 acc 0.66667 roc_auc 0.46940 prc_auc 0.66809[0m
[93maverage test of epoch 15: loss -5.99092 acc 0.65789 roc_auc 0.64308 prc_auc 0.80106[0m
[92maverage training of epoch 16: loss -6.28115 acc 0.66667 roc_auc 0.42880 prc_auc 0.64007[0m
[93maverage test of epoch 16: loss -6.46494 acc 0.65789 roc_auc 0.55538 prc_auc 0.68926[0m
[92maverage training of epoch 17: loss -6.76226 acc 0.66667 roc_auc 0.39970 prc_auc 0.63631[0m
[93maverage test of epoch 17: loss -6.96057 acc 0.65789 roc_auc 0.58154 prc_auc 0.78981[0m
[92maverage training of epoch 18: loss -7.24887 acc 0.66667 roc_auc 0.45320 prc_auc 0.62227[0m
[93maverage test of epoch 18: loss -7.42765 acc 0.65789 roc_auc 0.54308 prc_auc 0.68255[0m
[92maverage training of epoch 19: loss -7.77219 acc 0.66667 roc_auc 0.45650 prc_auc 0.66433[0m
[93maverage test of epoch 19: loss -7.95599 acc 0.65789 roc_auc 0.57538 prc_auc 0.74229[0m
[92maverage training of epoch 20: loss -8.30614 acc 0.66667 roc_auc 0.50210 prc_auc 0.65234[0m
[93maverage test of epoch 20: loss -8.47079 acc 0.65789 roc_auc 0.33692 prc_auc 0.59651[0m
[92maverage training of epoch 21: loss -8.80320 acc 0.66667 roc_auc 0.46720 prc_auc 0.66486[0m
[93maverage test of epoch 21: loss -9.01653 acc 0.65789 roc_auc 0.41692 prc_auc 0.60284[0m
[92maverage training of epoch 22: loss -9.34455 acc 0.66667 roc_auc 0.41880 prc_auc 0.64572[0m
[93maverage test of epoch 22: loss -9.54472 acc 0.65789 roc_auc 0.44154 prc_auc 0.65356[0m
[92maverage training of epoch 23: loss -9.94233 acc 0.66667 roc_auc 0.44390 prc_auc 0.62657[0m
[93maverage test of epoch 23: loss -10.11728 acc 0.65789 roc_auc 0.48462 prc_auc 0.63883[0m
[92maverage training of epoch 24: loss -10.50259 acc 0.66667 roc_auc 0.45940 prc_auc 0.63197[0m
[93maverage test of epoch 24: loss -10.65445 acc 0.65789 roc_auc 0.46462 prc_auc 0.66067[0m
[92maverage training of epoch 25: loss -11.07689 acc 0.66667 roc_auc 0.43090 prc_auc 0.61186[0m
[93maverage test of epoch 25: loss -11.26250 acc 0.65789 roc_auc 0.39538 prc_auc 0.61340[0m
[92maverage training of epoch 26: loss -11.66173 acc 0.66667 roc_auc 0.37770 prc_auc 0.61560[0m
[93maverage test of epoch 26: loss -11.89748 acc 0.65789 roc_auc 0.58000 prc_auc 0.69232[0m
[92maverage training of epoch 27: loss -12.29808 acc 0.66667 roc_auc 0.41600 prc_auc 0.62678[0m
[93maverage test of epoch 27: loss -12.47267 acc 0.65789 roc_auc 0.41846 prc_auc 0.64313[0m
[92maverage training of epoch 28: loss -12.94677 acc 0.66667 roc_auc 0.40950 prc_auc 0.61798[0m
[93maverage test of epoch 28: loss -13.16384 acc 0.65789 roc_auc 0.43231 prc_auc 0.62561[0m
[92maverage training of epoch 29: loss -13.58864 acc 0.66667 roc_auc 0.45430 prc_auc 0.64289[0m
[93maverage test of epoch 29: loss -13.78561 acc 0.65789 roc_auc 0.45538 prc_auc 0.63867[0m
[92maverage training of epoch 30: loss -14.26277 acc 0.66667 roc_auc 0.44610 prc_auc 0.64284[0m
[93maverage test of epoch 30: loss -14.46411 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -14.94065 acc 0.66667 roc_auc 0.45500 prc_auc 0.64736[0m
[93maverage test of epoch 31: loss -15.16848 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -15.63092 acc 0.66667 roc_auc 0.48500 prc_auc 0.66037[0m
[93maverage test of epoch 32: loss -15.82510 acc 0.65789 roc_auc 0.35846 prc_auc 0.60256[0m
[92maverage training of epoch 33: loss -16.34711 acc 0.66667 roc_auc 0.51000 prc_auc 0.67114[0m
[93maverage test of epoch 33: loss -16.58111 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -17.08154 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -17.29946 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -17.83043 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -18.07426 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -18.58643 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -18.79733 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -19.36491 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -19.57287 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -20.18376 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -20.41460 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -21.01155 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -21.23387 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -21.83619 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -22.04617 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -22.68686 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -22.91279 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -23.56674 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -23.79293 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -24.46197 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -24.69282 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -25.37827 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -25.62225 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -26.31041 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -26.57732 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -27.26968 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -27.52954 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -28.24618 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -28.51696 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -29.24229 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -29.53555 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -30.26990 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -30.54734 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 50: loss -31.32342 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 50: loss -31.60414 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 51: loss -32.37983 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 51: loss -32.67319 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 52: loss -33.46363 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 52: loss -33.77335 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 53: loss -34.59071 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 53: loss -34.89532 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 54: loss -35.71709 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 54: loss -36.01784 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 55: loss -36.87976 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 55: loss -37.20648 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 56: loss -38.04811 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 56: loss -38.37352 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 57: loss -39.26731 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 57: loss -39.59609 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 58: loss -40.50930 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 58: loss -40.82435 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 59: loss -41.75163 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 59: loss -42.06500 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 60: loss -43.03453 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 60: loss -43.35334 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 61: loss -44.33410 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 61: loss -44.63849 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 62: loss -45.66474 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 62: loss -45.99767 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 63: loss -47.00844 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 63: loss -47.35690 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 64: loss -48.38517 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 64: loss -48.72782 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 65: loss -49.79130 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 65: loss -50.12420 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 66: loss -51.21002 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 66: loss -51.57408 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 67: loss -52.66210 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 67: loss -53.01686 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 68: loss -54.13896 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 68: loss -54.49483 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 69: loss -55.63529 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 69: loss -55.99508 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 70: loss -57.16972 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 70: loss -57.52671 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 71: loss -58.71207 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 71: loss -59.07849 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 72: loss -60.29668 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 72: loss -60.66166 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 73: loss -61.90341 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 73: loss -62.25744 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 74: loss -63.53281 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 74: loss -63.90438 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 75: loss -65.19568 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 75: loss -65.56526 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 76: loss -66.87375 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 76: loss -67.27341 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 77: loss -68.58946 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 77: loss -68.97874 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 78: loss -70.33600 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 78: loss -70.72192 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 79: loss -72.10033 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 79: loss -72.48462 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 80: loss -73.89468 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 80: loss -74.29742 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 81: loss -75.72130 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 81: loss -76.12692 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 82: loss -77.57357 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 82: loss -77.97778 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 83: loss -79.45218 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 83: loss -79.86646 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 84: loss -81.36524 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 84: loss -81.77040 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 85: loss -83.29632 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 85: loss -83.70957 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 86: loss -85.26503 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 86: loss -85.68408 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 87: loss -87.25854 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 87: loss -87.68063 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 88: loss -89.28373 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 88: loss -89.70637 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 89: loss -91.34297 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 89: loss -91.76529 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -93.42942 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 90: loss -93.85077 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 91: loss -95.54590 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 91: loss -95.97631 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 92: loss -97.68573 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 92: loss -98.13110 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 93: loss -99.86808 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 93: loss -100.30626 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 94: loss -102.08124 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 94: loss -102.51483 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 95: loss -104.32154 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 95: loss -104.75823 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 96: loss -106.59445 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 96: loss -107.04550 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 97: loss -108.89909 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 97: loss -109.34061 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 98: loss -111.23161 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 98: loss -111.68777 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -113.60113 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 99: loss -114.05936 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=4, bias=True)
    (ReLU1): ReLU()
    (Linear2): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.78548 acc 0.66667 roc_auc 0.52740 prc_auc 0.70497[0m
[93maverage test of epoch 0: loss -0.90018 acc 0.65789 roc_auc 0.62462 prc_auc 0.82690[0m
[92maverage training of epoch 1: loss -0.99470 acc 0.66667 roc_auc 0.46060 prc_auc 0.66095[0m
[93maverage test of epoch 1: loss -1.09436 acc 0.65789 roc_auc 0.71077 prc_auc 0.87698[0m
[92maverage training of epoch 2: loss -1.20398 acc 0.66667 roc_auc 0.64200 prc_auc 0.79193[0m
[93maverage test of epoch 2: loss -1.34725 acc 0.65789 roc_auc 0.68615 prc_auc 0.82289[0m
[92maverage training of epoch 3: loss -1.53000 acc 0.66667 roc_auc 0.54140 prc_auc 0.69036[0m
[93maverage test of epoch 3: loss -1.71514 acc 0.65789 roc_auc 0.64615 prc_auc 0.79018[0m
[92maverage training of epoch 4: loss -1.86179 acc 0.66667 roc_auc 0.47900 prc_auc 0.64575[0m
[93maverage test of epoch 4: loss -1.98948 acc 0.65789 roc_auc 0.55077 prc_auc 0.74739[0m
[92maverage training of epoch 5: loss -2.14687 acc 0.66667 roc_auc 0.48380 prc_auc 0.68583[0m
[93maverage test of epoch 5: loss -2.28544 acc 0.65789 roc_auc 0.62154 prc_auc 0.78535[0m
[92maverage training of epoch 6: loss -2.42588 acc 0.66667 roc_auc 0.48720 prc_auc 0.66112[0m
[93maverage test of epoch 6: loss -2.56083 acc 0.65789 roc_auc 0.55385 prc_auc 0.72721[0m
[92maverage training of epoch 7: loss -2.70029 acc 0.66667 roc_auc 0.47400 prc_auc 0.64796[0m
[93maverage test of epoch 7: loss -2.83912 acc 0.65789 roc_auc 0.51692 prc_auc 0.72989[0m
[92maverage training of epoch 8: loss -2.97120 acc 0.66667 roc_auc 0.45900 prc_auc 0.64986[0m
[93maverage test of epoch 8: loss -3.10829 acc 0.65789 roc_auc 0.74154 prc_auc 0.88010[0m
[92maverage training of epoch 9: loss -3.24202 acc 0.66667 roc_auc 0.46960 prc_auc 0.65060[0m
[93maverage test of epoch 9: loss -3.38048 acc 0.65789 roc_auc 0.45231 prc_auc 0.71154[0m
[92maverage training of epoch 10: loss -3.52186 acc 0.66667 roc_auc 0.50860 prc_auc 0.69538[0m
[93maverage test of epoch 10: loss -3.62937 acc 0.65789 roc_auc 0.58769 prc_auc 0.76946[0m
[92maverage training of epoch 11: loss -3.80225 acc 0.66667 roc_auc 0.46080 prc_auc 0.64646[0m
[93maverage test of epoch 11: loss -3.92711 acc 0.65789 roc_auc 0.66769 prc_auc 0.79842[0m
[92maverage training of epoch 12: loss -4.07999 acc 0.66667 roc_auc 0.53360 prc_auc 0.68832[0m
[93maverage test of epoch 12: loss -4.21570 acc 0.65789 roc_auc 0.57538 prc_auc 0.76477[0m
[92maverage training of epoch 13: loss -4.35727 acc 0.66667 roc_auc 0.45820 prc_auc 0.63517[0m
[93maverage test of epoch 13: loss -4.50077 acc 0.65789 roc_auc 0.62769 prc_auc 0.75697[0m
[92maverage training of epoch 14: loss -4.64333 acc 0.66667 roc_auc 0.46900 prc_auc 0.64036[0m
[93maverage test of epoch 14: loss -4.78240 acc 0.65789 roc_auc 0.60308 prc_auc 0.72692[0m
[92maverage training of epoch 15: loss -4.92931 acc 0.66667 roc_auc 0.49220 prc_auc 0.68464[0m
[93maverage test of epoch 15: loss -5.07447 acc 0.65789 roc_auc 0.62769 prc_auc 0.80477[0m
[92maverage training of epoch 16: loss -5.20875 acc 0.66667 roc_auc 0.47720 prc_auc 0.67787[0m
[93maverage test of epoch 16: loss -5.34264 acc 0.65789 roc_auc 0.74462 prc_auc 0.84665[0m
[92maverage training of epoch 17: loss -5.47873 acc 0.66667 roc_auc 0.54400 prc_auc 0.70310[0m
[93maverage test of epoch 17: loss -5.61188 acc 0.65789 roc_auc 0.42462 prc_auc 0.67901[0m
[92maverage training of epoch 18: loss -5.76702 acc 0.66667 roc_auc 0.42320 prc_auc 0.62497[0m
[93maverage test of epoch 18: loss -5.89816 acc 0.65789 roc_auc 0.42769 prc_auc 0.66032[0m
[92maverage training of epoch 19: loss -6.04685 acc 0.66667 roc_auc 0.48360 prc_auc 0.67207[0m
[93maverage test of epoch 19: loss -6.18141 acc 0.65789 roc_auc 0.56615 prc_auc 0.69040[0m
[92maverage training of epoch 20: loss -6.34561 acc 0.66667 roc_auc 0.46060 prc_auc 0.63258[0m
[93maverage test of epoch 20: loss -6.48321 acc 0.65789 roc_auc 0.50615 prc_auc 0.69510[0m
[92maverage training of epoch 21: loss -6.63889 acc 0.66667 roc_auc 0.45820 prc_auc 0.66372[0m
[93maverage test of epoch 21: loss -6.77561 acc 0.65789 roc_auc 0.60615 prc_auc 0.79906[0m
[92maverage training of epoch 22: loss -6.93601 acc 0.66667 roc_auc 0.44740 prc_auc 0.61853[0m
[93maverage test of epoch 22: loss -7.06672 acc 0.65789 roc_auc 0.41231 prc_auc 0.63918[0m
[92maverage training of epoch 23: loss -7.23950 acc 0.66667 roc_auc 0.42680 prc_auc 0.64794[0m
[93maverage test of epoch 23: loss -7.36703 acc 0.65789 roc_auc 0.49846 prc_auc 0.69342[0m
[92maverage training of epoch 24: loss -7.53744 acc 0.66667 roc_auc 0.47880 prc_auc 0.65563[0m
[93maverage test of epoch 24: loss -7.69592 acc 0.65789 roc_auc 0.62154 prc_auc 0.77999[0m
[92maverage training of epoch 25: loss -7.86801 acc 0.66667 roc_auc 0.45360 prc_auc 0.64767[0m
[93maverage test of epoch 25: loss -8.01063 acc 0.65789 roc_auc 0.67077 prc_auc 0.83651[0m
[92maverage training of epoch 26: loss -8.18402 acc 0.66667 roc_auc 0.43740 prc_auc 0.62348[0m
[93maverage test of epoch 26: loss -8.32729 acc 0.65789 roc_auc 0.38000 prc_auc 0.66196[0m
[92maverage training of epoch 27: loss -8.49709 acc 0.66667 roc_auc 0.46580 prc_auc 0.66763[0m
[93maverage test of epoch 27: loss -8.65181 acc 0.65789 roc_auc 0.68000 prc_auc 0.86028[0m
[92maverage training of epoch 28: loss -8.83648 acc 0.66667 roc_auc 0.49250 prc_auc 0.64122[0m
[93maverage test of epoch 28: loss -8.98572 acc 0.65789 roc_auc 0.66462 prc_auc 0.83371[0m
[92maverage training of epoch 29: loss -9.16175 acc 0.66667 roc_auc 0.46920 prc_auc 0.66407[0m
[93maverage test of epoch 29: loss -9.32983 acc 0.65789 roc_auc 0.46154 prc_auc 0.67335[0m
[92maverage training of epoch 30: loss -9.50981 acc 0.66667 roc_auc 0.48280 prc_auc 0.66479[0m
[93maverage test of epoch 30: loss -9.65330 acc 0.65789 roc_auc 0.50923 prc_auc 0.71643[0m
[92maverage training of epoch 31: loss -9.85244 acc 0.66667 roc_auc 0.48280 prc_auc 0.68881[0m
[93maverage test of epoch 31: loss -10.00137 acc 0.65789 roc_auc 0.75692 prc_auc 0.88160[0m
[92maverage training of epoch 32: loss -10.20938 acc 0.66667 roc_auc 0.43140 prc_auc 0.62377[0m
[93maverage test of epoch 32: loss -10.37069 acc 0.65789 roc_auc 0.67385 prc_auc 0.79163[0m
[92maverage training of epoch 33: loss -10.56036 acc 0.66667 roc_auc 0.42630 prc_auc 0.62708[0m
[93maverage test of epoch 33: loss -10.72754 acc 0.65789 roc_auc 0.54615 prc_auc 0.75576[0m
[92maverage training of epoch 34: loss -10.93812 acc 0.66667 roc_auc 0.43220 prc_auc 0.62207[0m
[93maverage test of epoch 34: loss -11.10345 acc 0.65789 roc_auc 0.41692 prc_auc 0.65286[0m
[92maverage training of epoch 35: loss -11.31087 acc 0.66667 roc_auc 0.44080 prc_auc 0.63608[0m
[93maverage test of epoch 35: loss -11.47423 acc 0.65789 roc_auc 0.63538 prc_auc 0.78898[0m
[92maverage training of epoch 36: loss -11.69202 acc 0.66667 roc_auc 0.43080 prc_auc 0.63059[0m
[93maverage test of epoch 36: loss -11.86174 acc 0.65789 roc_auc 0.42000 prc_auc 0.66703[0m
[92maverage training of epoch 37: loss -12.08705 acc 0.66667 roc_auc 0.46060 prc_auc 0.64979[0m
[93maverage test of epoch 37: loss -12.25828 acc 0.65789 roc_auc 0.40308 prc_auc 0.63884[0m
[92maverage training of epoch 38: loss -12.47727 acc 0.66667 roc_auc 0.49080 prc_auc 0.69574[0m
[93maverage test of epoch 38: loss -12.63176 acc 0.65789 roc_auc 0.45231 prc_auc 0.68685[0m
[92maverage training of epoch 39: loss -12.87737 acc 0.66667 roc_auc 0.43360 prc_auc 0.61357[0m
[93maverage test of epoch 39: loss -13.05976 acc 0.65789 roc_auc 0.21077 prc_auc 0.54549[0m
[92maverage training of epoch 40: loss -13.29892 acc 0.66667 roc_auc 0.47540 prc_auc 0.65016[0m
[93maverage test of epoch 40: loss -13.48495 acc 0.65789 roc_auc 0.56000 prc_auc 0.73716[0m
[92maverage training of epoch 41: loss -13.71140 acc 0.66667 roc_auc 0.45180 prc_auc 0.63948[0m
[93maverage test of epoch 41: loss -13.88997 acc 0.65789 roc_auc 0.61538 prc_auc 0.75366[0m
[92maverage training of epoch 42: loss -14.14434 acc 0.66667 roc_auc 0.46240 prc_auc 0.65206[0m
[93maverage test of epoch 42: loss -14.32292 acc 0.65789 roc_auc 0.53846 prc_auc 0.71825[0m
[92maverage training of epoch 43: loss -14.57777 acc 0.66667 roc_auc 0.48500 prc_auc 0.64865[0m
[93maverage test of epoch 43: loss -14.74463 acc 0.65789 roc_auc 0.50000 prc_auc 0.72518[0m
[92maverage training of epoch 44: loss -15.01609 acc 0.66667 roc_auc 0.48800 prc_auc 0.67342[0m
[93maverage test of epoch 44: loss -15.19849 acc 0.65789 roc_auc 0.58000 prc_auc 0.71935[0m
[92maverage training of epoch 45: loss -15.46420 acc 0.66667 roc_auc 0.48700 prc_auc 0.64758[0m
[93maverage test of epoch 45: loss -15.64481 acc 0.65789 roc_auc 0.53231 prc_auc 0.72237[0m
[92maverage training of epoch 46: loss -15.92292 acc 0.66667 roc_auc 0.44500 prc_auc 0.65297[0m
[93maverage test of epoch 46: loss -16.12558 acc 0.65789 roc_auc 0.31692 prc_auc 0.59689[0m
[92maverage training of epoch 47: loss -16.38782 acc 0.66667 roc_auc 0.44860 prc_auc 0.63680[0m
[93maverage test of epoch 47: loss -16.57783 acc 0.65789 roc_auc 0.53231 prc_auc 0.72363[0m
[92maverage training of epoch 48: loss -16.86568 acc 0.66667 roc_auc 0.45460 prc_auc 0.64079[0m
[93maverage test of epoch 48: loss -17.06849 acc 0.65789 roc_auc 0.57538 prc_auc 0.71952[0m
[92maverage training of epoch 49: loss -17.34804 acc 0.66667 roc_auc 0.47710 prc_auc 0.66436[0m
[93maverage test of epoch 49: loss -17.55143 acc 0.65789 roc_auc 0.60154 prc_auc 0.71421[0m
[92maverage training of epoch 50: loss -17.83634 acc 0.66667 roc_auc 0.44480 prc_auc 0.62915[0m
[93maverage test of epoch 50: loss -18.04721 acc 0.65789 roc_auc 0.67385 prc_auc 0.80035[0m
[92maverage training of epoch 51: loss -18.33793 acc 0.66667 roc_auc 0.45360 prc_auc 0.64125[0m
[93maverage test of epoch 51: loss -18.54539 acc 0.65789 roc_auc 0.48615 prc_auc 0.66408[0m
[92maverage training of epoch 52: loss -18.84512 acc 0.66667 roc_auc 0.44570 prc_auc 0.64682[0m
[93maverage test of epoch 52: loss -19.04663 acc 0.65789 roc_auc 0.42769 prc_auc 0.64057[0m
[92maverage training of epoch 53: loss -19.35985 acc 0.66667 roc_auc 0.45130 prc_auc 0.62436[0m
[93maverage test of epoch 53: loss -19.56920 acc 0.65789 roc_auc 0.65692 prc_auc 0.75269[0m
[92maverage training of epoch 54: loss -19.88906 acc 0.66667 roc_auc 0.45600 prc_auc 0.64894[0m
[93maverage test of epoch 54: loss -20.08949 acc 0.65789 roc_auc 0.48769 prc_auc 0.69335[0m
[92maverage training of epoch 55: loss -20.42803 acc 0.66667 roc_auc 0.45740 prc_auc 0.65107[0m
[93maverage test of epoch 55: loss -20.64541 acc 0.65789 roc_auc 0.47538 prc_auc 0.64539[0m
[92maverage training of epoch 56: loss -20.96663 acc 0.66667 roc_auc 0.45940 prc_auc 0.63299[0m
[93maverage test of epoch 56: loss -21.18150 acc 0.65789 roc_auc 0.44154 prc_auc 0.64703[0m
[92maverage training of epoch 57: loss -21.51755 acc 0.66667 roc_auc 0.46030 prc_auc 0.66432[0m
[93maverage test of epoch 57: loss -21.73700 acc 0.65789 roc_auc 0.59231 prc_auc 0.73109[0m
[92maverage training of epoch 58: loss -22.07936 acc 0.66667 roc_auc 0.45590 prc_auc 0.63889[0m
[93maverage test of epoch 58: loss -22.30391 acc 0.65789 roc_auc 0.50000 prc_auc 0.69823[0m
[92maverage training of epoch 59: loss -22.64554 acc 0.66667 roc_auc 0.45980 prc_auc 0.64574[0m
[93maverage test of epoch 59: loss -22.88179 acc 0.65789 roc_auc 0.41077 prc_auc 0.62459[0m
[92maverage training of epoch 60: loss -23.23083 acc 0.66667 roc_auc 0.45580 prc_auc 0.64602[0m
[93maverage test of epoch 60: loss -23.45896 acc 0.65789 roc_auc 0.53846 prc_auc 0.66957[0m
[92maverage training of epoch 61: loss -23.81294 acc 0.66667 roc_auc 0.48240 prc_auc 0.65776[0m
[93maverage test of epoch 61: loss -24.04855 acc 0.65789 roc_auc 0.54769 prc_auc 0.68330[0m
[92maverage training of epoch 62: loss -24.41472 acc 0.66667 roc_auc 0.46480 prc_auc 0.64716[0m
[93maverage test of epoch 62: loss -24.65325 acc 0.65789 roc_auc 0.42000 prc_auc 0.61935[0m
[92maverage training of epoch 63: loss -25.02215 acc 0.66667 roc_auc 0.45780 prc_auc 0.64205[0m
[93maverage test of epoch 63: loss -25.26697 acc 0.65789 roc_auc 0.50615 prc_auc 0.67140[0m
[92maverage training of epoch 64: loss -25.63627 acc 0.66667 roc_auc 0.45930 prc_auc 0.64391[0m
[93maverage test of epoch 64: loss -25.88223 acc 0.65789 roc_auc 0.50462 prc_auc 0.65697[0m
[92maverage training of epoch 65: loss -26.26620 acc 0.66667 roc_auc 0.46710 prc_auc 0.64260[0m
[93maverage test of epoch 65: loss -26.50740 acc 0.65789 roc_auc 0.51231 prc_auc 0.66508[0m
[92maverage training of epoch 66: loss -26.90080 acc 0.66667 roc_auc 0.45280 prc_auc 0.63246[0m
[93maverage test of epoch 66: loss -27.16013 acc 0.65789 roc_auc 0.64769 prc_auc 0.76526[0m
[92maverage training of epoch 67: loss -27.57815 acc 0.66667 roc_auc 0.45840 prc_auc 0.64657[0m
[93maverage test of epoch 67: loss -27.86775 acc 0.65789 roc_auc 0.56308 prc_auc 0.69810[0m
[92maverage training of epoch 68: loss -28.29953 acc 0.66667 roc_auc 0.46990 prc_auc 0.65518[0m
[93maverage test of epoch 68: loss -28.59129 acc 0.65789 roc_auc 0.56769 prc_auc 0.71246[0m
[92maverage training of epoch 69: loss -29.03617 acc 0.66667 roc_auc 0.45970 prc_auc 0.65666[0m
[93maverage test of epoch 69: loss -29.33437 acc 0.65789 roc_auc 0.34000 prc_auc 0.59318[0m
[92maverage training of epoch 70: loss -29.78197 acc 0.66667 roc_auc 0.46910 prc_auc 0.65365[0m
[93maverage test of epoch 70: loss -30.07527 acc 0.65789 roc_auc 0.67692 prc_auc 0.80042[0m
[92maverage training of epoch 71: loss -30.53735 acc 0.66667 roc_auc 0.46800 prc_auc 0.64952[0m
[93maverage test of epoch 71: loss -30.83587 acc 0.65789 roc_auc 0.48923 prc_auc 0.69379[0m
[92maverage training of epoch 72: loss -31.30402 acc 0.66667 roc_auc 0.46710 prc_auc 0.64816[0m
[93maverage test of epoch 72: loss -31.60596 acc 0.65789 roc_auc 0.54154 prc_auc 0.72353[0m
[92maverage training of epoch 73: loss -32.08260 acc 0.66667 roc_auc 0.45920 prc_auc 0.63887[0m
[93maverage test of epoch 73: loss -32.39049 acc 0.65789 roc_auc 0.51692 prc_auc 0.66497[0m
[92maverage training of epoch 74: loss -32.87244 acc 0.66667 roc_auc 0.45890 prc_auc 0.63962[0m
[93maverage test of epoch 74: loss -33.19051 acc 0.65789 roc_auc 0.39846 prc_auc 0.61157[0m
[92maverage training of epoch 75: loss -33.67828 acc 0.66667 roc_auc 0.45910 prc_auc 0.64120[0m
[93maverage test of epoch 75: loss -33.99892 acc 0.65789 roc_auc 0.53692 prc_auc 0.67535[0m
[92maverage training of epoch 76: loss -34.49804 acc 0.66667 roc_auc 0.46200 prc_auc 0.63708[0m
[93maverage test of epoch 76: loss -34.82112 acc 0.65789 roc_auc 0.49692 prc_auc 0.65651[0m
[92maverage training of epoch 77: loss -35.34464 acc 0.66667 roc_auc 0.46310 prc_auc 0.63885[0m
[93maverage test of epoch 77: loss -35.71308 acc 0.65789 roc_auc 0.56769 prc_auc 0.69215[0m
[92maverage training of epoch 78: loss -36.28596 acc 0.66667 roc_auc 0.46740 prc_auc 0.64875[0m
[93maverage test of epoch 78: loss -36.66846 acc 0.65789 roc_auc 0.61538 prc_auc 0.71429[0m
[92maverage training of epoch 79: loss -37.24758 acc 0.66667 roc_auc 0.47010 prc_auc 0.64892[0m
[93maverage test of epoch 79: loss -37.63210 acc 0.65789 roc_auc 0.52615 prc_auc 0.66991[0m
[92maverage training of epoch 80: loss -38.22764 acc 0.66667 roc_auc 0.46310 prc_auc 0.64048[0m
[93maverage test of epoch 80: loss -38.61289 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 81: loss -39.21727 acc 0.66667 roc_auc 0.45590 prc_auc 0.63594[0m
[93maverage test of epoch 81: loss -39.61352 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 82: loss -40.22881 acc 0.66667 roc_auc 0.46140 prc_auc 0.64571[0m
[93maverage test of epoch 82: loss -40.62614 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 83: loss -41.24907 acc 0.66667 roc_auc 0.43700 prc_auc 0.62887[0m
[93maverage test of epoch 83: loss -41.65409 acc 0.65789 roc_auc 0.53846 prc_auc 0.67568[0m
[92maverage training of epoch 84: loss -42.28729 acc 0.66667 roc_auc 0.46470 prc_auc 0.64539[0m
[93maverage test of epoch 84: loss -42.69720 acc 0.65789 roc_auc 0.48000 prc_auc 0.64902[0m
[92maverage training of epoch 85: loss -43.34569 acc 0.66667 roc_auc 0.45980 prc_auc 0.64778[0m
[93maverage test of epoch 85: loss -43.76097 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 86: loss -44.41917 acc 0.66667 roc_auc 0.47000 prc_auc 0.65389[0m
[93maverage test of epoch 86: loss -44.84037 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 87: loss -45.51215 acc 0.66667 roc_auc 0.47000 prc_auc 0.65376[0m
[93maverage test of epoch 87: loss -45.94098 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 88: loss -46.62520 acc 0.66667 roc_auc 0.42000 prc_auc 0.63619[0m
[93maverage test of epoch 88: loss -47.06102 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 89: loss -47.75823 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 89: loss -48.19633 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 90: loss -48.90993 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 90: loss -49.35844 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 91: loss -50.08506 acc 0.66667 roc_auc 0.46500 prc_auc 0.65167[0m
[93maverage test of epoch 91: loss -50.53790 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 92: loss -51.27675 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 92: loss -51.73439 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 93: loss -52.49456 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 93: loss -52.96046 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 94: loss -53.73334 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 94: loss -54.20640 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 95: loss -54.99038 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 95: loss -55.47265 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 96: loss -56.27177 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 96: loss -56.75980 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 97: loss -57.57652 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 97: loss -58.07445 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 98: loss -58.89986 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 98: loss -59.40669 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 99: loss -60.25356 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 99: loss -60.76264 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=4, bias=True)
    (ReLU1): ReLU()
    (Linear2): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss 0.00470 acc 0.33333 roc_auc 0.47380 prc_auc 0.67215[0m
[93maverage test of epoch 0: loss -0.03178 acc 0.34211 roc_auc 0.55692 prc_auc 0.68298[0m
[92maverage training of epoch 1: loss -0.03922 acc 0.33333 roc_auc 0.52240 prc_auc 0.73037[0m
[93maverage test of epoch 1: loss -0.07665 acc 0.34211 roc_auc 0.61231 prc_auc 0.69308[0m
[92maverage training of epoch 2: loss -0.08976 acc 0.33333 roc_auc 0.52820 prc_auc 0.69083[0m
[93maverage test of epoch 2: loss -0.12891 acc 0.34211 roc_auc 0.36923 prc_auc 0.57857[0m
[92maverage training of epoch 3: loss -0.14937 acc 0.33333 roc_auc 0.53020 prc_auc 0.71802[0m
[93maverage test of epoch 3: loss -0.19600 acc 0.34211 roc_auc 0.48000 prc_auc 0.71373[0m
[92maverage training of epoch 4: loss -0.21570 acc 0.33333 roc_auc 0.49300 prc_auc 0.66783[0m
[93maverage test of epoch 4: loss -0.27001 acc 0.34211 roc_auc 0.57538 prc_auc 0.75306[0m
[92maverage training of epoch 5: loss -0.30047 acc 0.33333 roc_auc 0.49680 prc_auc 0.70239[0m
[93maverage test of epoch 5: loss -0.35878 acc 0.34211 roc_auc 0.59385 prc_auc 0.72504[0m
[92maverage training of epoch 6: loss -0.39730 acc 0.33333 roc_auc 0.51120 prc_auc 0.70386[0m
[93maverage test of epoch 6: loss -0.46652 acc 0.34211 roc_auc 0.60923 prc_auc 0.75735[0m
[92maverage training of epoch 7: loss -0.50518 acc 0.33333 roc_auc 0.52380 prc_auc 0.71677[0m
[93maverage test of epoch 7: loss -0.56964 acc 0.34211 roc_auc 0.38462 prc_auc 0.59563[0m
[92maverage training of epoch 8: loss -0.62320 acc 0.33333 roc_auc 0.47700 prc_auc 0.68816[0m
[93maverage test of epoch 8: loss -0.70291 acc 0.34211 roc_auc 0.70462 prc_auc 0.81053[0m
[92maverage training of epoch 9: loss -0.75439 acc 0.33333 roc_auc 0.58960 prc_auc 0.76296[0m
[93maverage test of epoch 9: loss -0.83598 acc 0.34211 roc_auc 0.67692 prc_auc 0.81962[0m
[92maverage training of epoch 10: loss -0.89265 acc 0.33333 roc_auc 0.56820 prc_auc 0.75469[0m
[93maverage test of epoch 10: loss -0.98131 acc 0.34211 roc_auc 0.74154 prc_auc 0.86207[0m
[92maverage training of epoch 11: loss -1.03714 acc 0.33333 roc_auc 0.58860 prc_auc 0.77770[0m
[93maverage test of epoch 11: loss -1.12426 acc 0.34211 roc_auc 0.69538 prc_auc 0.81538[0m
[92maverage training of epoch 12: loss -1.18625 acc 0.33333 roc_auc 0.58620 prc_auc 0.75261[0m
[93maverage test of epoch 12: loss -1.27734 acc 0.34211 roc_auc 0.34769 prc_auc 0.61188[0m
[92maverage training of epoch 13: loss -1.34511 acc 0.33333 roc_auc 0.47960 prc_auc 0.64671[0m
[93maverage test of epoch 13: loss -1.45850 acc 0.34211 roc_auc 0.36615 prc_auc 0.63776[0m
[92maverage training of epoch 14: loss -1.53259 acc 0.33333 roc_auc 0.51460 prc_auc 0.67626[0m
[93maverage test of epoch 14: loss -1.64270 acc 0.34211 roc_auc 0.32308 prc_auc 0.60680[0m
[92maverage training of epoch 15: loss -1.72414 acc 0.33333 roc_auc 0.46200 prc_auc 0.65401[0m
[93maverage test of epoch 15: loss -1.84012 acc 0.34211 roc_auc 0.28923 prc_auc 0.57828[0m
[92maverage training of epoch 16: loss -1.92451 acc 0.33333 roc_auc 0.58160 prc_auc 0.71918[0m
[93maverage test of epoch 16: loss -2.06102 acc 0.34211 roc_auc 0.50154 prc_auc 0.70403[0m
[92maverage training of epoch 17: loss -2.15095 acc 0.33333 roc_auc 0.60700 prc_auc 0.74915[0m
[93maverage test of epoch 17: loss -2.27398 acc 0.34211 roc_auc 0.33231 prc_auc 0.64053[0m
[92maverage training of epoch 18: loss -2.38579 acc 0.33333 roc_auc 0.55360 prc_auc 0.68985[0m
[93maverage test of epoch 18: loss -2.52839 acc 0.34211 roc_auc 0.43077 prc_auc 0.65571[0m
[92maverage training of epoch 19: loss -2.64327 acc 0.33333 roc_auc 0.46700 prc_auc 0.63240[0m
[93maverage test of epoch 19: loss -2.80330 acc 0.34211 roc_auc 0.42462 prc_auc 0.68139[0m
[92maverage training of epoch 20: loss -2.92733 acc 0.33333 roc_auc 0.46920 prc_auc 0.67139[0m
[93maverage test of epoch 20: loss -3.09459 acc 0.34211 roc_auc 0.44615 prc_auc 0.69140[0m
[92maverage training of epoch 21: loss -3.24062 acc 0.33333 roc_auc 0.51520 prc_auc 0.70226[0m
[93maverage test of epoch 21: loss -3.42452 acc 0.34211 roc_auc 0.69846 prc_auc 0.84775[0m
[92maverage training of epoch 22: loss -3.59145 acc 0.33333 roc_auc 0.48400 prc_auc 0.68866[0m
[93maverage test of epoch 22: loss -3.79592 acc 0.34211 roc_auc 0.36000 prc_auc 0.58625[0m
[92maverage training of epoch 23: loss -3.96428 acc 0.33333 roc_auc 0.54260 prc_auc 0.67924[0m
[93maverage test of epoch 23: loss -4.19096 acc 0.34211 roc_auc 0.56308 prc_auc 0.67105[0m
[92maverage training of epoch 24: loss -4.37153 acc 0.33333 roc_auc 0.50760 prc_auc 0.65805[0m
[93maverage test of epoch 24: loss -4.60954 acc 0.34211 roc_auc 0.39385 prc_auc 0.62700[0m
[92maverage training of epoch 25: loss -4.77831 acc 0.33333 roc_auc 0.50060 prc_auc 0.69957[0m
[93maverage test of epoch 25: loss -5.01574 acc 0.34211 roc_auc 0.43385 prc_auc 0.60706[0m
[92maverage training of epoch 26: loss -5.20223 acc 0.33333 roc_auc 0.51700 prc_auc 0.66187[0m
[93maverage test of epoch 26: loss -5.44301 acc 0.34211 roc_auc 0.57538 prc_auc 0.72446[0m
[92maverage training of epoch 27: loss -5.62486 acc 0.33333 roc_auc 0.52440 prc_auc 0.67996[0m
[93maverage test of epoch 27: loss -5.87170 acc 0.34211 roc_auc 0.37231 prc_auc 0.59661[0m
[92maverage training of epoch 28: loss -6.07300 acc 0.33333 roc_auc 0.55900 prc_auc 0.74932[0m
[93maverage test of epoch 28: loss -6.32162 acc 0.34211 roc_auc 0.21846 prc_auc 0.51749[0m
[92maverage training of epoch 29: loss -6.53184 acc 0.33333 roc_auc 0.49340 prc_auc 0.64102[0m
[93maverage test of epoch 29: loss -6.79593 acc 0.34211 roc_auc 0.40308 prc_auc 0.60552[0m
[92maverage training of epoch 30: loss -7.01104 acc 0.33333 roc_auc 0.52840 prc_auc 0.69960[0m
[93maverage test of epoch 30: loss -7.28591 acc 0.34211 roc_auc 0.57846 prc_auc 0.78612[0m
[92maverage training of epoch 31: loss -7.50794 acc 0.33333 roc_auc 0.55660 prc_auc 0.73447[0m
[93maverage test of epoch 31: loss -7.79921 acc 0.34211 roc_auc 0.52615 prc_auc 0.69352[0m
[92maverage training of epoch 32: loss -8.01915 acc 0.33333 roc_auc 0.52600 prc_auc 0.73156[0m
[93maverage test of epoch 32: loss -8.29819 acc 0.34211 roc_auc 0.48000 prc_auc 0.63616[0m
[92maverage training of epoch 33: loss -8.53438 acc 0.33333 roc_auc 0.48400 prc_auc 0.67513[0m
[93maverage test of epoch 33: loss -8.82626 acc 0.34211 roc_auc 0.57846 prc_auc 0.74620[0m
[92maverage training of epoch 34: loss -9.06372 acc 0.33333 roc_auc 0.44660 prc_auc 0.64312[0m
[93maverage test of epoch 34: loss -9.38037 acc 0.34211 roc_auc 0.63077 prc_auc 0.80886[0m
[92maverage training of epoch 35: loss -9.62667 acc 0.33333 roc_auc 0.44520 prc_auc 0.65531[0m
[93maverage test of epoch 35: loss -9.93584 acc 0.34211 roc_auc 0.47077 prc_auc 0.64512[0m
[92maverage training of epoch 36: loss -10.19082 acc 0.33333 roc_auc 0.41280 prc_auc 0.61139[0m
[93maverage test of epoch 36: loss -10.51652 acc 0.34211 roc_auc 0.59538 prc_auc 0.72626[0m
[92maverage training of epoch 37: loss -10.78179 acc 0.33333 roc_auc 0.45500 prc_auc 0.63726[0m
[93maverage test of epoch 37: loss -11.11992 acc 0.34211 roc_auc 0.45538 prc_auc 0.63769[0m
[92maverage training of epoch 38: loss -11.38196 acc 0.33333 roc_auc 0.39840 prc_auc 0.61943[0m
[93maverage test of epoch 38: loss -11.72830 acc 0.34211 roc_auc 0.63846 prc_auc 0.79391[0m
[92maverage training of epoch 39: loss -12.00761 acc 0.33333 roc_auc 0.42160 prc_auc 0.60817[0m
[93maverage test of epoch 39: loss -12.36143 acc 0.34211 roc_auc 0.59385 prc_auc 0.77446[0m
[92maverage training of epoch 40: loss -12.64411 acc 0.33333 roc_auc 0.45120 prc_auc 0.62154[0m
[93maverage test of epoch 40: loss -13.00217 acc 0.34211 roc_auc 0.28923 prc_auc 0.54616[0m
[92maverage training of epoch 41: loss -13.30424 acc 0.33333 roc_auc 0.46450 prc_auc 0.65072[0m
[93maverage test of epoch 41: loss -13.66100 acc 0.34211 roc_auc 0.51077 prc_auc 0.75635[0m
[92maverage training of epoch 42: loss -13.97369 acc 0.33333 roc_auc 0.39820 prc_auc 0.60375[0m
[93maverage test of epoch 42: loss -14.35821 acc 0.34211 roc_auc 0.45846 prc_auc 0.64741[0m
[92maverage training of epoch 43: loss -14.67032 acc 0.33333 roc_auc 0.45680 prc_auc 0.64149[0m
[93maverage test of epoch 43: loss -15.06581 acc 0.34211 roc_auc 0.54154 prc_auc 0.71476[0m
[92maverage training of epoch 44: loss -15.38343 acc 0.33333 roc_auc 0.40660 prc_auc 0.63149[0m
[93maverage test of epoch 44: loss -15.79330 acc 0.34211 roc_auc 0.61538 prc_auc 0.75909[0m
[92maverage training of epoch 45: loss -16.12188 acc 0.33333 roc_auc 0.39740 prc_auc 0.62563[0m
[93maverage test of epoch 45: loss -16.52335 acc 0.34211 roc_auc 0.24923 prc_auc 0.52593[0m
[92maverage training of epoch 46: loss -16.87188 acc 0.33333 roc_auc 0.43260 prc_auc 0.63854[0m
[93maverage test of epoch 46: loss -17.28302 acc 0.34211 roc_auc 0.42462 prc_auc 0.62794[0m
[92maverage training of epoch 47: loss -17.63783 acc 0.33333 roc_auc 0.42130 prc_auc 0.63138[0m
[93maverage test of epoch 47: loss -18.07404 acc 0.34211 roc_auc 0.56923 prc_auc 0.76740[0m
[92maverage training of epoch 48: loss -18.43081 acc 0.33333 roc_auc 0.42720 prc_auc 0.66472[0m
[93maverage test of epoch 48: loss -18.86445 acc 0.34211 roc_auc 0.31846 prc_auc 0.55869[0m
[92maverage training of epoch 49: loss -19.24911 acc 0.33333 roc_auc 0.39890 prc_auc 0.62045[0m
[93maverage test of epoch 49: loss -19.69876 acc 0.34211 roc_auc 0.56154 prc_auc 0.76856[0m
[92maverage training of epoch 50: loss -20.09275 acc 0.33333 roc_auc 0.41980 prc_auc 0.63462[0m
[93maverage test of epoch 50: loss -20.55507 acc 0.34211 roc_auc 0.46615 prc_auc 0.65892[0m
[92maverage training of epoch 51: loss -20.94766 acc 0.33333 roc_auc 0.37360 prc_auc 0.57331[0m
[93maverage test of epoch 51: loss -21.42485 acc 0.34211 roc_auc 0.57385 prc_auc 0.76619[0m
[92maverage training of epoch 52: loss -21.82607 acc 0.33333 roc_auc 0.39120 prc_auc 0.59291[0m
[93maverage test of epoch 52: loss -22.31451 acc 0.34211 roc_auc 0.56000 prc_auc 0.71981[0m
[92maverage training of epoch 53: loss -22.72891 acc 0.33333 roc_auc 0.38320 prc_auc 0.62217[0m
[93maverage test of epoch 53: loss -23.22622 acc 0.34211 roc_auc 0.48000 prc_auc 0.62138[0m
[92maverage training of epoch 54: loss -23.65619 acc 0.33333 roc_auc 0.39940 prc_auc 0.60433[0m
[93maverage test of epoch 54: loss -24.16567 acc 0.34211 roc_auc 0.56462 prc_auc 0.75118[0m
[92maverage training of epoch 55: loss -24.60762 acc 0.33333 roc_auc 0.40630 prc_auc 0.61351[0m
[93maverage test of epoch 55: loss -25.12181 acc 0.34211 roc_auc 0.59692 prc_auc 0.72347[0m
[92maverage training of epoch 56: loss -25.57872 acc 0.33333 roc_auc 0.38280 prc_auc 0.61534[0m
[93maverage test of epoch 56: loss -26.11183 acc 0.34211 roc_auc 0.55846 prc_auc 0.73859[0m
[92maverage training of epoch 57: loss -26.57911 acc 0.33333 roc_auc 0.37960 prc_auc 0.58712[0m
[93maverage test of epoch 57: loss -27.11933 acc 0.34211 roc_auc 0.35846 prc_auc 0.58335[0m
[92maverage training of epoch 58: loss -27.59610 acc 0.33333 roc_auc 0.37660 prc_auc 0.58971[0m
[93maverage test of epoch 58: loss -28.15743 acc 0.34211 roc_auc 0.51538 prc_auc 0.72289[0m
[92maverage training of epoch 59: loss -28.65176 acc 0.33333 roc_auc 0.38280 prc_auc 0.59249[0m
[93maverage test of epoch 59: loss -29.20487 acc 0.34211 roc_auc 0.39077 prc_auc 0.59395[0m
[92maverage training of epoch 60: loss -29.72110 acc 0.33333 roc_auc 0.37680 prc_auc 0.60207[0m
[93maverage test of epoch 60: loss -30.29632 acc 0.34211 roc_auc 0.31692 prc_auc 0.63535[0m
[92maverage training of epoch 61: loss -30.81718 acc 0.33333 roc_auc 0.38320 prc_auc 0.59827[0m
[93maverage test of epoch 61: loss -31.40917 acc 0.34211 roc_auc 0.48308 prc_auc 0.68461[0m
[92maverage training of epoch 62: loss -31.94494 acc 0.33333 roc_auc 0.38200 prc_auc 0.58680[0m
[93maverage test of epoch 62: loss -32.53382 acc 0.34211 roc_auc 0.54769 prc_auc 0.73198[0m
[92maverage training of epoch 63: loss -33.09484 acc 0.33333 roc_auc 0.37240 prc_auc 0.57584[0m
[93maverage test of epoch 63: loss -33.70825 acc 0.34211 roc_auc 0.52000 prc_auc 0.72159[0m
[92maverage training of epoch 64: loss -34.26529 acc 0.33333 roc_auc 0.38020 prc_auc 0.58135[0m
[93maverage test of epoch 64: loss -34.89558 acc 0.34211 roc_auc 0.58462 prc_auc 0.77220[0m
[92maverage training of epoch 65: loss -35.46989 acc 0.33333 roc_auc 0.37760 prc_auc 0.58661[0m
[93maverage test of epoch 65: loss -36.10471 acc 0.34211 roc_auc 0.37231 prc_auc 0.62182[0m
[92maverage training of epoch 66: loss -36.69983 acc 0.33333 roc_auc 0.38080 prc_auc 0.60499[0m
[93maverage test of epoch 66: loss -37.35278 acc 0.34211 roc_auc 0.61385 prc_auc 0.73682[0m
[92maverage training of epoch 67: loss -37.95657 acc 0.33333 roc_auc 0.38540 prc_auc 0.60466[0m
[93maverage test of epoch 67: loss -38.61773 acc 0.34211 roc_auc 0.64923 prc_auc 0.79902[0m
[92maverage training of epoch 68: loss -39.24176 acc 0.33333 roc_auc 0.37800 prc_auc 0.58737[0m
[93maverage test of epoch 68: loss -39.91963 acc 0.34211 roc_auc 0.45231 prc_auc 0.60746[0m
[92maverage training of epoch 69: loss -40.55071 acc 0.33333 roc_auc 0.38280 prc_auc 0.58081[0m
[93maverage test of epoch 69: loss -41.24605 acc 0.34211 roc_auc 0.61692 prc_auc 0.73837[0m
[92maverage training of epoch 70: loss -41.89577 acc 0.33333 roc_auc 0.37980 prc_auc 0.58390[0m
[93maverage test of epoch 70: loss -42.60185 acc 0.34211 roc_auc 0.62769 prc_auc 0.77983[0m
[92maverage training of epoch 71: loss -43.26455 acc 0.33333 roc_auc 0.38020 prc_auc 0.57719[0m
[93maverage test of epoch 71: loss -43.98223 acc 0.34211 roc_auc 0.46923 prc_auc 0.66986[0m
[92maverage training of epoch 72: loss -44.66119 acc 0.33333 roc_auc 0.37960 prc_auc 0.57709[0m
[93maverage test of epoch 72: loss -45.39540 acc 0.34211 roc_auc 0.34000 prc_auc 0.59586[0m
[92maverage training of epoch 73: loss -46.08433 acc 0.33333 roc_auc 0.37540 prc_auc 0.57310[0m
[93maverage test of epoch 73: loss -46.83614 acc 0.34211 roc_auc 0.46462 prc_auc 0.64276[0m
[92maverage training of epoch 74: loss -47.54529 acc 0.33333 roc_auc 0.37590 prc_auc 0.57378[0m
[93maverage test of epoch 74: loss -48.31022 acc 0.34211 roc_auc 0.44769 prc_auc 0.71146[0m
[92maverage training of epoch 75: loss -49.03140 acc 0.33333 roc_auc 0.37680 prc_auc 0.57716[0m
[93maverage test of epoch 75: loss -49.81187 acc 0.34211 roc_auc 0.60615 prc_auc 0.70166[0m
[92maverage training of epoch 76: loss -50.54997 acc 0.33333 roc_auc 0.37400 prc_auc 0.57191[0m
[93maverage test of epoch 76: loss -51.33713 acc 0.34211 roc_auc 0.56923 prc_auc 0.68083[0m
[92maverage training of epoch 77: loss -52.09458 acc 0.33333 roc_auc 0.37620 prc_auc 0.57252[0m
[93maverage test of epoch 77: loss -52.90097 acc 0.34211 roc_auc 0.48615 prc_auc 0.64827[0m
[92maverage training of epoch 78: loss -53.67602 acc 0.33333 roc_auc 0.37630 prc_auc 0.57307[0m
[93maverage test of epoch 78: loss -54.49271 acc 0.34211 roc_auc 0.45385 prc_auc 0.70050[0m
[92maverage training of epoch 79: loss -55.28136 acc 0.33333 roc_auc 0.37390 prc_auc 0.57031[0m
[93maverage test of epoch 79: loss -56.10487 acc 0.34211 roc_auc 0.56615 prc_auc 0.70570[0m
[92maverage training of epoch 80: loss -56.91834 acc 0.33333 roc_auc 0.37440 prc_auc 0.57006[0m
[93maverage test of epoch 80: loss -57.76774 acc 0.34211 roc_auc 0.41077 prc_auc 0.60785[0m
[92maverage training of epoch 81: loss -58.59258 acc 0.33333 roc_auc 0.37580 prc_auc 0.57095[0m
[93maverage test of epoch 81: loss -59.44667 acc 0.34211 roc_auc 0.45692 prc_auc 0.68438[0m
[92maverage training of epoch 82: loss -60.28944 acc 0.33333 roc_auc 0.37690 prc_auc 0.57245[0m
[93maverage test of epoch 82: loss -61.16798 acc 0.34211 roc_auc 0.44462 prc_auc 0.62183[0m
[92maverage training of epoch 83: loss -62.02713 acc 0.33333 roc_auc 0.37620 prc_auc 0.57444[0m
[93maverage test of epoch 83: loss -62.91796 acc 0.34211 roc_auc 0.55538 prc_auc 0.74949[0m
[92maverage training of epoch 84: loss -63.79541 acc 0.49333 roc_auc 0.37740 prc_auc 0.57302[0m
[93maverage test of epoch 84: loss -64.69382 acc 0.65789 roc_auc 0.43231 prc_auc 0.62809[0m
[92maverage training of epoch 85: loss -65.59327 acc 0.66667 roc_auc 0.37900 prc_auc 0.57809[0m
[93maverage test of epoch 85: loss -66.51221 acc 0.65789 roc_auc 0.42769 prc_auc 0.65507[0m
[92maverage training of epoch 86: loss -67.42801 acc 0.66667 roc_auc 0.38020 prc_auc 0.57962[0m
[93maverage test of epoch 86: loss -68.35653 acc 0.65789 roc_auc 0.46308 prc_auc 0.63857[0m
[92maverage training of epoch 87: loss -69.29356 acc 0.66667 roc_auc 0.37790 prc_auc 0.57740[0m
[93maverage test of epoch 87: loss -70.24037 acc 0.65789 roc_auc 0.68154 prc_auc 0.74113[0m
[92maverage training of epoch 88: loss -71.19128 acc 0.66667 roc_auc 0.37690 prc_auc 0.57467[0m
[93maverage test of epoch 88: loss -72.14915 acc 0.65789 roc_auc 0.48308 prc_auc 0.64444[0m
[92maverage training of epoch 89: loss -73.12658 acc 0.66667 roc_auc 0.37970 prc_auc 0.58360[0m
[93maverage test of epoch 89: loss -74.10018 acc 0.65789 roc_auc 0.48769 prc_auc 0.64014[0m
[92maverage training of epoch 90: loss -75.09549 acc 0.66667 roc_auc 0.38220 prc_auc 0.58732[0m
[93maverage test of epoch 90: loss -76.08876 acc 0.65789 roc_auc 0.53385 prc_auc 0.68721[0m
[92maverage training of epoch 91: loss -77.09533 acc 0.66667 roc_auc 0.38300 prc_auc 0.58790[0m
[93maverage test of epoch 91: loss -78.10178 acc 0.65789 roc_auc 0.50308 prc_auc 0.65774[0m
[92maverage training of epoch 92: loss -79.13191 acc 0.66667 roc_auc 0.38430 prc_auc 0.58337[0m
[93maverage test of epoch 92: loss -80.15014 acc 0.65789 roc_auc 0.39846 prc_auc 0.60122[0m
[92maverage training of epoch 93: loss -81.20466 acc 0.66667 roc_auc 0.38500 prc_auc 0.58958[0m
[93maverage test of epoch 93: loss -82.24635 acc 0.65789 roc_auc 0.42769 prc_auc 0.62365[0m
[92maverage training of epoch 94: loss -83.31250 acc 0.66667 roc_auc 0.38540 prc_auc 0.58476[0m
[93maverage test of epoch 94: loss -84.36390 acc 0.65789 roc_auc 0.27077 prc_auc 0.53597[0m
[92maverage training of epoch 95: loss -85.45402 acc 0.66667 roc_auc 0.38650 prc_auc 0.59047[0m
[93maverage test of epoch 95: loss -86.52726 acc 0.65789 roc_auc 0.51231 prc_auc 0.68153[0m
[92maverage training of epoch 96: loss -87.63634 acc 0.66667 roc_auc 0.38720 prc_auc 0.59162[0m
[93maverage test of epoch 96: loss -88.72029 acc 0.65789 roc_auc 0.40308 prc_auc 0.61153[0m
[92maverage training of epoch 97: loss -89.84856 acc 0.66667 roc_auc 0.37800 prc_auc 0.57985[0m
[93maverage test of epoch 97: loss -90.95069 acc 0.65789 roc_auc 0.48769 prc_auc 0.65424[0m
[92maverage training of epoch 98: loss -92.09999 acc 0.66667 roc_auc 0.38780 prc_auc 0.59250[0m
[93maverage test of epoch 98: loss -93.22153 acc 0.65789 roc_auc 0.69231 prc_auc 0.78700[0m
[92maverage training of epoch 99: loss -94.39196 acc 0.66667 roc_auc 0.38840 prc_auc 0.59301[0m
[93maverage test of epoch 99: loss -95.52018 acc 0.65789 roc_auc 0.31231 prc_auc 0.57873[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=4, bias=True)
    (ReLU1): ReLU()
    (Linear2): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss 0.16213 acc 0.33775 roc_auc 0.52804 prc_auc 0.68008[0m
[93maverage test of epoch 0: loss 0.14206 acc 0.32432 roc_auc 0.66000 prc_auc 0.75492[0m
[92maverage training of epoch 1: loss 0.10978 acc 0.33775 roc_auc 0.58510 prc_auc 0.72345[0m
[93maverage test of epoch 1: loss 0.12657 acc 0.32432 roc_auc 0.39667 prc_auc 0.65878[0m
[92maverage training of epoch 2: loss 0.07046 acc 0.33775 roc_auc 0.50725 prc_auc 0.65051[0m
[93maverage test of epoch 2: loss 0.05644 acc 0.32432 roc_auc 0.48333 prc_auc 0.67120[0m
[92maverage training of epoch 3: loss 0.01448 acc 0.33775 roc_auc 0.51098 prc_auc 0.65773[0m
[93maverage test of epoch 3: loss 0.02658 acc 0.32432 roc_auc 0.51000 prc_auc 0.70227[0m
[92maverage training of epoch 4: loss -0.05729 acc 0.33775 roc_auc 0.56706 prc_auc 0.72485[0m
[93maverage test of epoch 4: loss -0.06066 acc 0.32432 roc_auc 0.54667 prc_auc 0.71869[0m
[92maverage training of epoch 5: loss -0.12840 acc 0.33775 roc_auc 0.55922 prc_auc 0.71593[0m
[93maverage test of epoch 5: loss -0.13933 acc 0.32432 roc_auc 0.60000 prc_auc 0.78781[0m
[92maverage training of epoch 6: loss -0.20043 acc 0.33775 roc_auc 0.55529 prc_auc 0.73400[0m
[93maverage test of epoch 6: loss -0.22924 acc 0.32432 roc_auc 0.58667 prc_auc 0.78336[0m
[92maverage training of epoch 7: loss -0.25967 acc 0.33775 roc_auc 0.47216 prc_auc 0.64438[0m
[93maverage test of epoch 7: loss -0.26648 acc 0.32432 roc_auc 0.44000 prc_auc 0.64398[0m
[92maverage training of epoch 8: loss -0.36385 acc 0.33775 roc_auc 0.54490 prc_auc 0.71476[0m
[93maverage test of epoch 8: loss -0.39521 acc 0.32432 roc_auc 0.60333 prc_auc 0.80581[0m
[92maverage training of epoch 9: loss -0.48327 acc 0.33775 roc_auc 0.62510 prc_auc 0.77955[0m
[93maverage test of epoch 9: loss -0.51326 acc 0.32432 roc_auc 0.69667 prc_auc 0.84707[0m
[92maverage training of epoch 10: loss -0.58786 acc 0.33775 roc_auc 0.65804 prc_auc 0.78767[0m
[93maverage test of epoch 10: loss -0.53350 acc 0.32432 roc_auc 0.39333 prc_auc 0.66460[0m
[92maverage training of epoch 11: loss -0.68738 acc 0.33775 roc_auc 0.56510 prc_auc 0.74193[0m
[93maverage test of epoch 11: loss -0.64552 acc 0.32432 roc_auc 0.37000 prc_auc 0.64698[0m
[92maverage training of epoch 12: loss -0.79213 acc 0.33775 roc_auc 0.55000 prc_auc 0.74307[0m
[93maverage test of epoch 12: loss -0.79533 acc 0.32432 roc_auc 0.62333 prc_auc 0.77806[0m
[92maverage training of epoch 13: loss -0.90539 acc 0.33775 roc_auc 0.57882 prc_auc 0.73633[0m
[93maverage test of epoch 13: loss -0.92673 acc 0.32432 roc_auc 0.54333 prc_auc 0.71882[0m
[92maverage training of epoch 14: loss -1.05372 acc 0.33775 roc_auc 0.60647 prc_auc 0.76570[0m
[93maverage test of epoch 14: loss -0.97171 acc 0.32432 roc_auc 0.41000 prc_auc 0.68746[0m
[92maverage training of epoch 15: loss -1.17741 acc 0.33775 roc_auc 0.59824 prc_auc 0.76877[0m
[93maverage test of epoch 15: loss -1.19057 acc 0.32432 roc_auc 0.55333 prc_auc 0.72674[0m
[92maverage training of epoch 16: loss -1.32668 acc 0.33775 roc_auc 0.59882 prc_auc 0.76510[0m
[93maverage test of epoch 16: loss -1.31719 acc 0.32432 roc_auc 0.44667 prc_auc 0.70162[0m
[92maverage training of epoch 17: loss -1.52971 acc 0.33775 roc_auc 0.63588 prc_auc 0.79871[0m
[93maverage test of epoch 17: loss -1.50584 acc 0.32432 roc_auc 0.46333 prc_auc 0.74915[0m
[92maverage training of epoch 18: loss -1.71486 acc 0.33775 roc_auc 0.63706 prc_auc 0.79390[0m
[93maverage test of epoch 18: loss -1.69032 acc 0.32432 roc_auc 0.52333 prc_auc 0.72382[0m
[92maverage training of epoch 19: loss -1.88698 acc 0.33775 roc_auc 0.58255 prc_auc 0.76109[0m
[93maverage test of epoch 19: loss -1.86753 acc 0.32432 roc_auc 0.57000 prc_auc 0.72882[0m
[92maverage training of epoch 20: loss -2.15355 acc 0.33775 roc_auc 0.75529 prc_auc 0.86505[0m
[93maverage test of epoch 20: loss -2.13167 acc 0.32432 roc_auc 0.64667 prc_auc 0.82181[0m
[92maverage training of epoch 21: loss -2.32449 acc 0.33775 roc_auc 0.64941 prc_auc 0.81113[0m
[93maverage test of epoch 21: loss -2.29920 acc 0.32432 roc_auc 0.52333 prc_auc 0.75264[0m
[92maverage training of epoch 22: loss -2.50914 acc 0.33775 roc_auc 0.65490 prc_auc 0.80381[0m
[93maverage test of epoch 22: loss -2.44663 acc 0.32432 roc_auc 0.44667 prc_auc 0.71130[0m
[92maverage training of epoch 23: loss -2.71529 acc 0.33775 roc_auc 0.66647 prc_auc 0.80207[0m
[93maverage test of epoch 23: loss -2.73218 acc 0.32432 roc_auc 0.69333 prc_auc 0.85146[0m
[92maverage training of epoch 24: loss -2.90194 acc 0.33775 roc_auc 0.64569 prc_auc 0.80681[0m
[93maverage test of epoch 24: loss -2.87737 acc 0.32432 roc_auc 0.57667 prc_auc 0.76392[0m
[92maverage training of epoch 25: loss -3.07112 acc 0.33775 roc_auc 0.52980 prc_auc 0.71285[0m
[93maverage test of epoch 25: loss -3.03200 acc 0.32432 roc_auc 0.55000 prc_auc 0.68700[0m
[92maverage training of epoch 26: loss -3.31751 acc 0.33775 roc_auc 0.60922 prc_auc 0.76879[0m
[93maverage test of epoch 26: loss -3.27700 acc 0.32432 roc_auc 0.49667 prc_auc 0.66382[0m
[92maverage training of epoch 27: loss -3.48375 acc 0.33775 roc_auc 0.53000 prc_auc 0.67570[0m
[93maverage test of epoch 27: loss -3.47932 acc 0.32432 roc_auc 0.52333 prc_auc 0.68243[0m
[92maverage training of epoch 28: loss -3.71148 acc 0.33775 roc_auc 0.53020 prc_auc 0.68953[0m
[93maverage test of epoch 28: loss -3.70899 acc 0.32432 roc_auc 0.49667 prc_auc 0.70678[0m
[92maverage training of epoch 29: loss -3.94899 acc 0.33775 roc_auc 0.58059 prc_auc 0.71795[0m
[93maverage test of epoch 29: loss -3.90174 acc 0.32432 roc_auc 0.65333 prc_auc 0.81050[0m
[92maverage training of epoch 30: loss -4.13566 acc 0.33775 roc_auc 0.49647 prc_auc 0.68660[0m
[93maverage test of epoch 30: loss -4.07868 acc 0.32432 roc_auc 0.46333 prc_auc 0.67200[0m
[92maverage training of epoch 31: loss -4.42970 acc 0.33775 roc_auc 0.57980 prc_auc 0.73057[0m
[93maverage test of epoch 31: loss -4.38892 acc 0.32432 roc_auc 0.53000 prc_auc 0.76306[0m
[92maverage training of epoch 32: loss -4.67703 acc 0.33775 roc_auc 0.61667 prc_auc 0.76728[0m
[93maverage test of epoch 32: loss -4.62937 acc 0.32432 roc_auc 0.52667 prc_auc 0.74694[0m
[92maverage training of epoch 33: loss -4.91924 acc 0.33775 roc_auc 0.58627 prc_auc 0.73223[0m
[93maverage test of epoch 33: loss -4.87891 acc 0.32432 roc_auc 0.37333 prc_auc 0.64731[0mUsing backend: pytorch

[92maverage training of epoch 34: loss -5.17227 acc 0.33775 roc_auc 0.55314 prc_auc 0.69168[0m
[93maverage test of epoch 34: loss -5.11250 acc 0.32432 roc_auc 0.40333 prc_auc 0.63572[0m
[92maverage training of epoch 35: loss -5.46168 acc 0.33775 roc_auc 0.45804 prc_auc 0.65393[0m
[93maverage test of epoch 35: loss -5.43425 acc 0.32432 roc_auc 0.47000 prc_auc 0.70740[0m
[92maverage training of epoch 36: loss -5.80508 acc 0.33775 roc_auc 0.56725 prc_auc 0.71659[0m
[93maverage test of epoch 36: loss -5.73058 acc 0.32432 roc_auc 0.48333 prc_auc 0.64330[0m
[92maverage training of epoch 37: loss -6.09031 acc 0.33775 roc_auc 0.53314 prc_auc 0.67047[0m
[93maverage test of epoch 37: loss -6.05551 acc 0.32432 roc_auc 0.43333 prc_auc 0.67211[0m
[92maverage training of epoch 38: loss -6.40618 acc 0.33775 roc_auc 0.46882 prc_auc 0.65507[0m
[93maverage test of epoch 38: loss -6.40072 acc 0.32432 roc_auc 0.42333 prc_auc 0.68542[0m
[92maverage training of epoch 39: loss -6.76262 acc 0.33775 roc_auc 0.48902 prc_auc 0.63584[0m
[93maverage test of epoch 39: loss -6.79135 acc 0.32432 roc_auc 0.45000 prc_auc 0.71040[0m
[92maverage training of epoch 40: loss -7.17538 acc 0.33775 roc_auc 0.53471 prc_auc 0.71564[0m
[93maverage test of epoch 40: loss -7.10256 acc 0.32432 roc_auc 0.33667 prc_auc 0.62333[0m
[92maverage training of epoch 41: loss -7.55028 acc 0.33775 roc_auc 0.51314 prc_auc 0.67536[0m
[93maverage test of epoch 41: loss -7.52751 acc 0.32432 roc_auc 0.42333 prc_auc 0.63991[0m
[92maverage training of epoch 42: loss -7.96669 acc 0.33775 roc_auc 0.55392 prc_auc 0.68848[0m
[93maverage test of epoch 42: loss -7.96065 acc 0.32432 roc_auc 0.60667 prc_auc 0.79623[0m
[92maverage training of epoch 43: loss -8.38693 acc 0.33775 roc_auc 0.52275 prc_auc 0.65956[0m
[93maverage test of epoch 43: loss -8.37656 acc 0.32432 roc_auc 0.47000 prc_auc 0.71576[0m
[92maverage training of epoch 44: loss -8.83964 acc 0.33775 roc_auc 0.59020 prc_auc 0.75638[0m
[93maverage test of epoch 44: loss -8.83257 acc 0.32432 roc_auc 0.44333 prc_auc 0.71733[0m
[92maverage training of epoch 45: loss -9.29255 acc 0.33775 roc_auc 0.54157 prc_auc 0.67737[0m
[93maverage test of epoch 45: loss -9.23196 acc 0.32432 roc_auc 0.53000 prc_auc 0.68781[0m
[92maverage training of epoch 46: loss -9.78665 acc 0.33775 roc_auc 0.59490 prc_auc 0.73571[0m
[93maverage test of epoch 46: loss -9.70778 acc 0.32432 roc_auc 0.22333 prc_auc 0.53379[0m
[92maverage training of epoch 47: loss -10.23603 acc 0.33775 roc_auc 0.50490 prc_auc 0.67049[0m
[93maverage test of epoch 47: loss -10.23371 acc 0.32432 roc_auc 0.54000 prc_auc 0.69311[0m
[92maverage training of epoch 48: loss -10.73181 acc 0.33775 roc_auc 0.49941 prc_auc 0.67003[0m
[93maverage test of epoch 48: loss -10.77811 acc 0.32432 roc_auc 0.68000 prc_auc 0.82387[0m
[92maverage training of epoch 49: loss -11.27990 acc 0.33775 roc_auc 0.56843 prc_auc 0.71657[0m
[93maverage test of epoch 49: loss -11.29693 acc 0.32432 roc_auc 0.64667 prc_auc 0.82544[0m
[92maverage training of epoch 50: loss -11.81776 acc 0.33775 roc_auc 0.55294 prc_auc 0.67403[0m
[93maverage test of epoch 50: loss -11.81033 acc 0.32432 roc_auc 0.66333 prc_auc 0.82479[0m
[92maverage training of epoch 51: loss -12.35397 acc 0.33775 roc_auc 0.50255 prc_auc 0.67346[0m
[93maverage test of epoch 51: loss -12.36263 acc 0.32432 roc_auc 0.58000 prc_auc 0.76032[0m
[92maverage training of epoch 52: loss -12.94077 acc 0.33775 roc_auc 0.58745 prc_auc 0.72028[0m
[93maverage test of epoch 52: loss -12.90879 acc 0.32432 roc_auc 0.37667 prc_auc 0.61778[0m
[92maverage training of epoch 53: loss -13.53193 acc 0.33775 roc_auc 0.54392 prc_auc 0.69642[0m
[93maverage test of epoch 53: loss -13.57832 acc 0.32432 roc_auc 0.67000 prc_auc 0.80283[0m
[92maverage training of epoch 54: loss -14.14202 acc 0.33775 roc_auc 0.57627 prc_auc 0.71979[0m
[93maverage test of epoch 54: loss -14.11206 acc 0.32432 roc_auc 0.54000 prc_auc 0.73390[0m
[92maverage training of epoch 55: loss -14.74263 acc 0.33775 roc_auc 0.48804 prc_auc 0.63588[0m
[93maverage test of epoch 55: loss -14.77242 acc 0.32432 roc_auc 0.56000 prc_auc 0.73266[0m
[92maverage training of epoch 56: loss -15.41354 acc 0.33775 roc_auc 0.52333 prc_auc 0.68196[0m
[93maverage test of epoch 56: loss -15.38819 acc 0.32432 roc_auc 0.44667 prc_auc 0.66743[0m
[92maverage training of epoch 57: loss -16.05457 acc 0.33775 roc_auc 0.51902 prc_auc 0.67490[0m
[93maverage test of epoch 57: loss -16.07967 acc 0.32432 roc_auc 0.54333 prc_auc 0.76519[0m
[92maverage training of epoch 58: loss -16.77323 acc 0.33775 roc_auc 0.57294 prc_auc 0.72159[0m
[93maverage test of epoch 58: loss -16.73118 acc 0.32432 roc_auc 0.37667 prc_auc 0.63110[0m
[92maverage training of epoch 59: loss -17.45681 acc 0.33775 roc_auc 0.51824 prc_auc 0.67926[0m
[93maverage test of epoch 59: loss -17.45251 acc 0.32432 roc_auc 0.67667 prc_auc 0.78156[0m
[92maverage training of epoch 60: loss -18.14979 acc 0.33775 roc_auc 0.48431 prc_auc 0.64119[0m
[93maverage test of epoch 60: loss -18.17203 acc 0.32432 roc_auc 0.59333 prc_auc 0.73727[0m
[92maverage training of epoch 61: loss -18.89740 acc 0.33775 roc_auc 0.54824 prc_auc 0.70384[0m
[93maverage test of epoch 61: loss -18.90882 acc 0.32432 roc_auc 0.54333 prc_auc 0.76239[0m
[92maverage training of epoch 62: loss -19.67089 acc 0.33775 roc_auc 0.54647 prc_auc 0.69493[0m
[93maverage test of epoch 62: loss -19.61808 acc 0.32432 roc_auc 0.48000 prc_auc 0.64002[0m
[92maverage training of epoch 63: loss -20.41910 acc 0.33775 roc_auc 0.49647 prc_auc 0.65051[0m
[93maverage test of epoch 63: loss -20.43021 acc 0.32432 roc_auc 0.52333 prc_auc 0.70624[0m
[92maverage training of epoch 64: loss -21.23208 acc 0.33775 roc_auc 0.58922 prc_auc 0.75677[0m
[93maverage test of epoch 64: loss -21.17485 acc 0.32432 roc_auc 0.30333 prc_auc 0.57498[0m
[92maverage training of epoch 65: loss -22.01971 acc 0.33775 roc_auc 0.48745 prc_auc 0.62833[0m
[93maverage test of epoch 65: loss -22.01640 acc 0.32432 roc_auc 0.45667 prc_auc 0.66378[0m
[92maverage training of epoch 66: loss -22.86084 acc 0.33775 roc_auc 0.57294 prc_auc 0.72377[0m
[93maverage test of epoch 66: loss -22.87062 acc 0.32432 roc_auc 0.55000 prc_auc 0.73485[0m
[92maverage training of epoch 67: loss -23.73448 acc 0.33775 roc_auc 0.57000 prc_auc 0.71524[0m
[93maverage test of epoch 67: loss -23.69712 acc 0.32432 roc_auc 0.32667 prc_auc 0.60220[0m
[92maverage training of epoch 68: loss -24.60993 acc 0.33775 roc_auc 0.56627 prc_auc 0.74035[0m
[93maverage test of epoch 68: loss -24.59192 acc 0.32432 roc_auc 0.45333 prc_auc 0.66003[0m
[92maverage training of epoch 69: loss -25.51616 acc 0.33775 roc_auc 0.52118 prc_auc 0.69640[0m
[93maverage test of epoch 69: loss -25.53384 acc 0.32432 roc_auc 0.52000 prc_auc 0.73613[0m
[92maverage training of epoch 70: loss -26.42355 acc 0.33775 roc_auc 0.54196 prc_auc 0.69969[0m
[93maverage test of epoch 70: loss -26.44222 acc 0.32432 roc_auc 0.63000 prc_auc 0.79138[0m
[92maverage training of epoch 71: loss -27.37240 acc 0.33775 roc_auc 0.52471 prc_auc 0.66200[0m
[93maverage test of epoch 71: loss -27.37023 acc 0.32432 roc_auc 0.60333 prc_auc 0.75243[0m
[92maverage training of epoch 72: loss -28.35067 acc 0.33775 roc_auc 0.55686 prc_auc 0.68851[0m
[93maverage test of epoch 72: loss -28.34142 acc 0.32432 roc_auc 0.67833 prc_auc 0.84264[0m
[92maverage training of epoch 73: loss -29.32333 acc 0.33775 roc_auc 0.50980 prc_auc 0.66195[0m
[93maverage test of epoch 73: loss -29.32201 acc 0.32432 roc_auc 0.63833 prc_auc 0.78163[0m
[92maverage training of epoch 74: loss -30.34226 acc 0.33775 roc_auc 0.53784 prc_auc 0.67349[0m
[93maverage test of epoch 74: loss -30.31511 acc 0.32432 roc_auc 0.50333 prc_auc 0.74662[0m
[92maverage training of epoch 75: loss -31.36886 acc 0.33775 roc_auc 0.50451 prc_auc 0.65776[0m
[93maverage test of epoch 75: loss -31.30801 acc 0.32432 roc_auc 0.47833 prc_auc 0.63829[0m
[92maverage training of epoch 76: loss -32.40776 acc 0.33775 roc_auc 0.52686 prc_auc 0.67332[0m
[93maverage test of epoch 76: loss -32.35196 acc 0.32432 roc_auc 0.42333 prc_auc 0.69717[0m
[92maverage training of epoch 77: loss -33.49560 acc 0.33775 roc_auc 0.53667 prc_auc 0.69305[0m
[93maverage test of epoch 77: loss -33.43953 acc 0.32432 roc_auc 0.46667 prc_auc 0.64662[0m
[92maverage training of epoch 78: loss -34.57884 acc 0.33775 roc_auc 0.53745 prc_auc 0.66115[0m
[93maverage test of epoch 78: loss -34.56497 acc 0.32432 roc_auc 0.40667 prc_auc 0.64517[0m
[92maverage training of epoch 79: loss -35.68838 acc 0.33775 roc_auc 0.56294 prc_auc 0.72077[0m
[93maverage test of epoch 79: loss -35.64755 acc 0.32432 roc_auc 0.55000 prc_auc 0.71262[0m
[92maverage training of epoch 80: loss -36.81053 acc 0.33775 roc_auc 0.52863 prc_auc 0.68318[0m
[93maverage test of epoch 80: loss -36.81152 acc 0.32432 roc_auc 0.49000 prc_auc 0.69612[0m
[92maverage training of epoch 81: loss -37.98534 acc 0.33775 roc_auc 0.57765 prc_auc 0.70509[0m
[93maverage test of epoch 81: loss -37.94340 acc 0.32432 roc_auc 0.41500 prc_auc 0.61544[0m
[92maverage training of epoch 82: loss -39.15013 acc 0.33775 roc_auc 0.51725 prc_auc 0.66079[0m
[93maverage test of epoch 82: loss -39.12553 acc 0.32432 roc_auc 0.48167 prc_auc 0.63040[0m
[92maverage training of epoch 83: loss -40.35822 acc 0.33775 roc_auc 0.53255 prc_auc 0.68576[0m
[93maverage test of epoch 83: loss -40.33487 acc 0.32432 roc_auc 0.61000 prc_auc 0.79506[0m
[92maverage training of epoch 84: loss -41.58504 acc 0.33775 roc_auc 0.58863 prc_auc 0.73030[0m
[93maverage test of epoch 84: loss -41.55928 acc 0.32432 roc_auc 0.49833 prc_auc 0.71065[0m
[92maverage training of epoch 85: loss -42.81620 acc 0.33775 roc_auc 0.51804 prc_auc 0.66429[0m
[93maverage test of epoch 85: loss -42.81713 acc 0.32432 roc_auc 0.63333 prc_auc 0.81935[0m
[92maverage training of epoch 86: loss -44.09301 acc 0.33775 roc_auc 0.57137 prc_auc 0.71983[0m
[93maverage test of epoch 86: loss -44.07480 acc 0.32432 roc_auc 0.43167 prc_auc 0.66667[0m
[92maverage training of epoch 87: loss -45.38262 acc 0.33775 roc_auc 0.57392 prc_auc 0.69948[0m
[93maverage test of epoch 87: loss -45.35245 acc 0.32432 roc_auc 0.46667 prc_auc 0.65022[0m
[92maverage training of epoch 88: loss -46.70290 acc 0.33775 roc_auc 0.55882 prc_auc 0.69466[0m
[93maverage test of epoch 88: loss -46.69036 acc 0.32432 roc_auc 0.64667 prc_auc 0.75619[0m
[92maverage training of epoch 89: loss -48.06113 acc 0.33775 roc_auc 0.54706 prc_auc 0.68395[0m
[93maverage test of epoch 89: loss -48.04653 acc 0.32432 roc_auc 0.53500 prc_auc 0.76925[0m
[92maverage training of epoch 90: loss -49.40795 acc 0.33775 roc_auc 0.53667 prc_auc 0.68492[0m
[93maverage test of epoch 90: loss -49.38928 acc 0.32432 roc_auc 0.53833 prc_auc 0.68883[0m
[92maverage training of epoch 91: loss -50.79846 acc 0.33775 roc_auc 0.54686 prc_auc 0.69077[0m
[93maverage test of epoch 91: loss -50.78561 acc 0.32432 roc_auc 0.63167 prc_auc 0.78159[0m
[92maverage training of epoch 92: loss -52.22162 acc 0.33775 roc_auc 0.57431 prc_auc 0.72136[0m
[93maverage test of epoch 92: loss -52.20423 acc 0.32432 roc_auc 0.42667 prc_auc 0.67002[0m
[92maverage training of epoch 93: loss -53.63014 acc 0.33775 roc_auc 0.53804 prc_auc 0.69047[0m
[93maverage test of epoch 93: loss -53.62131 acc 0.32432 roc_auc 0.41500 prc_auc 0.63765[0m
[92maverage training of epoch 94: loss -55.09529 acc 0.33775 roc_auc 0.55333 prc_auc 0.69679[0m
[93maverage test of epoch 94: loss -55.09929 acc 0.32432 roc_auc 0.40333 prc_auc 0.70012[0m
[92maverage training of epoch 95: loss -56.58217 acc 0.33775 roc_auc 0.55529 prc_auc 0.69502[0m
[93maverage test of epoch 95: loss -56.57837 acc 0.32432 roc_auc 0.50333 prc_auc 0.69749[0m
[92maverage training of epoch 96: loss -58.09250 acc 0.33775 roc_auc 0.55118 prc_auc 0.68416[0m
[93maverage test of epoch 96: loss -58.07598 acc 0.32432 roc_auc 0.50167 prc_auc 0.69621[0m
[92maverage training of epoch 97: loss -59.62543 acc 0.33775 roc_auc 0.54961 prc_auc 0.69053[0m
[93maverage test of epoch 97: loss -59.63049 acc 0.32432 roc_auc 0.57167 prc_auc 0.79144[0m
[92maverage training of epoch 98: loss -61.18289 acc 0.33775 roc_auc 0.55549 prc_auc 0.68866[0m
[93maverage test of epoch 98: loss -61.17288 acc 0.32432 roc_auc 0.59500 prc_auc 0.75266[0m
[92maverage training of epoch 99: loss -62.77901 acc 0.33775 roc_auc 0.54412 prc_auc 0.69508[0m
[93maverage test of epoch 99: loss -62.76594 acc 0.32432 roc_auc 0.51000 prc_auc 0.72339[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=4, bias=True)
    (ReLU1): ReLU()
    (Linear2): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss 0.74931 acc 0.43709 roc_auc 0.44765 prc_auc 0.64327[0m
[93maverage test of epoch 0: loss 0.46357 acc 0.70270 roc_auc 0.76333 prc_auc 0.87769[0m
[92maverage training of epoch 1: loss 0.23296 acc 0.64901 roc_auc 0.45510 prc_auc 0.68073[0m
[93maverage test of epoch 1: loss 0.00936 acc 0.67568 roc_auc 0.63667 prc_auc 0.71689[0m
[92maverage training of epoch 2: loss 0.02364 acc 0.66225 roc_auc 0.48569 prc_auc 0.64845[0m
[93maverage test of epoch 2: loss -0.04022 acc 0.67568 roc_auc 0.61000 prc_auc 0.82309[0m
[92maverage training of epoch 3: loss -0.04975 acc 0.66225 roc_auc 0.51961 prc_auc 0.66724[0m
[93maverage test of epoch 3: loss -0.08051 acc 0.67568 roc_auc 0.31667 prc_auc 0.61285[0m
[92maverage training of epoch 4: loss -0.10442 acc 0.66225 roc_auc 0.45510 prc_auc 0.64827[0m
[93maverage test of epoch 4: loss -0.21199 acc 0.67568 roc_auc 0.79000 prc_auc 0.90545[0m
[92maverage training of epoch 5: loss -0.20547 acc 0.66225 roc_auc 0.48235 prc_auc 0.66260[0m
[93maverage test of epoch 5: loss -0.33466 acc 0.67568 roc_auc 0.63333 prc_auc 0.75711[0m
[92maverage training of epoch 6: loss -0.39595 acc 0.66225 roc_auc 0.48471 prc_auc 0.65995[0m
[93maverage test of epoch 6: loss -0.55122 acc 0.67568 roc_auc 0.63667 prc_auc 0.83415[0m
[92maverage training of epoch 7: loss -0.60111 acc 0.66225 roc_auc 0.55725 prc_auc 0.72242[0m
[93maverage test of epoch 7: loss -0.71766 acc 0.67568 roc_auc 0.50000 prc_auc 0.75751[0m
[92maverage training of epoch 8: loss -0.79267 acc 0.66225 roc_auc 0.54216 prc_auc 0.72533[0m
[93maverage test of epoch 8: loss -0.94730 acc 0.67568 roc_auc 0.62333 prc_auc 0.80834[0m
[92maverage training of epoch 9: loss -0.98266 acc 0.66225 roc_auc 0.46039 prc_auc 0.65744[0m
[93maverage test of epoch 9: loss -1.17771 acc 0.67568 roc_auc 0.73333 prc_auc 0.85424[0m
[92maverage training of epoch 10: loss -1.21470 acc 0.66225 roc_auc 0.52725 prc_auc 0.71103[0m
[93maverage test of epoch 10: loss -1.39364 acc 0.67568 roc_auc 0.63000 prc_auc 0.81710[0m
[92maverage training of epoch 11: loss -1.43767 acc 0.66225 roc_auc 0.49843 prc_auc 0.68199[0m
[93maverage test of epoch 11: loss -1.65931 acc 0.67568 roc_auc 0.79667 prc_auc 0.89864[0m
[92maverage training of epoch 12: loss -1.67442 acc 0.66225 roc_auc 0.49471 prc_auc 0.66375[0m
[93maverage test of epoch 12: loss -1.88822 acc 0.67568 roc_auc 0.58667 prc_auc 0.80542[0m
[92maverage training of epoch 13: loss -1.91245 acc 0.66225 roc_auc 0.46627 prc_auc 0.66862[0m
[93maverage test of epoch 13: loss -2.11238 acc 0.67568 roc_auc 0.37000 prc_auc 0.69891[0m
[92maverage training of epoch 14: loss -2.16035 acc 0.66225 roc_auc 0.45676 prc_auc 0.66134[0m
[93maverage test of epoch 14: loss -2.40146 acc 0.67568 roc_auc 0.53333 prc_auc 0.78337[0m
[92maverage training of epoch 15: loss -2.41812 acc 0.66225 roc_auc 0.44500 prc_auc 0.62636[0m
[93maverage test of epoch 15: loss -2.67465 acc 0.67568 roc_auc 0.67333 prc_auc 0.85044[0m
[92maverage training of epoch 16: loss -2.67770 acc 0.66225 roc_auc 0.41147 prc_auc 0.59972[0m
[93maverage test of epoch 16: loss -2.93517 acc 0.67568 roc_auc 0.58500 prc_auc 0.78711[0m
[92maverage training of epoch 17: loss -2.96873 acc 0.66225 roc_auc 0.48235 prc_auc 0.67694[0m
[93maverage test of epoch 17: loss -3.22085 acc 0.67568 roc_auc 0.56500 prc_auc 0.75634[0m
[92maverage training of epoch 18: loss -3.21813 acc 0.66225 roc_auc 0.43618 prc_auc 0.62199[0m
[93maverage test of epoch 18: loss -3.51929 acc 0.67568 roc_auc 0.63000 prc_auc 0.83235[0m
[92maverage training of epoch 19: loss -3.50071 acc 0.66225 roc_auc 0.40637 prc_auc 0.60590[0m
[93maverage test of epoch 19: loss -3.83495 acc 0.67568 roc_auc 0.70833 prc_auc 0.85037[0m
[92maverage training of epoch 20: loss -3.79355 acc 0.66225 roc_auc 0.44343 prc_auc 0.61211[0m
[93maverage test of epoch 20: loss -4.08563 acc 0.67568 roc_auc 0.51167 prc_auc 0.71428[0m
[92maverage training of epoch 21: loss -4.09505 acc 0.66225 roc_auc 0.47765 prc_auc 0.66274[0m
[93maverage test of epoch 21: loss -4.39634 acc 0.67568 roc_auc 0.54167 prc_auc 0.70241[0m
[92maverage training of epoch 22: loss -4.39173 acc 0.66225 roc_auc 0.48588 prc_auc 0.68595[0m
[93maverage test of epoch 22: loss -4.69641 acc 0.67568 roc_auc 0.56000 prc_auc 0.76039[0m
[92maverage training of epoch 23: loss -4.67432 acc 0.66225 roc_auc 0.40098 prc_auc 0.63123[0m
[93maverage test of epoch 23: loss -5.04568 acc 0.67568 roc_auc 0.53167 prc_auc 0.71340[0m
[92maverage training of epoch 24: loss -4.99059 acc 0.66225 roc_auc 0.50137 prc_auc 0.66844[0m
[93maverage test of epoch 24: loss -5.32868 acc 0.67568 roc_auc 0.49167 prc_auc 0.69677[0m
[92maverage training of epoch 25: loss -5.30566 acc 0.66225 roc_auc 0.49814 prc_auc 0.65399[0m
[93maverage test of epoch 25: loss -5.63288 acc 0.67568 roc_auc 0.47333 prc_auc 0.70151[0m
[92maverage training of epoch 26: loss -5.63873 acc 0.66225 roc_auc 0.52343 prc_auc 0.69076[0m
[93maverage test of epoch 26: loss -5.94390 acc 0.67568 roc_auc 0.40000 prc_auc 0.62178[0m
[92maverage training of epoch 27: loss -5.99977 acc 0.66225 roc_auc 0.53078 prc_auc 0.66710[0m
[93maverage test of epoch 27: loss -6.34830 acc 0.67568 roc_auc 0.62000 prc_auc 0.73919[0m
[92maverage training of epoch 28: loss -6.32112 acc 0.66225 roc_auc 0.53098 prc_auc 0.67074[0m
[93maverage test of epoch 28: loss -6.68353 acc 0.67568 roc_auc 0.58500 prc_auc 0.71428[0m
[92maverage training of epoch 29: loss -6.64628 acc 0.66225 roc_auc 0.48637 prc_auc 0.65640[0m
[93maverage test of epoch 29: loss -7.03778 acc 0.67568 roc_auc 0.54667 prc_auc 0.70038[0m
[92maverage training of epoch 30: loss -6.97107 acc 0.66225 roc_auc 0.41431 prc_auc 0.62431[0m
[93maverage test of epoch 30: loss -7.36765 acc 0.67568 roc_auc 0.37667 prc_auc 0.62263[0m
[92maverage training of epoch 31: loss -7.36399 acc 0.66225 roc_auc 0.50029 prc_auc 0.66271[0m
[93maverage test of epoch 31: loss -7.78055 acc 0.67568 roc_auc 0.62500 prc_auc 0.73529[0m
[92maverage training of epoch 32: loss -7.72358 acc 0.66225 roc_auc 0.48549 prc_auc 0.65669[0m
[93maverage test of epoch 32: loss -8.11217 acc 0.67568 roc_auc 0.49333 prc_auc 0.67279[0m
[92maverage training of epoch 33: loss -8.07242 acc 0.66225 roc_auc 0.43686 prc_auc 0.63601[0m
[93maverage test of epoch 33: loss -8.47788 acc 0.67568 roc_auc 0.52000 prc_auc 0.68536[0m
[92maverage training of epoch 34: loss -8.46921 acc 0.66225 roc_auc 0.49882 prc_auc 0.66174[0m
[93maverage test of epoch 34: loss -8.86161 acc 0.67568 roc_auc 0.46000 prc_auc 0.65863[0m
[92maverage training of epoch 35: loss -8.84224 acc 0.66225 roc_auc 0.49000 prc_auc 0.65781[0m
[93maverage test of epoch 35: loss -9.31507 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 36: loss -9.25882 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 36: loss -9.72090 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 37: loss -9.67640 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 37: loss -10.08370 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 38: loss -10.09283 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 38: loss -10.49473 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 39: loss -10.50626 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 39: loss -10.96747 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -10.93814 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 40: loss -11.39135 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -11.38983 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 41: loss -11.91684 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -11.86300 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 42: loss -12.37543 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -12.31062 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 43: loss -12.80961 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -12.79369 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 44: loss -13.35596 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -13.31174 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 45: loss -13.85395 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -13.80485 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 46: loss -14.36840 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -14.32599 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 47: loss -14.89179 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -14.84464 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 48: loss -15.45361 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -15.40309 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 49: loss -16.03347 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 50: loss -15.94720 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 50: loss -16.60413 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 51: loss -16.53698 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 51: loss -17.11916 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 52: loss -17.10928 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 52: loss -17.78534 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 53: loss -17.72351 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 53: loss -18.41366 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 54: loss -18.34123 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 54: loss -18.99700 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 55: loss -18.97403 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 55: loss -19.66379 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 56: loss -19.61891 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 56: loss -20.32216 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 57: loss -20.28035 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 57: loss -21.03082 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 58: loss -20.96400 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 58: loss -21.71160 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 59: loss -21.66861 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 59: loss -22.43618 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 60: loss -22.39261 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 60: loss -23.18321 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 61: loss -23.12670 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 61: loss -23.93615 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 62: loss -23.86789 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 62: loss -24.69827 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 63: loss -24.64379 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 63: loss -25.47000 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 64: loss -25.41750 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 64: loss -26.28154 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 65: loss -26.22424 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 65: loss -27.10206 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 66: loss -27.02032 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 66: loss -27.93522 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 67: loss -27.87668 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 67: loss -28.77358 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 68: loss -28.75257 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 68: loss -29.69150 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 69: loss -29.64497 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 69: loss -30.58958 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 70: loss -30.53042 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 70: loss -31.51583 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 71: loss -31.45718 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 71: loss -32.44816 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 72: loss -32.38948 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 72: loss -33.38118 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 73: loss -33.35853 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 73: loss -34.38426 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 74: loss -34.33436 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 74: loss -35.39687 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 75: loss -35.33589 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 75: loss -36.42946 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 76: loss -36.35583 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 76: loss -37.44229 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 77: loss -37.39547 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 77: loss -38.50914 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 78: loss -38.46340 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 78: loss -39.59181 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 79: loss -39.52785 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 79: loss -40.69681 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 80: loss -40.63867 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 80: loss -41.81952 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 81: loss -41.76762 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 81: loss -42.95318 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 82: loss -42.91371 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 82: loss -44.16293 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 83: loss -44.08465 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 83: loss -45.36532 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 84: loss -45.28224 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 84: loss -46.56599 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 85: loss -46.50718 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 85: loss -47.82432 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 86: loss -47.75302 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 86: loss -49.07676 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 87: loss -49.01278 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 87: loss -50.37919 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 88: loss -50.31122 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 88: loss -51.69568 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 89: loss -51.62246 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 89: loss -53.03144 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 90: loss -52.96549 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 90: loss -54.41677 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 91: loss -54.34041 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 91: loss -55.80404 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 92: loss -55.73285 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 92: loss -57.22910 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 93: loss -57.15050 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 93: loss -58.66647 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 94: loss -58.60624 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 94: loss -60.17163 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 95: loss -60.09237 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 95: loss -61.67593 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 96: loss -61.60127 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 96: loss -63.21883 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 97: loss -63.14473 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 97: loss -64.79161 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 98: loss -64.71991 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 98: loss -66.39832 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 99: loss -66.33463 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 99: loss -68.03942 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 100)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 2)
('lr', 0.0001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.59474 ROC_AUC (avg): 0.46446 PRC_AUC (avg): 0.65872 

Average forward propagation time taken(ms): 4.570631458449191
Average backward propagation time taken(ms): 1.6288349406706562

