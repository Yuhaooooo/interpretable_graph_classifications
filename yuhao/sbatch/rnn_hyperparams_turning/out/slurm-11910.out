# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 1)
('lr', 0.0001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-21-57-06/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-21-57-06/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 16,
 'epochs': 50,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 4,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.0001,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 2,
 'num_workers': 8,
 'number_of_mlp_layer': 1,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-17-21-57-06',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 50, 'learning_rate': 0.0001, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss 1.34411 acc 0.33333 roc_auc 0.43000 prc_auc 0.62045[0m
[93maverage test of epoch 0: loss 1.22243 acc 0.34211 roc_auc 0.40308 prc_auc 0.64853[0m
[92maverage training of epoch 1: loss 1.22332 acc 0.33333 roc_auc 0.39460 prc_auc 0.60572[0m
[93maverage test of epoch 1: loss 1.10610 acc 0.34211 roc_auc 0.37846 prc_auc 0.61429[0m
[92maverage training of epoch 2: loss 1.08864 acc 0.33333 roc_auc 0.42780 prc_auc 0.64792[0m
[93maverage test of epoch 2: loss 0.96169 acc 0.34211 roc_auc 0.61538 prc_auc 0.75205[0m
[92maverage training of epoch 3: loss 0.96696 acc 0.33333 roc_auc 0.44480 prc_auc 0.66536[0m
[93maverage test of epoch 3: loss 0.88033 acc 0.34211 roc_auc 0.48000 prc_auc 0.67052[0m
[92maverage training of epoch 4: loss 0.85950 acc 0.33333 roc_auc 0.47020 prc_auc 0.65988[0m
[93maverage test of epoch 4: loss 0.74657 acc 0.34211 roc_auc 0.54462 prc_auc 0.74156[0m
[92maverage training of epoch 5: loss 0.73910 acc 0.33333 roc_auc 0.55640 prc_auc 0.74045[0m
[93maverage test of epoch 5: loss 0.66718 acc 0.34211 roc_auc 0.52000 prc_auc 0.73504[0m
[92maverage training of epoch 6: loss 0.66290 acc 0.33333 roc_auc 0.50120 prc_auc 0.67949[0m
[93maverage test of epoch 6: loss 0.57693 acc 0.34211 roc_auc 0.60000 prc_auc 0.74229[0m
[92maverage training of epoch 7: loss 0.55960 acc 0.33333 roc_auc 0.57100 prc_auc 0.74763[0m
[93maverage test of epoch 7: loss 0.51031 acc 0.34211 roc_auc 0.47077 prc_auc 0.66221[0m
[92maverage training of epoch 8: loss 0.48093 acc 0.33333 roc_auc 0.56580 prc_auc 0.72472[0m
[93maverage test of epoch 8: loss 0.44244 acc 0.34211 roc_auc 0.46769 prc_auc 0.67467[0m
[92maverage training of epoch 9: loss 0.42131 acc 0.33333 roc_auc 0.52480 prc_auc 0.70384[0m
[93maverage test of epoch 9: loss 0.35589 acc 0.34211 roc_auc 0.58462 prc_auc 0.78808[0m
[92maverage training of epoch 10: loss 0.35808 acc 0.33333 roc_auc 0.53640 prc_auc 0.71659[0m
[93maverage test of epoch 10: loss 0.35311 acc 0.34211 roc_auc 0.40923 prc_auc 0.66241[0m
[92maverage training of epoch 11: loss 0.30142 acc 0.33333 roc_auc 0.53100 prc_auc 0.73184[0m
[93maverage test of epoch 11: loss 0.24438 acc 0.34211 roc_auc 0.58462 prc_auc 0.78683[0m
[92maverage training of epoch 12: loss 0.25971 acc 0.33333 roc_auc 0.50100 prc_auc 0.69212[0m
[93maverage test of epoch 12: loss 0.20402 acc 0.34211 roc_auc 0.53231 prc_auc 0.74855[0m
[92maverage training of epoch 13: loss 0.18870 acc 0.33333 roc_auc 0.56460 prc_auc 0.75257[0m
[93maverage test of epoch 13: loss 0.15379 acc 0.34211 roc_auc 0.55077 prc_auc 0.75200[0m
[92maverage training of epoch 14: loss 0.13185 acc 0.33333 roc_auc 0.60940 prc_auc 0.76265[0m
[93maverage test of epoch 14: loss 0.15014 acc 0.34211 roc_auc 0.41846 prc_auc 0.71566[0m
[92maverage training of epoch 15: loss 0.08894 acc 0.33333 roc_auc 0.62360 prc_auc 0.80136[0m
[93maverage test of epoch 15: loss 0.09934 acc 0.34211 roc_auc 0.46769 prc_auc 0.71057[0m
[92maverage training of epoch 16: loss 0.03976 acc 0.33333 roc_auc 0.63400 prc_auc 0.80380[0m
[93maverage test of epoch 16: loss 0.01624 acc 0.34211 roc_auc 0.64923 prc_auc 0.82977[0m
[92maverage training of epoch 17: loss 0.02577 acc 0.33333 roc_auc 0.56420 prc_auc 0.76520[0m
[93maverage test of epoch 17: loss -0.03815 acc 0.34211 roc_auc 0.66769 prc_auc 0.82184[0m
[92maverage training of epoch 18: loss 0.00057 acc 0.33333 roc_auc 0.53360 prc_auc 0.73708[0m
[93maverage test of epoch 18: loss 0.04848 acc 0.34211 roc_auc 0.27692 prc_auc 0.62149[0m
[92maverage training of epoch 19: loss -0.04494 acc 0.33333 roc_auc 0.58060 prc_auc 0.76490[0m
[93maverage test of epoch 19: loss -0.04750 acc 0.34211 roc_auc 0.51385 prc_auc 0.69476[0m
[92maverage training of epoch 20: loss -0.08875 acc 0.33333 roc_auc 0.61700 prc_auc 0.79742[0m
[93maverage test of epoch 20: loss -0.07281 acc 0.34211 roc_auc 0.56000 prc_auc 0.74306[0m
[92maverage training of epoch 21: loss -0.14155 acc 0.33333 roc_auc 0.69360 prc_auc 0.82923[0m
[93maverage test of epoch 21: loss -0.17719 acc 0.34211 roc_auc 0.74769 prc_auc 0.82577[0m
[92maverage training of epoch 22: loss -0.13876 acc 0.36667 roc_auc 0.62140 prc_auc 0.81486[0m
[93maverage test of epoch 22: loss -0.17743 acc 0.34211 roc_auc 0.74462 prc_auc 0.88113[0m
[92maverage training of epoch 23: loss -0.18232 acc 0.41333 roc_auc 0.67240 prc_auc 0.78932[0m
[93maverage test of epoch 23: loss -0.18540 acc 0.42105 roc_auc 0.65538 prc_auc 0.78046[0m
[92maverage training of epoch 24: loss -0.21873 acc 0.47333 roc_auc 0.74460 prc_auc 0.83796[0m
[93maverage test of epoch 24: loss -0.21805 acc 0.50000 roc_auc 0.70769 prc_auc 0.83704[0m
[92maverage training of epoch 25: loss -0.23875 acc 0.62000 roc_auc 0.73240 prc_auc 0.86284[0m
[93maverage test of epoch 25: loss -0.25546 acc 0.55263 roc_auc 0.80615 prc_auc 0.87132[0m
[92maverage training of epoch 26: loss -0.25751 acc 0.58000 roc_auc 0.74540 prc_auc 0.85266[0m
[93maverage test of epoch 26: loss -0.25723 acc 0.52632 roc_auc 0.73538 prc_auc 0.87204[0m
[92maverage training of epoch 27: loss -0.28804 acc 0.58000 roc_auc 0.74920 prc_auc 0.80292[0m
[93maverage test of epoch 27: loss -0.30653 acc 0.65789 roc_auc 0.74769 prc_auc 0.85675[0m
[92maverage training of epoch 28: loss -0.33488 acc 0.61333 roc_auc 0.80300 prc_auc 0.88443[0m
[93maverage test of epoch 28: loss -0.35413 acc 0.60526 roc_auc 0.76615 prc_auc 0.87181[0m
[92maverage training of epoch 29: loss -0.37389 acc 0.66000 roc_auc 0.83960 prc_auc 0.92375[0m
[93maverage test of epoch 29: loss -0.40713 acc 0.68421 roc_auc 0.81538 prc_auc 0.91279[0m
[92maverage training of epoch 30: loss -0.42779 acc 0.67333 roc_auc 0.86660 prc_auc 0.89516[0m
[93maverage test of epoch 30: loss -0.46021 acc 0.68421 roc_auc 0.87077 prc_auc 0.93596[0m
[92maverage training of epoch 31: loss -0.46905 acc 0.68667 roc_auc 0.84560 prc_auc 0.91319[0m
[93maverage test of epoch 31: loss -0.47797 acc 0.65789 roc_auc 0.84923 prc_auc 0.92798[0m
[92maverage training of epoch 32: loss -0.53909 acc 0.73333 roc_auc 0.88680 prc_auc 0.92945[0m
[93maverage test of epoch 32: loss -0.54932 acc 0.65789 roc_auc 0.85538 prc_auc 0.92954[0m
[92maverage training of epoch 33: loss -0.59036 acc 0.72000 roc_auc 0.86400 prc_auc 0.90623[0m
[93maverage test of epoch 33: loss -0.62739 acc 0.71053 roc_auc 0.85538 prc_auc 0.91010[0m
[92maverage training of epoch 34: loss -0.65930 acc 0.70000 roc_auc 0.87120 prc_auc 0.89044[0m
[93maverage test of epoch 34: loss -0.72293 acc 0.68421 roc_auc 0.88308 prc_auc 0.94784[0m
[92maverage training of epoch 35: loss -0.77560 acc 0.73333 roc_auc 0.87660 prc_auc 0.88983[0m
[93maverage test of epoch 35: loss -0.86849 acc 0.76316 roc_auc 0.87692 prc_auc 0.94023[0m
[92maverage training of epoch 36: loss -0.93244 acc 0.75333 roc_auc 0.89900 prc_auc 0.91723[0m
[93maverage test of epoch 36: loss -1.00906 acc 0.76316 roc_auc 0.90769 prc_auc 0.95257[0m
[92maverage training of epoch 37: loss -1.08464 acc 0.76667 roc_auc 0.90680 prc_auc 0.94215[0m
[93maverage test of epoch 37: loss -1.15276 acc 0.73684 roc_auc 0.88000 prc_auc 0.92858[0m
[92maverage training of epoch 38: loss -1.19856 acc 0.77333 roc_auc 0.87120 prc_auc 0.90922[0m
[93maverage test of epoch 38: loss -1.29221 acc 0.81579 roc_auc 0.84923 prc_auc 0.92697[0m
[92maverage training of epoch 39: loss -1.37828 acc 0.82667 roc_auc 0.86600 prc_auc 0.87197[0m
[93maverage test of epoch 39: loss -1.40833 acc 0.73684 roc_auc 0.87077 prc_auc 0.94080[0m
[92maverage training of epoch 40: loss -1.54404 acc 0.82000 roc_auc 0.87780 prc_auc 0.89196[0m
[93maverage test of epoch 40: loss -1.60284 acc 0.81579 roc_auc 0.87077 prc_auc 0.93858[0m
[92maverage training of epoch 41: loss -1.68630 acc 0.82667 roc_auc 0.88180 prc_auc 0.90251[0m
[93maverage test of epoch 41: loss -1.66320 acc 0.81579 roc_auc 0.81538 prc_auc 0.89540[0m
[92maverage training of epoch 42: loss -1.82903 acc 0.80000 roc_auc 0.86900 prc_auc 0.88981[0m
[93maverage test of epoch 42: loss -1.93894 acc 0.78947 roc_auc 0.88000 prc_auc 0.91914[0m
[92maverage training of epoch 43: loss -2.07659 acc 0.82667 roc_auc 0.88220 prc_auc 0.90582[0m
[93maverage test of epoch 43: loss -2.05838 acc 0.81579 roc_auc 0.84923 prc_auc 0.93483[0m
[92maverage training of epoch 44: loss -2.19374 acc 0.82667 roc_auc 0.87140 prc_auc 0.88697[0m
[93maverage test of epoch 44: loss -2.23865 acc 0.81579 roc_auc 0.83692 prc_auc 0.91636[0m
[92maverage training of epoch 45: loss -2.43897 acc 0.83333 roc_auc 0.89980 prc_auc 0.91624[0m
[93maverage test of epoch 45: loss -2.36573 acc 0.78947 roc_auc 0.85846 prc_auc 0.93385[0m
[92maverage training of epoch 46: loss -2.56686 acc 0.84667 roc_auc 0.86900 prc_auc 0.89745[0m
[93maverage test of epoch 46: loss -2.59803 acc 0.78947 roc_auc 0.88000 prc_auc 0.94148[0m
[92maverage training of epoch 47: loss -2.76548 acc 0.83333 roc_auc 0.90440 prc_auc 0.94900[0m
[93maverage test of epoch 47: loss -2.74172 acc 0.81579 roc_auc 0.88000 prc_auc 0.94248[0m
[92maverage training of epoch 48: loss -2.88174 acc 0.81333 roc_auc 0.88160 prc_auc 0.90558[0m
[93maverage test of epoch 48: loss -2.85694 acc 0.78947 roc_auc 0.84615 prc_auc 0.92480[0m
[92maverage training of epoch 49: loss -3.05913 acc 0.83333 roc_auc 0.87620 prc_auc 0.91765[0m
[93maverage test of epoch 49: loss -3.03536 acc 0.78947 roc_auc 0.85231 prc_auc 0.91877[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -1.12334 acc 0.66667 roc_auc 0.42400 prc_auc 0.62025[0m
[93maverage test of epoch 0: loss -1.31154 acc 0.65789 roc_auc 0.35385 prc_auc 0.59224[0m
[92maverage training of epoch 1: loss -1.50511 acc 0.66667 roc_auc 0.44580 prc_auc 0.63147[0m
[93maverage test of epoch 1: loss -1.68236 acc 0.65789 roc_auc 0.65538 prc_auc 0.75376[0m
[92maverage training of epoch 2: loss -1.84841 acc 0.66667 roc_auc 0.49660 prc_auc 0.66427[0m
[93maverage test of epoch 2: loss -2.00300 acc 0.65789 roc_auc 0.47077 prc_auc 0.68452[0m
[92maverage training of epoch 3: loss -2.15897 acc 0.66667 roc_auc 0.46560 prc_auc 0.68097[0m
[93maverage test of epoch 3: loss -2.28566 acc 0.65789 roc_auc 0.49846 prc_auc 0.63589[0m
[92maverage training of epoch 4: loss -2.43905 acc 0.66667 roc_auc 0.40660 prc_auc 0.60407[0m
[93maverage test of epoch 4: loss -2.58165 acc 0.65789 roc_auc 0.55692 prc_auc 0.68496[0m
[92maverage training of epoch 5: loss -2.67345 acc 0.66667 roc_auc 0.41220 prc_auc 0.59930[0m
[93maverage test of epoch 5: loss -2.78742 acc 0.65789 roc_auc 0.51692 prc_auc 0.68722[0m
[92maverage training of epoch 6: loss -2.90859 acc 0.66667 roc_auc 0.46640 prc_auc 0.64994[0m
[93maverage test of epoch 6: loss -2.97987 acc 0.65789 roc_auc 0.47077 prc_auc 0.65409[0m
[92maverage training of epoch 7: loss -3.11460 acc 0.66667 roc_auc 0.45740 prc_auc 0.65804[0m
[93maverage test of epoch 7: loss -3.21194 acc 0.65789 roc_auc 0.65231 prc_auc 0.75028[0m
[92maverage training of epoch 8: loss -3.31358 acc 0.66667 roc_auc 0.45520 prc_auc 0.63261[0m
[93maverage test of epoch 8: loss -3.38493 acc 0.65789 roc_auc 0.54462 prc_auc 0.74802[0m
[92maverage training of epoch 9: loss -3.51006 acc 0.66667 roc_auc 0.50660 prc_auc 0.67779[0m
[93maverage test of epoch 9: loss -3.57169 acc 0.65789 roc_auc 0.56923 prc_auc 0.72645[0m
[92maverage training of epoch 10: loss -3.69029 acc 0.66667 roc_auc 0.47920 prc_auc 0.65947[0m
[93maverage test of epoch 10: loss -3.76377 acc 0.65789 roc_auc 0.50154 prc_auc 0.68743[0m
[92maverage training of epoch 11: loss -3.87516 acc 0.66667 roc_auc 0.44140 prc_auc 0.66547[0m
[93maverage test of epoch 11: loss -3.95906 acc 0.65789 roc_auc 0.57538 prc_auc 0.75452[0m
[92maverage training of epoch 12: loss -4.06972 acc 0.66667 roc_auc 0.47120 prc_auc 0.66749[0m
[93maverage test of epoch 12: loss -4.15234 acc 0.65789 roc_auc 0.40923 prc_auc 0.65077[0m
[92maverage training of epoch 13: loss -4.25124 acc 0.66667 roc_auc 0.53040 prc_auc 0.68125[0m
[93maverage test of epoch 13: loss -4.32873 acc 0.65789 roc_auc 0.68615 prc_auc 0.84984[0m
[92maverage training of epoch 14: loss -4.46061 acc 0.66667 roc_auc 0.50160 prc_auc 0.66240[0m
[93maverage test of epoch 14: loss -4.54202 acc 0.65789 roc_auc 0.48615 prc_auc 0.67650[0m
[92maverage training of epoch 15: loss -4.66523 acc 0.66667 roc_auc 0.44400 prc_auc 0.63923[0m
[93maverage test of epoch 15: loss -4.72884 acc 0.65789 roc_auc 0.46769 prc_auc 0.69470[0m
[92maverage training of epoch 16: loss -4.85405 acc 0.66667 roc_auc 0.51140 prc_auc 0.68268[0m
[93maverage test of epoch 16: loss -4.94441 acc 0.65789 roc_auc 0.57846 prc_auc 0.79394[0m
[92maverage training of epoch 17: loss -5.07229 acc 0.66667 roc_auc 0.46240 prc_auc 0.65255[0m
[93maverage test of epoch 17: loss -5.13844 acc 0.65789 roc_auc 0.50154 prc_auc 0.69500[0m
[92maverage training of epoch 18: loss -5.27750 acc 0.66667 roc_auc 0.45420 prc_auc 0.63789[0m
[93maverage test of epoch 18: loss -5.36776 acc 0.65789 roc_auc 0.56308 prc_auc 0.74399[0m
[92maverage training of epoch 19: loss -5.48764 acc 0.66667 roc_auc 0.48140 prc_auc 0.68297[0m
[93maverage test of epoch 19: loss -5.55762 acc 0.65789 roc_auc 0.47077 prc_auc 0.72652[0m
[92maverage training of epoch 20: loss -5.70232 acc 0.66667 roc_auc 0.47860 prc_auc 0.65781[0m
[93maverage test of epoch 20: loss -5.78152 acc 0.65789 roc_auc 0.51385 prc_auc 0.69025[0m
[92maverage training of epoch 21: loss -5.92098 acc 0.66667 roc_auc 0.53960 prc_auc 0.68355[0m
[93maverage test of epoch 21: loss -6.00115 acc 0.65789 roc_auc 0.50308 prc_auc 0.70162[0m
[92maverage training of epoch 22: loss -6.13776 acc 0.66667 roc_auc 0.52820 prc_auc 0.67822[0m
[93maverage test of epoch 22: loss -6.21473 acc 0.65789 roc_auc 0.40000 prc_auc 0.59617[0m
[92maverage training of epoch 23: loss -6.34918 acc 0.66667 roc_auc 0.46050 prc_auc 0.66555[0m
[93maverage test of epoch 23: loss -6.42172 acc 0.65789 roc_auc 0.45231 prc_auc 0.64699[0m
[92maverage training of epoch 24: loss -6.57817 acc 0.66667 roc_auc 0.47140 prc_auc 0.65470[0m
[93maverage test of epoch 24: loss -6.65675 acc 0.65789 roc_auc 0.54769 prc_auc 0.77061[0m
[92maverage training of epoch 25: loss -6.80612 acc 0.66667 roc_auc 0.45380 prc_auc 0.62663[0m
[93maverage test of epoch 25: loss -6.88777 acc 0.65789 roc_auc 0.58154 prc_auc 0.73203[0m
[92maverage training of epoch 26: loss -7.02533 acc 0.66667 roc_auc 0.50080 prc_auc 0.67516[0m
[93maverage test of epoch 26: loss -7.09037 acc 0.65789 roc_auc 0.46462 prc_auc 0.70530[0m
[92maverage training of epoch 27: loss -7.25360 acc 0.66667 roc_auc 0.52450 prc_auc 0.66609[0m
[93maverage test of epoch 27: loss -7.34404 acc 0.65789 roc_auc 0.65538 prc_auc 0.80793[0m
[92maverage training of epoch 28: loss -7.48453 acc 0.66667 roc_auc 0.47820 prc_auc 0.68995[0m
[93maverage test of epoch 28: loss -7.57875 acc 0.65789 roc_auc 0.58154 prc_auc 0.74221[0m
[92maverage training of epoch 29: loss -7.71857 acc 0.66667 roc_auc 0.46590 prc_auc 0.64251[0m
[93maverage test of epoch 29: loss -7.78825 acc 0.65789 roc_auc 0.50462 prc_auc 0.74354[0m
[92maverage training of epoch 30: loss -7.95363 acc 0.66667 roc_auc 0.46570 prc_auc 0.67285[0m
[93maverage test of epoch 30: loss -8.03718 acc 0.65789 roc_auc 0.64308 prc_auc 0.81915[0m
[92maverage training of epoch 31: loss -8.19902 acc 0.66667 roc_auc 0.47010 prc_auc 0.65195[0m
[93maverage test of epoch 31: loss -8.27832 acc 0.65789 roc_auc 0.64615 prc_auc 0.81317[0m
[92maverage training of epoch 32: loss -8.44505 acc 0.66667 roc_auc 0.43280 prc_auc 0.61011[0m
[93maverage test of epoch 32: loss -8.52478 acc 0.65789 roc_auc 0.47077 prc_auc 0.63363[0m
[92maverage training of epoch 33: loss -8.69470 acc 0.66667 roc_auc 0.43630 prc_auc 0.63050[0m
[93maverage test of epoch 33: loss -8.77723 acc 0.65789 roc_auc 0.54615 prc_auc 0.69863[0m
[92maverage training of epoch 34: loss -8.94344 acc 0.66667 roc_auc 0.47940 prc_auc 0.68255[0m
[93maverage test of epoch 34: loss -9.02884 acc 0.65789 roc_auc 0.40154 prc_auc 0.68595[0m
[92maverage training of epoch 35: loss -9.19499 acc 0.66667 roc_auc 0.48390 prc_auc 0.65052[0m
[93maverage test of epoch 35: loss -9.28676 acc 0.65789 roc_auc 0.52308 prc_auc 0.70636[0m
[92maverage training of epoch 36: loss -9.44854 acc 0.66667 roc_auc 0.43760 prc_auc 0.62328[0m
[93maverage test of epoch 36: loss -9.54315 acc 0.65789 roc_auc 0.46923 prc_auc 0.68535[0m
[92maverage training of epoch 37: loss -9.71008 acc 0.66667 roc_auc 0.48040 prc_auc 0.65926[0m
[93maverage test of epoch 37: loss -9.78800 acc 0.65789 roc_auc 0.42923 prc_auc 0.59510[0m
[92maverage training of epoch 38: loss -9.97238 acc 0.66667 roc_auc 0.48460 prc_auc 0.64040[0m
[93maverage test of epoch 38: loss -10.06525 acc 0.65789 roc_auc 0.51231 prc_auc 0.73309[0m
[92maverage training of epoch 39: loss -10.24229 acc 0.66667 roc_auc 0.47580 prc_auc 0.67146[0m
[93maverage test of epoch 39: loss -10.32593 acc 0.65789 roc_auc 0.66154 prc_auc 0.75620[0m
[92maverage training of epoch 40: loss -10.50210 acc 0.66667 roc_auc 0.45830 prc_auc 0.66752[0m
[93maverage test of epoch 40: loss -10.59654 acc 0.65789 roc_auc 0.53231 prc_auc 0.68321[0m
[92maverage training of epoch 41: loss -10.77055 acc 0.66667 roc_auc 0.44950 prc_auc 0.64184[0m
[93maverage test of epoch 41: loss -10.85651 acc 0.65789 roc_auc 0.49846 prc_auc 0.69096[0m
[92maverage training of epoch 42: loss -11.05079 acc 0.66667 roc_auc 0.49480 prc_auc 0.66744[0m
[93maverage test of epoch 42: loss -11.12805 acc 0.65789 roc_auc 0.64462 prc_auc 0.76852[0m
[92maverage training of epoch 43: loss -11.32836 acc 0.66667 roc_auc 0.50740 prc_auc 0.68878[0m
[93maverage test of epoch 43: loss -11.41673 acc 0.65789 roc_auc 0.67692 prc_auc 0.75664[0m
[92maverage training of epoch 44: loss -11.60264 acc 0.66667 roc_auc 0.45480 prc_auc 0.64046[0m
[93maverage test of epoch 44: loss -11.68363 acc 0.65789 roc_auc 0.45538 prc_auc 0.64167[0m
[92maverage training of epoch 45: loss -11.88810 acc 0.66667 roc_auc 0.47390 prc_auc 0.65392[0m
[93maverage test of epoch 45: loss -11.97913 acc 0.65789 roc_auc 0.59231 prc_auc 0.76480[0m
[92maverage training of epoch 46: loss -12.17275 acc 0.66667 roc_auc 0.45830 prc_auc 0.61928[0m
[93maverage test of epoch 46: loss -12.26978 acc 0.65789 roc_auc 0.61231 prc_auc 0.78568[0m
[92maverage training of epoch 47: loss -12.46644 acc 0.66667 roc_auc 0.46890 prc_auc 0.64425[0m
[93maverage test of epoch 47: loss -12.55184 acc 0.65789 roc_auc 0.56154 prc_auc 0.73163[0m
[92maverage training of epoch 48: loss -12.75599 acc 0.66667 roc_auc 0.47640 prc_auc 0.66073[0m
[93maverage test of epoch 48: loss -12.84511 acc 0.65789 roc_auc 0.34923 prc_auc 0.58408[0m
[92maverage training of epoch 49: loss -13.05166 acc 0.66667 roc_auc 0.43060 prc_auc 0.62442[0m
[93maverage test of epoch 49: loss -13.12497 acc 0.65789 roc_auc 0.43846 prc_auc 0.65303[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss 0.71249 acc 0.33333 roc_auc 0.39520 prc_auc 0.61083[0m
[93maverage test of epoch 0: loss 0.55675 acc 0.34211 roc_auc 0.42769 prc_auc 0.61892[0m
[92maverage training of epoch 1: loss 0.43842 acc 0.33333 roc_auc 0.42920 prc_auc 0.63439[0m
[93maverage test of epoch 1: loss 0.31046 acc 0.34211 roc_auc 0.46462 prc_auc 0.67802[0m
[92maverage training of epoch 2: loss 0.18903 acc 0.33333 roc_auc 0.42640 prc_auc 0.63988[0m
[93maverage test of epoch 2: loss 0.06829 acc 0.34211 roc_auc 0.24000 prc_auc 0.52166[0m
[92maverage training of epoch 3: loss -0.02348 acc 0.33333 roc_auc 0.45380 prc_auc 0.64647[0m
[93maverage test of epoch 3: loss -0.09214 acc 0.34211 roc_auc 0.53538 prc_auc 0.66003[0m
[92maverage training of epoch 4: loss -0.14453 acc 0.50000 roc_auc 0.40420 prc_auc 0.59924[0m
[93maverage test of epoch 4: loss -0.19458 acc 0.57895 roc_auc 0.34462 prc_auc 0.64174[0m
[92maverage training of epoch 5: loss -0.26888 acc 0.66000 roc_auc 0.46440 prc_auc 0.67480[0m
[93maverage test of epoch 5: loss -0.33493 acc 0.65789 roc_auc 0.47692 prc_auc 0.71199[0m
[92maverage training of epoch 6: loss -0.40536 acc 0.66667 roc_auc 0.44940 prc_auc 0.65452[0m
[93maverage test of epoch 6: loss -0.47675 acc 0.65789 roc_auc 0.72923 prc_auc 0.81501[0m
[92maverage training of epoch 7: loss -0.53852 acc 0.66667 roc_auc 0.44540 prc_auc 0.64904[0m
[93maverage test of epoch 7: loss -0.59855 acc 0.65789 roc_auc 0.44000 prc_auc 0.62102[0m
[92maverage training of epoch 8: loss -0.67141 acc 0.66667 roc_auc 0.38740 prc_auc 0.61562[0m
[93maverage test of epoch 8: loss -0.73894 acc 0.65789 roc_auc 0.50462 prc_auc 0.68276[0m
[92maverage training of epoch 9: loss -0.81192 acc 0.66667 roc_auc 0.48180 prc_auc 0.66421[0m
[93maverage test of epoch 9: loss -0.87918 acc 0.65789 roc_auc 0.32000 prc_auc 0.57499[0m
[92maverage training of epoch 10: loss -0.93024 acc 0.66667 roc_auc 0.52700 prc_auc 0.67078[0m
[93maverage test of epoch 10: loss -1.00272 acc 0.65789 roc_auc 0.59077 prc_auc 0.78580[0m
[92maverage training of epoch 11: loss -1.05264 acc 0.66667 roc_auc 0.41700 prc_auc 0.60789[0m
[93maverage test of epoch 11: loss -1.11103 acc 0.65789 roc_auc 0.42154 prc_auc 0.65862[0m
[92maverage training of epoch 12: loss -1.15989 acc 0.66667 roc_auc 0.52340 prc_auc 0.67773[0m
[93maverage test of epoch 12: loss -1.22458 acc 0.65789 roc_auc 0.58769 prc_auc 0.78456[0m
[92maverage training of epoch 13: loss -1.26478 acc 0.66667 roc_auc 0.42260 prc_auc 0.61217[0m
[93maverage test of epoch 13: loss -1.30552 acc 0.65789 roc_auc 0.71385 prc_auc 0.85178[0m
[92maverage training of epoch 14: loss -1.37529 acc 0.66667 roc_auc 0.48220 prc_auc 0.65965[0m
[93maverage test of epoch 14: loss -1.42677 acc 0.65789 roc_auc 0.38462 prc_auc 0.62963[0m
[92maverage training of epoch 15: loss -1.48558 acc 0.66667 roc_auc 0.46160 prc_auc 0.65257[0m
[93maverage test of epoch 15: loss -1.53194 acc 0.65789 roc_auc 0.53231 prc_auc 0.71177[0m
[92maverage training of epoch 16: loss -1.61631 acc 0.66667 roc_auc 0.44700 prc_auc 0.64348[0m
[93maverage test of epoch 16: loss -1.67621 acc 0.65789 roc_auc 0.62462 prc_auc 0.78571[0m
[92maverage training of epoch 17: loss -1.75235 acc 0.66667 roc_auc 0.45880 prc_auc 0.64745[0m
[93maverage test of epoch 17: loss -1.81026 acc 0.65789 roc_auc 0.59692 prc_auc 0.73012[0m
[92maverage training of epoch 18: loss -1.89605 acc 0.66667 roc_auc 0.41720 prc_auc 0.61619[0m
[93maverage test of epoch 18: loss -1.97288 acc 0.65789 roc_auc 0.66769 prc_auc 0.80372[0m
[92maverage training of epoch 19: loss -2.04154 acc 0.66667 roc_auc 0.46600 prc_auc 0.67296[0m
[93maverage test of epoch 19: loss -2.11762 acc 0.65789 roc_auc 0.42769 prc_auc 0.68289[0m
[92maverage training of epoch 20: loss -2.21782 acc 0.66667 roc_auc 0.46640 prc_auc 0.65307[0m
[93maverage test of epoch 20: loss -2.28266 acc 0.65789 roc_auc 0.47385 prc_auc 0.68800[0m
[92maverage training of epoch 21: loss -2.38019 acc 0.66667 roc_auc 0.48460 prc_auc 0.66196[0m
[93maverage test of epoch 21: loss -2.48058 acc 0.65789 roc_auc 0.42769 prc_auc 0.67857[0m
[92maverage training of epoch 22: loss -2.67042 acc 0.66667 roc_auc 0.42400 prc_auc 0.61983[0m
[93maverage test of epoch 22: loss -2.86031 acc 0.65789 roc_auc 0.56923 prc_auc 0.70647[0m
[92maverage training of epoch 23: loss -3.03991 acc 0.66667 roc_auc 0.50500 prc_auc 0.67235[0m
[93maverage test of epoch 23: loss -3.17290 acc 0.65789 roc_auc 0.56923 prc_auc 0.71263[0m
[92maverage training of epoch 24: loss -3.33595 acc 0.66667 roc_auc 0.44660 prc_auc 0.63746[0m
[93maverage test of epoch 24: loss -3.43785 acc 0.65789 roc_auc 0.28923 prc_auc 0.55491[0m
[92maverage training of epoch 25: loss -3.60182 acc 0.66667 roc_auc 0.44590 prc_auc 0.65319[0m
[93maverage test of epoch 25: loss -3.70486 acc 0.65789 roc_auc 0.53231 prc_auc 0.75220[0m
[92maverage training of epoch 26: loss -3.84629 acc 0.66667 roc_auc 0.47120 prc_auc 0.66371[0m
[93maverage test of epoch 26: loss -3.94361 acc 0.65789 roc_auc 0.51692 prc_auc 0.69937[0m
[92maverage training of epoch 27: loss -4.09546 acc 0.66667 roc_auc 0.44420 prc_auc 0.65041[0m
[93maverage test of epoch 27: loss -4.19971 acc 0.65789 roc_auc 0.55385 prc_auc 0.71203[0m
[92maverage training of epoch 28: loss -4.32579 acc 0.66667 roc_auc 0.43380 prc_auc 0.65165[0m
[93maverage test of epoch 28: loss -4.42592 acc 0.65789 roc_auc 0.38154 prc_auc 0.62654[0m
[92maverage training of epoch 29: loss -4.56378 acc 0.66667 roc_auc 0.40020 prc_auc 0.61005[0m
[93maverage test of epoch 29: loss -4.66190 acc 0.65789 roc_auc 0.56615 prc_auc 0.71794[0m
[92maverage training of epoch 30: loss -4.78746 acc 0.66667 roc_auc 0.50080 prc_auc 0.66516[0m
[93maverage test of epoch 30: loss -4.88065 acc 0.65789 roc_auc 0.39385 prc_auc 0.64452[0m
[92maverage training of epoch 31: loss -5.02887 acc 0.66667 roc_auc 0.46180 prc_auc 0.63631[0m
[93maverage test of epoch 31: loss -5.12890 acc 0.65789 roc_auc 0.63385 prc_auc 0.74912[0m
[92maverage training of epoch 32: loss -5.25984 acc 0.66667 roc_auc 0.51860 prc_auc 0.70183[0m
[93maverage test of epoch 32: loss -5.35336 acc 0.65789 roc_auc 0.59077 prc_auc 0.74616[0m
[92maverage training of epoch 33: loss -5.48245 acc 0.66667 roc_auc 0.52060 prc_auc 0.66717[0m
[93maverage test of epoch 33: loss -5.58106 acc 0.65789 roc_auc 0.64923 prc_auc 0.75806[0m
[92maverage training of epoch 34: loss -5.71417 acc 0.66667 roc_auc 0.51730 prc_auc 0.68710[0m
[93maverage test of epoch 34: loss -5.78501 acc 0.65789 roc_auc 0.60615 prc_auc 0.79605[0m
[92maverage training of epoch 35: loss -5.94961 acc 0.66667 roc_auc 0.46860 prc_auc 0.63015[0m
[93maverage test of epoch 35: loss -6.03898 acc 0.65789 roc_auc 0.70462 prc_auc 0.83683[0m
[92maverage training of epoch 36: loss -6.17451 acc 0.66667 roc_auc 0.47670 prc_auc 0.65962[0m
[93maverage test of epoch 36: loss -6.27241 acc 0.65789 roc_auc 0.58615 prc_auc 0.74346[0m
[92maverage training of epoch 37: loss -6.41126 acc 0.66667 roc_auc 0.47800 prc_auc 0.67016[0m
[93maverage test of epoch 37: loss -6.48997 acc 0.65789 roc_auc 0.48000 prc_auc 0.65424[0m
[92maverage training of epoch 38: loss -6.65247 acc 0.66667 roc_auc 0.46640 prc_auc 0.65155[0m
[93maverage test of epoch 38: loss -6.74710 acc 0.65789 roc_auc 0.57231 prc_auc 0.71951[0m
[92maverage training of epoch 39: loss -6.88192 acc 0.66667 roc_auc 0.42420 prc_auc 0.62220[0m
[93maverage test of epoch 39: loss -6.96752 acc 0.65789 roc_auc 0.38462 prc_auc 0.62663[0m
[92maverage training of epoch 40: loss -7.12340 acc 0.66667 roc_auc 0.39840 prc_auc 0.62224[0m
[93maverage test of epoch 40: loss -7.21679 acc 0.65789 roc_auc 0.48308 prc_auc 0.67400[0m
[92maverage training of epoch 41: loss -7.36496 acc 0.66667 roc_auc 0.43720 prc_auc 0.65973[0m
[93maverage test of epoch 41: loss -7.45582 acc 0.65789 roc_auc 0.29846 prc_auc 0.53535[0m
[92maverage training of epoch 42: loss -7.60943 acc 0.66667 roc_auc 0.45600 prc_auc 0.64575[0m
[93maverage test of epoch 42: loss -7.69313 acc 0.65789 roc_auc 0.63077 prc_auc 0.80507[0m
[92maverage training of epoch 43: loss -7.85514 acc 0.66667 roc_auc 0.46600 prc_auc 0.65270[0m
[93maverage test of epoch 43: loss -7.95653 acc 0.65789 roc_auc 0.52923 prc_auc 0.66431[0m
[92maverage training of epoch 44: loss -8.11475 acc 0.66667 roc_auc 0.44640 prc_auc 0.65642[0m
[93maverage test of epoch 44: loss -8.18155 acc 0.65789 roc_auc 0.47846 prc_auc 0.65155[0m
[92maverage training of epoch 45: loss -8.35720 acc 0.66667 roc_auc 0.40800 prc_auc 0.59592[0m
[93maverage test of epoch 45: loss -8.45654 acc 0.65789 roc_auc 0.49385 prc_auc 0.71936[0m
[92maverage training of epoch 46: loss -8.61605 acc 0.66667 roc_auc 0.46100 prc_auc 0.66299[0m
[93maverage test of epoch 46: loss -8.71596 acc 0.65789 roc_auc 0.66615 prc_auc 0.81333[0m
[92maverage training of epoch 47: loss -8.87111 acc 0.66667 roc_auc 0.41540 prc_auc 0.63507[0m
[93maverage test of epoch 47: loss -8.96908 acc 0.65789 roc_auc 0.41385 prc_auc 0.67016[0m
[92maverage training of epoch 48: loss -9.13327 acc 0.66667 roc_auc 0.41440 prc_auc 0.63601[0m
[93maverage test of epoch 48: loss -9.22365 acc 0.65789 roc_auc 0.49538 prc_auc 0.67583[0m
[92maverage training of epoch 49: loss -9.39674 acc 0.66667 roc_auc 0.42380 prc_auc 0.63738[0m
[93maverage test of epoch 49: loss -9.49244 acc 0.65789 roc_auc 0.43538 prc_auc 0.60799[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss -0.01512 acc 0.66225 roc_auc 0.48333 prc_auc 0.66417[0m
[93maverage test of epoch 0: loss -0.07248 acc 0.67568 roc_auc 0.34333 prc_auc 0.63964[0m
[92maverage training of epoch 1: loss -0.15880 acc 0.66225 roc_auc 0.44333 prc_auc 0.64905[0m
[93maverage test of epoch 1: loss -0.29912 acc 0.67568 roc_auc 0.56333 prc_auc 0.72987[0m
[92maverage training of epoch 2: loss -0.44797 acc 0.66225 roc_auc 0.42784 prc_auc 0.61738[0m
[93maverage test of epoch 2: loss -0.73259 acc 0.67568 roc_auc 0.65667 prc_auc 0.80357[0m
[92maverage training of epoch 3: loss -0.91522 acc 0.66225 roc_auc 0.46333 prc_auc 0.64716[0m
[93maverage test of epoch 3: loss -1.20722 acc 0.67568 roc_auc 0.50333 prc_auc 0.65408[0m
[92maverage training of epoch 4: loss -1.47684 acc 0.66225 roc_auc 0.53275 prc_auc 0.68137[0m
[93maverage test of epoch 4: loss -1.83599 acc 0.67568 roc_auc 0.57000 prc_auc 0.70582[0m
[92maverage training of epoch 5: loss -2.08908 acc 0.66225 roc_auc 0.43941 prc_auc 0.67033[0m
[93maverage test of epoch 5: loss -2.51560 acc 0.67568 roc_auc 0.62333 prc_auc 0.82566[0m
[92maverage training of epoch 6: loss -2.78182 acc 0.66225 roc_auc 0.52235 prc_auc 0.68585[0m
[93maverage test of epoch 6: loss -3.17343 acc 0.67568 roc_auc 0.73333 prc_auc 0.87211[0m
[92maverage training of epoch 7: loss -3.45412 acc 0.66225 roc_auc 0.51451 prc_auc 0.68174[0m
[93maverage test of epoch 7: loss -3.89369 acc 0.67568 roc_auc 0.59667 prc_auc 0.71984[0m
[92maverage training of epoch 8: loss -4.14358 acc 0.66225 roc_auc 0.43706 prc_auc 0.62118[0m
[93maverage test of epoch 8: loss -4.52212 acc 0.67568 roc_auc 0.55667 prc_auc 0.74357[0m
[92maverage training of epoch 9: loss -4.72197 acc 0.66225 roc_auc 0.46275 prc_auc 0.63875[0m
[93maverage test of epoch 9: loss -5.08936 acc 0.67568 roc_auc 0.58667 prc_auc 0.75187[0m
[92maverage training of epoch 10: loss -5.20050 acc 0.66225 roc_auc 0.43941 prc_auc 0.62349[0m
[93maverage test of epoch 10: loss -5.57966 acc 0.67568 roc_auc 0.71000 prc_auc 0.84452[0m
[92maverage training of epoch 11: loss -5.69278 acc 0.66225 roc_auc 0.47765 prc_auc 0.66815[0m
[93maverage test of epoch 11: loss -5.96501 acc 0.67568 roc_auc 0.42667 prc_auc 0.68984[0m
[92maverage training of epoch 12: loss -6.11436 acc 0.66225 roc_auc 0.46951 prc_auc 0.63376[0m
[93maverage test of epoch 12: loss -6.42107 acc 0.67568 roc_auc 0.22667 prc_auc 0.54444[0m
[92maverage training of epoch 13: loss -6.53265 acc 0.66225 roc_auc 0.44382 prc_auc 0.64119[0m
[93maverage test of epoch 13: loss -6.86489 acc 0.67568 roc_auc 0.53667 prc_auc 0.72755[0m
[92maverage training of epoch 14: loss -6.92916 acc 0.66225 roc_auc 0.38029 prc_auc 0.59933[0m
[93maverage test of epoch 14: loss -7.29365 acc 0.67568 roc_auc 0.61167 prc_auc 0.81406[0m
[92maverage training of epoch 15: loss -7.34982 acc 0.66225 roc_auc 0.46549 prc_auc 0.69645[0m
[93maverage test of epoch 15: loss -7.67756 acc 0.67568 roc_auc 0.59833 prc_auc 0.82004[0m
[92maverage training of epoch 16: loss -7.73818 acc 0.66225 roc_auc 0.44392 prc_auc 0.65899[0m
[93maverage test of epoch 16: loss -8.03625 acc 0.67568 roc_auc 0.44667 prc_auc 0.66959[0m
[92maverage training of epoch 17: loss -8.13098 acc 0.66225 roc_auc 0.48275 prc_auc 0.65558[0m
[93maverage test of epoch 17: loss -8.47420 acc 0.67568 roc_auc 0.60667 prc_auc 0.81807[0m
[92maverage training of epoch 18: loss -8.51582 acc 0.66225 roc_auc 0.46814 prc_auc 0.65359[0m
[93maverage test of epoch 18: loss -8.84149 acc 0.67568 roc_auc 0.37333 prc_auc 0.62978[0m
[92maverage training of epoch 19: loss -8.87949 acc 0.66225 roc_auc 0.44735 prc_auc 0.62725[0m
[93maverage test of epoch 19: loss -9.23200 acc 0.67568 roc_auc 0.53167 prc_auc 0.68644[0m
[92maverage training of epoch 20: loss -9.27098 acc 0.66225 roc_auc 0.46049 prc_auc 0.64292[0m
[93maverage test of epoch 20: loss -9.61376 acc 0.67568 roc_auc 0.66667 prc_auc 0.80016[0m
[92maverage training of epoch 21: loss -9.66069 acc 0.66225 roc_auc 0.54176 prc_auc 0.70311[0m
[93maverage test of epoch 21: loss -9.98222 acc 0.67568 roc_auc 0.70000 prc_auc 0.78441[0m
[92maverage training of epoch 22: loss -10.01710 acc 0.66225 roc_auc 0.47049 prc_auc 0.64243[0m
[93maverage test of epoch 22: loss -10.36113 acc 0.67568 roc_auc 0.60833 prc_auc 0.76043[0m
[92maverage training of epoch 23: loss -10.38484 acc 0.66225 roc_auc 0.43275 prc_auc 0.62870[0m
[93maverage test of epoch 23: loss -10.74479 acc 0.67568 roc_auc 0.56167 prc_auc 0.71176[0m
[92maverage training of epoch 24: loss -10.76589 acc 0.66225 roc_auc 0.48294 prc_auc 0.64635[0m
[93maverage test of epoch 24: loss -11.10695 acc 0.67568 roc_auc 0.66500 prc_auc 0.81360[0m
[92maverage training of epoch 25: loss -11.14493 acc 0.66225 roc_auc 0.46108 prc_auc 0.63830[0m
[93maverage test of epoch 25: loss -11.49436 acc 0.67568 roc_auc 0.69500 prc_auc 0.84330[0m
[92maverage training of epoch 26: loss -11.51278 acc 0.66225 roc_auc 0.57500 prc_auc 0.70428[0m
[93maverage test of epoch 26: loss -11.86249 acc 0.67568 roc_auc 0.38000 prc_auc 0.60916[0m
[92maverage training of epoch 27: loss -11.88469 acc 0.66225 roc_auc 0.41980 prc_auc 0.61788[0m
[93maverage test of epoch 27: loss -12.23707 acc 0.67568 roc_auc 0.50333 prc_auc 0.66907[0m
[92maverage training of epoch 28: loss -12.26033 acc 0.66225 roc_auc 0.47725 prc_auc 0.63986[0m
[93maverage test of epoch 28: loss -12.60522 acc 0.67568 roc_auc 0.56500 prc_auc 0.73125[0m
[92maverage training of epoch 29: loss -12.64372 acc 0.66225 roc_auc 0.49941 prc_auc 0.66864[0m
[93maverage test of epoch 29: loss -12.99349 acc 0.67568 roc_auc 0.51167 prc_auc 0.69179[0m
[92maverage training of epoch 30: loss -13.01667 acc 0.66225 roc_auc 0.42647 prc_auc 0.61968[0m
[93maverage test of epoch 30: loss -13.39249 acc 0.67568 roc_auc 0.50167 prc_auc 0.66991[0m
[92maverage training of epoch 31: loss -13.40330 acc 0.66225 roc_auc 0.45461 prc_auc 0.63516[0m
[93maverage test of epoch 31: loss -13.78992 acc 0.67568 roc_auc 0.62333 prc_auc 0.76305[0m
[92maverage training of epoch 32: loss -13.77709 acc 0.66225 roc_auc 0.40784 prc_auc 0.62091[0m
[93maverage test of epoch 32: loss -14.16602 acc 0.67568 roc_auc 0.63000 prc_auc 0.74363[0m
[92maverage training of epoch 33: loss -14.17593 acc 0.66225 roc_auc 0.46098 prc_auc 0.64216[0m
[93maverage test of epoch 33: loss -14.56201 acc 0.67568 roc_auc 0.43000 prc_auc 0.64258[0m
[92maverage training of epoch 34: loss -14.56929 acc 0.66225 roc_auc 0.43569 prc_auc 0.63141[0m
[93maverage test of epoch 34: loss -14.96119 acc 0.67568 roc_auc 0.46000 prc_auc 0.66546[0m
[92maverage training of epoch 35: loss -14.96465 acc 0.66225 roc_auc 0.38922 prc_auc 0.61121[0m
[93maverage test of epoch 35: loss -15.36268 acc 0.67568 roc_auc 0.52000 prc_auc 0.68558[0m
[92maverage training of epoch 36: loss -15.36178 acc 0.66225 roc_auc 0.52265 prc_auc 0.67208[0m
[93maverage test of epoch 36: loss -15.75568 acc 0.67568 roc_auc 0.56833 prc_auc 0.70759[0m
[92maverage training of epoch 37: loss -15.77402 acc 0.66225 roc_auc 0.44902 prc_auc 0.63993[0m
[93maverage test of epoch 37: loss -16.16122 acc 0.67568 roc_auc 0.42000 prc_auc 0.64265[0m
[92maverage training of epoch 38: loss -16.17074 acc 0.66225 roc_auc 0.49039 prc_auc 0.65807[0m
[93maverage test of epoch 38: loss -16.54586 acc 0.67568 roc_auc 0.46667 prc_auc 0.66157[0m
[92maverage training of epoch 39: loss -16.57764 acc 0.66225 roc_auc 0.47980 prc_auc 0.65335[0m
[93maverage test of epoch 39: loss -16.97997 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -16.97881 acc 0.66225 roc_auc 0.47706 prc_auc 0.65222[0m
[93maverage test of epoch 40: loss -17.39195 acc 0.67568 roc_auc 0.54167 prc_auc 0.69444[0m
[92maverage training of epoch 41: loss -17.40244 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 41: loss -17.83922 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -17.82453 acc 0.66225 roc_auc 0.48471 prc_auc 0.65557[0m
[93maverage test of epoch 42: loss -18.26761 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -18.25518 acc 0.66225 roc_auc 0.52441 prc_auc 0.67336[0m
[93maverage test of epoch 43: loss -18.68852 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -18.67473 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 44: loss -19.09881 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -19.10656 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 45: loss -19.56150 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -19.54357 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 46: loss -19.97512 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -19.97858 acc 0.66225 roc_auc 0.43647 prc_auc 0.63600[0m
[93maverage test of epoch 47: loss -20.43076 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -20.42578 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 48: loss -20.89785 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -20.87739 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 49: loss -21.33947 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=16, bias=True)
  (rnn): LSTM(16, 4, num_layers=2, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.0001
[92maverage training of epoch 0: loss 0.24111 acc 0.33775 roc_auc 0.54216 prc_auc 0.68848[0m
[93maverage test of epoch 0: loss 0.22443 acc 0.32432 roc_auc 0.55333 prc_auc 0.69688[0m
[92maverage training of epoch 1: loss 0.18906 acc 0.33775 roc_auc 0.56176 prc_auc 0.71315[0m
[93maverage test of epoch 1: loss 0.17218 acc 0.32432 roc_auc 0.36333 prc_auc 0.59230[0m
[92maverage training of epoch 2: loss 0.13477 acc 0.33775 roc_auc 0.59392 prc_auc 0.72456[0m
[93maverage test of epoch 2: loss 0.11689 acc 0.32432 roc_auc 0.64000 prc_auc 0.80926[0m
[92maverage training of epoch 3: loss 0.07465 acc 0.33775 roc_auc 0.55078 prc_auc 0.71092[0m
[93maverage test of epoch 3: loss 0.05540 acc 0.32432 roc_auc 0.44667 prc_auc 0.71522[0m
[92maverage training of epoch 4: loss 0.01023 acc 0.33775 roc_auc 0.51098 prc_auc 0.68978[0m
[93maverage test of epoch 4: loss -0.00882 acc 0.32432 roc_auc 0.32667 prc_auc 0.60518[0mUsing backend: pytorch

[92maverage training of epoch 5: loss -0.05762 acc 0.33775 roc_auc 0.46608 prc_auc 0.65643[0m
[93maverage test of epoch 5: loss -0.08342 acc 0.32432 roc_auc 0.27667 prc_auc 0.58249[0m
[92maverage training of epoch 6: loss -0.12884 acc 0.33775 roc_auc 0.41569 prc_auc 0.63684[0m
[93maverage test of epoch 6: loss -0.15511 acc 0.32432 roc_auc 0.37333 prc_auc 0.64806[0m
[92maverage training of epoch 7: loss -0.21762 acc 0.33775 roc_auc 0.43118 prc_auc 0.61893[0m
[93maverage test of epoch 7: loss -0.24407 acc 0.32432 roc_auc 0.50333 prc_auc 0.76364[0m
[92maverage training of epoch 8: loss -0.31680 acc 0.33775 roc_auc 0.56118 prc_auc 0.70248[0m
[93maverage test of epoch 8: loss -0.34629 acc 0.32432 roc_auc 0.29333 prc_auc 0.57369[0m
[92maverage training of epoch 9: loss -0.42280 acc 0.33775 roc_auc 0.49000 prc_auc 0.64703[0m
[93maverage test of epoch 9: loss -0.46297 acc 0.32432 roc_auc 0.61000 prc_auc 0.79837[0m
[92maverage training of epoch 10: loss -0.53385 acc 0.33775 roc_auc 0.50471 prc_auc 0.65499[0m
[93maverage test of epoch 10: loss -0.56780 acc 0.32432 roc_auc 0.48333 prc_auc 0.68526[0m
[92maverage training of epoch 11: loss -0.64483 acc 0.33775 roc_auc 0.52412 prc_auc 0.68039[0m
[93maverage test of epoch 11: loss -0.68294 acc 0.32432 roc_auc 0.56667 prc_auc 0.77518[0m
[92maverage training of epoch 12: loss -0.76328 acc 0.33775 roc_auc 0.50373 prc_auc 0.65771[0m
[93maverage test of epoch 12: loss -0.80463 acc 0.32432 roc_auc 0.51333 prc_auc 0.73192[0m
[92maverage training of epoch 13: loss -0.87751 acc 0.33775 roc_auc 0.54000 prc_auc 0.70706[0m
[93maverage test of epoch 13: loss -0.91348 acc 0.32432 roc_auc 0.40667 prc_auc 0.71015[0m
[92maverage training of epoch 14: loss -0.99683 acc 0.33775 roc_auc 0.45961 prc_auc 0.63550[0m
[93maverage test of epoch 14: loss -1.04879 acc 0.32432 roc_auc 0.49333 prc_auc 0.74131[0m
[92maverage training of epoch 15: loss -1.14665 acc 0.33775 roc_auc 0.56471 prc_auc 0.69320[0m
[93maverage test of epoch 15: loss -1.18890 acc 0.32432 roc_auc 0.42667 prc_auc 0.66865[0m
[92maverage training of epoch 16: loss -1.30993 acc 0.33775 roc_auc 0.54392 prc_auc 0.67427[0m
[93maverage test of epoch 16: loss -1.35971 acc 0.32432 roc_auc 0.56000 prc_auc 0.74420[0m
[92maverage training of epoch 17: loss -1.44740 acc 0.33775 roc_auc 0.45294 prc_auc 0.65132[0m
[93maverage test of epoch 17: loss -1.49457 acc 0.32432 roc_auc 0.42000 prc_auc 0.64348[0m
[92maverage training of epoch 18: loss -1.59493 acc 0.33775 roc_auc 0.47255 prc_auc 0.66033[0m
[93maverage test of epoch 18: loss -1.64689 acc 0.32432 roc_auc 0.56667 prc_auc 0.73248[0m
[92maverage training of epoch 19: loss -1.74130 acc 0.33775 roc_auc 0.51706 prc_auc 0.71256[0m
[93maverage test of epoch 19: loss -1.75850 acc 0.32432 roc_auc 0.41333 prc_auc 0.65970[0m
[92maverage training of epoch 20: loss -1.86808 acc 0.33775 roc_auc 0.42020 prc_auc 0.62051[0m
[93maverage test of epoch 20: loss -1.90750 acc 0.32432 roc_auc 0.35333 prc_auc 0.64426[0m
[92maverage training of epoch 21: loss -2.01973 acc 0.33775 roc_auc 0.46961 prc_auc 0.66124[0m
[93maverage test of epoch 21: loss -2.05935 acc 0.32432 roc_auc 0.57000 prc_auc 0.75049[0m
[92maverage training of epoch 22: loss -2.16652 acc 0.33775 roc_auc 0.57353 prc_auc 0.72526[0m
[93maverage test of epoch 22: loss -2.21091 acc 0.32432 roc_auc 0.59000 prc_auc 0.82093[0m
[92maverage training of epoch 23: loss -2.31463 acc 0.33775 roc_auc 0.53706 prc_auc 0.69249[0m
[93maverage test of epoch 23: loss -2.35038 acc 0.32432 roc_auc 0.52667 prc_auc 0.75755[0m
[92maverage training of epoch 24: loss -2.44209 acc 0.33775 roc_auc 0.33039 prc_auc 0.58013[0m
[93maverage test of epoch 24: loss -2.51751 acc 0.32432 roc_auc 0.51667 prc_auc 0.70217[0m
[92maverage training of epoch 25: loss -2.61083 acc 0.33775 roc_auc 0.47098 prc_auc 0.65546[0m
[93maverage test of epoch 25: loss -2.64611 acc 0.32432 roc_auc 0.42333 prc_auc 0.66054[0m
[92maverage training of epoch 26: loss -2.77013 acc 0.33775 roc_auc 0.52451 prc_auc 0.66247[0m
[93maverage test of epoch 26: loss -2.81072 acc 0.32432 roc_auc 0.44667 prc_auc 0.66066[0m
[92maverage training of epoch 27: loss -2.92850 acc 0.33775 roc_auc 0.40216 prc_auc 0.61029[0m
[93maverage test of epoch 27: loss -2.97932 acc 0.32432 roc_auc 0.38333 prc_auc 0.65430[0m
[92maverage training of epoch 28: loss -3.09242 acc 0.33775 roc_auc 0.42667 prc_auc 0.63043[0m
[93maverage test of epoch 28: loss -3.15841 acc 0.32432 roc_auc 0.54667 prc_auc 0.74762[0m
[92maverage training of epoch 29: loss -3.26856 acc 0.33775 roc_auc 0.42569 prc_auc 0.64421[0m
[93maverage test of epoch 29: loss -3.31520 acc 0.32432 roc_auc 0.55000 prc_auc 0.71477[0m
[92maverage training of epoch 30: loss -3.44786 acc 0.33775 roc_auc 0.46451 prc_auc 0.67808[0m
[93maverage test of epoch 30: loss -3.50426 acc 0.32432 roc_auc 0.60667 prc_auc 0.77434[0m
[92maverage training of epoch 31: loss -3.62394 acc 0.33775 roc_auc 0.46667 prc_auc 0.65129[0m
[93maverage test of epoch 31: loss -3.67684 acc 0.32432 roc_auc 0.47667 prc_auc 0.66830[0m
[92maverage training of epoch 32: loss -3.81124 acc 0.33775 roc_auc 0.51784 prc_auc 0.70999[0m
[93maverage test of epoch 32: loss -3.86387 acc 0.32432 roc_auc 0.43667 prc_auc 0.66900[0m
[92maverage training of epoch 33: loss -3.99133 acc 0.33775 roc_auc 0.44765 prc_auc 0.64767[0m
[93maverage test of epoch 33: loss -4.06259 acc 0.32432 roc_auc 0.39000 prc_auc 0.61515[0m
[92maverage training of epoch 34: loss -4.18250 acc 0.33775 roc_auc 0.48863 prc_auc 0.66373[0m
[93maverage test of epoch 34: loss -4.24786 acc 0.32432 roc_auc 0.39333 prc_auc 0.66979[0m
[92maverage training of epoch 35: loss -4.38064 acc 0.33775 roc_auc 0.50451 prc_auc 0.67803[0m
[93maverage test of epoch 35: loss -4.45532 acc 0.32432 roc_auc 0.40333 prc_auc 0.64332[0m
[92maverage training of epoch 36: loss -4.57370 acc 0.33775 roc_auc 0.44647 prc_auc 0.65593[0m
[93maverage test of epoch 36: loss -4.64612 acc 0.32432 roc_auc 0.47000 prc_auc 0.72586[0m
[92maverage training of epoch 37: loss -4.78462 acc 0.33775 roc_auc 0.43118 prc_auc 0.63570[0m
[93maverage test of epoch 37: loss -4.85307 acc 0.32432 roc_auc 0.58000 prc_auc 0.78704[0m
[92maverage training of epoch 38: loss -5.00021 acc 0.33775 roc_auc 0.51059 prc_auc 0.71915[0m
[93maverage test of epoch 38: loss -5.05999 acc 0.32432 roc_auc 0.33000 prc_auc 0.62712[0m
[92maverage training of epoch 39: loss -5.20799 acc 0.33775 roc_auc 0.45431 prc_auc 0.63553[0m
[93maverage test of epoch 39: loss -5.28132 acc 0.32432 roc_auc 0.46000 prc_auc 0.67266[0m
[92maverage training of epoch 40: loss -5.42785 acc 0.33775 roc_auc 0.40569 prc_auc 0.61110[0m
[93maverage test of epoch 40: loss -5.50211 acc 0.32432 roc_auc 0.63167 prc_auc 0.76731[0m
[92maverage training of epoch 41: loss -5.64401 acc 0.33775 roc_auc 0.46549 prc_auc 0.62930[0m
[93maverage test of epoch 41: loss -5.73032 acc 0.32432 roc_auc 0.70333 prc_auc 0.83509[0m
[92maverage training of epoch 42: loss -5.88022 acc 0.33775 roc_auc 0.52490 prc_auc 0.68996[0m
[93maverage test of epoch 42: loss -5.95466 acc 0.32432 roc_auc 0.45000 prc_auc 0.65167[0m
[92maverage training of epoch 43: loss -6.09680 acc 0.33775 roc_auc 0.42784 prc_auc 0.62648[0m
[93maverage test of epoch 43: loss -6.19207 acc 0.32432 roc_auc 0.48000 prc_auc 0.67171[0m
[92maverage training of epoch 44: loss -6.32911 acc 0.33775 roc_auc 0.37569 prc_auc 0.59272[0m
[93maverage test of epoch 44: loss -6.41399 acc 0.32432 roc_auc 0.37333 prc_auc 0.60920[0m
[92maverage training of epoch 45: loss -6.57028 acc 0.33775 roc_auc 0.45020 prc_auc 0.67045[0m
[93maverage test of epoch 45: loss -6.64601 acc 0.32432 roc_auc 0.36667 prc_auc 0.61299[0m
[92maverage training of epoch 46: loss -6.81402 acc 0.33775 roc_auc 0.39039 prc_auc 0.58412[0m
[93maverage test of epoch 46: loss -6.90262 acc 0.32432 roc_auc 0.60333 prc_auc 0.75548[0m
[92maverage training of epoch 47: loss -7.05702 acc 0.33775 roc_auc 0.40059 prc_auc 0.58825[0m
[93maverage test of epoch 47: loss -7.14835 acc 0.32432 roc_auc 0.40667 prc_auc 0.61606[0m
[92maverage training of epoch 48: loss -7.30474 acc 0.33775 roc_auc 0.44196 prc_auc 0.62697[0m
[93maverage test of epoch 48: loss -7.40256 acc 0.32432 roc_auc 0.56333 prc_auc 0.74434[0m
[92maverage training of epoch 49: loss -7.56190 acc 0.33775 roc_auc 0.43510 prc_auc 0.62707[0m
[93maverage test of epoch 49: loss -7.63881 acc 0.32432 roc_auc 0.48667 prc_auc 0.63972[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 2)
('embedding_size_dfscode_rnn', 16)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 1)
('lr', 0.0001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.62105 ROC_AUC (avg): 0.54256 PRC_AUC (avg): 0.69904 

Average forward propagation time taken(ms): 4.290032794964533
Average backward propagation time taken(ms): 1.5825609283251214

