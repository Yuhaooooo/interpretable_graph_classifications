# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 2)
('lr', 0.001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-17-15-32/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-17-15-32/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 8,
 'epochs': 50,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 4,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.001,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 1,
 'num_workers': 8,
 'number_of_mlp_layer': 2,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-17-17-15-32',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 50, 'learning_rate': 0.001, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=4, bias=True)
    (ReLU1): ReLU()
    (Linear2): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -0.03536 acc 0.33333 roc_auc 0.35980 prc_auc 0.56795[0m
[93maverage test of epoch 0: loss -0.09716 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 1: loss -0.14649 acc 0.33333 roc_auc 0.36200 prc_auc 0.56634[0m
[93maverage test of epoch 1: loss -0.20704 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 2: loss -0.25672 acc 0.33333 roc_auc 0.36060 prc_auc 0.56544[0m
[93maverage test of epoch 2: loss -0.31704 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 3: loss -0.36705 acc 0.33333 roc_auc 0.35980 prc_auc 0.56475[0m
[93maverage test of epoch 3: loss -0.42710 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 4: loss -0.47743 acc 0.33333 roc_auc 0.35860 prc_auc 0.56321[0m
[93maverage test of epoch 4: loss -0.53719 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 5: loss -0.58784 acc 0.33333 roc_auc 0.35830 prc_auc 0.56291[0m
[93maverage test of epoch 5: loss -0.64730 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 6: loss -0.69826 acc 0.33333 roc_auc 0.35780 prc_auc 0.56257[0m
[93maverage test of epoch 6: loss -0.75742 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 7: loss -0.80870 acc 0.33333 roc_auc 0.35760 prc_auc 0.56233[0m
[93maverage test of epoch 7: loss -0.86754 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 8: loss -0.91914 acc 0.33333 roc_auc 0.35760 prc_auc 0.56226[0m
[93maverage test of epoch 8: loss -0.97768 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 9: loss -1.02959 acc 0.33333 roc_auc 0.35760 prc_auc 0.56226[0m
[93maverage test of epoch 9: loss -1.08782 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 10: loss -1.14004 acc 0.33333 roc_auc 0.35740 prc_auc 0.56208[0m
[93maverage test of epoch 10: loss -1.19796 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 11: loss -1.25050 acc 0.33333 roc_auc 0.35740 prc_auc 0.56208[0m
[93maverage test of epoch 11: loss -1.30810 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 12: loss -1.36096 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 12: loss -1.41825 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 13: loss -1.47142 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 13: loss -1.52840 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 14: loss -1.58188 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 14: loss -1.63855 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 15: loss -1.69235 acc 0.33333 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 15: loss -1.74870 acc 0.34211 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 16: loss -1.80281 acc 0.52000 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 16: loss -1.85885 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 17: loss -1.91328 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 17: loss -1.96900 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 18: loss -2.02374 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 18: loss -2.07915 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -2.13421 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 19: loss -2.18930 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -2.24467 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 20: loss -2.29945 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -2.35514 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 21: loss -2.40960 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -2.46561 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 22: loss -2.51976 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -2.57607 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 23: loss -2.62991 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -2.68654 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 24: loss -2.74006 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -2.79700 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 25: loss -2.85021 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -2.90747 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 26: loss -2.96036 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -3.01794 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 27: loss -3.07051 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -3.12840 acc 0.66667 roc_auc 0.35700 prc_auc 0.56188[0m
[93maverage test of epoch 28: loss -3.18066 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -3.87458 acc 0.66667 roc_auc 0.41760 prc_auc 0.62496[0m
[93maverage test of epoch 29: loss -6.65524 acc 0.65789 roc_auc 0.87077 prc_auc 0.92513[0m
[92maverage training of epoch 30: loss -13.45810 acc 0.66667 roc_auc 0.41640 prc_auc 0.62266[0m
[93maverage test of epoch 30: loss -21.69144 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -31.84138 acc 0.66667 roc_auc 0.41560 prc_auc 0.62131[0m
[93maverage test of epoch 31: loss -42.93173 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -55.16199 acc 0.66667 roc_auc 0.43460 prc_auc 0.63374[0m
[93maverage test of epoch 32: loss -68.17820 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -82.35988 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 33: loss -97.26683 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -113.46381 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -130.29804 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -148.57321 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -167.38191 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -187.81307 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -208.65646 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -231.33136 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -254.27818 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -280.31590 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -308.11614 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -348.55601 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -396.30771 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -455.91257 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -518.37859 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -587.33721 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -658.38756 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -736.22193 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -815.59481 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -902.43207 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -990.23861 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -1086.37927 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -1182.85550 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -1288.66107 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -1394.08698 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -1509.95768 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -1624.64908 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -1751.01403 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -1875.30698 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -2012.61362 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -2146.85712 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -2295.56796 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -2440.12064 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=4, bias=True)
    (ReLU1): ReLU()
    (Linear2): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss 0.02346 acc 0.56000 roc_auc 0.42440 prc_auc 0.60155[0m
[93maverage test of epoch 0: loss -0.08468 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 1: loss -0.14339 acc 0.66667 roc_auc 0.42100 prc_auc 0.60386[0m
[93maverage test of epoch 1: loss -0.19470 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 2: loss -0.25375 acc 0.66667 roc_auc 0.42000 prc_auc 0.60471[0m
[93maverage test of epoch 2: loss -0.30479 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 3: loss -0.36416 acc 0.66667 roc_auc 0.42000 prc_auc 0.60471[0m
[93maverage test of epoch 3: loss -0.41491 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 4: loss -0.47459 acc 0.66667 roc_auc 0.42000 prc_auc 0.60471[0m
[93maverage test of epoch 4: loss -0.52504 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 5: loss -0.58504 acc 0.66667 roc_auc 0.42000 prc_auc 0.60471[0m
[93maverage test of epoch 5: loss -0.63519 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 6: loss -0.69550 acc 0.66667 roc_auc 0.42020 prc_auc 0.60485[0m
[93maverage test of epoch 6: loss -0.74534 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 7: loss -0.80597 acc 0.66667 roc_auc 0.42020 prc_auc 0.60485[0m
[93maverage test of epoch 7: loss -0.85549 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 8: loss -0.91644 acc 0.66667 roc_auc 0.42020 prc_auc 0.60485[0m
[93maverage test of epoch 8: loss -0.96564 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 9: loss -1.02691 acc 0.66667 roc_auc 0.42020 prc_auc 0.60485[0m
[93maverage test of epoch 9: loss -1.07580 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 10: loss -1.13738 acc 0.66667 roc_auc 0.42000 prc_auc 0.60455[0m
[93maverage test of epoch 10: loss -1.18596 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 11: loss -1.24785 acc 0.66667 roc_auc 0.42000 prc_auc 0.60455[0m
[93maverage test of epoch 11: loss -1.29612 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 12: loss -1.35833 acc 0.66667 roc_auc 0.42000 prc_auc 0.60455[0m
[93maverage test of epoch 12: loss -1.40629 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 13: loss -1.46881 acc 0.66667 roc_auc 0.42000 prc_auc 0.60455[0m
[93maverage test of epoch 13: loss -1.51645 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 14: loss -1.57929 acc 0.66667 roc_auc 0.42000 prc_auc 0.60455[0m
[93maverage test of epoch 14: loss -1.62661 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 15: loss -1.68976 acc 0.66667 roc_auc 0.42000 prc_auc 0.60455[0m
[93maverage test of epoch 15: loss -1.73678 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 16: loss -1.80024 acc 0.66667 roc_auc 0.42000 prc_auc 0.60455[0m
[93maverage test of epoch 16: loss -1.84694 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 17: loss -1.91072 acc 0.66667 roc_auc 0.42000 prc_auc 0.60455[0m
[93maverage test of epoch 17: loss -1.95710 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 18: loss -2.02120 acc 0.66667 roc_auc 0.42000 prc_auc 0.60455[0m
[93maverage test of epoch 18: loss -2.06726 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -2.13167 acc 0.66667 roc_auc 0.42000 prc_auc 0.60455[0m
[93maverage test of epoch 19: loss -2.17743 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -2.24215 acc 0.66667 roc_auc 0.42000 prc_auc 0.60455[0m
[93maverage test of epoch 20: loss -2.28759 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -2.35263 acc 0.66667 roc_auc 0.42000 prc_auc 0.60455[0m
[93maverage test of epoch 21: loss -2.39775 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -2.46310 acc 0.66667 roc_auc 0.42000 prc_auc 0.60455[0m
[93maverage test of epoch 22: loss -2.50791 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -2.57358 acc 0.66667 roc_auc 0.42000 prc_auc 0.60455[0m
[93maverage test of epoch 23: loss -2.61807 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -2.68406 acc 0.66667 roc_auc 0.42010 prc_auc 0.60455[0m
[93maverage test of epoch 24: loss -2.72823 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -2.79453 acc 0.66667 roc_auc 0.42010 prc_auc 0.60455[0m
[93maverage test of epoch 25: loss -2.83840 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -2.90501 acc 0.66667 roc_auc 0.42010 prc_auc 0.60455[0m
[93maverage test of epoch 26: loss -2.94856 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -3.01548 acc 0.66667 roc_auc 0.42010 prc_auc 0.60455[0m
[93maverage test of epoch 27: loss -3.05872 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -3.12596 acc 0.66667 roc_auc 0.42000 prc_auc 0.60455[0m
[93maverage test of epoch 28: loss -3.16887 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -3.23643 acc 0.66667 roc_auc 0.42010 prc_auc 0.60455[0m
[93maverage test of epoch 29: loss -3.27903 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -3.34690 acc 0.66667 roc_auc 0.42010 prc_auc 0.60455[0m
[93maverage test of epoch 30: loss -3.38919 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -3.45738 acc 0.66667 roc_auc 0.42010 prc_auc 0.60455[0m
[93maverage test of epoch 31: loss -3.49935 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -3.56785 acc 0.66667 roc_auc 0.42000 prc_auc 0.60455[0m
[93maverage test of epoch 32: loss -3.60951 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -3.67833 acc 0.66667 roc_auc 0.42010 prc_auc 0.60455[0m
[93maverage test of epoch 33: loss -3.71967 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -3.78880 acc 0.66667 roc_auc 0.42000 prc_auc 0.60455[0m
[93maverage test of epoch 34: loss -3.82983 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -3.89928 acc 0.66667 roc_auc 0.42000 prc_auc 0.60455[0m
[93maverage test of epoch 35: loss -3.93999 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -4.00975 acc 0.66667 roc_auc 0.42000 prc_auc 0.60455[0m
[93maverage test of epoch 36: loss -4.05015 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -4.12022 acc 0.66667 roc_auc 0.42010 prc_auc 0.60455[0m
[93maverage test of epoch 37: loss -4.16030 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -4.23069 acc 0.66667 roc_auc 0.42010 prc_auc 0.60455[0m
[93maverage test of epoch 38: loss -4.27046 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -4.34116 acc 0.66667 roc_auc 0.42010 prc_auc 0.60455[0m
[93maverage test of epoch 39: loss -4.38062 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -4.45163 acc 0.66667 roc_auc 0.42010 prc_auc 0.60455[0m
[93maverage test of epoch 40: loss -4.49077 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -4.56210 acc 0.66667 roc_auc 0.42000 prc_auc 0.60455[0m
[93maverage test of epoch 41: loss -4.60093 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -4.67257 acc 0.66667 roc_auc 0.42010 prc_auc 0.60455[0m
[93maverage test of epoch 42: loss -4.71108 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -4.78304 acc 0.66667 roc_auc 0.42010 prc_auc 0.60455[0m
[93maverage test of epoch 43: loss -4.82123 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -4.89351 acc 0.66667 roc_auc 0.42010 prc_auc 0.60455[0m
[93maverage test of epoch 44: loss -4.93139 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -5.11553 acc 0.66667 roc_auc 0.42640 prc_auc 0.62727[0m
[93maverage test of epoch 45: loss -5.67944 acc 0.65789 roc_auc 0.88154 prc_auc 0.93002[0m
[92maverage training of epoch 46: loss -10.78493 acc 0.66667 roc_auc 0.42840 prc_auc 0.61481[0m
[93maverage test of epoch 46: loss -18.46926 acc 0.65789 roc_auc 0.85385 prc_auc 0.88194[0m
[92maverage training of epoch 47: loss -29.34324 acc 0.66667 roc_auc 0.45950 prc_auc 0.64221[0m
[93maverage test of epoch 47: loss -41.27410 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -54.99515 acc 0.66667 roc_auc 0.47310 prc_auc 0.64839[0m
[93maverage test of epoch 48: loss -70.19326 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -88.87705 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -108.92966 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=4, bias=True)
    (ReLU1): ReLU()
    (Linear2): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss 0.58850 acc 0.66667 roc_auc 0.46280 prc_auc 0.65022[0m
[93maverage test of epoch 0: loss 0.45387 acc 0.65789 roc_auc 0.87077 prc_auc 0.93382[0m
[92maverage training of epoch 1: loss 0.34543 acc 0.66667 roc_auc 0.40280 prc_auc 0.60757[0m
[93maverage test of epoch 1: loss 0.24491 acc 0.65789 roc_auc 0.84000 prc_auc 0.91448[0m
[92maverage training of epoch 2: loss 0.15435 acc 0.66667 roc_auc 0.41110 prc_auc 0.61279[0m
[93maverage test of epoch 2: loss 0.06608 acc 0.65789 roc_auc 0.16923 prc_auc 0.54660[0m
[92maverage training of epoch 3: loss 0.00003 acc 0.66667 roc_auc 0.36700 prc_auc 0.57273[0m
[93maverage test of epoch 3: loss -0.05539 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 4: loss -0.11128 acc 0.66667 roc_auc 0.37840 prc_auc 0.57576[0m
[93maverage test of epoch 4: loss -0.16549 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 5: loss -0.22170 acc 0.66667 roc_auc 0.37840 prc_auc 0.57569[0m
[93maverage test of epoch 5: loss -0.27561 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 6: loss -0.33213 acc 0.66667 roc_auc 0.37800 prc_auc 0.57538[0m
[93maverage test of epoch 6: loss -0.38573 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 7: loss -0.44257 acc 0.66667 roc_auc 0.37780 prc_auc 0.57519[0m
[93maverage test of epoch 7: loss -0.49586 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 8: loss -0.55302 acc 0.66667 roc_auc 0.37800 prc_auc 0.57538[0m
[93maverage test of epoch 8: loss -0.60600 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 9: loss -0.66347 acc 0.66667 roc_auc 0.37760 prc_auc 0.57522[0m
[93maverage test of epoch 9: loss -0.71614 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 10: loss -0.77393 acc 0.66667 roc_auc 0.37740 prc_auc 0.57503[0m
[93maverage test of epoch 10: loss -0.82629 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 11: loss -0.88439 acc 0.66667 roc_auc 0.37710 prc_auc 0.57482[0m
[93maverage test of epoch 11: loss -0.93643 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 12: loss -0.99485 acc 0.66667 roc_auc 0.37700 prc_auc 0.57482[0m
[93maverage test of epoch 12: loss -1.04658 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 13: loss -1.10531 acc 0.66667 roc_auc 0.37700 prc_auc 0.57482[0m
[93maverage test of epoch 13: loss -1.15673 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 14: loss -1.21578 acc 0.66667 roc_auc 0.37690 prc_auc 0.57463[0m
[93maverage test of epoch 14: loss -1.26688 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 15: loss -1.32624 acc 0.66667 roc_auc 0.37680 prc_auc 0.57463[0m
[93maverage test of epoch 15: loss -1.37703 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 16: loss -1.43671 acc 0.66667 roc_auc 0.37680 prc_auc 0.57485[0m
[93maverage test of epoch 16: loss -1.48718 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 17: loss -1.54717 acc 0.66667 roc_auc 0.37680 prc_auc 0.57463[0m
[93maverage test of epoch 17: loss -1.59733 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 18: loss -1.65764 acc 0.66667 roc_auc 0.37680 prc_auc 0.57463[0m
[93maverage test of epoch 18: loss -1.70748 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -1.76810 acc 0.66667 roc_auc 0.37670 prc_auc 0.57444[0m
[93maverage test of epoch 19: loss -1.81764 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -1.87857 acc 0.66667 roc_auc 0.37660 prc_auc 0.57444[0m
[93maverage test of epoch 20: loss -1.92779 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -1.98904 acc 0.66667 roc_auc 0.37660 prc_auc 0.57444[0m
[93maverage test of epoch 21: loss -2.03794 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -2.09951 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 22: loss -2.14809 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -2.20997 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 23: loss -2.25824 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -2.32044 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 24: loss -2.36839 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -2.43090 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 25: loss -2.47854 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -2.54137 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 26: loss -2.58869 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -2.65183 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 27: loss -2.69884 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -2.76230 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 28: loss -2.80899 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -2.87276 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 29: loss -2.91914 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -2.98322 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 30: loss -3.02929 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -3.09369 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 31: loss -3.13944 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -3.20415 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 32: loss -3.24959 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -3.31461 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 33: loss -3.35973 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -3.42507 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 34: loss -3.46988 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -3.53553 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 35: loss -3.58002 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -3.64599 acc 0.66667 roc_auc 0.37640 prc_auc 0.57439[0m
[93maverage test of epoch 36: loss -3.69017 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -3.75645 acc 0.66667 roc_auc 0.37640 prc_auc 0.57445[0m
[93maverage test of epoch 37: loss -3.80031 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -4.79573 acc 0.66667 roc_auc 0.44000 prc_auc 0.64356[0m
[93maverage test of epoch 38: loss -9.27447 acc 0.65789 roc_auc 0.14000 prc_auc 0.57168[0m
[92maverage training of epoch 39: loss -21.95711 acc 0.66667 roc_auc 0.44350 prc_auc 0.64178[0m
[93maverage test of epoch 39: loss -37.05996 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -56.83871 acc 0.66667 roc_auc 0.46580 prc_auc 0.64689[0m
[93maverage test of epoch 40: loss -79.67378 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -105.96476 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -134.14565 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -165.57259 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -198.69942 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -235.31780 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -273.40325 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -315.33367 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -358.46533 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -405.88649 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -454.20019 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -507.32647 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -560.98899 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -620.06049 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -679.26038 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -744.53745 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -809.47975 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -881.23773 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -952.13895 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=4, bias=True)
    (ReLU1): ReLU()
    (Linear2): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -0.14758 acc 0.66225 roc_auc 0.47882 prc_auc 0.64713[0m
[93maverage test of epoch 0: loss -0.24716 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 1: loss -0.30486 acc 0.66225 roc_auc 0.37412 prc_auc 0.57594[0m
[93maverage test of epoch 1: loss -0.39271 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 2: loss -0.47672 acc 0.66225 roc_auc 0.36686 prc_auc 0.57229[0m
[93maverage test of epoch 2: loss -0.60586 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 3: loss -0.74554 acc 0.66225 roc_auc 0.37490 prc_auc 0.56956[0m
[93maverage test of epoch 3: loss -0.93575 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 4: loss -1.12897 acc 0.66225 roc_auc 0.38137 prc_auc 0.57364[0m
[93maverage test of epoch 4: loss -1.37030 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 5: loss -1.59221 acc 0.66225 roc_auc 0.38216 prc_auc 0.57397[0m
[93maverage test of epoch 5: loss -1.86070 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 6: loss -2.10332 acc 0.66225 roc_auc 0.38382 prc_auc 0.57496[0m
[93maverage test of epoch 6: loss -2.39653 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 7: loss -2.65843 acc 0.66225 roc_auc 0.38451 prc_auc 0.57647[0m
[93maverage test of epoch 7: loss -2.97359 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 8: loss -3.24732 acc 0.66225 roc_auc 0.38529 prc_auc 0.57673[0m
[93maverage test of epoch 8: loss -3.57886 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 9: loss -3.86428 acc 0.66225 roc_auc 0.38529 prc_auc 0.57703[0m
[93maverage test of epoch 9: loss -4.21245 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 10: loss -4.50803 acc 0.66225 roc_auc 0.38569 prc_auc 0.57726[0m
[93maverage test of epoch 10: loss -4.87196 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 11: loss -5.17840 acc 0.66225 roc_auc 0.38529 prc_auc 0.57719[0m
[93maverage test of epoch 11: loss -5.55912 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 12: loss -5.87692 acc 0.66225 roc_auc 0.38588 prc_auc 0.57769[0m
[93maverage test of epoch 12: loss -6.27512 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 13: loss -6.60458 acc 0.66225 roc_auc 0.38627 prc_auc 0.57815[0m
[93maverage test of epoch 13: loss -7.02077 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 14: loss -7.40332 acc 0.66225 roc_auc 0.40157 prc_auc 0.59144[0m
[93maverage test of epoch 14: loss -7.99916 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 15: loss -8.66660 acc 0.66225 roc_auc 0.39892 prc_auc 0.58816[0m
[93maverage test of epoch 15: loss -9.47483 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 16: loss -10.18467 acc 0.66225 roc_auc 0.39961 prc_auc 0.58813[0m
[93maverage test of epoch 16: loss -11.01670 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 17: loss -11.72001 acc 0.66225 roc_auc 0.39833 prc_auc 0.58776[0m
[93maverage test of epoch 17: loss -12.56505 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 18: loss -13.27621 acc 0.66225 roc_auc 0.39804 prc_auc 0.58783[0m
[93maverage test of epoch 18: loss -14.14369 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 19: loss -14.86540 acc 0.66225 roc_auc 0.39725 prc_auc 0.58695[0m
[93maverage test of epoch 19: loss -15.75908 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 20: loss -16.49574 acc 0.66225 roc_auc 0.39725 prc_auc 0.58695[0m
[93maverage test of epoch 20: loss -17.41965 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 21: loss -18.17361 acc 0.66225 roc_auc 0.39755 prc_auc 0.58723[0m
[93maverage test of epoch 21: loss -19.13019 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 22: loss -19.90287 acc 0.66225 roc_auc 0.39814 prc_auc 0.58746[0m
[93maverage test of epoch 22: loss -20.89383 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 23: loss -21.75807 acc 0.66225 roc_auc 0.40422 prc_auc 0.59257[0m
[93maverage test of epoch 23: loss -23.00135 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 24: loss -24.16383 acc 0.66225 roc_auc 0.40392 prc_auc 0.59066[0m
[93maverage test of epoch 24: loss -25.61295 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 25: loss -26.80723 acc 0.66225 roc_auc 0.40382 prc_auc 0.59011[0m
[93maverage test of epoch 25: loss -28.28490 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 26: loss -29.48079 acc 0.66225 roc_auc 0.40353 prc_auc 0.58998[0m
[93maverage test of epoch 26: loss -30.99192 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 27: loss -32.26706 acc 0.66225 roc_auc 0.40314 prc_auc 0.59060[0m
[93maverage test of epoch 27: loss -35.64830 acc 0.67568 roc_auc 0.54000 prc_auc 0.70162[0m
[92maverage training of epoch 28: loss -69.38120 acc 0.66225 roc_auc 0.45863 prc_auc 0.63801[0m
[93maverage test of epoch 28: loss -110.29296 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 29: loss -152.18006 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 29: loss -198.42671 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 30: loss -245.24565 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 30: loss -297.51929 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 31: loss -349.59432 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 31: loss -408.28251 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 32: loss -465.86210 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 32: loss -531.31967 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 33: loss -594.64495 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 33: loss -667.22938 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 34: loss -736.54324 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 34: loss -816.62001 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 35: loss -892.17027 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 35: loss -980.11524 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 36: loss -1062.15323 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 36: loss -1158.35125 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 37: loss -1247.13177 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 37: loss -1351.97698 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 38: loss -1447.75788 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 38: loss -1561.65203 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 39: loss -1664.69210 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 39: loss -1788.04412 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -1898.60448 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 40: loss -2031.83077 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -2157.54726 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 41: loss -2315.32060 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -2459.02057 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 42: loss -2632.42279 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -2786.91232 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 43: loss -2974.22526 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -3139.49209 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 44: loss -3341.04843 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -3517.32559 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 45: loss -3733.61130 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -3921.19292 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 46: loss -4152.74723 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -4351.94723 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 47: loss -4599.33094 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -4810.47511 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 48: loss -5074.26650 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -5297.68296 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 49: loss -5578.47023 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=4, bias=True)
    (ReLU0): ReLU()
    (Linear1): Linear(in_features=4, out_features=4, bias=True)
    (ReLU1): ReLU()
    (Linear2): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.001
[92maverage training of epoch 0: loss -0.32360 acc 0.33775 roc_auc 0.41176 prc_auc 0.60413[0m
[93maverage test of epoch 0: loss -0.51179 acc 0.32432 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 1: loss -0.79606 acc 0.37086 roc_auc 0.42020 prc_auc 0.61144[0m
[93maverage test of epoch 1: loss -1.55646 acc 0.67568 roc_auc 0.20333 prc_auc 0.59414[0mUsing backend: pytorch
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))

[92maverage training of epoch 2: loss -3.71405 acc 0.66225 roc_auc 0.41706 prc_auc 0.61112[0m
[93maverage test of epoch 2: loss -6.77002 acc 0.67568 roc_auc 0.74667 prc_auc 0.89103[0m
[92maverage training of epoch 3: loss -9.58603 acc 0.66225 roc_auc 0.41804 prc_auc 0.61187[0m
[93maverage test of epoch 3: loss -12.94824 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 4: loss -16.32840 acc 0.66225 roc_auc 0.41980 prc_auc 0.61775[0m
[93maverage test of epoch 4: loss -20.56694 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 5: loss -24.73950 acc 0.66225 roc_auc 0.49922 prc_auc 0.66190[0m
[93maverage test of epoch 5: loss -30.08813 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 6: loss -35.11919 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 6: loss -41.54667 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 7: loss -47.40695 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 7: loss -54.96306 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 8: loss -61.71862 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 8: loss -70.49700 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 9: loss -78.20943 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 9: loss -88.30149 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 10: loss -97.03012 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 10: loss -108.52667 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 11: loss -118.32948 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 11: loss -131.32152 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 12: loss -142.25556 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 12: loss -156.83450 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 13: loss -168.95617 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 13: loss -185.21420 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 14: loss -198.57927 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 14: loss -216.60868 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 15: loss -231.26907 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 15: loss -251.15773 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 16: loss -267.16654 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 16: loss -289.00852 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 17: loss -306.42089 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 17: loss -330.31206 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 18: loss -349.18289 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 18: loss -375.22008 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 19: loss -395.60322 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 19: loss -423.88394 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 20: loss -445.83303 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 20: loss -476.45528 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 21: loss -500.02359 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 21: loss -533.08647 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 22: loss -558.32655 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 22: loss -593.93009 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 23: loss -620.89353 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 23: loss -659.13783 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 24: loss -687.87641 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 24: loss -728.86321 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 25: loss -759.42729 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 25: loss -803.25804 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 26: loss -835.69841 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 26: loss -882.47668 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 27: loss -916.84192 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 27: loss -966.67076 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 28: loss -1003.01066 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 28: loss -1055.99307 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 29: loss -1094.69103 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 29: loss -1152.90917 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 30: loss -1198.16325 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 30: loss -1263.25555 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 31: loss -1311.61024 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 31: loss -1381.15210 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 32: loss -1432.40856 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 32: loss -1506.39479 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 33: loss -1560.55616 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 33: loss -1639.07838 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 34: loss -1696.19904 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 34: loss -1779.39650 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 35: loss -1839.53538 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 35: loss -1927.54814 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 36: loss -1990.77786 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 36: loss -2083.76057 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 37: loss -2150.14216 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 37: loss -2248.23870 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 38: loss -2317.84741 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 38: loss -2421.21729 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 39: loss -2494.12274 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 39: loss -2602.92496 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -2679.19858 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 40: loss -2793.58992 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -2873.30134 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 41: loss -2993.44723 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -3076.66810 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 42: loss -3202.73076 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -3289.52968 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 43: loss -3421.67219 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -3512.11593 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 44: loss -3650.49839 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -3744.64443 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 45: loss -3889.42717 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -3987.34105 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 46: loss -4138.68949 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -4240.44350 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 47: loss -4398.53249 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -4504.18466 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 48: loss -4669.18291 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -4778.81432 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 49: loss -4950.90387 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 2)
('lr', 0.001)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.66501 ROC_AUC (avg): 0.5 PRC_AUC (avg): 0.66501 

Average forward propagation time taken(ms): 3.123373561475026
Average backward propagation time taken(ms): 1.0024637236310452

