# conda environments:
#
base                     /apps/anaconda3
DGCNN                    /home/FYP/heyu0012/.conda/envs/DGCNN
GCNN_GAP                 /home/FYP/heyu0012/.conda/envs/GCNN_GAP
GCNN_GAP_graphgen     *  /home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen
graphgen                 /home/FYP/heyu0012/.conda/envs/graphgen
pytorch                  /home/FYP/heyu0012/.conda/envs/pytorch

====== begin of gnn configuration ======
| msg_average = 0
======   end of gnn configuration ======






Params Turning Set
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.01)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))






args.base_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/
args.graph_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/
args.min_dfscode_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/
args.min_dfscode_tensor_path: /home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/
*** 1 train_index:  [  0   2   3   6   9  10  11  12  13  14  15  16  17  19  20  21  22  23
  24  26  27  30  31  32  33  35  36  38  39  41  42  43  44  45  46  47
  48  49  50  52  53  54  56  57  59  60  61  62  63  64  65  66  67  69
  70  71  72  73  74  76  77  78  79  80  81  82  83  84  87  88  89  91
  92  94  95  96  97  98 100 101 102 103 104 106 107 108 109 110 112 113
 115 116 117 118 119 120 121 122 124 125 126 127 129 130 131 132 134 136
 138 139 140 141 142 144 145 146 147 148 149 151 152 153 154 155 156 157
 158 159 160 161 164 165 166 167 169 170 171 172 173 175 176 177 178 179
 180 182 184 185 186 187]
*** 2 test_index:  [  1   4   5   7   8  18  25  28  29  34  37  40  51  55  58  68  75  85
  86  90  93  99 105 111 114 123 128 133 135 137 143 150 162 163 168 174
 181 183]
*** 1 train_index:  [  0   1   2   4   5   6   7   8  10  11  12  13  14  15  16  17  18  19
  20  21  22  24  25  26  27  28  29  30  32  33  34  35  36  37  38  39
  40  41  43  44  45  46  49  50  51  52  53  54  55  56  58  59  60  61
  62  63  64  65  66  67  68  69  70  71  74  75  76  77  79  80  81  82
  83  84  85  86  88  90  91  92  93  94  96  97  98  99 101 102 103 104
 105 106 107 111 112 113 114 115 120 121 122 123 124 125 126 128 129 130
 131 133 134 135 136 137 138 139 140 143 144 145 147 148 150 153 154 155
 156 159 162 163 164 165 167 168 169 170 171 172 173 174 175 177 178 179
 180 181 182 183 186 187]
*** 2 test_index:  [  3   9  23  31  42  47  48  57  72  73  78  87  89  95 100 108 109 110
 116 117 118 119 127 132 141 142 146 149 151 152 157 158 160 161 166 176
 184 185]
*** 1 train_index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18  19
  20  23  24  25  26  28  29  31  32  34  35  36  37  38  40  41  42  43
  44  47  48  51  53  54  55  56  57  58  59  60  64  66  68  70  71  72
  73  74  75  76  77  78  79  81  82  84  85  86  87  88  89  90  92  93
  95  96  97  98  99 100 104 105 106 107 108 109 110 111 112 113 114 115
 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 133 134
 135 137 139 140 141 142 143 144 146 148 149 150 151 152 153 156 157 158
 159 160 161 162 163 165 166 167 168 169 171 172 173 174 175 176 177 178
 179 181 183 184 185 186]
*** 2 test_index:  [  0  16  21  22  27  30  33  39  45  46  49  50  52  61  62  63  65  67
  69  80  83  91  94 101 102 103 122 136 138 145 147 154 155 164 170 180
 182 187]
*** 1 train_index:  [  0   1   3   4   5   6   7   8   9  13  14  16  18  19  21  22  23  25
  26  27  28  29  30  31  33  34  36  37  38  39  40  42  43  45  46  47
  48  49  50  51  52  53  55  56  57  58  60  61  62  63  65  66  67  68
  69  71  72  73  75  76  77  78  79  80  81  83  84  85  86  87  88  89
  90  91  92  93  94  95  97  98  99 100 101 102 103 105 106 108 109 110
 111 113 114 115 116 117 118 119 120 121 122 123 125 127 128 131 132 133
 134 135 136 137 138 140 141 142 143 144 145 146 147 148 149 150 151 152
 154 155 156 157 158 160 161 162 163 164 165 166 168 170 171 174 175 176
 180 181 182 183 184 185 187]
*** 2 test_index:  [  2  10  11  12  15  17  20  24  32  35  41  44  54  59  64  70  74  82
  96 104 107 112 124 126 129 130 139 153 159 167 169 172 173 177 178 179
 186]
*** 1 train_index:  [  0   1   2   3   4   5   7   8   9  10  11  12  15  16  17  18  20  21
  22  23  24  25  27  28  29  30  31  32  33  34  35  37  39  40  41  42
  44  45  46  47  48  49  50  51  52  54  55  57  58  59  61  62  63  64
  65  67  68  69  70  72  73  74  75  78  80  82  83  85  86  87  89  90
  91  93  94  95  96  99 100 101 102 103 104 105 107 108 109 110 111 112
 114 116 117 118 119 122 123 124 126 127 128 129 130 132 133 135 136 137
 138 139 141 142 143 145 146 147 149 150 151 152 153 154 155 157 158 159
 160 161 162 163 164 166 167 168 169 170 172 173 174 176 177 178 179 180
 181 182 183 184 185 186 187]
*** 2 test_index:  [  6  13  14  19  26  36  38  43  53  56  60  66  71  76  77  79  81  84
  88  92  97  98 106 113 115 120 121 125 131 134 140 144 148 156 165 171
 175]
{'base_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/',
 'batch_size': 1,
 'clean_temp': False,
 'clean_tensorboard': False,
 'current_dataset_path': None,
 'current_min_dfscode_path': None,
 'current_model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-16-51-21/',
 'current_processed_dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'current_temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/DFScodeRNN_cls_LSTM_MUTAG_2021-01-17-16-51-21/',
 'dataset_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/datasets/',
 'device': device(type='cuda', index=0),
 'dfscode_rnn_dropout': 0.2,
 'embedding_size_dfscode_rnn': 8,
 'epochs': 50,
 'epochs_end': 10000,
 'epochs_save': 20,
 'epochs_validate': 1,
 'fname': 'DFScodeRNN_cls_LSTM_MUTAG',
 'gradient_clipping': True,
 'graph_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/graphs/',
 'graph_type': 'MUTAG',
 'graphgen_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/',
 'hidden_size_dfscode_rnn': 4,
 'load_device': device(type='cuda', index=0),
 'load_model': False,
 'load_model_path': '',
 'log_tensorboard': False,
 'lr': 0.01,
 'max_prev_node': None,
 'min_dfscode_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscodes/',
 'min_dfscode_tensor_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/min_dfscode_tensors/',
 'model_save_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/model_save/',
 'note': 'DFScodeRNN_cls_LSTM',
 'num_graphs': None,
 'num_layers': 1,
 'num_workers': 8,
 'number_of_mlp_layer': 0,
 'rnn_type': 'LSTM',
 'save_model': False,
 'temp_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tmp/',
 'tensorboard_path': '/home/FYP/heyu0012/projects/interpretable_graph_classifications/data/MUTAG/graphgen/tensorboard/',
 'time': '2021-01-17-16-51-21',
 'weights': False}


graphgen args.__dict__: None




dataset_features: {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}




config: {'general': {'data_autobalance': False, 'print_dataset_features': True, 'batch_size': 1, 'extract_features': False}, 'run': {'num_epochs': 50, 'learning_rate': 0.01, 'seed': 1800, 'k_fold': 5, 'model': 'DFScodeRNN_cls_LSTM', 'dataset': 'MUTAG'}, 'GNN_models': {'DGCNN': {'convolution_layers_size': '32-32-32-1', 'sortpooling_k': 0.6, 'n_hidden': 128, 'convolution_dropout': 0.5, 'pred_dropout': 0.5, 'FP_len': 0}, 'GCN': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'GCND': {'convolution_layers_size': '128-256-512', 'dropout': 0.5}, 'DiffPool': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DiffPoolD': {'convolution_layers_size': '64-64-64', 'pred_hidden_layers': '50-50-50', 'assign_ratio': 0.25, 'number_of_pooling': 1, 'concat_tensors': False}, 'DFScodeRNN_cls': {'dummy': 0}}, 'dataset_features': {'node_forward': {'0': 0, '1': 1, '2': 2, '3': 3, '5': 4, '6': 5, '4': 6}, 'node_backward': {0: '0', 1: '1', 2: '2', 3: '3', 4: '5', 5: '6', 6: '4'}, 'edge_forward': {'0': 0}, 'edge_backward': {0: '0'}, 'max_nodes': 28, 'min_nodes': 10, 'max_edges': 33, 'min_edges': 10, 'max_degree': 4, 'label_size': 2}}


Training a new model: DFScodeRNN_cls_LSTM
Training model with dataset, testing using fold 0
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.01
[92maverage training of epoch 0: loss -3.74332 acc 0.59333 roc_auc 0.36280 prc_auc 0.57016[0m
[93maverage test of epoch 0: loss -7.31678 acc 0.65789 roc_auc 0.84769 prc_auc 0.90110[0m
[92maverage training of epoch 1: loss -10.32981 acc 0.66667 roc_auc 0.36140 prc_auc 0.56750[0m
[93maverage test of epoch 1: loss -13.29692 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 2: loss -16.18057 acc 0.66667 roc_auc 0.35960 prc_auc 0.56456[0m
[93maverage test of epoch 2: loss -19.03464 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 3: loss -21.88696 acc 0.66667 roc_auc 0.35860 prc_auc 0.56340[0m
[93maverage test of epoch 3: loss -24.68707 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 4: loss -27.53183 acc 0.66667 roc_auc 0.35870 prc_auc 0.56332[0m
[93maverage test of epoch 4: loss -30.29568 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 5: loss -33.14233 acc 0.66667 roc_auc 0.36130 prc_auc 0.56970[0m
[93maverage test of epoch 5: loss -35.87769 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 6: loss -38.73097 acc 0.66667 roc_auc 0.37150 prc_auc 0.59032[0m
[93maverage test of epoch 6: loss -41.44191 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 7: loss -44.30452 acc 0.66667 roc_auc 0.42000 prc_auc 0.62878[0m
[93maverage test of epoch 7: loss -46.99350 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 8: loss -49.86712 acc 0.66667 roc_auc 0.46000 prc_auc 0.64944[0m
[93maverage test of epoch 8: loss -52.53567 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 9: loss -55.42144 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 9: loss -58.07063 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 10: loss -60.96932 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 10: loss -63.59991 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 11: loss -66.51209 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 11: loss -69.12463 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 12: loss -72.05073 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 12: loss -74.64562 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 13: loss -77.58595 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 13: loss -80.16351 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 14: loss -83.11834 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 14: loss -85.67884 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 15: loss -88.64835 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 15: loss -91.19198 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 16: loss -94.17634 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 16: loss -96.70326 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 17: loss -99.70260 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 17: loss -102.21294 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 18: loss -105.22736 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 18: loss -107.72121 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -110.75082 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 19: loss -113.22831 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -116.27316 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 20: loss -118.73434 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -121.79449 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 21: loss -124.23941 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -127.31493 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 22: loss -129.74365 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -132.83457 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 23: loss -135.24712 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -138.35346 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 24: loss -140.74988 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -143.87172 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 25: loss -146.25208 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -149.38941 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 26: loss -151.75367 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -154.90652 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 27: loss -157.25474 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -160.42314 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 28: loss -162.75534 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -165.93930 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 29: loss -168.25547 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -171.45500 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 30: loss -173.75518 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -176.97029 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 31: loss -179.25447 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -182.48521 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 32: loss -184.75343 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -187.99978 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 33: loss -190.25202 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -193.51398 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -195.75024 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -199.02786 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -201.24820 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -204.54141 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -206.74574 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -210.05461 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -212.24300 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -215.56752 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -217.73996 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -221.08013 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -223.23662 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -226.59243 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -228.73295 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -232.10443 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -234.22901 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -237.61614 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -239.72475 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -243.12754 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -245.22018 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -248.63865 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -250.71535 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -254.14954 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -256.21030 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -259.66021 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -261.70504 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -265.17061 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -267.19952 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -270.68072 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -272.69369 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -276.19057 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -278.18760 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 1
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.01
[92maverage training of epoch 0: loss -3.58264 acc 0.33333 roc_auc 0.38120 prc_auc 0.59895[0m
[93maverage test of epoch 0: loss -7.16042 acc 0.34211 roc_auc 0.26308 prc_auc 0.62473[0m
[92maverage training of epoch 1: loss -10.49697 acc 0.58667 roc_auc 0.42320 prc_auc 0.60444[0m
[93maverage test of epoch 1: loss -13.67724 acc 0.65789 roc_auc 0.23692 prc_auc 0.65725[0m
[92maverage training of epoch 2: loss -16.62868 acc 0.66667 roc_auc 0.42080 prc_auc 0.60491[0m
[93maverage test of epoch 2: loss -19.57563 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 3: loss -22.45528 acc 0.66667 roc_auc 0.42000 prc_auc 0.60471[0m
[93maverage test of epoch 3: loss -25.31848 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 4: loss -28.17401 acc 0.66667 roc_auc 0.42000 prc_auc 0.60471[0m
[93maverage test of epoch 4: loss -30.98725 acc 0.65789 roc_auc 0.54000 prc_auc 0.68526[0m
[92maverage training of epoch 5: loss -33.83574 acc 0.66667 roc_auc 0.42030 prc_auc 0.60468[0m
[93maverage test of epoch 5: loss -36.61264 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 6: loss -39.46223 acc 0.66667 roc_auc 0.41980 prc_auc 0.60377[0m
[93maverage test of epoch 6: loss -42.20971 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 7: loss -45.06486 acc 0.66667 roc_auc 0.41970 prc_auc 0.59844[0m
[93maverage test of epoch 7: loss -47.78689 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 8: loss -50.65040 acc 0.66667 roc_auc 0.42370 prc_auc 0.61237[0m
[93maverage test of epoch 8: loss -53.34949 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 9: loss -56.22315 acc 0.66667 roc_auc 0.47480 prc_auc 0.65172[0m
[93maverage test of epoch 9: loss -58.90100 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 10: loss -61.78608 acc 0.66667 roc_auc 0.48000 prc_auc 0.65792[0m
[93maverage test of epoch 10: loss -64.44387 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 11: loss -67.34126 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 11: loss -69.97985 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 12: loss -72.89021 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 12: loss -75.51025 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 13: loss -78.43410 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 13: loss -81.03607 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 14: loss -83.97380 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 14: loss -86.55811 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 15: loss -89.51002 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 15: loss -92.07696 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 16: loss -95.04328 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 16: loss -97.59309 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 17: loss -100.57407 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 17: loss -103.10696 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 18: loss -106.10272 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 18: loss -108.61884 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -111.62953 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 19: loss -114.12901 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -117.15473 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 20: loss -119.63769 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -122.67855 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 21: loss -125.14509 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -128.20116 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 22: loss -130.65136 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -133.72272 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 23: loss -136.15662 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -139.24330 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 24: loss -141.66098 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -144.76307 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 25: loss -147.16460 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -150.28207 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 26: loss -152.66741 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -155.80036 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 27: loss -158.16962 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -161.31803 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 28: loss -163.67118 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -166.83513 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 29: loss -169.17221 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -172.35170 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 30: loss -174.67273 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -177.86775 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 31: loss -180.17276 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -183.38339 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 32: loss -185.67241 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -188.89863 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 33: loss -191.17164 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -194.41341 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -196.67044 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -199.92781 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -202.16883 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -205.44182 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -207.66685 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -210.95547 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -213.16458 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -216.46886 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -218.66201 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -221.98196 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -224.15915 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -227.49473 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -229.65595 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -233.00716 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -235.15239 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -238.51926 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -240.64852 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -244.03104 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -246.14435 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -249.54254 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -251.63991 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -255.05380 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -257.13526 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -260.56484 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -262.63039 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -266.07563 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -268.12519 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -271.58614 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -273.61977 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -277.09638 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -279.11403 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 2
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.01
[92maverage training of epoch 0: loss -4.86087 acc 0.64667 roc_auc 0.41540 prc_auc 0.61567[0m
[93maverage test of epoch 0: loss -8.31393 acc 0.65789 roc_auc 0.70308 prc_auc 0.77947[0m
[92maverage training of epoch 1: loss -11.28765 acc 0.66667 roc_auc 0.37860 prc_auc 0.57523[0m
[93maverage test of epoch 1: loss -14.22830 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 2: loss -17.09276 acc 0.66667 roc_auc 0.37780 prc_auc 0.57513[0m
[93maverage test of epoch 2: loss -19.93484 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 3: loss -22.77403 acc 0.66667 roc_auc 0.37760 prc_auc 0.57508[0m
[93maverage test of epoch 3: loss -25.56761 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 4: loss -28.40218 acc 0.66667 roc_auc 0.37740 prc_auc 0.57585[0m
[93maverage test of epoch 4: loss -31.16240 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 5: loss -34.00060 acc 0.66667 roc_auc 0.37830 prc_auc 0.57841[0m
[93maverage test of epoch 5: loss -36.73411 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 6: loss -39.58006 acc 0.66667 roc_auc 0.38170 prc_auc 0.58693[0m
[93maverage test of epoch 6: loss -42.29037 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 7: loss -45.14644 acc 0.66667 roc_auc 0.39270 prc_auc 0.61106[0m
[93maverage test of epoch 7: loss -47.83563 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 8: loss -50.70328 acc 0.66667 roc_auc 0.43500 prc_auc 0.63969[0m
[93maverage test of epoch 8: loss -53.37269 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 9: loss -56.25291 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 9: loss -58.90345 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 10: loss -61.79692 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 10: loss -64.42923 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 11: loss -67.33645 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 11: loss -69.95101 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 12: loss -72.87236 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 12: loss -75.46953 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 13: loss -78.40530 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 13: loss -80.98533 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 14: loss -83.93572 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 14: loss -86.49885 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 15: loss -89.46404 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 15: loss -92.01041 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 16: loss -94.99055 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 16: loss -97.52034 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 17: loss -100.51552 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 17: loss -103.02882 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 18: loss -106.03918 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 18: loss -108.53608 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 19: loss -111.56166 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 19: loss -114.04224 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 20: loss -117.08311 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 20: loss -119.54742 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 21: loss -122.60365 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 21: loss -125.05178 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 22: loss -128.12339 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 22: loss -130.55533 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 23: loss -133.64238 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 23: loss -136.05820 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 24: loss -139.16073 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 24: loss -141.56045 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 25: loss -144.67846 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 25: loss -147.06210 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 26: loss -150.19566 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 26: loss -152.56325 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 27: loss -155.71234 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 27: loss -158.06388 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 28: loss -161.22850 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 28: loss -163.56405 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 29: loss -166.74427 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 29: loss -169.06384 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 30: loss -172.25964 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 30: loss -174.56321 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 31: loss -177.77461 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 31: loss -180.06221 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 32: loss -183.28924 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 32: loss -185.56087 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 33: loss -188.80353 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 33: loss -191.05919 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 34: loss -194.31747 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 34: loss -196.55714 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 35: loss -199.83105 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 35: loss -202.05473 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 36: loss -205.34428 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 36: loss -207.55198 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 37: loss -210.85715 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 37: loss -213.04889 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 38: loss -216.36970 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 38: loss -218.54551 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 39: loss -221.88201 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 39: loss -224.04190 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 40: loss -227.39409 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 40: loss -229.53808 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 41: loss -232.90595 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 41: loss -235.03401 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 42: loss -238.41752 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 42: loss -240.52958 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 43: loss -243.92877 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 43: loss -246.02487 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 44: loss -249.43970 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 44: loss -251.51981 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 45: loss -254.95035 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 45: loss -257.01452 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 46: loss -260.46073 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 46: loss -262.50895 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 47: loss -265.97087 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 47: loss -268.00316 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 48: loss -271.48079 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 48: loss -273.49717 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
[92maverage training of epoch 49: loss -276.99047 acc 0.66667 roc_auc 0.50000 prc_auc 0.66667[0m
[93maverage test of epoch 49: loss -278.99092 acc 0.65789 roc_auc 0.50000 prc_auc 0.65789[0m
Training model with dataset, testing using fold 3
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.01
[92maverage training of epoch 0: loss -3.52645 acc 0.33775 roc_auc 0.33098 prc_auc 0.59795[0m
[93maverage test of epoch 0: loss -6.91860 acc 0.32432 roc_auc 0.81500 prc_auc 0.87072[0m
[92maverage training of epoch 1: loss -9.86968 acc 0.32450 roc_auc 0.37843 prc_auc 0.57197[0m
[93maverage test of epoch 1: loss -12.86797 acc 0.67568 roc_auc 0.68167 prc_auc 0.79318[0m
[92maverage training of epoch 2: loss -15.67995 acc 0.66225 roc_auc 0.37765 prc_auc 0.57095[0m
[93maverage test of epoch 2: loss -18.62718 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 3: loss -21.37640 acc 0.66225 roc_auc 0.37686 prc_auc 0.57044[0m
[93maverage test of epoch 3: loss -24.31746 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 4: loss -27.02327 acc 0.66225 roc_auc 0.37657 prc_auc 0.57026[0m
[93maverage test of epoch 4: loss -29.97194 acc 0.67568 roc_auc 0.52000 prc_auc 0.68865[0m
[92maverage training of epoch 5: loss -32.64219 acc 0.66225 roc_auc 0.37647 prc_auc 0.57058[0m
[93maverage test of epoch 5: loss -35.60454 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 6: loss -38.24322 acc 0.66225 roc_auc 0.37608 prc_auc 0.56941[0m
[93maverage test of epoch 6: loss -41.22244 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 7: loss -43.83187 acc 0.66225 roc_auc 0.37608 prc_auc 0.57039[0m
[93maverage test of epoch 7: loss -46.82988 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 8: loss -49.41148 acc 0.66225 roc_auc 0.37294 prc_auc 0.57149[0m
[93maverage test of epoch 8: loss -52.42948 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 9: loss -54.98425 acc 0.66225 roc_auc 0.38863 prc_auc 0.59145[0m
[93maverage test of epoch 9: loss -58.02307 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 10: loss -60.55168 acc 0.66225 roc_auc 0.43647 prc_auc 0.62891[0m
[93maverage test of epoch 10: loss -63.61192 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 11: loss -66.11485 acc 0.66225 roc_auc 0.48284 prc_auc 0.65469[0m
[93maverage test of epoch 11: loss -69.19692 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 12: loss -71.67456 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 12: loss -74.77880 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 13: loss -77.23142 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 13: loss -80.35806 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 14: loss -82.78591 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 14: loss -85.93517 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 15: loss -88.33839 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 15: loss -91.51041 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 16: loss -93.88915 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 16: loss -97.08407 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 17: loss -99.43844 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 17: loss -102.65634 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 18: loss -104.98646 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 18: loss -108.22744 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 19: loss -110.53334 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 19: loss -113.79748 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 20: loss -116.07926 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 20: loss -119.36661 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 21: loss -121.62430 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 21: loss -124.93488 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 22: loss -127.16853 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 22: loss -130.50241 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 23: loss -132.71205 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 23: loss -136.06928 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 24: loss -138.25493 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 24: loss -141.63553 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 25: loss -143.79722 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 25: loss -147.20119 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 26: loss -149.33894 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 26: loss -152.76630 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 27: loss -154.88016 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 27: loss -158.33097 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 28: loss -160.42096 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 28: loss -163.89522 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 29: loss -165.96133 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 29: loss -169.45907 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 30: loss -171.50129 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 30: loss -175.02249 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 31: loss -177.04084 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 31: loss -180.58556 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 32: loss -182.58006 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 32: loss -186.14827 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 33: loss -188.11892 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 33: loss -191.71064 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 34: loss -193.65747 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 34: loss -197.27274 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 35: loss -199.19571 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 35: loss -202.83452 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 36: loss -204.73362 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 36: loss -208.39590 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 37: loss -210.27114 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 37: loss -213.95697 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 38: loss -215.80837 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 38: loss -219.51772 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 39: loss -221.34527 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 39: loss -225.07815 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -226.88188 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 40: loss -230.63832 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -232.41822 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 41: loss -236.19826 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -237.95432 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 42: loss -241.75793 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -243.49012 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 43: loss -247.31723 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -249.02558 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 44: loss -252.87625 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -254.56076 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 45: loss -258.43503 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -260.09569 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 46: loss -263.99358 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -265.63043 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 47: loss -269.55189 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -271.16489 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 48: loss -275.10991 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -276.69910 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 49: loss -280.66772 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Training model with dataset, testing using fold 4
use LSTM
{'dfs_code_rnn': RNN(
  (input): Linear(in_features=76, out_features=8, bias=True)
  (rnn): LSTM(8, 4, batch_first=True, dropout=0.2)
), 'output_layer': MLP_layers(
  (mlp): Sequential(
    (Linear0): Linear(in_features=4, out_features=2, bias=True)
  )
)}
DfscodeRnn_cls_LSTM args.lr: 0.01
[92maverage training of epoch 0: loss -4.30864 acc 0.66225 roc_auc 0.37804 prc_auc 0.57289[0m
[93maverage test of epoch 0: loss -7.83182 acc 0.67568 roc_auc 0.86000 prc_auc 0.90919[0m
[92maverage training of epoch 1: loss -10.63945 acc 0.66225 roc_auc 0.37137 prc_auc 0.56906[0m
[93maverage test of epoch 1: loss -13.69444 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 2: loss -16.39044 acc 0.66225 roc_auc 0.37078 prc_auc 0.56886[0m
[93maverage test of epoch 2: loss -19.41189 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 3: loss -22.05417 acc 0.66225 roc_auc 0.37039 prc_auc 0.57180[0m
[93maverage test of epoch 3: loss -25.07613 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 4: loss -27.67951 acc 0.66225 roc_auc 0.36951 prc_auc 0.57219[0mUsing backend: pytorch
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
//home/FYP/heyu0012/.conda/envs/GCNN_GAP_graphgen/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1
  "num_layers={}".format(dropout, num_layers))

[93maverage test of epoch 4: loss -30.71253 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 5: loss -33.28308 acc 0.66225 roc_auc 0.37765 prc_auc 0.58641[0m
[93maverage test of epoch 5: loss -36.33186 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 6: loss -38.87264 acc 0.66225 roc_auc 0.43118 prc_auc 0.62946[0m
[93maverage test of epoch 6: loss -41.93967 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 7: loss -44.45245 acc 0.66225 roc_auc 0.46882 prc_auc 0.64865[0m
[93maverage test of epoch 7: loss -47.53923 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 8: loss -50.02514 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 8: loss -53.13261 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 9: loss -55.59239 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 9: loss -58.72120 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 10: loss -61.15539 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 10: loss -64.30602 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 11: loss -66.71498 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 11: loss -69.88778 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 12: loss -72.27180 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 12: loss -75.46700 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 13: loss -77.82630 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 13: loss -81.04411 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 14: loss -83.37886 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 14: loss -86.61942 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 15: loss -88.92977 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 15: loss -92.19324 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 16: loss -94.47928 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 16: loss -97.76575 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 17: loss -100.02756 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 17: loss -103.33711 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 18: loss -105.57478 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 18: loss -108.90748 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 19: loss -111.12105 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 19: loss -114.47696 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 20: loss -116.66650 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 20: loss -120.04566 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 21: loss -122.21118 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 21: loss -125.61364 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 22: loss -127.75518 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 22: loss -131.18096 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 23: loss -133.29858 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 23: loss -136.74770 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 24: loss -138.84138 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 24: loss -142.31389 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 25: loss -144.38368 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 25: loss -147.87962 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 26: loss -149.92552 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 26: loss -153.44487 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 27: loss -155.46689 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 27: loss -159.00967 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 28: loss -161.00784 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 28: loss -164.57408 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 29: loss -166.54837 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 29: loss -170.13809 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 30: loss -172.08852 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 30: loss -175.70172 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 31: loss -177.62832 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 31: loss -181.26499 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 32: loss -183.16777 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 32: loss -186.82792 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 33: loss -188.70689 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 33: loss -192.39055 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 34: loss -194.24571 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 34: loss -197.95289 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 35: loss -199.78420 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 35: loss -203.51487 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 36: loss -205.32236 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 36: loss -209.07655 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 37: loss -210.86022 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 37: loss -214.63798 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 38: loss -216.39778 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 38: loss -220.19908 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 39: loss -221.93506 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 39: loss -225.75992 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 40: loss -227.47207 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 40: loss -231.32049 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 41: loss -233.00880 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 41: loss -236.88076 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 42: loss -238.54527 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 42: loss -242.44078 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 43: loss -244.08147 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 43: loss -248.00047 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 44: loss -249.61738 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 44: loss -253.55995 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 45: loss -255.15301 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 45: loss -259.11916 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 46: loss -260.68840 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 46: loss -264.67811 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 47: loss -266.22347 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 47: loss -270.23676 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 48: loss -271.75828 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 48: loss -275.79513 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
[92maverage training of epoch 49: loss -277.29283 acc 0.66225 roc_auc 0.50000 prc_auc 0.66225[0m
[93maverage test of epoch 49: loss -281.35328 acc 0.67568 roc_auc 0.50000 prc_auc 0.67568[0m
Run statistics: 
('note', 'DFScodeRNN_cls_LSTM')
('graph_type', 'MUTAG')
('epochs', 50)
('batch_size', 1)
('num_layers', 1)
('embedding_size_dfscode_rnn', 8)
('hidden_size_dfscode_rnn', 4)
('dfscode_rnn_dropout', 0.2)
('number_of_mlp_layer', 0)
('lr', 0.01)
('rnn_type', 'LSTM')
('gradient_clipping', True)
('device', device(type='cuda', index=0))


Accuracy (avg): 0.66501 ROC_AUC (avg): 0.5 PRC_AUC (avg): 0.66501 

Average forward propagation time taken(ms): 2.4776352570497884
Average backward propagation time taken(ms): 0.8716304019136272

